[{"Process":{"Description":"Two main kind of cells can be used as inputs for l2p : First, you can use l2p to print symbolic layout cells. File formats can be .ap or .cp . This is given by an environment variable MBK_IN_PH that gives the appropriate symbolic layout file format. Second, you can use l2p to print real layout cells whose file formats can be .cif or .gds . This is given by an environment variable RDS_IN that gives the appropriate real layout file format. The path to the input file is set up by two environment variables: MBK_WORK_LIB(3) and if not found MBK_CATA_LIB(3). The output of l2p is a PostScript file in the current directory. The drawing size and the paper size can be specified by the user. So, you can split your drawing in as many pages as wanted. The resulting file can be then used on any adequat Postcript printer. l2p will generate in the current directory, either a single file called <cellname>.ps, either several files suffixed by -<x>x<y>.ps, depending on wether you've asked for a monopage plot or for a drawing that will be splitted on several pages. If you do something like l2p -pages=2x1 cell, it will generate two files called cell-1x1.ps, and cell-2x1.ps.","Process Name":"l2p","Link":"https:\/\/linux.die.net\/man\/1\/l2p"}},{"Process":{"Description":"bd_addr","Process Name":"l2ping","Link":"https:\/\/linux.die.net\/man\/1\/l2ping"}},{"Process":{"Description":null,"Process Name":"l4p-tmpl","Link":"https:\/\/linux.die.net\/man\/1\/l4p-tmpl"}},{"Process":{"Description":"labrea creates virtual machines for unused IP addresses in the specified block of IP addresses. LaBrea sits and listens for ARP \"who-has\" requests. When an ARP request for a particular IP goes unanswered for longer than its \"rate\" setting (default: 3 seconds), labrea crafts an ARP reply that routes all traffic destined for the IP to a \"bogus\" MAC address. labrea sniffs for TCP\/IP traffic sent to that MAC address and then responds to any SYN packet with a SYN\/ACK packet that it creates.","Process Name":"labrea","Link":"https:\/\/linux.die.net\/man\/1\/labrea"}},{"Process":{"Description":"LaCheck is a general purpose consistency checker for LaTeX documents. It reads a LaTeX document and displays warning messages, if it finds bad sequences. It should be noted, that the badness is very subjective. LaCheck is designed to help find common mistakes in LaTeX documents, especially those made by beginners. The things checked are: Mismatched groups (braces), environments and math mode delimiters. When a mismatch is found, line numbers for both start and end of the mismatch is given. The error messages comes in pairs, one for the end match and one for the beginning, marked with `<-' and `->' respectively. Bad spacing including missing a `\\ ' after an abbreviation, missing an `\\@' before a punctuation mark in a paragraph that is ended by an capital letter, double spaces like ` ', bad usage of ellipsis (like using ... instead of \\ldots, or using \\ldots where \\cdots should be used), missing before a \\cite or \\ref commands, space before footnotes, italic corrections before comma, point, or italic text, italic correction after normal text, missing italic correction when switching from italic to normal text, and double italic correction. Badly placed punctuation marks around end of math mode delimiters. This is, punctuation placed right after display math end or punctuation placed right before text math end. Sequences of whitespace followed by punctuation marks are also caught. Bad use of quotation characters, i.e. constructs like \"'word\" or \"word`\" are warned about, tabs in verbatim environments are caught, certain TeX primitives are frowned upon, attempts to give font specifiers arguments such as \\em{text} are noted, and use of @ in LaTeX macros are reported. LaCheck will read files that are input using \\input or \\include. Files with suffix `.sty' are omitted, as they probably will cause LaCheck to crash. LaCheck may be invoked from within emacs(1) using compile: To run: M-x compile RET lacheck RET , and then C-x ' to parse the messages","Process Name":"lacheck","Link":"https:\/\/linux.die.net\/man\/1\/lacheck"}},{"Process":{"Description":null,"Process Name":"lambda","Link":"https:\/\/linux.die.net\/man\/1\/lambda"}},{"Process":{"Description":"The lamboot tool starts the LAM software on each of the machines specified in the boot schema, <bhost>. The boot schema specifies the hostnames of nodes to be used in the run-time MPI environment, and optionally lists how may CPUs LAM may used on each node. The user may wish to first run the recon(1) tool to verify that LAM can be started. Starting LAM is a three step procedure. In the first step, hboot(1) is invoked on each of the specified machines. Then each machine allocates a dynamic port and communicates it back to lamboot which collects them. In the third step, lamboot gives each machine the list of machines\/ports in order to form a fully connected topology. If any machine was not able to start, or if a timeout period expires before the first step completes, lamboot invokes lamwipe(1) to terminate LAM and reports the error. The <bhost> file is a LAM boot schema written in the host file syntax. See bhost(5). Instead of the command line, a boot schema can be specified in the LAMBHOST environment variable. Otherwise a default file, lam-bhost.def, is used. LAM searches for <bhost> first in the local directory and then in the installation directory under etc\/. In addition, lamboot uses a process schema for the individual LAM nodes. A process schema (see conf(5)) is a description of the processes which constitute the operating system on a node. In general, the system administrator maintains this file -- LAM\/MPI users will generally not need to change this file. It is also possible for the user to customize the LAM software with a private process schema. The bhost file The format of the <bhost> file is documented in the bhost(5) man page. lamboot will resolve all names in <bhost> on the node in which lamboot was invoked (the origin node). After that, LAM will only use IP addresses, not names. Specifically, the name resolution configuration on all other nodes is not used. Hence, the the origin node must be able to resolve all the names in <bhost> to addresses that are reachable by all other nodes. A common mistake is to list localhost (or any name that resolves to the special address 127.0.0.1 -- the loopback TCP\/IP device) in a <bhost> file that contains other nodes. In this case, the address 127.0.0.1 would be sent to each of the other nodes as the address of the origin node. If the other nodes try to use 127.0.0.1 to contact the origin node, they will actually be contacting themselves, and would eventually timeout and fail. The IP addresses obtained from <bhost> are used for LAM's meta messages: startup and shutdown of jobs, out-of-band messages used for coordination, etc. The amount of traffic is fairly low (unless using the \"lamd\" mode of MPI message passing, in which case all MPI traffic will also utilize LAM's meta messages for transport -- see mpirun(1)). When using the TCP RPI, these IP addresses are also used for MPI message passing via direct sockets between each pair of nodes. A common case is where a \"master\" node has multiple network interface cards (NICs) -- one that is connected to a public network, and one that is connected to a private network where parallel jobs are to be run. To include the master node in a <bhost> file, the IP name (or address) of the NIC on the private network should be listed in <bhost>. This ensures that all the other nodes can reach the master node on the private network. As another example, some configurations have multiple TCP\/IP NICs in each node of a parallel job. One NIC is considered \"slow\" (e.g., 10Mbps), while the other is considered \"fast\" (e.g., 100Mbps). It is desirable to allow LAM to take advantage of the higher bandwidth on the \"fast\" network for MPI messages. As such, <bhost> should list the IP names (or addresses) of all the \"fast\" NICs. However, if the LAM RPI does not use TCP\/IP (e.g., the Myrinet\/GM RPI), the <bhost> file should probably list the \"slow\" NICs so that LAM's meta message traffic does not cause overhead and potentially detract from performance on the \"fast\" network from other high-performance applications. Delaying hostname lookups Normally, name resolution of hostnames is done on the machines where lamboot is invoked. This is done for optimization reasons, so that the list of hostnames only needs to be resolved once (potentially minimizing the amount of DNS or other hostname-lookup network traffic). However, in some non-uniform networking environments, this is not sufficient because each host may have a different IP address on each of its peers. For example, host A may have address Z on host B, but have address Y on host C. The -l option to lamboot will cause LAM to distribute hostnames to each node rather than a fully resolved set of IP addresses. Hence, each node where LAM is booted will do its own name resolution on the list of hostnames. SSI (System Services Interface) The -ssi switch allows the passing of parameters to various SSI modules. LAM's SSI modules are described in detail in lamssi(7). SSI modules have direct impact on MPI programs because they allow tunable parameters to be set at run time (such as which boot device driver to use, what parameters to pass to that driver, etc.). The -ssi switch takes two arguments: <key> and <value>. The <key> argument generally specifies which SSI module will receive the value. For example, the <key> \"boot\" is used to select which RPI to be used for starting processes on remote nodes. The <value> argument is the value that is passed. For example: lamboot -ssi boot tm Tells LAM to use the \"tm\" boot module for native launching in PBSPro \/ OpenPBS environments (the tm boot module does not require a boot schema). lamboot -ssi boot rsh -ssi rsh_agent \"ssh -x\" boot_schema Tells LAM to use the \"rsh\" boot module, and tells the rsh module to use \"ssh -x\" as the specific agent to launch executables on remote nodes. And so on. LAM's boot SSI modules are described in lamssi_boot(7). This page should be consulted for specific actions that are taken by, and how to tweak the run-time behavior of each boot module. The -ssi switch can be used multiple times to specify different <key> and\/or <value> arguments. If the same <key> is specified more than once, the <value>s are concatenated with a comma (\",\") separating them. Note that the -ssi switch is simply a shortcut for setting environment variables. The same effect may be accomplished by setting corresponding environment variables before running lamboot. The form of the environment variables that LAM sets are: LAM_MPI_SSI_<key>=<value>. Note that the -ssi switch overrides any previously set environment variables. Also note that unknown <key> arguments are still set as environment variable -- they are not checked (by lamwipe) for correctness. Illegal or incorrect <value> arguments may or may not be reported -- it depends on the specific SSI module. Remote Executable Invocation All tweakable aspects of launching executables on remote nodes during lamboot are discussed in lamssi(7) and lamssi_boot(7). Topics include (but are not limited to): discovery of remote shell, run-time overrides of the agent use to launch remote executables (e.g., rsh and ssh), etc. Closing stdio The stdio of each LAM daemon on a remote host that is launched by lamboot is closed by default. Normally, the stdio of the LAM daemon launched on the local host is left open so that the internal LAM tstdio(3) package works properly. However, it is sometimes desirable to close the stdio of the local LAM daemon as well. For example: rsh somenode lamboot -s hostfile This is because rsh waits for two conditions before exiting: lamboot to exit, and stdout \/ stderr to be closed. Without -s, stdout \/ stderr would not be closed, and rsh (and ssh) will hang even though lamboot had completed. -s causes the stdout \/ stderr of the local LAM daemon to be closed upon invocation, which will allow rsh to complete. Using -s will not affect lamboot in any other way, but it will prevent the tstdio(3) package from working properly. Fault Tolerance If the -x option is given, LAM runs in fault tolerant mode. In this mode, nodes exchange ''heart beat'' messages periodically to make sure all nodes are running and the links connecting them are operational. When a node's heart beats stop, it is declared ''dead'' and all LAM nodes (and processes) are notified. This allows users to write fault tolerant applications that can degrade gracefully, or fully recover by replacing the defunct node with another (see lamgrow(1)). Since this mode introduces a performance penalty, it is not activated by default.","Process Name":"lamboot","Link":"https:\/\/linux.die.net\/man\/1\/lamboot"}},{"Process":{"Description":null,"Process Name":"lamcheckpoint","Link":"https:\/\/linux.die.net\/man\/1\/lamcheckpoint"}},{"Process":{"Description":"The lamclean command attempts to remove all user processes and messages from all nodes. It also de-allocates all user allocated resources and cancels all user process registrations. This happens by invoking many different remote services which have previously been invoked individually by several other commands. These commands should still be used when partial selective removal of user presence is desired. Otherwise, lamclean is a quick and convenient way of starting over after a bad application run without rebooting the system. lamclean takes the following actions on the following system processes on all nodes: kenyad The LAM SIGUDIE signal (terminate) is sent to all user processes. See doom(1). bufferd The entire daemon is reset to its initial state after booting. See sweep(1). filed All user file descriptors are closed. See fctl(1). traced All traces are removed. See lamtrace(1). lamclean will not succeed if any of the nodes are unreachable due to catastrophic failure or maximum buffer overflow with link jamming. If lamclean does not return, use lamwipe(1) and lamboot(1) to restart the multicomputer.","Process Name":"lamclean","Link":"https:\/\/linux.die.net\/man\/1\/lamclean"}},{"Process":{"Description":"LAM is an MPI programming environment and development system for a message-passing parallel machine constituted with heterogeneous UNIX computers on a network. With LAM, a dedicated cluster or an existing network computing infrastructure can act as one parallel computer solving one compute-intensive problem. LAM emphasizes productivity in the application development cycle with extensive control and monitoring functionality. The user can easily debug the common errors in parallel programming and is well equipped to diagnose more difficult problems. LAM features a full implementation of the MPI communication standard, with the exception that the MPI_CANCEL function will not properly cancel messages that have been sent. User Information Users are strongly encouraged to read the LAM\/MPI User's Guide that is included with the LAM\/MPI distribution, and is provided on the main LAM\/MPI web site ( http:\/\/www.lam-mpi.org\/). Up-to-Date Information The LAM home page can be found on the World Wide Web at: http:\/\/www.lam-mpi.org\/. It should be consulted for the most current information about LAM, as well as updates, patches, etc.","Process Name":"lamd","Link":"https:\/\/linux.die.net\/man\/1\/lamd"}},{"Process":{"Description":"LAME is a program which can be used to create compressed audio files. (Lame ain't an MP3 encoder). These audio files can be played back by popular MP3 players such as mpg123 or madplay. To read from stdin, use \"-\" for <infile>. To write to stdout, use \"-\" for <outfile>.","Process Name":"lame","Link":"https:\/\/linux.die.net\/man\/1\/lame"}},{"Process":{"Description":"The lament program draws an animation of a particular puzzle box repeatedly solving itself.","Process Name":"lament","Link":"https:\/\/linux.die.net\/man\/1\/lament"}},{"Process":{"Description":"lamexec is essentially a clone of the mpirun(1), but is intended for non-MPI programs. One invocation of lamexec starts a non-MPI application running under LAM. To start the same program on all LAM nodes, the application can be specified on the lamexec command line. To start multiple applications on the LAM nodes, an application schema is required in a separate file. See appschema(5) for a description of the application schema syntax, but it essentially contains multiple lamexec command lines, less the command name itself. The ability to specify different options for different instantiations of a program is another reason to use an application schema. Location Nomenclature The location nomenclature that is used for the <where> clause mention in the SYNTAX section, above, is identical to mpirun(1)'s nomenclature. See the mpirun(1) man page for a lengthy discussion of the location nomenclature. Note that the by-CPU syntax, while valid for lamexec, is not quite as meaningful because process rank ordering in MPI_COMM_WORLD is irrelevant. As such, the by-node nomenclature is typically the preferred syntax for lamexec. Application Schema or Executable Program? To distinguish the two different forms, lamexec looks on the command line for <nodes> or the -c option. If neither is specified, then the file named on the command line is assumed to be an application schema. If either one or both are specified, then the file is assumed to be an executable program. If <nodes> and -c both are specified, then copies of the program are started on the specified nodes according to an internal LAM scheduling policy. Specifying just one node effectively forces LAM to run all copies of the program in one place. If -c is given, but not <nodes>, then all LAM nodes are used. If <nodes> is given, but not -c, then one copy of the program is run on each node. Program Transfer By default, LAM searches for executable programs on the target node where a particular instantiation will run. If the file system is not shared, the target nodes are homogeneous, and the program is frequently recompiled, it can be convenient to have LAM transfer the program from a source node (usually the local node) to each target node. The -s option specifies this behavior and identifies the single source node. Locating Files LAM looks for an executable program by searching the directories in the user's PATH environment variable as defined on the source node(s). This behavior is consistent with logging into the source node and executing the program from the shell. On remote nodes, the \".\" path is the home directory. LAM looks for an application schema in three directories: the local directory, the value of the LAMAPPLDIR environment variable, and laminstalldir\/boot, where \"laminstalldir\" is the directory where LAM\/MPI was installed. Standard I\/O LAM directs UNIX standard input to \/dev\/null on all remote nodes. On the local node that invoked lamexec, standard input is inherited from lamexec. The default is what used to be the -w option to prevent conflicting access to the terminal. LAM directs UNIX standard output and error to the LAM daemon on all remote nodes. LAM ships all captured output\/error to the node that invoked lamexec and prints it on the standard output\/error of lamexec. Local processes inherit the standard output\/error of lamexec and transfer to it directly. Thus it is possible to redirect standard I\/O for LAM applications by using the typical shell redirection procedure on lamexec. % lamexec N my_app < my_input > my_output The -f option avoids all the setup required to support standard I\/O described above. Remote processes are completely directed to \/dev\/null and local processes inherit file descriptors from lamboot(1). Pseudo-tty support The -pty option enabled pseudo-tty support for process output. This allows, among other things, for line buffered output from remote nodes (which is probably what you want). This option is not currently the default for lamexec because it has not been thoroughly tested on a variety of different Unixes. Users are encouraged to use -pty and report any problems back to the LAM Team. Current Working Directory The current working directory for new processes created on the local node is inherited from lamexec. The current working directory for new processes created on remote nodes is the remote user's home directory. This default behavior is overridden by the -D option. The -D option will change the current working directory of new processes to the directory where the executable resides before the new user's program is invoked. An alternative to the -D option is the -wd option. -wd allows the user to specify an arbitrary current working directory (vs. the location of the executable). Note that the -wd option can be used in application schema files (see appschema(5)) as well. Process Environment Processes in the application inherit their environment from the LAM daemon upon the node on which they are running. The environment of a LAM daemon is fixed upon booting of the LAM with lamboot(1) and is inherited from the user's shell. On the origin node this will be the shell from which lamboot(1) was invoked and on remote nodes this will be the shell started by rsh(1). When running dynamically linked applications which require the LD_LIBRARY_PATH environment variable to be set, care must be taken to ensure that it is correctly set when booting the LAM. Exported Environment Variables The -x option to lamexec can be used to export specific environment variables to the new processes. While the syntax of the -x option allows the definition of new variables, note that the parser for this option is currently not very sophisticated - it does not even understand quoted values. Users are advised to set variables in the environment and use -x to export them; not to define them.","Process Name":"lamexec","Link":"https:\/\/linux.die.net\/man\/1\/lamexec"}},{"Process":{"Description":"An existing LAM universe, initiated by lamboot(1), can be enlarged to include more nodes with lamgrow. One new node is added for each invocation. At a minimum, the host name that will run the new node is given on the command line. If a different userid is required to access the host, it is specified with the appropriate boot SSI options (see lamssi_boot(7)). The new node can be assigned any unused, non-negative identifier. If no identifier is specified, the highest node identifier in the current LAM universe plus one is used. Note that lamboot(1) always assigns node identifiers consecutively from 0. lamgrow can be run from any node in the current LAM universe. Specifically -- it cannot be run from the intended new host. Two invocations of lamgrow should not run concurrently, and the command attempts to detect this situation. The name of the host specified in lamgrow should not be the one which is already present in the user's LAM universe and the command attempts to detect this situation too. Resource managers will be the most common user of lamgrow. When hosts become idle and a user has expressed a desire to the manager that extra cycles should be exploited, the manager could invoke lamgrow and then launch the specified application process(es) on the new node.","Process Name":"lamgrow","Link":"https:\/\/linux.die.net\/man\/1\/lamgrow"}},{"Process":{"Description":"The lamhalt tool terminates the LAM software on each of the nodes that were initially booted with lamboot and\/or lamgrow. No additional command line arguments are necessary - lamhalt simply sends a message to each remote node telling it to shut down. Each remote node invokes tkill(1) locally to shut down. See tkill(1) for a description of how LAM is terminated on each node. lamhalt may fail if one of the remote nodes has failed, and does not respond to lamhalt's queries. In this case, the lamwipe(1) command should be used to shut down LAM\/MPI. If lamwipe(1) fails, the user can manually invoke tkill(1) on the troubled node. In extreme cases, the user may have to terminate individual LAM processes with kill(1). Older versions of lamhalt would return 1-3 seconds before the entire LAM universe was shut down. This caused problems for some LAM users, particularly those who had scripts that invoked lamboot immediately after lamhalt. lamhalt has therefore been changed to wait until the entire LAM universe is down before exiting. This makes the execution of lamhalt take a few seconds (typically less than 5). For users who want the old lamhalt behavior, use the -i (or \"immediate\") switch, which will cause lamhalt to return immediately, likely before the entire LAM universe has been taken down.","Process Name":"lamhalt","Link":"https:\/\/linux.die.net\/man\/1\/lamhalt"}},{"Process":{"Description":"The laminfo command is used to display information about a LAM\/MPI installation. Particularly with the SSI run-time module selection system, the laminfo command can be useful to scripts and resource managers to determine the capabilities of the installed LAM\/MPI in order to pass run-time parameters to MPI programs. Output can be displayed in a \"pretty\" format (i.e., suitable for human reading) and also in a parsable format (i.e., suitable for easy parsing by scripts or other automated mechanisms). There are no other LAM API functions to retrieve this data (in any language); the laminfo command is the best mechanism to obtain any configuration information about LAM\/MPI. The parsable output was designed such that common utilities such as grep, awk, cut, and sed can easily be used to extract relevant information. Running laminfo with no arguments will display a subset of configuration parameters in the \"pretty\" format (see the EXAMPLES section, below). Several command line options are available to limit exactly which information is displayed. These options, when used in conjunction with the parsable output, can provide automated mechanisms specific information about the capabilities of LAM\/MPI. General Parameters The -pretty and -parsable switches are used to select whether to display the output in \"pretty\" or machine-parsable format, respectively. If neither is specified, -pretty is the default. The -arch switch will display the architecture that LAM\/MPI was configured and compiled on. The -config switch will display a set of configuration information about the MPI capabilities of LAM\/MPI, such as whether there are C, C++, and Fortran MPI bindings available, whether there is MPI profiling support for C, C++, and Fortran, whether ROMIO support is available, whether IMPI support is available, whether debugging support is available (mostly for LAM\/MPI maintainers), and whether LAM\/MPI is \"purify clean\" (meaning that it is suitable for use with memory checking debuggers). Most of these are options to the LAM\/MPI configure script, and are configure\/compile-time selections that cannot be changed once LAM has been installed. While there is no fine-grained control to individually request each of these pieces of information, using -config in conjunction with -parsable and commands such as grep can return any individual piece of information. Param Parameters The -param switch can be used to show available SSI parameters and their default values. The type and module arguments can be used to specify a particular SSI type and\/or module, or use the special keyword \"all\" to indicate all available SSI types\/modules (respectively). Available SSI types are: all Show all SSI types base Intrinsic LAM\/MPI parameters boot Boot modules (e.g., lamboot) coll MPI collectives cr Checkpoint \/ restart RPI MPI point-to-point. The names of the modules that are available are dependant upon which modules are available for any given type. See EXAMPLES, below, for example usage. Path Parameters The -path switch returns various paths that were compiled into LAM\/MPI. These were all decided when LAM was configured, and cannot be changed at run-time. However, knowing the location of these directories can be useful in order to find LAM data files, binaries, include files, etc. The -path switch takes a parameter: item. Possible values for item are: prefix Display the prefix directory for LAM\/MPI bindir Display the directory where the LAM\/MPI executables were installed libdir Display the directory where the LAM\/MPI libraries were installed incdir Display the directory where the LAM\/MPI include files were installed pkglibdir Display the directory where the LAM\/MPI dynamic libraries were installed sysconfdir Display the directory where the LAM\/MPI help and configuration files were installed Note that although LAM's GNU configure script defaults to certain values for all of these directories based on the prefix (e.g., bindir is typically $prefix\/bin), they can all be overriden by command line switches to configure, and should therefore never be assumed. Use laminfo to determine what values were selected at configure time. Version Parameters Since each SSI module in LAM\/MPI is an independant entity in itself, it may have an entirely different version number than LAM\/MPI itself. Indeed, each SSI module has three version numbers: the version of the base SSI API that it supports, the version of the component type API that it supports, and its own version number. Most users will only care about the last one (the module's own version number). The -path switch takes two parameters: item and scope. The item can be the main LAM version itself, any of the SSI types, or a specific SSI module. There are currently four kinds of SSI modules that can be queried: boot, coll, rpi, and cr. Hence, the version numbers that can be obtained from the -version switch are: lam The version of LAM\/MPI boot The three versions of each boot SSI module boot:name The three versions of a specific boot SSI module coll The three versions of each coll SSI module coll:name The three versions of a specific coll SSI module rpi The three versions of each rpi SSI module rpi:name The three versions of a specific rpi SSI module cr The three versions of each cr SSI module cr:name The three versions of a specific cr SSI module The scope argument describes what part of the version number to display. This allows either the full version number to be displayed, or any specific individual component of the version number. Valid values for scope are: full Display the full version number (i.e., all components). A sequence of rules are used to run all the components together into a single string. Generally: major and minor are always displayed, but other components are only displayed if they are not zero. major Display the major version number minor Display the minor version number release Display the release version number alpha Display the alpha version number. In the full scope, if nonzero, this number will be preceeded by \"a\". beta Display the beta version number. In the full scope, if nonzero, this number will be preceeded by \"b\". cvs Display whether LAM was installed from a CVS checkout. In pretty mode, this will be the string \"cvs\" if true, or blank if false. In parsable mode, this will be 1 if true, 0 if false.","Process Name":"laminfo","Link":"https:\/\/linux.die.net\/man\/1\/laminfo"}},{"Process":{"Description":"The lamnodes command is used to resolve LAM node\/CPU nomenclature to Unix hostnames. It can be used to determine the current running configuration of the LAM\/MPI run-time environment, and generate a boot schema that can be used to launch LAM in the future. By default, lamnodes will print out the node number, default IP name, CPU count, and per-node flags for each node in the running LAM. gethostbyaddr(3) is used to obtain default hostnames. If gethostbyaddr(3) fails, the IP number is displayed instead. This command can be used by setup shell scripts (and the like) to determine information from a currently-running LAM universe. For example, use lamnodes to resolve particular CPUs and\/or nodes to specific unix hostnames. In a batch environment, lamnodes can be used to determine which CPUs share a common node (note that MPI_GET_PROCESSOR_NAME can be used for a similar effect in an MPI program). lamnodes also shows per-node flags. Currently defined flags are: origin The node where lamboot was executed. this_node The node where lamnodes is running. no_schedule The node will not be used to run MPI and serial processes when N and C are used to mpirun and lamexec.","Process Name":"lamnodes","Link":"https:\/\/linux.die.net\/man\/1\/lamnodes"}},{"Process":{"Description":"A MPI application can be restarted using lamrestart. lamrestart calls the module-specific restart function. If the selected SSI module is 'self', the SSI parameter specifying the arguments to be passed to mpirun should also be given as an argument to lamrestart. In case the 'blcr' Checkpoint\/Restart module is specified as the 'cr' SSI parameter, the location of the context file should be passed as an argument to lamrestart.","Process Name":"lamrestart","Link":"https:\/\/linux.die.net\/man\/1\/lamrestart"}},{"Process":{"Description":"An existing LAM session, initiated by lamboot(1), can be shrunk to include less nodes with lamshrink. One node is removed for each invocation. At a minimum, the node ID is given on the command line. Once lamshrink completes, the node ID is invalid across the remaining nodes (as can be seen by running lamnodes(1)). Existing application processes on the target node can be warned of impending shutdown with the -w option. A LAM signal (SIGFUSE) will be sent to these processes and lamshrink will then pause for the given number of seconds before proceeding with removing the node. By default, SIGFUSE is ignored. A different handler can be installed with ksignal(2). All application processes on all remaining nodes are always informed of the death of a node. This is also done with a signal (SIGSHRINK), which by default causes a process's runtime route cache to be flushed (to remove any cached information on the dead node). If this signal is re-vectored for the purpose of fault tolerance, the old handler should be called at the beginning of the new handler. The signal does not, by itself, give the process information on which node has been removed. One technique for getting this information is to query the router for information on all relevant nodes using getroute(2). The dead node will cause this routine to return an error. FAULT TOLERANCE If enabled with lamboot(1), LAM will watch for nodes that fail. The procedure for removing a node that has failed is the same as lamshrink after the warning step. In particular, the SIGSHRINK signal is delivered.","Process Name":"lamshrink","Link":"https:\/\/linux.die.net\/man\/1\/lamshrink"}},{"Process":{"Description":"The -t option of mpirun(1) and loadgo(1) allows the application to generate execution traces. These traces are first stored in a buffer within each application process. When the buffer is full and when the application terminates, the runtime buffer is flushed to the trace daemon (a structural component within the LAM daemon). The trace daemon will also collect data up to a pre-compiled limit. Beyond this limit, the oldest traces in will be forgotten in favor of the newer traces. After an application has finished, the record of its execution is stored in the trace daemons of each node that was running the application. The lamtrace command can be used to retrieve these traces and store them in one file for display by a performance visualization tool, such as xmpi(1). If the application was started by xmpi(1), lamtrace is not normally needed as the equivalent functionality is invoked with a button. Incomplete trace data can be unloaded while the application is running. The output file must not exist prior to invoking lamtrace. This is a good situation to use the -k option, which preserves the trace daemon's contents after unloading. Each reload will then get the entire run's trace data up to the present time. A running process is likely to be holding the most recent trace data in an internal buffer. A standard LAM signal, LAM_SIGTRACE (see doom(1)), causes trace enabled processes to flush the internal trace buffer to the daemon. The -f option tells lamtrace to send this signal to all target processes before unloading trace data. A race condition develops between the target process storing trace data to the daemon and the unloading procedure. The problem is foisted upon the user who gives a delay parameter after -f. Trace data are organized by node, process identifier and list number. A process can store traces on any node, although the local node is the obvious, least intrusive choice. The process can identify itself in any meaningful way (getpid(2) is a good idea) The list number is also chosen by the process. These values may be set by an instrumented library, such as libmpi(3), or directly by the application with lam_rtrstore(2). Unloading flexibility follows that of storing with the -l option selecting the list number, and standard LAM command line mnemonics selecting nodes and processes. Dropping old traces when a pre-compiled volume limit is reached only happens for positive list numbers. Traces in negatively numbered lists will be collected until the underlying system runs out of memory. Do not use negative list numbers for high volume trace data. If no process selection is given on the command line, trace data will be unloaded for all processes on each specified node. LAM, its trace daemon and lamtrace are all unaware of the format and meaning of traces. The -R option does not unload trace data. It causes the target trace daemons to free the memory occupied by trace data in the given list. If all lists are specified (no -l option), the trace daemon is effectively reset to its state after initiating LAM. Unloading MPI Trace Data A special capability, selected by the -mpi option, exists to search for and unload only the trace data generated by an MPI application. For this purpose, lamtrace is aware of the particular reserved list numbers that libmpi(3) uses to store traces. It begins by searching all specified nodes and processes (the whole LAM multicomputer, if nothing is specified) for a special trace generated by process rank 0 in MPI_COMM_WORLD of an MPI application. This special trace contains the node and process identifiers of all processes in that MPI_COMM_WORLD communicator. lamtrace then uses the node \/ process information to collect all trace data generated by libmpi(3). If multiple world communicators exist within LAM's trace daemons, the first one found is used. Multiple worlds may be present due to multiple concurrent applications, trace data from a previous run not removed (either with lamtrace or lamclean(1)), or an application that spawns processes. A particular world communicator can be located by providing precise node and process location to lamtrace. The -mpi option is not compatible with the -l option.","Process Name":"lamtrace","Link":"https:\/\/linux.die.net\/man\/1\/lamtrace"}},{"Process":{"Description":"This command has been deprecated in favor of the lamhalt command. lamwipe should only be necessary if lamhalt fails and is unable to clean up the LAM run-time environment properly. The lamwipe tool terminates the LAM software on each of the machines specified in the boot schema, <bhost>. lamwipe is the topology tool that terminates LAM on the UNIX(tm) nodes of a multicomputer system. It invokes tkill(1) on each machine. See tkill(1) for a description of how LAM is terminated on each node. The <bhost> file is a LAM boot schema written in the host file syntax. CPU counts in the boot schema are ignored by lamwipe. See bhost(5). Instead of the command line, a boot schema can be specified in the LAMBHOST environment variable. Otherwise a default file, bhost.def, is used. LAM searches for <bhost> first in the local directory and then in the installation directory under etc\/. lamwipe does not quit if a particular remote node cannot be reached or if tkill(1) fails on any node. A message is printed if either of these failures occur, in which case the user should investigate the cause of failure and, if necessary, terminate LAM by manually executing tkill(1) on the problem node(s). In extreme cases, the user may have to terminate individual LAM processes with kill(1). lamwipe will terminate after a limited number of nodes if the -n option is given. This is mainly intended for use by lamboot(1), which invokes lamwipe when a boot does not successfully complete. SSI (System Services Interface) The -ssi switch allows the passing of parameters to various SSI modules. LAM's SSI modules are described in detail in lamssi(7). SSI modules have direct impact on MPI programs because they allow tunable parameters to be set at run time (such as which boot device driver to use, what parameters to pass to that driver, etc.). The -ssi switch takes two arguments: <key> and <value>. The <key> argument generally specifies which SSI module will receive the value. For example, the <key> \"boot\" is used to select which RPI to be used for starting processes on remote nodes. The <value> argument is the value that is passed. For example: lamboot -ssi boot tm Tells LAM to use the \"tm\" boot module for native launching in PBSPro \/ OpenPBS environments (the tm boot module does not require a boot schema). lamboot -ssi boot rsh -ssi rsh_agent \"ssh -x\" boot_file Tells LAM to use the \"rsh\" boot module, and tells the rsh module to use \"ssh -x\" as the specific agent to launch executables on remote nodes. And so on. LAM's boot SSI modules are described in lamssi_boot(7). The -ssi switch can be used multiple times to specify different <key> and\/or <value> arguments. If the same <key> is specified more than once, the <value>s are concatenated with a comma (\",\") separating them. Note that the -ssi switch is simply a shortcut for setting environment variables. The same effect may be accomplished by setting corresponding environment variables before running lamwipe. The form of the environment variables that LAM sets are: LAM_MPI_SSI_<key>=<value>. Note that the -ssi switch overrides any previously set environment variables. Also note that unknown <key> arguments are still set as environment variable -- they are not checked (by lamwipe) for correctness. Illegal or incorrect <value> arguments may or may not be reported -- it depends on the specific SSI module. Remote Executable Invocation All tweakable aspects of launching executables on remote nodes during lamwipe are discussed in lamssi(7) and lamssi_boot(7). Topics include (but are not limited to): discovery of remote shell, run-time overrides of the agent use to launch remote executables (e.g., rsh and ssh), etc.","Process Name":"lamwipe","Link":"https:\/\/linux.die.net\/man\/1\/lamwipe"}},{"Process":{"Description":null,"Process Name":"langident","Link":"https:\/\/linux.die.net\/man\/1\/langident"}},{"Process":{"Description":"language-guess takes one or more file names as arguments and guesses for each one which language it is written in. It uses Text::Language::Guess, please see its manual page for details.","Process Name":"language-guess","Link":"https:\/\/linux.die.net\/man\/1\/language-guess"}},{"Process":{"Description":"lapply reads an apply-able transcript line-by-line, modifying the file system to match the transcript. Transcript lines are applied in order unless they are directories marked for deletion. In such cases, subsequent transcript lines are first applied until the file system object listed is outside of the directory. If another directory marked for deletion is encountered, the process is started recursively. lapply downloads missing files indicated by a \"+\" from the radmind server host. file is applied to the system with the attributes as described in the transcript line. File system objects marked with a \"-\" are removed. Other transcript lines indicate that a file system object must be modified or created if missing. lapply is not able to create doors or sockets. File system objects listed in the transcript and present in the file system as a different type are automatically removed. By default, lapply will exit with an error if an object's full path is not present on the file system. When run with the -C option, lapply will attempt to create any intermediate directories that are missing. Intermediated directories inherit the owner, group and permissions of its parent directory. The radmind tools are unaware of user defined file flags, some of which may prevent lapply from successfully completing. Using the -F option, lapply will remove all user defined flags. If apply-able-transcript is not given, lapply will use the standard input for reading. lapply is also capable of decoding applefiles stored on the server by lcreate(1), restoring the files' Mac OS HFS+ metadata to the client machine. (Mac OS X, HFS+-formatted drives only.)","Process Name":"lapply","Link":"https:\/\/linux.die.net\/man\/1\/lapply"}},{"Process":{"Description":"largeprimes generates a provable prime of specified bitsize and prints it on STDOUT . For more details see Crypt::Primes(3) manpage.","Process Name":"largeprimes","Link":"https:\/\/linux.die.net\/man\/1\/largeprimes"}},{"Process":{"Description":"The laser program draws vaguely laser-like moving lines","Process Name":"laser","Link":"https:\/\/linux.die.net\/man\/1\/laser"}},{"Process":{"Description":"This GUI application allows for viewing laser scanner data remotely. It connects to a Fawkes instance and reads the current data from the blackboard and updates as new data comes in. It can show high and low resolution laser interfaces, and visualize the data as beams, end points, or hull. The data can be freely zoomed, moved, and rotated by 90 degrees.","Process Name":"lasergui","Link":"https:\/\/linux.die.net\/man\/1\/lasergui"}},{"Process":{"Description":"Last searches back through the file \/var\/log\/wtmp (or the file designated by the -f flag) and displays a list of all users logged in (and out) since that file was created. Names of users and tty's can be given, in which case last will show only those entries matching the arguments. Names of ttys can be abbreviated, thus last 0 is the same as last tty0. When last catches a SIGINT signal (generated by the interrupt key, usually control-C) or a SIGQUIT signal (generated by the quit key, usually control-\\), last will show how far it has searched through the file; in the case of the SIGINT signal last will then terminate. The pseudo user reboot logs in each time the system is rebooted. Thus last reboot will show a log of all reboots since the log file was created. Lastb is the same as last, except that by default it shows a log of the file \/var\/log\/btmp, which contains all the bad login attempts.","Process Name":"last","Link":"https:\/\/linux.die.net\/man\/1\/last"}},{"Process":{"Description":null,"Process Name":"lastb","Link":"https:\/\/linux.die.net\/man\/1\/lastb"}},{"Process":{"Description":null,"Process Name":"lastcomm","Link":"https:\/\/linux.die.net\/man\/1\/lastcomm"}},{"Process":{"Description":"This manual page is not meant to be exhaustive. The complete documentation for this version of TeX can be found in the info file or manual Web2C: A TeX implementation. The LaTeX language is described in the book LaTeX - A Document Preparation System. LaTeX is a TeX macro package, not a modification to the TeX source program, so all the capabilities described in tex(1) are present. The LaTeX macros encourage writers to think about the content of their documents, rather than the form. The ideal, very difficult to realize, is to have no formatting commands (like ''switch to italic'' or ''skip 2 picas'') in the document at all; instead, everything is done by specific markup instructions: ''emphasize'', ''start a section''. The primary source of documentation for LaTeX is the LaTeX manual referenced below, and the local guide in the file local-guide.tex or local.tex or some such. elatex is the e-TeX extended mode version of LaTeX format. lambda is the Omega version of the LaTeX format. pdflatex is the pdfTeX version of the LaTeX format. On some systems latex209 and slitex are available for compatibility with older versions of LaTeX. These should not be used for new texts.","Process Name":"latex","Link":"https:\/\/linux.die.net\/man\/1\/latex"}},{"Process":{"Description":"This manual page explains the LaTeX2HTML utility, which is a Perl program that translates LaTeX document into HTML format. For each source file given as an argument the translator will create a directory containing the corresponding HTML files. For details and examples, please consult the online html documentation, a copy of which should be available in \/usr\/share\/doc\/latex2html\/manual.ps.gz or \/usr\/share\/doc\/latex2html\/html\/","Process Name":"latex2html","Link":"https:\/\/linux.die.net\/man\/1\/latex2html"}},{"Process":{"Description":"latex2png -- Convert a LaTeX file to a PNG image USAGE: latex2png [-d density] [-h] [-k] [-c] [-g] [-m] [-H home dir] file[.tex|.eps] The latex2png command converts a LaTeX file into a PNG image. The first page is translated into an image at the specified resolution. latex2png can also be used to convert encapsulated postscript (EPS) files to PNG images. Options: -c produce color image -d density density is the number of dots per inch to use in the created image (default 144 dpi) -g produce gray images -h help -H home_dir home_dir is a directory to be included in search path (default is directory that contains the LaTeX file). This is used to create PNG images in another directory (e.g., \/tmp) and still allow LaTeX to find files that it needs to include. -k keep intermediate files (for debugging) -m produce monochrome (black and white) image (default) -v version Examples: latex2png -d 144 \/tmp\/file #create \/tmp\/file.png at 144 dpi latex2png file.eps #create file.png latex2png file.tex #create file.png via latex latex2png -H . \/tmp\/file #search the cwd for image files","Process Name":"latex2png","Link":"https:\/\/linux.die.net\/man\/1\/latex2png"}},{"Process":{"Description":null,"Process Name":"latex2rtf","Link":"https:\/\/linux.die.net\/man\/1\/latex2rtf"}},{"Process":{"Description":"latrace is able to run a command and display its dynamic library calls using a LD_AUDIT libc feature (available from libc version 2.4 onward - see the section called \"DISCUSSION\" ). It is also capable to measure and display various statistics of dynamic calls. If the config file is provided, latrace will display symbol's arguments with detailed output for structures. The config file syntax is similar to the C language, with several exceptions (see the section called \"CONFIG\"). The latrace by default fully operates inside of the traced program. However another pipe mode is available, to move the main work to the latrace binary (see the section called \"PIPE mode\"). Its use is very similar to strace(1) and ltrace(1).","Process Name":"latrace","Link":"https:\/\/linux.die.net\/man\/1\/latrace"}},{"Process":{"Description":"lav2mpeg is a shell script to ease the use of the mjpeg utilities, providing a convenient way to convert from MJPEG files to popular MPEG file formats. It supports output in VCD, medium and high rate VCD, SVCD, high rate SVCD, and generic mpeg1 and mpeg2 The input files may be any combination of AVI (.avi), Quicktime (.qt) or editlist files so long as they are all lavtools- readable (e.g. MJPEG-encoded AVI\/Quicktime or DV type 2 AVI).","Process Name":"lav2mpeg","Link":"https:\/\/linux.die.net\/man\/1\/lav2mpeg"}},{"Process":{"Description":null,"Process Name":"lav2wav","Link":"https:\/\/linux.die.net\/man\/1\/lav2wav"}},{"Process":{"Description":"lav2yuv converts an MJPEG video sequence described by a sequence of MJPEG video files and\/or edit lists pointing to such files into the simple uncompressed planar 4:2:0 Y'CbCr format, as used by mpeg2enc(1) MPEG encoder and image processing filters like yuvscaler(1) or yuv2dfilter(1) or yuvdenoise(1). Output is to stdout so that by piping the output of lav2yuv into a suitable pipeline it is possible to process and then encode or play back video recorded in any of the mjpegtools MJPEG container formats: AVI, quicktime or edit lists describing editted versions of video held in such files. Mixing different files with different video formats is currently not possible. The -S -T -D options are used for scene detection which is used by linux video studio.","Process Name":"lav2yuv","Link":"https:\/\/linux.die.net\/man\/1\/lav2yuv"}},{"Process":{"Description":null,"Process Name":"lavalite","Link":"https:\/\/linux.die.net\/man\/1\/lavalite"}},{"Process":{"Description":"lavpipe reads a script file called 'pipe list' that is of a similar structure as the edit lists that can be fed into lav2yuv. For info about the pipe list format see below. The pipe list defines several video sources and filters that are combined by lavpipe to produce a single output YUV stream on stdout (which for example can be compressed and stored to disk via mpeg2enc(1) or yuv2lav(1)).","Process Name":"lavpipe","Link":"https:\/\/linux.die.net\/man\/1\/lavpipe"}},{"Process":{"Description":null,"Process Name":"lavplay","Link":"https:\/\/linux.die.net\/man\/1\/lavplay"}},{"Process":{"Description":"lavrec can be used to record video in MJPEG format (either quicktime or AVI) from a zoran video-capture device, such as the Miro\/Pinnacle DC10(+), the Iomega Buz or Linux Media Labs' LML33, or from a generic video4linux device, such as the cheap Bt848 or Bt878 based TV-cards that are being sold in every computer shop around the corner.","Process Name":"lavrec","Link":"https:\/\/linux.die.net\/man\/1\/lavrec"}},{"Process":{"Description":"lavtrans can be used to convert the recorded videos from one MJPEG \"container\" format to another one. It can also be used to split the streams, or do destructive edits. Like all the other mjpegtools(1) lavtrans also accept a edit list file in place of actual video files. This allows it to be used to construct a stand-alone copy of the editted video sequence described in the editlist. Note that lavtrans can only change the container type of MJPEG video, not the format. As such it is not possible to use it combine streams of different format.","Process Name":"lavtrans","Link":"https:\/\/linux.die.net\/man\/1\/lavtrans"}},{"Process":{"Description":"This binary is an integrated development environment for the Free Pascal Compiler (FPC) which is an advanced Turbo Pascal and Delphi (7.0) compatible multi-target Pascal compiler. The IDE uses fpc(1) The current main supported targets are Linux, Mac OS X, Freebsd, and Windows. The other targets are either based on older versions of the compiler or are still in development. This manpage is meant for quick-reference only. Lazarus comes with an online manual, which is updated constantly, while this man page can be out of date.","Process Name":"lazarus-ide","Link":"https:\/\/linux.die.net\/man\/1\/lazarus-ide"}},{"Process":{"Description":"lazbuild builds a Lazarus project or package. It compiles projects (.lpi) and packages (.lpk). It checks and automatically compiles required packages.","Process Name":"lazbuild","Link":"https:\/\/linux.die.net\/man\/1\/lazbuild"}},{"Process":{"Description":"lazres builds resources for a Lazarus project or package.","Process Name":"lazres","Link":"https:\/\/linux.die.net\/man\/1\/lazres"}},{"Process":{"Description":null,"Process Name":"lbdb-fetchaddr","Link":"https:\/\/linux.die.net\/man\/1\/lbdb-fetchaddr"}},{"Process":{"Description":"dotlock implements the traditional mail spool file locking method: To lock file, a file named file.lock is created.","Process Name":"lbdb_dotlock","Link":"https:\/\/linux.die.net\/man\/1\/lbdb_dotlock"}},{"Process":{"Description":"lbdbq is the client program for the little brother's database. It will attempt to invoke various modules to gather information about persons matching something. E.g., it may look at a list of addresses from which you have received mail, it may look at YP maps, or it may try to finger something@ <various hosts>. The behavior is configurable: Upon startup, lbdbq will source the shell scripts: \/etc\/lbdb.rc $HOME\/.lbdbrc $HOME\/.lbdb\/lbdbrc $HOME\/.lbdb\/rc if they exist. They can be used to set the following global variables: MODULES_PATH a space separated list of directories, where lbdbq should look for modules. METHODS a space separated list of the modules to use. SORT_OUTPUT If you set this to false or no, lbdbq won't sort the addresses but returns them in reverse order (which means that the most recent address in m_inmail database is first). If you set this to name, lbdbq sorts the output by real name. If you set this to comment, it sort the output by the comment (for example the date in m_inmail). If you set this to address, lbdbq sorts the output by addresses (that's the default). KEEP_DUPES If you set this to true or yes, lbdbq won't remove duplicate addresses with different real name comment fields. Note that there are defaults, so you should most probably modify these variables using constructs like this: MODULES_PATH=\"$MODULES_PATH $HOME\/lbdb_modules\" Additionally, modules may have configuration variables of their own.","Process Name":"lbdbq","Link":"https:\/\/linux.die.net\/man\/1\/lbdbq"}},{"Process":{"Description":"This manual page documents briefly the lbmount command. lbmount is a suid wrapper that creates mountpoints in \/media and bind mounts ltspfs mounted devices to there lbmount","Process Name":"lbmount","Link":"https:\/\/linux.die.net\/man\/1\/lbmount"}},{"Process":{"Description":"Compress or decompress FILE operands or standard input to regular files or standard output using the Burrows-Wheeler block-sorting text compression algorithm. The lbzip2 utility employs multiple threads and an input-bound splitter even when decompressing .bz2 files created by standard bzip2. Compression is generally considerably better than that achieved by more conventional LZ77\/LZ78-based compressors, and competitive with all but the best of the PPM family of statistical compressors. Compression is always performed, even if the compressed file is slightly larger than the original. The worst case expansion is for files of zero length, which expand to fourteen bytes. Random data (including the output of most file compressors) is coded with asymptotic expansion of around 0.5%. The command-line options are deliberately very similar to those of bzip2 and gzip, but they are not identical.","Process Name":"lbunzip2","Link":"https:\/\/linux.die.net\/man\/1\/lbunzip2"}},{"Process":{"Description":"Applications that would like to take advantage of the Low Bandwidth extension to X (LBX) must make their connections to an lbxproxy. These applications need to know nothing about LBX, they simply connect to the lbxproxy as if were a regular server. The lbxproxy accepts client connections, multiplexes them over a single connection to the X server, and performs various optimizations on the X protocol to make it faster over low bandwidth and\/or high latency connections. With regard to authentication\/authorization, lbxproxy simply passes along to the server the credentials presented by the client. Since X clients will connect to lbxproxy, it is important that the user's .Xauthority file contain entries with valid keys associated with the network ID of the proxy. lbxproxy does not get involved with how these entries are added to the .Xauthority file. The user is responsible for setting it up. The lbxproxy program has various options, all of which are optional. If :<display> is specified, the proxy will use the given display port when listening for connections. The display port is an offset from port 6000, identical to the way in which regular X display connections are specified. If no port is specified on the command line option, lbxproxy will default to port 63. If the port number that the proxy tries to listen on is in use, the proxy will attempt to use another port number. If the proxy is not using the Proxy Manager and the default port number cannot be used, the port number that is used will be written to stderr. The other command line options that can be specified are: -help Prints a brief help message about the command line options. -display dpy Specifies the address of the X server supporting the LBX extension. If this option is not specified, the display is obtained by the DISPLAY environment variable. -motion count A limited number of pointer motion events are allowed to be in flight between the server and the proxy at any given time. The maximum number of motion events that can be in flight is set with this option; the default is 8. -maxservers number The default behavior of lbxproxy is to manage a single server. However, lbxproxy can manage more than one server. The default maximum number of servers is 20. The number of servers can be overridden by setting the environment variable LBXPROXY_MAXSERVERS to the desired number. The order of precedence from highest to lowest: command line, environment variable, default number. -[terminate|reset] The default behavior of lbxproxy is to continue running as usual when it's last client exits. The -terminate option will cause lbxproxy to exit when the last client exits. The -reset option will cause lbxproxy to reset itself when the last client exits. Resetting causes lbxproxy to clean up it's state and reconnect to the server. -reconnect The default behavior of lbxproxy is to exit when its connection to the server is broken. The -reconnect option will cause lbxproxy to just reset instead (see -reset above) and attempt to reconnect to the server. -I Causes all remaining arguments to be ignored. -nolbx Disables all LBX optimizations. -nocomp Disables stream compression. -nodelta Disables delta request substitutions. -notags Disables usage of tags. -nogfx Disables reencoding of graphics requests (not including image related requests). -noimage Disables image compression. -nosquish Disables squishing of X events. -nointernsc Disables short circuiting of InternAtom requests. -noatomsfile Disables reading of the atoms control file. See the section on \"Atom Control\" for more details. -atomsfile file Overrides the default AtomControl file. See the section on \"Atom Control\" for more details. -nowinattr Disables GetWindowAttributes\/GetGeometry grouping into one round trip. -nograbcmap Disables colormap grabbing. -norgbfile Disables color name to RGB resolution in proxy. -rgbfile path Specifies an alternate RGB database for color name to RGB resolution. -tagcachesize Set the size of the proxy's tag cache (in bytes). -zlevel level Set the Zlib compression level (used for stream compression). default is 6 1 = worst compression, fastest 9 = best compression, slowest -compstats Report stream compression statistics every time the proxy resets or receives a SIGHUP signal. -nozeropad Don't zero out unused pad bytes in X requests, replies, and events. -cheaterrors Allows cheating on X protocol for the sake of improved performance. The X protocol guarantees that any replies, events or errors generated by a previous request will be sent before those of a later request. This puts substantial restrictions on when lbxproxy can short circuit a request. The -cheaterrors option allows lbxproxy to violate X protocol rules with respect to errors. Use at your own risk. -cheatevents The -cheatevents option allows lbxproxy to violate X protocol rules with respect to events as well as errors. Use at your own risk.","Process Name":"lbxproxy","Link":"https:\/\/linux.die.net\/man\/1\/lbxproxy"}},{"Process":{"Description":"Compress or decompress FILE operands or standard input to regular files or standard output using the Burrows-Wheeler block-sorting text compression algorithm. The lbzip2 utility employs multiple threads and an input-bound splitter even when decompressing .bz2 files created by standard bzip2. Compression is generally considerably better than that achieved by more conventional LZ77\/LZ78-based compressors, and competitive with all but the best of the PPM family of statistical compressors. Compression is always performed, even if the compressed file is slightly larger than the original. The worst case expansion is for files of zero length, which expand to fourteen bytes. Random data (including the output of most file compressors) is coded with asymptotic expansion of around 0.5%. The command-line options are deliberately very similar to those of bzip2 and gzip, but they are not identical.","Process Name":"lbzcat","Link":"https:\/\/linux.die.net\/man\/1\/lbzcat"}},{"Process":{"Description":null,"Process Name":"lbzip2","Link":"https:\/\/linux.die.net\/man\/1\/lbzip2"}},{"Process":{"Description":"lc tool is a license compiler for Mono. It's used to convert a licenses.licx file to a resource that can be embedded into an executable. When using commercial components for .NET they often require a license resource at runtime to make sure the developer was licensed to use this control. The most common way of making sure the component was properly licensed is by using license resources. At compile time the developer uses the lc tool to convert a licenses.licx file to a programname.exe.resources file and embed that as a managed resource during compilation.","Process Name":"lc","Link":"https:\/\/linux.die.net\/man\/1\/lc"}},{"Process":{"Description":null,"Process Name":"lcdtest","Link":"https:\/\/linux.die.net\/man\/1\/lcdtest"}},{"Process":{"Description":"lcg-aa adds an alias in the RMC or the LFC for a given GUID. If you specify a given command line option multiple times, the command takes into account only the very last one so that in a script, you can override a particular option in a pre-set option set (like gcc does). guid specifies the Grid Unique IDentifier. lfn specifies the new alias. -b,--nobdii If this flag is present, it means that you don't want to make BDII calls to get LFC endpoint. So, you have to define the environment variable 'LFC_HOST'. --connect-timeout Sets the connect timeout, used when connecting to a remote host. The connection will be aborted if the remote host doesn't reply after value seconds. Default: 60 seconds. --sendreceive-timeout Sets the send\/receive data timeout, used when transferring data to\/from a remote host. The connection will be aborted if no data is transfered after value seconds. Default: 0 (blocking). --bdii-timeout Sets the BDII timeout, used when searching information into BDII. The connection will be aborted if the search is longer than value seconds. Default: 60 seconds. vo specifies the Virtual Organization the user belongs to. If it is not specified, the environment variable LCG_GFAL_VO will be used. conf_file This argument is currently ignored. -i,--insecure Insecure mode. This argument is currently ignored. The access to the Replica Catalog or the LFC is done according to the endpoints published in MDS.","Process Name":"lcg-aa","Link":"https:\/\/linux.die.net\/man\/1\/lcg-aa"}},{"Process":{"Description":"lcg-bringonline brings SURLs online. It means that file which are on tape are recalled and put on disk for a quicker future access. If you specify a given command line option multiple times, the command takes into account only the very last one so that in a script, you can override a particular option in a pre-set option set (like gcc does). conntimeout Sets the connect timeout, used when connecting to a remote host. The connection will be aborted if the remote host doesn't reply after conntimeout seconds. Default: 60 seconds. sndtimeout Sets the send\/receive data timeout, used when transferring data to\/from a remote host. The connection will be aborted if no data is transfered after sndtimeout seconds. Default: 0 (blocking). bdiitimeout Sets the BDII timeout, used when searching information into BDII. The connection will be aborted if the search is longer than bdiitimeout seconds. Default: 60 seconds. srmtimeout Sets the SRM timeout, used when doing an asynchronous SRM request. The request will be aborted if it is still queued after srmtimeout seconds. Default: 3600 seconds (1 hour). surl specifies the Site URL. An SURL scheme can be sfn: for a classical SE or srm:. localfile specifies a local file in which there is the list of SURLs. defaulttype specifies the default SE type you want to use. Possible values are none, se, srmv1, srmv2, for respectively no default type, classic SE, SRMv1, and SRMv2. But if according to the BDII the default type is not available for this SE, it will use another type. setype specifies the SE type you want to use for the destination file. Possible values are none, se, srmv1, srmv2, for respectively no type, classic SE, SRMv1, and SRMv2. But if according to the BDII the default type is not available for this SE, it will fail. protocol specifies the list of protocols which can be used to access the file. spacetokendesc specifies the space token to use with surls -b,--nobdii If this flag is present, it means that you don't want to make BDII calls to get SE type. So, you must provide the type of the SE for srm: arguments, and full endpoint in SURLs. For SE type, defaulttype can be used. -v,--verbose Verbose mode. You can specify it twice for extra verbose mode.","Process Name":"lcg-bringonline","Link":"https:\/\/linux.die.net\/man\/1\/lcg-bringonline"}},{"Process":{"Description":null,"Process Name":"lcg-cp","Link":"https:\/\/linux.die.net\/man\/1\/lcg-cp"}},{"Process":{"Description":"lcg-cr copies a file to a Storage Element and registers the file in the Replica Catalog or the LFC. If you specify a given command line option multiple times, the command takes into account only the very last one so that in a script, you can override a particular option in a pre-set option set (like gcc does). The program prints the actual GUID on stdout. src_file specifies the source file name: the protocol can be file: or gsiftp:. dest_file specifies the destination. It can be the Storage Element fully qualified hostname or an SURL. In the latter case, the scheme can be sfn: for a classical SE or srm:. If only the fully qualified hostname is given, a filename is generated in the same format as with the Replica Manager. guid specifies the Grid Unique IDentifier. If this option is not present, a GUID is generated internally. lfn specifies the Logical File Name associated with the file. If this option is present, an entry is added to the Replica Metadata Catalog or the LFC. The entry must not exist otherwise the command fails. relative_path specifies the path relative to the SARoot for the given VO. nbstreams specifies the number of parallel streams (default 1). defaulttype specifies the default SE type you want to use. Possible values are none, se, srmv1, srmv2, for respectively no default type, classic SE, SRMv1, and SRMv2. But if according to the BDII the default type is not available for this SE, it will use another type. setype specifies the SE type you want to use for the destination file. Possible values are none, se, srmv1, srmv2, for respectively no type, classic SE, SRMv1, and SRMv2. But if according to the BDII the default type is not available for this SE, it will fail. spacetokendesc specifies the space token to use with src_file conntimeout Sets the connect timeout, used when connecting to a remote host. The connection will be aborted if the remote host doesn't reply after conntimeout seconds. Default: 60 seconds. sndtimeout Sets the send\/receive data timeout, used when transferring data to\/from a remote host. The connection will be aborted if no data is transfered after sndtimeout seconds. Default: 0 (blocking). bdiitimeout Sets the BDII timeout, used when searching information into BDII. The connection will be aborted if the search is longer than bdiitimeout seconds. Default: 60 seconds. srmtimeout Sets the SRM timeout, used when doing an asynchronous SRM request. The request will be aborted if it is still queued after srmtimeout seconds. Default: 3600 seconds (1 hour). vo specifies the Virtual Organization the user belongs to. If it is not specified, the environment variable LCG_GFAL_VO will be used. conf_file This argument is currently ignored. cksmtype is the checksum type (algorithm) to use. Possible values (case insensitive) are: NONE No checksum verification CRC32 CRC32 algorithm will be used ADLER32 Adler32 algorithm will be used MD5 MD5 algorithm will be used SHA1 SHA-1 algorithm will be used protocol_list A comma-separated list of protocols (for example protocol1,protocol2 ) --checksum If this flag is present, verification of data integrity between source and destination files will be dine using default checksum algorithm (Adler32). In case of failure, the destination won't be removed, but an error message will be printed. -b,--nobdii If this flag is present, it means that you don't want to make BDII calls to get SE type. So, you must provide the type of the SE for srm: arguments, and full endpoint in SURLs. For SE type, defaulttype can be used. -v,--verbose Verbose mode. You can specify it twice for extra verbose mode. -f,--nofilesizecheck Disables the file size check between the source and destionation file sizes.This option must be specified in case of copying named pipe. --dst-protocols The ordered list of transfer protocols to help TURL construction. The list is passed to the SE, it should pick up an appropriate one and construct destination TURL-s according to it. Ignored if the destination file does not follow the SURL scheme.","Process Name":"lcg-cr","Link":"https:\/\/linux.die.net\/man\/1\/lcg-cr"}},{"Process":{"Description":"lcg-del deletes files (either one replica or all replicas). If it was the last or only valid replica, the entries corresponding to this GUID are also removed from the RMC or the LFC. If you specify a given command line option multiple times, the command takes into account only the very last one so that in a script, you can override a particular option in a pre-set option set (like gcc does). gridfile specifies a Logical File Name, a Grid Unique IDentifier or a Site URL. An SURL scheme can be sfn: for a classical SE or srm:. localfile specifies a local file in which there is the list of SURLs. se Only the replica residing on se is deleted. vo specifies the Virtual Organization the user belongs to. If it is not specified, the environment variable LCG_GFAL_VO will be used. force This option forces exit code to be 0, even if one or more files failed. conntimeout Sets the connect timeout, used when connecting to a remote host. The connection will be aborted if the remote host doesn't reply after conntimeout seconds. Default: 60 seconds. sndtimeout Sets the send\/receive data timeout, used when transferring data to\/from a remote host. The connection will be aborted if no data is transfered after sndtimeout seconds. Default: 0 (blocking). bdiitimeout Sets the BDII timeout, used when searching information into BDII. The connection will be aborted if the search is longer than bdiitimeout seconds. Default: 60 seconds. srmtimeout Sets the SRM timeout, used when doing an asynchronous SRM request. The request will be aborted if it is still queued after srmtimeout seconds. Default: 3600 seconds (1 hour). defaulttype specifies the default SE type you want to use. Possible values are none, se, srmv1, srmv2, for respectively no default type, classic SE, SRMv1, and SRMv2. But if according to the BDII the default type is not available for this SE, it will use another type. setype specifies the SE type you want to use for the file. Possible values are none, se, srmv1, srmv2, for respectively no type, classic SE, SRMv1, and SRMv2. But if according to the BDII the default type is not available for this SE, it will fail. conf_file This argument is currently ignored. -a An attempt is made to delete all replicas for the file specified as a GUID or LFN. To remove only an alias of the replica, use lcg-ra instead. -d,--dir If this flag is present, it means that the user want to delete (empty) directory. Note that it is possible to delete only one directory at a time. -b,--nobdii If this flag is present, it means that you don't want to make BDII calls to get SE type. So, you must provide the type of the SE for srm: arguments, and full endpoint in SURLs. For SE type, defaulttype can be used. -l,--nolfc If this flag is present, it means that the SURL is not registered in any LFC server, and so you explicitely ask lcg-del to not connect to the LFC server. -v,--verbose Verbose mode. You can specify it twice for extra verbose mode.","Process Name":"lcg-del","Link":"https:\/\/linux.die.net\/man\/1\/lcg-del"}},{"Process":{"Description":null,"Process Name":"lcg-get-checksum","Link":"https:\/\/linux.die.net\/man\/1\/lcg-get-checksum"}},{"Process":{"Description":"lcg-getturls gets the TURLs for given SURLs and transfer protocols. If you specify a given command line option multiple times, the command takes into account only the very last one so that in a script, you can override a particular option in a pre-set option set (like gcc does). conntimeout Sets the connect timeout, used when connecting to a remote host. The connection will be aborted if the remote host doesn't reply after conntimeout seconds. Default: 60 seconds. sndtimeout Sets the send\/receive data timeout, used when transferring data to\/from a remote host. The connection will be aborted if no data is transfered after sndtimeout seconds. Default: 0 (blocking). bdiitimeout Sets the BDII timeout, used when searching information into BDII. The connection will be aborted if the search is longer than bdiitimeout seconds. Default: 60 seconds. srmtimeout Sets the SRM timeout, used when doing an asynchronous SRM request. The request will be aborted if it is still queued after srmtimeout seconds. Default: 3600 seconds (1 hour). surl specifies the Site URL. An SURL scheme can be sfn: for a classical SE or srm:. localfile specifies a local file in which there is the list of SURLs. defaulttype specifies the default SE type you want to use. Possible values are none, se, srmv1, srmv2, for respectively no default type, classic SE, SRMv1, and SRMv2. But if according to the BDII the default type is not available for this SE, it will use another type. setype specifies the SE type you want to use for the destination file. Possible values are none, se, srmv1, srmv2, for respectively no type, classic SE, SRMv1, and SRMv2. But if according to the BDII the default type is not available for this SE, it will fail. protocol specifies the list of protocols which can be used to access the file. spacetokendesc specifies the space token to use with surls -b,--nobdii If this flag is present, it means that you don't want to make BDII calls to get SE type. So, you must provide the type of the SE for srm: arguments, and full endpoint in SURLs. For SE type, defaulttype can be used. -v,--verbose Verbose mode. You can specify it twice for extra verbose mode.","Process Name":"lcg-getturls","Link":"https:\/\/linux.die.net\/man\/1\/lcg-getturls"}},{"Process":{"Description":"lcg-gt gets the TURL for a given SURL and transfer protocol. The program prints 1\/2\/3 lines on stdout depending on the SE type: turl, reqid and fileid. If you specify a given command line option multiple times, the command takes into account only the very last one so that in a script, you can override a particular option in a pre-set option set (like gcc does). Classic SE turl SRMv1 turl, reqid, fileid SRMv2 turl, reqtoken reqid\/fileid or reqtoken are needed to set the file state to \"Running\" or \"Done\" in the Storage Resource Manager. --connect-timeout Sets the connect timeout, used when connecting to a remote host. The connection will be aborted if the remote host doesn't reply after value seconds. Default: 60 seconds. --sendreceive-timeout Sets the send\/receive data timeout, used when transferring data to\/from a remote host. The connection will be aborted if no data is transfered after value seconds. Default: 0 (blocking). --bdii-timeout Sets the BDII timeout, used when searching information into BDII. The connection will be aborted if the search is longer than value seconds. Default: 60 seconds. --srm-timeout Sets the SRM timeout, used when doing an asynchronous SRM request. The request will be aborted if it is still queued after value seconds. Default: 3600 seconds (1 hour). surl specifies the Site URL. An SURL scheme can be sfn: for a classical SE or srm:. defaulttype specifies the default SE type you want to use. Possible values are none, se, srmv1, srmv2, for respectively no default type, classic SE, SRMv1, and SRMv2. But if according to the BDII the default type is not available for this SE, it will use another type. setype specifies the SE type you want to use. Possible values are none, se, srmv1, srmv2, for respectively no type, classic SE, SRMv1, and SRMv2. But if according to the BDII the default type is not available for this SE, it will fail. protocol specifies an ordered list of protocols to access the file. The first protocol which is supported by the SE will be used. spacetokendesc specifies the space token to use with src_file -b,--nobdii If this flag is present, it means that you don't want to make BDII calls to get SE type. So, you must provide the type of the SE for srm: arguments, and full endpoint in SURLs. For SE type, defaulttype can be used. -v,--verbose Verbose mode. You can specify it twice for extra verbose mode.","Process Name":"lcg-gt","Link":"https:\/\/linux.die.net\/man\/1\/lcg-gt"}},{"Process":{"Description":"lcg-infosites provides a user-friendly way to query the EGI\/WLCG information system for services that match given criteria. The supported options and selections are detailed below.","Process Name":"lcg-infosites","Link":"https:\/\/linux.die.net\/man\/1\/lcg-infosites"}},{"Process":{"Description":null,"Process Name":"lcg-la","Link":"https:\/\/linux.die.net\/man\/1\/lcg-la"}},{"Process":{"Description":"lcg-lg gets the GUID for a given LFN or SURL. The program prints the actual GUID on stdout. If you specify a given command line option multiple times, the command takes into account only the very last one so that in a script, you can override a particular option in a pre-set option set (like gcc does). lfn_or_surl specifies the Logical File Name or the Site URL. An SURL scheme can be sfn: for a classical SE or srm:. --connect-timeout Sets the connect timeout, used when connecting to a remote host. The connection will be aborted if the remote host doesn't reply after value seconds. Default: 60 seconds. --sendreceive-timeout Sets the send\/receive data timeout, used when transferring data to\/from a remote host. The connection will be aborted if no data is transfered after value seconds. Default: 0 (blocking). --bdii-timeout Sets the BDII timeout, used when searching information into BDII. The connection will be aborted if the search is longer than value seconds. Default: 60 seconds. vo specifies the Virtual Organization the user belongs to. If it is not specified, the environment variable LCG_GFAL_VO will be used. conf_file This argument is currently ignored. -b,--nobdii If this flag is present, it means that you don't want to make BDII calls to get SE type. So, you must provide the type of the SE for srm: arguments, and full endpoint in SURLs. For SE type, defaulttype can be used (it will be used for both source and destination). -v,--verbose Verbose mode. You can specify it twice for extra verbose mode.","Process Name":"lcg-lg","Link":"https:\/\/linux.die.net\/man\/1\/lcg-lg"}},{"Process":{"Description":"lcg-lr lists the replicas for a given LFN, GUID or SURL. If you specify a given command line option multiple times, the command takes into account only the very last one so that in a script, you can override a particular option in a pre-set option set (like gcc does). file specifies the Logical File Name, the Grid Unique IDentifier or the Site URL. An SURL scheme can be sfn: for a classical SE or srm:. --connect-timeout Sets the connect timeout, used when connecting to a remote host. The connection will be aborted if the remote host doesn't reply after value seconds. Default: 60 seconds. --sendreceive-timeout Sets the send\/receive data timeout, used when transferring data to\/from a remote host. The connection will be aborted if no data is transfered after value seconds. Default: 0 (blocking). --bdii-timeout Sets the BDII timeout, used when searching information into BDII. The connection will be aborted if the search is longer than value seconds. Default: 60 seconds. vo specifies the Virtual Organization the user belongs to. If it is not specified, the environment variable LCG_GFAL_VO will be used. conf_file This argument is currently ignored. -b,--nobdii If this flag is present, it means that you don't want to make BDII calls to get SE type. So, you must provide the type of the SE for srm: arguments, and full endpoint in SURLs. For SE type, defaulttype can be used (it will be used for both source and destination). -v,--verbose Verbose mode. You can specify it twice for extra verbose mode.","Process Name":"lcg-lr","Link":"https:\/\/linux.die.net\/man\/1\/lcg-lr"}},{"Process":{"Description":null,"Process Name":"lcg-ls","Link":"https:\/\/linux.die.net\/man\/1\/lcg-ls"}},{"Process":{"Description":"lcg-ra removes an alias in the RMC or the LFC for a given GUID. If you specify a given command line option multiple times, the command takes into account only the very last one so that in a script, you can override a particular option in a pre-set option set (like gcc does). guid specifies the Grid Unique IDentifier. lfn specifies the alias to be removed. --connect-timeout Sets the connect timeout, used when connecting to a remote host. The connection will be aborted if the remote host doesn't reply after value seconds. Default: 60 seconds. --sendreceive-timeout Sets the send\/receive data timeout, used when transferring data to\/from a remote host. The connection will be aborted if no data is transfered after value seconds. Default: 0 (blocking). --bdii-timeout Sets the BDII timeout, used when searching information into BDII. The connection will be aborted if the search is longer than value seconds. Default: 60 seconds. vo specifies the Virtual Organization the user belongs to. If it is not specified, the environment variable LCG_GFAL_VO will be used. conf_file This argument is currently ignored. -b,--nobdii If this flag is present, it means that you don't want to make BDII calls to get SE type. So, you must provide the type of the SE for srm: arguments, and full endpoint in SURLs. For SE type, defaulttype can be used (it will be used for both source and destination). -v,--verbose Verbose mode. You can specify it twice for extra verbose mode.","Process Name":"lcg-ra","Link":"https:\/\/linux.die.net\/man\/1\/lcg-ra"}},{"Process":{"Description":null,"Process Name":"lcg-rep","Link":"https:\/\/linux.die.net\/man\/1\/lcg-rep"}},{"Process":{"Description":"lcg-replica-manager is a replacement for the EDG Replica Manager. All commands supported by lcg_utils are included. The command lines options accepted are those of the edg-rm script.","Process Name":"lcg-replica-manager","Link":"https:\/\/linux.die.net\/man\/1\/lcg-replica-manager"}},{"Process":{"Description":null,"Process Name":"lcg-rf","Link":"https:\/\/linux.die.net\/man\/1\/lcg-rf"}},{"Process":{"Description":"lcg-sd sets file status to \"Done\" for a given SURL in a specified request. This is only meaningful if the space is managed by an SRM. If you specify a given command line option multiple times, the command takes into account only the very last one so that in a script, you can override a particular option in a pre-set option set (like gcc does). --connect-timeout Sets the connect timeout, used when connecting to a remote host. The connection will be aborted if the remote host doesn't reply after value seconds. Default: 60 seconds. --sendreceive-timeout Sets the send\/receive data timeout, used when transferring data to\/from a remote host. The connection will be aborted if no data is transfered after value seconds. Default: 0 (blocking). --bdii-timeout Sets the BDII timeout, used when searching information into BDII. The connection will be aborted if the search is longer than value seconds. Default: 60 seconds. --srm-timeout Sets the SRM timeout, used when doing an asynchronous SRM request. The request will be aborted if it is still queued after value seconds. Default: 3600 seconds (1 hour). surl specifies the Site URL. An SURL starts with srm:. reqid is the request identifier returned by lcg_gt with SRMv1. fileid is the file ordinal returned by lcg_gt with SRMv1. reqtoken is the token returned by lcg_gt with SRMv2. oflag Ignored. Kept for syntax backward compatibility. Put '0' for example. -b,--nobdii If this flag is present, it means that you don't want to make BDII calls to get SE type. So, you must provide full endpoint in SURLs. The SE type is deduced from argument list. If you specify reqid and fileid it is a SRMv1 endpoint. If you specify reqtoken it is a SRMv2 endpoint. -v,--verbose Verbose mode. You can specify it twice for extra verbose mode.","Process Name":"lcg-sd","Link":"https:\/\/linux.die.net\/man\/1\/lcg-sd"}},{"Process":{"Description":"lcg-stmd get space tokens associated to a space token description, and their metadata. If you specify a given command line option multiple times, the command takes into account only the very last one so that in a script, you can override a particular option in a pre-set option set (like gcc does). --connect-timeout Sets the connect timeout, used when connecting to a remote host. The connection will be aborted if the remote host doesn't reply after value seconds. Default: 60 seconds. --sendreceive-timeout Sets the send\/receive data timeout, used when transferring data to\/from a remote host. The connection will be aborted if no data is transfered after value seconds. Default: 0 (blocking). --bdii-timeout Sets the BDII timeout, used when searching information into BDII. The connection will be aborted if the search is longer than value seconds. Default: 60 seconds. --srm-timeout Sets the SRM timeout, used when doing an asynchronous SRM request. The request will be aborted if it is still queued after value seconds. Default: 3600 seconds (1 hour). -i,--insecure Insecure mode. This argument is currently ignored. -b,--nobdii If this flag is present, it means that you don't want to make BDII calls to get SE type. So, you must provide the full (SRMv2) endpoint. timeout specifies the value of timeout (default 0). spacetokendesc specify the space token description whom you want to get metadata from. endpoint the endpoint of the SE where the spacetokendesc is defined. Note that as only SRMv2 supports space tokens the endpoint must be SRMv2-compliant. -v,--verbose Verbose mode. You can specify it twice for extra verbose mode.","Process Name":"lcg-stmd","Link":"https:\/\/linux.die.net\/man\/1\/lcg-stmd"}},{"Process":{"Description":null,"Process Name":"lcg-uf","Link":"https:\/\/linux.die.net\/man\/1\/lcg-uf"}},{"Process":{"Description":"lcg_util is a set of methods interfacing to the Storage Elements and the RLS or the LFC. Two interfaces are provided: API and CLI. Use man command for details of the lcg_util commands: lcg-aa add an alias in the RMC or the LFC for a given GUID lcg-cp copy a Grid file to a local destination lcg-cr copy and register a file lcg-del delete files (SURLs or LFNs) lcg-getturls get the TURLs for given SURLs and transfer protocols lcg-gt get the TURL for a given SURL and transfer protocols lcg-la list the aliases for a given LFN, GUID or SURL lcg-lg get the GUID for a given LFN or SURL lcg-lr list the replicas for a given LFN, GUID or SURL lcg-ls list file information for given SURLs or LFNs lcg-ra remove an alias in the RMC or the LFC for a given GUID lcg-rep copy a file from one Storage Element to another Storage Element and registers it in the LRC or the LFC lcg-rf register in the LRC (and optionally in the RMC) or the LFC a file residing on an SE lcg-sd set file status to \"Done\" for a given SURL in a specified request lcg-uf unregister in the LRC or the LFC a file residing on an SE","Process Name":"lcg_util","Link":"https:\/\/linux.die.net\/man\/1\/lcg_util"}},{"Process":{"Description":"Displays or allows changing password policy of user.","Process Name":"lchage","Link":"https:\/\/linux.die.net\/man\/1\/lchage"}},{"Process":{"Description":"Displays and allows changing information about user that is available using the finger(1) command (usually stored in the \"gecos\" field of \/etc\/passwd). If the user argument is not provided, username of the invoking user is used; the user argument is ignored if lchfn is run set-uid to a different user. Entering an empty string (by pressing Enter) at a prompt is interpreted as accepting a default value; to erase an attribute (or to use an empty string as the attribute value), enter a single dot character.","Process Name":"lchfn","Link":"https:\/\/linux.die.net\/man\/1\/lchfn"}},{"Process":{"Description":"Displays and allows changing login shell of user. If the user argument is not provided, username of the invoking user is used; the user argument is ignored if lchsh is run set-uid to a different user. Entering an empty string (by pressing Enter) at the \"New Shell\" prompt is interpreted as accepting the current value.","Process Name":"lchsh","Link":"https:\/\/linux.die.net\/man\/1\/lchsh"}},{"Process":{"Description":"lckdo runs a program with a lock held, in order to prevent multiple processes from running in parallel. Use just like nice or nohup. Now that util-linux contains a similar command named flock, lckdo is deprecated, and will be removed from some future version of moreutils.","Process Name":"lckdo","Link":"https:\/\/linux.die.net\/man\/1\/lckdo"}},{"Process":{"Description":"lcksum verifies and updates the checksums and file sizes of the transcript transcript line-by-line. If more than one transcript is passed to lcksum, all transcripts will be verified and updated. lcksum compares the checksum and file size listed in transcript to that of the file in the file system. Files must be located in file directory associated with transcript. With the -n option lcksum verifies but does not modify transcript. If there is a difference in either the checksum or file size, the transcript line is updated using the checksum, file size and modification time of the actual file. In update mode, lcksum may modify the file sizes and\/or checksums in transcript, so the user must have write access to transcript. If an error occurs during an update of transcript, lcksum removes the temporary copy of transcript that it created and exits with a status of 2. lcksum also verifies that transcript is sorted in depth first order. With the -P option, lcksum will only verify transcript lines with paths starting with prefix.","Process Name":"lcksum","Link":"https:\/\/linux.die.net\/man\/1\/lcksum"}},{"Process":{"Description":"lcm-gen is the Lightweight Communications and Marshalling code generation utility. It takes as input one or more .lcm files containing LCM message type definitions, and generates language-specific bindings for marshalling and unmarshalling messages of the specified types. Currently, lcm-gen is capable of generating language bindings for C, C++, C#, Python, and Java.","Process Name":"lcm-gen","Link":"https:\/\/linux.die.net\/man\/1\/lcm-gen"}},{"Process":{"Description":"lcm-logger is the Lightweight Communications and Marshalling message logging utility. It subscribes to all channels on an LCM network, and records all messages received to FILE. If FILE is not specified, then a filename is automatically chosen.","Process Name":"lcm-logger","Link":"https:\/\/linux.die.net\/man\/1\/lcm-logger"}},{"Process":{"Description":"lcm-logplayer is a minimalist Lightweight Communications and Marshalling logfile playback tool. It provides a small set of options for controlling logfile playback, and is primarily intended for situations where a command line program is either desired or the only option. In situations where both Java and a graphical interface are available, lcm-logplayer-gui provides a more featureful logplayer with a graphical user interface.","Process Name":"lcm-logplayer","Link":"https:\/\/linux.die.net\/man\/1\/lcm-logplayer"}},{"Process":{"Description":null,"Process Name":"lcm-logplayer-gui","Link":"https:\/\/linux.die.net\/man\/1\/lcm-logplayer-gui"}},{"Process":{"Description":"lcm-spy is the Lightweight Communications and Marshalling traffic inspection utility. It is a graphical tool for viewing messages received on an LCM network, and is analagous to tools like Ethereal\/Wireshark and tcpdump in that it is able to inspect all LCM messages received and provide information and statistics on the channels used. When given appropriate LCM type definitions, lcm-spy is able to automatically detect and decode messages, and can display the individual fields of recognized messages. lcm-spy is limited to displaying statistics for unrecognized messages. lcm-spy collects the following statistics for each channel: - Channel name - Number of messages received - Message Rate (Hz) - Bandwidth (KB\/s) On its own, this information can often be used to verify that messages are being transmitted on the expected channels, and at the expected data rates.","Process Name":"lcm-spy","Link":"https:\/\/linux.die.net\/man\/1\/lcm-spy"}},{"Process":{"Description":null,"Process Name":"lcov","Link":"https:\/\/linux.die.net\/man\/1\/lcov"}},{"Process":{"Description":"lcreate reads and uploads a transcript and all corresponding files to the radmind server. lcreate verifies the size listed in the transcript with the actual size of the file and stops on any differences. If the -F option is given, lcreate will store the file on the server and give a warning. If the -n option is given, no files or transcripts are uploaded. Instead, lcreate verifies that all files exist in the filesystem and have the same size as listed in the transcript. If used with the -c option, checksums are also verified. If the -n option is given, no files or transcripts are uploaded. Instead, lcreate uses access(2) to verify that all files in the transcript exist in the filesystem, are readable by the user and have the same size as listed in the transcript. If used with the -c option, rather than calling access(2), checksums are caluclated to verify file contents and user access. If the -N option is given, indicating the transcript specified for upload is negative, lcreate will upload all corresponding files as zero length. If the -T option is given, lcreate will upload the transcript only. No corresponding files will be uploaded. The transcript's stored name is, by default, the last part ( after the slash ) of the given path, or as specified by the name given with the -t option. lcreate will print ( to the standard output ) the entire protocol exchange with the radmind server when the -v option is given. By default, lcreate displays the percentage of bytes processed in a format that can be passed directly to iHook. lcreate stores a Macintosh HFS+ file's data and corresponding metadata in a single applefile(5) on the server. With the -N option, applefiles are stored with a zero length resource fork, zero length data fork and a creator type of RDMD. Systems running Mac OS X on UFS-formatted drives do not need this special support.","Process Name":"lcreate","Link":"https:\/\/linux.die.net\/man\/1\/lcreate"}},{"Process":{"Description":null,"Process Name":"ld","Link":"https:\/\/linux.die.net\/man\/1\/ld"}},{"Process":{"Description":"This linker understands only the object files produced by the as86 assembler, it can link them into either an impure or a separate I&D executable. The linking defaults are everything off or none except for -0 and the output file is a.out. There is not a standard library location defined in the linker.","Process Name":"ld86","Link":"https:\/\/linux.die.net\/man\/1\/ld86"}},{"Process":{"Description":null,"Process Name":"ldap-agent","Link":"https:\/\/linux.die.net\/man\/1\/ldap-agent"}},{"Process":{"Description":"ldap2zone is a tool that reads info for a zone from LDAP and constructs a standard plain ascii zone file that is written to the standard output. The LDAP information has to be stored using the dnszone schema. The schema is used by BIND with LDAP back-end. zone-name Name of the zone, eg \"mydomain.net.\" LDAP-URL LDAP URL to dnszone information default-ttl Default TTL value to be used in zone serial (optional) Program checks this number to be different than SOA serial number.","Process Name":"ldap2zone","Link":"https:\/\/linux.die.net\/man\/1\/ldap2zone"}},{"Process":{"Description":null,"Process Name":"ldapadd","Link":"https:\/\/linux.die.net\/man\/1\/ldapadd"}},{"Process":{"Description":"ldapcompare is a shell-accessible interface to the ldap_compare_ext(3) library call. ldapcompare opens a connection to an LDAP server, binds, and performs a compare using specified parameters. The DN should be a distinguished name in the directory. Attr should be a known attribute. If followed by one colon, the assertion value should be provided as a string. If followed by two colons, the base64 encoding of the value is provided. The result code of the compare is provided as the exit code and, unless ran with -z, the program prints TRUE, FALSE, or UNDEFINED on standard output.","Process Name":"ldapcompare","Link":"https:\/\/linux.die.net\/man\/1\/ldapcompare"}},{"Process":{"Description":null,"Process Name":"ldapdelete","Link":"https:\/\/linux.die.net\/man\/1\/ldapdelete"}},{"Process":{"Description":"ldapdiff combines classical \"diff\" and \"patch\" functionality in one application. the difference is, that ldapdiff is not designed for use on flat ascii files, it is designed for \"patching\" ldap directories using ldif files. This manual page was written for the Debian distribution because the original program does not have a manual page.","Process Name":"ldapdiff","Link":"https:\/\/linux.die.net\/man\/1\/ldapdiff"}},{"Process":{"Description":"ldapexop issues the LDAP extended operation specified by oid or one of the special keywords whoami, cancel, or refresh. Additional data for the extended operation can be passed to the server using data or base-64 encoded as b64data in the case of oid, or using the additional parameters in the case of the specially named extended operations above. Please note that ldapexop behaves differently for the same extended operation when it was given as an OID or as a specialliy named operation: Calling ldapexop with the OID of the whoami (RFC 4532) extended operation ldapexop [<options>] 1.3.6.1.4.1.4203.1.11.3 yields # extended operation response\ndata:: <base64 encoded response data> while calling it with the keyword whoami ldapexop [<options>] whoami results in dn:<client's identity>","Process Name":"ldapexop","Link":"https:\/\/linux.die.net\/man\/1\/ldapexop"}},{"Process":{"Description":"ldapmodify is a shell-accessible interface to the ldap_add_ext(3), ldap_modify_ext(3), ldap_delete_ext(3) and ldap_rename(3). library calls. ldapadd is implemented as a hard link to the ldapmodify tool. When invoked as ldapadd the -a (add new entry) flag is turned on automatically. ldapmodify opens a connection to an LDAP server, binds, and modifies or adds entries. The entry information is read from standard input or from file through the use of the -f option.","Process Name":"ldapmodify","Link":"https:\/\/linux.die.net\/man\/1\/ldapmodify"}},{"Process":{"Description":"ldapmodrdn is a shell-accessible interface to the ldap_rename(3) library call. ldapmodrdn opens a connection to an LDAP server, binds, and modifies the RDN of entries. The entry information is read from standard input, from file through the use of the -f option, or from the command-line pair dn and rdn.","Process Name":"ldapmodrdn","Link":"https:\/\/linux.die.net\/man\/1\/ldapmodrdn"}},{"Process":{"Description":"ldappasswd is a tool to set the password of an LDAP user. ldappasswd uses the LDAPv3 Password Modify (RFC 3062) extended operation. ldappasswd sets the password of associated with the user [or an optionally specified user]. If the new password is not specified on the command line and the user doesn't enable prompting, the server will be asked to generate a password for the user. ldappasswd is neither designed nor intended to be a replacement for passwd(1) and should not be installed as such.","Process Name":"ldappasswd","Link":"https:\/\/linux.die.net\/man\/1\/ldappasswd"}},{"Process":{"Description":"ldapsearch is a shell-accessible interface to the ldap_search_ext(3) library call. ldapsearch opens a connection to an LDAP server, binds, and performs a search using specified parameters. The filter should conform to the string representation for search filters as defined in RFC 4515. If not provided, the default filter, (objectClass=*), is used. If ldapsearch finds one or more entries, the attributes specified by attrs are returned. If * is listed, all user attributes are returned. If + is listed, all operational attributes are returned. If no attrs are listed, all user attributes are returned. If only 1.1 is listed, no attributes will be returned. The search results are displayed using an extended version of LDIF. Option -L controls the format of the output.","Process Name":"ldapsearch","Link":"https:\/\/linux.die.net\/man\/1\/ldapsearch"}},{"Process":{"Description":"ldapurl is a command that allows to either compose or decompose LDAP URIs. When invoked with the -H option, ldapurl extracts the components of the ldapuri option argument, unescaping hex-escaped chars as required. It basically acts as a frontend to the ldap_url_parse(3) call. Otherwise, it builds an LDAP URI based on the components passed with the appropriate options, performing the inverse operation. Option -H is incompatible with options -a, -b, -E, -f, -H, -h, -p, -S, and -s.","Process Name":"ldapurl","Link":"https:\/\/linux.die.net\/man\/1\/ldapurl"}},{"Process":{"Description":"Quickstart: ldapvi --discover --host HOSTNAME Perform an LDAP search and update results using a text editor. Other usage: ldapvi --out [OPTION]... [FILTER] [AD]... Print entries ldapvi --in [OPTION]... [FILENAME] Load change records ldapvi --delete [OPTION]... DN... Edit a delete record ldapvi --rename [OPTION]... DN1 DN2 Edit a rename record Connection options: -h, --host URL Server. -D, --user USER Search filter or DN: User to bind as. [1] Sets --bind simple. -w, --password SECRET Password (also valid for SASL). --bind [simple,sasl] Disable or enable SASL. --bind-dialog [never,auto,always] Interactive login dialog. SASL options (these parameters set --bind sasl): -I, --sasl-interactive Set --bind-dialog always. -O, --sasl-secprops P SASL security properties. -Q, --sasl-quiet Set --bind-dialog never. -R, --sasl-realm R SASL realm. -U, --sasl-authcid AC SASL authentication identity. -X, --sasl-authzid AZ SASL authorization identity. -Y, --sasl-mech MECH SASL mechanism. Search parameters: -b, --base DN Search base. -s, --scope SCOPE Search scope. One of base|one|sub. -S, --sort KEYS Sort control (critical). Miscellaneous options: --add (Only with --in, --ldapmodify:) Treat attrval records as new entries to add. -o, --class OBJCLASS Class to add. Can be repeated. Implies -A. --config Print parameters in ldap.conf syntax. -c --continue Ignore LDAP errors and continue processing. --deleteoldrdn (Only with --rename:) Delete the old RDN. -a, --deref never|searching|finding|always -d, --discover Auto-detect naming contexts. [2] -A, --empty Don't search, start with empty file. See -o. --encoding [ASCII|UTF-8|binary] The encoding to allow. Default is UTF-8. -H, --help This help. --ldap-conf Always read libldap configuration. -m, --may Show missing optional attributes as comments. -M, --managedsait manageDsaIT control (critical). --noquestions Commit without asking for confirmation. -!, --noninteractive Never ask any questions. -q, --quiet Disable progress output. -R, --read DN Same as -b DN -s base '(objectclass=*)' + * -Z, --starttls Require startTLS. --tls [never|allow|try|strict] Level of TLS strictess. -v, --verbose Note every update. Shortcuts: --ldapsearch Short for --quiet --out --ldapmodify Short for --noninteractive --in --ldapdelete Short for --noninteractive --delete --ldapmoddn Short for --noninteractive --rename Environment variables: VISUAL, EDITOR, PAGER. [1] User names can be specified as distinguished names: uid=foo,ou=bar,dc=acme,dc=com or search filters: (uid=foo) Note the use of parenthesis, which can be omitted from search filters usually but are required here. For this searching bind to work, your client library must be configured with appropriate default search parameters. [2] Repeat the search for each naming context found and present the concatenation of all search results. Conflicts with --base. With --config, show a BASE configuration line for each context. A special (offline) option is --diff, which compares two files and writes any changes to standard output in LDIF format.","Process Name":"ldapvi","Link":"https:\/\/linux.die.net\/man\/1\/ldapvi"}},{"Process":{"Description":"ldapwhoami implements the LDAP \"Who Am I?\" extended operation. ldapwhoami opens a connection to an LDAP server, binds, and performs a whoami operation.","Process Name":"ldapwhoami","Link":"https:\/\/linux.die.net\/man\/1\/ldapwhoami"}},{"Process":{"Description":"ldbadd adds records to an ldb(7) database. It reads the ldif(5) files specified on the command line and adds the records from these files to the LDB database, which is specified by the -H option or the LDB_URL environment variable. If - is specified as a ldb file, the ldif input is read from standard input.","Process Name":"ldb3add","Link":"https:\/\/linux.die.net\/man\/1\/ldb3add"}},{"Process":{"Description":null,"Process Name":"ldb3del","Link":"https:\/\/linux.die.net\/man\/1\/ldb3del"}},{"Process":{"Description":"ldbedit is a utility that allows you to edit LDB entries (in tdb files, sqlite files or LDAP servers) using your preferred editor. ldbedit generates an LDIF file based on your query, allows you to edit the LDIF, and then merges that LDIF back into the LDB backend.","Process Name":"ldb3edit","Link":"https:\/\/linux.die.net\/man\/1\/ldb3edit"}},{"Process":{"Description":null,"Process Name":"ldb3modify","Link":"https:\/\/linux.die.net\/man\/1\/ldb3modify"}},{"Process":{"Description":"ldbrename is a utility that allows you to rename trees in an LDB database based by DN. This utility takes two arguments: the original DN name of the top element and the DN to change it to.","Process Name":"ldb3rename","Link":"https:\/\/linux.die.net\/man\/1\/ldb3rename"}},{"Process":{"Description":null,"Process Name":"ldb3search","Link":"https:\/\/linux.die.net\/man\/1\/ldb3search"}},{"Process":{"Description":"ldbadd adds records to an ldb(3) database. It reads the ldif(5) files specified on the command line and adds the records from these files to the LDB database, which is specified by the -H option or the LDB_URL environment variable. If - is specified as a ldb file, the ldif input is read from standard input.","Process Name":"ldbadd","Link":"https:\/\/linux.die.net\/man\/1\/ldbadd"}},{"Process":{"Description":"ldbdel deletes records from an ldb(3) database. It deletes the records identified by the dn's specified on the command-line. ldbdel uses either the database that is specified with the -H option or the database specified by the LDB_URL environment variable.","Process Name":"ldbdel","Link":"https:\/\/linux.die.net\/man\/1\/ldbdel"}},{"Process":{"Description":"ldbedit is a utility that allows you to edit LDB entries (in tdb files, sqlite files or LDAP servers) using your preferred editor. ldbedit generates an LDIF file based on your query, allows you to edit the LDIF, and then merges that LDIF back into the LDB backend.","Process Name":"ldbedit","Link":"https:\/\/linux.die.net\/man\/1\/ldbedit"}},{"Process":{"Description":"ldbmodify changes, adds and deletes records in a LDB database. The changes that should be made to the LDB database are read from the specified LDIF-file. If - is specified as the filename, input is read from stdin. For now, see ldapmodify(1) for details on the LDIF file format.","Process Name":"ldbmodify","Link":"https:\/\/linux.die.net\/man\/1\/ldbmodify"}},{"Process":{"Description":null,"Process Name":"ldbrename","Link":"https:\/\/linux.die.net\/man\/1\/ldbrename"}},{"Process":{"Description":"ldbsearch searches a LDB database for records matching the specified expression (see the ldapsearch(1) manpage for a description of the expression format). For each record, the specified attributes are printed.","Process Name":"ldbsearch","Link":"https:\/\/linux.die.net\/man\/1\/ldbsearch"}},{"Process":{"Description":"This tool is a LDAP client targeted to validate the reliability of the product under a wide variety of stress conditions.","Process Name":"ldclt","Link":"https:\/\/linux.die.net\/man\/1\/ldclt"}},{"Process":{"Description":null,"Process Name":"ldd","Link":"https:\/\/linux.die.net\/man\/1\/ldd"}},{"Process":{"Description":null,"Process Name":"ldif","Link":"https:\/\/linux.die.net\/man\/1\/ldif"}},{"Process":{"Description":"ldm(1) starts an X server and presents the user with a login screen, similar to the gdm(1) login prompt. instead of using the XDMCP protocol, ldm(1) uses ssh(1) connect to remote servers, then starts an Xsession either via ssh(1) X forwarding, or direct TCP\/IP connection. It was designed for the LTSP project, but could be used in a non-ltsp environment as well.","Process Name":"ldm","Link":"https:\/\/linux.die.net\/man\/1\/ldm"}},{"Process":{"Description":"ldns-chaos retrieves all the addresses of the nameserver and then queries each address for its version.bind and hostname.bind. ldns-chaos is a bit more complex than ldns-mx.","Process Name":"ldns-chaos","Link":"https:\/\/linux.die.net\/man\/1\/ldns-chaos"}},{"Process":{"Description":null,"Process Name":"ldns-compare-zones","Link":"https:\/\/linux.die.net\/man\/1\/ldns-compare-zones"}},{"Process":{"Description":"When writing programs using ldns, you have to tell the compiler where to look for include files and what libraries from which location to link to. ldns-config can be used to find out what flags to use with the C compiler and the linker.","Process Name":"ldns-config","Link":"https:\/\/linux.die.net\/man\/1\/ldns-config"}},{"Process":{"Description":null,"Process Name":"ldns-dane","Link":"https:\/\/linux.die.net\/man\/1\/ldns-dane"}},{"Process":{"Description":"dpa is used to analyze dns packets in trace files. It has 3 main options: count, filter, and count uniques (i.e. count all different occurences).","Process Name":"ldns-dpa","Link":"https:\/\/linux.die.net\/man\/1\/ldns-dpa"}},{"Process":{"Description":"ldns-gen-zone reads a DNS zone file and prints it. It is build for speed, not for a nice formatting. The output has one resource record per line and no pretty-printing makeup. DNSSEC data (NSEC, NSEC3, RRSIG or DNSKEY) is not stripped. You may want to use ldns-read-zone for that. Existing DS records are also not stripped. The idea is to use this tool for quickly generating a representative artificial zonefile from a real zonefile, to use it for testing purposes.","Process Name":"ldns-gen-zone","Link":"https:\/\/linux.die.net\/man\/1\/ldns-gen-zone"}},{"Process":{"Description":"ldns-key2ds is used to transform a public DNSKEY RR to a DS RR. When run it will read file with a DNSKEY RR in it and it will create a .ds file with the DS RR in it. It prints out the basename for this file (K<name>+<alg>+<id>). By default it takes a pick of algorithm similar to the key algorithm, SHA1 for RSASHA1, and so on.","Process Name":"ldns-key2ds","Link":"https:\/\/linux.die.net\/man\/1\/ldns-key2ds"}},{"Process":{"Description":"ldns-keyfetcher is used to retrieve the DNSKEYs of a zone. First it finds all authoritative nameservers of the zone by tracing it from the root down. All authoritative nameservers are then queried (using TCP) for the DNSKEY RRset of the zone apex. If the results are all the same, the key resource record set is printed.","Process Name":"ldns-keyfetcher","Link":"https:\/\/linux.die.net\/man\/1\/ldns-keyfetcher"}},{"Process":{"Description":null,"Process Name":"ldns-keygen","Link":"https:\/\/linux.die.net\/man\/1\/ldns-keygen"}},{"Process":{"Description":"ldns-mx is used to print out mx information of a domain.","Process Name":"ldns-mx","Link":"https:\/\/linux.die.net\/man\/1\/ldns-mx"}},{"Process":{"Description":"ldns-notify sends a NOTIFY message to DNS servers. This tells them that an updated zone is available at the master servers. It can perform TSIG signatures and it can add a SOA serial number of the updated zone. If a server already has that serial number it will disregard the message.","Process Name":"ldns-notify","Link":"https:\/\/linux.die.net\/man\/1\/ldns-notify"}},{"Process":{"Description":null,"Process Name":"ldns-nsec3-hash","Link":"https:\/\/linux.die.net\/man\/1\/ldns-nsec3-hash"}},{"Process":{"Description":"ldns-read-zone reads a DNS zone file and prints it. The output has 1 resource record per line, and no pretty-printing makeup.","Process Name":"ldns-read-zone","Link":"https:\/\/linux.die.net\/man\/1\/ldns-read-zone"}},{"Process":{"Description":null,"Process Name":"ldns-resolver","Link":"https:\/\/linux.die.net\/man\/1\/ldns-resolver"}},{"Process":{"Description":"ldns-revoke is used to revoke a public DNSKEY RR. When run it will read file with a DNSKEY RR in it, sets the revoke bit and write back the output to file .","Process Name":"ldns-revoke","Link":"https:\/\/linux.die.net\/man\/1\/ldns-revoke"}},{"Process":{"Description":null,"Process Name":"ldns-rrsig","Link":"https:\/\/linux.die.net\/man\/1\/ldns-rrsig"}},{"Process":{"Description":null,"Process Name":"ldns-signzone","Link":"https:\/\/linux.die.net\/man\/1\/ldns-signzone"}},{"Process":{"Description":"ldns-test-edns tests a DNS cache and checks if it supports EDNS0 and DNSSEC types so that it can be used as a dnssec-enabled DNS cache. It sends two queries to the cache, one for the root key and one for a DS record. These must succeed, the answer must have EDNS, that type and signatures. If the IP address is good for DNSSEC, it is printed with 'OK'. Otherwise short description is given of the failure. If OK is given, the cache should be good to use as a cache for a local configured DNSSEC validator. The tool assumes the root is signed and Sweden is signed. Also, the queries are sent with the CD flag, the tool does not check that the results are validated, but that they can be validated.","Process Name":"ldns-test-edns","Link":"https:\/\/linux.die.net\/man\/1\/ldns-test-edns"}},{"Process":{"Description":null,"Process Name":"ldns-testns","Link":"https:\/\/linux.die.net\/man\/1\/ldns-testns"}},{"Process":{"Description":"ldns-update is used to send a dynamic update packet.","Process Name":"ldns-update","Link":"https:\/\/linux.die.net\/man\/1\/ldns-update"}},{"Process":{"Description":"ldns-verify-zone reads a DNS zone file and verifies it. RRSIG resource records are checked against the DNSKEY set at the zone apex. Each name is checked for an NSEC(3), if appropriate.","Process Name":"ldns-verify-zone","Link":"https:\/\/linux.die.net\/man\/1\/ldns-verify-zone"}},{"Process":{"Description":"ldns-version is used to print out version information of the ldns library and tools","Process Name":"ldns-version","Link":"https:\/\/linux.die.net\/man\/1\/ldns-version"}},{"Process":{"Description":null,"Process Name":"ldns-walk","Link":"https:\/\/linux.die.net\/man\/1\/ldns-walk"}},{"Process":{"Description":null,"Process Name":"ldns-zcat","Link":"https:\/\/linux.die.net\/man\/1\/ldns-zcat"}},{"Process":{"Description":"","Process Name":"ldns-zsplit","Link":"https:\/\/linux.die.net\/man\/1\/ldns-zsplit"}},{"Process":{"Description":null,"Process Name":"ldnsd","Link":"https:\/\/linux.die.net\/man\/1\/ldnsd"}},{"Process":{"Description":"ldo65 is a linker for files in the 'o65' object format, formerly ld65 but renamed to avoid conflicts with the cc65 package (a separate product).","Process Name":"ldo65","Link":"https:\/\/linux.die.net\/man\/1\/ldo65"}},{"Process":{"Description":null,"Process Name":"ldrdf","Link":"https:\/\/linux.die.net\/man\/1\/ldrdf"}},{"Process":{"Description":"leafnode-version just prints the leafnode version, and in verbose mode, more information such as spool directory and lock file location, and exits with code 0.","Process Name":"leafnode-version","Link":"https:\/\/linux.die.net\/man\/1\/leafnode-version"}},{"Process":{"Description":"This program is part of Netpbm(1). leaftoppm reads a PPM image as input and generates an Interleaf image file as output. Interleaf is a now-defunct (actually purchased ca. 2000 by BroadVision) technical publishing software company.","Process Name":"leaftoppm","Link":"https:\/\/linux.die.net\/man\/1\/leaftoppm"}},{"Process":{"Description":"Ledger is a command-line accounting tool with the moxie to exist. It provides no bells or whistles, and returns the user to the days before user interfaces were even a twinkling in their father's CRT.","Process Name":"ledger","Link":"https:\/\/linux.die.net\/man\/1\/ledger"}},{"Process":{"Description":null,"Process Name":"lefty","Link":"https:\/\/linux.die.net\/man\/1\/lefty"}},{"Process":{"Description":"Less is a program similar to more (1), but which allows backward movement in the file as well as forward movement. Also, less does not have to read the entire input file before starting, so with large input files it starts up faster than text editors like vi (1). Less uses termcap (or terminfo on some systems), so it can run on a variety of terminals. There is even limited support for hardcopy terminals. (On a hardcopy terminal, lines which should be printed at the top of the screen are prefixed with a caret.) Commands are based on both more and vi. Commands may be preceded by a decimal number, called N in the descriptions below. The number is used by some commands, as indicated.","Process Name":"less","Link":"https:\/\/linux.die.net\/man\/1\/less"}},{"Process":{"Description":"lessecho is a program that simply echos its arguments on standard output. But any argument containing spaces is enclosed in quotes.","Process Name":"lessecho","Link":"https:\/\/linux.die.net\/man\/1\/lessecho"}},{"Process":{"Description":"Lesskey is used to specify a set of key bindings to be used by less. The input file is a text file which describes the key bindings, If the input file is \"-\", standard input is read. If no input file is specified, a standard filename is used as the name of the input file, which depends on the system being used: On Unix systems, $HOME\/.lesskey is used; on MS-DOS systems, $HOME\/_lesskey is used; and on OS\/2 systems $HOME\/lesskey.ini is used, or $INIT\/lesskey.ini if $HOME is undefined. The output file is a binary file which is used by less. If no output file is specified, and the environment variable LESSKEY is set, the value of LESSKEY is used as the name of the output file. Otherwise, a standard filename is used as the name of the output file, which depends on the system being used: On Unix and OS-9 systems, $HOME\/.less is used; on MS-DOS systems, $HOME\/_less is used; and on OS\/2 systems, $HOME\/less.ini is used, or $INIT\/less.ini if $HOME is undefined. If the output file already exists, lesskey will overwrite it. The -V or --version option causes lesskey to print its version number and immediately exit. If -V or --version is present, other options and arguments are ignored. The input file consists of one or more sections. Each section starts with a line that identifies the type of section. Possible sections are: #command Defines new command keys. #line-edit Defines new line-editing keys. #env Defines environment variables. Blank lines and lines which start with a pound sign (#) are ignored, except for the special section header lines.","Process Name":"lesskey","Link":"https:\/\/linux.die.net\/man\/1\/lesskey"}},{"Process":{"Description":null,"Process Name":"lesstif","Link":"https:\/\/linux.die.net\/man\/1\/lesstif"}},{"Process":{"Description":"","Process Name":"let","Link":"https:\/\/linux.die.net\/man\/1\/let"}},{"Process":{"Description":null,"Process Name":"lex","Link":"https:\/\/linux.die.net\/man\/1\/lex"}},{"Process":{"Description":"lfc-chgrp sets the group ownership of a LFC directory\/file in the name server to the value of group. To change the group ID, the effective user ID of the process must match the owner ID of the file and the new group must be in the list of groups the caller belong to or the caller must have ADMIN privilege in the Cupv database. group is either a valid group name or a valid numeric ID. path specifies the LFC pathname. If path does not start with \/, it is prefixed by the content of the LFC_HOME environment variable.","Process Name":"lfc-chgrp","Link":"https:\/\/linux.die.net\/man\/1\/lfc-chgrp"}},{"Process":{"Description":"lfc-chmod sets the access mode of LFC directory\/ file(s) in the name server to the octal value in absolute_mode. Symbolic mode changes are not supported yet. The effective user ID of the process must match the owner of the file or the caller must have ADMIN privilege in the Cupv database. path specifies the LFC pathname. If path does not start with \/, it is prefixed by the content of the LFC_HOME environment variable.","Process Name":"lfc-chmod","Link":"https:\/\/linux.die.net\/man\/1\/lfc-chmod"}},{"Process":{"Description":"lfc-chown sets the owner and\/or the group of a LFC directory\/file in the name server to the values in owner and group respectively. To change the owner ID, if the group ID does not change and if the caller and the new owner ID belong to that group, GRP_ADMIN privilege is needed, otherwise the caller must have ADMIN privilege in the Cupv database. To change the group ID, the effective user ID of the process must match the owner ID of the file and the new group must be in the list of groups the caller belong to or the caller must have ADMIN privilege in the Cupv database. owner is either a valid username or a valid numeric ID. group is either a valid group name or a valid numeric ID. path specifies the LFC pathname. If path does not start with \/, it is prefixed by the content of the LFC_HOME environment variable.","Process Name":"lfc-chown","Link":"https:\/\/linux.die.net\/man\/1\/lfc-chown"}},{"Process":{"Description":null,"Process Name":"lfc-delcomment","Link":"https:\/\/linux.die.net\/man\/1\/lfc-delcomment"}},{"Process":{"Description":"lcg-dli-client lists the replicas for a given LFN or GUID using the Data Location Interface (DLI) Web service for a LFC Server. logical file a URI which specifies the Logical File Name ( lfn: ) or the Grid Unique IDentifier ( guid: ). endpoint specifies a web service endpoint to connect to. This consists of a http URL with a hostname and an optional port number. An example is http:\/\/lfc-dteam.cern.ch:8085\/","Process Name":"lfc-dli-client","Link":"https:\/\/linux.die.net\/man\/1\/lfc-dli-client"}},{"Process":{"Description":"lfc-entergrpmap defines a new group entry in Virtual Id table. This command requires ADMIN privilege.","Process Name":"lfc-entergrpmap","Link":"https:\/\/linux.die.net\/man\/1\/lfc-entergrpmap"}},{"Process":{"Description":null,"Process Name":"lfc-enterusrmap","Link":"https:\/\/linux.die.net\/man\/1\/lfc-enterusrmap"}},{"Process":{"Description":"lfc-getacl gets the Access Control List associated with a LFC directory\/file. For each path, it displays the file name, owner, the group, and the Access Control List (ACL) if present. If a directory has a default ACL, lfc-getacl also displays the default ACL. Regular files cannot have default ACLs. The output looks like: # file: filename\n# owner: username\n# group: groupname\nuser::perm\nuser:uid:perm\ngroup::perm\ngroup:gid:perm\nmask:perm\nother:perm\ndefault:user::perm\ndefault:user:uid:perm\ndefault:group::perm\ndefault:group:gid:perm\ndefault:mask:perm\ndefault:other:perm The first \"user\" entry gives the permissions granted to the owner of the file. The following \"user\" entries show the permissions granted to specific users, they are sorted in ascending order of uid. The first \"group\" entry gives the permissions granted to the group owner of the file. The following \"group\" entries show the permissions granted to specific groups, they are sorted in ascending order of gid. The \"mask\" entry is the maximum permission granted to specific users or groups. It does not affect the \"owner\" and \"other\" permissions. The \"mask\" entry must be present if there are specific \"user\" or \"group\" entries. \"default\" entries associated with a directory are inherited as access ACL by the files or sub-directories created in that directory. The umask is not used. Sub-directories also inherit the default ACL as default ACL. As soon as there is one default ACL entry, the 3 default ACL base entries (default user, default group, default other) must be present. The entry processing conforms to the Posix 1003.1e draft standard 17. path specifies the LFC pathname. If path does not start with \/, it is prefixed by the content of the LFC_HOME environment variable. uid is displayed as the username if known else as the numeric id. gid is displayed as the groupname if known else as the numeric id. perm is expressed as a combination of characters rwx-","Process Name":"lfc-getacl","Link":"https:\/\/linux.die.net\/man\/1\/lfc-getacl"}},{"Process":{"Description":null,"Process Name":"lfc-listgrpmap","Link":"https:\/\/linux.die.net\/man\/1\/lfc-listgrpmap"}},{"Process":{"Description":"lfc-listusrmap queries about a given user or lists all existing users in virtual uid table. This function requires ADMIN privilege.","Process Name":"lfc-listusrmap","Link":"https:\/\/linux.die.net\/man\/1\/lfc-listusrmap"}},{"Process":{"Description":"lfc-ln makes a symbolic link to a file or a directory in the LFC Name Server. This requires write permission in linkname parent directory. If linkname does not start with \/, it is prefixed by the content of the LFC_HOME environment variable. If linkname is not specified, the link is created in the current directory with the same basename as the target. In the second form, it creates in directory a link for each target.","Process Name":"lfc-ln","Link":"https:\/\/linux.die.net\/man\/1\/lfc-ln"}},{"Process":{"Description":null,"Process Name":"lfc-ls","Link":"https:\/\/linux.die.net\/man\/1\/lfc-ls"}},{"Process":{"Description":"lfc-mkdir creates the specified LFC directories in the name server. This requires write permission in the parent directory. The owner ID and group ID of the new directories are set to the requestor's real user ID and group ID, respectively. path specifies the LFC pathname. If path does not start with \/, it is prefixed by the content of the LFC_HOME environment variable. The lfc-mkdir command has the following options: -m specifies the mode to be used. Default mode is 777. -p creates all the non-existing parent directories first. The mode set for the created intermediate directories is the logical difference between 0777 and the user umask but at least 0300.","Process Name":"lfc-mkdir","Link":"https:\/\/linux.die.net\/man\/1\/lfc-mkdir"}},{"Process":{"Description":null,"Process Name":"lfc-modifygrpmap","Link":"https:\/\/linux.die.net\/man\/1\/lfc-modifygrpmap"}},{"Process":{"Description":"lfc-modifyusrmap modifies the user entry corresponding to a given virtual uid. This command requires ADMIN privilege.","Process Name":"lfc-modifyusrmap","Link":"https:\/\/linux.die.net\/man\/1\/lfc-modifyusrmap"}},{"Process":{"Description":"lfc-ping checks if the name server is alive and prints its version number.","Process Name":"lfc-ping","Link":"https:\/\/linux.die.net\/man\/1\/lfc-ping"}},{"Process":{"Description":null,"Process Name":"lfc-rename","Link":"https:\/\/linux.die.net\/man\/1\/lfc-rename"}},{"Process":{"Description":"lfc-rm removes LFC files or directories in the name server. For directories either -r or -R must be present. For regular files, it calls lfc_unlink while for directories, it calls lfc_rmdir. This requires write permission in the parent directory and the file itself. If write permission on an entry is denied, the standard input is a terminal and the -f option is not given, the prompt \"override write protection\" appears and if the response is not y, the entry is not deleted. Entries directly under a protected directory are never deleted. path specifies the LFC pathname. If path does not start with \/, it is prefixed by the content of the LFC_HOME environment variable.","Process Name":"lfc-rm","Link":"https:\/\/linux.die.net\/man\/1\/lfc-rm"}},{"Process":{"Description":"lfc-rmgrpmap suppresses the group entry corresponding to a given virtual gid or group name. If both are specified, they must point at the same entry. This command requires ADMIN privilege.","Process Name":"lfc-rmgrpmap","Link":"https:\/\/linux.die.net\/man\/1\/lfc-rmgrpmap"}},{"Process":{"Description":"lfc-rmusrmap suppresses the user entry corresponding to a given virtual uid or user name. If both are specified, they must point at the same entry. This command requires ADMIN privilege.","Process Name":"lfc-rmusrmap","Link":"https:\/\/linux.die.net\/man\/1\/lfc-rmusrmap"}},{"Process":{"Description":"lfc-setacl sets the Access Control List associated with a LFC directory\/file. acl_entries is a comma separated list of entries. Each entry has colon separated fields: ACL type, id (uid or gid), permission. Only directories can have default ACL entries. The entries look like: user::perm\nuser:uid:perm\ngroup::perm\ngroup:gid:perm\nmask:perm\nother:perm\ndefault:user::perm\ndefault:user:uid:perm\ndefault:group::perm\ndefault:group:gid:perm\ndefault:mask:perm\ndefault:other:perm The ACL type can be abbreviated to the first letter. The first \"user\" entry gives the permissions granted to the owner of the file. The following \"user\" entries show the permissions granted to specific users, they are sorted in ascending order of uid. The first \"group\" entry gives the permissions granted to the group owner of the file. The following \"group\" entries show the permissions granted to specific groups, they are sorted in ascending order of gid. The \"mask\" entry is the maximum permission granted to specific users or groups. It does not affect the \"owner\" and \"other\" permissions. The \"mask\" entry must be present if there are specific \"user\" or \"group\" entries. \"default\" entries associated with a directory are inherited as access ACL by the files or sub-directories created in that directory. The umask is not used. Sub-directories also inherit the default ACL as default ACL. As soon as there is one default ACL entry, the 3 default ACL base entries (default user, default group, default other) must be present. The entry processing conforms to the Posix 1003.1e draft standard 17. The effective user ID of the process must match the owner of the file or the caller must have ADMIN privilege in the Cupv database. path specifies the LFC pathname. If path does not start with \/, it is prefixed by the content of the LFC_HOME environment variable. uid can be given as the username or the corresponding numeric id. gid can be given as the groupname or the corresponding numeric id. perm can be expressed as a combination of characters rwx- or as a value between 0 and 7.","Process Name":"lfc-setacl","Link":"https:\/\/linux.die.net\/man\/1\/lfc-setacl"}},{"Process":{"Description":null,"Process Name":"lfc-setcomment","Link":"https:\/\/linux.die.net\/man\/1\/lfc-setcomment"}},{"Process":{"Description":"lfdiff retrieves file, given as an unencoded path, from the radmind server host and writes it to \/tmp. file is then compared to the local copy of file using diff(1). The server copy and the local copy of file are passed to diff(1) as file1 and file2 arguments respectively. file is removed from \/tmp on exit. lfdiff supports all single letter diff(1) options not duplicated in lfdiff. All other diff(1) options are given using the -X option.","Process Name":"lfdiff","Link":"https:\/\/linux.die.net\/man\/1\/lfdiff"}},{"Process":{"Description":null,"Process Name":"lftp","Link":"https:\/\/linux.die.net\/man\/1\/lftp"}},{"Process":{"Description":"This manual page documents briefly the lftpget command. lftpget is a shell script for downloading by URL, it calls 'lftp -c'. It supports the same set of protocols as lftp does, including ftp, http, fish, sftp.","Process Name":"lftpget","Link":"https:\/\/linux.die.net\/man\/1\/lftpget"}},{"Process":{"Description":null,"Process Name":"lg_intro","Link":"https:\/\/linux.die.net\/man\/1\/lg_intro"}},{"Process":{"Description":null,"Process Name":"lgroupadd","Link":"https:\/\/linux.die.net\/man\/1\/lgroupadd"}},{"Process":{"Description":"Deletes the user group with name group.","Process Name":"lgroupdel","Link":"https:\/\/linux.die.net\/man\/1\/lgroupdel"}},{"Process":{"Description":null,"Process Name":"lgroupmod","Link":"https:\/\/linux.die.net\/man\/1\/lgroupmod"}},{"Process":{"Description":"lib3ds-config is a tool that is used to configure to determine the compiler and linker flags that should be used to compile and link programs that use lib3ds. It is also used internally to the .m4 macros for GNU autoconf that are included with lib3ds.","Process Name":"lib3ds-config","Link":"https:\/\/linux.die.net\/man\/1\/lib3ds-config"}},{"Process":{"Description":null,"Process Name":"libgc","Link":"https:\/\/linux.die.net\/man\/1\/libgc"}},{"Process":{"Description":null,"Process Name":"libguestfs-test-tool","Link":"https:\/\/linux.die.net\/man\/1\/libguestfs-test-tool"}},{"Process":{"Description":"libmikmod-config is a tool that is used to configure to determine the compiler and linker flags that should be used to compile and link programs that use libmikmod. It is also used internally to the .m4 macros for GNU autoconf that are included with libmikmod.","Process Name":"libmikmod-config","Link":"https:\/\/linux.die.net\/man\/1\/libmikmod-config"}},{"Process":{"Description":null,"Process Name":"libnet10-config","Link":"https:\/\/linux.die.net\/man\/1\/libnet10-config"}},{"Process":{"Description":"The libnetcfg utility can be used to configure the libnet. Starting from perl 5.8 libnet is part of the standard Perl distribution, but the libnetcfg can be used for any libnet installation.","Process Name":"libnetcfg","Link":"https:\/\/linux.die.net\/man\/1\/libnetcfg"}},{"Process":{"Description":"libopenvas-config script displays the compiler\/linker flags other program sources can use to link to the OpenVAS libraries.","Process Name":"libopenvas-config","Link":"https:\/\/linux.die.net\/man\/1\/libopenvas-config"}},{"Process":{"Description":null,"Process Name":"libval_check_conf","Link":"https:\/\/linux.die.net\/man\/1\/libval_check_conf"}},{"Process":{"Description":"The libvirtMib_subagent provides SNMP functionality for libvirt. Therefore it is now possible to gather and set domain status over SNMP from one place. This allows to create views of entire platforms end to end. It communicates with SNMP agent over AgentX protocol ( RFC 2741) and extends agent's set of infomation provided. Therefore, we need a running SNMP agent. This behaviour can be avoided using -M option. The libvirtMib_subagent understands these OPTIONS : -f Don't fork. Run in foreground. -D[ token[, ...]] Turn on debugging output for the given TOKEN (s). Without any tokens specified, it defaults to printing all the tokens (which is equivalent to the keyword ' \"ALL\"'). You might want to try ALL for extremely verbose output. Note: You can't put a space between the -D and the tokens. -H Display a list of configuration file directives understood by the agent and then exit. -M Run as a normal SNMP Agent instead of an AgentX sub-agent. -x ADDRESS Connect to master agent at ADDRESS (default \"\/var\/agentx\/master\"). The address can either be a Unix domain socket path, or the address of a network interface. The format is the same as the format of listening addresses described below. -L Do not open a log file; print all messages to stderr. The last optional LISTENING ADDRESSES specify on which addresses should subagent running in normal SNMP Agent mode listen for incoming requests. See snmpd for further information.","Process Name":"libvirtmib_subagent","Link":"https:\/\/linux.die.net\/man\/1\/libvirtmib_subagent"}},{"Process":{"Description":null,"Process Name":"licensecheck","Link":"https:\/\/linux.die.net\/man\/1\/licensecheck"}},{"Process":{"Description":"Displays information about groups containing user name, or users contained in group name. By default lid lists groups containing user name, or groups containing the invoking user if name is not specified; the mode of operation can be changed using the -g option.","Process Name":"lid","Link":"https:\/\/linux.die.net\/man\/1\/lid"}},{"Process":{"Description":"Liferea (Linux Feed Reader) is an RSS\/RDF and Atom news aggregator which also supports CDF channels, OCS, and OPML directories. It's intended to be a clone of the Windows-only FeedReader. It can be used to maintain a list of subscribed feeds, browse and search through their items, and displays their contents using GtkHTML or Mozilla.","Process Name":"liferea","Link":"https:\/\/linux.die.net\/man\/1\/liferea"}},{"Process":{"Description":"The first argument should be an image of a piece of grey card, subsequent arguments should be images taken with the same lighting set-up which need correcting. The corrected images are written to files prefixed with \"ic_\". For example, suppose you have a directory with the following files in: example% ls dat1.1.v dat1.2.v dat2.1.v dat2.2.v dat3.1.v dat3.2.v dat4.1.v dat4.2.v grey.v then run light_correct like this: example% light_correct grey.v dat*.v to generate this: example% ls dat1.1.v dat1.2.v dat2.1.v dat2.2.v dat3.1.v dat3.2.v dat4.1.v dat4.2.v grey.v ic_dat1.1.v ic_dat1.2.v ic_dat2.1.v ic_dat2.2.v ic_dat3.1.v ic_dat3.2.v ic_dat4.1.v ic_dat4.2.v light_correct works by smoothing out the grey card image, finding grey-mean\/pixel for each point, and then multiplying the result by all the following images. It also removes any .desc files it generates, to avoid problems with im_global_balance(3).","Process Name":"light_correct","Link":"https:\/\/linux.die.net\/man\/1\/light_correct"}},{"Process":{"Description":"The lightning program draws fractal lightning bolts","Process Name":"lightning","Link":"https:\/\/linux.die.net\/man\/1\/lightning"}},{"Process":{"Description":"lights gives a very simple overview of the rollover status of a set of zones. The rollover status counts are given in a \"traffic light\" display. In contrast, blinkenlights gives a detailed display of the roll status of a set of zones. lights gives very little control over rollerd, the way blinkenlights does. lights can halt rollerd's execution only. The rollover status is retrieved in one of two ways. By default, rollerd is contacted via the rollctl command. Alternately, if the -rrf option is given, then zone status is read directly from a rollrec file. The default method gets the status directly from rollerd and the user need not know the location of the relevant rollrec file. However, that method will not get zone status until rollerd is available to respond to the information request. Consequently, the alternate method allows lights to bypass communicating with rollerd and not having to wait for rollerd to be available. A window is created that has three colored sections - green, yellow, and red. The green section displays a count of those zones that are in \"normal\" status; that is, they are not in rollover. The yellow section displays a count of those zones that are in rollover. The red section displays a count of those zones that are in need of attention. A common cause for this last state is because a zone is in phase 6 of KSK rollover and is waiting for its parent zone to publish the child's new DS record. Clicking on the color rows in the main window will bring up a dialog box that lists the zones in that state. This list will not automatically update as zones change rollover state.","Process Name":"lights","Link":"https:\/\/linux.die.net\/man\/1\/lights"}},{"Process":{"Description":"","Process Name":"lighttpd","Link":"https:\/\/linux.die.net\/man\/1\/lighttpd"}},{"Process":{"Description":"Call the link function to create a link named FILE2 to an existing FILE1. --help display this help and exit --version output version information and exit","Process Name":"link","Link":"https:\/\/linux.die.net\/man\/1\/link"}},{"Process":{"Description":"LinkChecker features recursive checking, multithreading, output in colored or normal text, HTML, SQL, CSV or a sitemap graph in GML or XML, support for HTTP\/1.1, HTTPS, FTP, mailto:, news:, nntp:, Telnet and local file links, restriction of link checking with regular expression filters for URLs, proxy support, username\/password authorization for HTTP and FTP, robots.txt exclusion protocol support, i18n support, a command line interface and a (Fast)CGI web interface (requires HTTP server)","Process Name":"linkchecker","Link":"https:\/\/linux.die.net\/man\/1\/linkchecker"}},{"Process":{"Description":"This program is similar to ping(1), but tests connectivity at the link layer (layer-2) instead of the network layer (layer-3). It receives one parameter which is the destination address, sends a special LLC-TEST packet and waits for a reply. linkloop_reply runs as a daemon, listening at the llc level on network interfaces passed on the command line, and responding by sending back a test packet. The destination address can be given in the following forms: colon separated Example: 00:02:B3:C0:DC:CA Hexadecimal Example: 0x0002B3C0DCCA Name Taken from \/etc\/ethers","Process Name":"linkloop","Link":"https:\/\/linux.die.net\/man\/1\/linkloop"}},{"Process":{"Description":"ELinks is a text mode WWW browser, supporting colors, table rendering, background downloading, menu driven configuration interface, tabbed browsing and slim code. Frames are supported. You can have different file formats associated with external viewers. mailto: and telnet: are supported via external clients. ELinks can handle both local files and remote URLs. The main supported remote URL protocols are HTTP, HTTPS (with SSL support compiled in) and FTP. Additional protocol support exists for BitTorrent finger, Gopher, SMB and NNTP. The homepage of ELinks can be found at <http:\/\/elinks.cz\/>, where the ELinks manual is also hosted.","Process Name":"links","Link":"https:\/\/linux.die.net\/man\/1\/links"}},{"Process":{"Description":"links is a text mode WWW browser with ncurses interface, supporting colors, correct table rendering, background downloading, menu driven configuration interface and slim code. Frames are supported. You can have different file formats associated with external viewers. mailto: and telnet: are supported via external clients. links can handle local (file:\/\/) or remote (http:\/\/ or ftp:\/\/) URLs.","Process Name":"links2","Link":"https:\/\/linux.die.net\/man\/1\/links2"}},{"Process":{"Description":"This manual page briefly documents linsmith. It was written for the Debian GNU\/Linux distribution because the original program does not have a manual page. A more complete manual is included (in PDF form) with the installation. linSmith is a Smith Charting program, mainly designed for educational use. As such, there is an emphasis on capabilities that improve the 'showing the effect of'-style of operation. It's main features are: * Definition of multiple load impedances (at different frequencies) * Addition of discrete (L, C, parallel and series LC, and transformer) and line components (open and closed stubs, line segments) * Connection in series and parallel * Easy experimentation with values using scrollbars * A 'virtual' component switches from impedance to admittance to help explaining (or understanding) parallel components * The chart works in real impedances (not normalized ones) * Direct view of the result on the screen * Ability to generate publication quality Postscript output * A 'log' file with textual results at each intermediate step * Load and circuit configuration is stored separately, permitting several solutions without re-defining the other","Process Name":"linsmith","Link":"https:\/\/linux.die.net\/man\/1\/linsmith"}},{"Process":{"Description":"The pvf tools are a collection of tools to convert vgetty modem data to and from the 'raw modem data' format, and from that to and from various audio file formats (like .au or .wav). In addition, there are some tools to manipulate pvf files, like speed up files or cut off trailing noise. A list of commands is below in the \"see also\" section. You can run those commands with the -h switch for available options. Please also look at the individual contributed man pages.","Process Name":"lintopvf","Link":"https:\/\/linux.die.net\/man\/1\/lintopvf"}},{"Process":{"Description":"linux_logo is a program that generates a color ANSI picture of a penguin which includes some system information obtained from the \/proc filesystem.","Process Name":"linux_logo","Link":"https:\/\/linux.die.net\/man\/1\/linux_logo"}},{"Process":{"Description":"The linuxdoc suite is a collection of text formatters which understands a LinuxDoc DTD SGML source file. Each formatter (or \"back-end\") renders the source file into a variety of output formats, including HTML, TeX, DVI, PostScript, plain text, and groff(1) source in manual-page format. The linuxdoc suite is provided for backward compatibility, because there are still many useful documents written in LinuxDoc DTD sgml source. The markup language(s) accepted by these formatters is described in the Linuxdoc-Tools User's Guide. They are variants of an SGML document type definition originally designed by Matt Welsh for Linux documentation.","Process Name":"linuxdoc","Link":"https:\/\/linux.die.net\/man\/1\/linuxdoc"}},{"Process":{"Description":"lircrcd reads the given .lircrc config file and synchronises the mode that the LIRC clients using this config file (irexec(1), irxevent(1) , etc.) are in. Using lircrcd has to be explicitly enabled in the config file by adding the following line at the beginning of the file: #! lircrcd -h --help display this message -v --version display version -p --permission= mode file permissions for socket -o --output= socket output socket filename","Process Name":"lircrcd","Link":"https:\/\/linux.die.net\/man\/1\/lircrcd"}},{"Process":{"Description":"The lisa program draws animated full-loop lisajous figures.","Process Name":"lisa","Link":"https:\/\/linux.die.net\/man\/1\/lisa"}},{"Process":{"Description":"This program is part of Netpbm(1). listpmfile reads a Lisp Machine bitmap as input and produces a PGM image as output. This is the file format written by the tv:write-bit-array-file function on TI Explorer and Symbolics lisp machines. Multi-plane bitmaps on lisp machines are color; but the Lispm image file format does not include a color map, so we must treat it as a monochrome instead and produce PGM. This is unfortunate.","Process Name":"lispmtopgm","Link":"https:\/\/linux.die.net\/man\/1\/lispmtopgm"}},{"Process":{"Description":"Another Lissajous figure. This one draws the progress of circular shapes along a path.","Process Name":"lissie","Link":"https:\/\/linux.die.net\/man\/1\/lissie"}},{"Process":{"Description":"list_audio_tracks equals to the invocation of icedax, so all the arguments for the latter can be used.","Process Name":"list_audio_tracks","Link":"https:\/\/linux.die.net\/man\/1\/list_audio_tracks"}},{"Process":{"Description":null,"Process Name":"listres","Link":"https:\/\/linux.die.net\/man\/1\/listres"}},{"Process":{"Description":"lit is a portable tool for executing LLVM and Clang style test suites, summarizing their results, and providing indication of failures. lit is designed to be a lightweight testing tool with as simple a user interface as possible. lit should be run with one or more tests to run specified on the command line. Tests can be either individual test files or directories to search for tests (see \" TEST DISCOVERY \"). Each specified test will be executed (potentially in parallel) and once all tests have been run lit will print summary information on the number of tests which passed or failed (see \" TEST STATUS RESULTS \"). The lit program will execute with a non-zero exit code if any tests fail. By default lit will use a succinct progress display and will only print summary information for test failures. See \" OUTPUT OPTIONS \" for options controlling the lit progress display and output. lit also includes a number of options for controlling how tests are exected (specific features may depend on the particular test format). See \" EXECUTION OPTIONS \" for more information. Finally, lit also supports additional options for only running a subset of the options specified on the command line, see \" SELECTION OPTIONS \" for more information. Users interested in the lit architecture or designing a lit testing implementation should see \" LIT ARCHITECTURE \"","Process Name":"lit","Link":"https:\/\/linux.die.net\/man\/1\/lit"}},{"Process":{"Description":null,"Process Name":"lkbib","Link":"https:\/\/linux.die.net\/man\/1\/lkbib"}},{"Process":{"Description":null,"Process Name":"llc","Link":"https:\/\/linux.die.net\/man\/1\/llc"}},{"Process":{"Description":"lli directly executes programs in LLVM bitcode format. It takes a program in LLVM bitcode format and executes it using a just-in-time compiler, if one is available for the current architecture, or an interpreter. lli takes all of the same code generator options as llc, but they are only effective when lli is using the just-in-time compiler. If filename is not specified, then lli reads the LLVM bitcode for the program from standard input. The optional args specified on the command line are passed to the program as arguments.","Process Name":"lli","Link":"https:\/\/linux.die.net\/man\/1\/lli"}},{"Process":{"Description":"The llvm-ar command is similar to the common Unix utility, \"ar\". It archives several files together into a single file. The intent for this is to produce archive libraries by LLVM bitcode that can be linked into an LLVM program. However, the archive can contain any kind of file. By default, llvm-ar generates a symbol table that makes linking faster because only the symbol table needs to be consulted, not each individual file member of the archive. The llvm-ar command can be used to read both SVR4 and BSD style archive files. However, it cannot be used to write them. While the llvm-ar command produces files that are almost identical to the format used by other \"ar\" implementations, it has two significant departures in order to make the archive appropriate for LLVM . The first departure is that llvm-ar only uses BSD4 .4 style long path names (stored immediately after the header) and never contains a string table for long names. The second departure is that the symbol table is formated for efficient construction of an in-memory data structure that permits rapid (red-black tree) lookups. Consequently, archives produced with llvm-ar usually won't be readable or editable with any \"ar\" implementation or useful for linking. Using the \"f\" modifier to flatten file names will make the archive readable by other \"ar\" implementations but not for linking because the symbol table format for LLVM is unique. If an SVR4 or BSD style archive is used with the \"r\" (replace) or \"q\" (quick update) operations, the archive will be reconstructed in LLVM format. This means that the string table will be dropped (in deference to BSD 4.4 long names) and an LLVM symbol table will be added (by default). The system symbol table will be retained. Here's where llvm-ar departs from previous \"ar\" implementations: Symbol Table Since llvm-ar is intended to archive bitcode files, the symbol table won't make much sense to anything but LLVM . Consequently, the symbol table's format has been simplified. It consists simply of a sequence of pairs of a file member index number as an LSB 4byte integer and a null-terminated string. Long Paths Some \"ar\" implementations ( SVR4 ) use a separate file member to record long path names (> 15 characters). llvm-ar takes the BSD 4.4 and Mac OS X approach which is to simply store the full path name immediately preceding the data for the file. The path name is null terminated and may contain the slash (\/) character. Compression llvm-ar can compress the members of an archive to save space. The compression used depends on what's available on the platform and what choices the LLVM Compressor utility makes. It generally favors bzip2 but will select between \"no compression\" or bzip2 depending on what makes sense for the file's content. Directory Recursion Most \"ar\" implementations do not recurse through directories but simply ignore directories if they are presented to the program in the files option. llvm-ar, however, can recurse through directory structures and add all the files under a directory, if requested. TOC Verbose Output When llvm-ar prints out the verbose table of contents ( \"tv\" option), it precedes the usual output with a character indicating the basic kind of content in the file. A blank means the file is a regular file. A 'Z' means the file is compressed. A 'B' means the file is an LLVM bitcode file. An 'S' means the file is the symbol table.","Process Name":"llvm-ar","Link":"https:\/\/linux.die.net\/man\/1\/llvm-ar"}},{"Process":{"Description":"llvm-as is the LLVM assembler. It reads a file containing human-readable LLVM assembly language, translates it to LLVM bitcode, and writes the result into a file or to standard output. If filename is omitted or is \"-\", then llvm-as reads its input from standard input. If an output file is not specified with the -o option, then llvm-as sends its output to a file or standard output by following these rules: \u2022 If the input is standard input, then the output is standard output. \u2022 If the input is a file that ends with \".ll\", then the output file is of the same name, except that the suffix is changed to \".bc\". \u2022 If the input is a file that does not end with the \".ll\" suffix, then the output file has the same name as the input file, except that the \".bc\" suffix is appended.","Process Name":"llvm-as","Link":"https:\/\/linux.die.net\/man\/1\/llvm-as"}},{"Process":{"Description":"The llvm-bcanalyzer command is a small utility for analyzing bitcode files. The tool reads a bitcode file (such as generated with the llvm-as tool) and produces a statistical report on the contents of the bitcode file. The tool can also dump a low level but human readable version of the bitcode file. This tool is probably not of much interest or utility except for those working directly with the bitcode file format. Most LLVM users can just ignore this tool. If filename is omitted or is \"-\", then llvm-bcanalyzer reads its input from standard input. This is useful for combining the tool into a pipeline. Output is written to the standard output.","Process Name":"llvm-bcanalyzer","Link":"https:\/\/linux.die.net\/man\/1\/llvm-bcanalyzer"}},{"Process":{"Description":"llvm-config makes it easier to build applications that use LLVM . It can print the compiler flags, linker flags and object libraries needed to link against LLVM .","Process Name":"llvm-config","Link":"https:\/\/linux.die.net\/man\/1\/llvm-config"}},{"Process":{"Description":"llvm-diff compares the structure of two LLVM modules, primarily focusing on differences in function definitions. Insignificant differences, such as changes in the ordering of globals or in the names of local values, are ignored. An input module will be interpreted as an assembly file if its name ends in '.ll'; otherwise it will be read in as a bitcode file. If a list of global names is given, just the values with those names are compared; otherwise, all global values are compared, and diagnostics are produced for globals which only appear in one module or the other. llvm-diff compares two functions by comparing their basic blocks, beginning with the entry blocks. If the terminators seem to match, then the corresponding successors are compared; otherwise they are ignored. This algorithm is very sensitive to changes in control flow, which tend to stop any downstream changes from being detected. llvm-diff is intended as a debugging tool for writers of LLVM passes and frontends. It does not have a stable output format.","Process Name":"llvm-diff","Link":"https:\/\/linux.die.net\/man\/1\/llvm-diff"}},{"Process":{"Description":"The llvm-dis command is the LLVM disassembler. It takes an LLVM bitcode file and converts it into human-readable LLVM assembly language. If filename is omitted or specified as \"-\", llvm-dis reads its input from standard input. If the input is being read from standard input, then llvm-dis will send its output to standard output by default. Otherwise, the output will be written to a file named after the input file, with a \".ll\" suffix added (any existing \".bc\" suffix will first be removed). You can override the choice of output file using the -o option.","Process Name":"llvm-dis","Link":"https:\/\/linux.die.net\/man\/1\/llvm-dis"}},{"Process":{"Description":"The llvm-extract command takes the name of a function and extracts it from the specified LLVM bitcode file. It is primarily used as a debugging tool to reduce test cases from larger programs that are triggering a bug. In addition to extracting the bitcode of the specified function, llvm-extract will also remove unreachable global variables, prototypes, and unused types. The llvm-extract command reads its input from standard input if filename is omitted or if filename is -. The output is always written to standard output, unless the -o option is specified (see below).","Process Name":"llvm-extract","Link":"https:\/\/linux.die.net\/man\/1\/llvm-extract"}},{"Process":{"Description":null,"Process Name":"llvm-ld","Link":"https:\/\/linux.die.net\/man\/1\/llvm-ld"}},{"Process":{"Description":"llvm-link takes several LLVM bitcode files and links them together into a single LLVM bitcode file. It writes the output file to standard output, unless the -o option is used to specify a filename. llvm-link attempts to load the input files from the current directory. If that fails, it looks for each file in each of the directories specified by the -L options on the command line. The library search paths are global; each one is searched for every input file if necessary. The directories are searched in the order they were specified on the command line.","Process Name":"llvm-link","Link":"https:\/\/linux.die.net\/man\/1\/llvm-link"}},{"Process":{"Description":"The llvm-nm utility lists the names of symbols from the LLVM bitcode files, or ar archives containing LLVM bitcode files, named on the command line. Each symbol is listed along with some simple information about its provenance. If no file name is specified, or - is used as a file name, llvm-nm will process a bitcode file on its standard input stream. llvm-nm's default output format is the traditional BSD nm output format. Each such output record consists of an (optional) 8-digit hexadecimal address, followed by a type code character, followed by a name, for each symbol. One record is printed per line; fields are separated by spaces. When the address is omitted, it is replaced by 8 spaces. Type code characters currently supported, and their meanings, are as follows: U Named object is referenced but undefined in this bitcode file C Common (multiple definitions link together into one def) W Weak reference (multiple definitions link together into zero or one definitions) t Local function (text) object T Global function (text) object d Local data object D Global data object ? Something unrecognizable Because LLVM bitcode files typically contain objects that are not considered to have addresses until they are linked into an executable image or dynamically compiled \"just-in-time\", llvm-nm does not print an address for any symbol, even symbols which are defined in the bitcode file.","Process Name":"llvm-nm","Link":"https:\/\/linux.die.net\/man\/1\/llvm-nm"}},{"Process":{"Description":null,"Process Name":"llvm-prof","Link":"https:\/\/linux.die.net\/man\/1\/llvm-prof"}},{"Process":{"Description":"The llvm-ranlib command is similar to the common Unix utility, \"ranlib\". It adds or updates the symbol table in an LLVM archive file. Note that using the llvm-ar modifier s is usually more efficient than running llvm-ranlib which is only provided only for completness and compatibility. Unlike other implementations of \"ranlib\", llvm-ranlib indexes LLVM bitcode files, not native object modules. You can list the contents of the symbol table with the \"llvm-nm -s\" command.","Process Name":"llvm-ranlib","Link":"https:\/\/linux.die.net\/man\/1\/llvm-ranlib"}},{"Process":{"Description":null,"Process Name":"llvmc","Link":"https:\/\/linux.die.net\/man\/1\/llvmc"}},{"Process":{"Description":"Use this software to convert Lemonldap::NG configuration file into SQL instructions. Options * -c : add \"create table\" instruction * -t : name of the table (lmConfig by default)","Process Name":"lmconfig_file2mysql","Link":"https:\/\/linux.die.net\/man\/1\/lmconfig_file2mysql"}},{"Process":{"Description":null,"Process Name":"lmerge","Link":"https:\/\/linux.die.net\/man\/1\/lmerge"}},{"Process":{"Description":"The lmorph program shows smooth and non-linear morphing between 1D curves.","Process Name":"lmorph","Link":"https:\/\/linux.die.net\/man\/1\/lmorph"}},{"Process":{"Description":null,"Process Name":"lmtptest","Link":"https:\/\/linux.die.net\/man\/1\/lmtptest"}},{"Process":{"Description":"In the 1st form, create a link to TARGET with the name LINK_NAME. In the 2nd form, create a link to TARGET in the current directory. In the 3rd and 4th forms, create links to each TARGET in DIRECTORY. Create hard links by default, symbolic links with --symbolic. When creating hard links, each TARGET must exist. Symbolic links can hold arbitrary text; if later resolved, a relative link is interpreted in relation to its parent directory. Mandatory arguments to long options are mandatory for short options too. --backup[= CONTROL] make a backup of each existing destination file -b like --backup but does not accept an argument -d, -F, --directory allow the superuser to attempt to hard link directories (note: will probably fail due to system restrictions, even for the superuser) -f, --force remove existing destination files -i, --interactive prompt whether to remove destinations -L, --logical make hard links to symbolic link references -n, --no-dereference treat destination that is a symlink to a directory as if it were a normal file -P, --physical make hard links directly to symbolic links -s, --symbolic make symbolic links instead of hard links -S, --suffix= SUFFIX override the usual backup suffix -t, --target-directory= DIRECTORY specify the DIRECTORY in which to create the links -T, --no-target-directory treat LINK_NAME as a normal file -v, --verbose print name of each linked file --help display this help and exit --version output version information and exit The backup suffix is '~', unless set with --suffix or SIMPLE_BACKUP_SUFFIX. The version control method may be selected via the --backup option or through the VERSION_CONTROL environment variable. Here are the values: Using -s ignores -L and -P. Otherwise, the last option specified controls behavior when the source is a symbolic link, defaulting to -P. none, off never make backups (even if --backup is given) numbered, t make numbered backups existing, nil numbered if numbered backups exist, simple otherwise simple, never always make simple backups","Process Name":"ln","Link":"https:\/\/linux.die.net\/man\/1\/ln"}},{"Process":{"Description":null,"Process Name":"lndir","Link":"https:\/\/linux.die.net\/man\/1\/lndir"}},{"Process":{"Description":"lneato is a graph editor for the X Window System. It may be run as a standalone editor, or as a front end for applications that use graphs. It can control multiple windows viewing different graphs. lneato is written on top of neato and lefty. lefty is a general-purpose programmable editor for technical pictures. It has an interpretive programming language similar to AWK and C. The user interface and graph editing operations of lneato are written as lefty functions. Programmer-defined graph operations may be loaded as well. Graph layouts are made by neato, which runs as a separate process that communicates with lefty through pipes.","Process Name":"lneato","Link":"https:\/\/linux.die.net\/man\/1\/lneato"}},{"Process":{"Description":null,"Process Name":"lnewusers","Link":"https:\/\/linux.die.net\/man\/1\/lnewusers"}},{"Process":{"Description":"The loaderinfo command reads various information from SCSI tape loaders. Its intended use is for high-level programs that are trying to decide what the capabilities of a device are. The following are printed: Element Address Assignment Page: This tells how many elements are in the loader, and what their raw hardware addresses are. Transport Geometry Descriptor Page: Will display whether media is invertible or not (usable with some optical jukeboxes for detirmining whether to \"flip\" media after writing to the first side). Device Capabilities Page Currently will only display whether we can transfer between slots (i.e. whether 'mtx transfer' works). Inquiry Page Aside from the normal inquiry info, will also print out whether we have a bar code reader (for loaders that support the Exabyte extension for reporting presense of said reader).","Process Name":"loaderinfo","Link":"https:\/\/linux.die.net\/man\/1\/loaderinfo"}},{"Process":{"Description":null,"Process Name":"loadgo","Link":"https:\/\/linux.die.net\/man\/1\/loadgo"}},{"Process":{"Description":"The program loadkeys reads the file or files specified by filename.... Its main purpose is to load the kernel keymap for the console. The affected console device or devices can be specified using the -C (or --console ) option. This option supports a list of device names","Process Name":"loadkeys","Link":"https:\/\/linux.die.net\/man\/1\/loadkeys"}},{"Process":{"Description":null,"Process Name":"local","Link":"https:\/\/linux.die.net\/man\/1\/local"}},{"Process":{"Description":"The locale program writes information about the current locale environment, or all locales, to standard output. When invoked without arguments, locale summarizes the current locale environment for each locale category defined by the LC_* environment variables. -a, --all-locales Write names of available locales. -m, --charmaps Write names of available charmaps. Output Format: -c, --category-name Write names of selected categories. -k, --keyword-name Write names and values of selected keywords.","Process Name":"locale","Link":"https:\/\/linux.die.net\/man\/1\/locale"}},{"Process":{"Description":"The localedef program reads the indicated charmap and input files, compiles them to a form usable by the locale(7) functions in the C library, and places the six output files in the outputpath directory. If no charmapfile is given, POSIX is used by default. If no inputfile is given, or if it is given as -, localedef reads from standard input.","Process Name":"localedef","Link":"https:\/\/linux.die.net\/man\/1\/localedef"}},{"Process":{"Description":"locate reads one or more databases prepared by updatedb(8) and writes file names matching at least one of the PATTERNs to standard output, one per line. If --regex is not specified, PATTERNs can contain globbing characters. If any PATTERN contains no globbing characters, locate behaves as if the pattern were *PATTERN*. By default, locate does not check whether files found in database still exist. locate can never report files created after the most recent update of the relevant database.","Process Name":"locate","Link":"https:\/\/linux.die.net\/man\/1\/locate"}},{"Process":{"Description":"Lockerd will start a daemon to watch for and service connects by the Perl IPC::Locker package.","Process Name":"lockerd","Link":"https:\/\/linux.die.net\/man\/1\/lockerd"}},{"Process":{"Description":null,"Process Name":"lockersh","Link":"https:\/\/linux.die.net\/man\/1\/lockersh"}},{"Process":{"Description":null,"Process Name":"lockfile","Link":"https:\/\/linux.die.net\/man\/1\/lockfile"}},{"Process":{"Description":"Lockfile-progs provides a set a programs that can be used to lock and unlock mailboxes and files safely (via liblockfile): mail-lock - lock the current user's mailbox\nmail-unlock - unlock the current user's mailbox\nmail-touchlock - touch the lock on the current user's mailbox\nlockfile-create - lock a given file\nlockfile-remove - remove the lock on a given file\nlockfile-touch - touch the lock on a given file\nlockfile-check - check the lock on a given file By default, the filename argument refers to the name of the file to be locked, and the name of the lockfile will be filename .lock. However, if the --lock-name argument is specified, then filename will be taken as the name of the lockfile itself. Each of the mail locking commands attempts to lock \/var\/spool\/mail\/<user>, where <user> is the name associated with the effective user ID, as determined by via geteuid(2). Once a file is locked, the lock must be touched at least once every five minutes or the lock will be considered stale, and subsequent lock attempts will succeed. Also see the --use-pid option and the lockfile_create(3) manpage. The lockfile-check command tests whether or not a valid lock already exists.","Process Name":"lockfile-check","Link":"https:\/\/linux.die.net\/man\/1\/lockfile-check"}},{"Process":{"Description":null,"Process Name":"lockfile-create","Link":"https:\/\/linux.die.net\/man\/1\/lockfile-create"}},{"Process":{"Description":"Lockfile-progs provides a set a programs that can be used to lock and unlock mailboxes and files safely (via liblockfile): mail-lock - lock the current user's mailbox\nmail-unlock - unlock the current user's mailbox\nmail-touchlock - touch the lock on the current user's mailbox\nlockfile-create - lock a given file\nlockfile-remove - remove the lock on a given file\nlockfile-touch - touch the lock on a given file\nlockfile-check - check the lock on a given file By default, the filename argument refers to the name of the file to be locked, and the name of the lockfile will be filename .lock. However, if the --lock-name argument is specified, then filename will be taken as the name of the lockfile itself. Each of the mail locking commands attempts to lock \/var\/spool\/mail\/<user>, where <user> is the name associated with the effective user ID, as determined by via geteuid(2). Once a file is locked, the lock must be touched at least once every five minutes or the lock will be considered stale, and subsequent lock attempts will succeed. Also see the --use-pid option and the lockfile_create(3) manpage. The lockfile-check command tests whether or not a valid lock already exists.","Process Name":"lockfile-progs","Link":"https:\/\/linux.die.net\/man\/1\/lockfile-progs"}},{"Process":{"Description":null,"Process Name":"lockfile-remove","Link":"https:\/\/linux.die.net\/man\/1\/lockfile-remove"}},{"Process":{"Description":"Lockfile-progs provides a set a programs that can be used to lock and unlock mailboxes and files safely (via liblockfile): mail-lock - lock the current user's mailbox\nmail-unlock - unlock the current user's mailbox\nmail-touchlock - touch the lock on the current user's mailbox\nlockfile-create - lock a given file\nlockfile-remove - remove the lock on a given file\nlockfile-touch - touch the lock on a given file\nlockfile-check - check the lock on a given file By default, the filename argument refers to the name of the file to be locked, and the name of the lockfile will be filename .lock. However, if the --lock-name argument is specified, then filename will be taken as the name of the lockfile itself. Each of the mail locking commands attempts to lock \/var\/spool\/mail\/<user>, where <user> is the name associated with the effective user ID, as determined by via geteuid(2). Once a file is locked, the lock must be touched at least once every five minutes or the lock will be considered stale, and subsequent lock attempts will succeed. Also see the --use-pid option and the lockfile_create(3) manpage. The lockfile-check command tests whether or not a valid lock already exists.","Process Name":"lockfile-touch","Link":"https:\/\/linux.die.net\/man\/1\/lockfile-touch"}},{"Process":{"Description":null,"Process Name":"locktest","Link":"https:\/\/linux.die.net\/man\/1\/locktest"}},{"Process":{"Description":null,"Process Name":"log","Link":"https:\/\/linux.die.net\/man\/1\/log"}},{"Process":{"Description":"This tool is part of the samba(7) suite. log2pcap reads in a samba log file and generates a pcap file (readable by most sniffers, such as ethereal or tcpdump) based on the packet dumps in the log file. The log file must have a log level of at least 5 to get the SMB header\/parameters right, 10 to get the first 512 data bytes of the packet and 50 to get the whole packet.","Process Name":"log2pcap","Link":"https:\/\/linux.die.net\/man\/1\/log2pcap"}},{"Process":{"Description":null,"Process Name":"logcheck-test","Link":"https:\/\/linux.die.net\/man\/1\/logcheck-test"}},{"Process":{"Description":"Analyzes Directory Server access log files for specific information defined on the command line","Process Name":"logconv.pl","Link":"https:\/\/linux.die.net\/man\/1\/logconv.pl"}},{"Process":{"Description":null,"Process Name":"loggen","Link":"https:\/\/linux.die.net\/man\/1\/loggen"}},{"Process":{"Description":"Logger makes entries in the system log. It provides a shell command interface to the syslog(3) system log module. Options:       -i'         Log the process id of the logger process with each line. -s' Log the message to standard error, as well as the system log. -f file Log the specified file. -p pri Enter the message with the specified priority. The priority may be specified numerically or as a ''facility.level'' pair. For example, ''-p local3.info'' logs the message(s) as informational level in the local3 facility. The default is ''user.notice.'' -t tag Mark every line in the log with the specified tag. -u sock Write to socket as specified with socket instead of builtin syslog routines. -d' Use a datagram instead of a stream connection to this socket. --' End the argument list. This is to allow the message to start with a hyphen (-). message Write the message to log; if not specified, and the -f flag is not provided, standard input is logged. The logger utility exits 0 on success, and >0 if an error occurs. Valid facility names are: auth, authpriv (for security information of a sensitive nature), cron, daemon, ftp, kern, lpr, mail, news, security (deprecated synonym for auth), syslog, user, uucp, and local0 to local7, inclusive. Valid level names are): alert, crit, debug, emerg, err, error (deprecated synonym for err), info, notice, panic (deprecated synonym for emerg), warning, warn (deprecated synonym for warning). For the priority order and intended purposes of these levels, see syslog(3).","Process Name":"logger","Link":"https:\/\/linux.die.net\/man\/1\/logger"}},{"Process":{"Description":null,"Process Name":"login","Link":"https:\/\/linux.die.net\/man\/1\/login"}},{"Process":{"Description":"Logmonster is a tool to collect log files from one or many Apache web servers, split them based on the virtual host they were served for, sort the logs into cronological order, and finally pipe the sorted logs to the log file analyzer of choice (webalizer, http-analyze, AWstats, etc). MOTIVATION Log collection: I have a number of web sites that are mirrored on two or three web servers. The statistics I care about are agreggate. I want to know how much traffic a web site is getting across all the servers. To accomplish that, the logs must be collected from each server. Sorting: Since most log processors require the log file entries to be in chronological order, simply concatenating them, or feeding them one after another does not work. Logmonster takes care of this by sorting all the log entries for each vhost into chronological order. Processor Agnostic: If I want to switch from one log processor to another, it should be simple and painless. Logmonster takes care of all the dirty work to make the possible. Each domain can even have its own processor. FEATURES * Log Retrieval from one or mnay hosts * Ouputs to webalizer, http-analyze, and AWstats. * Automatic vhost configuration Logmonster reads your Apache config files to learn about your virtual hosts and their file system location. Logmonster also generates config files as required (ie, awstats.example.com.conf). * Settings configuration for each virtualhost Outputs stats into each virtual domains stats dir, if that directory exists. This is an easy way to enable or disable stats for a virtual host. If \"stats\" exists, it will be updated. Otherwise it will not. Can also creates missing stats directories if desired (see statsdir_policy in logmonster.conf). * Efficient uses Compress::Zlib to read directly from .gz files to minimizes network and disk usage. Skips processing logs for vhosts with no $statsdir. Skips sorting if you only have logs from one host. * Flexible update intervals you can run it monthly, daily, or hourly * Reporting saves an activity report and sends an email friendly report. * Reliable lots of error checking so if something goes wrong, it gives a useful error message. * Apache savvy Understands and correctly deals with server aliases","Process Name":"logmonster.pl","Link":"https:\/\/linux.die.net\/man\/1\/logmonster.pl"}},{"Process":{"Description":null,"Process Name":"logname","Link":"https:\/\/linux.die.net\/man\/1\/logname"}},{"Process":{"Description":null,"Process Name":"logout","Link":"https:\/\/linux.die.net\/man\/1\/logout"}},{"Process":{"Description":"","Process Name":"logresolve","Link":"https:\/\/linux.die.net\/man\/1\/logresolve"}},{"Process":{"Description":"The longrun utility is used to control and query LongRun settings on Transmeta Crusoe processors. -c device Set the CPUID device. The default CPUID device is \/dev\/cpu\/0\/cpuid. -m device Set the MSR device. The default CPUID device is \/dev\/cpu\/0\/msr. -h Print help. -l List LongRun information about available performance levels for the CPU. The following values are reported on all Transmeta CPUs that implement LongRun. % An available performance level, expressed as a percentage of range of available core CPU frequencies. 0 corresponds to the lowest available frequency and 100 corresponds to the highest. MHz The core CPU frequency at that level. Volts The core CPU voltage at that level. usage The power usage relative to the maximum performance level. -p Print current LongRun settings and status: whether LongRun is enabled, whether LongRun Thermal Extensions are active, the current LongRun performance window (expressed as a percentile range), the current LongRun performance level (expressed as a percentile), and the current LongRun flags. -v Be more verbose. -f flag Set a LongRun mode flag. Currently, the two supported flags are performance and economy. This controls whether the processor is in \"performance mode\" or \"economy mode\". -s low high Set the current LongRun performance window as a percentile range. The low number cannot be greater than the high number. The minimum and maximum performance values accepted by the CPU are 0 and 100, respectively. -t num Set current LongRun Thermal Extensions setting (0 to 8, 8 = off). Take care with -t 0 and -t 1. Longrun Thermal Extensions (LTX) is an alternative way to manipulate the power saving functionality of the processor, by controlling heat dissipation directly. Settings 2 through 8 represent power utilization levels from 25% to 100%, respectively, in 12.5% increments. NOTE: Settings 0 and 1 are listed as 'reserved' in the TM5600 literature. Though they appear to represent 0% and 12.5% respectively on the TM5800 chip, use these settings at your own risk. Interaction with the -s flag: Originally intended as a mechanism to use Transmeta chips on fanless machines (referred to apocryphally as \"coolrun\"), the -t flag limits the power range of the processor. The performance range of the processor is limited first by the -t flag, and then subsequently the -s flag. In other words, setting both '-s 57 100' and '-t 7' will result in the processor running in the 57 to 75% power range. Notes: This functionality may or may not provide you with different performance per watt characteristings than the -s flag. It is provided for completeness, and left as an exercise to the reader to decide if it is appropriate on their system. As mentioned above, use the -t 0 and -t 1 settings with caution.","Process Name":"longrun","Link":"https:\/\/linux.die.net\/man\/1\/longrun"}},{"Process":{"Description":"The look utility displays any lines in file which contain string as a prefix. As look performs a binary search, the lines in file must be sorted (where sort(1) got the same options -d and\/or -f that look is invoked with). If file is not specified, the file \/usr\/share\/dict\/words is used, only alphanumeric characters are compared and the case of alphabetic characters is ignored. Options:       -d'        Dictionary character set and order, i.e. only alphanumericcharacters are compared. (On by default if no file specified). -f' Ignore the case of alphabetic characters. (On by default if no file specified). -a' Use the alternate dictionary \/usr\/share\/dict\/web2 -t' Specify a string termination character, i.e. only the characters in string up to and including the first occurrence of termchar are compared. The look utility exits 0 if one or more lines were found and displayed, 1 if no lines were found, and >1 if an error occurred.","Process Name":"look","Link":"https:\/\/linux.die.net\/man\/1\/look"}},{"Process":{"Description":null,"Process Name":"lookbib","Link":"https:\/\/linux.die.net\/man\/1\/lookbib"}},{"Process":{"Description":"loon is a CAD tool that allows to remove fanout problems within a gate netlist and also to optimize the delay. The netlist can be hierarchical and is flattened if necessary. loon runs in batch mode and a parameter file can be used (see man lax) to parametrize optimization by adding informations on outputs (fanin), inputs (fanout, delay) and by setting general parameters such as optimization level. loon permits to compute delays of gates in the netlist and gives the critical path in the netlist. The global optimization of loon performs gate repowering to decrease the critical path delay and global capacitance. Buffers are only inserted in critical path. lax Parameter file description The lax file is common with other logic synthesis tools and is used for driving the synthesis process. See lax(5) manual for more detail. lax uses a lot of parameters to guide every step of the synthesis process. Some parameters are globally used (for example, optimization level whereas others are specifically used (load capacitance for the netlist optimization only). Here is the default lax file (see the user's manual for further information about the syntax of the '.lax' file): Optimization mode = 2 (50% area - 50% delay) Input impedance = 0 Output capacitance = 0 Delayed input = none Auxiliary signal saved = none","Process Name":"loon","Link":"https:\/\/linux.die.net\/man\/1\/loon"}},{"Process":{"Description":"Another cellular automaton. This one produces loop-shaped colonies that spawn, age, and eventually die.","Process Name":"loop","Link":"https:\/\/linux.die.net\/man\/1\/loop"}},{"Process":{"Description":null,"Process Name":"lore","Link":"https:\/\/linux.die.net\/man\/1\/lore"}},{"Process":{"Description":"Invoke the Basser Lout interpreter on the concatenation of the named files, producing a PostScript file on standard output suitable for printing on PostScript printers using lpr(1). If no files are named, stdin is used instead. The special file name ' -' may be used to denote standard input. White space between flags and their associated option values is optional. An optional .lt suffix may be used for Lout source and include files. When invoking files ending in this suffix the suffix may be omitted.","Process Name":"lout","Link":"https:\/\/linux.die.net\/man\/1\/lout"}},{"Process":{"Description":"The lp utility shall copy the input files to an output destination in an unspecified manner. The default output destination should be to a hardcopy device, such as a printer or microfilm recorder, that produces non-volatile, human-readable documents. If such a device is not available to the application, or if the system provides no such device, the lp utility shall exit with a non-zero exit status. The actual writing to the output device may occur some time after the lp utility successfully exits. During the portion of the writing that corresponds to each input file, the implementation shall guarantee exclusive access to the device. The lp utility shall associate a unique request ID with each request. Normally, a banner page is produced to separate and identify each print job. This page may be suppressed by implementation-defined conditions, such as an operator command or one of the -o option values.","Process Name":"lp","Link":"https:\/\/linux.die.net\/man\/1\/lp"}},{"Process":{"Description":"lp submits files for printing or alters a pending job. Use a filename of \"-\" to force printing from the standard input.","Process Name":"lp-cups","Link":"https:\/\/linux.die.net\/man\/1\/lp-cups"}},{"Process":{"Description":null,"Process Name":"lp5250d","Link":"https:\/\/linux.die.net\/man\/1\/lp5250d"}},{"Process":{"Description":"Changes password of user or group name. If the name argument is not provided, username of the invoking user is used; the name argument is ignored if lpasswd is run set-uid to a different user. Entering an empty password (by pressing Enter) aborts the password setting operation.","Process Name":"lpasswd","Link":"https:\/\/linux.die.net\/man\/1\/lpasswd"}},{"Process":{"Description":null,"Process Name":"lpoptions","Link":"https:\/\/linux.die.net\/man\/1\/lpoptions"}},{"Process":{"Description":"lppasswd adds, changes, or deletes passwords in the CUPS digest password file, passwd.md5. When run by a normal user, lppasswd will prompt for the old and new passwords. When run by the super-user, lppasswd can add new accounts ( -a username), change existing accounts ( username), or delete accounts ( -x username) in the digest password file. Digest usernames do not have to match local UNIX usernames.","Process Name":"lppasswd","Link":"https:\/\/linux.die.net\/man\/1\/lppasswd"}},{"Process":{"Description":"lpq shows the current print queue status on the named printer. Jobs queued on the default destination will be shown if no printer or class is specified on the command-line. The +interval option allows you to continuously report the jobs in the queue until the queue is empty; the list of jobs is shown once every interval seconds.","Process Name":"lpq-cups","Link":"https:\/\/linux.die.net\/man\/1\/lpq-cups"}},{"Process":{"Description":null,"Process Name":"lpr-cups","Link":"https:\/\/linux.die.net\/man\/1\/lpr-cups"}},{"Process":{"Description":"lprm cancels print jobs that have been queued for printing. If no arguments are supplied, the current job on the default destination is cancelled. You can specify one or more job ID numbers to cancel those jobs or use the - option to cancel all jobs.","Process Name":"lprm-cups","Link":"https:\/\/linux.die.net\/man\/1\/lprm-cups"}},{"Process":{"Description":null,"Process Name":"lpstat-cups","Link":"https:\/\/linux.die.net\/man\/1\/lpstat-cups"}},{"Process":{"Description":"lqtplay just plays the given quicktime movie in a window on your X11 display. Sound is played using a OSS dsp device or Alsa (if available). Some info about the movie and some other stuff is printed on stderr. No fancy GUI. The only interactive element is that you can resize the window, and lqtplay will adapt the video size if support for hardware-scaled video is available. lqtplay comes with libquicktime and uses libquicktime to read and decode the movies. It is a sample application and intentionally kept simple. If you want a full-featured media player, have a look at gstreamer.","Process Name":"lqtplay","Link":"https:\/\/linux.die.net\/man\/1\/lqtplay"}},{"Process":{"Description":null,"Process Name":"lrelease","Link":"https:\/\/linux.die.net\/man\/1\/lrelease"}},{"Process":{"Description":"lrstolfm Creates an LFM file from resources for a Lazarus project or package (LRS).","Process Name":"lrstolfm","Link":"https:\/\/linux.die.net\/man\/1\/lrstolfm"}},{"Process":{"Description":null,"Process Name":"lrunzip","Link":"https:\/\/linux.die.net\/man\/1\/lrunzip"}},{"Process":{"Description":null,"Process Name":"lrzcat","Link":"https:\/\/linux.die.net\/man\/1\/lrzcat"}},{"Process":{"Description":"LRZIP is a file compression program designed to do particularly well on very large files containing long distance redundancy. lrztar is a wrapper for LRZIP to simplify compression and decompression of directories.","Process Name":"lrzip","Link":"https:\/\/linux.die.net\/man\/1\/lrzip"}},{"Process":{"Description":null,"Process Name":"lrztar","Link":"https:\/\/linux.die.net\/man\/1\/lrztar"}},{"Process":{"Description":"lrzuntar is identical to \"lrztar -d\" used to decompress lrzip compressed tarballs.","Process Name":"lrzuntar","Link":"https:\/\/linux.die.net\/man\/1\/lrzuntar"}},{"Process":{"Description":null,"Process Name":"ls","Link":"https:\/\/linux.die.net\/man\/1\/ls"}},{"Process":{"Description":"lsattr lists the file attributes on a second extended file system. See chattr(1) for a description of the attributes and what they mean.","Process Name":"lsattr","Link":"https:\/\/linux.die.net\/man\/1\/lsattr"}},{"Process":{"Description":null,"Process Name":"lsb_release","Link":"https:\/\/linux.die.net\/man\/1\/lsb_release"}},{"Process":{"Description":"The command list all\/chosen cgroups. <controllers>:<path> defines control groups which subgroups will be shown. If this parameter is not used then the command list all cgroups which are present.","Process Name":"lscgroup","Link":"https:\/\/linux.die.net\/man\/1\/lscgroup"}},{"Process":{"Description":null,"Process Name":"lscpu","Link":"https:\/\/linux.die.net\/man\/1\/lscpu"}},{"Process":{"Description":"lsdic displays the list of the user's dictionaries. To display the list of another user, specify the user name by -u option. To display the system dictionary list, specify the -i option.","Process Name":"lsdic","Link":"https:\/\/linux.die.net\/man\/1\/lsdic"}},{"Process":{"Description":null,"Process Name":"lsdiff","Link":"https:\/\/linux.die.net\/man\/1\/lsdiff"}},{"Process":{"Description":"The lsdnssec program summarizes information about DNSSEC-related files. These files may be specified on the command line or found in directories that were given on the command line. The -d flag controls the amount of detail in the lsdnssec output. lsdnssec displays the following information about each zone for which it collects information: keys Key information is shown about the keys currently in use. A bar graph is included that shows the age of the key with respect to the configured expected key lifetime. This information is collected from any .krf files lsdnssec finds. rolling status If any zone keys are being rolled via rollerd, then the status of the rolling state is shown. The time needed to reach the next state is also displayed. This information is collected from any .rollrec or .rrf files found by lsdnssec.","Process Name":"lsdnssec","Link":"https:\/\/linux.die.net\/man\/1\/lsdnssec"}},{"Process":{"Description":null,"Process Name":"lsdvd","Link":"https:\/\/linux.die.net\/man\/1\/lsdvd"}},{"Process":{"Description":"lshal is a utility for displaying items in the HAL device database. For more information about both the big picture and specific HAL properties, refer to the HAL spec which can be found in \/usr\/share\/doc\/hal-0.5.14\/spec\/hal-spec.html depending on the distribution.","Process Name":"lshal","Link":"https:\/\/linux.die.net\/man\/1\/lshal"}},{"Process":{"Description":null,"Process Name":"lshell","Link":"https:\/\/linux.die.net\/man\/1\/lshell"}},{"Process":{"Description":"lshw is a small tool to extract detailed information on the hardware configuration of the machine. It can report exact memory configuration, firmware version, mainboard configuration, CPU version and speed, cache configuration, bus speed, etc. on DMI-capable x86 or IA-64 systems and on some PowerPC machines (PowerMac G4 is known to work). It currently supports DMI (x86 and IA-64 only), OpenFirmware device tree (PowerPC only), PCI\/AGP, CPUID (x86), IDE\/ATA\/ATAPI, PCMCIA (only tested on x86), SCSI and USB. -version Displays the version of lshw and exits. -help Displays the available command line options and quits. -X Launch the X11 GUI (if available). -html Outputs the device tree as an HTML page. -xml Outputs the device tree as an XML tree. -short Outputs the device tree showing hardware paths, very much like the output of HP-UX's ioscan. -businfo Outputs the device list showing bus information, detailing SCSI, USB, IDE and PCI addresses. -class class Only show the given class of hardware. class can be found using lshw -short or lshw -businfo. -C class Alias for -class class. -enable test -disable test Enables or disables a test. test can be dmi (for DMI\/SMBIOS extensions), device-tree (for OpenFirmware device tree), spd (for memory Serial Presence Detect), memory (for memory-size guessing heuristics), cpuinfo (for kernel-reported CPU detection), cpuid (for CPU detection), pci (for PCI\/AGP access), isapnp (for ISA PnP extensions), pcmcia (for PCMCIA\/PCCARD), ide (for IDE\/ATAPI), usb (for USB devices), scsi (for SCSI) or network (for network interfaces detection). -quiet Don't display status. -sanitize Remove potentially sensible information from output (IP addresses, serial numbers, etc.). -numeric Also display numeric IDs (for PCI and USB devices).","Process Name":"lshw","Link":"https:\/\/linux.die.net\/man\/1\/lshw"}},{"Process":{"Description":null,"Process Name":"lskrf","Link":"https:\/\/linux.die.net\/man\/1\/lskrf"}},{"Process":{"Description":"This program inputs the data of the coefficient matrix from matrix_filename and solves the linear equation Ax = b with the solver specified by options. It outputs the solution to solution_filename in the extended Matrix Market format and the residual_history to residual_filename in the PLAIN format (see Appendix of the Lis User Manual). The Matrix Market and extended Matrix Market formats are supported for matrix_filename. One of the following values can be specified by rhs_setting: 0 Use the right hand side vector b included in matrix_filename 1 Use b = (1, ..., 1)^T 2 Use b = A x (1, ..., 1)^T rhs_filename The filename for the right-hand side vector The PLAIN and Matrix Market formats are supported for rhs_filename.","Process Name":"lsolve","Link":"https:\/\/linux.die.net\/man\/1\/lsolve"}},{"Process":{"Description":null,"Process Name":"lsort","Link":"https:\/\/linux.die.net\/man\/1\/lsort"}},{"Process":{"Description":"lspst is a program that can read an Outlook PST (Personal Folders) file and produce a simple listing of the data (contacts, email subjects, etc).","Process Name":"lspst","Link":"https:\/\/linux.die.net\/man\/1\/lspst"}},{"Process":{"Description":null,"Process Name":"lsrealm","Link":"https:\/\/linux.die.net\/man\/1\/lsrealm"}},{"Process":{"Description":null,"Process Name":"lsroll","Link":"https:\/\/linux.die.net\/man\/1\/lsroll"}},{"Process":{"Description":null,"Process Name":"lss16toppm","Link":"https:\/\/linux.die.net\/man\/1\/lss16toppm"}},{"Process":{"Description":null,"Process Name":"lssubsys","Link":"https:\/\/linux.die.net\/man\/1\/lssubsys"}},{"Process":{"Description":"lstopo and lstopo-no-graphics are capable of displaying a topological map of the system in a variety of different output formats. The only difference between lstopo and lstopo-no-graphics is that graphical outputs are only supported by lstopo, to reduce dependencies on external libraries. If no filename is specified and the DISPLAY environment variable is set, lstopo displays the map in a graphical window. If no filename is specified and the DISPLAY environment variable is not set, a text summary is displayed. The filename specified directly implies the output format that will be used; see the OUTPUT FORMATS section, below. Output formats that support color will indicate specific characteristics about individual CPUs by their color; see the COLORS section, below.","Process Name":"lstopo","Link":"https:\/\/linux.die.net\/man\/1\/lstopo"}},{"Process":{"Description":null,"Process Name":"lstopo-no-graphics","Link":"https:\/\/linux.die.net\/man\/1\/lstopo-no-graphics"}},{"Process":{"Description":"Lsyncd(1) watches local directory trees through an event monitor interface (inotify, fsevents). It aggregates and combines events for a few seconds and then spawns one or more processes to synchronize the changes. By default this is rsync(1). Lsyncd is thus a light-weight asynchronous live mirror solution that is comparatively easy to install not requiring new filesystems or blockdevices and does not hamper local filesystem performance. Rsync+ssh is an advanced action configuration that uses a ssh(1) to act file and directory moves directly on the target instead of retransmitting the move destination over the wire. Fine-grained customization can be achieved through the CONFIG-FILE. Custom action configs can even be written from scratch in cascading layers ranging from shell scripts to code written in the lua(1) language. This way simplicity can be balanced with powerfulness. See the online manual for details on the CONFIG-FILE http:\/\/code.google.com\/p\/lsyncd\/wiki\/Lsyncd20Manual Note that under normal configuration Lsyncd will delete pre-existing files in the target directories that are not present in the respective source directory.","Process Name":"lsyncd","Link":"https:\/\/linux.die.net\/man\/1\/lsyncd"}},{"Process":{"Description":null,"Process Name":"ltdbtool","Link":"https:\/\/linux.die.net\/man\/1\/ltdbtool"}},{"Process":{"Description":"ltrace is a program that simply runs the specified command until it exits. It intercepts and records the dynamic library calls which are called by the executed process and the signals which are received by that process. It can also intercept and print the system calls executed by the program. Its use is very similar to strace(1).","Process Name":"ltrace","Link":"https:\/\/linux.die.net\/man\/1\/ltrace"}},{"Process":{"Description":null,"Process Name":"ltsp-info","Link":"https:\/\/linux.die.net\/man\/1\/ltsp-info"}},{"Process":{"Description":"This manual page documents briefly the ltspfs command. ltspfs is a program that mounts fuse based filesystems that got exported by ltspfsd","Process Name":"ltspfs","Link":"https:\/\/linux.die.net\/man\/1\/ltspfs"}},{"Process":{"Description":null,"Process Name":"ltspfs_mount","Link":"https:\/\/linux.die.net\/man\/1\/ltspfs_mount"}},{"Process":{"Description":"ltspfs_umount is called by ltspfsd(1) when an ltspfs filesystem is no longer used or idle. This program is not intended to be run manually.","Process Name":"ltspfs_umount","Link":"https:\/\/linux.die.net\/man\/1\/ltspfs_umount"}},{"Process":{"Description":null,"Process Name":"ltspfsd","Link":"https:\/\/linux.die.net\/man\/1\/ltspfsd"}},{"Process":{"Description":"This manual page documents briefly the ltspfsmounter command. ltspfsmounter is a program that mounts fuse based filesystems that got exported by ltspfsd from a thin client it uses ltspfs and the lbmount suid wrapper to bind mount them to \/media. This program is not intended to be run manually, but by udev scripts from the ltspfsd package installed on a thin client.","Process Name":"ltspfsmounter","Link":"https:\/\/linux.die.net\/man\/1\/ltspfsmounter"}},{"Process":{"Description":null,"Process Name":"lttng","Link":"https:\/\/linux.die.net\/man\/1\/lttng"}},{"Process":{"Description":"The LTTng project aims at providing highly efficient tracing tools for Linux. It's tracers help tracking down performance issues and debugging problems involving multiple concurrent processes and threads. Tracing across multiple systems is also possible. The lttng-gen-tp tool simplify the generation of the UST tracepoint files. It takes a simple template file and generate the necessary code to use the defined tracepoints in your application. The section TEMPLATE FILE FORMAT describe the content of the template file. Currently, the tool can generate the .h, .c and .o associated to your tracepoint. The generated .h can be directly included in your application. You can let the tool generate the .o or compile the .c yourself. You can compile the .c into a .o, .a or .so at your choice and link it with your application. Refer to the UST documentation for the advantages and disadvantage of each form. To compile the resulting .c file, you need to add the options \"-llttng-ust -I.\". Note for C++ support: although an application instrumented with tracepoints can be compiled with g++, tracepoint probes should be compiled with gcc (only tested with gcc so far).","Process Name":"lttng-gen-tp","Link":"https:\/\/linux.die.net\/man\/1\/lttng-gen-tp"}},{"Process":{"Description":null,"Process Name":"lua","Link":"https:\/\/linux.die.net\/man\/1\/lua"}},{"Process":{"Description":"luac is the Lua compiler. It translates programs written in the Lua programming language into binary files that can be later loaded and executed. The main advantages of precompiling chunks are: faster loading, protecting source code from accidental user changes, and off-line syntax checking. Pre-compiling does not imply faster execution because in Lua chunks are always compiled into bytecodes before being executed. luac simply allows those bytecodes to be saved in a file for later execution. Pre-compiled chunks are not necessarily smaller than the corresponding source. The main goal in pre-compiling is faster loading. The binary files created by luac are portable only among architectures with the same word size and byte order. luac produces a single output file containing the bytecodes for all source files given. By default, the output file is named luac.out, but you can change this with the -o option. In the command line, you can mix text files containing Lua source and binary files containing precompiled chunks. This is useful to combine several precompiled chunks, even from different (but compatible) platforms, into a single precompiled chunk. You can use '-' to indicate the standard input as a source file and '--' to signal the end of options (that is, all remaining arguments will be treated as files even if they start with '-'). The internal format of the binary files produced by luac is likely to change when a new version of Lua is released. So, save the source files of all Lua programs that you precompile.","Process Name":"luac","Link":"https:\/\/linux.die.net\/man\/1\/luac"}},{"Process":{"Description":null,"Process Name":"luit","Link":"https:\/\/linux.die.net\/man\/1\/luit"}},{"Process":{"Description":null,"Process Name":"luks-format","Link":"https:\/\/linux.die.net\/man\/1\/luks-format"}},{"Process":{"Description":"Luks-is-encrypted is a tool that will determine if a device contains a LUKS header.","Process Name":"luks-is-encrypted","Link":"https:\/\/linux.die.net\/man\/1\/luks-is-encrypted"}},{"Process":{"Description":null,"Process Name":"luks-setup","Link":"https:\/\/linux.die.net\/man\/1\/luks-setup"}},{"Process":{"Description":"","Process Name":"luks-tools","Link":"https:\/\/linux.die.net\/man\/1\/luks-tools"}},{"Process":{"Description":null,"Process Name":"lupdate","Link":"https:\/\/linux.die.net\/man\/1\/lupdate"}},{"Process":{"Description":"Adds an user with name user.","Process Name":"luseradd","Link":"https:\/\/linux.die.net\/man\/1\/luseradd"}},{"Process":{"Description":"Deletes the user with name user.","Process Name":"luserdel","Link":"https:\/\/linux.die.net\/man\/1\/luserdel"}},{"Process":{"Description":null,"Process Name":"lusermod","Link":"https:\/\/linux.die.net\/man\/1\/lusermod"}},{"Process":{"Description":"Multilingual file viewer lv is a powerful multilingual file viewer. Apparently, lv looks like less (1), a representative file viewer on UNIX as you know, so UNIX people (and less people on other OSs) don't have to learn a burdensome new interface. lv can be used on MSDOS ANSI terminals and almost all UNIX platforms. lv is a currently growing software, so your feedback is welcome and helpful for us to refine the future lv. Multiple coding systems lv can decode and encode multilingual streams through many coding systems, for example, ISO 2022 based coding systems such as iso-2022-jp, and EUC (Extended Unix Code) like euc-japan. Furthermore, localized coding systems such as shift-jis, big5 and HZ are also supported. lv can be used not only as a file viewer but also as a coding-system translation filter like nkf (1) and tcs (1). Multilingual regular expressions \/ Multilingual grep lv can recognize multi-bytes patterns as regular expressions, and lv also provides multilingual grep (1) functionality by giving it another name, lgrep. Pattern matching is conducted in the charset level, so an EUC fragment, for example, can be found in the ISO 2022 tailored streams, of course. Supporting the Unicode standard lv provides Unicode facilities which enables you to handle Unicode streams encoded in UTF-7 or UTF-8, and lv can also convert their code-points between Unicode and other charsets. So you can display Unicode or foreign texts on your terminal, using the code conversion function to your favorite charsets via Unicode. (However, MSDOS version of lv has none of the Unicode facility.) ANSI escape sequence through lv can recognize ANSI escape sequences for text decoration. So you can look ANSI-decorated streams such as colored source codes generated by another software just like intended image on ANSI terminals. Completely original lv is a completely original software including no code drawn from less and grep and other programs at all.","Process Name":"lv","Link":"https:\/\/linux.die.net\/man\/1\/lv"}},{"Process":{"Description":null,"Process Name":"lvx","Link":"https:\/\/linux.die.net\/man\/1\/lvx"}},{"Process":{"Description":null,"Process Name":"lwp-download","Link":"https:\/\/linux.die.net\/man\/1\/lwp-download"}},{"Process":{"Description":"The lwp-dump program will get the resource indentified by the URL and then dump the response object to STDOUT . This will display the headers returned and the initial part of the content, escaped so that it's safe to display even binary content. The escapes syntax used is the same as for Perl's double quoted strings. If there is no content the string \"(no content)\" is shown in its place. The following options are recognized: --agent str Override the user agent string passed to the server. --keep-client-headers LWP internally generate various \"Client-*\" headers that are stripped by lwp-dump in order to show the headers exactly as the server provided them. This option will suppress this. --max-length n How much of the content to show. The default is 512. Set this to 0 for unlimited. If the content is longer then the string is chopped at the limit and the string \"...\\n(### more bytes not shown)\" appended. --method str Use the given method for the request instead of the default \" GET \". --parse-head By default lwp-dump will not try to initialize headers by looking at the head section of HTML documents. This option enables this. This corresponds to \"parse_head\" in LWP::UserAgent.","Process Name":"lwp-dump","Link":"https:\/\/linux.die.net\/man\/1\/lwp-dump"}},{"Process":{"Description":null,"Process Name":"lwp-mirror","Link":"https:\/\/linux.die.net\/man\/1\/lwp-mirror"}},{"Process":{"Description":"This program can be used to send requests to WWW servers and your local file system. The request content for POST and PUT methods is read from stdin. The content of the response is printed on stdout. Error messages are printed on stderr. The program returns a status value indicating the number of URLs that failed. The options are: -m <method> Set which method to use for the request. If this option is not used, then the method is derived from the name of the program. -f Force request through, even if the program believes that the method is illegal. The server might reject the request eventually. -b <uri> This URI will be used as the base URI for resolving all relative URIs given as argument. -t <timeout> Set the timeout value for the requests. The timeout is the amount of time that the program will wait for a response from the remote server before it fails. The default unit for the timeout value is seconds. You might append \"m\" or \"h\" to the timeout value to make it minutes or hours, respectively. The default timeout is '3m', i.e. 3 minutes. -i <time> Set the If-Modified-Since header in the request. If time is the name of a file, use the modification timestamp for this file. If time is not a file, it is parsed as a literal date. Take a look at HTTP::Date for recognized formats. -c <content-type> Set the Content-Type for the request. This option is only allowed for requests that take a content, i.e. POST and PUT . You can force methods to take content by using the \"-f\" option together with \"-c\". The default Content-Type for POST is \"application\/x-www-form-urlencoded\". The default Content-type for the others is \"text\/plain\". -p <proxy-url> Set the proxy to be used for the requests. The program also loads proxy settings from the environment. You can disable this with the \"-P\" option. -P Don't load proxy settings from environment. -H <header> Send this HTTP header with each request. You can specify several, e.g.: lwp-request \\\n    -H 'Referer: http:\/\/other.url\/' \\\n    -H 'Host: somehost' \\\n    http:\/\/this.url\/ -C <username>:<password> Provide credentials for documents that are protected by Basic Authentication. If the document is protected and you did not specify the username and password with this option, then you will be prompted to provide these values. The following options controls what is displayed by the program: -u Print request method and absolute URL as requests are made. -U Print request headers in addition to request method and absolute URL . -s Print response status code. This option is always on for HEAD requests. -S Print response status chain. This shows redirect and authorization requests that are handled by the library. -e Print response headers. This option is always on for HEAD requests. -d Do not print the content of the response. -o <format> Process HTML content in various ways before printing it. If the content type of the response is not HTML , then this option has no effect. The legal format values are; text, ps, links, html and dump. If you specify the text format then the HTML will be formatted as plain latin1 text. If you specify the ps format then it will be formatted as Postscript. The links format will output all links found in the HTML document. Relative links will be expanded to absolute ones. The html format will reformat the HTML code and the dump format will just dump the HTML syntax tree. Note that the \"HTML-Tree\" distribution needs to be installed for this option to work. In addition the \"HTML-Format\" distribution needs to be installed for -o text or -o ps to work. -v Print the version number of the program and quit. -h Print usage message and quit. -a Set text(ascii) mode for content input and output. If this option is not used, content input and output is done in binary mode. Because this program is implemented using the LWP library, it will only support the protocols that LWP supports.","Process Name":"lwp-request","Link":"https:\/\/linux.die.net\/man\/1\/lwp-request"}},{"Process":{"Description":null,"Process Name":"lwp-rget","Link":"https:\/\/linux.die.net\/man\/1\/lwp-rget"}},{"Process":{"Description":null,"Process Name":"lxc-attach","Link":"https:\/\/linux.die.net\/man\/1\/lxc-attach"}},{"Process":{"Description":"","Process Name":"lxc-cgroup","Link":"https:\/\/linux.die.net\/man\/1\/lxc-cgroup"}},{"Process":{"Description":null,"Process Name":"lxc-checkpoint","Link":"https:\/\/linux.die.net\/man\/1\/lxc-checkpoint"}},{"Process":{"Description":null,"Process Name":"lxc-console","Link":"https:\/\/linux.die.net\/man\/1\/lxc-console"}},{"Process":{"Description":"","Process Name":"lxc-create","Link":"https:\/\/linux.die.net\/man\/1\/lxc-create"}},{"Process":{"Description":null,"Process Name":"lxc-destroy","Link":"https:\/\/linux.die.net\/man\/1\/lxc-destroy"}},{"Process":{"Description":"lxc-execute runs the specified command inside the container specified by name. It will setup the container according to the configuration previously defined with the lxc-create command or with the configuration file parameter. If no configuration is defined, the default isolation is used. This command is mainly used when you want to quickly launch an application in an isolated environment. lxc-execute command will run the specified command into the container via an intermediate process, lxc-init. This lxc-init after launching the specified command, will wait for its end and all other reparented processes. (that allows to support daemons in the container). In other words, in the container, lxc-init has the pid 1 and the first process of the application has the pid 2. The above lxc-init is designed to forward received signals to the started command. So lxc-kill (1) sent signal is received by the user specified command (pid 2 in the container).","Process Name":"lxc-execute","Link":"https:\/\/linux.die.net\/man\/1\/lxc-execute"}},{"Process":{"Description":null,"Process Name":"lxc-freeze","Link":"https:\/\/linux.die.net\/man\/1\/lxc-freeze"}},{"Process":{"Description":null,"Process Name":"lxc-kill","Link":"https:\/\/linux.die.net\/man\/1\/lxc-kill"}},{"Process":{"Description":"","Process Name":"lxc-ls","Link":"https:\/\/linux.die.net\/man\/1\/lxc-ls"}},{"Process":{"Description":"","Process Name":"lxc-monitor","Link":"https:\/\/linux.die.net\/man\/1\/lxc-monitor"}},{"Process":{"Description":"","Process Name":"lxc-ps","Link":"https:\/\/linux.die.net\/man\/1\/lxc-ps"}},{"Process":{"Description":null,"Process Name":"lxc-restart","Link":"https:\/\/linux.die.net\/man\/1\/lxc-restart"}},{"Process":{"Description":"lxc-start runs the specified command inside the container specified by name. It will setup the container according to the configuration previously defined with the lxc-create command or with the configuration file parameter. If no configuration is defined, the default isolation is used. The orphan process group and daemon are not supported by this command, use the lxc-execute command instead. If no command is specified, lxc-start will use the default \"\/sbin\/init\" command to run a system container.","Process Name":"lxc-start","Link":"https:\/\/linux.die.net\/man\/1\/lxc-start"}},{"Process":{"Description":null,"Process Name":"lxc-stop","Link":"https:\/\/linux.die.net\/man\/1\/lxc-stop"}},{"Process":{"Description":"","Process Name":"lxc-unfreeze","Link":"https:\/\/linux.die.net\/man\/1\/lxc-unfreeze"}},{"Process":{"Description":null,"Process Name":"lxc-wait","Link":"https:\/\/linux.die.net\/man\/1\/lxc-wait"}},{"Process":{"Description":null,"Process Name":"lxdvdrip","Link":"https:\/\/linux.die.net\/man\/1\/lxdvdrip"}},{"Process":{"Description":"Mines LXT2 files for specific data values and generates gtkwave save files to stdout for future reload.","Process Name":"lxt2miner","Link":"https:\/\/linux.die.net\/man\/1\/lxt2miner"}},{"Process":{"Description":null,"Process Name":"lxt2vcd","Link":"https:\/\/linux.die.net\/man\/1\/lxt2vcd"}},{"Process":{"Description":null,"Process Name":"lynx","Link":"https:\/\/linux.die.net\/man\/1\/lynx"}},{"Process":{"Description":"The XML Bookmark Exchange Language, or XBEL, is an Internet \"bookmarks\" interchange format. lynx_parse parses Lynx bookmark files.","Process Name":"lynx_parse","Link":"https:\/\/linux.die.net\/man\/1\/lynx_parse"}},{"Process":{"Description":"LyX is too complex to be described completely in the \"man\" page format. If your system is properly configured, you can access the full documentation within LyX under the Help menu. LyX is a document preparation system. It excels at letting you create complex technical and scientific articles with mathematics, cross-references, bibliographies, indices, etc. It is very good at documents of any length in which the usual processing abilities are required: automatic sectioning and pagination, spellchecking, and so forth. It can also be used to write a letter to your mom, though granted, there are probably simpler programs available for that. It is definitely not the best tool for creating banners, flyers, or advertisements, though with some effort all these can be done, too. Some examples of what it is used for: memos, letters, dissertations and theses, lecture notes, seminar notebooks, conference proceedings, software documentation, books (on PostgreSQL, remote sensing, cryptology, fictional novels, poetry, and even a children's book or two), articles in refereed scientific journals, scripts for plays and movies, business proposals... you get the idea. Currently, LyX uses the Qt4 library as a toolkit. LyX should run everywhere, where this library runs. This is on all major Unix platforms as well as Windows and Mac OS X (which actually is a unix platform).","Process Name":"lyx","Link":"https:\/\/linux.die.net\/man\/1\/lyx"}},{"Process":{"Description":null,"Process Name":"lyxclient","Link":"https:\/\/linux.die.net\/man\/1\/lyxclient"}},{"Process":{"Description":"xz is a general-purpose data compression tool with command line syntax similar to gzip(1) and bzip2(1). The native file format is the .xz format, but also the legacy .lzma format and raw compressed streams with no container format headers are supported. xz compresses or decompresses each file according to the selected operation mode. If no files are given or file is -, xz reads from standard input and writes the processed data to standard output. xz will refuse (display an error and skip the file) to write compressed data to standard output if it is a terminal. Similarly, xz will refuse to read compressed data from standard input if it is a terminal. Unless --stdout is specified, files other than - are written to a new file whose name is derived from the source file name: When compressing, the suffix of the target file format (.xz or .lzma) is appended to the source filename to get the target filename. When decompressing, the .xz or .lzma suffix is removed from the filename to get the target filename. xz also recognizes the suffixes .txz and .tlz, and replaces them with the .tar suffix. If the target file already exists, an error is displayed and the file is skipped. Unless writing to standard output, xz will display a warning and skip the file if any of the following applies: File is not a regular file. Symbolic links are not followed, thus they are never considered to be regular files. File has more than one hardlink. File has setuid, setgid, or sticky bit set. The operation mode is set to compress, and the file already has a suffix of the target file format (.xz or .txz when compressing to the .xz format, and .lzma or .tlz when compressing to the .lzma format). The operation mode is set to decompress, and the file doesn't have a suffix of any of the supported file formats (.xz, .txz, .lzma, or .tlz). After successfully compressing or decompressing the file, xz copies the owner, group, permissions, access time, and modification time from the source file to the target file. If copying the group fails, the permissions are modified so that the target file doesn't become accessible to users who didn't have permission to access the source file. xz doesn't support copying other metadata like access control lists or extended attributes yet. Once the target file has been successfully closed, the source file is removed unless --keep was specified. The source file is never removed if the output is written to standard output. Sending SIGINFO or SIGUSR1 to the xz process makes it print progress information to standard error. This has only limited use since when standard error is a terminal, using --verbose will display an automatically updating progress indicator. Memory usage The memory usage of xz varies from a few hundred kilobytes to several gigabytes depending on the compression settings. The settings used when compressing a file affect also the memory usage of the decompressor. Typically the decompressor needs only 5 % to 20 % of the amount of RAM that the compressor needed when creating the file. Still, the worst-case memory usage of the decompressor is several gigabytes. To prevent uncomfortable surprises caused by huge memory usage, xz has a built-in memory usage limiter. The default limit is 40 % of total physical RAM. While operating systems provide ways to limit the memory usage of processes, relying on it wasn't deemed to be flexible enough. When compressing, if the selected compression settings exceed the memory usage limit, the settings are automatically adjusted downwards and a notice about this is displayed. As an exception, if the memory usage limit is exceeded when compressing with --format=raw, an error is displayed and xz will exit with exit status 1. If source file cannot be decompressed without exceeding the memory usage limit, an error message is displayed and the file is skipped. Note that compressed files may contain many blocks, which may have been compressed with different settings. Typically all blocks will have roughly the same memory requirements, but it is possible that a block later in the file will exceed the memory usage limit, and an error about too low memory usage limit gets displayed after some data has already been decompressed. The absolute value of the active memory usage limit can be seen near the bottom of the output of --long-help. The default limit can be overriden with --memory=limit.","Process Name":"lzcat","Link":"https:\/\/linux.die.net\/man\/1\/lzcat"}},{"Process":{"Description":null,"Process Name":"lzcmp","Link":"https:\/\/linux.die.net\/man\/1\/lzcmp"}},{"Process":{"Description":"xzcmp and xdiff invoke cmp(1) or diff(1) on files compressed with xz(1), lzma(1), gzip(1), or bzip2(1). All options specified are passed directly to cmp or diff. If only one file is specified, then the files compared are file1 (which must have a suffix of a supported compression format) and file1 from which the compression format suffix has been stripped. If two files are specified, then they are uncompressed if necessary and fed to cmp(1) or diff(1). The exit status from cmp or diff is preserved. The names lzcmp and lzdiff are provided for backward compatibility with LZMA Utils.","Process Name":"lzdiff","Link":"https:\/\/linux.die.net\/man\/1\/lzdiff"}},{"Process":{"Description":null,"Process Name":"lzegrep","Link":"https:\/\/linux.die.net\/man\/1\/lzegrep"}},{"Process":{"Description":"xzgrep invokes grep(1) on files which may be either uncompressed or compressed with xz(1), lzma(1), gzip(1), or bzip2(1). All options specified are passed directly to grep(1). If no file is specified, then the standard input is decompressed if necessary and fed to grep(1). When reading from standard input, gzip(1) and bzip2(1) compressed files are not supported. If xzgrep is invoked as xzegrep or xzfgrep then egrep(1) or fgrep(1) is used instead of grep(1). The same applies to names lzgrep, lzegrep, and lzfgrep, which are provided for backward compatibility with LZMA Utils.","Process Name":"lzfgrep","Link":"https:\/\/linux.die.net\/man\/1\/lzfgrep"}},{"Process":{"Description":null,"Process Name":"lzgrep","Link":"https:\/\/linux.die.net\/man\/1\/lzgrep"}},{"Process":{"Description":"Lzip - A data compressor based on the LZMA algorithm.","Process Name":"lzip","Link":"https:\/\/linux.die.net\/man\/1\/lzip"}},{"Process":{"Description":null,"Process Name":"lziprecover","Link":"https:\/\/linux.die.net\/man\/1\/lziprecover"}},{"Process":{"Description":"xzless is a filter that displays pagefulls of uncompressed text from compressed file(s) to a terminal. It works on files compressed with xz(1) or lzma(1). If no files are given, xzless reads from standard input. xzless uses less(1) as its only pager. Unlike xzmore, the choice of pagers is not alterable by an environment variable. Commands are based on both more(1) and vi(1), and allow back and forth movement and searching. See the less(1) manual for more information. The command named lzless is provided for backward compatibility with LZMA Utils.","Process Name":"lzless","Link":"https:\/\/linux.die.net\/man\/1\/lzless"}},{"Process":{"Description":null,"Process Name":"lzma","Link":"https:\/\/linux.die.net\/man\/1\/lzma"}},{"Process":{"Description":"xzdec is a liblzma-based decompression-only tool for .xz (and only .xz) files. xzdec is intended to work as a drop-in replacement for xz(1) in the most common situations where a script has been written to use xz --decompress --stdout (and possibly a few other commonly used options) to decompress .xz files. lzmadec is identical to xzdec except that lzmadec supports .lzma files instead of .xz files. To reduce the size of the executable, xzdec doesn't support multithreading or localization, and doesn't read options from XZ_OPT environment variable. xzdec doesn't support displaying intermediate progress information: sending SIGINFO to xzdec does nothing, but sending SIGUSR1 terminates the process instead of displaying progress information.","Process Name":"lzmadec","Link":"https:\/\/linux.die.net\/man\/1\/lzmadec"}},{"Process":{"Description":null,"Process Name":"lzmainfo","Link":"https:\/\/linux.die.net\/man\/1\/lzmainfo"}},{"Process":{"Description":"xzmore is a filter which allows examination of xz(1) or lzma(1) compressed text files one screenful at a time on a soft-copy terminal. To use a pager other than the default more, set environment variable PAGER to the name of the desired program. The name lzmore is provided for backward compatibility with LZMA Utils. e or q When the prompt --More--(Next file: file) is printed, this command causes xzmore to exit. s When the prompt --More--(Next file: file) is printed, this command causes xzmore to skip the next file and continue. For list of keyboard commands supported while actually viewing the content of a file, refer to manual of the pager you use, usually more(1).","Process Name":"lzmore","Link":"https:\/\/linux.die.net\/man\/1\/lzmore"}},{"Process":{"Description":null,"Process Name":"lzop","Link":"https:\/\/linux.die.net\/man\/1\/lzop"}}]