[{"Process":{"Description":"b2m accepts Babyl format mail (as used by older versions of Rmail in GNU Emacs) on standard input, and converts it to mbox format on standard output. Babyl was the storage format used by Rmail prior to Emacs 23.1. Since then, it uses standard mbox format. This program is distributed with GNU Emacs.","Process Name":"b2m","Link":"https:\/\/linux.die.net\/man\/1\/b2m"}},{"Process":{"Description":"b43-fwcutter can extract the firmware for your Broadcom 43xx hardware from different closed source drivers. The b43 driver depends on this firmware files and can't work without them. Currently b43-fwcutter supports Apple MacOS X, Microsoft Windows 98\/ME\/2000\/XP and Linux drivers, but keep in mind that b43-fwcutter doesn't support all driver versions. Example: b43-fwcutter bcmwl5.sys to cut the firmware out of bcmwl5.sys","Process Name":"b43-fwcutter","Link":"https:\/\/linux.die.net\/man\/1\/b43-fwcutter"}},{"Process":{"Description":"Babel is a cross-platform program designed to interconvert between many file formats used in molecular modeling and computational chemistry and related areas. Open Babel is also a complete programmers toolkit for developing chemistry software. For more information, se the Open Babel web pages <http:\/\/openbabel.org\/>.","Process Name":"babel","Link":"https:\/\/linux.die.net\/man\/1\/babel"}},{"Process":{"Description":"The CUPS backend interface provides a standard method for sending document files to different physical interfaces. Backends must be capable of reading from a filename on the command-line or from the standard input, copying the standard input to a temporary file if required by the physical interface. The command name (argv[0]) is set to the device URI of the destination printer.","Process Name":"backend","Link":"https:\/\/linux.die.net\/man\/1\/backend"}},{"Process":{"Description":"Back In Time is a simple backup tool for Linux. The backup is done by taking snapshots of a specified set of folders. All you have to do is configure: where to save snapshots, what folders to backup. You can also specify a backup schedule: disabled, every 5 minutes, every 10 minutes, every hour, every day, every week, every month. To configure it use one of the graphical interfaces available (backintime-gnome or backintime-kde4). It acts as a 'user mode' backup tool. This means that you can backup\/restore only folders you have write access to (actually you can backup read-only folders, but you can't restore them). If you want to run it as root you need to use 'su'. A new snapshot is created only if something changed since the last snapshot (if any). A snapshot contains all the files from the selected folders (except for exclude patterns). In order to reduce disk space it use hard-links (if possible) between snapshots for unchanged files. This way a file of 10Mb, unchanged for 10 snapshots, will use only 10Mb on the disk. When you restore a file 'A', if it already exists on the file system it will be renamed to 'A.backup.currentdate'. For automatic backup it use 'cron' so there is no need for a daemon, but 'cron' must be running. user-callback During backup process the application can call a user callback at different steps. This callback is \"$XDG_CONFIG_HOME\/backintime\/user-callback\" (by default $XDG_CONFIG_HOME is ~\/.config). The first argument is the progile id (1=Main Profile, ...). The second argument is the progile name. The third argument is the reason: Backup process begins. Backup process ends. A new snapshot was taken. The extra arguments are snapshot ID and snapshot path. There was an error. The second argument is the error code. Error codes: The application is not configured. A \"take snapshot\" process is already running. Can't find snapshots folder (is it on a removable drive ?). A snapshot for \"now\" already exist.","Process Name":"backintime","Link":"https:\/\/linux.die.net\/man\/1\/backintime"}},{"Process":{"Description":"Back In Time is a simple backup tool for Linux. This is the Gnome version. For more information about Back In Time see backintime man page. If you want to run it as root you need to use 'gksu'.","Process Name":"backintime-gnome","Link":"https:\/\/linux.die.net\/man\/1\/backintime-gnome"}},{"Process":{"Description":"backtracker reads (longitude, latitude, age) positions from infiles [or standard input] and computes rotated (x,y,t) coordinates using the specified rotation parameters. It can either calculate final positions [Default] or create a sampled track (flowline or hotspot track) between the initial and final positions. The former mode allows additional data fields after the first 3 columns which must have (longitude,latitude,age). See option -: on how to read (latitude,longitude,age) files. No space between the option flag and the associated arguments. Use upper case for the option flags and lower case for modifiers. infile(s) Data file(s) to be projected. If not given, standard input is read. -E Give file with rotation parameters. This file must contain one record for each rotation; each record must be of the following format: lon lat tstart [tstop] angle [ khat a b c d e f g df ] where tstart and tstop are in Myr and lon lat angle are in degrees. tstart and tstop are the ages of the old and young ends of a stage. If -C is set then a total reconstruction rotation is expected and tstop is implicitly set to 0 and should not be specified in the file. If a covariance matrix C for the rotation is available it must be specified in a format using the nine optional terms listed in brackets. Here, C = (g\/khat)*[ a b d; b c e; d e f ] which shows C made up of three row vectors. If the degrees of freedom (df) in fitting the rotation is 0 or not given it is set to 10000. Blank lines and records whose first column contains # will be ignored. -e Alternatively, specify the longitude, latitude, and opening angle (all in degrees and separated by \/) for a single total reconstruction rotation that should be applied to all input points.","Process Name":"backtracker","Link":"https:\/\/linux.die.net\/man\/1\/backtracker"}},{"Process":{"Description":"Backupninja allows you to coordinate system backups by dropping a few simple configuration files into \/etc\/backup.d\/. Most programs you might use for making backups don't have their own configuration file format. Backupninja provides a centralized way to configure and coordinate many different backup utilities.","Process Name":"backupninja","Link":"https:\/\/linux.die.net\/man\/1\/backupninja"}},{"Process":{"Description":"This manual page documents briefly the bacula-tray-monitor command, a simple monitor for the 'system tray' in KDE\/GNOME","Process Name":"bacula-tray-monitor","Link":"https:\/\/linux.die.net\/man\/1\/bacula-tray-monitor"}},{"Process":{"Description":"bakefile creates various types of Makefiles and project files from a single project description called a \"Bakefile\".","Process Name":"bakefile","Link":"https:\/\/linux.die.net\/man\/1\/bakefile"}},{"Process":{"Description":"Calls bakefile with flags listed in description file (Bakefiles.bkgen or file specified using the --desc option).","Process Name":"bakefile_gen","Link":"https:\/\/linux.die.net\/man\/1\/bakefile_gen"}},{"Process":{"Description":"For the \"autoconf\" format, Bakefile creates Makefile.in files that depend on the availability of common pieces of a GNU build system. (config.guess, install-sh, etc.) These tools are part of Automake, which can copy these files into a project's directory during processing. bakefilize effectively replaces the automake --add-missing feature. It is standard practice in Autoconf-based projects to provide a \"bootstrap\" script (commonly called either bootstrap or autogen.sh) to run commands like autoconf with the proper flags and in the proper order. You should run bakefilize in that script, at some point before the configure script runs.","Process Name":"bakefilize","Link":"https:\/\/linux.die.net\/man\/1\/bakefilize"}},{"Process":{"Description":"Balance is a simple, generic \"userland\" TCP proxy, which allows simple round-robin load balancing and graceful failover between several destination servers. Balance supports IPv6 on the listening side which makes it a very useful tool for IPv6 migration of IPv4 only services and servers. Balance is available at http:\/\/balance.sourceforge.net. Definitions: A possible destination consisting of a host address and a port is called a \"channel\". A channel is member of a \"channel group\". Channels are numbered in a group starting with 0. Groups are numbered starting with 0, which is the initial default group. Balance accepts connections on the given port and forwards them to the supplied channels. At least one channel (in the default group) must be specified. If there are two or more channels specified in a group balance performs a simple round-robin load balancing between the channels. Balance allows the definition of further channel groups. The connection scheme works as follows: balance tries first to establish a connection to a channel in the first group (0), performing the standard round-robin load balancing scheme. If no channel in this group is available, balance proceeds with the next higher channel group. Groups are simply separated with a \"!\" at the command line at startup and can be controlled interactively with the \"group\" command. A \"%\" instead of a \"!\" as a group separator declares the previous group to be of type \"hash\". This means that instead of a round-robin algorithm, a hash distribution based on the client ip address is used to determine the destination channel. This allows connecting one client always to the same server (e.g. balancing http sessions to a single server). Hosts may be specified either by hostname or by IP address. Ports may be specified either by name (as listed in \/etc\/services) or numerically. If no port is specified in a destination, the destination port defaults to the source port that balance controls. Balance allows the specification of the maximum number of connections per channel. This parameter can be optionally added after the port specification separated by a colon (\":\"). If a maximum number of connections is specified a channel will only be used for this maximum number of simultaneous connections. A maxc value of 0 denotes an unlimited number of connections. This is the initial default value of a channel. The maximum number of groups and channels balance can handle is specified at compile time and is initially 16 channels in 16 groups. Failover to another destination (a \"channel\") occurs if the connection is refused on the current channel or if the connect timeout is reached trying to establish a connection. If all possible destinations (channels) currently fail, the client connection to balance is closed. Balance accepts the following options: a Enable autodisable option: A channel needs to be manually re-enabled after a failure. b Bindhost: Balance binds to the specified host (or address) for listen() instead to INADDR_ANY. B Bindhost: Balance binds to the specified host (or address) for outgoing connections (the connection will be initiated from this address). c Command: allows to send a command to the balance master process (see interactive mode) d Debug: Balance outputs debugging and tracing information messages on stderr. H Hashfailover: Balance does failover to next node even if hash is used. F Foreground: tells balance to stay in foreground. This might be useful for testing and debugging since balance can be stopped in that mode using ^C (or other interrupt character). M Use memory mapping for IPC instead of shared memory i Interactive Control: Balance connects to the running instance defined by local port and bind address via shared memory and allows to control the behaviour of it using a command line interface. The access permission using this interface are determined by the access restrictions of the shared memory segment in effect. help or \"?\" prints out a short command overview, create allows to establish a new destination definition (channel) consisting of host and port in the current group, disable disables a channel in the current group, enable enables a channel again in the current group, group changes the current group in interactive mode where all following commands are targeted, hash changes the current group to be of type \"Hash\", help prints out online help informations, kill shuts down the master process and exits interactive mode, maxc <channel> <maxc> sets the maximum number of connection ot the channel (0 means infinite), mrtg-bytes <group> <channel> prints out the bytes received\/sent in MRTG compatible format (intended to be called with -c automatically by MRTG), mrtg-conns <group> <channel> prints out the total connections in MRTG compatible format (intended to be called with -c automatically by MRTG), quit exits the interactive mode, reset resets the byte counters of a channel, rr changes the current group to be of type \"Round Robin\", show shows an overview and the status of all channels including the incoming and outgoing transfer volume in bytes. The output is sorted by groups. Additionally the current connections (c) and the maximum allowed connections (maxc) are printed, version prints out the version and MAXGROUPS and MAXCHANNELS constants at compile time. p Packetdump: Balance shows all incoming and outgoing data on stdout using a simple always readable external representation of data. This might be useful for debugging and protocol analysis. t Connect Timeout: the default timeout trying to establish a connection to any destination can be changed using this option. The default timeout after which a destination is regarded to be currently inaccessible is 5 seconds. T Select Timeout: Timeout for select(), default = 0 (never). This feature is currently untested.","Process Name":"balance","Link":"https:\/\/linux.die.net\/man\/1\/balance"}},{"Process":{"Description":"baobab is able to scan either specific folders or the whole filesystem (local and remote), in order to give the user a graphical tree representation including each directory size or percentage in the branch. It also auto-detects in real-time any change made to your home directory as far as any mounted\/unmounted device. A graphical treemap window is also provided for any selected folder. A detailed documentation on the program could be read at: http:\/\/www.gnome.org\/projects\/baobab","Process Name":"baobab","Link":"https:\/\/linux.die.net\/man\/1\/baobab"}},{"Process":{"Description":"Bar is a simple tool to process a stream of data and print a display for the user on stderr showing (a) the amount of data passed, (b) the throughput of the data transfer, and, if the total size of the data stream is known, (c) estimated time remaining, percent complete, and a progress bar. Bar was originally written for the purpose of estimating the amount of time needed to transfer large amounts (many, many gigabytes) of data across a network. (Usually in an SSH\/tar pipe.)","Process Name":"bar","Link":"https:\/\/linux.die.net\/man\/1\/bar"}},{"Process":{"Description":"The information below is extracted from the texinfo file, which is the preferred source of information. The barcode program is a front-end to access some features of the library from the command line. It is able to read user supplied strings from the command line or a data file (standard input by default) and encode all of them.","Process Name":"barcode","Link":"https:\/\/linux.die.net\/man\/1\/barcode"}},{"Process":{"Description":"Base64 encode or decode FILE, or standard input, to standard output. -w, --wrap= COLS Wrap encoded lines after COLS character (default 76). Use 0 to disable line wrapping. -d, --decode Decode data. -i, --ignore-garbage When decoding, ignore non-alphabet characters. --help display this help and exit --version output version information and exit With no FILE, or when FILE is -, read standard input. The data are encoded as described for the base64 alphabet in RFC 3548. When decoding, the input may contain newlines in addition to the bytes of the formal base64 alphabet. Use --ignore-garbage to attempt to recover from any other non-alphabet bytes in the encoded stream.","Process Name":"base64","Link":"https:\/\/linux.die.net\/man\/1\/base64"}},{"Process":{"Description":"This program can either encode a file with Base64 encoding suited for inclusion of binary data into text files such as XML files and decode Base64 encoded data back into its original form. The first argument controls whether base64tool will encode or decode. The second argument is name of the file that data is read from. The third argument is the name of the file that output is written to. The file will be overwritten if it exists. When encoding an optional fourth parameter, maxlen, specifies the maximum line length to output. It defaults to 72 if left out.","Process Name":"base64tool","Link":"https:\/\/linux.die.net\/man\/1\/base64tool"}},{"Process":{"Description":"Print NAME with any leading directory components removed. If specified, also remove a trailing SUFFIX. --help display this help and exit --version output version information and exit","Process Name":"basename","Link":"https:\/\/linux.die.net\/man\/1\/basename"}},{"Process":{"Description":"This program uses your configuration's \"installprivlib\" directory to look up the full paths to those pod pages. Any files in that directory whose names end in \".pod\" will be printed to the standard output, one per line. This is normally used in backticks to produce a list of filenames for other commands.","Process Name":"basepods","Link":"https:\/\/linux.die.net\/man\/1\/basepods"}},{"Process":{"Description":"Bash is an sh-compatible command language interpreter that executes commands read from the standard input or from a file. Bash also incorporates useful features from the Korn and C shells (ksh and csh). Bash is intended to be a conformant implementation of the Shell and Utilities portion of the IEEE POSIX specification (IEEE Standard 1003.1). Bash can be configured to be POSIX-conformant by default.","Process Name":"bash","Link":"https:\/\/linux.die.net\/man\/1\/bash"}},{"Process":{"Description":"bashbug is a shell script to help the user compose and mail bug reports concerning bash in a standard format. bashbug invokes the editor specified by the environment variable EDITOR on a temporary copy of the bug report format outline. The user must fill in the appropriate fields and exit the editor. bashbug then mails the completed report to bug-bash@gnu.org, or email-address. If the report cannot be mailed, it is saved in the file dead.bashbug in the invoking user's home directory. The bug report format outline consists of several sections. The first section provides information about the machine, operating system, the bash version, and the compilation environment. The second section should be filled in with a description of the bug. The third section should be a description of how to reproduce the bug. The optional fourth section is for a proposed fix. Fixes are encouraged.","Process Name":"bashbug","Link":"https:\/\/linux.die.net\/man\/1\/bashbug"}},{"Process":{"Description":"The pvf tools are a collection of tools to convert vgetty modem data to and from the 'raw modem data' format, and from that to and from various audio file formats (like .au or .wav). In addition, there are some tools to manipulate pvf files, like speed up files or cut off trailing noise. A list of commands is below in the \"see also\" section. You can run those commands with the -h switch for available options. Please also look at the individual contributed man pages.","Process Name":"basictopvf","Link":"https:\/\/linux.die.net\/man\/1\/basictopvf"}},{"Process":{"Description":"Basilisk II is a free, portable 68k Mac emulator. For more information, see the included \"README\" file.","Process Name":"basiliskii","Link":"https:\/\/linux.die.net\/man\/1\/basiliskii"}},{"Process":{"Description":"This manual page documents briefly the bat command, the Qt4 version of the Bacula Administration Tool console. This is a GUI full featured program similar the bconsole program, but it is graphical oriented and more features.","Process Name":"bat","Link":"https:\/\/linux.die.net\/man\/1\/bat"}},{"Process":{"Description":"at and batch read commands from standard input or a specified file which are to be executed at a later time. at executes commands at a specified time. atq lists the user's pending jobs, unless the user is the superuser; in that case, everybody's jobs are listed. The format of the output lines (one for each job) is: Job number, date, hour, queue, and username. atrm deletes jobs, identified by their job number. batch executes commands when system load levels permit; in other words, when the load average drops below 0.8, or the value specified in the invocation of atd. At allows fairly complex time specifications, extending the POSIX.2 standard. It accepts times of the form HH:MM to run a job at a specific time of day. (If that time is already past, the next day is assumed.) You may also specify midnight, noon, or teatime (4pm) and you can have a time-of-day suffixed with AM or PM for running in the morning or the evening. You can also say what day the job will be run, by giving a date in the form month-name day with an optional year, or giving a date of the form MMDDYY or MM\/DD\/YY or DD.MM.YY or YYYY-MM-DD. The specification of a date must follow the specification of the time of day. You can also give times like now + count time-units, where the time-units can be minutes, hours, days, or weeks and you can tell at to run the job today by suffixing the time with today and to run the job tomorrow by suffixing the time with tomorrow. For example, to run a job at 4pm three days from now, you would do at 4pm + 3 days, to run a job at 10:00am on July 31, you would do at 10am Jul 31 and to run a job at 1am tomorrow, you would do at 1am tomorrow. The exact definition of the time specification can be found in \/usr\/share\/doc\/at-3.1.10\/timespec. For both at and batch, commands are read from standard input or the file specified with the -f option and executed. The working directory, the environment (except for the variables TERM, DISPLAY and _) and the umask are retained from the time of invocation. An at - or batch - command invoked from a su(1) shell will retain the current userid. The user will be mailed standard error and standard output from his commands, if any. Mail will be sent using the command \/usr\/sbin\/sendmail. If at is executed from a su(1) shell, the owner of the login shell will receive the mail. The superuser may use these commands in any case. For other users, permission to use at is determined by the files \/etc\/at.allow and \/etc\/at.deny. If the file \/etc\/at.allow exists, only usernames mentioned in it are allowed to use at. If \/etc\/at.allow does not exist, \/etc\/at.deny is checked, every username not mentioned in it is then allowed to use at. If neither exists, only the superuser is allowed use of at. An empty \/etc\/at.deny means that every user is allowed use these commands, this is the default configuration.","Process Name":"batch","Link":"https:\/\/linux.die.net\/man\/1\/batch"}},{"Process":{"Description":"The area defined by the rectangle left, top, width, height is cropped out of each of the images and saved in a file of the same name, but prefixed by \"crop_\". For example: batch_crop 10 10 100 100 fred.jpg jim.png will make two images, crop_fred.jpg and crop_jim.png, each of 100 by 100 pixels, taken from the corresponding input images.","Process Name":"batch_crop","Link":"https:\/\/linux.die.net\/man\/1\/batch_crop"}},{"Process":{"Description":"The first argument is the name of an image type, subsequent arguments are the names of files to be converted to that type. VIPS can usually read almost any image type, but it can only write VIPS, PNG, TIFF, PPM\/PGM\/PBM and JPEG. You can specify conversion parameters in the type name. For example: batch_image_convert tiff fred.jpg jim.png will convert fred.jpg and jim.png to TIFF format. batch_image_convert jpeg:95 jim.png will write jim.jpeg with a 95% quality factor.","Process Name":"batch_image_convert","Link":"https:\/\/linux.die.net\/man\/1\/batch_image_convert"}},{"Process":{"Description":"The first argument specifies a file containing the transformation, subsequent arguments are image files to be transformed. The transformed image is written to a new file, named as the old file, but with \"rsc_\" prepended to the file name. For example: batch_rubber_sheet lens.mat fred.jpg jim.png will read a transform from the file lens.mat and apply it to fred.jpg and jim.png, writing files rsc_fred.jpg and rsc_jim.png.","Process Name":"batch_rubber_sheet","Link":"https:\/\/linux.die.net\/man\/1\/batch_rubber_sheet"}},{"Process":{"Description":"bbe is a sed-like editor for binary files. It performs binary transformations on the blocks of input stream.","Process Name":"bbe","Link":"https:\/\/linux.die.net\/man\/1\/bbe"}},{"Process":{"Description":"bbkeys is the keygrabber for the blackbox window manager. bbkeys handles all keybindings and keyboard shortcuts for blackbox. It uses blackbox's Image classes for rendering its look and feel so that bbkeys will render itself to match whatever blackbox style is used. It is highly configurable either via the bbconf GUI utility or the (now deprecated) bbkeysconf GUI utility or by hand-editting bbkeys's config file.","Process Name":"bbkeys","Link":"https:\/\/linux.die.net\/man\/1\/bbkeys"}},{"Process":{"Description":"bbox reads a rawppm or rawpbm file and prints out the bounding box of the image (as postscript comment and in postscript points, i.e. 1\/72dpi) as well as the high resolution bounding box. Input is read from standard input if no filename is specified. Example output:       %%BoundingBox: 12 253 829 837\n      %%HiResBoundingBox: 12.500000 253.000000 828.500000 837.00000\n   bbox has only very limited memory requirements as it reads the input line by line and thus needs to store only one picture line in memory.","Process Name":"bbox","Link":"https:\/\/linux.die.net\/man\/1\/bbox"}},{"Process":{"Description":"bc is a language that supports arbitrary precision numbers with interactive execution of statements. There are some similarities in the syntax to the C programming language. A standard math library is available by command line option. If requested, the math library is defined before processing any files. bc starts by processing code from all the files listed on the command line in the order listed. After all files have been processed, bc reads from the standard input. All code is executed as it is read. (If a file contains a command to halt the processor, bc will never read from the standard input.) This version of bc contains several extensions beyond traditional bc implementations and the POSIX draft standard. Command line options can cause these extensions to print a warning or to be rejected. This document describes the language accepted by this processor. Extensions will be identified as such. Options -h, --help Print the usage and exit. -i, --interactive Force interactive mode. -l, --mathlib Define the standard math library. -w, --warn Give warnings for extensions to POSIX bc. -s, --standard Process exactly the POSIX bc language. -q, --quiet Do not print the normal GNU bc welcome. -v, --version Print the version number and copyright and quit. Numbers The most basic element in bc is the number. Numbers are arbitrary precision numbers. This precision is both in the integer part and the fractional part. All numbers are represented internally in decimal and all computation is done in decimal. (This version truncates results from divide and multiply operations.) There are two attributes of numbers, the length and the scale. The length is the total number of significant decimal digits in a number and the scale is the total number of decimal digits after the decimal point. For example: .000001 has a length of 6 and scale of 6.\n1935.000 has a length of 7 and a scale of 3. Variables Numbers are stored in two types of variables, simple variables and arrays. Both simple variables and array variables are named. Names begin with a letter followed by any number of letters, digits and underscores. All letters must be lower case. (Full alpha-numeric names are an extension. In POSIX bc all names are a single lower case letter.) The type of variable is clear by the context because all array variable names will be followed by brackets ([]). There are four special variables, scale, ibase, obase, and last. scale defines how some operations use digits after the decimal point. The default value of scale is 0. ibase and obase define the conversion base for input and output numbers. The default for both input and output is base 10. last (an extension) is a variable that has the value of the last printed number. These will be discussed in further detail where appropriate. All of these variables may have values assigned to them as well as used in expressions. Comments Comments in bc start with the characters \/* and end with the characters *\/. Comments may start anywhere and appear as a single space in the input. (This causes comments to delimit other input items. For example, a comment can not be found in the middle of a variable name.) Comments include any newlines (end of line) between the start and the end of the comment. To support the use of scripts for bc, a single line comment has been added as an extension. A single line comment starts at a # character and continues to the next end of the line. The end of line character is not part of the comment and is processed normally. Expressions The numbers are manipulated by expressions and statements. Since the language was designed to be interactive, statements and expressions are executed as soon as possible. There is no \"main\" program. Instead, code is executed as it is encountered. (Functions, discussed in detail later, are defined when encountered.) A simple expression is just a constant. bc converts constants into internal decimal numbers using the current input base, specified by the variable ibase. (There is an exception in functions.) The legal values of ibase are 2 through 16. Assigning a value outside this range to ibase will result in a value of 2 or 16. Input numbers may contain the characters 0-9 and A-F. (Note: They must be capitals. Lower case letters are variable names.) Single digit numbers always have the value of the digit regardless of the value of ibase. (i.e. A = 10.) For multi-digit numbers, bc changes all input digits greater or equal to ibase to the value of ibase-1. This makes the number FFF always be the largest 3 digit number of the input base. Full expressions are similar to many other high level languages. Since there is only one kind of number, there are no rules for mixing types. Instead, there are rules on the scale of expressions. Every expression has a scale. This is derived from the scale of original numbers, the operation performed and in many cases, the value of the variable scale. Legal values of the variable scale are 0 to the maximum number representable by a C integer. In the following descriptions of legal expressions, \"expr\" refers to a complete expression and \"var\" refers to a simple or an array variable. A simple variable is just a name and an array variable is specified as name[ expr] Unless specifically mentioned the scale of the result is the maximum scale of the expressions involved. - expr The result is the negation of the expression. ++ var The variable is incremented by one and the new value is the result of the expression. -- var The variable is decremented by one and the new value is the result of the expression. var ++ The result of the expression is the value of the variable and then the variable is incremented by one. var -- The result of the expression is the value of the variable and then the variable is decremented by one. expr + expr The result of the expression is the sum of the two expressions. expr - expr The result of the expression is the difference of the two expressions. expr * expr The result of the expression is the product of the two expressions. expr \/ expr The result of the expression is the quotient of the two expressions. The scale of the result is the value of the variable scale. expr % expr The result of the expression is the \"remainder\" and it is computed in the following way. To compute a%b, first a\/b is computed to scale digits. That result is used to compute a-(a\/b)*b to the scale of the maximum of scale+ scale(b) and scale(a). If scale is set to zero and both expressions are integers this expression is the integer remainder function. expr ^ expr The result of the expression is the value of the first raised to the second. The second expression must be an integer. (If the second expression is not an integer, a warning is generated and the expression is truncated to get an integer value.) The scale of the result is scale if the exponent is negative. If the exponent is positive the scale of the result is the minimum of the scale of the first expression times the value of the exponent and the maximum of scale and the scale of the first expression. (e.g. scale(a^b) = min( scale(a)*b, max( scale, scale(a))).) It should be noted that expr^0 will always return the value of 1. ( expr ) This alters the standard precedence to force the evaluation of the expression. var = expr The variable is assigned the value of the expression. var <op>= expr This is equivalent to \"var = var <op> expr\" with the exception that the \"var\" part is evaluated only once. This can make a difference if \"var\" is an array. Relational expressions are a special kind of expression that always evaluate to 0 or 1, 0 if the relation is false and 1 if the relation is true. These may appear in any legal expression. (POSIX bc requires that relational expressions are used only in if, while, and for statements and that only one relational test may be done in them.) The relational operators are expr1 < expr2 The result is 1 if expr1 is strictly less than expr2. expr1 <= expr2 The result is 1 if expr1 is less than or equal to expr2. expr1 > expr2 The result is 1 if expr1 is strictly greater than expr2. expr1 >= expr2 The result is 1 if expr1 is greater than or equal to expr2. expr1 == expr2 The result is 1 if expr1 is equal to expr2. expr1 != expr2 The result is 1 if expr1 is not equal to expr2. Boolean operations are also legal. (POSIX bc does NOT have boolean operations). The result of all boolean operations are 0 and 1 (for false and true) as in relational expressions. The boolean operators are: !expr The result is 1 if expr is 0. expr && expr The result is 1 if both expressions are non-zero. expr || expr The result is 1 if either expression is non-zero. The expression precedence is as follows: (lowest to highest) || operator, left associative\n&& operator, left associative\n! operator, nonassociative\nRelational operators, left associative\nAssignment operator, right associative\n+ and - operators, left associative\n*, \/ and % operators, left associative\n^ operator, right associative\nunary - operator, nonassociative\n++ and -- operators, nonassociative This precedence was chosen so that POSIX compliant bc programs will run correctly. This will cause the use of the relational and logical operators to have some unusual behavior when used with assignment expressions. Consider the expression: a = 3 < 5 Most C programmers would assume this would assign the result of \"3 < 5\" (the value 1) to the variable \"a\". What this does in bc is assign the value 3 to the variable \"a\" and then compare 3 to 5. It is best to use parenthesis when using relational and logical operators with the assignment operators. There are a few more special expressions that are provided in bc. These have to do with user defined functions and standard functions. They all appear as \"name(parameters)\". See the section on functions for user defined functions. The standard functions are: length ( expression ) The value of the length function is the number of significant digits in the expression. read ( ) The read function (an extension) will read a number from the standard input, regardless of where the function occurs. Beware, this can cause problems with the mixing of data and program in the standard input. The best use for this function is in a previously written program that needs input from the user, but never allows program code to be input from the user. The value of the read function is the number read from the standard input using the current value of the variable ibase for the conversion base. scale ( expression ) The value of the scale function is the number of digits after the decimal point in the expression. sqrt ( expression ) The value of the sqrt function is the square root of the expression. If the expression is negative, a run time error is generated. Statements Statements (as in most algebraic languages) provide the sequencing of expression evaluation. In bc statements are executed \"as soon as possible.\" Execution happens when a newline in encountered and there is one or more complete statements. Due to this immediate execution, newlines are very important in bc. In fact, both a semicolon and a newline are used as statement separators. An improperly placed newline will cause a syntax error. Because newlines are statement separators, it is possible to hide a newline by using the backslash character. The sequence \"\\<nl>\", where <nl> is the newline appears to bc as whitespace instead of a newline. A statement list is a series of statements separated by semicolons and newlines. The following is a list of bc statements and what they do: (Things enclosed in brackets ([]) are optional parts of the statement.) expression This statement does one of two things. If the expression starts with \"<variable> <assignment> ...\", it is considered to be an assignment statement. If the expression is not an assignment statement, the expression is evaluated and printed to the output. After the number is printed, a newline is printed. For example, \"a=1\" is an assignment statement and \"(a=1)\" is an expression that has an embedded assignment. All numbers that are printed are printed in the base specified by the variable obase. The legal values for obase are 2 through BC_BASE_MAX. (See the section LIMITS.) For bases 2 through 16, the usual method of writing numbers is used. For bases greater than 16, bc uses a multi-character digit method of printing the numbers where each higher base digit is printed as a base 10 number. The multi-character digits are separated by spaces. Each digit contains the number of characters required to represent the base ten value of \"obase-1\". Since numbers are of arbitrary precision, some numbers may not be printable on a single output line. These long numbers will be split across lines using the \"\\\" as the last character on a line. The maximum number of characters printed per line is 70. Due to the interactive nature of bc, printing a number causes the side effect of assigning the printed value to the special variable last. This allows the user to recover the last value printed without having to retype the expression that printed the number. Assigning to last is legal and will overwrite the last printed value with the assigned value. The newly assigned value will remain until the next number is printed or another value is assigned to last. (Some installations may allow the use of a single period (.) which is not part of a number as a short hand notation for for last.) string The string is printed to the output. Strings start with a double quote character and contain all characters until the next double quote character. All characters are take literally, including any newline. No newline character is printed after the string. print list The print statement (an extension) provides another method of output. The \"list\" is a list of strings and expressions separated by commas. Each string or expression is printed in the order of the list. No terminating newline is printed. Expressions are evaluated and their value is printed and assigned to the variable last. Strings in the print statement are printed to the output and may contain special characters. Special characters start with the backslash character (\\). The special characters recognized by bc are \"a\" (alert or bell), \"b\" (backspace), \"f\" (form feed), \"n\" (newline), \"r\" (carriage return), \"q\" (double quote), \"t\" (tab), and \"\\\" (backslash). Any other character following the backslash will be ignored. { statement_list } This is the compound statement. It allows multiple statements to be grouped together for execution. if ( expression ) statement1 [ else statement2] The if statement evaluates the expression and executes statement1 or statement2 depending on the value of the expression. If the expression is non-zero, statement1 is executed. If statement2 is present and the value of the expression is 0, then statement2 is executed. (The else clause is an extension.) while ( expression ) statement The while statement will execute the statement while the expression is non-zero. It evaluates the expression before each execution of the statement. Termination of the loop is caused by a zero expression value or the execution of a break statement. for ( [expression1] ; [expression2] ; [expression3] ) statement The for statement controls repeated execution of the statement. Expression1 is evaluated before the loop. Expression2 is evaluated before each execution of the statement. If it is non-zero, the statement is evaluated. If it is zero, the loop is terminated. After each execution of the statement, expression3 is evaluated before the reevaluation of expression2. If expression1 or expression3 are missing, nothing is evaluated at the point they would be evaluated. If expression2 is missing, it is the same as substituting the value 1 for expression2. (The optional expressions are an extension. POSIX bc requires all three expressions.) The following is equivalent code for the for statement: expression1;\nwhile (expression2) {\n   statement;\n   expression3;\n} break This statement causes a forced exit of the most recent enclosing while statement or for statement. continue The continue statement (an extension) causes the most recent enclosing for statement to start the next iteration. halt The halt statement (an extension) is an executed statement that causes the bc processor to quit only when it is executed. For example, \"if (0 == 1) halt\" will not cause bc to terminate because the halt is not executed. return Return the value 0 from a function. (See the section on functions.) return ( expression ) Return the value of the expression from a function. (See the section on functions.) As an extension, the parenthesis are not required. Pseudo Statements These statements are not statements in the traditional sense. They are not executed statements. Their function is performed at \"compile\" time. limits Print the local limits enforced by the local version of bc. This is an extension. quit When the quit statement is read, the bc processor is terminated, regardless of where the quit statement is found. For example, \"if (0 == 1) quit\" will cause bc to terminate. warranty Print a longer warranty notice. This is an extension. Functions Functions provide a method of defining a computation that can be executed later. Functions in bc always compute a value and return it to the caller. Function definitions are \"dynamic\" in the sense that a function is undefined until a definition is encountered in the input. That definition is then used until another definition function for the same name is encountered. The new definition then replaces the older definition. A function is defined as follows: define name ( parameters ) { newline\n    auto_list   statement_list } A function call is just an expression of the form \" name(parameters)\". Parameters are numbers or arrays (an extension). In the function definition, zero or more parameters are defined by listing their names separated by commas. All parameters are call by value parameters. Arrays are specified in the parameter definition by the notation \"name[]\". In the function call, actual parameters are full expressions for number parameters. The same notation is used for passing arrays as for defining array parameters. The named array is passed by value to the function. Since function definitions are dynamic, parameter numbers and types are checked when a function is called. Any mismatch in number or types of parameters will cause a runtime error. A runtime error will also occur for the call to an undefined function. The auto_list is an optional list of variables that are for \"local\" use. The syntax of the auto list (if present) is \"auto name, ... ;\". (The semicolon is optional.) Each name is the name of an auto variable. Arrays may be specified by using the same notation as used in parameters. These variables have their values pushed onto a stack at the start of the function. The variables are then initialized to zero and used throughout the execution of the function. At function exit, these variables are popped so that the original value (at the time of the function call) of these variables are restored. The parameters are really auto variables that are initialized to a value provided in the function call. Auto variables are different than traditional local variables because if function A calls function B, B may access function A's auto variables by just using the same name, unless function B has called them auto variables. Due to the fact that auto variables and parameters are pushed onto a stack, bc supports recursive functions. The function body is a list of bc statements. Again, statements are separated by semicolons or newlines. Return statements cause the termination of a function and the return of a value. There are two versions of the return statement. The first form, \"return\", returns the value 0 to the calling expression. The second form, \"return ( expression )\", computes the value of the expression and returns that value to the calling expression. There is an implied \"return (0)\" at the end of every function. This allows a function to terminate and return 0 without an explicit return statement. Functions also change the usage of the variable ibase. All constants in the function body will be converted using the value of ibase at the time of the function call. Changes of ibase will be ignored during the execution of the function except for the standard function read, which will always use the current value of ibase for conversion of numbers. Several extensions have been added to functions. First, the format of the definition has been slightly relaxed. The standard requires the opening brace be on the same line as the define keyword and all other parts must be on following lines. This version of bc will allow any number of newlines before and after the opening brace of the function. For example, the following definitions are legal. CW\ndefine d (n) { return (2*n); }\ndefine d (n)\n  { return (2*n); } Functions may be defined as void. A void funtion returns no value and thus may not be used in any place that needs a value. A void function does not produce any output when called by itself on an input line. The key word void is placed between the key word define and the function name. For example, consider the following session. CW\ndefine py (y) { print \"--->\", y, \"<---\", \"0; }\ndefine void px (x) { print \"--->\", x, \"<---\", \"0; }\npy(1)\n--->1<---\n0\npx(1)\n--->1<--- Since py is not a void function, the call of py(1) prints the desired output and then prints a second line that is the value of the function. Since the value of a function that is not given an explicit return statement is zero, the zero is printed. For px(1), no zero is printed because the function is a void function. Also, call by variable for arrays was added. To declare a call by variable array, the declaration of the array parameter in the function definition looks like \"*name[]\". The call to the function remains the same as call by value arrays. Math Library If bc is invoked with the -l option, a math library is preloaded and the default scale is set to 20. The math functions will calculate their results to the scale set at the time of their call. The math library defines the following functions: s ( x) The sine of x, x is in radians. c ( x) The cosine of x, x is in radians. a ( x) The arctangent of x, arctangent returns radians. l ( x) The natural logarithm of x. e ( x) The exponential function of raising e to the value x. j ( n,x) The Bessel function of integer order n of x. Examples In \/bin\/sh, the following will assign the value of \"pi\" to the shell variable pi. CW pi=$(echo \"scale=10; 4* a(1)\" | bc -l) The following is the definition of the exponential function used in the math library. This function is written in POSIX bc. CW\nscale = 20\n\/* Uses the fact that e^x = (e^(x\/2))^2\n   When x is small enough, we use the series:\n     e^x = 1 + x + x^2\/2! + x^3\/3! + ...\n*\/\ndefine e(x) {\n  auto  a, d, e, f, i, m, v, z\n  \/* Check the sign of x. *\/\n  if (x<0) {\n    m = 1\n    x = -x\n  }\n  \/* Precondition x. *\/\n  z = scale;\n  scale = 4 + z + .44*x;\n  while (x > 1) {\n    f += 1;\n    x \/= 2;\n  }\n  \/* Initialize the variables. *\/\n  v = 1+x\n  a = x\n  d = 1\n  for (i=2; 1; i++) {\n    e = (a *= x) \/ (d *= i)\n    if (e == 0) {\n      if (f>0) while (f--)  v = v*v;\n      scale = z\n      if (m) return (1\/v);\n      return (v\/1);\n    }\n    v += e\n  }\n} The following is code that uses the extended features of bc to implement a simple program for calculating checkbook balances. This program is best kept in a file so that it can be used many times without having to retype it at every use. CW\nscale=2\nprint \"\\nCheck book program!\\n\"\nprint \"  Remember, deposits are negative transactions.\\n\"\nprint \"  Exit by a 0 transaction.\\n\\n\"\nprint \"Initial balance? \"; bal = read()\nbal \/= 1\nprint \"\\n\"\nwhile (1) {\n  \"current balance = \"; bal\n  \"transaction? \"; trans = read()\n  if (trans == 0) break;\n  bal -= trans\n  bal \/= 1\n}\nquit The following is the definition of the recursive factorial function. CW\ndefine f (x) {\n  if (x <= 1) return (1);\n  return (f(x-1) * x);\n} Readline and Libedit Options GNU bc can be compiled (via a configure option) to use the GNU readline input editor library or the BSD libedit library. This allows the user to do editing of lines before sending them to bc. It also allows for a history of previous lines typed. When this option is selected, bc has one more special variable. This special variable, history is the number of lines of history retained. For readline, a value of -1 means that an unlimited number of history lines are retained. Setting the value of history to a positive number restricts the number of history lines to the number given. The value of 0 disables the history feature. The default value is 100. For more information, read the user manuals for the GNU readline, history and BSD libedit libraries. One can not enable both readline and libedit at the same time. Differences This version of bc was implemented from the POSIX P1003.2\/D11 draft and contains several differences and extensions relative to the draft and traditional implementations. It is not implemented in the traditional way using dc(1). This version is a single process which parses and runs a byte code translation of the program. There is an \"undocumented\" option (-c) that causes the program to output the byte code to the standard output instead of running it. It was mainly used for debugging the parser and preparing the math library. A major source of differences is extensions, where a feature is extended to add more functionality and additions, where new features are added. The following is the list of differences and extensions. LANG environment This version does not conform to the POSIX standard in the processing of the LANG environment variable and all environment variables starting with LC_. names Traditional and POSIX bc have single letter names for functions, variables and arrays. They have been extended to be multi-character names that start with a letter and may contain letters, numbers and the underscore character. Strings Strings are not allowed to contain NUL characters. POSIX says all characters must be included in strings. last POSIX bc does not have a last variable. Some implementations of bc use the period (.) in a similar way. comparisons POSIX bc allows comparisons only in the if statement, the while statement, and the second expression of the for statement. Also, only one relational operation is allowed in each of those statements. if statement, else clause POSIX bc does not have an else clause. for statement POSIX bc requires all expressions to be present in the for statement. &&, ||, ! POSIX bc does not have the logical operators. read function POSIX bc does not have a read function. print statement POSIX bc does not have a print statement . continue statement POSIX bc does not have a continue statement. return statement POSIX bc requires parentheses around the return expression. array parameters POSIX bc does not (currently) support array parameters in full. The POSIX grammar allows for arrays in function definitions, but does not provide a method to specify an array as an actual parameter. (This is most likely an oversight in the grammar.) Traditional implementations of bc have only call by value array parameters. function format POSIX bc requires the opening brace on the same line as the define key word and the auto statement on the next line. =+, =-, =*, =\/, =%, =^ POSIX bc does not require these \"old style\" assignment operators to be defined. This version may allow these \"old style\" assignments. Use the limits statement to see if the installed version supports them. If it does support the \"old style\" assignment operators, the statement \"a =- 1\" will decrement a by 1 instead of setting a to the value -1. spaces in numbers Other implementations of bc allow spaces in numbers. For example, \"x=1 3\" would assign the value 13 to the variable x. The same statement would cause a syntax error in this version of bc. errors and execution This implementation varies from other implementations in terms of what code will be executed when syntax and other errors are found in the program. If a syntax error is found in a function definition, error recovery tries to find the beginning of a statement and continue to parse the function. Once a syntax error is found in the function, the function will not be callable and becomes undefined. Syntax errors in the interactive execution code will invalidate the current execution block. The execution block is terminated by an end of line that appears after a complete sequence of statements. For example, a = 1\nb = 2 has two execution blocks and { a = 1\n  b = 2 } has one execution block. Any runtime error will terminate the execution of the current execution block. A runtime warning will not terminate the current execution block. Interrupts During an interactive session, the SIGINT signal (usually generated by the control-C character from the terminal) will cause execution of the current execution block to be interrupted. It will display a \"runtime\" error indicating which function was interrupted. After all runtime structures have been cleaned up, a message will be printed to notify the user that bc is ready for more input. All previously defined functions remain defined and the value of all non-auto variables are the value at the point of interruption. All auto variables and function parameters are removed during the clean up process. During a non-interactive session, the SIGINT signal will terminate the entire run of bc. Limits The following are the limits currently in place for this bc processor. Some of them may have been changed by an installation. Use the limits statement to see the actual values. BC_BASE_MAX The maximum output base is currently set at 999. The maximum input base is 16. BC_DIM_MAX This is currently an arbitrary limit of 65535 as distributed. Your installation may be different. BC_SCALE_MAX The number of digits after the decimal point is limited to INT_MAX digits. Also, the number of digits before the decimal point is limited to INT_MAX digits. BC_STRING_MAX The limit on the number of characters in a string is INT_MAX characters. exponent The value of the exponent in the raise operation (^) is limited to LONG_MAX. variable names The current limit on the number of unique names is 32767 for each of simple variables, arrays and functions.","Process Name":"bc","Link":"https:\/\/linux.die.net\/man\/1\/bc"}},{"Process":{"Description":"Bcc is a simple C compiler that produces 8086 assembler, in addition compiler compile time options allow 80386 or 6809 versions. The compiler understands traditional K&R C with just the restriction that bit fields are mapped to one of the other integer types. The default operation is to produce an 8086 executable called a.out from the source file.","Process Name":"bcc","Link":"https:\/\/linux.die.net\/man\/1\/bcc"}},{"Process":{"Description":"bcfg2 Runs the Bcfg2 configuration process on the current host. This process consists of first fetching and executing probes, uploading probe results, fetching the client configuration, checking the current client state, attempting to install the desired configuration, and finally uploading statistics about the Bcfg2 execution and client state.","Process Name":"bcfg2","Link":"https:\/\/linux.die.net\/man\/1\/bcfg2"}},{"Process":{"Description":"bchunk converts a CD image in a \".bin \/ .cue\" format (sometimes \".raw \/ .cue\") to a set of .iso and .cdr tracks. The bin\/cue format is used by some non-Unix cd-writing software, but is not supported on most other cd-writing programs. image.bin is the raw cd image file. image.cue is the track index file containing track types and offsets. basename is used for the beginning part of the created track files. The produced .iso track contains an ISO file system, which can be mounted through a loop device on Linux systems, or written on a CD-R using cdrecord. The .cdr tracks are in the native CD audio format. They can be either written on a CD-R using cdrecord -audio, or converted to WAV (or any other sound format for that matter) using sox. It is advisable to edit the .cue file to either MODE2\/2352\/2048 or MODE2\/2352\/2324 depending on whether an ISO filesystem or a VCD is desired, respectively. The format itself does not contain this feature and in an ambiguous case it can only guess.","Process Name":"bchunk","Link":"https:\/\/linux.die.net\/man\/1\/bchunk"}},{"Process":{"Description":"bcomps decomposes graphs into their biconnected components, printing the components to standard output.","Process Name":"bcomps","Link":"https:\/\/linux.die.net\/man\/1\/bcomps"}},{"Process":{"Description":"bcrypt encrypts and decrypts files using the blowfish algorithm. Encrypted files will be saved with an extension of .bfe. Any files ending in .bfe will be assumed to be encrypted with bcrypt and will attempt to decrypt them. Any other input files will be encrypted. If more than one type of file is given, bcrypt will process all files which are the same as the first filetype given. By default, bcrypt will compress input files before encryption, remove input files after they are processed (assuming they are processed successfully) and overwrite input files with random data to prevent data recovery. Passphrases may be between 8 and 56 characters. Regardless of the passphrase size, the key is hashed internally to 448 bits - the largest keysize supported by the blowfish algorithm. However, it is still wise to use a strong passphrase.","Process Name":"bcrypt","Link":"https:\/\/linux.die.net\/man\/1\/bcrypt"}},{"Process":{"Description":"bdd is a library that enables to represent a boolean expression as a Multi Reduced Ordered Binary Decision Diagrams. viewbddallocinfo - displays memory informations. applybddnodenot - complements a bdd. applybddnodeterm - applies an operator on two bdd nodes. applybddnode - applies an operator on two bdd nodes. applybddnodeite - computes the IF-THEN-ELSE logical operation. applybddnodelist - applies an opertor to a bdd nodes list. addbddassoc - creates a new association variables. addbddnodeassoc - adds a bdd node in a variable association. delbddassoc - deletes a variable association. delbddnodeassoc - deletes a bdd node in a variable association. destroybddassoc - frees all the variable associations. viewbddassoc - displays variable associations. checkbddvar - checks the coherence of a variable. checkbddindex - checks the coherence of a bdd index. checkbddoper - ckecks the coherence of an operator. checkbddassoc - checks a variable association. checkbddmaxnode - checks if the max node reached. createbddcircuit - creates a bdd circuit. resetbddcircuit - resets a bdd circuit. destroybddcircuit - frees a bdd circuit. searchbddcircuitin - searches a specified input in a circuit. addbddcircuitin - adds a new input in a circuit. addbddcircuitaux - adds an auxialiary variable in a circuit. searchbddcircuitout - searches a specified output in a circuit. addbddcircuitout - adds a new output in a circuit. delbddcircuitout - deletes a specified output in a circuit. addbddcircuitabl - converts an abl to a bdd node. convertbddcircuitabl - converts a bdd node to an abl. convertbddcircuitsumabl - converts a bdd node to an abl. viewbddcircuit - displays a bdd circuit. cofactorbddnode - computes the generalized cofactor. restrictbddnode - substitutes a variable by zero or one. composebddnode - substitutes a variable by a bdd node. convertbddindexabl - converts a bdd index to an atomic abl. convertbddmuxabl - converts a bdd node to a multiplexor. convertbddnodeabl - converts a bdd node to an abl. convertbddnodesumabl - converts a bdd node to an abl. existbddnodeassocon - computes an existantial quantification. existbddnodeassocoff - computes an existantial quantification. garbagebddsystem - forces a bdd garbage collection. implybddnode - computes a bdd that implies a conjonction. intersectbddnode - tests for an intersection. markbddnode - marks a bdd node. unmarkbddnode - clears a marked bdd node. getbddnodenum - gets the number of nodes in a bdd. getbddnodesize - gets the number of nodes in a bdd. addbddnode - adds a new bdd node. addbddnodelist - adds a node in a chain_list. delbddnode - deletes a bdd node. delbddnodelist - deletes a list of bdd nodes. viewbddnode - displays a bdd node. incbddrefext - increments the number of external reference. incbddrefint - increments the number of internal reference. decbddrefext - decrements the number of external reference. decbddrefint - decrements the number of internal reference. setbddrefext - sets a node visible from outside. unsetbddrefext - sets a node invisible from outside. clearbddsystemrefint - clears all the internal references. clearbddsystemrefext - clears all the external references. clearbddsystemref - clears all the references. relprodbddnodeassoc - computes a relation product. reorderbddsystemsimple - reorders the bdd nodes. reorderbddsystemwindow - reorders the bdd nodes. reorderbddsystemtop - reorders the bdd nodes. reorderbddsystemdynamic - sets the dynamic reorder parameters. satisfybddnode - finds a satisfying path for a bdd. simpbddnodedcon - simplifies a bdd with don't cares on its on-set. simpbddnodedcoff - simplifies a bdd with don't cares on its off-set substbddnodeassoc - substitutes variables with bdd nodes. getbddnodesupport - gives the support of a bdd node. isbddvarinsupport - checks if a variable appears in a bdd node. createbddsystem - creates a bdd system. resetbddsystem - resets a bdd system. destroybddsystem - frees a bdd system. viewbddsystem - displays a bdd system. viewbddsysteminfo - displays statisticals informations. testbddcircuit - debbugs a bdd circuit. addbddvar - creates a new variable. addbddvarlast - creates a new variable. addbddvarfirst - creates a new variable. addbddvarbefore - creates a new variable. addbddvarafter - creates a new variable. sweepbddvar - sweeps all the unused nodes for a variable. swapbddvar - swaps two contigous variables. getbddvarbyindex - converts bdd index to a variable number. getbddvarindex - converts a variable number in a bdd index. getbddvarnode - gives the bdd node of a variable. getbddvarnodebyindex - gives the bdd node of a variable. addbddvarauxsingle - creates an auxiliary variable. addbddvarauxglobal - creates an auxiliary variable. libBdd101.a : allocbdduserfunc, allocbddheath, allocbddhnode, allocbddhoper, allocbddhnodetable, allocbddhopertable, allocbddblock, allocbddnodeblock, allocbddvartree, allocbddvarchild, allocbddvarnode, allocbddindexnode, allocbddvar, allocbddindex, allocbddassoc, allocbddassocnode, allocbddnamein, allocbddindexin, allocbddsystem, allocbddcircuit, viewbddallocinfo, applybddnodenot, applybddnodeterm, applybddnode, applybddnodeite, applybddnodelist, addbddassoc, addbddnodeassoc, delbddassoc, delbddnodeassoc, destroybddassoc, viewbddassoc, addbddblock, createbddblock, resetbddblock, destroybddblock, viewbddblock, checkbddvar, checkbddindex, checkbddoper, checkbddassoc, checkbddmaxnode, createbddcircuit, resetbddcircuit, destroybddcircuit, searchbddcircuitin, addbddcircuitin, addbddcircuitaux, searchbddcircuitout, addbddcircuitout, delbddcircuitout, addbddcircuitabl, convertbddcircuitabl, convertbddcircuitsumabl, viewbddcircuit, cofactorbddnode, restrictbddnode, composebddnode, convertbddindexabl, convertbddmuxabl, convertbddnodeabl, convertbddnodesumabl, existbddnodeassocon, existbddnodeassocoff, freebdduserfunc, freebddheath, freebddhnode, freebddhoper, freebddhnodetable, freebddhopertable, freebddblock, freebddnodeblock, freebddvartree, freebddvarchild, freebddvarnode, freebddindexnode, freebddvar, freebddindex, freebddassoc, freebddassocnode, freebddnamein, freebddindexin, freebddsystem, freebddcircuit, garbagebddsystem, getbddheathvar, getbddheath, delbddheath, setbddhnodefunc, getbddhnodesize, getbddhnodekey, getbddhnodeindex, checkbddhnode, createbddhnodetable, destroybddhnodetable, resetbddhnodetable, resizebddhnodetable, stretchbddhnodetable, addbddhnode, delbddhnode, viewbddhnode, viewbddhnodetable, viewbddindexnode, viewbddvarnode, setbddhoperfunc, getbddhopersize, getbddhoperkey, createbddhopertable, destroybddhopertable, resetbddhopertable, addbddhoper, searchbddhoper, viewbddhoper, viewbddhopertable, implybddnode, intersectbddnode, markbddnode, unmarkbddnode, getbddnodenum, getbddnodesize, addbddnode, addbddnodelist, delbddnode, delbddnodelist, viewbddnode, incbddrefext, incbddrefint, decbddrefext, decbddrefint, setbddrefext, unsetbddrefext, clearbddsystemrefint, clearbddsystemrefext, clearbddsystemref, relprodbddnodeassoc, reorderbddvartreewindow2, reorderbddvartreewindow3, reorderbddsystemsimple, reorderbddsystemwindow, reorderbddsystemtop, reorderbddsystemdynamic, resizebddvarchild, resizebddvarnode, resizebddvar, resizebddindexnode, resizebddindex, resizebddassocnode, resizebddnamein, resizebddindexin, satisfybddnode, simpbddnodedcon, simpbddnodedcoff, substbddnodeassoc, getbddnodesupport, isbddvarinsupport, createbddsystem, resetbddsystem, destroybddsystem, viewbddsystem, viewbddsysteminfo, testbddcircuit, addbdduserfunc, delbdduserfunc, execbdduserfunc, destroybdduserfunc, newbddvar, addbddvar, addbddvarlast, addbddvarfirst, addbddvarbefore, addbddvarafter, sweepbddvar, swapbddvar, getbddvarbyindex, getbddvarindex, getbddvarnode, getbddvarnodebyindex, addbddvarauxsingle, addbddvarauxglobal, searchbddvartree, deltabddvartree, shiftbddvartree, addbddvartree, swapbddvartree, createbddvartree, resetbddvartree, destroybddvartree, viewbddvartree.","Process Name":"bdd","Link":"https:\/\/linux.die.net\/man\/1\/bdd"}},{"Process":{"Description":"This script converts BDF-style X11 font files into a format that can be loaded by the GD module using the GD::Font->load() method. There are a number of ways to obtain BDF fonts. 1. The font is already present on your system. Some BDF fonts can be found in the standard X11R6 distribution. This script will automatically uncompress gzipped font files if their extension ends with .gz (the gunzip program must be on your path). 2. From a font server. The \"fstobdf\" utility, a standard X11 utility, will read a named font from the font server of your choice and return it in BDF format. You can pipe it to bdf2gdfont.pl: fstobdf -s fontserverhost:7100 -fn 8x16 | bdf2gdfont.pl > newfont.fnt Use xlsfonts to find out what fonts are available. Most fonts will have long names like -B&H-LucidaTypewriter-Bold-R-Normal-Sans-18-180-75-75-M-110-ISO8859-10. 3. Using the pcf2bdf utility. Some fonts are only available in PCF (compiled) format. To obtain these, you can either turn on a font server and follow recipe (2), or use TAGA Nayuta's pcf2bdf utility. This utility is available from http:\/\/www.tsg.ne.jp\/GANA\/S\/pcf2bdf\/ (page is in Japanese, but you can find the download link). Limitations This font converter only works with fixed-width fonts. If used with a TrueType or proportional font it will die with an error message.","Process Name":"bdf2gdfont.pl","Link":"https:\/\/linux.die.net\/man\/1\/bdf2gdfont.pl"}},{"Process":{"Description":"Bdftopcf is a font compiler for the X server and font server. Fonts in Portable Compiled Format can be read by any architecture, although the file is structured to allow one particular architecture to read them directly without reformatting. This allows fast reading on the appropriate machine, but the files are still portable (but read more slowly) on other machines.","Process Name":"bdftopcf","Link":"https:\/\/linux.die.net\/man\/1\/bdftopcf"}},{"Process":{"Description":"bdftruncate allows one to generate from an ISO10646-1 encoded BDF font other ISO10646-1 BDF fonts in which all characters above a threshold code value are stored unencoded. This is often desirable because the Xlib API and X11 protocol data structures used for representing font metric information are extremely inefficient when handling sparsely populated fonts.","Process Name":"bdftruncate","Link":"https:\/\/linux.die.net\/man\/1\/bdftruncate"}},{"Process":{"Description":"The bdii-update process obtains the LDIF by reading files found the ldif directory, running providers found in the provider directory and running plugins found in the plugin directory. The difference between providers and plugins is that providers return complete entries and plugins provide modifications to existing entries. The process can be run either as a daemon that periodically syncronizes an LDAP database or as a command that will print the result to stdout.","Process Name":"bdii-update","Link":"https:\/\/linux.die.net\/man\/1\/bdii-update"}},{"Process":{"Description":"Bdy is a filter used to find boundary curves in Geomview objects. The program reads a geomview object from standard input and prints the resultant vector object to standard output. Bdy finds the segments of the vector by first converting the given object into a polylist (See anytooff(1)). Then, it finds all edges used once and only once in the polylist and combines these edges into a vector object. The optional precision arguement specifies the maximum distance between vertices that are to be considered identical. By default, it is set to 0.0, indicating that the vertices must be numerically identical. It may sometimes be necessary to set it to a higher value to compensate for floating-point error. The vector object is always black.","Process Name":"bdy","Link":"https:\/\/linux.die.net\/man\/1\/bdy"}},{"Process":{"Description":"be allows commandline interaction with the Bugs Everywhere database in a project tree. To avoid bit-rotted documentation, we do not describe all available commands and options in this manpage. Run be help for accurate documentation. See the Bugs Everywhere Manual for more detailed documentation and tutorials.","Process Name":"be","Link":"https:\/\/linux.die.net\/man\/1\/be"}},{"Process":{"Description":"This manual page documents briefly the beanstalkd work-queue service. The beanstalk interface is generic, but was originally designed for reducing the latency of page views in high-volume web applications by running time-consuming tasks asynchronously.","Process Name":"beanstalkd","Link":"https:\/\/linux.die.net\/man\/1\/beanstalkd"}},{"Process":{"Description":"beep allows the user to control the pc-speaker with precision, allowing different sounds to indicate different events. While it can be run quite happily on the command line, it's intended place of residence is within shell\/perl scripts, notifying the user when something interesting occurs. Of course, it has no notion of what's interesting, but it's real good at that notifying part. All options have default values, meaning that just typing 'beep' will work. If an option is specified more than once on the command line, subsequent options override their predecessors. So 'beep -f 200 -f 300' will beep at 300Hz.","Process Name":"beep","Link":"https:\/\/linux.die.net\/man\/1\/beep"}},{"Process":{"Description":"BMP is an audio player","Process Name":"beep-media-player-2","Link":"https:\/\/linux.die.net\/man\/1\/beep-media-player-2"}},{"Process":{"Description":"beesu is a wrapper around su(1) and works with consolehelper(8) in Fedora to provide a graphical interface like gksu. beesu is dedicated to all the friends of honey bees!","Process Name":"beesu","Link":"https:\/\/linux.die.net\/man\/1\/beesu"}},{"Process":{"Description":"The beforelight program is a sample implementation of a screen saver for X servers supporting the MIT-SCREEN-SAVER extension.","Process Name":"beforelight","Link":"https:\/\/linux.die.net\/man\/1\/beforelight"}},{"Process":{"Description":"","Process Name":"begin","Link":"https:\/\/linux.die.net\/man\/1\/begin"}},{"Process":{"Description":"The beid-pkcs11-tool utility can be used from the command line to perform miscellaneous operations on the Belgium eID PKCS11 library, such as changing your PIN or testing the library.","Process Name":"beid-pkcs11-tool","Link":"https:\/\/linux.die.net\/man\/1\/beid-pkcs11-tool"}},{"Process":{"Description":"The beid-tool utility can be used from the command line to perform miscellaneous smart card operations such as getting the card ATR or listing the PC\/SC compliant smartcard readers that are installed.","Process Name":"beid-tool","Link":"https:\/\/linux.die.net\/man\/1\/beid-tool"}},{"Process":{"Description":"This manual page documents briefly the bez2mesh command. bez2mesh Dices a BEZ file to a list of MESHes, each diced NxN. If N negative, everts each patch.","Process Name":"bez2mesh","Link":"https:\/\/linux.die.net\/man\/1\/bez2mesh"}},{"Process":{"Description":"bf_compact creates a more compact bogofilter working directory with a dump\/load cycle and renames the previous bogofilter_directory to bogofilter_directory.old. Note: bf_compact cannot be used to process the current working directory, \".\", because that cannot be renamed. If no wordlist_file arguments are given, then bf_compact will use the configured set of wordlists, if the given bogofilter_directory is the same as the configured, or use all *.db files if it is a different directory.","Process Name":"bf_compact","Link":"https:\/\/linux.die.net\/man\/1\/bf_compact"}},{"Process":{"Description":"bf_copy copies a bogofilter working directory to another directory. Currently it copies the database files (*.db), related files (log.*), and DB_CONFIG (if present).","Process Name":"bf_copy","Link":"https:\/\/linux.die.net\/man\/1\/bf_copy"}},{"Process":{"Description":"bf_tar bundles a bogofilter working directory in tar format and copies it to standard output (your console, or where you redirect it, see EXAMPLES below).","Process Name":"bf_tar","Link":"https:\/\/linux.die.net\/man\/1\/bf_tar"}},{"Process":{"Description":"Most MPI users will probably not need to use the bfctl and sweep commands; see lamclean(1). This command is only installed if LAM\/MPI was configured with the --with-trillium switch. The bfctl command controls buffering parameters on any node. It must be called with an option: bfctl <node(s)> by itself has no function. sweep is used after an application program error or premature termination to remove all messages held in buffers. The total space that can be consumed by the buffer daemon's buffer pool is adjusted with the -s <space> option, where <space> is the maximum number of bytes in the buffer pool; the default is 2 Mbytes. The <space> parameter should not be less than MAXNMSGLEN (defined in <net.h>). In the event of an application program error or premature termination of an application process, unwanted messages often collect in the buffers. The user will need to \"sweep\" the buffers clean before running the application program again. bfctl -R <node(s)> will remove all messages from the internal buffer pool on the given nodes. sweep <nodes> is equivalent to bfctl -R <nodes>. Sweeping buffered messages can be done in a selective manner, removing all messages of a specific event. The event is specified by the -e option. Message Buffering The purpose of LAM network buffering is to receive, store, and forward messages to provide very loose synchronization for senders, to allow selective out-of-order synchronization for receivers and to facilitate debugging synchronization errors. Two communicating processes using network functions nsend(2) and nrecv(2) (or functions built upon these) have the option of using the network buffers or not. By default, they are used. The message is routed to the buffer daemon on each node along the path from the sender to the receiver. If the two processes are on different nodes, the buffer daemon on the sender's node is skipped. The receiver synchronizes by first sending a query to the local buffer daemon and then waiting for a message to arrive on the selected event. If the buffer daemon has a synchronizing message, it forwards it to the receiver immediately. Otherwise the buffer daemon forwards the message when it arrives. The sender blocks only if there is no appropriate buffer space available on the receiver's node and on all nodes in between. Bypassing Buffers Buffering is turned off by setting the NOBUF flag in the nh_flags field of the network message descriptor prior to calling nrecv(2) in the receiver and nsend(2) in the sender. The NOBUF flag must be used with care and caution. Setting the flag in one but not the other process may inhibit synchronization. Toggling the NOBUF flag in a stream of messages to same receiver on the same synchronization point (event and type, see nsend(2)), may cause messages to get out of order. Even without buffering the node-to-node links can hold one or more messages. Thus the sender will block when all the links on the path to the receiver's node are stuffed with messages. When the sender and receiver are on the same node, synchronization is strong and the sender will block until the receiver takes the message. The buffer daemon will refuse to receive any message for buffering if the current size of the buffer pool exceeds the upper size limit. It will resume receiving messages when space is cleared through forwarding messages to receivers or other nodes.","Process Name":"bfctl","Link":"https:\/\/linux.die.net\/man\/1\/bfctl"}},{"Process":{"Description":"addr2line translates addresses into file names and line numbers. Given an address in an executable or an offset in a section of a relocatable object, it uses the debugging information to figure out which file name and line number are associated with it. The executable or relocatable object to use is specified with the -e option. The default is the file a.out. The section in the relocatable object to use is specified with the -j option. addr2line has two modes of operation. In the first, hexadecimal addresses are specified on the command line, and addr2line displays the file name and line number for each address. In the second, addr2line reads hexadecimal addresses from standard input, and prints the file name and line number for each address on standard output. In this mode, addr2line may be used in a pipe to convert dynamically chosen addresses. The format of the output is FILENAME:LINENO . The file name and line number for each input address is printed on separate lines. If the -f option is used, then each FILENAME:LINENO line is preceded by FUNCTIONNAME which is the name of the function containing the address. If the -i option is used and the code at the given address is present there because of inlining by the compiler then the { FUNCTIONNAME } FILENAME:LINENO information for the inlining function will be displayed afterwards. This continues recursively until there is no more inlining to report. If the -a option is used then the output is prefixed by the input address. If the -p option is used then the output for each input address is displayed on one, possibly quite long, line. If -p is not used then the output is broken up into multiple lines, based on the paragraphs above. If the file name or function name can not be determined, addr2line will print two question marks in their place. If the line number can not be determined, addr2line will print 0.","Process Name":"bfin-linux-gnu-addr2line","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-addr2line"}},{"Process":{"Description":"The GNU ar program creates, modifies, and extracts from archives. An archive is a single file holding a collection of other files in a structure that makes it possible to retrieve the original individual files (called members of the archive). The original files' contents, mode (permissions), timestamp, owner, and group are preserved in the archive, and can be restored on extraction. GNU ar can maintain archives whose members have names of any length; however, depending on how ar is configured on your system, a limit on member-name length may be imposed for compatibility with archive formats maintained with other tools. If it exists, the limit is often 15 characters (typical of formats related to a.out) or 16 characters (typical of formats related to coff). ar is considered a binary utility because archives of this sort are most often used as libraries holding commonly needed subroutines. ar creates an index to the symbols defined in relocatable object modules in the archive when you specify the modifier s. Once created, this index is updated in the archive whenever ar makes a change to its contents (save for the q update operation). An archive with such an index speeds up linking to the library, and allows routines in the library to call each other without regard to their placement in the archive. You may use nm -s or nm --print-armap to list this index table. If an archive lacks the table, another form of ar called ranlib can be used to add just the table. GNU ar can optionally create a thin archive, which contains a symbol index and references to the original copies of the member files of the archives. Such an archive is useful for building libraries for use within a local build, where the relocatable objects are expected to remain available, and copying the contents of each object would only waste time and space. Thin archives are also flattened, so that adding one or more archives to a thin archive will add the elements of the nested archive individually. The paths to the elements of the archive are stored relative to the archive itself. GNU ar is designed to be compatible with two different facilities. You can control its activity using command-line options, like the different varieties of ar on Unix systems; or, if you specify the single command-line option -M, you can control it with a script supplied via standard input, like the MRI \"librarian\" program.","Process Name":"bfin-linux-gnu-ar","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-ar"}},{"Process":{"Description":"GNU as is really a family of assemblers. If you use (or have used) the GNU assembler on one architecture, you should find a fairly similar environment when you use it on another architecture. Each version has much in common with the others, including object file formats, most assembler directives (often called pseudo-ops) and assembler syntax. as is primarily intended to assemble the output of the GNU C compiler \"gcc\" for use by the linker \"ld\". Nevertheless, we've tried to make as assemble correctly everything that other assemblers for the same machine would assemble. Any exceptions are documented explicitly. This doesn't mean as always uses the same syntax as another assembler for the same architecture; for example, we know of several incompatible versions of 680x0 assembly language syntax. Each time you run as it assembles exactly one source program. The source program is made up of one or more files. (The standard input is also a file.) You give as a command line that has zero or more input file names. The input files are read (from left file name to right). A command line argument (in any position) that has no special meaning is taken to be an input file name. If you give as no file names it attempts to read one input file from the as standard input, which is normally your terminal. You may have to type ctl-D to tell as there is no more program to assemble. Use -- if you need to explicitly name the standard input file in your command line. If the source is empty, as produces a small, empty object file. as may write warnings and error messages to the standard error file (usually your terminal). This should not happen when a compiler runs as automatically. Warnings report an assumption made so that as could keep assembling a flawed program; errors report a grave problem that stops the assembly. If you are invoking as via the GNU C compiler, you can use the -Wa option to pass arguments through to the assembler. The assembler arguments must be separated from each other (and the -Wa) by commas. For example: gcc -c -g -O -Wa,-alh,-L file.c This passes two options to the assembler: -alh (emit a listing to standard output with high-level and assembly source) and -L (retain local symbols in the symbol table). Usually you do not need to use this -Wa mechanism, since many compiler command-line options are automatically passed to the assembler by the compiler. (You can call the GNU compiler driver with the -v option to see precisely what options it passes to each compilation pass, including the assembler.)","Process Name":"bfin-linux-gnu-as","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-as"}},{"Process":{"Description":"The C ++ and Java languages provide function overloading, which means that you can write many functions with the same name, providing that each function takes parameters of different types. In order to be able to distinguish these similarly named functions C ++ and Java encode them into a low-level assembler name which uniquely identifies each different version. This process is known as mangling. The c++filt [1] program does the inverse mapping: it decodes (demangles) low-level names into user-level names so that they can be read. Every alphanumeric word (consisting of letters, digits, underscores, dollars, or periods) seen in the input is a potential mangled name. If the name decodes into a C ++ name, the C ++ name replaces the low-level name in the output, otherwise the original word is output. In this way you can pass an entire assembler source file, containing mangled names, through c++filt and see the same source file containing demangled names. You can also use c++filt to decipher individual symbols by passing them on the command line: c++filt <symbol> If no symbol arguments are given, c++filt reads symbol names from the standard input instead. All the results are printed on the standard output. The difference between reading names from the command line versus reading names from the standard input is that command line arguments are expected to be just mangled names and no checking is performed to separate them from surrounding text. Thus for example: c++filt -n _Z1fv will work and demangle the name to \"f()\" whereas: c++filt -n _Z1fv, will not work. (Note the extra comma at the end of the mangled name which makes it invalid). This command however will work: echo _Z1fv, | c++filt -n and will display \"f(),\", i.e., the demangled name followed by a trailing comma. This behaviour is because when the names are read from the standard input it is expected that they might be part of an assembler source file where there might be extra, extraneous characters trailing after a mangled name. For example: .type   _Z1fv, @function","Process Name":"bfin-linux-gnu-c++filt","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-c++filt"}},{"Process":{"Description":"The C preprocessor, often known as cpp, is a macro processor that is used automatically by the C compiler to transform your program before compilation. It is called a macro processor because it allows you to define macros, which are brief abbreviations for longer constructs. The C preprocessor is intended to be used only with C, C ++ , and Objective-C source code. In the past, it has been abused as a general text processor. It will choke on input which does not obey C's lexical rules. For example, apostrophes will be interpreted as the beginning of character constants, and cause errors. Also, you cannot rely on it preserving characteristics of the input which are not significant to C-family languages. If a Makefile is preprocessed, all the hard tabs will be removed, and the Makefile will not work. Having said that, you can often get away with using cpp on things which are not C. Other Algol-ish programming languages are often safe (Pascal, Ada, etc.) So is assembly, with caution. -traditional-cpp mode preserves more white space, and is otherwise more permissive. Many of the problems can be avoided by writing C or C ++ style comments instead of native language comments, and keeping macros simple. Wherever possible, you should use a preprocessor geared to the language you are writing in. Modern versions of the GNU assembler have macro facilities. Most high level programming languages have their own conditional compilation and inclusion mechanism. If all else fails, try a true general text processor, such as GNU M4. C preprocessors vary in some details. This manual discusses the GNU C preprocessor, which provides a small superset of the features of ISO Standard C. In its default mode, the GNU C preprocessor does not do a few things required by the standard. These are features which are rarely, if ever, used, and may cause surprising changes to the meaning of a program which does not expect them. To get strict ISO Standard C, you should use the -std=c90, -std=c99 or -std=c11 options, depending on which version of the standard you want. To get all the mandatory diagnostics, you must also use -pedantic. This manual describes the behavior of the ISO preprocessor. To minimize gratuitous differences, where the ISO preprocessor's behavior does not conflict with traditional semantics, the traditional preprocessor should behave the same way. The various differences that do exist are detailed in the section Traditional Mode. For clarity, unless noted otherwise, references to CPP in this manual refer to GNU CPP .","Process Name":"bfin-linux-gnu-cpp","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-cpp"}},{"Process":{"Description":"dlltool reads its inputs, which can come from the -d and -b options as well as object files specified on the command line. It then processes these inputs and if the -e option has been specified it creates a exports file. If the -l option has been specified it creates a library file and if the -z option has been specified it creates a def file. Any or all of the -e, -l and -z options can be present in one invocation of dlltool. When creating a DLL , along with the source for the DLL , it is necessary to have three other files. dlltool can help with the creation of these files. The first file is a .def file which specifies which functions are exported from the DLL , which functions the DLL imports, and so on. This is a text file and can be created by hand, or dlltool can be used to create it using the -z option. In this case dlltool will scan the object files specified on its command line looking for those functions which have been specially marked as being exported and put entries for them in the .def file it creates. In order to mark a function as being exported from a DLL , it needs to have an -export:<name_of_function> entry in the .drectve section of the object file. This can be done in C by using the asm() operator: asm (\".section .drectve\");\nasm (\".ascii \\\"-export:my_func\\\"\");\n\nint my_func (void) { ... } The second file needed for DLL creation is an exports file. This file is linked with the object files that make up the body of the DLL and it handles the interface between the DLL and the outside world. This is a binary file and it can be created by giving the -e option to dlltool when it is creating or reading in a .def file. The third file needed for DLL creation is the library file that programs will link with in order to access the functions in the DLL (an 'import library'). This file can be created by giving the -l option to dlltool when it is creating or reading in a .def file. If the -y option is specified, dlltool generates a delay-import library that can be used instead of the normal import library to allow a program to link to the dll only as soon as an imported function is called for the first time. The resulting executable will need to be linked to the static delayimp library containing __delayLoadHelper2(), which in turn will import LoadLibraryA and GetProcAddress from kernel32. dlltool builds the library file by hand, but it builds the exports file by creating temporary files containing assembler statements and then assembling these. The -S command line option can be used to specify the path to the assembler that dlltool will use, and the -f option can be used to pass specific flags to that assembler. The -n can be used to prevent dlltool from deleting these temporary assembler files when it is done, and if -n is specified twice then this will prevent dlltool from deleting the temporary object files it used to build the library. Here is an example of creating a DLL from a source file dll.c and also creating a program (from an object file called program.o) that uses that DLL: gcc -c dll.c\ndlltool -e exports.o -l dll.lib dll.o\ngcc dll.o exports.o -o dll.dll\ngcc program.o dll.lib -o program dlltool may also be used to query an existing import library to determine the name of the DLL to which it is associated. See the description of the -I or --identify option.","Process Name":"bfin-linux-gnu-dlltool","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-dlltool"}},{"Process":{"Description":"elfedit updates the ELF header of ELF files which have the matching ELF machine and file types. The options control how and which fields in the ELF header should be updated. elffile... are the ELF files to be updated. 32-bit and 64-bit ELF files are supported, as are archives containing ELF files.","Process Name":"bfin-linux-gnu-elfedit","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-elfedit"}},{"Process":{"Description":"When you invoke GCC , it normally does preprocessing, compilation, assembly and linking. The \"overall options\" allow you to stop this process at an intermediate stage. For example, the -c option says not to run the linker. Then the output consists of object files output by the assembler. Other options are passed on to one stage of processing. Some options control the preprocessor and others the compiler itself. Yet other options control the assembler and linker; most of these are not documented here, since you rarely need to use any of them. Most of the command-line options that you can use with GCC are useful for C programs; when an option is only useful with another language (usually C ++ ), the explanation says so explicitly. If the description for a particular option does not mention a source language, you can use that option with all supported languages. The gcc program accepts options and file names as operands. Many options have multi-letter names; therefore multiple single-letter options may not be grouped: -dv is very different from -d -v. You can mix options and other arguments. For the most part, the order you use doesn't matter. Order does matter when you use several options of the same kind; for example, if you specify -L more than once, the directories are searched in the order specified. Also, the placement of the -l option is significant. Many options have long names starting with -f or with -W---for example, -fmove-loop-invariants, -Wformat and so on. Most of these have both positive and negative forms; the negative form of -ffoo would be -fno-foo. This manual documents only one of these two forms, whichever one is not the default.","Process Name":"bfin-linux-gnu-gcc","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-gcc"}},{"Process":{"Description":"gcov is a test coverage program. Use it in concert with GCC to analyze your programs to help create more efficient, faster running code and to discover untested parts of your program. You can use gcov as a profiling tool to help discover where your optimization efforts will best affect your code. You can also use gcov along with the other profiling tool, gprof, to assess which parts of your code use the greatest amount of computing time. Profiling tools help you analyze your code's performance. Using a profiler such as gcov or gprof, you can find out some basic performance statistics, such as: \u2022 how often each line of code executes \u2022 what lines of code are actually executed \u2022 how much computing time each section of code uses Once you know these things about how your code works when compiled, you can look at each module to see which modules should be optimized. gcov helps you determine where to work on optimization. Software developers also use coverage testing in concert with testsuites, to make sure software is actually good enough for a release. Testsuites can verify that a program works as expected; a coverage program tests to see how much of the program is exercised by the testsuite. Developers can then determine what kinds of test cases need to be added to the testsuites to create both better testing and a better final product. You should compile your code without optimization if you plan to use gcov because the optimization, by combining some lines of code into one function, may not give you as much information as you need to look for 'hot spots' where the code is using a great deal of computer time. Likewise, because gcov accumulates statistics by line (at the lowest resolution), it works best with a programming style that places only one statement on each line. If you use complicated macros that expand to loops or to other control structures, the statistics are less helpful---they only report on the line where the macro call appears. If your complex macros behave like functions, you can replace them with inline functions to solve this problem. gcov creates a logfile called sourcefile.gcov which indicates how many times each line of a source file sourcefile.c has executed. You can use these logfiles along with gprof to aid in fine-tuning the performance of your programs. gprof gives timing information you can use along with the information you get from gcov. gcov works only on code compiled with GCC . It is not compatible with any other profiling or test coverage mechanism.","Process Name":"bfin-linux-gnu-gcov","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-gcov"}},{"Process":{"Description":"\"gprof\" produces an execution profile of C, Pascal, or Fortran77 programs. The effect of called routines is incorporated in the profile of each caller. The profile data is taken from the call graph profile file (gmon.out default) which is created by programs that are compiled with the -pg option of \"cc\", \"pc\", and \"f77\". The -pg option also links in versions of the library routines that are compiled for profiling. \"Gprof\" reads the given object file (the default is \"a.out\") and establishes the relation between its symbol table and the call graph profile from gmon.out. If more than one profile file is specified, the \"gprof\" output shows the sum of the profile information in the given profile files. \"Gprof\" calculates the amount of time spent in each routine. Next, these times are propagated along the edges of the call graph. Cycles are discovered, and calls into a cycle are made to share the time of the cycle. Several forms of output are available from the analysis. The flat profile shows how much time your program spent in each function, and how many times that function was called. If you simply want to know which functions burn most of the cycles, it is stated concisely here. The call graph shows, for each function, which functions called it, which other functions it called, and how many times. There is also an estimate of how much time was spent in the subroutines of each function. This can suggest places where you might try to eliminate function calls that use a lot of time. The annotated source listing is a copy of the program's source code, labeled with the number of times each line of the program was executed.","Process Name":"bfin-linux-gnu-gprof","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-gprof"}},{"Process":{"Description":"ld combines a number of object and archive files, relocates their data and ties up symbol references. Usually the last step in compiling a program is to run ld. ld accepts Linker Command Language files written in a superset of AT&T 's Link Editor Command Language syntax, to provide explicit and total control over the linking process. This man page does not describe the command language; see the ld entry in \"info\" for full details on the command language and on other aspects of the GNU linker. This version of ld uses the general purpose BFD libraries to operate on object files. This allows ld to read, combine, and write object files in many different formats---for example, COFF or \"a.out\". Different formats may be linked together to produce any available kind of object file. Aside from its flexibility, the GNU linker is more helpful than other linkers in providing diagnostic information. Many linkers abandon execution immediately upon encountering an error; whenever possible, ld continues executing, allowing you to identify other errors (or, in some cases, to get an output file in spite of the error). The GNU linker ld is meant to cover a broad range of situations, and to be as compatible as possible with other linkers. As a result, you have many choices to control its behavior.","Process Name":"bfin-linux-gnu-ld","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-ld"}},{"Process":{"Description":"nlmconv converts the relocatable i386 object file infile into the NetWare Loadable Module outfile, optionally reading headerfile for NLM header information. For instructions on writing the NLM command file language used in header files, see the linkers section, NLMLINK in particular, of the NLM Development and Tools Overview, which is part of the NLM Software Developer's Kit (\" NLM SDK \"), available from Novell, Inc. nlmconv uses the GNU Binary File Descriptor library to read infile; nlmconv can perform a link step. In other words, you can list more than one object file for input if you list them in the definitions file (rather than simply specifying one input file on the command line). In this case, nlmconv calls the linker for you.","Process Name":"bfin-linux-gnu-nlmconv","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-nlmconv"}},{"Process":{"Description":"GNU nm lists the symbols from object files objfile.... If no object files are listed as arguments, nm assumes the file a.out. For each symbol, nm shows: \u2022 The symbol value, in the radix selected by options (see below), or hexadecimal by default. \u2022 The symbol type. At least the following types are used; others are, as well, depending on the object file format. If lowercase, the symbol is usually local; if uppercase, the symbol is global (external). There are however a few lowercase symbols that are shown for special global symbols (\"u\", \"v\" and \"w\"). \"A\" The symbol's value is absolute, and will not be changed by further linking. \"B\" \"b\" The symbol is in the uninitialized data section (known as BSS ). \"C\" The symbol is common. Common symbols are uninitialized data. When linking, multiple common symbols may appear with the same name. If the symbol is defined anywhere, the common symbols are treated as undefined references. \"D\" \"d\" The symbol is in the initialized data section. \"G\" \"g\" The symbol is in an initialized data section for small objects. Some object file formats permit more efficient access to small data objects, such as a global int variable as opposed to a large global array. \"i\" For PE format files this indicates that the symbol is in a section specific to the implementation of DLLs. For ELF format files this indicates that the symbol is an indirect function. This is a GNU extension to the standard set of ELF symbol types. It indicates a symbol which if referenced by a relocation does not evaluate to its address, but instead must be invoked at runtime. The runtime execution will then return the value to be used in the relocation. \"N\" The symbol is a debugging symbol. \"p\" The symbols is in a stack unwind section. \"R\" \"r\" The symbol is in a read only data section. \"S\" \"s\" The symbol is in an uninitialized data section for small objects. \"T\" \"t\" The symbol is in the text (code) section. \"U\" The symbol is undefined. \"u\" The symbol is a unique global symbol. This is a GNU extension to the standard set of ELF symbol bindings. For such a symbol the dynamic linker will make sure that in the entire process there is just one symbol with this name and type in use. \"V\" \"v\" The symbol is a weak object. When a weak defined symbol is linked with a normal defined symbol, the normal defined symbol is used with no error. When a weak undefined symbol is linked and the symbol is not defined, the value of the weak symbol becomes zero with no error. On some systems, uppercase indicates that a default value has been specified. \"W\" \"w\" The symbol is a weak symbol that has not been specifically tagged as a weak object symbol. When a weak defined symbol is linked with a normal defined symbol, the normal defined symbol is used with no error. When a weak undefined symbol is linked and the symbol is not defined, the value of the symbol is determined in a system-specific manner without error. On some systems, uppercase indicates that a default value has been specified. \"-\" The symbol is a stabs symbol in an a.out object file. In this case, the next values printed are the stabs other field, the stabs desc field, and the stab type. Stabs symbols are used to hold debugging information. \"?\" The symbol type is unknown, or object file format specific. \u2022 The symbol name.","Process Name":"bfin-linux-gnu-nm","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-nm"}},{"Process":{"Description":"The GNU objcopy utility copies the contents of an object file to another. objcopy uses the GNU BFD Library to read and write the object files. It can write the destination object file in a format different from that of the source object file. The exact behavior of objcopy is controlled by command-line options. Note that objcopy should be able to copy a fully linked file between any two formats. However, copying a relocatable object file between any two formats may not work as expected. objcopy creates temporary files to do its translations and deletes them afterward. objcopy uses BFD to do all its translation work; it has access to all the formats described in BFD and thus is able to recognize most formats without being told explicitly. objcopy can be used to generate S-records by using an output target of srec (e.g., use -O srec). objcopy can be used to generate a raw binary file by using an output target of binary (e.g., use -O binary). When objcopy generates a raw binary file, it will essentially produce a memory dump of the contents of the input object file. All symbols and relocation information will be discarded. The memory dump will start at the load address of the lowest section copied into the output file. When generating an S-record or a raw binary file, it may be helpful to use -S to remove sections containing debugging information. In some cases -R will be useful to remove sections which contain information that is not needed by the binary file. Note---objcopy is not able to change the endianness of its input files. If the input format has an endianness (some formats do not), objcopy can only copy the inputs into file formats that have the same endianness or which have no endianness (e.g., srec). (However, see the --reverse-bytes option.)","Process Name":"bfin-linux-gnu-objcopy","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-objcopy"}},{"Process":{"Description":"objdump displays information about one or more object files. The options control what particular information to display. This information is mostly useful to programmers who are working on the compilation tools, as opposed to programmers who just want their program to compile and work. objfile... are the object files to be examined. When you specify archives, objdump shows information on each of the member object files.","Process Name":"bfin-linux-gnu-objdump","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-objdump"}},{"Process":{"Description":"ranlib generates an index to the contents of an archive and stores it in the archive. The index lists each symbol defined by a member of an archive that is a relocatable object file. You may use nm -s or nm --print-armap to list this index. An archive with such an index speeds up linking to the library and allows routines in the library to call each other without regard to their placement in the archive. The GNU ranlib program is another form of GNU ar; running ranlib is completely equivalent to executing ar -s.","Process Name":"bfin-linux-gnu-ranlib","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-ranlib"}},{"Process":{"Description":"readelf displays information about one or more ELF format object files. The options control what particular information to display. elffile... are the object files to be examined. 32-bit and 64-bit ELF files are supported, as are archives containing ELF files. This program performs a similar function to objdump but it goes into more detail and it exists independently of the BFD library, so if there is a bug in BFD then readelf will not be affected.","Process Name":"bfin-linux-gnu-readelf","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-readelf"}},{"Process":{"Description":"The GNU size utility lists the section sizes---and the total size---for each of the object or archive files objfile in its argument list. By default, one line of output is generated for each object file or each module in an archive. objfile... are the object files to be examined. If none are specified, the file \"a.out\" will be used.","Process Name":"bfin-linux-gnu-size","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-size"}},{"Process":{"Description":"For each file given, GNU strings prints the printable character sequences that are at least 4 characters long (or the number given with the options below) and are followed by an unprintable character. By default, it only prints the strings from the initialized and loaded sections of object files; for other types of files, it prints the strings from the whole file. strings is mainly useful for determining the contents of non-text files.","Process Name":"bfin-linux-gnu-strings","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-strings"}},{"Process":{"Description":"GNU strip discards all symbols from object files objfile. The list of object files may include archives. At least one object file must be given. strip modifies the files named in its argument, rather than writing modified copies under different names.","Process Name":"bfin-linux-gnu-strip","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-strip"}},{"Process":{"Description":"windmc reads message definitions from an input file (.mc) and translate them into a set of output files. The output files may be of four kinds: \"h\" A C header file containing the message definitions. \"rc\" A resource file compilable by the windres tool. \"bin\" One or more binary files containing the resource data for a specific message language. \"dbg\" A C include file that maps message id's to their symbolic name. The exact description of these different formats is available in documentation from Microsoft. When windmc converts from the \"mc\" format to the \"bin\" format, \"rc\", \"h\", and optional \"dbg\" it is acting like the Windows Message Compiler.","Process Name":"bfin-linux-gnu-windmc","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-windmc"}},{"Process":{"Description":"windres reads resources from an input file and copies them into an output file. Either file may be in one of three formats: \"rc\" A text format read by the Resource Compiler. \"res\" A binary format generated by the Resource Compiler. \"coff\" A COFF object or executable. The exact description of these different formats is available in documentation from Microsoft. When windres converts from the \"rc\" format to the \"res\" format, it is acting like the Windows Resource Compiler. When windres converts from the \"res\" format to the \"coff\" format, it is acting like the Windows \"CVTRES\" program. When windres generates an \"rc\" file, the output is similar but not identical to the format expected for the input. When an input \"rc\" file refers to an external filename, an output \"rc\" file will instead include the file contents. If the input or output format is not specified, windres will guess based on the file name, or, for the input file, the file contents. A file with an extension of .rc will be treated as an \"rc\" file, a file with an extension of .res will be treated as a \"res\" file, and a file with an extension of .o or .exe will be treated as a \"coff\" file. If no output file is specified, windres will print the resources in \"rc\" format to standard output. The normal use is for you to write an \"rc\" file, use windres to convert it to a COFF object file, and then link the COFF file into your application. This will make the resources described in the \"rc\" file available to Windows.","Process Name":"bfin-linux-gnu-windres","Link":"https:\/\/linux.die.net\/man\/1\/bfin-linux-gnu-windres"}},{"Process":{"Description":"bfr's purpose is to buffer data. (I hope this is obvious. =)) It buffers from its standard input and\/or a list of files of your choosing, and allows this data to flow to its standard output at whatever rate that end can handle. Its useful for any situation in which its beneficial to have I\/O occur in a detached yet smooth fashion... possible applications: \u2022 - CD burning. A user in Spain was using this in front of cdrecord, apparently the CPU couldn't keep up with the 8x burner, so 30 megs (cdrecord's limit) wasn't enough. \u2022 - Backups. bfr can be configured to release its data in large chunks, rather than small flowing increments, which reduces tape seek. bfr also has a speedcap option, which ensures bfr will never output more than a certain amount (which you specify) of data per second. This makes it useful for network backups without saturating your backbone or T1. \u2022 - Multimedia. Since bfr does its best to yield data to its output at whatever pace the other side can handle (essentially keeping the output stuffed full), it reduces skips. This helps both movies (the pr0n must go on!) and audio (ditto mp3!). The bfp program, included in this package, is an extension to bfr whose primary purpose is to aid skipless audio playback, by properly configuring and writing to \/dev\/dsp.","Process Name":"bfr","Link":"https:\/\/linux.die.net\/man\/1\/bfr"}},{"Process":{"Description":"Most MPI users will probably not need to use the bfstate command; see mpimsg(1). This command is only installed if LAM\/MPI was configured with the --with-trillium switch. The bfstate command displays information on LAM network message buffers on any node in the multicomputer. For each message, bfstate outputs the following information: NODE node containing the message DEST destination node of the message EVENT message event (see nsend(2)) TYPE message type LENGTH message length in bytes The -l option prints the following summary on each node's buffer system, after all messages for that node have been displayed. - maximum size of the internal buffer pool - amount of space currently used in the pool. Individual message buffers hold network message packets, which may be only part of a complete user message. Normally, bfstate summarizes packets into complete messages. If all packets for a message are not on the same node, no information is displayed. The -p option disables this behaviour and one line on information is displayed for each packet. The -B option changes the maximum number of packet buffers acquired (and hence displayable) from the node.","Process Name":"bfstate","Link":"https:\/\/linux.die.net\/man\/1\/bfstate"}},{"Process":{"Description":"","Process Name":"bg","Link":"https:\/\/linux.die.net\/man\/1\/bg"}},{"Process":{"Description":"Bglafile is a Module Access File generator. It produces file that suits Bigloo option -afile. A Module Access File is a scheme list. Each elements of that list is a list of at least two elements: a module name, the file that implements that module. For BEE (the Bigloo Integrated Development Environment) to be able to retrieve files from module names, it is mandatory that the first parentheses of the global list is left alone on one line.","Process Name":"bglafile","Link":"https:\/\/linux.die.net\/man\/1\/bglafile"}},{"Process":{"Description":"bgldepend program reads each sourcefile in sequence and parses it to find the module include and import module directives. bgldepend computes the transitive closure of the import relationship. That is, it is sufficient to provide bgldepend with a single Bigloo file that imports all the project file (e.g. the \"main\" file.) Every file that a sourcefile includes, directly or indirectly, is what bgldepend calls a dependency. These dependencies are then written to a makefile in such a way that make(1) will know which object files must be recompiled when a dependency has changed. By default, bgldepend writes its output on the standard output device. If bgldepend is provided with a -o makefile option, it will update the makefile file. That is, it will search the makefile for the line: # bgldepend start (don't edit) and # bgldepend stop Dependencies will be written in between these two lines.","Process Name":"bgldepend","Link":"https:\/\/linux.die.net\/man\/1\/bgldepend"}},{"Process":{"Description":"Bgljfile is a Jvm Access File generator. It produces file that suits Bigloo option -bgljfile. A Jvm Access File is a scheme list. Each elements of that list is a list of at least two elements: a module name, the Java class file that implements that module.","Process Name":"bgljfile","Link":"https:\/\/linux.die.net\/man\/1\/bgljfile"}},{"Process":{"Description":"bglmake reads sourcefile, computes the transitive closure of the import relationship and generates a makefile file that can be used by the glmake(1) program to compile the application or the library. If no sourcefile is provided, then bglmake display the template file for generating Makefile.","Process Name":"bglmake","Link":"https:\/\/linux.die.net\/man\/1\/bglmake"}},{"Process":{"Description":"bglmco reads sourcefile and produces a module checksum object file. This bglmco file is used to ensure modules coherence in Bigloo Makefiles.","Process Name":"bglmco","Link":"https:\/\/linux.die.net\/man\/1\/bglmco"}},{"Process":{"Description":"bglpp reads sourcefile one at a time and pretty print them. Normally bglpp output its result on the standard output device.","Process Name":"bglpp","Link":"https:\/\/linux.die.net\/man\/1\/bglpp"}},{"Process":{"Description":"bglprof is a front-end to the gprof program. Any option that applied to gprof suits for bglprof. bglprof reads an extra monitoring file, the bmon.out file. This file is generated when executing a program that has been linked by Bigloo making use of the -p option. See the glprof manual for an detailed documentation.","Process Name":"bglprof","Link":"https:\/\/linux.die.net\/man\/1\/bglprof"}},{"Process":{"Description":"The bgltags program is used to create a tag table file, in a format understood by emacs(1). This programs understand the syntax of the Bigloo files. It reads the files specified on the command line, and write a tag table (defaults: TAGS) in the current working directory. Files specified with relative file names will be recorded in the tag table with file names relative to the directory where the tag table re- sides. Files specified with absolute file names will be recorded with absolute file names. The program does not recognize the language used in an input file based on its file name and contents. The --language switch can be used to force parsing of the file names following the switch according to the given language, overriding guesses based on file-name extensions. Source files that are not Scheme are actually processed by the etags program.","Process Name":"bgltags","Link":"https:\/\/linux.die.net\/man\/1\/bgltags"}},{"Process":{"Description":"The biasbat command applies bias correction to a set of source frames. The bias correction is applied in advanced calibration scheme only, please refer to documentation about the calibration of CCD frames. The source frames and the bias frame must be in the FITS format and of same dimensions. The output file is written in the FITS format too.","Process Name":"biasbat","Link":"https:\/\/linux.die.net\/man\/1\/biasbat"}},{"Process":{"Description":"The bibutils program set inter-converts between various bibliography formats using Library of Congress [1] 's Metadata Object Description Schema (MODS) [2] version 3.1. For example, one can convert RIS-format files to Bibtex by doing two transformations: RIS->MODS->Bibtex.","Process Name":"bib2xml","Link":"https:\/\/linux.die.net\/man\/1\/bib2xml"}},{"Process":{"Description":"The bibutils program set inter-converts between various bibliography formats using Library of Congress [1] 's Metadata Object Description Schema (MODS) [2] version 3.1. For example, one can convert RIS-format files to Bibtex by doing two transformations: RIS->MODS->Bibtex.","Process Name":"biblatex2xml","Link":"https:\/\/linux.die.net\/man\/1\/biblatex2xml"}},{"Process":{"Description":"This manual page is not meant to be exhaustive. The complete documentation for this version of TeX can be found in the info file or manual Web2C: A TeX implementation. BibTeX reads the top-level auxiliary (.aux) file that was output during the running of latex(1) or tex(1) and creates a bibliography (.bbl) file that will be incorporated into the document on subsequent runs of LaTeX or TeX. The auxname on the command line must be given without the .aux extension. If you don't give the auxname, the program prompts you for it. BibTeX looks up, in bibliographic database (.bib) files specified by the \\bibliography command, the entries specified by the \\cite and \\nocite commands in the LaTeX or TeX source file. It formats the information from those entries according to instructions in a bibliography style (.bst) file (specified by the \\bibliographystyle command, and it outputs the results to the .bbl file. The LaTeX manual explains what a LaTeX source file must contain to work with BibTeX. Appendix B of the manual describes the format of the .bib files. The 'BibTeXing' document describes extensions and details of this format, and it gives other useful hints for using BibTeX.","Process Name":"bibtex","Link":"https:\/\/linux.die.net\/man\/1\/bibtex"}},{"Process":{"Description":"The bibutils program set inter-converts between various bibliography formats using Library of Congress [1] 's Metadata Object Description Schema (MODS) [2] version 3.1. For example, one can convert RIS-format files to Bibtex by doing two transformations: RIS->MODS->Bibtex.","Process Name":"bibutils","Link":"https:\/\/linux.die.net\/man\/1\/bibutils"}},{"Process":{"Description":"Bigloo is a Scheme compiler. Scheme is defined in an IEEE standard for the Scheme Programming Language but Bigloo does not entirely conform to it. The compiler produces either C files or Java class files. The C files are then compiled by any ISO C compiler to produce .o or executable files. Bigloo is a module compiler which means that it is allowed to compile several files and to link them together to produce an unique executable.","Process Name":"bigloo","Link":"https:\/\/linux.die.net\/man\/1\/bigloo"}},{"Process":{"Description":"bin2obj reads a binary file and converts it to a pascal typed constant declaration. The constant is an array of bytes (zero based), in which each byte has the value of the byte at the offset index in the file. (index is the index in the array).","Process Name":"bin2obj","Link":"https:\/\/linux.die.net\/man\/1\/bin2obj"}},{"Process":{"Description":"Most people use the decimal numbering system. This system uses ten symbols to represent numbers. When those ten symbols are used up, they start all over again and increment the position to the left. The digit 0 is only shown if it is the only symbol in the sequence, or if it is not the first one. If this sounds cryptic to you, this is what I've just said in numbers:  0\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 and so on. Each time the digit nine is incremented, it is reset to 0 and the position before (to the left) is incremented (from 0 to 1). Then number 9 can be seen as \"00009\" and when we should increment 9, we reset it to zero and increment the digit just before the 9 so the number becomes \"00010\". Leading zeros we don't write except if it is the only digit (number 0). And of course, we write zeros if they occur anywhere inside or at the end of a number: \"00010\" -> \" 0010\" -> \" 010\" -> \"  10\", but not \"  1 \". This was pretty basic, you already knew this. Why did I tell it? Well, computers usually do not represent numbers with 10 different digits. They only use two different symbols, namely \"0\" and \"1\". Apply the same rules to this set of digits and you get the binary numbering system:    0\n   1\n  10\n  11\n 100\n 101\n 110\n 111\n1000\n1001\n1010\n1011\n1100\n1101 and so on. If you count the number of rows, you'll see that these are again 14 different numbers. The numbers are the same and mean the same as in the first list, we just used a different representation. This means that you have to know the representation used, or as it is called the numbering system or base. Normally, if we do not explicitly specify the numbering system used, we implicitly use the decimal system. If we want to use any other numbering system, we'll have to make that clear. There are a few widely adopted methods to do so. One common form is to write 1010(2) which means that you wrote down a number in its binary representation. It is the number ten. If you would write 1010 without specifying the base, the number is interpreted as one thousand and ten using base 10. In books, another form is common. It uses subscripts (little characters, more or less in between two rows). You can leave out the parentheses in that case and write down the number in normal characters followed by a little two just behind it. As the numbering system used is also called the base, we talk of the number 1100 base 2, the number 12 base 10. Within the binary system, it is common to write leading zeros. The numbers are written down in series of four, eight or sixteen depending on the context. We can use the binary form when talking to computers (...programming...), but the numbers will have large representations. The number 65'535 (often in the decimal system a ' is used to separate blocks of three digits for readability) would be written down as 1111111111111111(2) which is 16 times the digit 1. This is difficult and prone to errors. Therefore, we usually would use another base, called hexadecimal. It uses 16 different symbols. First the symbols from the decimal system are used, thereafter we continue with alphabetic characters. We get 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E and F. This system is chosen because the hexadecimal form can be converted into the binary system very easily (and back). There is yet another system in use, called the octal system. This was more common in the old days, but is not used very often anymore. As you might find it in use sometimes, you should get used to it and we'll show it below. It's the same story as with the other representations, but with eight different symbols. Binary      (2)\nOctal       (8)\nDecimal     (10)\nHexadecimal (16)\n\n(2)    (8) (10) (16)\n00000   0    0    0\n00001   1    1    1\n00010   2    2    2\n00011   3    3    3\n00100   4    4    4\n00101   5    5    5\n00110   6    6    6\n00111   7    7    7\n01000  10    8    8\n01001  11    9    9\n01010  12   10    A\n01011  13   11    B\n01100  14   12    C\n01101  15   13    D\n01110  16   14    E\n01111  17   15    F\n10000  20   16   10\n10001  21   17   11\n10010  22   18   12\n10011  23   19   13\n10100  24   20   14\n10101  25   21   15 Most computers used nowadays are using bytes of eight bits. This means that they store eight bits at a time. You can see why the octal system is not the most practical for that: You'd need three digits to represent the eight bits and this means that you'd have to use one complete digit to represent only two bits (2+3+3=8). This is a waste. For hexadecimal digits, you need only two digits which are used completely: (2)      (8)  (10) (16)\n11111111 377  255   FF You can see why binary and hexadecimal can be converted quickly: For each hexadecimal digit there are exactly four binary digits. Take a binary number: take four digits from the right and make a hexadecimal digit from it (see the table above). Repeat this until there are no more digits. And the other way around: Take a hexadecimal number. For each digit, write down its binary equivalent. Computers (or rather the parsers running on them) would have a hard time converting a number like 1234(16). Therefore hexadecimal numbers are specified with a prefix. This prefix depends on the language you're writing in. Some of the prefixes are \"0x\" for C, \"$\" for Pascal, \"#\" for HTML . It is common to assume that if a number starts with a zero, it is octal. It does not matter what is used as long as you know what it is. I will use \"0x\" for hexadecimal, \"%\" for binary and \"0\" for octal. The following numbers are all the same, just their representation (base) is different: 021 0x11 17 %00010001 To do arithmetics and conversions you need to understand one more thing. It is something you already know but perhaps you do not \"see\" it yet: If you write down 1234, (no prefix, so it is decimal) you are talking about the number one thousand, two hundred and thirty four. In sort of a formula: 1 * 1000 = 1000\n2 *  100 =  200\n3 *   10 =   30\n4 *    1 =    4 This can also be written as: 1 * 10^3\n2 * 10^2\n3 * 10^1\n4 * 10^0 where ^ means \"to the power of\". We are using the base 10, and the positions 0,1,2 and 3. The right-most position should NOT be multiplied with 10. The second from the right should be multiplied one time with 10. The third from the right is multiplied with 10 two times. This continues for whatever positions are used. It is the same in all other representations: 0x1234 will be 1 * 16^3\n2 * 16^2\n3 * 16^1\n4 * 16^0 01234 would be 1 * 8^3\n2 * 8^2\n3 * 8^1\n4 * 8^0 This example can not be done for binary as that system only uses two symbols. Another example: %1010 would be 1 * 2^3\n0 * 2^2\n1 * 2^1\n0 * 2^0 It would have been easier to convert it to its hexadecimal form and just translate %1010 into 0xA. After a while you get used to it. You will not need to do any calculations anymore, but just know that 0xA means 10. To convert a decimal number into a hexadecimal you could use the next method. It will take some time to be able to do the estimates, but it will be easier when you use the system more frequently. We'll look at yet another way afterwards. First you need to know how many positions will be used in the other system. To do so, you need to know the maximum numbers you'll be using. Well, that's not as hard as it looks. In decimal, the maximum number that you can form with two digits is \"99\". The maximum for three: \"999\". The next number would need an extra position. Reverse this idea and you will see that the number can be found by taking 10^3 (10*10*10 is 1000) minus 1 or 10^2 minus one. This can be done for hexadecimal as well: 16^4 = 0x10000 = 65536\n16^3 =  0x1000 =  4096\n16^2 =   0x100 =   256\n16^1 =    0x10 =    16 If a number is smaller than 65'536 it will fit in four positions. If the number is bigger than 4'095, you must use position 4. How many times you can subtract 4'096 from the number without going below zero is the first digit you write down. This will always be a number from 1 to 15 (0x1 to 0xF). Do the same for the other positions. Let's try with 41'029. It is smaller than 16^4 but bigger than 16^3-1. This means that we have to use four positions. We can subtract 16^3 from 41'029 ten times without going below zero. The left-most digit will therefore be \"A\", so we have 0xA????. The number is reduced to 41'029 - 10*4'096 = 41'029-40'960 = 69. 69 is smaller than 16^3 but not bigger than 16^2-1. The second digit is therefore \"0\" and we now have 0xA0??. 69 is smaller than 16^2 and bigger than 16^1-1. We can subtract 16^1 (which is just plain 16) four times and write down \"4\" to get 0xA04?. Subtract 64 from 69 (69 - 4*16) and the last digit is 5 --> 0xA045. The other method builds up the number from the right. Let's try 41'029 again. Divide by 16 and do not use fractions (only whole numbers). 41'029 \/ 16 is 2'564 with a remainder of 5. Write down 5.\n2'564 \/ 16 is 160 with a remainder of 4. Write the 4 before the 5.\n160 \/ 16 is 10 with no remainder. Prepend 45 with 0.\n10 \/ 16 is below one. End here and prepend 0xA. End up with 0xA045. Which method to use is up to you. Use whatever works for you. I use them both without being able to tell what method I use in each case, it just depends on the number, I think. Fact is, some numbers will occur frequently while programming. If the number is close to one I am familiar with, then I will use the first method (like 32'770 which is into 32'768 + 2 and I just know that it is 0x8000 + 0x2 = 0x8002). For binary the same approach can be used. The base is 2 and not 16, and the number of positions will grow rapidly. Using the second method has the advantage that you can see very easily if you should write down a zero or a one: if you divide by two the remainder will be zero if it is an even number and one if it is an odd number: 41029 \/ 2 = 20514 remainder 1\n20514 \/ 2 = 10257 remainder 0\n10257 \/ 2 =  5128 remainder 1\n 5128 \/ 2 =  2564 remainder 0\n 2564 \/ 2 =  1282 remainder 0\n 1282 \/ 2 =   641 remainder 0\n  641 \/ 2 =   320 remainder 1\n  320 \/ 2 =   160 remainder 0\n  160 \/ 2 =    80 remainder 0\n   80 \/ 2 =    40 remainder 0\n   40 \/ 2 =    20 remainder 0\n   20 \/ 2 =    10 remainder 0\n   10 \/ 2 =     5 remainder 0\n    5 \/ 2 =     2 remainder 1\n    2 \/ 2 =     1 remainder 0\n    1 \/ 2 below 0 remainder 1 Write down the results from right to left: %1010000001000101 Group by four: %1010000001000101\n%101000000100 0101\n%10100000 0100 0101\n%1010 0000 0100 0101 Convert into hexadecimal: 0xA045 Group %1010000001000101 by three and convert into octal: %1010000001000101\n%1010000001000 101\n%1010000001 000 101\n%1010000 001 000 101\n%1010 000 001 000 101\n%1 010 000 001 000 101\n%001 010 000 001 000 101\n   1   2   0   1   0   5 --> 0120105\n\nSo: %1010000001000101 = 0120105 = 0xA045 = 41029\nOr: 1010000001000101(2) = 120105(8) = A045(16) = 41029(10)\nOr: 1010000001000101(2) = 120105(8) = A045(16) = 41029 At first while adding numbers, you'll convert them to their decimal form and then back into their original form after doing the addition. If you use the other numbering system often, you will see that you'll be able to do arithmetics directly in the base that is used. In any representation it is the same, add the numbers on the right, write down the right-most digit from the result, remember the other digits and use them in the next round. Continue with the second digit from the right and so on: %1010 + %0111 --> 10 + 7 --> 17 --> %00010001 will become    %1010\n   %0111 +\n    ||||\n    |||+-- add 0 + 1, result is 1, nothing to remember\n    ||+--- add 1 + 1, result is %10, write down 0 and remember 1\n    |+---- add 0 + 1 + 1(remembered), result = 0, remember 1\n    +----- add 1 + 0 + 1(remembered), result = 0, remember 1\n           nothing to add, 1 remembered, result = 1\n--------\n  %10001 is the result, I like to write it as %00010001 For low values, try to do the calculations yourself, then check them with a calculator. The more you do the calculations yourself, the more you'll find that you didn't make mistakes. In the end, you'll do calculi in other bases as easily as you do them in decimal. When the numbers get bigger, you'll have to realize that a computer is not called a computer just to have a nice name. There are many different calculators available, use them. For Unix you could use \"bc\" which is short for Binary Calculator. It calculates not only in decimal, but in all bases you'll ever want to use (among them Binary). For people on Windows: Start the calculator (start->programs->accessories->calculator) and if necessary click view->scientific. You now have a scientific calculator and can compute in binary or hexadecimal.","Process Name":"bin_dec_hex","Link":"https:\/\/linux.die.net\/man\/1\/bin_dec_hex"}},{"Process":{"Description":"","Process Name":"bind","Link":"https:\/\/linux.die.net\/man\/1\/bind"}},{"Process":{"Description":"binfile expects as input a raw UNIX file with its filename held by the string in and writes it to the vasari image file out by filling properly the header details. It is expected that the file has sizes xs by ys and has b bands. It is an error if the file in has less than xs*ys*b data. The program is unable to check whether the supplied xs, ys and b are correct.","Process Name":"binfile","Link":"https:\/\/linux.die.net\/man\/1\/binfile"}},{"Process":{"Description":"binlegs will make changes to the mgg supplement data base files gmt_legs.d and gmt_index.b for the legs listed in the leglistfile. Normally, only the data archivist will need to be concerned with these operations. leglistfile Contains the list of legs to be worked on.","Process Name":"binlegs","Link":"https:\/\/linux.die.net\/man\/1\/binlegs"}},{"Process":{"Description":"This program is part of Netpbm(1). bioradtopgm reads a Biorad confocal file as input and produces a PGM image as output. If the resulting image is upside down, run it through pamflip -tb.","Process Name":"bioradtopgm","Link":"https:\/\/linux.die.net\/man\/1\/bioradtopgm"}},{"Process":{"Description":"biosdevname takes a kernel device name as an argument, and returns the BIOS-given name it \"should\" be.","Process Name":"biosdevname","Link":"https:\/\/linux.die.net\/man\/1\/biosdevname"}},{"Process":{"Description":"BIP is an IRC Proxy","Process Name":"bip","Link":"https:\/\/linux.die.net\/man\/1\/bip"}},{"Process":{"Description":"Bison is a parser generator in the style of yacc(1). It should be upwardly compatible with input files designed for yacc. Input files should follow the yacc convention of ending in .y. Unlike yacc, the generated files do not have fixed names, but instead use the prefix of the input file. Moreover, if you need to put C++ code in the input file, you can end his name by a C++-like extension (.ypp or .y++), then bison will follow your extension to name the output file (.cpp or .c++). For instance, a grammar description file named parse.yxx would produce the generated parser in a file named parse.tab.cxx, instead of yacc's y.tab.c or old Bison version's parse.tab.c. This description of the options that can be given to bison is adapted from the node Invocation in the bison.texinfo manual, which should be taken as authoritative. Bison supports both traditional single-letter options and mnemonic long option names. Long option names are indicated with -- instead of -. Abbreviations for option names are allowed as long as they are unique. When a long option takes an argument, like --file-prefix, connect the option name and the argument with =. Generate LALR(1) and GLR parsers. Mandatory arguments to long options are mandatory for short options too. The same is true for optional arguments. Operation modes: -h, --help display this help and exit -V, --version output version information and exit --print-localedir output directory containing locale-dependent data --print-datadir output directory containing skeletons and XSLT -y, --yacc emulate POSIX Yacc -W, --warnings= [CATEGORY] report the warnings falling in CATEGORY Parser: -L, --language= LANGUAGE specify the output programming language (this is an experimental feature) -S, --skeleton= FILE specify the skeleton to use -t, --debug instrument the parser for debugging --locations enable locations computation -p, --name-prefix= PREFIX prepend PREFIX to the external symbols -l, --no-lines don't generate '#line' directives -k, --token-table include a table of token names Output: --defines[= FILE] also produce a header file -d likewise but cannot specify FILE (for POSIX Yacc) -r, --report= THINGS also produce details on the automaton --report-file= FILE write report to FILE -v, --verbose same as '--report=state' -b, --file-prefix= PREFIX specify a PREFIX for output files -o, --output= FILE leave output to FILE -g, --graph[= FILE] also output a graph of the automaton -x, --xml[= FILE] also output an XML report of the automaton (the XML schema is experimental) Warning categories include: 'midrule-values' unset or unused midrule values 'yacc' incompatibilities with POSIX YACC 'all' all the warnings 'no-CATEGORY' turn off warnings in CATEGORY 'none' turn off all the warnings 'error' treat warnings as errors THINGS is a list of comma separated words that can include: 'state' describe the states 'itemset' complete the core item sets with their closure 'lookahead' explicitly associate lookahead tokens to items 'solved' describe shift\/reduce conflicts solving 'all' include all the above information 'none' disable the report","Process Name":"bison","Link":"https:\/\/linux.die.net\/man\/1\/bison"}},{"Process":{"Description":"BitchX is a VERY heavily modified ircII client. It includes many things such as built in CDCC (XDCC) offering, built in flood protection, etc. It is easier to script things in BitchX because unlike plain, vanilla ircII, half the script does not have to be devoted to changing the appearance of ircII. It also includes many other new features, such as port scanning, advanced TCL, a CD player, a mail client, screening process, etc. BitchX - Based on EPIC Software Labs epic ircII (1998). Version (BitchX-1.0c18) -- Date (20010108).","Process Name":"bitchx","Link":"https:\/\/linux.die.net\/man\/1\/bitchx"}},{"Process":{"Description":"The bitmap program is a rudimentary tool for creating or editing rectangular images made up of 1's and 0's. Bitmaps are used in X for defining clipping regions, cursor shapes, icon shapes, and tile and stipple patterns. The bmtoa and atobm filters convert bitmap files (FILE FORMAT) to and from ASCII strings. They are most commonly used to quickly print out bitmaps and to generate versions for including in text.","Process Name":"bitmap","Link":"https:\/\/linux.die.net\/man\/1\/bitmap"}},{"Process":{"Description":"","Process Name":"bkhive","Link":"https:\/\/linux.die.net\/man\/1\/bkhive"}},{"Process":{"Description":"Blackbox is a window manager for the Open Group's X Window System, Version 11 Release 6 and above. Its design is meant to be visually minimalist and fast. Blackbox is similar to the NeXT interface and Windowmaker. Applications are launched using a menu which is accessed by right clicking on the root window. Workspaces, a system of virtual desktops are controlled via a menu which is accessed by middle clicking on the root window and by using the toolbar. Individual windows can be controlled by buttons on the title bar and more options are available by right clicking on the title bar. Blackbox is able to generate beautiful window decorations on the fly at high speed. Themes, called styles in Blackbox terminology, are very flexible but the use of pixmaps has been purposefully avoided to eliminate dependencies and excess memory usage. Blackbox itself does not directly handle key bindings like most other window managers. This task is handled by a separate utility called bbkeys. Although Blackbox has a built-in workspace (paging) system, bbpager, which provides a graphical pager, is popular with many users. bbkeys, bbpager and several other bbtools can be found by going to      http:\/\/bbtools.thelinuxcommunity.org\/\n The slit is an edge of the screen which can hold specially designed programs called dock apps (from Windowmaker). In addition, the popular program gkrellm will also run in the slit. There is a huge selection of dockapps available and they run the gamut from must-have gadgets to utterly useless (but cute and\/or funny) eye candy.      http:\/\/www.bensinclair.com\/dockapp\/\n     http:\/\/dockapps.org\/","Process Name":"blackbox","Link":"https:\/\/linux.die.net\/man\/1\/blackbox"}},{"Process":{"Description":"Draws a simulation of flying space-combat robots (cleverly disguised as colored circles) doing battle in front of a moving star field.","Process Name":"blaster","Link":"https:\/\/linux.die.net\/man\/1\/blaster"}},{"Process":{"Description":"Shows a ball contained inside of a bounding box. Colored blocks blink in when the ball hits the edges.","Process Name":"blinkbox","Link":"https:\/\/linux.die.net\/man\/1\/blinkbox"}},{"Process":{"Description":"blinkenlights is a GUI tool for use with monitoring and controlling the DNSSEC-Tools rollerd program. It displays information on the current state of the zones rollerd is managing. The user may control some aspects of rollerd's execution using blinkenlights menu commands. blinkenlights creates a window in which to display information about each zone rollerd is managing. (These zones are those in rollerd's current rollrec file.) As a zone's rollover status changes, blinkenlights will update its display for that zone. Skipped zones, zones listed in the rollrec file but which are not in rollover or normal operation, are displayed but have very little useful information to display. The user may also select a set of zones to hide from the display. These zones, if in the rolling state, will continue to roll; however, their zone information will not be displayed. Display state for each zone will persist across blinkenlights executions. Menu commands are available for controlling rollerd. The commands which operate on a single zone may be executed by keyboard shortcuts. The zone may be selected either by clicking in its \"zone stripe\" or by choosing from a dialog box. Display and execution options for blinkenlights are also available through menu commands. More information about the menu commands is available in the MENU COMMANDS section. blinkenlights is only intended to be started by rollerd, not directly by a user. There are two ways to have rollerd start blinkenlights. First, rollctl may be given the -display option. Second, the -display option may be given on rollerd's command line.","Process Name":"blinkenlights","Link":"https:\/\/linux.die.net\/man\/1\/blinkenlights"}},{"Process":{"Description":"The blitspin program repeatedly rotates a bitmap by 90 degrees by using logical operations: the bitmap is divided into quadrants, and the quadrants are shifted clockwise. Then the same thing is done again with progressively smaller quadrants, except that all sub-quadrants of a given size are rotated in parallel. So this takes O(16*log2(N)) blits of size NxN, with the limitation that the image must be square, and the size must be a power of 2.","Process Name":"blitspin","Link":"https:\/\/linux.die.net\/man\/1\/blitspin"}},{"Process":{"Description":"The blkparse utility will attempt to combine streams of events for various devices on various CPUs, and produce a formatted output of the event information. Specifically, it will take the (machine-readable) output of the blktrace utility and convert it to a nicely formatted and human-readable form. As with blktrace, some details concerning blkparse will help in understanding the command line options presented below. - By default, blkparse expects to run in a post-processing mode; one where the trace events have been saved by a previous run of blktrace, and blkparse is combining event streams and dumping formatted data. blkparse may be run in a live manner concurrently with blktrace by specifying -i - to blkparse, and combining it with the live option for blktrace. An example would be: % blktrace -d \/dev\/sda -o - | blkparse -i - - You can set how many blkparse batches event reads via the -b option, the default is to handle events in batches of 512. - If you have saved event traces in blktrace with different output names (via the -o option to blktrace), you must specify the same input name via the -i option. - The format of the output data can be controlled via the -f or -F options -- see OUTPUT DESCRIPTION AND FORMATTING for details. By default, blkparse sends formatted data to standard output. This may be changed via the -o option, or text output can be disabled via the -O option. A merged binary stream can be produced using the -d option.","Process Name":"blkparse","Link":"https:\/\/linux.die.net\/man\/1\/blkparse"}},{"Process":{"Description":"The blkrawverify utility can be used to verify data retrieved via blktrace. It will check for valid event formats, forward progressing sequence numbers and time stamps, also does reasonable checks for other potential issues within individual events. Errors found will be tracked in <dev>.verify.out.","Process Name":"blkrawverify","Link":"https:\/\/linux.die.net\/man\/1\/blkrawverify"}},{"Process":{"Description":"The program reads data from standard input and write the same data to standard output. Write operations to output use a fixed block size of 512. The output data stream can be used by dd to write to a disk or disk partition.","Process Name":"blks","Link":"https:\/\/linux.die.net\/man\/1\/blks"}},{"Process":{"Description":"The program reads data from standard input and write the same data to standard output. Write operations to output use a fixed block size, either the size specified as command line argument or 512. The output data stream can be used by dd to write to a disk or disk partition.","Process Name":"blksize","Link":"https:\/\/linux.die.net\/man\/1\/blksize"}},{"Process":{"Description":"","Process Name":"block","Link":"https:\/\/linux.die.net\/man\/1\/block"}},{"Process":{"Description":"blockmean reads arbitrarily located ( x,y,z) triples [or optionally weighted quadruples ( x,y,z,w)] from standard input [or xyz[w]file(s)] and writes to standard output a mean position and value for every non-empty block in a grid region defined by the -R and -I arguments. Either blockmean, blockmedian, or blockmode should be used as a pre-processor before running surface to avoid aliasing short wavelengths. These routines are also generally useful for decimating or averaging ( x,y,z) data. You can modify the precision of the output format by editing the D_FORMAT parameter in your .gmtdefaults4 file, or you may choose binary input and\/or output using single or double precision storage. xyz[w]file(s) 3 [or 4] column ASCII file(s) [or binary, see -b] holding ( x,y,z[, w]) data values. [ w] is an optional weight for the data. If no file is specified, blockmean will read from standard input. -I x_inc [and optionally y_inc] is the grid spacing. Optionally, append a suffix modifier. Geographical (degrees) coordinates: Append m to indicate arc minutes or c to indicate arc seconds. If one of the units e, k, i, or n is appended instead, the increment is assumed to be given in meter, km, miles, or nautical miles, respectively, and will be converted to the equivalent degrees longitude at the middle latitude of the region (the conversion depends on ELLIPSOID). If \/ y_inc is given but set to 0 it will be reset equal to x_inc; otherwise it will be converted to degrees latitude. All coordinates: If = is appended then the corresponding max x ( east) or y ( north) may be slightly adjusted to fit exactly the given increment [by default the increment may be adjusted slightly to fit the given domain]. Finally, instead of giving an increment you may specify the number of nodes desired by appending + to the supplied integer argument; the increment is then recalculated from the number of nodes and the domain. The resulting increment value depends on whether you have selected a gridline-registered or pixel-registered grid; see Appendix B for details. Note: if -R grdfile is used then grid spacing has already been initialized; use -I to override the values. -R xmin, xmax, ymin, and ymax specify the Region of interest. For geographic regions, these limits correspond to west, east, south, and north and you may specify them in decimal degrees or in [+-]dd:mm[:ss.xxx][W|E|S|N] format. Append r if lower left and upper right map coordinates are given instead of w\/e\/s\/n. The two shorthands -Rg and -Rd stand for global domain (0\/360 and -180\/+180 in longitude respectively, with -90\/+90 in latitude). Alternatively, specify the name of an existing grid file and the -R settings (and grid spacing, if applicable) are copied from the grid. For calendar time coordinates you may either give (a) relative time (relative to the selected TIME_EPOCH and in the selected TIME_UNIT; append t to -JX| x), or (b) absolute time of the form [ date] T[ clock] (append T to -JX| x). At least one of date and clock must be present; the T is always required. The date string must be of the form [-]yyyy[-mm[-dd]] (Gregorian calendar) or yyyy[-Www[-d]] (ISO week calendar), while the clock string must be of the form hh:mm:ss[.xxx]. The use of delimiters and their type and positions must be exactly as indicated (however, input, output and plot formats are customizable; see gmtdefaults).","Process Name":"blockmean","Link":"https:\/\/linux.die.net\/man\/1\/blockmean"}},{"Process":{"Description":"blockmedian reads arbitrarily located ( x,y,z) triples [or optionally weighted quadruples ( x,y,z,w)] from standard input [or xyz[w]file(s)] and writes to standard output a median position and value for every non-empty block in a grid region defined by the -R and -I arguments. Either blockmean, blockmedian, or blockmode should be used as a pre-processor before running surface to avoid aliasing short wavelengths. These routines are also generally useful for decimating or averaging ( x,y,z) data. You can modify the precision of the output format by editing the D_FORMAT parameter in your .gmtdefaults4 file, or you may choose binary input and\/or output using single or double precision storage. xyz[w]file(s) 3 [or 4] column ASCII file(s) [or binary, see -b] holding ( x,y,z[, w]) data values. [ w] is an optional weight for the data. If no file is specified, blockmedian will read from standard input. -I x_inc [and optionally y_inc] is the grid spacing. Optionally, append a suffix modifier. Geographical (degrees) coordinates: Append m to indicate arc minutes or c to indicate arc seconds. If one of the units e, k, i, or n is appended instead, the increment is assumed to be given in meter, km, miles, or nautical miles, respectively, and will be converted to the equivalent degrees longitude at the middle latitude of the region (the conversion depends on ELLIPSOID). If \/ y_inc is given but set to 0 it will be reset equal to x_inc; otherwise it will be converted to degrees latitude. All coordinates: If = is appended then the corresponding max x ( east) or y ( north) may be slightly adjusted to fit exactly the given increment [by default the increment may be adjusted slightly to fit the given domain]. Finally, instead of giving an increment you may specify the number of nodes desired by appending + to the supplied integer argument; the increment is then recalculated from the number of nodes and the domain. The resulting increment value depends on whether you have selected a gridline-registered or pixel-registered grid; see Appendix B for details. Note: if -R grdfile is used then grid spacing has already been initialized; use -I to override the values. -R xmin, xmax, ymin, and ymax specify the Region of interest. For geographic regions, these limits correspond to west, east, south, and north and you may specify them in decimal degrees or in [+-]dd:mm[:ss.xxx][W|E|S|N] format. Append r if lower left and upper right map coordinates are given instead of w\/e\/s\/n. The two shorthands -Rg and -Rd stand for global domain (0\/360 and -180\/+180 in longitude respectively, with -90\/+90 in latitude). Alternatively, specify the name of an existing grid file and the -R settings (and grid spacing, if applicable) are copied from the grid. For calendar time coordinates you may either give (a) relative time (relative to the selected TIME_EPOCH and in the selected TIME_UNIT; append t to -JX| x), or (b) absolute time of the form [ date] T[ clock] (append T to -JX| x). At least one of date and clock must be present; the T is always required. The date string must be of the form [-]yyyy[-mm[-dd]] (Gregorian calendar) or yyyy[-Www[-d]] (ISO week calendar), while the clock string must be of the form hh:mm:ss[.xxx]. The use of delimiters and their type and positions must be exactly as indicated (however, input, output and plot formats are customizable; see gmtdefaults).","Process Name":"blockmedian","Link":"https:\/\/linux.die.net\/man\/1\/blockmedian"}},{"Process":{"Description":"blockmode reads arbitrarily located ( x,y,z) triples [or optionally weighted quadruples ( x,y,z,w)] from standard input [or xyz[w]file(s)] and writes to standard output mode estimates of position and value for every non-empty block in a grid region defined by the -R and -I arguments. Either blockmean, blockmedian, or blockmode should be used as a pre-processor before running surface to avoid aliasing short wavelengths. These routines are also generally useful for decimating or averaging ( x,y,z) data. You can modify the precision of the output format by editing the D_FORMAT parameter in your .gmtdefaults4 file, or you may choose binary input and\/or output using single or double precision storage. xyz[w]file(s) 3 [or 4] column ASCII file(s) [or binary, see -b] holding ( x,y,z[, w]) data values. [ w] is an optional weight for the data. If no file is specified, blockmode will read from standard input. -I x_inc [and optionally y_inc] is the grid spacing. Optionally, append a suffix modifier. Geographical (degrees) coordinates: Append m to indicate arc minutes or c to indicate arc seconds. If one of the units e, k, i, or n is appended instead, the increment is assumed to be given in meter, km, miles, or nautical miles, respectively, and will be converted to the equivalent degrees longitude at the middle latitude of the region (the conversion depends on ELLIPSOID). If \/ y_inc is given but set to 0 it will be reset equal to x_inc; otherwise it will be converted to degrees latitude. All coordinates: If = is appended then the corresponding max x ( east) or y ( north) may be slightly adjusted to fit exactly the given increment [by default the increment may be adjusted slightly to fit the given domain]. Finally, instead of giving an increment you may specify the number of nodes desired by appending + to the supplied integer argument; the increment is then recalculated from the number of nodes and the domain. The resulting increment value depends on whether you have selected a gridline-registered or pixel-registered grid; see Appendix B for details. Note: if -R grdfile is used then grid spacing has already been initialized; use -I to override the values. -R xmin, xmax, ymin, and ymax specify the Region of interest. For geographic regions, these limits correspond to west, east, south, and north and you may specify them in decimal degrees or in [+-]dd:mm[:ss.xxx][W|E|S|N] format. Append r if lower left and upper right map coordinates are given instead of w\/e\/s\/n. The two shorthands -Rg and -Rd stand for global domain (0\/360 and -180\/+180 in longitude respectively, with -90\/+90 in latitude). Alternatively, specify the name of an existing grid file and the -R settings (and grid spacing, if applicable) are copied from the grid. For calendar time coordinates you may either give (a) relative time (relative to the selected TIME_EPOCH and in the selected TIME_UNIT; append t to -JX| x), or (b) absolute time of the form [ date] T[ clock] (append T to -JX| x). At least one of date and clock must be present; the T is always required. The date string must be of the form [-]yyyy[-mm[-dd]] (Gregorian calendar) or yyyy[-Www[-d]] (ISO week calendar), while the clock string must be of the form hh:mm:ss[.xxx]. The use of delimiters and their type and positions must be exactly as indicated (however, input, output and plot formats are customizable; see gmtdefaults).","Process Name":"blockmode","Link":"https:\/\/linux.die.net\/man\/1\/blockmode"}},{"Process":{"Description":"Blocktube draws a swirling, falling tunnel of reflective slabs. They fade from hue to hue.","Process Name":"blocktube","Link":"https:\/\/linux.die.net\/man\/1\/blocktube"}},{"Process":{"Description":"clogin is an expect(1) script to automate the process of logging into a Cisco router, catalyst switch, Extreme switch, Juniper ERX\/E-series, Procket Networks, or Redback router. There are complementary scripts for Alteon, Avocent (Cyclades), Bay Networks (nortel), ADC-kentrox EZ-T3 mux, Foundry, HP Procurve Switches and Cisco AGMs, Hitachi Routers, Juniper Networks, MRV optical switch, Netscreen firewalls, Netscaler, Riverstone, Netopia, and Lucent TNT, named alogin, avologin, blogin, elogin, flogin, fnlogin, hlogin, htlogin, jlogin, mrvlogin, nlogin, nslogin, rivlogin, tlogin, and tntlogin, respectively. clogin reads the .cloginrc file for its configuration, then connects and logs into each of the routers specified on the command line in the order listed. Command-line options exist to override some of the directives found in the .cloginrc configuration file. The command-line options are as follows: -S Save the configuration on exit, if the device prompts at logout time. This only has affect when used with -s. -V Prints package name and version strings. -c Command to be run on each router list on the command-line. Multiple commands maybe listed by separating them with semi-colons (;). The argument should be quoted to avoid shell expansion. -d Enable expect debugging. -E Specifies a variable to pass through to scripts (-s). For example, the command-line option -Efoo=bar will produce a global variable by the name Efoo with the initial value \"bar\". -e Specify a password to be supplied when gaining enable privileges on the router(s). Also see the password directive of the .cloginrc file. -f Specifies an alternate configuration file. The default is $HOME\/.cloginrc. -p Specifies a password associated with the user specified by the -u option, user directive of the .cloginrc file, or the Unix username of the user. -s The filename of an expect(1) script which will be sourced after the login is successful and is expected to return control to clogin, with the connection to the router intact, when it is done. Note that clogin disables log_user of expect(1)when -s is used. Example script(s) can be found in share\/rancid\/*.exp. -t Alters the timeout interval; the period that clogin waits for an individual command to return a prompt or the login process to produce a prompt or failure. The argument is in seconds. -u Specifies the username used when prompted. The command-line option overrides any user directive found in .cloginrc. The default is the current Unix username. -v Specifies a vty password, that which is prompted for upon connection to the router. This overrides the vty password of the .cloginrc file's password directive. -w Specifies the username used if prompted when gaining enable privileges. The command-line option overrides any user or enauser directives found in .cloginrc. The default is the current Unix username. -x Similar to the -c option; -x specifies a file with commands to run on each of the routers. The commands must not expect additional input, such as 'copy rcp startup-config' does. For example: show version\nshow logging -y Specifies the encryption algorithm for use with the ssh(1) -c option. The default encryption type is often not supported. See the ssh(1) man page for details. The default is 3des.","Process Name":"blogin","Link":"https:\/\/linux.die.net\/man\/1\/blogin"}},{"Process":{"Description":"The BLTK can be used with various workloads to simulate different types of laptop usage. The following workloads are currently implemented: Idle workload collect statistics only (mostly used to measure battery life) Reader workload simulates text reading on laptop (mostly used to measure battery life) Playback workload simulates laptop entertaining usage (produces constant average load on the system) Office Activity workload simulates laptop usage for different office activities (based on OpenOffice.org office suit) When started, test collects platform\/OS initial info and if it's OK prompts user to unplug AC adapter. After cable unplugged, workload started. During the workload execution test harness collects various system information (e.g. CPU load, battery drain, display state, CPU frequency, etc...). After battery completely discharged user should plug the AC cable back and boot the system. When it is done the results are available. There are several tools for result evaluation. They allow creating report file for test run, to gather results into a table for system comparison, and to draw graphs for different purposes. Results - after the battery dies and the system booted back, the results are available. They are stored in 'bltk\/<wokload_name>.results' directory (or in the directory, specified in -r option). If target directory already exist the tool will add numeric extension to its name (.001, .002 e.t.c.) The results consist of the following files (see below for detailed description): cmd In this file 'bltk' command with arguments are stored infoi<N>.log (info1.log, info2.log, ...) Here initial system info is stored. Another two files (info1.log, info2.log) contains system info after AC adapter was unplugged, and on 5% battery capacity remained. They are used to check whether any changes occurred during test execution. stat.log Statistics generated by bltk harness are stored here. One statistic line generated per 1 minute (or per number of seconds, specified in -t option). system<N> When -k 1 is used, the system information is stored under this directory. The numbers at the end of directory name have the following meanings: initial system info system info after AC adapter was unplugged system info on 5% battery capacity remained version this file contains version information workload the file contains info about workload work_out.log err.log There are stored any error messages warning.log Contains warnings work.log Strings generated by USR1, USR2 signals from workload. String format is the same as in the 'stat.log' file. fail when test fails score Report Report.table","Process Name":"bltk","Link":"https:\/\/linux.die.net\/man\/1\/bltk"}},{"Process":{"Description":"The following tools are implemented for results analysis: bltk_report automated report creation bltk_report_table summary table creation from several results folders bltk_plot graph drawing","Process Name":"bltk_report","Link":"https:\/\/linux.die.net\/man\/1\/bltk_report"}},{"Process":{"Description":"bluefish is an open-source editor for experienced web designers and programmers, supporting many programming and markup languages, but focusing on creating dynamic and interactive websites.","Process Name":"bluefish","Link":"https:\/\/linux.die.net\/man\/1\/bluefish"}},{"Process":{"Description":"bluetooth-applet will stay in your GNOME panel as a Bluetooth icon and will pop up a dialog whenever a passkey (aka PIN) is required from the Linux Bluetooth stack. bluetooth-applet is part of bluez-gnome, see also http:\/\/www.bluez.org","Process Name":"bluetooth-applet","Link":"https:\/\/linux.die.net\/man\/1\/bluetooth-applet"}},{"Process":{"Description":"bluetooth-properties will display a dialog for changing Bluetooth preferences. bluetooth-properties is part of bluez-gnome, see also http:\/\/www.bluez.org","Process Name":"bluetooth-properties","Link":"https:\/\/linux.die.net\/man\/1\/bluetooth-properties"}},{"Process":{"Description":"bluetooth-sendto will display a dialog for transfering files over Bluetooth. bluetooth-sendto is part of gnome-bluetooth, see also http:\/\/live.gnome.org\/GnomeBluetooth","Process Name":"bluetooth-sendto","Link":"https:\/\/linux.die.net\/man\/1\/bluetooth-sendto"}},{"Process":{"Description":"bluetooth-wizard will display a wizard for setting up Bluetooth devices. bluetooth-wizard is part of bluez-gnome, see also http:\/\/www.bluez.org","Process Name":"bluetooth-wizard","Link":"https:\/\/linux.die.net\/man\/1\/bluetooth-wizard"}},{"Process":{"Description":"bmake is a program designed to simplify the maintenance of other programs. Its input is a list of specifications as to the files upon which programs and other files depend. If no -f makefile makefile option is given, bmake will try to open 'makefile' then 'Makefile' in order to find the specifications. If the file '.depend' exists, it is read (see mkdep(1)). This manual page is intended as a reference document only. For a more thorough description of bmake and makefiles, please refer to Make - A Tutorial. bmake will prepend the contents of the MAKEFLAGS environment variable to the command line arguments before parsing them. The options are as follows:       -B'        Try to be backwards compatible by executing a single shellper command and by executing the commands to make the sources ofa dependency line in sequence. -C directory Change to directory before reading the makefiles or doing anything else. If multiple -C options are specified, each is interpreted relative to the previous one: -C \/ -C etc is equivalent to -C \/etc. -D variable Define variable to be 1, in the global context. -d [-]flags Turn on debugging, and specify which portions of bmake are to print debugging information. Unless the flags are preceded by '-' they are added to the MAKEFLAGS environment variable and will be processed by any child make processes. By default, debugging information is printed to standard error, but this can be changed using the F debugging flag. The debugging output is always unbuffered; in addition, if debugging is enabled but debugging output is not directed to standard output, then the standard output is line buffered. Flags is one or more of the following: A' Print all possible debugging information; equivalent to specifying all of the debugging flags. a' Print debugging information about archive searching and caching. C' Print debugging information about current working directory. c' Print debugging information about conditional evaluation. d' Print debugging information about directory searching and caching. e' Print debugging information about failed commands and targets. F[ +]filename Specify where debugging output is written. This must be the last flag, because it consumes the remainder of the argument. If the character immediately after the 'F' flag is '+', then the file will be opened in append mode; otherwise the file will be overwritten. If the file name is 'stdout' or 'stderr' then debugging output will be written to the standard output or standard error output file descriptors respectively (and the '+' option has no effect). Otherwise, the output will be written to the named file. If the file name ends '.%d' then the '%d' is replaced by the pid. f' Print debugging information about loop evaluation. g1' Print the input graph before making anything. g2' Print the input graph after making everything, or before exiting on error. g3' Print the input graph before exiting on error. j' Print debugging information about running multiple shells. l' Print commands in Makefiles regardless of whether or not they are prefixed by '@' or other \"quiet\" flags. Also known as \"loud\" behavior. M' Print debugging information about \"meta\" mode decisions about targets. m' Print debugging information about making targets, including modification dates. n' Don't delete the temporary command scripts created when running commands. These temporary scripts are created in the directory referred to by the TMPDIR environment variable, or in \/tmp if TMPDIR is unset or set to the empty string. The temporary scripts are created by mkstemp(3), and have names of the form makeXXXXXX. NOTE: This can create many files in TMPDIR or \/tmp, so use with care. p' Print debugging information about makefile parsing. s' Print debugging information about suffix-transformation rules. t' Print debugging information about target list maintenance. v' Print debugging information about variable assignment. x' Run shell commands with -x so the actual commands are printed as they are executed. -e' Specify that environment variables override macro assignments within makefiles. -f makefile Specify a makefile to read instead of the default 'makefile'. If makefile is '-', standard input is read. Multiple makefiles may be specified, and are read in the order specified. -I directory Specify a directory in which to search for makefiles and included makefiles. The system makefile directory (or directories, see the -m option) is automatically included as part of this list. -i' Ignore non-zero exit of shell commands in the makefile. Equivalent to specifying '-' before each command line in the makefile. -J private This option should not be specified by the user. When the j option is in use in a recursive build, this option is passed by a make to child makes to allow all the make processes in the build to cooperate to avoid overloading the system. -j max_jobs Specify the maximum number of jobs that bmake may have running at any one time. The value is saved in .MAKE.JOBS. Turns compatibility mode off, unless the B flag is also specified. When compatibility mode is off, all commands associated with a target are executed in a single shell invocation as opposed to the traditional one shell invocation per line. This can break traditional scripts which change directories on each command invocation and then expect to start with a fresh environment on the next line. It is more efficient to correct the scripts rather than turn backwards compatibility on. -k' Continue processing after errors are encountered, but only on those targets that do not depend on the target whose creation caused the error. -m directory Specify a directory in which to search for sys.mk and makefiles included via the < file>-style include statement. The -m option can be used multiple times to form a search path. This path will override the default system include path: \/usr\/share\/mk. Furthermore the system include path will be appended to the search path used for \" file\"-style include statements (see the -I option). If a file or directory name in the -m argument (or the MAKESYSPATH environment variable) starts with the string \"...\/\" then bmake will search for the specified file or directory named in the remaining part of the argument string. The search starts with the current directory of the Makefile and then works upward towards the root of the filesystem. If the search is successful, then the resulting directory replaces the \"...\/\" specification in the -m argument. If used, this feature allows bmake to easily search in the current source tree for customized sys.mk files (e.g., by using \"...\/mk\/sys.mk\" as an argument). -n' Display the commands that would have been executed, but do not actually execute them unless the target depends on the .MAKE special source (see below). -N' Display the commands which would have been executed, but do not actually execute any of them; useful for debugging top-level makefiles without descending into subdirectories. -q' Do not execute any commands, but exit 0 if the specified targets are up-to-date and 1, otherwise. -r' Do not use the built-in rules specified in the system makefile. -s' Do not echo any commands as they are executed. Equivalent to specifying '@' before each command line in the makefile. -T tracefile When used with the -j flag, append a trace record to tracefile for each job started and completed. -t' Rather than re-building a target as specified in the makefile, create it or update its modification time to make it appear up-to-date. -V variable Print bmake's idea of the value of variable, in the global context. Do not build any targets. Multiple instances of this option may be specified; the variables will be printed one per line, with a blank line for each null or undefined variable. If variable contains a '$' then the value will be expanded before printing. -W' Treat any warnings during makefile parsing as errors. -X' Don't export variables passed on the command line to the environment individually. Variables passed on the command line are still exported via the MAKEFLAGS environment variable. This option may be useful on systems which have a small limit on the size of command arguments. variable=value Set the value of the variable variable to value. Normally, all values passed on the command line are also exported to sub-makes in the environment. The -X flag disables this behavior. Variable assignments should follow options for POSIX compatibility but no ordering is enforced. There are seven different types of lines in a makefile: file dependency specifications, shell commands, variable assignments, include statements, conditional directives, for loops, and comments. In general, lines may be continued from one line to the next by ending them with a backslash ('\\'). The trailing newline character and initial whitespace on the following line are compressed into a single space.","Process Name":"bmake","Link":"https:\/\/linux.die.net\/man\/1\/bmake"}},{"Process":{"Description":"Bmeps reads the specified input file, converts it and write output to the specified file. If no output file name is specified bmeps writes to standard output. If no input file name is specified bmeps reads from standard input. If bmeps is run on a directory it searches the directory for files it can handle. A conversion is done for each file found, except when running in make mode. In make mode bmeps checks for a conversion output file, a conversion is run only if the output file does not yet exist or is not up to date.","Process Name":"bmeps","Link":"https:\/\/linux.die.net\/man\/1\/bmeps"}},{"Process":{"Description":"bmf is a Bayesian mail filter. In its normal mode of operation, it takes an email message or other text on standard input, does a statistical check against lists of \"good\" and \"spam\" words, registers the new data, and returns a status code indicating whether or not the message is spam. BMF is written with fast, zero-copy algorithms, coded directly in C, and tuned for speed. It aims to be faster, smaller, and more versatile than similar applications. bmf supports both mbox and maildir mail storage formats. It will automatically process multiple messages within an mbox file separately.","Process Name":"bmf","Link":"https:\/\/linux.die.net\/man\/1\/bmf"}},{"Process":{"Description":"bmfconv converts bmf token databases between the supported formats. It can import flat text files into databases and export databases into flat text files. PLEASE NOTE that the text files used in import and export operations are read and written in the current directory.","Process Name":"bmfconv","Link":"https:\/\/linux.die.net\/man\/1\/bmfconv"}},{"Process":{"Description":"bmon is a portable bandwidth monitor with multiple input methods and output modes. A set of architecture specific input modules provide the core with the listof interfaces and their counters. The core stores this counters and provides rate estimation including a history over the last 60 seconds, minutes, hours and days to the output modules which output them according to the configuration. The set of counters is dependant on the input module and may vary. Secondary input and output modules may be used to collect counter values from other nodes or to write HTML statistics. This input\/output architecture minimizes the work needed to port it to other architectures or generate specific statistics.","Process Name":"bmon","Link":"https:\/\/linux.die.net\/man\/1\/bmon"}},{"Process":{"Description":"more is a filter that displays the contents of a binary file on the terminal, one screenful at a time. It normally pauses after each screenful, and prints --More-- at the bottom of the screen. bmore provides a two-line overlap between screens for continuity. If bmore is reading from a file rather than a pipe, the percentage of characters displayed so far is also shown. bmore scrolls up to display one more screen line in response to a RETURN character; it displays another screenful in response to a SPACE character. Other commands are listed below. The screen is divided in three sections or panes: The byte offset (extreme left), the hex pane (middle), and an ascii pane (right) which shows as printable characters those bytes in the hex pane. On an 80 column terminal there will be sixteen hex values and their ASCII values on each screen line. Note that (as one would expect) the first byte has the offset 0 (zero). bmore sets the terminal to noecho mode, so that the output can be continuous. Commands that you type do not normally show up on your terminal, except for the \/ , \\ and ! commands. If the standard output is not a terminal, more acts just like cat(1V), except that a header is printed before each file in a series.","Process Name":"bmore","Link":"https:\/\/linux.die.net\/man\/1\/bmore"}},{"Process":{"Description":"bmp2tiff converts a Microsoft Windows Device Independent Bitmap image file to TIFF. If several input BMP files are being specified the multipage TIFF output file will be created. By default, the TIFF image is created with data samples packed (PlanarConfiguration=1), compressed with the PackBits algorithm (Compression=32773), and with each strip no more than 8 kilobytes. These characteristics can overridden, or explicitly specified with the options described below.","Process Name":"bmp2tiff","Link":"https:\/\/linux.die.net\/man\/1\/bmp2tiff"}},{"Process":{"Description":"This program is part of Netpbm(1). bmptopnm reads a Microsoft Windows or OS\/2 BMP file as input. and produces a PBM, PGM, or PNM image as output. If the input is colormapped and contains only black and white, the output is PBM. If the input is colormapped and contains only black white and gray, the output is PGM. Otherwise, the output is PPM. bmptopnm understands BMP files compressed with run length encoding (RLE4\/RLE8), but not if that encoding includes a 'delta' (which is rare). bmptopnm recognizes the delta and issues an error message. bmptopnm cannot convert BMP files compressed with JPEG or PNG encoding. It recognizes the compression and issues an error message. Before Netpbm 10.32 (February 2006), bmptopnm couldn't convert RLE BMP files either. Before Netpbm 10.18 (September 2003), this program could not convert BMP images with the BI_BITFIELDS format (\"compression type\"). It would recognize the format and issue an error message. bmptopnm cannot convert OS\/2 BMP files with 16 bits per pixel (only because the author did not have a complete specification for them). It recognizes the format and issues an error message. Before Netpbm 10.16 (June 2003), it also could not convert Windows BMP files with 16 bits per pixel.","Process Name":"bmptopnm","Link":"https:\/\/linux.die.net\/man\/1\/bmptopnm"}},{"Process":{"Description":"This program is part of Netpbm(1). bmptoppm was replaced in Netpbm 9.25 (March 2002) by bmptopnm(1). bmptopnm is backward compatible with bmptoppm except that it generates PBM and PGM output when it is more appropriate than PPM.","Process Name":"bmptoppm","Link":"https:\/\/linux.die.net\/man\/1\/bmptoppm"}},{"Process":{"Description":"The bitmap program is a rudimentary tool for creating or editing rectangular images made up of 1's and 0's. Bitmaps are used in X for defining clipping regions, cursor shapes, icon shapes, and tile and stipple patterns. The bmtoa and atobm filters convert bitmap files (FILE FORMAT) to and from ASCII strings. They are most commonly used to quickly print out bitmaps and to generate versions for including in text.","Process Name":"bmtoa","Link":"https:\/\/linux.die.net\/man\/1\/bmtoa"}},{"Process":{"Description":"bno_plot is a visualization tool for the block layer IO tracing tool called blktrace(8). As noted in its documentation, blktrace is a block layer IO tracing mechanism which provides detailed information about request queue operations up to user space. bno_plot utilizes gnuplot to generate a 3D plot of the block number output from btt. If no <files> are specified, it will utilize all files generated after btt was run with -B blknos (meaning: all files of the form blknos*[rw].dat). The -K option forces bno_plot to put the keys below the graph. If it is not specified, all keys for input files are put in the upper right corner of the graph. If the number of devices exceed 10, then bno_plot will automatically push the keys under the graph. To use this utility, the gnuplot package needs to be installed. To exit the plotter, enter 'quit' or ^D at the 'gnuplot> ' prompt.","Process Name":"bno_plot","Link":"https:\/\/linux.die.net\/man\/1\/bno_plot"}},{"Process":{"Description":"bodhi is the comment-line tool for interacting with a bodhi instance.","Process Name":"bodhi","Link":"https:\/\/linux.die.net\/man\/1\/bodhi"}},{"Process":{"Description":"Bogofilter is a Bayesian spam filter. In its normal mode of operation, it takes an email message or other text on standard input, does a statistical check against lists of \"good\" and \"bad\" words, and returns a status code indicating whether or not the message is spam. Bogofilter is designed with a fast algorithm, uses the Berkeley DB for fast startup and lookups, coded directly in C, and tuned for speed, so it can be used for production by sites that process a lot of mail.","Process Name":"bogofilter","Link":"https:\/\/linux.die.net\/man\/1\/bogofilter"}},{"Process":{"Description":"Bogolexer is part of the bogofilter Bayesian spam filter package. It is used to separate messages into tokens and to test new versions of the lexer.l code.","Process Name":"bogolexer","Link":"https:\/\/linux.die.net\/man\/1\/bogolexer"}},{"Process":{"Description":"Bogotune tries to find optimum parameter settings for bogofilter. It needs at least one set each of spam and non-spam messages. The production wordlist is normally used, but it can be directed to read a different wordlist, or to build its own from half the supplied messages. In order to produce useful results, bogotune has minimum message count requirements. The wordlist it uses must have at least 2,000 spam and 2,000 non-spam in it and the message files must contain at least 500 spam and 500 non-spam messages. Also, the ratio of spam to non-spam should be in the range 0.2 to 5. If you direct bogotune to build its own wordlist, it will use the half the input or 2000 messages (whichever is larger) for the wordlist. Message files may be in mbox, maildir, or MH folder or any combination. Msg-count files can also be used, but not mixed with other formats.","Process Name":"bogotune","Link":"https:\/\/linux.die.net\/man\/1\/bogotune"}},{"Process":{"Description":"bogoupgrade is a command to upgrade bogofilter's databases from an old format to the current format. Since the format of the database changes once in a while, the utility is designed to make the upgrade easy.","Process Name":"bogoupgrade","Link":"https:\/\/linux.die.net\/man\/1\/bogoupgrade"}},{"Process":{"Description":"Bogoutil is part of the bogofilter Bayesian spam filter package. It is used to dump and load bogofilter's Berkeley DB databases to and from text files, perform database maintenance functions, and to display the values for specific words.","Process Name":"bogoutil","Link":"https:\/\/linux.die.net\/man\/1\/bogoutil"}},{"Process":{"Description":"The BOINC \"core client\", boinc, is the heart of BOINC. It controls which project applications are run on your computer, downloading \"Workunits\" and uploading the \"Result\" files from completed tasks. boinc is usually run in the background, ideally as a daemon. It can then be controlled either by a graphical tool called the BOINC Manager, boincmgr(1), or a command-line tool called boinccmd(1), by means of Remote Proceedure Calls (RPCs) over port 31416. The BOINC core client can be controlled by command-line options, configuration files, and environment variables. Standard usage is simply to start the client running in the background.","Process Name":"boinc","Link":"https:\/\/linux.die.net\/man\/1\/boinc"}},{"Process":{"Description":"The BOINC command tool (boinccmd) provides a command line interface to a running BOINC core client (boinc(1)).","Process Name":"boinccmd","Link":"https:\/\/linux.die.net\/man\/1\/boinccmd"}},{"Process":{"Description":"The BOINC manager (boincmgr) is a controling and monitoring utility for the BOINC core client (boinc(1)).","Process Name":"boincmgr","Link":"https:\/\/linux.die.net\/man\/1\/boincmgr"}},{"Process":{"Description":"bombardment is part of the Siege package. It calls siege with an initial number of clients. When that run finishes, it immediately calls siege again with that number of clients plus the increment. It does this the number of times specified in the fourth argument.","Process Name":"bombardment","Link":"https:\/\/linux.die.net\/man\/1\/bombardment"}},{"Process":{"Description":"They take CSV format (comma-delimited spreadsheet files AKA Comma Seperated Values in MS land) data on standard input and produce HTML or plain text on standard output respectively.","Process Name":"bon_csv2html","Link":"https:\/\/linux.die.net\/man\/1\/bon_csv2html"}},{"Process":{"Description":"They take CSV format (comma-delimited spreadsheet files AKA Comma Seperated Values in MS land) data on standard input and produce HTML or plain text on standard output respectively.","Process Name":"bon_csv2txt","Link":"https:\/\/linux.die.net\/man\/1\/bon_csv2txt"}},{"Process":{"Description":"Bonnie measures the performance of UNIX filesystem operations. For details, see http:\/\/www.textuality.com\/bonnie\/","Process Name":"bonnie","Link":"https:\/\/linux.die.net\/man\/1\/bonnie"}},{"Process":{"Description":"This application tracks information about installed components and brokers components, in conjunction with its client library; libbonobo-activation. It reads the component descriptions from ${prefix}\/lib\/bonobo\/servers\/*.server. These files provide an XML description of a components capabilities which can be queried and manipulated by clients from the client library. Bonobo-activation-server also ensures that the minimum neccessary number of servers for your display setup are running. Bonobo-activation-server executes all components with the environment inherited from the first process to start the server. In addition to using your prefix, it will examine the BONOBO_ACTIVATION_PATH and the GNOME2_PATH environment variables to find .server files. In addition it examines an XML configuration file in ${prefix}\/etc\/bonobo-activation\/bonobo-activation-config.xml For more information see http:\/\/www.gnome.org. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"bonobo-activation-server","Link":"https:\/\/linux.die.net\/man\/1\/bonobo-activation-server"}},{"Process":{"Description":"boog is a mapper of a behavioural description onto a predefined standard cell library as SXLIB. It is the second step of the logic synthesis: it builds a gate network using a standard cell library. Input file description The logic level behavioural description (.vbe file) uses the same VHDL subset as the logic simulator asimut, the FSM synthesizer syf, the functional abstractor yagle and the formal prover proof (for further information about the subset of VHDL, see the \"vbe\" manual). Some constraints due to hardware mapping exist. These attributes are only supported by technology mapping onto a standard cell library as sxlib. For the register signal description, only one condition statement must appear. STABLE must be strictely used as a negativ motion and joined to clock setup value. Setup can be on high or low value, but it would be worthy to choose it accordingly with hardware register cell. # Example label: BLOCK (NOT ck 'STABLE and ck='1') BEGIN reg <= GUARDED expr; END BLOCK; You can also put a write enable condition to your register: label: BLOCK (NOT ck 'STABLE and ck='1' and wen='1') BEGIN reg <= GUARDED expr; END BLOCK; A special feature has been introduced in the VHDL subset in order to allow the don't care description for external outputs and internal registers : A bit signal can take the 'd' value. This value is interpreted as a '0' by the logic simulator asimut. Don't Cares are automatically generated by syf in the resulting '.vbe' file. Output file description A pure standard cell netlist is produced by boog. This file is destinated for \/fBloon\/fP alliance utility to improve RC delays. Any equipotential keeps its name from connector to connector. In trouble case, buffers are inserted to respect this VHDL constraint. lax Parameter file description The lax file is common with other logic synthesis tools and is used for driving the synthesis process. See lax(5) manual for more detail. lax uses a lot of parameters to guide every step of the synthesis process. Some parameters are globally used (for example, optimization level whereas others are specifically used (load capacitance for the netlist optimization only). Here is the default lax file (see the user's manual for further information about the syntax of the '.lax' file): Optimization mode = 2 (50% area - 50% delay) Input impedance = 0 Output capacitance = 0 Delayed input = none Auxiliary signal saved = none Mapping with a standard cell library Every cell appearing in the directory defined by the environment variable MBK_TARGET_LIB may be used by boog since they are described as a '.vbe' file. There are some restrictions about the type of the cell used. Every cell has to have only one output. The cell must be characterized. The timing and area informations required by boog are specified in the \"generic\" clause of the \".vbe\" file.","Process Name":"boog","Link":"https:\/\/linux.die.net\/man\/1\/boog"}},{"Process":{"Description":"bookman compiles a set of man pages files specified by manfile arguments, or if no manfile is given, filenames are read from standard input.","Process Name":"bookman","Link":"https:\/\/linux.die.net\/man\/1\/bookman"}},{"Process":{"Description":"BOOM is used for the first step of the synthesis process. It optimizes a behavioural description using a Reduced Ordered Binary Decision Diagram representation of logic functions. The file filename is the input behavioural description and must be written in vbe(5) format. The resulting behavioural optimized description is saved with the name outname or input_name_o in vbe(5) format.","Process Name":"boom","Link":"https:\/\/linux.die.net\/man\/1\/boom"}},{"Process":{"Description":"The bouboule program draws spinning 3D blobs.","Process Name":"bouboule","Link":"https:\/\/linux.die.net\/man\/1\/bouboule"}},{"Process":{"Description":"It's very silly.","Process Name":"bouncingcow","Link":"https:\/\/linux.die.net\/man\/1\/bouncingcow"}},{"Process":{"Description":"Draws a box full of 3D bouncing balls that explode.","Process Name":"boxed","Link":"https:\/\/linux.die.net\/man\/1\/boxed"}},{"Process":{"Description":"Boxes is a text filter which can draw any kind of box around its input text. Box design choices range from simple boxes to complex ASCII art. A box can also be removed and repaired, even if it has been badly damaged by editing of the text inside. Since boxes may be open on any side, boxes can also be used to create regional comments in any programming language. New box designs of all sorts can easily be added and shared by appending to a free format configuration file. boxes was originally intended to be used with the vim(1) text editor, but it can be tied to any text editor which supports filters, as well as called from the command line as a standalone tool.","Process Name":"boxes","Link":"https:\/\/linux.die.net\/man\/1\/boxes"}},{"Process":{"Description":"The idea is to provide the user with all the features in-line, much like modern IDEs, but in a simple, lightweight package that can be run in a terminal window. * In-line syntax highlighting. Hilights commands as you type! * Readline-like autocomplete with suggestions displayed as you type. Press tab to complete expressions when there's only one suggestion. * Expected parameter list. This displays a list of parameters for any function you call. It uses the inspect module, then tries pydoc. * Rewind. This is a bit misleading, but it code that has been entered is remembered, and when you Rewind, it pops the last line and re-evaluates the entire code. This is error-prone, and mostly useful for defining classes and functions. * Pastebin code\/write to file. This posts the current buffer to a pastebin (paste.pocoo.org) or writes it to a file. * Flush curses screen to stdout. Unlike other curses apps, bpython dumps the screen data to stdout when you quit, so you see what you've done in the buffer of your terminal.","Process Name":"bpython","Link":"https:\/\/linux.die.net\/man\/1\/bpython"}},{"Process":{"Description":"The braid program draws random color-cycling braids around a circle.","Process Name":"braid","Link":"https:\/\/linux.die.net\/man\/1\/braid"}},{"Process":{"Description":"rancid is a perl(1) script which uses the login scripts (see clogin(1)) to login to a device, execute commands to display the configuration, etc, then filters the output for formatting, security, and so on. rancid's product is a file with the name of it's last argument plus the suffix .new. For example, hostname.new. There are complementary scripts for other platforms and\/or manufacturers that are supported by rancid(1). Briefly, these are: agmrancid Cisco Anomaly Guard Module (AGM) arancid Alteon WebOS switches arrancid Arista Networks devices brancid Bay Networks (nortel) cat5rancid Cisco catalyst switches cssrancid Cisco content services switches erancid ADC-kentrox EZ-T3 mux f10rancid Force10 f5rancid F5 BigIPs fnrancid Fortinet Firewalls francid Foundry and HP procurve OEMs of Foundry hrancid HP Procurve Switches htranicd Hitachi Routers jerancid Juniper Networks E-series jrancid Juniper Networks mrancid MRTd mrvrancid MRV optical switches nrancid Netscreen firewalls nsrancid Netscaler nxrancid Cisco Nexus boxes prancid Procket Networks rivrancid Riverstone rrancid Redback srancid SMC switch (some Dell OEMs) trancid Netopia sDSL\/T1 routers tntrancid Lucent TNT xrancid Extreme switches xrrancid Cisco IOS-XR boxes zrancid Zebra routing software The command-line options are as follows: -V Prints package name and version strings. -d Display debugging information. -l Display somewhat less debugging information. -f rancid should interpret the next argument as a filename which contains the output it would normally collect from the device ( hostname) with clogin(1).","Process Name":"brancid","Link":"https:\/\/linux.die.net\/man\/1\/brancid"}},{"Process":{"Description":"This manual page documents briefly the brasero command. rasero is a disc burning application. It is designed to be simple and easy to use. It allows to create data CD\/DVD, audio CD, to copy CD\/DVD and to burn images. It has some nices features, such as a song, image and video previewer. It can also search for files (thanks to beagle) and display a playlist and its contents.","Process Name":"brasero","Link":"https:\/\/linux.die.net\/man\/1\/brasero"}},{"Process":{"Description":"","Process Name":"break","Link":"https:\/\/linux.die.net\/man\/1\/break"}},{"Process":{"Description":"","Process Name":"breakpoint","Link":"https:\/\/linux.die.net\/man\/1\/breakpoint"}},{"Process":{"Description":"brltty is a background process (daemon) which provides access to the console screen (when in text mode) for a blind person using a refreshable braille display. It drives the braille display, and provides complete screen review functionality. Some speech capability has also been incorporated.","Process Name":"brltty","Link":"https:\/\/linux.die.net\/man\/1\/brltty"}},{"Process":{"Description":"This program is part of Netpbm(1). brushtopbm reads a Xerox doodle brush file as input. and produces a portable bitmap as output. Note that there is currently no pbmtobrush tool.","Process Name":"brushtopbm","Link":"https:\/\/linux.die.net\/man\/1\/brushtopbm"}},{"Process":{"Description":"bsdiff compares <                         oldfile> to <                                       newfile> and writes to <                                                                 patchfile> abinary patch suitable for use by bspatch(1).  When <                                                           oldfile> and <     newfile> are two versions of an executable program, the patches producedare on average a factor of five smaller than those produced by any otherbinary patch tool known to the author.\nbsdiff uses memory equal to 17 times the size of <                                                         oldfile>, andrequires an absolute minimum working set size of 8 times the size ofoldfile.","Process Name":"bsdiff","Link":"https:\/\/linux.die.net\/man\/1\/bsdiff"}},{"Process":{"Description":"bsdl2jtag converts BSDL files to JTAG files which can be used by jtag(1). bsdl2jtag reads from bsdlfile and produces its output in the file jtagfile.","Process Name":"bsdl2jtag","Link":"https:\/\/linux.die.net\/man\/1\/bsdl2jtag"}},{"Process":{"Description":"bsetbg is intended to provide a standard method for the Blackbox window manager to alter the background of the root window (although it will work with any other window manager as well). bsetbg acts as a wrapper both to bsetroot and to a flexible variety of third-party applications that it uses when handling images files.","Process Name":"bsetbg","Link":"https:\/\/linux.die.net\/man\/1\/bsetbg"}},{"Process":{"Description":"Bsetroot is a utility that can control the appearance of the root window in three ways: Either give it a solid color, or write a two color modula pattern to it, or render a gradient texture, based on two different colors. Bsetroot resembles xsetroot(1) in this functionality but it supports multiple screen displays, and gradient textures the same way as Blackbox does. It doesn't handle cursors etc. Bsetroot is part of the Blackbox package.","Process Name":"bsetroot","Link":"https:\/\/linux.die.net\/man\/1\/bsetroot"}},{"Process":{"Description":"Sh is the standard command interpreter for the system. The current version of sh is in the process of being changed to conform with the POSIX 1003.2 and 1003.2a specifications for the shell. This version has many features which make it appear similar in some respects to the Korn shell, but it is not a Korn shell clone (see ksh(1)). Only features designated by POSIX, plus a few Berkeley extensions, are being incorporated into this shell. We expect POSIX conformance by the time 4.4 BSD is released. This man page is not intended to be a tutorial or a complete specification of the shell. Overview The shell is a command that reads lines from either a file or the terminal, interprets them, and generally executes other commands. It is the program that is running when a user logs into the system (although a user can select a different shell with the chsh(1) command). The shell implements a language that has flow control constructs, a macro facility that provides a variety of features in addition to data storage. It incorporates many features to aid interactive use and has the advantage that the interpretative language is common to both interactive and non-interactive use (shell scripts). That is, commands can be typed directly to the running shell or can be put into a file and the file can be executed directly by the shell. Invocation If no args are present and if the standard input of the shell is connected to a terminal (or if the -i flag is set), and the -c option is not present, the shell is considered an interactive shell. An interactive shell generally prompts before each command and handles programming and command errors differently (as described below). When first starting, the shell inspects argument 0, and if it begins with a dash '-', the shell is also considered a login shell. This is normally done automatically by the system when the user first logs in. A login shell first reads commands from the files \/etc\/profile and .profile if they exist. If the environment variable ENV is set on entry to a shell, or is set in the .profile of a login shell, the shell next reads commands from the file named in ENV. Therefore, a user should place commands that are to be executed only at login time in the .profile file, and commands that are executed for every shell inside the ENV file. To set the ENV variable to some file, place the following line in your .profile of your home directory ENV=$HOME\/.shinit; export ENV substituting for ''.shinit'' any filename you wish. Since the ENV file is read for every invocation of the shell, including shell scripts and non-interactive shells, the following paradigm is useful for restricting commands in the ENV file to interactive invocations. Place commands within the ''case'' and ''esac'' below (these commands are described later): case $- in *i*) # commands for interactive use only ... esac If command line arguments besides the options have been specified, then the shell treats the first argument as the name of a file from which to read commands (a shell script), and the remaining arguments are set as the positional parameters of the shell ($1, $2, etc). Otherwise, the shell reads commands from its standard input. Argument List Processing All of the single letter options have a corresponding name that can be used as an argument to the -o option. The set -o name is provided next to the single letter option in the description below. Specifying a dash ''-'' turns the option on, while using a plus ''+'' disables the option. The following options can be set from the command line or with the set(1) builtin (described later).             -a allexport'                 Export all variables assigned to.(UNIMPLEMENTED for 4.4alpha) -c' Read commands from the command line. No commands will be read from the standard input. -C noclobber' Don't overwrite existing files with ''>''. (UNIMPLEMENTED for 4.4alpha) -e errexit' If not interactive, exit immediately if any untested command fails. The exit status of a command is considered to be explicitly tested if the command is used to control an if, elif, while, or until; or if the command is the left hand operand of an ''&&'' or ''||'' operator. -f noglob' Disable pathname expansion. -n noexec' If not interactive, read commands but do not execute them. This is useful for checking the syntax of shell scripts. -u nounset' Write a message to standard error when attempting to expand a variable that is not set, and if the shell is not interactive, exit immediately. (UNIMPLEMENTED for 4.4alpha) -v verbose' The shell writes its input to standard error as it is read. Useful for debugging. -x xtrace' Write each command to standard error (preceded by a '+ ') before it is executed. Useful for debugging. -q quietprofile If the -v or -x options have been set, do not apply them when reading initialization files, these being \/etc\/profile, .profile, and the file specified by the ENV environment variable. -I ignoreeof' Ignore EOF's from input when interactive. -i interactive Force the shell to behave interactively. -m monitor' Turn on job control (set automatically when interactive). -s stdin' Read commands from standard input (set automatically if no file arguments are present). This option has no effect when set after the shell has already started running (i.e. with set(1)). -V vi' Enable the built-in vi(1) command line editor (disables -E if it has been set). -E emacs' Enable the built-in emacs(1) command line editor (disables -V if it has been set). -b notify' Enable asynchronous notification of background job completion. (UNIMPLEMENTED for 4.4alpha) Lexical Structure The shell reads input in terms of lines from a file and breaks it up into words at whitespace (blanks and tabs), and at certain sequences of characters that are special to the shell called ''operators''. There are two types of operators: control operators and redirection operators (their meaning is discussed later). Following is a list of operators: Control operators: & && (); ;; | || <newline> Redirection operator: < > >| << >> <& >& <<- <> Quoting Quoting is used to remove the special meaning of certain characters or words to the shell, such as operators, whitespace, or keywords. There are three types of quoting: matched single quotes, matched double quotes, and backslash. Backslash A backslash preserves the literal meaning of the following character, with the exception of <newline>. A backslash preceding a <newline> is treated as a line continuation. Single Quotes Enclosing characters in single quotes preserves the literal meaning of all the characters (except single quotes, making it impossible to put single-quotes in a single-quoted string). Double Quotes Enclosing characters within double quotes preserves the literal meaning of all characters except dollarsign ($), backquote ('), and backslash (\\). The backslash inside double quotes is historically weird, and serves to quote only the following characters: $ ' \" \\ <newline>. Otherwise it remains literal. Reserved Words Reserved words are words that have special meaning to the shell and are recognized at the beginning of a line and after a control operator. The following are reserved words: ! elif fi while case else for then { } do done until if esac Their meaning is discussed later. Aliases An alias is a name and corresponding value set using the alias(1) builtin command. Whenever a reserved word may occur (see above), and after checking for reserved words, the shell checks the word to see if it matches an alias. If it does, it replaces it in the input stream with its value. For example, if there is an alias called ''lf'' with the value ''ls -F'', then the input: lf foobar <return> would become ls -F foobar <return> Aliases provide a convenient way for naive users to create shorthands for commands without having to learn how to create functions with arguments. They can also be used to create lexically obscure code. This use is discouraged. Commands The shell interprets the words it reads according to a language, the specification of which is outside the scope of this man page (refer to the BNF in the POSIX 1003.2 document). Essentially though, a line is read and if the first word of the line (or after a control operator) is not a reserved word, then the shell has recognized a simple command. Otherwise, a complex command or some other special construct may have been recognized. Simple Commands If a simple command has been recognized, the shell performs the following actions: 1. Leading words of the form ''name=value'' are stripped off andassigned to the environment of the simple command.Redirection operators and their arguments (as described below)are stripped off and saved for processing. 2. The remaining words are expanded as described in the section called ''Expansions'', and the first remaining word is considered the command name and the command is located. The remaining words are considered the arguments of the command. If no command name resulted, then the ''name=value'' variable assignments recognized in item 1 affect the current shell. 3. Redirections are performed as described in the next section. Redirections Redirections are used to change where a command reads its input or sends its output. In general, redirections open, close, or duplicate an existing reference to a file. The overall format used for redirection is: [n] redir-op file where redir-op is one of the redirection operators mentioned previously. Following is a list of the possible redirections. The [n] is an optional number, as in '3' (not '[3]', that refers to a file descriptor. [n]> file Redirect standard output (or n) to file. [n]>| file Same, but override the -C option. [n]>> file Append standard output (or n) to file. [n]< file Redirect standard input (or n) from file. [n1]<&n2' Duplicate standard input (or n1) from file descriptor n2. [n]<&-' Close standard input (or n). [n1]>&n2' Duplicate standard output (or n1) from n2. [n]>&-' Close standard output (or n). [n]<> file Open file for reading and writing on standard input (or n). The following redirection is often called a ''here-document''. [n]<< delimiter here-doc-text... delimiter All the text on successive lines up to the delimiter is saved away and made available to the command on standard input, or file descriptor n if it is specified. If the delimiter as specified on the initial line is quoted, then the here-doc-text is treated literally, otherwise the text is subjected to parameter expansion, command substitution, and arithmetic expansion (as described in the section on ''Expansions''). If the operator is ''<<-'' instead of ''<<'', then leading tabs in the here-doc-text are stripped. Search and Execution There are three types of commands: shell functions, builtin commands, and normal programs -- and the command is searched for (by name) in that order. They each are executed in a different way. When a shell function is executed, all of the shell positional parameters (except $0, which remains unchanged) are set to the arguments of the shell function. The variables which are explicitly placed in the environment of the command (by placing assignments to them before the function name) are made local to the function and are set to the values given. Then the command given in the function definition is executed. The positional parameters are restored to their original values when the command completes. This all occurs within the current shell. Shell builtins are executed internally to the shell, without spawning a new process. Otherwise, if the command name doesn't match a function or builtin, the command is searched for as a normal program in the filesystem (as described in the next section). When a normal program is executed, the shell runs the program, passing the arguments and the environment to the program. If the program is not a normal executable file (i.e., if it does not begin with the \"magic number\" whose ASCII representation is \"#!\", so execve(2) returns ENOEXEC then) the shell will interpret the program in a subshell. The child shell will reinitialize itself in this case, so that the effect will be as if a new shell had been invoked to handle the ad-hoc shell script, except that the location of hashed commands located in the parent shell will be remembered by the child. Note that previous versions of this document and the source code itself misleadingly and sporadically refer to a shell script without a magic number as a \"shell procedure\". Path Search When locating a command, the shell first looks to see if it has a shell function by that name. Then it looks for a builtin command by that name. If a builtin command is not found, one of two things happen: 1. Command names containing a slash are simply executed without performing any searches. 2. The shell searches each entry in PATH in turn for the command. The value of the PATH variable should be a series of entries separated by colons. Each entry consists of a directory name. The current directory may be indicated implicitly by an empty directory name, or explicitly by a single period. Command Exit Status Each command has an exit status that can influence the behavior of other shell commands. The paradigm is that a command exits with zero for normal or success, and non-zero for failure, error, or a false indication. The man page for each command should indicate the various exit codes and what they mean. Additionally, the builtin commands return exit codes, as does an executed shell function. Complex Commands Complex commands are combinations of simple commands with control operators or reserved words, together creating a larger complex command. More generally, a command is one of the following: \u2022 simple command \u2022 pipeline \u2022 list or compound-list \u2022 compound command \u2022 function definition Unless otherwise stated, the exit status of a command is that of the last simple command executed by the command. Pipelines A pipeline is a sequence of one or more commands separated by the control operator |. The standard output of all but the last command is connected to the standard input of the next command. The standard output of the last command is inherited from the shell, as usual. The format for a pipeline is: [!] command1 [| command2 ...] The standard output of command1 is connected to the standard input of command2. The standard input, standard output, or both of a command is considered to be assigned by the pipeline before any redirection specified by redirection operators that are part of the command. If the pipeline is not in the background (discussed later), the shell waits for all commands to complete. If the reserved word ! does not precede the pipeline, the exit status is the exit status of the last command specified in the pipeline. Otherwise, the exit status is the logical NOT of the exit status of the last command. That is, if the last command returns zero, the exit status is 1; if the last command returns greater than zero, the exit status is zero. Because pipeline assignment of standard input or standard output or both takes place before redirection, it can be modified by redirection. For example: $ command1 2>&1 | command2 sends both the standard output and standard error of command1 to the standard input of command2. A ; or <newline> terminator causes the preceding AND-OR-list (described next) to be executed sequentially; a & causes asynchronous execution of the preceding AND-OR-list. Note that unlike some other shells, each process in the pipeline is a child of the invoking shell (unless it is a shell builtin, in which case it executes in the current shell -- but any effect it has on the environment is wiped). Background Commands -- & If a command is terminated by the control operator ampersand (&), the shell executes the command asynchronously -- that is, the shell does not wait for the command to finish before executing the next command. The format for running a command in background is: command1 & [command2 & ...] If the shell is not interactive, the standard input of an asynchronous command is set to \/dev\/null. Lists -- Generally Speaking A list is a sequence of zero or more commands separated by newlines, semicolons, or ampersands, and optionally terminated by one of these three characters. The commands in a list are executed in the order they are written. If command is followed by an ampersand, the shell starts the command and immediately proceed onto the next command; otherwise it waits for the command to terminate before proceeding to the next one. Short-Circuit List Operators ''&&'' and ''||'' are AND-OR list operators. ''&&'' executes the first command, and then executes the second command iff the exit status of the first command is zero. ''||'' is similar, but executes the second command iff the exit status of the first command is nonzero. ''&&'' and ''||'' both have the same priority. Flow-Control Constructs -- if, while, for, case The syntax of the if command is if list then list [ elif list then list ] ... [ else list ] fi The syntax of the while command is while list\ndo   list\ndone The two lists are executed repeatedly while the exit status of the first list is zero. The until command is similar, but has the word until in place of while, which causes it to repeat until the exit status of the first list is zero. The syntax of the for command is for variable in word...\ndo   list\ndone The words are expanded, and then the list is executed repeatedly with the variable set to each word in turn. do and done may be replaced with ''{'' and ''}''. The syntax of the break and continue command is break [ num ]\ncontinue [ num ] Break terminates the num innermost for or while loops. Continue continues with the next iteration of the innermost loop. These are implemented as builtin commands. The syntax of the case command is case word in\npattern) list ;;\n...\nesac The pattern can actually be one or more patterns (see Shell Patterns described later), separated by ''|'' characters. Grouping Commands Together Commands may be grouped by writing either (list) or { list; } The first of these executes the commands in a subshell. Builtin commands grouped into a (list) will not affect the current shell. The second form does not fork another shell so is slightly more efficient. Grouping commands together this way allows you to redirect their output as though they were one program: { printf \" hello \" ; printf \" world\\n\" ; } > greeting Functions The syntax of a function definition is name () command A function definition is an executable statement; when executed it installs a function named name and returns an exit status of zero. The command is normally a list enclosed between ''{'' and ''}''. Variables may be declared to be local to a function by using a local command. This should appear as the first statement of a function, and the syntax is local [variable | -] ... Local is implemented as a builtin command. When a variable is made local, it inherits the initial value and exported and readonly flags from the variable with the same name in the surrounding scope, if there is one. Otherwise, the variable is initially unset. The shell uses dynamic scoping, so that if you make the variable x local to function f, which then calls function g, references to the variable x made inside g will refer to the variable x declared inside f, not to the global variable named x. The only special parameter than can be made local is ''-''. Making ''-'' local any shell options that are changed via the set command inside the function to be restored to their original values when the function returns. The syntax of the return command is return [exitstatus] It terminates the currently executing function. Return is implemented as a builtin command. Variables and Parameters The shell maintains a set of parameters. A parameter denoted by a name is called a variable. When starting up, the shell turns all the environment variables into shell variables. New variables can be set using the form name=value Variables set by the user must have a name consisting solely of alphabetics, numerics, and underscores - the first of which must not be numeric. A parameter can also be denoted by a number or a special character as explained below. Positional Parameters A positional parameter is a parameter denoted by a number (n > 0). The shell sets these initially to the values of its command line arguments that follow the name of the shell script. The set(1) builtin can also be used to set or reset them. Special Parameters A special parameter is a parameter denoted by one of the following special characters. The value of the parameter is listed next to its character. *'             Expands to the positional parameters, starting from one.When the expansion occurs within a double-quoted string itexpands to a single field with the value of each parameterseparated by the first character of the IFS variable, or bya <space> if IFS is unset. @' Expands to the positional parameters, starting from one. When the expansion occurs within double-quotes, each positional parameter expands as a separate argument. If there are no positional parameters, the expansion of @ generates zero arguments, even when @ is double-quoted. What this basically means, for example, is if $1 is ''abc'' and $2 is ''def ghi'', then \"$@\" expands to the two arguments: \"abc\" \"def ghi\" #' Expands to the number of positional parameters. ?' Expands to the exit status of the most recent pipeline. - (Hyphen.) Expands to the current option flags (the single-letter option names concatenated into a string) as specified on invocation, by the set builtin command, or implicitly by the shell. $' Expands to the process ID of the invoked shell. A subshell retains the same value of $ as its parent. !' Expands to the process ID of the most recent background command executed from the current shell. For a pipeline, the process ID is that of the last command in the pipeline. 0 (Zero.)' Expands to the name of the shell or shell script. Word Expansions This clause describes the various expansions that are performed on words. Not all expansions are performed on every word, as explained later. Tilde expansions, parameter expansions, command substitutions, arithmetic expansions, and quote removals that occur within a single word expand to a single field. It is only field splitting or pathname expansion that can create multiple fields from a single word. The single exception to this rule is the expansion of the special parameter @ within double-quotes, as was described above. The order of word expansion is: 1. Tilde Expansion, Parameter Expansion, Command Substitution, Arithmetic Expansion (these all occur at the same time). 2. Field Splitting is performed on fields generated by step (1) unless the IFS variable is null. 3. Pathname Expansion (unless set -f is in effect). 4. Quote Removal. The $ character is used to introduce parameter expansion, command substitution, or arithmetic evaluation. Tilde Expansion (substituting a user's home directory) A word beginning with an unquoted tilde character (~) is subjected to tilde expansion. All the characters up to a slash (\/) or the end of the word are treated as a username and are replaced with the user's home directory. If the username is missing (as in ~\/foobar), the tilde is replaced with the value of the HOME variable (the current user's home directory). Parameter Expansion The format for parameter expansion is as follows: ${expression} where expression consists of all characters until the matching ''}''. Any ''}'' escaped by a backslash or within a quoted string, and characters in embedded arithmetic expansions, command substitutions, and variable expansions, are not examined in determining the matching ''}''. The simplest form for parameter expansion is: ${parameter} The value, if any, of parameter is substituted. The parameter name or symbol can be enclosed in braces, which are optional except for positional parameters with more than one digit or when parameter is followed by a character that could be interpreted as part of the name. If a parameter expansion occurs inside double-quotes: 1. Pathname expansion is not performed on the results of the expansion. 2. Field splitting is not performed on the results of the expansion, with the exception of @. In addition, a parameter expansion can be modified by using one of the following formats. ${parameter:-word}' Use Default Values. If parameter is unset or null, the expansion of word is substituted; otherwise, the value of parameter is substituted. ${parameter:=word}' Assign Default Values. If parameter is unset or null, the expansion of word is assigned to parameter. In all cases, the final value of parameter is substituted. Only variables, not positional parameters or special parameters, can be assigned in this way. ${parameter:?[word]} Indicate Error if Null or Unset. If parameter is unset or null, the expansion of word (or a message indicating it is unset if word is omitted) is written to standard error and the shell exits with a nonzero exit status. Otherwise, the value of parameter is substituted. An interactive shell need not exit. ${parameter:+word}' Use Alternative Value. If parameter is unset or null, null is substituted; otherwise, the expansion of word is substituted. In the parameter expansions shown previously, use of the colon in the format results in a test for a parameter that is unset or null; omission of the colon results in a test for a parameter that is only unset. ${#parameter}' String Length. The length in characters of the value of parameter. The following four varieties of parameter expansion provide for substring processing. In each case, pattern matching notation (see Shell Patterns), rather than regular expression notation, is used to evaluate the patterns. If parameter is * or @, the result of the expansion is unspecified. Enclosing the full parameter expansion string in double-quotes does not cause the following four varieties of pattern characters to be quoted, whereas quoting characters within the braces has this effect. ${parameter%word}' Remove Smallest Suffix Pattern. The word is expanded to produce a pattern. The parameter expansion then results in parameter, with the smallest portion of the suffix matched by the pattern deleted. ${parameter%%word}' Remove Largest Suffix Pattern. The word is expanded to produce a pattern. The parameter expansion then results in parameter, with the largest portion of the suffix matched by the pattern deleted. ${parameter#word}' Remove Smallest Prefix Pattern. The word is expanded to produce a pattern. The parameter expansion then results in parameter, with the smallest portion of the prefix matched by the pattern deleted. ${parameter##word}' Remove Largest Prefix Pattern. The word is expanded to produce a pattern. The parameter expansion then results in parameter, with the largest portion of the prefix matched by the pattern deleted. Command Substitution Command substitution allows the output of a command to be substituted in place of the command name itself. Command substitution occurs when the command is enclosed as follows: $(command) or ( ''backquoted'' version): 'command' The shell expands the command substitution by executing command in a subshell environment and replacing the command substitution with the standard output of the command, removing sequences of one or more <newline>s at the end of the substitution. (Embedded <newline>s before the end of the output are not removed; however, during field splitting, they may be translated into <space>s, depending on the value of IFS and quoting that is in effect.) Arithmetic Expansion Arithmetic expansion provides a mechanism for evaluating an arithmetic expression and substituting its value. The format for arithmetic expansion is as follows: $((expression)) The expression is treated as if it were in double-quotes, except that a double-quote inside the expression is not treated specially. The shell expands all tokens in the expression for parameter expansion, command substitution, and quote removal. Next, the shell treats this as an arithmetic expression and substitutes the value of the expression. White Space Splitting (Field Splitting) After parameter expansion, command substitution, and arithmetic expansion the shell scans the results of expansions and substitutions that did not occur in double-quotes for field splitting and multiple fields can result. The shell treats each character of the IFS as a delimiter and use the delimiters to split the results of parameter expansion and command substitution into fields. Pathname Expansion (File Name Generation) Unless the -f flag is set, file name generation is performed after word splitting is complete. Each word is viewed as a series of patterns, separated by slashes. The process of expansion replaces the word with the names of all existing files whose names can be formed by replacing each pattern with a string that matches the specified pattern. There are two restrictions on this: first, a pattern cannot match a string containing a slash, and second, a pattern cannot match a string starting with a period unless the first character of the pattern is a period. The next section describes the patterns used for both Pathname Expansion and the case(1) command. Shell Patterns A pattern consists of normal characters, which match themselves, and meta-characters. The meta-characters are ''!'', ''*'', ''?'', and ''[''. These characters lose their special meanings if they are quoted. When command or variable substitution is performed and the dollar sign or back quotes are not double quoted, the value of the variable or the output of the command is scanned for these characters and they are turned into meta-characters. An asterisk (''*'') matches any string of characters. A question mark matches any single character. A left bracket (''['') introduces a character class. The end of the character class is indicated by a ('']''); if the '']'' is missing then the ''['' matches a ''['' rather than introducing a character class. A character class matches any of the characters between the square brackets. A range of characters may be specified using a minus sign. The character class may be complemented by making an exclamation point the first character of the character class. To include a '']'' in a character class, make it the first character listed (after the ''!'', if any). To include a minus sign, make it the first or last character listed Builtins This section lists the builtin commands which are builtin because they need to perform some operation that can't be performed by a separate process. In addition to these, there are several other commands that may be builtin for efficiency (e.g. printf(1), echo(1), test(1), etc). :' A null command that returns a 0 (true) exit value. . file The commands in the specified file are read and executed by the shell. alias [name[=string ...]] If name=string is specified, the shell defines the alias name with value string. If just name is specified, the value of the alias name is printed. With no arguments, the alias builtin prints the names and values of all defined aliases (see unalias). bg [job] ... Continue the specified jobs (or the current job if no jobs are given) in the background. command command arg... Execute the specified builtin command. (This is useful when you have a shell function with the same name as a builtin command.) cd [directory] Switch to the specified directory (default $HOME). If an entry for CDPATH appears in the environment of the cd command or the shell variable CDPATH is set and the directory name does not begin with a slash, then the directories listed in CDPATH will be searched for the specified directory. The format of CDPATH is the same as that of PATH. In an interactive shell, the cd command will print out the name of the directory that it actually switched to if this is different from the name that the user gave. These may be different either because the CDPATH mechanism was used or because a symbolic link was crossed. eval string... Concatenate all the arguments with spaces. Then re-parse and execute the command. exec [command arg...] Unless command is omitted, the shell process is replaced with the specified program (which must be a real program, not a shell builtin or function). Any redirections on the exec command are marked as permanent, so that they are not undone when the exec command finishes. exit [exitstatus] Terminate the shell process. If exitstatus is given it is used as the exit status of the shell; otherwise the exit status of the preceding command is used. export name... export -p The specified names are exported so that they will appear in the environment of subsequent commands. The only way to un-export a variable is to unset it. The shell allows the value of a variable to be set at the same time it is exported by writing export name=value With no arguments the export command lists the names of all exported variables. With the -p option specified the output will be formatted suitably for non-interactive use. fg [job] Move the specified job or the current job to the foreground. getopts optstring var The POSIX getopts command, not to be confused with the Bell Labs -derived getopt(1). The first argument should be a series of letters, each of which may be optionally followed by a colon to indicate that the option requires an argument. The variable specified is set to the parsed option. The getopts command deprecates the older getopt(1) utility due to its handling of arguments containing whitespace. The getopts builtin may be used to obtain options and their arguments from a list of parameters. When invoked, getopts places the value of the next option from the option string in the list in the shell variable specified by var and it's index in the shell variable OPTIND. When the shell is invoked, OPTIND is initialized to 1. For each option that requires an argument, the getopts builtin will place it in the shell variable OPTARG. If an option is not allowed for in the optstring, then OPTARG will be unset. optstring is a string of recognized option letters (see getopt(3)). If a letter is followed by a colon, the option is expected to have an argument which may or may not be separated from it by white space. If an option character is not found where expected, getopts will set the variable var to a ''?''; getopts will then unset OPTARG and write output to standard error. By specifying a colon as the first character of optstring all errors will be ignored. A nonzero value is returned when the last option is reached. If there are no remaining arguments, getopts will set var to the special option, ''--'', otherwise, it will set var to ''?''. The following code fragment shows how one might process the arguments for a command that can take the options [a] and [b], and the option [c], which requires an argument. while getopts abc: f do case $f in a | b) flag=$f;; c) carg=$OPTARG;; \\?) echo $USAGE; exit 1;; esac done shift 'expr $OPTIND - 1' This code will accept any of the following as equivalent: cmd -acarg file file\ncmd -a -c arg file file\ncmd -carg -a file file\ncmd -a -carg -- file file hash -rv command... The shell maintains a hash table which remembers the locations of commands. With no arguments whatsoever, the hash command prints out the contents of this table. Entries which have not been looked at since the last cd command are marked with an asterisk; it is possible for these entries to be invalid. With arguments, the hash command removes the specified commands from the hash table (unless they are functions) and then locates them. With the -v option, hash prints the locations of the commands as it finds them. The -r option causes the hash command to delete all the entries in the hash table except for functions. jobs This command lists out all the background processes which are children of the current shell process. pwd' Print the current directory. The builtin command may differ from the program of the same name because the builtin command remembers what the current directory is rather than recomputing it each time. This makes it faster. However, if the current directory is renamed, the builtin version of pwd will continue to print the old name for the directory. read [-p prompt] [-r] variable... The prompt is printed if the -p option is specified and the standard input is a terminal. Then a line is read from the standard input. The trailing newline is deleted from the line and the line is split as described in the section on word splitting above, and the pieces are assigned to the variables in order. At least one variable must be specified. If there are more pieces than variables, the remaining pieces (along with the characters in IFS that separated them) are assigned to the last variable. If there are more variables than pieces, the remaining variables are assigned the null string. The read builtin will indicate success unless EOF is encountered on input, in which case failure is returned. By default, unless the -r option is specified, the backslash ''\\'' acts as an escape character, causing the following character to be treated literally. If a backslash is followed by a newline, the backslash and the newline will be deleted. readonly name... readonly -p The specified names are marked as read only, so that they cannot be subsequently modified or unset. The shell allows the value of a variable to be set at the same time it is marked read only by writing readonly name=value With no arguments the readonly command lists the names of all read only variables. With the -p option specified the output will be formatted suitably for non-interactive use. set [ { -options | +options | -- }] arg... The set command performs three different functions. With no arguments, it lists the values of all shell variables. If options are given, it sets the specified option flags, or clears them as described in the section called Argument List Processing. The third use of the set command is to set the values of the shell's positional parameters to the specified args. To change the positional parameters without changing any options, use ''--'' as the first argument to set. If no args are present, the set command will clear all the positional parameters (equivalent to executing ''shift $#''.) setvar variable value Assigns value to variable. (In general it is better to write variable=value rather than using setvar. setvar is intended to be used in functions that assign values to variables whose names are passed as parameters.) shift [n] Shift the positional parameters n times. A shift sets the value of $1 to the value of $2, the value of $2 to the value of $3, and so on, decreasing the value of $# by one. If n is greater than the number of positional parameters, shift will issue an error message, and exit with return status 2. times Print the accumulated user and system times for the shell and for processes run from the shell. The return status is 0. trap action signal... Cause the shell to parse and execute action when any of the specified signals are received. The signals are specified by signal number. If signal is 0, the action is executed when the shell exits. action may be null or ''-''; the former causes the specified signal to be ignored and the latter causes the default action to be taken. When the shell forks off a subshell, it resets trapped (but not ignored) signals to the default action. The trap command has no effect on signals that were ignored on entry to the shell. type [name ...] Interpret each name as a command and print the resolution of the command search. Possible resolutions are: shell keyword, alias, shell builtin, command, tracked alias and not found. For aliases the alias expansion is printed; for commands and tracked aliases the complete pathname of the command is printed. ulimit [-H | -S] [-a | -tfdscmlpn [value]] Inquire about or set the hard or soft limits on processes or set new limits. The choice between hard limit (which no process is allowed to violate, and which may not be raised once it has been lowered) and soft limit (which causes processes to be signaled but not necessarily killed, and which may be raised) is made with these flags: -H' set or inquire about hard limits -S' set or inquire about soft limits. If neither -H nor -S is specified, the soft limit is displayed or both limits are set. If both are specified, the last one wins. The limit to be interrogated or set, then, is chosen by specifying any one of these flags: -a' show all the current limits -t' show or set the limit on CPU time (in seconds) -f' show or set the limit on the largest file that can be created (in 512-byte blocks) -d' show or set the limit on the data segment size of a process (in kilobytes) -s' show or set the limit on the stack size of a process (in kilobytes) -c' show or set the limit on the largest core dump size that can be produced (in 512-byte blocks) -m' show or set the limit on the total physical memory that can be in use by a process (in kilobytes) -l' show or set the limit on how much memory a process can lock with mlock(2) (in kilobytes) -p' show or set the limit on the number of processes this user can have at one time -n' show or set the limit on the number files a process can have open at once If none of these is specified, it is the limit on file size that is shown or set. If value is specified, the limit is set to that number; otherwise the current limit is displayed. Limits of an arbitrary process can be displayed or set using the sysctl(8) utility. umask [mask] Set the value of umask (see umask(2)) to the specified octal value. If the argument is omitted, the umask value is printed. unalias [-a] [name] If name is specified, the shell removes that alias. If -a is specified, all aliases are removed. unset name... The specified variables and functions are unset and unexported. If a given name corresponds to both a variable and a function, both the variable and the function are unset. wait [job] Wait for the specified job to complete and return the exit status of the last process in the job. If the argument is omitted, wait for all jobs to complete and the return an exit status of zero.","Process Name":"bsh","Link":"https:\/\/linux.die.net\/man\/1\/bsh"}},{"Process":{"Description":"bsmtp is a simple mail user agent designed to permit more flexibility than the standard mail programs typically found on Unix systems, and to ease portability. It can even run on Windows machines. It is used by the Director daemon to send notifications and requests to the operator.","Process Name":"bsmtp","Link":"https:\/\/linux.die.net\/man\/1\/bsmtp"}},{"Process":{"Description":"The bsod program is the finest in personal computer emulation. bsod steps through a set of screens, each one a recreation of a different failure mode of an operating system. Systems depicted include Windows 3.1, Windows 95, Windows NT, MS-DOS, AmigaDOS 1.3, Linux, SCO UNIX, BSD UNIX, HPUX, Solaris, VMS, HVX\/GCOS6, IBM OS\/390, MacOS (MacsBug, Bomb, Sad Mac, and OSX), Atari ST, Apple ][+, and NCD X Terminals.","Process Name":"bsod","Link":"https:\/\/linux.die.net\/man\/1\/bsod"}},{"Process":{"Description":"usage: bsondump [options] <bson filename> options: --help produce help message --version show version information -v [ --verbose ] be more verbose (include multiple times for more verbosity e.g. -vvvvv) --objcheck validate object before inserting --filter arg filter to apply before inserting --type arg (=json) type of output: json,debug","Process Name":"bsondump","Link":"https:\/\/linux.die.net\/man\/1\/bsondump"}},{"Process":{"Description":"bspatch generates <                           newfile> from <                                           oldfile> and <                                                           patchfile> where <     patchfile> is a binary patch built by bsdiff(1).\nbspatch uses memory equal to the size of <                                                 oldfile> plus the size of <     newfile>, but can tolerate a very small working set without a dramaticloss of performance.","Process Name":"bspatch","Link":"https:\/\/linux.die.net\/man\/1\/bspatch"}},{"Process":{"Description":"bsqldb is a utility program distributed with FreeTDS. bsqldb is a non-interactive equivalent of the \"isql\" utility programs distributed by Sybase and Microsoft. Like them, bsqldb uses the command \"go\" on a line by itself as a separator between batches. The last batch need not be followed by \"go\". bsqldb makes use of the DB-Library API provided by FreeTDS. This API is of course also available to application developers.","Process Name":"bsqldb","Link":"https:\/\/linux.die.net\/man\/1\/bsqldb"}},{"Process":{"Description":"bsqlodbc is a utility program distributed with FreeTDS. bsqlodbc is a non-interactive equivalent of the \"isql\" utility programs distributed by Sybase and Microsoft. Like them, bsqlodbc uses the command \"go\" on a line by itself as a separator between batches. The last batch need not be followed by \"go\". bsqlodbc makes use of the ODBC API provided by FreeTDS. This API is of course also available to application developers.","Process Name":"bsqlodbc","Link":"https:\/\/linux.die.net\/man\/1\/bsqlodbc"}},{"Process":{"Description":"bssh\/bvnc\/bshell browses for SSH\/VNC servers on the local network, shows them in a GUI for the user to select one and finally calls ssh\/vncviewer after a selection was made. If the binary is called as bssh only ssh servers will be shown. If the binary is called as bvnc only VNC servers will be shown. If the binary is called as bshell both VNC and SSH servers are shown.","Process Name":"bssh","Link":"https:\/\/linux.die.net\/man\/1\/bssh"}},{"Process":{"Description":"bti sends a tweet message to twitter.com or identi.ca.","Process Name":"bti","Link":"https:\/\/linux.die.net\/man\/1\/bti"}},{"Process":{"Description":"bti-shrink-urls converts URLs to a shorter form using a web service. Currently http:\/\/2tu.us\/ (default) and http:\/\/bit.ly \/ http:\/\/j.mp are supported.","Process Name":"bti-shrink-urls","Link":"https:\/\/linux.die.net\/man\/1\/bti-shrink-urls"}},{"Process":{"Description":"btparser is a command line tool that analyzes backtraces produced by GDB and provides their textual representation useful for crash duplication detection. By default, btparser prints the backtrace tree created by parsing the input file.","Process Name":"btparser","Link":"https:\/\/linux.die.net\/man\/1\/btparser"}},{"Process":{"Description":"btt is a post-processing tool for the block layer IO tracing tool called blktrace(8). As noted in its documentation, blktrace is a block layer IO tracing mechanism which provides detailed information about request queue operations up to user space. btt will take in binary dump data from blkparse, and analyse the events, producing a series of output from the analysis. It will also build .dat files containing \"range data\" -- showing things like Q activity (periods of time while Q events are being produced), C activity (likewise for command completions), and etc. Included with the distribution is a simple 3D plotting utility, bno_plot, which can plot the block numbers btt outputs if the -B option is specified. The display will display each IO generated, with the time (seconds) along the X-axis, the block number (start) along the Y-axis and the number of blocks transferred in the IO represented along the Z-axis.","Process Name":"btt","Link":"https:\/\/linux.die.net\/man\/1\/btt"}},{"Process":{"Description":"Draws a stream of rising, undulating 3D bubbles, rising toward the top of the screen, with nice specular reflections.","Process Name":"bubble3d","Link":"https:\/\/linux.die.net\/man\/1\/bubble3d"}},{"Process":{"Description":"bubbles gives a simple display of the roll status of a set of zones listed in a rollrec file. In contrast, blinkenlights gives a detailed display of the roll status of a set of zones. bubbles gives very little control over rollerd, the way blinkenlights does. bubbles can halt rollerd's execution only. A rollrec file contains one or more rollrec records. These records are used by the DNSSEC-Tools rollover utilities (rollerd, etc.) to describe zones' rollover states. Each zone's rollrec record contains such information as the zone file, the rollover phase, and logging level. rollrec files are text files. When bubbles starts, a window is created that has \"bubbles\" for each zone with a rollrec record in the given rollrec file. (Clicking on a bubble doesn't do anything.) By default, all zones with a display flag set on will be shown in the bubbles window. Options may be given to modify this behavior. The zone bubbles are color-coded according to roll-over state. The default colors are: * green: not in roll-over * yellow: in ZSK roll-over * red: in KSK roll-over These colors may be specified by the user via command-line options. In building the bubble window, bubbles window defaults to creating a square window. This may be overridden by specifying the number of columns, using the -columns option.","Process Name":"bubbles","Link":"https:\/\/linux.die.net\/man\/1\/bubbles"}},{"Process":{"Description":"The bucardo_ctl script is the main interaction to a running Bucardo instance. It can be used to start and stop Bucardo, add new items, kick syncs, and even install and upgrade Bucardo itself. For more complete documentation, please view the wiki at: http:\/\/bucardo.org\/","Process Name":"bucardo_ctl","Link":"https:\/\/linux.die.net\/man\/1\/bucardo_ctl"}},{"Process":{"Description":"Buffer reads from standard input reblocking to the given blocksize and writes each block to standard output. Internally buffer is a pair of processes communicating via a large circular queue held in shared memory. The reader process only has to block when the queue is full and the writer process when the queue is empty. Buffer is designed to try and keep the writer side continuously busy so that it can stream when writing to tape drives. When used to write tapes with an intervening network buffer can result in a considerable increase in throughput. The default settings for buffer are normally good enough. If you are a heavy tape user then it is worth your while trying out various different combinations of options. In particular running a buffer at both ends of the pipe can provide a substantial increase (see last example below).","Process Name":"buffer","Link":"https:\/\/linux.die.net\/man\/1\/buffer"}},{"Process":{"Description":"bug-buddy is a graphical bug reporting tool for GNOME. The goal of Bug Buddy is to make reporting bugs very simple and easy for the user, while making the reports themselves more useful and informative for the developer.","Process Name":"bug-buddy","Link":"https:\/\/linux.die.net\/man\/1\/bug-buddy"}},{"Process":{"Description":"bugpoint narrows down the source of problems in LLVM tools and passes. It can be used to debug three types of failures: optimizer crashes, miscompilations by optimizers, or bad native code generation (including problems in the static and JIT compilers). It aims to reduce large test cases to small, useful ones. For more information on the design and inner workings of bugpoint, as well as advice for using bugpoint, see llvm\/docs\/Bugpoint.html in the LLVM distribution.","Process Name":"bugpoint","Link":"https:\/\/linux.die.net\/man\/1\/bugpoint"}},{"Process":{"Description":"Bugz is a program which gives you access to the features of the bugzilla bug tracking system from the command line. This man page is a stub; the bugz program has extensive built in help. bugz -h will show the help for the global options and bugz [subcommand] -h will show the help for a specific subcommand.","Process Name":"bugz","Link":"https:\/\/linux.die.net\/man\/1\/bugz"}},{"Process":{"Description":"bugzilla is a command-line utility that allows access to the XML-RPC interface provided by Bugzilla. command is one of: * login - log into the given bugzilla instance * new - create a new bug * query - search for bugs matching given criteria * modify - modify existing bugs * attach - attach files to existing bugs, or get attachments * info - get info about the given bugzilla instance","Process Name":"bugzilla","Link":"https:\/\/linux.die.net\/man\/1\/bugzilla"}},{"Process":{"Description":"Small utility to build a Java CLASSPATH with the named JARs. The CLASSPATH is returned to standard output.","Process Name":"build-classpath","Link":"https:\/\/linux.die.net\/man\/1\/build-classpath"}},{"Process":{"Description":"Build a JAR repository in the named directory by copying files or creating symbolic links","Process Name":"build-jar-repository","Link":"https:\/\/linux.die.net\/man\/1\/build-jar-repository"}},{"Process":{"Description":"buildrealms helps in setting up a realms environment for use by dtrealms. buildrealms creates the required file hierarchies for each realm, it moves a realm's files to their appropriate place in the hierarchy, and it updates several files for the final destination. The realm hierarchies are built in a staging area, which will hold the files for all the realms. These are rollrec files, keyrec files, key files, configuration files, log files, and anything else needed for by DNSSEC-Tools to manage key rollover. After buildrealms creates these files, the user should check the files to ensure that they are correct. The files and directories in the staging then must be manually moved to the final directory. It is from this directory that dtrealms will manage the various realms. If the final directory isn't specified (via an option), then the directory in which buildrealms was executed will be the final directory. buildrealms uses a realms file to control how it builds the realms environment. This realm entries in this file have a hoard field, which is only used by buildrealms. For each realm, this field's value is a directory which holds the files needed by that particular realm. After building that realm, buildrealms removes the hoard entry from that realm record. After all the realms have been built, a copy of this realms file is moved into the staging area. There are two operations buildrealms currently provides. These operations are in support of creating and maintaining a DNSSEC-Tools realms environment. This documentation describes the operations individually. Realms Environment Creation The create command builds the whole realms environment. The realm file hierarchies are built in the staging area. After buildrealms creates these files, the user should check the files to ensure that they are correct. The files and directories in the staging then must be manually moved to the final directory. If the final directory isn't specified (via an option), then the directory in which buildrealms was executed will be the final directory. buildrealms takes the following actions when given the create command: \u2022 A file hierarchy is created for each realm. \u2022 A DNSSEC-Tools configuration file is put in each realm's hierarchy. If the -config option is given, then the specified configuration file will be copied to each realm. If it isn't given, then each realm's hoard will be searched for a file whose name ends with .conf. The first such file found will be used for that realm only. If such a file is not found, then the system-wide DNSSEC-Tools configuration file will be used for that realm. \u2022 The realm's rollrec, keyrec, zone, and key files are moved into the hierarchy. The rollrec file is named in the realms file. The keyrec and signed zone files are listed in the rollrec file. The unsigned zone files and key files are listed in the keyrec file. \u2022 A key archive is created for each realm's existing, expired keys. The key archive is placed in the realm's state directory in the staging area. Archived keys, as listed in the keyrec files, are moved to this key archive. \u2022 Paths in several files are adjusted for the new hierarchy and the realm's final destination. These paths include archived keys in the realm's keyrec files, the key archive and rollerd log files in the realm's DNSSEC-Tools configuration file, and key directories in the keyrec files. Realms Hierarchy Creation The trees command builds the basic directory hierarchy for each realm in the staging area. However, no other files or directories are copied or moved in to the staging area.. The following directories are created for each realm: \u2022 configuration directory - This holds the dnssec-tools directory. \u2022 dnssec-tools directory - This will hold the DNSSEC-Tools configuration file. \u2022 state directory - This will hold the realm's state information, including the key archive. \u2022 realm directory - This will hold the realm's rollrec file, the keyrec files, the zone files (signed and unsigned), and the key files.","Process Name":"buildrealms","Link":"https:\/\/linux.die.net\/man\/1\/buildrealms"}},{"Process":{"Description":"","Process Name":"builtin","Link":"https:\/\/linux.die.net\/man\/1\/builtin"}},{"Process":{"Description":"","Process Name":"builtins","Link":"https:\/\/linux.die.net\/man\/1\/builtins"}},{"Process":{"Description":"The bumps program takes an image and exposes small, distorted sections of it as if through an odd wandering spotlight beam. The image that it manipulates will be grabbed from the portion of the screen underlying the window, or from the system's video input, or from a random file on disk, as indicated by the grabDesktopImages, grabVideoFrames, and chooseRandomImages options in the ~\/.xscreensaver file; see xscreensaver-demo(1) for more details.","Process Name":"bumps","Link":"https:\/\/linux.die.net\/man\/1\/bumps"}},{"Process":{"Description":"bzip2 compresses files using the Burrows-Wheeler block sorting text compression algorithm, and Huffman coding. Compression is generally considerably better than that achieved by more conventional LZ77\/LZ78-based compressors, and approaches the performance of the PPM family of statistical compressors. The command-line options are deliberately very similar to those of GNU gzip, but they are not identical. bzip2 expects a list of file names to accompany the command-line flags. Each file is replaced by a compressed version of itself, with the name \"original_name.bz2\". Each compressed file has the same modification date, permissions, and, when possible, ownership as the corresponding original, so that these properties can be correctly restored at decompression time. File name handling is naive in the sense that there is no mechanism for preserving original file names, permissions, ownerships or dates in filesystems which lack these concepts, or have serious file name length restrictions, such as MS-DOS. bzip2 and bunzip2 will by default not overwrite existing files. If you want this to happen, specify the -f flag. If no file names are specified, bzip2 compresses from standard input to standard output. In this case, bzip2 will decline to write compressed output to a terminal, as this would be entirely incomprehensible and therefore pointless. bunzip2 (or bzip2 -d) decompresses all specified files. Files which were not created by bzip2 will be detected and ignored, and a warning issued. bzip2 attempts to guess the filename for the decompressed file from that of the compressed file as follows: filename.bz2 becomes filename filename.bz becomes filename filename.tbz2 becomes filename.tar filename.tbz becomes filename.tar anyothername becomes anyothername.out If the file does not end in one of the recognised endings, .bz2, .bz, .tbz2 or .tbz, bzip2 complains that it cannot guess the name of the original file, and uses the original name with .out appended. As with compression, supplying no filenames causes decompression from standard input to standard output. bunzip2 will correctly decompress a file which is the concatenation of two or more compressed files. The result is the concatenation of the corresponding uncompressed files. Integrity testing (-t) of concatenated compressed files is also supported. You can also compress or decompress files to the standard output by giving the -c flag. Multiple files may be compressed and decompressed like this. The resulting outputs are fed sequentially to stdout. Compression of multiple files in this manner generates a stream containing multiple compressed file representations. Such a stream can be decompressed correctly only by bzip2 version 0.9.0 or later. Earlier versions of bzip2 will stop after decompressing the first file in the stream. bzcat (or bzip2 -dc) decompresses all specified files to the standard output. bzip2 will read arguments from the environment variables BZIP2 and BZIP, in that order, and will process them before any arguments read from the command line. This gives a convenient way to supply default arguments. Compression is always performed, even if the compressed file is slightly larger than the original. Files of less than about one hundred bytes tend to get larger, since the compression mechanism has a constant overhead in the region of 50 bytes. Random data (including the output of most file compressors) is coded at about 8.05 bits per byte, giving an expansion of around 0.5%. As a self-check for your protection, bzip2 uses 32-bit CRCs to make sure that the decompressed version of a file is identical to the original. This guards against corruption of the compressed data, and against undetected bugs in bzip2 (hopefully very unlikely). The chances of data corruption going undetected is microscopic, about one chance in four billion for each file processed. Be aware, though, that the check occurs upon decompression, so it can only tell you that something is wrong. It can't help you recover the original uncompressed data. You can use bzip2recover to try to recover data from damaged files. Return values: 0 for a normal exit, 1 for environmental problems (file not found, invalid flags, I\/O errors, &c), 2 to indicate a corrupt compressed file, 3 for an internal consistency error (eg, bug) which caused bzip2 to panic.","Process Name":"bunzip2","Link":"https:\/\/linux.die.net\/man\/1\/bunzip2"}},{"Process":{"Description":"BusyBox combines tiny versions of many common UNIX utilities into a single small executable. It provides minimalist replacements for most of the utilities you usually find in GNU coreutils, util-linux, etc. The utilities in BusyBox generally have fewer options than their full-featured GNU cousins; however, the options that are included provide the expected functionality and behave very much like their GNU counterparts. BusyBox has been written with size-optimization and limited resources in mind. It is also extremely modular so you can easily include or exclude commands (or features) at compile time. This makes it easy to customize your embedded systems. To create a working system, just add \/dev, \/etc, and a Linux kernel. BusyBox provides a fairly complete POSIX environment for any small or embedded system. BusyBox is extremely configurable. This allows you to include only the components you need, thereby reducing binary size. Run 'make config' or 'make menuconfig' to select the functionality that you wish to enable. Then run 'make' to compile BusyBox using your configuration. After the compile has finished, you should use 'make install' to install BusyBox. This will install the 'bin\/busybox' binary, in the target directory specified by CONFIG_PREFIX . CONFIG_PREFIX can be set when configuring BusyBox, or you can specify an alternative location at install time (i.e., with a command line like 'make CONFIG_PREFIX=\/tmp\/foo install'). If you enabled any applet installation scheme (either as symlinks or hardlinks), these will also be installed in the location pointed to by CONFIG_PREFIX .","Process Name":"busybox","Link":"https:\/\/linux.die.net\/man\/1\/busybox"}},{"Process":{"Description":"BusyBox combines tiny versions of many common UNIX utilities into a single small executable. It provides minimalist replacements for most of the utilities you usually find in GNU coreutils, util-linux, etc. The utilities in BusyBox generally have fewer options than their full-featured GNU cousins; however, the options that are included provide the expected functionality and behave very much like their GNU counterparts. BusyBox has been written with size-optimization and limited resources in mind. It is also extremely modular so you can easily include or exclude commands (or features) at compile time. This makes it easy to customize your embedded systems. To create a working system, just add \/dev, \/etc, and a Linux kernel. BusyBox provides a fairly complete POSIX environment for any small or embedded system. BusyBox is extremely configurable. This allows you to include only the components you need, thereby reducing binary size. Run 'make config' or 'make menuconfig' to select the functionality that you wish to enable. Then run 'make' to compile BusyBox using your configuration. After the compile has finished, you should use 'make install' to install BusyBox. This will install the 'bin\/busybox' binary, in the target directory specified by CONFIG_PREFIX . CONFIG_PREFIX can be set when configuring BusyBox, or you can specify an alternative location at install time (i.e., with a command line like 'make CONFIG_PREFIX=\/tmp\/foo install'). If you enabled any applet installation scheme (either as symlinks or hardlinks), these will also be installed in the location pointed to by CONFIG_PREFIX .","Process Name":"busybox.petitboot","Link":"https:\/\/linux.die.net\/man\/1\/busybox.petitboot"}},{"Process":{"Description":"Bvi stands for \"Binary VIsual editor\". Bvi is a screen oriented editor for binary files; its command set is based on that of the vi(1) text editor. As a binary editor does not have the concept of \"lines\" there are differences from Vi commands wherever the latter are line orientate.","Process Name":"bvi","Link":"https:\/\/linux.die.net\/man\/1\/bvi"}},{"Process":{"Description":"bssh\/bvnc\/bshell browses for SSH\/VNC servers on the local network, shows them in a GUI for the user to select one and finally calls ssh\/vncviewer after a selection was made. If the binary is called as bssh only ssh servers will be shown. If the binary is called as bvnc only VNC servers will be shown. If the binary is called as bshell both VNC and SSH servers are shown.","Process Name":"bvnc","Link":"https:\/\/linux.die.net\/man\/1\/bvnc"}},{"Process":{"Description":"BWA is a fast light-weighted tool that aligns relatively short sequences (queries) to a sequence database (targe), such as the human reference genome. It implements two different algorithms, both based on Burrows-Wheeler Transform (BWT). The first algorithm is designed for short queries up to ~200bp with low error rate (<3%). It does gapped global alignment w.r.t. queries, supports paired-end reads, and is one of the fastest short read alignment algorithms to date while also visiting suboptimal hits. The second algorithm, BWA-SW, is designed for long reads with more errors. It performs heuristic Smith-Waterman-like alignment to find high-scoring local hits (and thus chimera). On low-error short queries, BWA-SW is slower and less accurate than the first algorithm, but on long queries, it is better. For both algorithms, the database file in the FASTA format must be first indexed with the 'index' command, which typically takes a few hours. The first algorithm is implemented via the 'aln' command, which finds the suffix array (SA) coordinates of good hits of each individual read, and the 'samse\/sampe' command, which converts SA coordinates to chromosomal coordinate and pairs reads (for 'sampe'). The second algorithm is invoked by the 'bwasw' command. It works for single-end reads only.","Process Name":"bwa","Link":"https:\/\/linux.die.net\/man\/1\/bwa"}},{"Process":{"Description":"bwm-ng can be used to monitor the current bandwidth of all or some specific network interfaces or disks (or partitions). It shows total of in and out as well as total of all interfaces\/devices. Several different output methods are supported (curses, curses2, plain, csv and html). bwm-ng is not limited in the number of interfaces or disks and can handle new ones dynamically while its running or hide those which are not up.","Process Name":"bwm-ng","Link":"https:\/\/linux.die.net\/man\/1\/bwm-ng"}},{"Process":{"Description":"Yacc reads the grammar specification in the file filename and generates an LALR(1) parser for it. The parsers consist of a set of LALR(1) parsing tables and a driver routine written in the C programming language. Yacc normally writes the parse tables and the driver routine to the file y.tab.c. The following options are available: -b file_prefix The -b option changes the prefix prepended to the output file names to the string denoted by file_prefix. The default prefix is the character y. -d The -d option causes the header file y.tab.h to be written. -g The -g option causes a graphical description of the generated LALR(1) parser to be written to the file y.dot in graphviz format, ready to be processed by dot(1). -l If the -l option is not specified, yacc will insert #line directives in the generated code. The #line directives let the C compiler relate errors in the generated code to the user's original code. If the -l option is specified, yacc will not insert the #line directives. #line directives specified by the user will be retained. -o output_file specify the filename for the parser file. If this option is not given, the output filename is the file prefix concatenated with the file suffix, e.g., y.tab.c. This overrides the -p option. -p symbol_prefix The -p option changes the prefix prepended to yacc-generated symbols to the string denoted by symbol_prefix. The default prefix is the string yy. -r The -r option causes yacc to produce separate files for code and tables. The code file is named y.code.c, and the tables file is named y.tab.c. -t The -t option changes the preprocessor directives generated by yacc so that debugging statements will be incorporated in the compiled code. -v The -v option causes a human-readable description of the generated parser to be written to the file y.output. -V print the version number to the standard output.","Process Name":"byacc","Link":"https:\/\/linux.die.net\/man\/1\/byacc"}},{"Process":{"Description":"byobu is a script that launches a text based window manager (either screen(1) or tmux(1)) in the byobu configuration. This enables the display of system information and status notifications within two lines at the bottom of the screen session. It also enables multiple tabbed terminal sessions, accessible through simple keystrokes. byobu currently defaults to using tmux(1) (if present) as the backend, however, this can be overriden with the byobu-select-backend(1) utility. Note that BYOBU_CONFIG_DIR=$XDG_CONFIG_HOME\/byobu if defined, and $HOME\/.byobu otherwise.","Process Name":"byobu","Link":"https:\/\/linux.die.net\/man\/1\/byobu"}},{"Process":{"Description":"byobu-config is an application that can configure a number of options available in the byobu utility. The menu provided by the byobu should be self-explanatory.","Process Name":"byobu-config","Link":"https:\/\/linux.die.net\/man\/1\/byobu-config"}},{"Process":{"Description":"byobu-ctrl-a is an interactive program that allows a user to configure the behavior of the 'ctrl-a' key sequence. Traditional GNU screen(1) uses ctrl-a as its escape character, while GNU emacs(1) uses ctrl-a to move the cursor to the beginning of the line. This conflict has caused unending amounts of grief among Screen, Byobu, and Emacs-mode users. Thus, this program exists to allow each user to choose the behavior of ctrl-a in their local environment. http:\/\/launchpad.net\/byobu","Process Name":"byobu-ctrl-a","Link":"https:\/\/linux.die.net\/man\/1\/byobu-ctrl-a"}},{"Process":{"Description":"byobu-enable will do two things: 1) run byobu-launcher-install(1) to configure byobu(1) to launch automatically on login 2) then launch byobu(1) byobu-disable will simply run byobu-launcher-uninstall(1).","Process Name":"byobu-disable","Link":"https:\/\/linux.die.net\/man\/1\/byobu-disable"}},{"Process":{"Description":"byobu-enable will do two things: 1) run byobu-launcher-install(1) to configure byobu(1) to launch automatically on login 2) then launch byobu(1) byobu-disable will simply run byobu-launcher-uninstall(1).","Process Name":"byobu-enable","Link":"https:\/\/linux.die.net\/man\/1\/byobu-enable"}},{"Process":{"Description":"The byobu-export utility is now deprecated. To install byobu on a system for which byobu is not packaged, or where you are not the root user, simply: * Download the latest release (>= 3.0) from: https:\/\/launchpad.net\/byobu\/+download * And follow the instructions in the README","Process Name":"byobu-export","Link":"https:\/\/linux.die.net\/man\/1\/byobu-export"}},{"Process":{"Description":"byobu-janitor is script for cleaning environment after upgrades, it consists from several tasks where aim is to ensure that environment is ready for new version of byobu.","Process Name":"byobu-janitor","Link":"https:\/\/linux.die.net\/man\/1\/byobu-janitor"}},{"Process":{"Description":"byobu-launcher is a simple application that will launch screen(1) in a byobu(1) configuration, reconnecting to an existing detached session (if available).","Process Name":"byobu-launch","Link":"https:\/\/linux.die.net\/man\/1\/byobu-launch"}},{"Process":{"Description":"byobu-launcher is a simple application that will launch screen(1) in a byobu(1) configuration, reconnecting to an existing detached session (if available).","Process Name":"byobu-launcher","Link":"https:\/\/linux.die.net\/man\/1\/byobu-launcher"}},{"Process":{"Description":"byobu-launcher-install(1) is a simple utilty that will add a line to your $HOME\/.profile file which launches byobu(1) any time you login through ssh(1) or on a console(4). By default, when users detach from the byobu(1) session they will also logout. Users can change this behavior by adding the [-n|--no-logout] option when they run byobu-launcher-install(1). You can disable this behavior entirely at any time with the byobu-launcher-uninstall(1) utility.","Process Name":"byobu-launcher-install","Link":"https:\/\/linux.die.net\/man\/1\/byobu-launcher-install"}},{"Process":{"Description":"byobu-launcher-uninstall(1) is a simple utilty that removes the line added to your $HOME\/.profile by byobu-launcher-install(1) which launches byobu(1) any time you login through ssh(1) or on a console(4).","Process Name":"byobu-launcher-uninstall","Link":"https:\/\/linux.die.net\/man\/1\/byobu-launcher-uninstall"}},{"Process":{"Description":"byobu-layout will save and restore byobu-tmux(1) split window layouts. If 'name' is blank, it operates interactively. Note that this only works with Byobu when backed by tmux(1), and not screen(1).","Process Name":"byobu-layout","Link":"https:\/\/linux.die.net\/man\/1\/byobu-layout"}},{"Process":{"Description":"byobu-quiet will disable ALL of Byobu's status indicators and eliminate the hardstatus line. Some administrators, in some environments, at some times may prefer a very minimal, quiet Byobu, without the potentially distracting status indicators and eye candy. However, the window menu is preserved, as well as all of Byobu's keybindings and helper utilities. To elminate the window list, use byobu-silent(1).","Process Name":"byobu-quiet","Link":"https:\/\/linux.die.net\/man\/1\/byobu-quiet"}},{"Process":{"Description":"byobu-reconnect-sockets is a sourcable bit of shell code that will update the GPG_AGENT_INFO and DBUS_SESSION_BUS_ADDRESS environment variables in the current shell, such that you may restablish connection to gpg-agent(1) and dbus-daemon(1). This is often useful when reattaching to a detached Byobu session. http:\/\/launchpad.net\/byobu","Process Name":"byobu-reconnect-sockets","Link":"https:\/\/linux.die.net\/man\/1\/byobu-reconnect-sockets"}},{"Process":{"Description":"byobu-screen launches byobu(1) with screen(1) as the backend window manager.","Process Name":"byobu-screen","Link":"https:\/\/linux.die.net\/man\/1\/byobu-screen"}},{"Process":{"Description":"byobu-select-backend is an application that lists the available Byobu backends and allows you to select your default. You can select one of either screen(1) or tmux(1) on the command line, or giving no command line parameters, the utility will run interactively. This utility will only affect which backend is used by default when simply running, byobu(1). Note that at any time, you can force the backend of a particular session by running the helpers, byobu-screen(1) or byobu-tmux(1).","Process Name":"byobu-select-backend","Link":"https:\/\/linux.die.net\/man\/1\/byobu-select-backend"}},{"Process":{"Description":"byobu-select-profile is an application that lists the available Byobu colors and allows you to select the foreground and background color.","Process Name":"byobu-select-profile","Link":"https:\/\/linux.die.net\/man\/1\/byobu-select-profile"}},{"Process":{"Description":"byobu-select-session is an application that lists the available screen sessions running on the system, and prompts the user to select one. The user also has the option to create a new Byobu session, or launch the default shell without Byobu. If an invalid selection is chosen 3 times in a row, the user is connected to the youngest session. By default, if only one session exists, the user is connected to that session, and if no sessions exist, a new session is created -- such that there is no interactive prompt in the normal behavior. However, some users may choose to always be prompted, by touching the file $BYOBU_CONFIG_DIR\/.always-select. Note that BYOBU_CONFIG_DIR=$HOME\/.byobu. Named sessions that begin with a \".\" are \"hidden\" from byobu-select-session(1). This is useful, for instance, if you do not want a session to be automatically selected at login. Example: byobu -S .hidden","Process Name":"byobu-select-session","Link":"https:\/\/linux.die.net\/man\/1\/byobu-select-session"}},{"Process":{"Description":"byobu-shell is a simple script that prints the message of the day (\/etc\/motd) and launches a shell. $SHELL will be invoked if it exists. Otherwise, \/bin\/sh will be used. http:\/\/launchpad.net\/byobu","Process Name":"byobu-shell","Link":"https:\/\/linux.die.net\/man\/1\/byobu-shell"}},{"Process":{"Description":"byobu-silent will disable ALL of Byobu's status indicators, eliminate the hardstatus line, and the window list. Some administrators, in some environments, at some times may prefer a very minimal, quiet Byobu, without the potentially distracting status indicators and eye candy. byobu-silent implies byobu-quiet.","Process Name":"byobu-silent","Link":"https:\/\/linux.die.net\/man\/1\/byobu-silent"}},{"Process":{"Description":"byobu-status is a program periodically called by the BYOBU_BACKEND to gather the formatted status strings displayed in to lower status bar(s). http:\/\/launchpad.net\/byobu","Process Name":"byobu-status","Link":"https:\/\/linux.die.net\/man\/1\/byobu-status"}},{"Process":{"Description":"byobu-status-detail is a simple script that uses a sensible pager for displaying the detailed status of all byobu status scripts. http:\/\/launchpad.net\/byobu","Process Name":"byobu-status-detail","Link":"https:\/\/linux.die.net\/man\/1\/byobu-status-detail"}},{"Process":{"Description":"byobu-tmux launches byobu(1) with tmux(1) as the backend window manager.","Process Name":"byobu-tmux","Link":"https:\/\/linux.die.net\/man\/1\/byobu-tmux"}},{"Process":{"Description":"Byzanz debug recording can be created by using the extension .byzanz. To convert these recordings into the other formats supported by Byzanz, byzanz-playback can be used. The INFILE must e a byzanz debug file, the OUTFILE is the file to convert it to. Its extension determines the format to be used. See the byzanz-record(1) man page for a list of supported formats and their extensions.","Process Name":"byzanz-playback","Link":"https:\/\/linux.die.net\/man\/1\/byzanz-playback"}},{"Process":{"Description":"Byzanz records your desktop session to an animated GIF. You can record your entire screen, a single window, or an arbitrary region. byzanz-record allows you to make recordings from the command line. Graphical users may want to use the panel applet instead.","Process Name":"byzanz-record","Link":"https:\/\/linux.die.net\/man\/1\/byzanz-record"}},{"Process":{"Description":"bzip2 compresses files using the Burrows-Wheeler block sorting text compression algorithm, and Huffman coding. Compression is generally considerably better than that achieved by more conventional LZ77\/LZ78-based compressors, and approaches the performance of the PPM family of statistical compressors. The command-line options are deliberately very similar to those of GNU gzip, but they are not identical. bzip2 expects a list of file names to accompany the command-line flags. Each file is replaced by a compressed version of itself, with the name \"original_name.bz2\". Each compressed file has the same modification date, permissions, and, when possible, ownership as the corresponding original, so that these properties can be correctly restored at decompression time. File name handling is naive in the sense that there is no mechanism for preserving original file names, permissions, ownerships or dates in filesystems which lack these concepts, or have serious file name length restrictions, such as MS-DOS. bzip2 and bunzip2 will by default not overwrite existing files. If you want this to happen, specify the -f flag. If no file names are specified, bzip2 compresses from standard input to standard output. In this case, bzip2 will decline to write compressed output to a terminal, as this would be entirely incomprehensible and therefore pointless. bunzip2 (or bzip2 -d) decompresses all specified files. Files which were not created by bzip2 will be detected and ignored, and a warning issued. bzip2 attempts to guess the filename for the decompressed file from that of the compressed file as follows: filename.bz2 becomes filename filename.bz becomes filename filename.tbz2 becomes filename.tar filename.tbz becomes filename.tar anyothername becomes anyothername.out If the file does not end in one of the recognised endings, .bz2, .bz, .tbz2 or .tbz, bzip2 complains that it cannot guess the name of the original file, and uses the original name with .out appended. As with compression, supplying no filenames causes decompression from standard input to standard output. bunzip2 will correctly decompress a file which is the concatenation of two or more compressed files. The result is the concatenation of the corresponding uncompressed files. Integrity testing (-t) of concatenated compressed files is also supported. You can also compress or decompress files to the standard output by giving the -c flag. Multiple files may be compressed and decompressed like this. The resulting outputs are fed sequentially to stdout. Compression of multiple files in this manner generates a stream containing multiple compressed file representations. Such a stream can be decompressed correctly only by bzip2 version 0.9.0 or later. Earlier versions of bzip2 will stop after decompressing the first file in the stream. bzcat (or bzip2 -dc) decompresses all specified files to the standard output. bzip2 will read arguments from the environment variables BZIP2 and BZIP, in that order, and will process them before any arguments read from the command line. This gives a convenient way to supply default arguments. Compression is always performed, even if the compressed file is slightly larger than the original. Files of less than about one hundred bytes tend to get larger, since the compression mechanism has a constant overhead in the region of 50 bytes. Random data (including the output of most file compressors) is coded at about 8.05 bits per byte, giving an expansion of around 0.5%. As a self-check for your protection, bzip2 uses 32-bit CRCs to make sure that the decompressed version of a file is identical to the original. This guards against corruption of the compressed data, and against undetected bugs in bzip2 (hopefully very unlikely). The chances of data corruption going undetected is microscopic, about one chance in four billion for each file processed. Be aware, though, that the check occurs upon decompression, so it can only tell you that something is wrong. It can't help you recover the original uncompressed data. You can use bzip2recover to try to recover data from damaged files. Return values: 0 for a normal exit, 1 for environmental problems (file not found, invalid flags, I\/O errors, &c), 2 to indicate a corrupt compressed file, 3 for an internal consistency error (eg, bug) which caused bzip2 to panic.","Process Name":"bzcat","Link":"https:\/\/linux.die.net\/man\/1\/bzcat"}},{"Process":{"Description":"Bzcmp and bzdiff are used to invoke the cmp or the diff program on bzip2 compressed files. All options specified are passed directly to cmp or diff. If only 1 file is specified, then the files compared are file1 and an uncompressed file1.bz2. If two files are specified, then they are uncompressed if necessary and fed to cmp or diff. The exit status from cmp or diff is preserved.","Process Name":"bzcmp","Link":"https:\/\/linux.die.net\/man\/1\/bzcmp"}},{"Process":{"Description":"Bzcmp and bzdiff are used to invoke the cmp or the diff program on bzip2 compressed files. All options specified are passed directly to cmp or diff. If only 1 file is specified, then the files compared are file1 and an uncompressed file1.bz2. If two files are specified, then they are uncompressed if necessary and fed to cmp or diff. The exit status from cmp or diff is preserved.","Process Name":"bzdiff","Link":"https:\/\/linux.die.net\/man\/1\/bzdiff"}},{"Process":{"Description":"Bzgrep is used to invoke the grep on bzip2-compressed files. All options specified are passed directly to grep. If no file is specified, then the standard input is decompressed if necessary and fed to grep. Otherwise the given files are uncompressed if necessary and fed to grep. If bzgrep is invoked as bzegrep or bzfgrep then egrep or fgrep is used instead of grep. If the GREP environment variable is set, bzgrep uses it as the grep program to be invoked. For example: for sh: GREP=fgrep bzgrep string files for csh: (setenv GREP fgrep; bzgrep string files)","Process Name":"bzgrep","Link":"https:\/\/linux.die.net\/man\/1\/bzgrep"}},{"Process":{"Description":"bzip2 compresses files using the Burrows-Wheeler block sorting text compression algorithm, and Huffman coding. Compression is generally considerably better than that achieved by more conventional LZ77\/LZ78-based compressors, and approaches the performance of the PPM family of statistical compressors. The command-line options are deliberately very similar to those of GNU gzip, but they are not identical. bzip2 expects a list of file names to accompany the command-line flags. Each file is replaced by a compressed version of itself, with the name \"original_name.bz2\". Each compressed file has the same modification date, permissions, and, when possible, ownership as the corresponding original, so that these properties can be correctly restored at decompression time. File name handling is naive in the sense that there is no mechanism for preserving original file names, permissions, ownerships or dates in filesystems which lack these concepts, or have serious file name length restrictions, such as MS-DOS. bzip2 and bunzip2 will by default not overwrite existing files. If you want this to happen, specify the -f flag. If no file names are specified, bzip2 compresses from standard input to standard output. In this case, bzip2 will decline to write compressed output to a terminal, as this would be entirely incomprehensible and therefore pointless. bunzip2 (or bzip2 -d) decompresses all specified files. Files which were not created by bzip2 will be detected and ignored, and a warning issued. bzip2 attempts to guess the filename for the decompressed file from that of the compressed file as follows: filename.bz2 becomes filename filename.bz becomes filename filename.tbz2 becomes filename.tar filename.tbz becomes filename.tar anyothername becomes anyothername.out If the file does not end in one of the recognised endings, .bz2, .bz, .tbz2 or .tbz, bzip2 complains that it cannot guess the name of the original file, and uses the original name with .out appended. As with compression, supplying no filenames causes decompression from standard input to standard output. bunzip2 will correctly decompress a file which is the concatenation of two or more compressed files. The result is the concatenation of the corresponding uncompressed files. Integrity testing (-t) of concatenated compressed files is also supported. You can also compress or decompress files to the standard output by giving the -c flag. Multiple files may be compressed and decompressed like this. The resulting outputs are fed sequentially to stdout. Compression of multiple files in this manner generates a stream containing multiple compressed file representations. Such a stream can be decompressed correctly only by bzip2 version 0.9.0 or later. Earlier versions of bzip2 will stop after decompressing the first file in the stream. bzcat (or bzip2 -dc) decompresses all specified files to the standard output. bzip2 will read arguments from the environment variables BZIP2 and BZIP, in that order, and will process them before any arguments read from the command line. This gives a convenient way to supply default arguments. Compression is always performed, even if the compressed file is slightly larger than the original. Files of less than about one hundred bytes tend to get larger, since the compression mechanism has a constant overhead in the region of 50 bytes. Random data (including the output of most file compressors) is coded at about 8.05 bits per byte, giving an expansion of around 0.5%. As a self-check for your protection, bzip2 uses 32-bit CRCs to make sure that the decompressed version of a file is identical to the original. This guards against corruption of the compressed data, and against undetected bugs in bzip2 (hopefully very unlikely). The chances of data corruption going undetected is microscopic, about one chance in four billion for each file processed. Be aware, though, that the check occurs upon decompression, so it can only tell you that something is wrong. It can't help you recover the original uncompressed data. You can use bzip2recover to try to recover data from damaged files. Return values: 0 for a normal exit, 1 for environmental problems (file not found, invalid flags, I\/O errors, &c), 2 to indicate a corrupt compressed file, 3 for an internal consistency error (eg, bug) which caused bzip2 to panic.","Process Name":"bzip2","Link":"https:\/\/linux.die.net\/man\/1\/bzip2"}},{"Process":{"Description":"bzip2 compresses files using the Burrows-Wheeler block sorting text compression algorithm, and Huffman coding. Compression is generally considerably better than that achieved by more conventional LZ77\/LZ78-based compressors, and approaches the performance of the PPM family of statistical compressors. The command-line options are deliberately very similar to those of GNU gzip, but they are not identical. bzip2 expects a list of file names to accompany the command-line flags. Each file is replaced by a compressed version of itself, with the name \"original_name.bz2\". Each compressed file has the same modification date, permissions, and, when possible, ownership as the corresponding original, so that these properties can be correctly restored at decompression time. File name handling is naive in the sense that there is no mechanism for preserving original file names, permissions, ownerships or dates in filesystems which lack these concepts, or have serious file name length restrictions, such as MS-DOS. bzip2 and bunzip2 will by default not overwrite existing files. If you want this to happen, specify the -f flag. If no file names are specified, bzip2 compresses from standard input to standard output. In this case, bzip2 will decline to write compressed output to a terminal, as this would be entirely incomprehensible and therefore pointless. bunzip2 (or bzip2 -d) decompresses all specified files. Files which were not created by bzip2 will be detected and ignored, and a warning issued. bzip2 attempts to guess the filename for the decompressed file from that of the compressed file as follows: filename.bz2 becomes filename filename.bz becomes filename filename.tbz2 becomes filename.tar filename.tbz becomes filename.tar anyothername becomes anyothername.out If the file does not end in one of the recognised endings, .bz2, .bz, .tbz2 or .tbz, bzip2 complains that it cannot guess the name of the original file, and uses the original name with .out appended. As with compression, supplying no filenames causes decompression from standard input to standard output. bunzip2 will correctly decompress a file which is the concatenation of two or more compressed files. The result is the concatenation of the corresponding uncompressed files. Integrity testing (-t) of concatenated compressed files is also supported. You can also compress or decompress files to the standard output by giving the -c flag. Multiple files may be compressed and decompressed like this. The resulting outputs are fed sequentially to stdout. Compression of multiple files in this manner generates a stream containing multiple compressed file representations. Such a stream can be decompressed correctly only by bzip2 version 0.9.0 or later. Earlier versions of bzip2 will stop after decompressing the first file in the stream. bzcat (or bzip2 -dc) decompresses all specified files to the standard output. bzip2 will read arguments from the environment variables BZIP2 and BZIP, in that order, and will process them before any arguments read from the command line. This gives a convenient way to supply default arguments. Compression is always performed, even if the compressed file is slightly larger than the original. Files of less than about one hundred bytes tend to get larger, since the compression mechanism has a constant overhead in the region of 50 bytes. Random data (including the output of most file compressors) is coded at about 8.05 bits per byte, giving an expansion of around 0.5%. As a self-check for your protection, bzip2 uses 32-bit CRCs to make sure that the decompressed version of a file is identical to the original. This guards against corruption of the compressed data, and against undetected bugs in bzip2 (hopefully very unlikely). The chances of data corruption going undetected is microscopic, about one chance in four billion for each file processed. Be aware, though, that the check occurs upon decompression, so it can only tell you that something is wrong. It can't help you recover the original uncompressed data. You can use bzip2recover to try to recover data from damaged files. Return values: 0 for a normal exit, 1 for environmental problems (file not found, invalid flags, I\/O errors, &c), 2 to indicate a corrupt compressed file, 3 for an internal consistency error (eg, bug) which caused bzip2 to panic.","Process Name":"bzip2recover","Link":"https:\/\/linux.die.net\/man\/1\/bzip2recover"}},{"Process":{"Description":"Bzmore is a filter which allows examination of compressed or plain text files one screenful at a time on a soft-copy terminal. bzmore works on files compressed with bzip2 and also on uncompressed files. If a file does not exist, bzmore looks for a file of the same name with the addition of a .bz2 suffix. Bzmore normally pauses after each screenful, printing --More-- at the bottom of the screen. If the user then types a carriage return, one more line is displayed. If the user hits a space, another screenful is displayed. Other possibilities are enumerated later. Bzmore looks in the file \/etc\/termcap to determine terminal characteristics, and to determine the default window size. On a terminal capable of displaying 24 lines, the default window size is 22 lines. Other sequences which may be typed when bzmore pauses, and their effects, are as follows (i is an optional integer argument, defaulting to 1) : i<space> display i more lines, (or another screenful if no argument is given) ^D display 11 more lines (a ''scroll''). If i is given, then the scroll size is set to i. d same as ^D (control-D) iz same as typing a space except that i, if present, becomes the new window size. Note that the window size reverts back to the default at the end of the current file. is skip i lines and print a screenful of lines if skip i screenfuls and print a screenful of lines q or Q quit reading the current file; go on to the next (if any) e or q When the prompt --More--(Next file: file) is printed, this command causes bzmore to exit. s When the prompt --More--(Next file: file) is printed, this command causes bzmore to skip the next file and continue. = Display the current line number. i\/expr search for the i-th occurrence of the regular expression expr. If the pattern is not found, bzmore goes on to the next file (if any). Otherwise, a screenful is displayed, starting two lines before the place where the expression was found. The user's erase and kill characters may be used to edit the regular expression. Erasing back past the first column cancels the search command. in search for the i-th occurrence of the last regular expression entered. !command invoke a shell with command. The character '!' in \"command\" are replaced with the previous shell command. The sequence \"\\!\" is replaced by \"!\". :q or :Q quit reading the current file; go on to the next (if any) (same as q or Q). . (dot) repeat the previous command. The commands take effect immediately, i.e., it is not necessary to type a carriage return. Up to the time when the command character itself is given, the user may hit the line kill character to cancel the numerical argument being formed. In addition, the user may hit the erase character to redisplay the --More-- message. At any time when output is being sent to the terminal, the user can hit the quit key (normally control-\\). Bzmore will stop sending output, and will display the usual --More-- prompt. The user may then enter one of the above commands in the normal manner. Unfortunately, some output is lost when this is done, due to the fact that any characters waiting in the terminal's output queue are flushed when the quit signal occurs. The terminal is set to noecho mode by this program so that the output can be continuous. What you type will thus not show on your terminal, except for the \/ and ! commands. If the standard output is not a teletype, then bzmore acts just like bzcat, except that a header is printed before each file.","Process Name":"bzless","Link":"https:\/\/linux.die.net\/man\/1\/bzless"}},{"Process":{"Description":"Bzmore is a filter which allows examination of compressed or plain text files one screenful at a time on a soft-copy terminal. bzmore works on files compressed with bzip2 and also on uncompressed files. If a file does not exist, bzmore looks for a file of the same name with the addition of a .bz2 suffix. Bzmore normally pauses after each screenful, printing --More-- at the bottom of the screen. If the user then types a carriage return, one more line is displayed. If the user hits a space, another screenful is displayed. Other possibilities are enumerated later. Bzmore looks in the file \/etc\/termcap to determine terminal characteristics, and to determine the default window size. On a terminal capable of displaying 24 lines, the default window size is 22 lines. Other sequences which may be typed when bzmore pauses, and their effects, are as follows (i is an optional integer argument, defaulting to 1) : i<space> display i more lines, (or another screenful if no argument is given) ^D display 11 more lines (a ''scroll''). If i is given, then the scroll size is set to i. d same as ^D (control-D) iz same as typing a space except that i, if present, becomes the new window size. Note that the window size reverts back to the default at the end of the current file. is skip i lines and print a screenful of lines if skip i screenfuls and print a screenful of lines q or Q quit reading the current file; go on to the next (if any) e or q When the prompt --More--(Next file: file) is printed, this command causes bzmore to exit. s When the prompt --More--(Next file: file) is printed, this command causes bzmore to skip the next file and continue. = Display the current line number. i\/expr search for the i-th occurrence of the regular expression expr. If the pattern is not found, bzmore goes on to the next file (if any). Otherwise, a screenful is displayed, starting two lines before the place where the expression was found. The user's erase and kill characters may be used to edit the regular expression. Erasing back past the first column cancels the search command. in search for the i-th occurrence of the last regular expression entered. !command invoke a shell with command. The character '!' in \"command\" are replaced with the previous shell command. The sequence \"\\!\" is replaced by \"!\". :q or :Q quit reading the current file; go on to the next (if any) (same as q or Q). . (dot) repeat the previous command. The commands take effect immediately, i.e., it is not necessary to type a carriage return. Up to the time when the command character itself is given, the user may hit the line kill character to cancel the numerical argument being formed. In addition, the user may hit the erase character to redisplay the --More-- message. At any time when output is being sent to the terminal, the user can hit the quit key (normally control-\\). Bzmore will stop sending output, and will display the usual --More-- prompt. The user may then enter one of the above commands in the normal manner. Unfortunately, some output is lost when this is done, due to the fact that any characters waiting in the terminal's output queue are flushed when the quit signal occurs. The terminal is set to noecho mode by this program so that the output can be continuous. What you type will thus not show on your terminal, except for the \/ and ! commands. If the standard output is not a teletype, then bzmore acts just like bzcat, except that a header is printed before each file.","Process Name":"bzmore","Link":"https:\/\/linux.die.net\/man\/1\/bzmore"}},{"Process":{"Description":"Bazaar (or bzr) is a project of Canonical to develop an open source distributed version control system that is powerful, friendly, and scalable. Version control means a system that keeps track of previous revisions of software source code or similar information and helps people work on it in teams.","Process Name":"bzr","Link":"https:\/\/linux.die.net\/man\/1\/bzr"}},{"Process":{"Description":"The first form of the command line (option -e ) compresses the data from file inputfile and writes the compressed data into outputfile. The second form of the command line (option -d ) decompressed file inputfile and writes the output to outputfile.","Process Name":"bzz","Link":"https:\/\/linux.die.net\/man\/1\/bzz"}}]