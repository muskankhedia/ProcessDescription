[{"Process":{"Description":"k2f is a FSM translator from ALLIANCE format (\".fsm\") to Berkeley format (\".kiss2\").","Process Name":"k2f","Link":"https:\/\/linux.die.net\/man\/1\/k2f"}},{"Process":{"Description":"k5srvutil allows a system manager to list or change keys currently in his keytab or to add new keys to the keytab. Operation must be one of the following: list lists the keys in a keytab showing version number and principal name. change changes all the keys in the keytab to new randomly-generated keys, updating the keys in the Kerberos server's database to match by using the kadmin protocol. If a key's version number doesn't match the version number stored in the Kerberos server's database, then the operation will fail. The old keys are retained so that existing tickets continue to work. If the -i flag is given, k5srvutil will prompt for yes or no before changing each key. If the -k option is used, the old and new keys will be displayed. delold Deletes keys that are not the most recent version from the keytab. This operation should be used some time after a change operation to remove old keys. If the -i flag is used, then the program prompts the user whether the old keys associated with each principal should be removed. delete deletes particular keys in the keytab, interactively prompting for each key. In all cases, the default file used is \/etc\/krb5.keytab file unless this is overridden by the -f option. k5srvutil uses the kadmin program to edit the keytab in place. However, old keys are retained, so they are available in case of failure.","Process Name":"k5srvutil","Link":"https:\/\/linux.die.net\/man\/1\/k5srvutil"}},{"Process":{"Description":null,"Process Name":"k5start","Link":"https:\/\/linux.die.net\/man\/1\/k5start"}},{"Process":{"Description":"kadmin and kadmin.local are command-line interfaces to the Kerberos V5 KADM5 administration system. Both kadmin and kadmin.local provide identical functionalities; the difference is that kadmin.local runs on the master KDC if the database is db2 and does not use Kerberos to authenticate to the database. Except as explicitly noted otherwise, this man page will use kadmin to refer to both versions. kadmin provides for the maintenance of Kerberos principals, KADM5 policies, and service key tables (keytabs). The remote version uses Kerberos authentication and an encrypted RPC, to operate securely from anywhere on the network. It authenticates to the KADM5 server using the service principal kadmin\/admin. If the credentials cache contains a ticket for the kadmin\/admin principal, and the -c credentials_cache option is specified, that ticket is used to authenticate to KADM5. Otherwise, the -p and -k options are used to specify the client Kerberos principal name used to authenticate. Once kadmin has determined the principal name, it requests a kadmin\/admin Kerberos service ticket from the KDC, and uses that service ticket to authenticate to KADM5. If the database is db2, the local client kadmin.local, is intended to run directly on the master KDC without Kerberos authentication. The local version provides all of the functionality of the now obsolete kdb5_edit(8), except for database dump and load, which is now provided by the kdb5_util(8) utility. If the database is LDAP, kadmin.local need not be run on the KDC. kadmin.local can be configured to log updates for incremental database propagation. Incremental propagation allows slave KDC servers to receive principal and policy updates incrementally instead of receiving full dumps of the database. This facility can be enabled in the kdc.conf file with the iprop_enable option. See the kdc.conf documentation for other options for tuning incremental propagation parameters.","Process Name":"kadmin","Link":"https:\/\/linux.die.net\/man\/1\/kadmin"}},{"Process":{"Description":"A media player for KDE 3. Can use multiple backends for playback, default is xine.","Process Name":"kaffeine","Link":"https:\/\/linux.die.net\/man\/1\/kaffeine"}},{"Process":{"Description":"The kaleidescope program draws line segments in a symmetric pattern that evolves over time.","Process Name":"kaleidescope","Link":"https:\/\/linux.die.net\/man\/1\/kaleidescope"}},{"Process":{"Description":null,"Process Name":"kappfinder","Link":"https:\/\/linux.die.net\/man\/1\/kappfinder"}},{"Process":{"Description":"kasumi is a personal dictionary manager for Anthy.","Process Name":"kasumi","Link":"https:\/\/linux.die.net\/man\/1\/kasumi"}},{"Process":{"Description":"katalyzer analyzes Kate streams and displays information about them. The type of information to select is selectable on the command line. Several multiplexed Kate streams may be analyzed at the same time.","Process Name":"katalyzer","Link":"https:\/\/linux.die.net\/man\/1\/katalyzer"}},{"Process":{"Description":null,"Process Name":"kate","Link":"https:\/\/linux.die.net\/man\/1\/kate"}},{"Process":{"Description":"katedec decodes Kate streams to libkate's custom description language.","Process Name":"katedec","Link":"https:\/\/linux.die.net\/man\/1\/katedec"}},{"Process":{"Description":"KateDJ allows extracting Kate tracks embedded in an Ogg stream, editing them, and rebuilding the Ogg stream after the Kate tracks are modified. KateDJ is a simple GUI program, so usage is UI driven, rather than command line driven. This is a walkthrough of the usual program flow: Select 'Load Ogg stream' to select the Ogg file you want to remix. Select 'Demux file' to extract Kate streams from this file to a temporary directory. Depending on the size of the Ogg file, that step may take a while. A message will then tell you where the temporary files have been placed. All Kate streams will be decoded to a text description and placed in this temporary directory, and a list of them, along with their serial number, language, and category, will be displayed in a list. Those files may then be edited at will, either in the embedded editor by double clicking on the stream in the supplied list, or with your favorite text editor. Any modification may be done, including removing some of those files altogether, or even adding some. However, in order to be recognized, any new files must be named according to the same naming convention as the existing ones. Once the desired modifications are done, select 'Remux file from parts' to attempt to recreate the Ogg stream. If any error occurs (eg, syntax error in the Kate files), a message will inform you. Once the errors are fixed, select 'Remux file from parts' again, until the operation succeeds. The embedded editor can test a modified stream, so it more convenient for quick modifications, while your editor of choice may be more powerful for complex modification.","Process Name":"katedj","Link":"https:\/\/linux.die.net\/man\/1\/katedj"}},{"Process":{"Description":null,"Process Name":"kateenc","Link":"https:\/\/linux.die.net\/man\/1\/kateenc"}},{"Process":{"Description":"kbd-test prints the values reported by the keyboard input function from the CURSES library. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"kbd-test","Link":"https:\/\/linux.die.net\/man\/1\/kbd-test"}},{"Process":{"Description":"Without argument, kbd_mode prints the current keyboard mode (RAW, MEDIUMRAW or XLATE). With argument, it sets the keyboard mode as indicated: -s: scancode mode (RAW), -k: keycode mode (MEDIUMRAW), -a: ASCII mode (XLATE), -u: UTF-8 mode (UNICODE). Of course the \"-a\" is only traditional, and the code used can be any 8-bit character set. With \"-u\" a 16-bit character set is expected, and these chars are transmitted to the kernel as 1, 2, or 3 bytes (following the UTF-8 coding). In these latter two modes the key mapping defined by loadkeys(1) is used. Warning: changing the keyboard mode, other than between ASCII and Unicode, will probably make your keyboard unusable. This command is only meant for use (say via remote login) when some program left your keyboard in the wrong state. Note that in some obsolete versions of this program the \"-u\" option was a synonym for \"-s\".","Process Name":"kbd_mode","Link":"https:\/\/linux.die.net\/man\/1\/kbd_mode"}},{"Process":{"Description":"KBibTeX is a BibTeX editor for KDE written by Thomas Fischer and released under the GPL. KBibTeX can be started as a stand-alone program or embedded into virtually every KDE program (e.g. Konqueror). It supports searching for citations via Google and CiteSeer.","Process Name":"kbibtex","Link":"https:\/\/linux.die.net\/man\/1\/kbibtex"}},{"Process":{"Description":null,"Process Name":"kbookmarkmerger","Link":"https:\/\/linux.die.net\/man\/1\/kbookmarkmerger"}},{"Process":{"Description":"Compiles a Linux kernel to benchmark a system or test its stability","Process Name":"kcbench","Link":"https:\/\/linux.die.net\/man\/1\/kcbench"}},{"Process":{"Description":"kcc is a filter that reads file sequencially, converts kanji encodings and output to stdou. If no file is specified, or specified - as filename, it read from stdin. You can specify kanji encodings for input\/output. However, kcc detect input encodig automatically, if you don't specify input encoding. Available kanji encodings are JIS (7 bit and\/or 8 bit), Shift JISEUCDEC . For input encoding, you can mix when these are pair of one of EUC DEC or Shift JIS and 7 bit JIS. SI \/ SOESC (I are recognized as halfwidth of JIS .","Process Name":"kcc","Link":"https:\/\/linux.die.net\/man\/1\/kcc"}},{"Process":{"Description":"The command 'kccachetest' is a utility for facility test and performance test of the cache hash database. This command is used in the following format. 'rnum' specifies the number of iterations. kccachetest order [ -th num] [ -rnd] [ -etc] [ -tran] [ -tc] [ -bnum num] [ -capcnt num][ -capsiz num] [ -lv] rnum Performs in-order tests. kccachetest queue [ -th num] [ -it num] [ -rnd] [ -tc] [ -bnum num] [ -capcnt num][ -capsiz num] [ -lv] rnum Performs queuing operations. kccachetest wicked [ -th num] [ -it num] [ -tc] [ -bnum num] [ -capcnt num] [ -capsiz num] [ -lv] rnum Performs mixed operations selected at random. kccachetest tran [ -th num] [ -it num] [ -tc] [ -bnum num] [ -capcnt num] [ -capsiz num] [ -lv] rnum Performs test of transaction. Options feature the following. -th num : specifies the number of worker threads. -rnd : performs random test. -etc : performs miscellaneous operations. -tran : performs transaction. -tc : tunes the database with the compression option. -bnum num : specifies the number of buckets of the hash table. -capcnt num : specifies the maximum number of records. -capsiz num : specifies the maximum size of memory usage. -lv : reports all errors. -it num : specifies the number of repetition. This command returns 0 on success, another on failure. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"kccachetest","Link":"https:\/\/linux.die.net\/man\/1\/kccachetest"}},{"Process":{"Description":"The command 'kcdirmgr' is a utility for test and debugging of the directory hash database and its applications. 'path' specifies the path of a database file. 'key' specifies the key of a record. 'value' specifies the value of a record. 'file' specifies the input\/output file. kcdirmgr create [ -otr] [ -onl| -otl| -onr] [ -tc] path Creates a database file. kcdirmgr inform [ -onl| -otl| -onr] [ -st] path Prints status information. kcdirmgr set [ -onl| -otl| -onr] [ -add| -app| -rep| -inci| -incd] [ -sx] path key value Stores a record. kcdirmgr remove [ -onl| -otl| -onr] [ -sx] path key Removes a record. kcdirmgr get [ -onl| -otl| -onr] [ -rm] [ -sx] [ -px] [ -pz] path key Prints the value of a record. kcdirmgr list [ -onl| -otl| -onr] [ -max num] [ -rm] [ -sx] [ -pv] [ -px] path [ key] Prints keys of all records, separated by line feeds. kcdirmgr clear [ -onl| -otl| -onr] path Removes all records of a database. kcdirmgr import [ -onl| -otl| -onr] [ -sx] path [ file] Imports records from a TSV file. kcdirmgr copy [ -onl| -otl| -onr] path file Copies the whole database. kcdirmgr dump [ -onl| -otl| -onr] path [ file] Dumps records into a snapshot file. kcdirmgr load [ -otr] [ -onl| -otl| -onr] path [ file] Loads records from a snapshot file. kcdirmgr defrag [ -onl| -otl| -onr] path Performs defragmentation. kcdirmgr setbulk [ -onl| -otl| -onr] path key value ... Store records at once. kcdirmgr removebulk [ -onl| -otl| -onr] [ -sx] path key ... Remove records at once. kcdirmgr getbulk [ -onl| -otl| -onr] [ -sx] [ -px] path key ... Retrieve records at once. kcdirmgr check [ -onl| -otl| -onr] path Checks consistency. Options feature the following. -otr : opens the database with the truncation option. -onl : opens the database with the no locking option. -otl : opens the database with the try locking option. -onr : opens the database with the no auto repair option. -tc : tunes the database with the compression option. -st : prints miscellaneous information. -add : performs adding operation. -app : performs appending operation. -rep : performs replacing operation. -inci : performs integer increment operation. -incd : performs real number increment operation. -sx : the input data is evaluated as a hexadecimal data string. -rm : removes the record. -px : the output data is converted into a hexadecimal data string. -pz : does not append line feed at the end of the output. -max num : specifies the maximum number of shown records. -pv : prints values of records also. This command returns 0 on success, another on failure.","Process Name":"kcdirmgr","Link":"https:\/\/linux.die.net\/man\/1\/kcdirmgr"}},{"Process":{"Description":null,"Process Name":"kcdirtest","Link":"https:\/\/linux.die.net\/man\/1\/kcdirtest"}},{"Process":{"Description":"The command 'kcforestmgr' is a utility for test and debugging of the file tree database and its applications. 'path' specifies the path of a database file. 'key' specifies the key of a record. 'value' specifies the value of a record. 'file' specifies the input\/output file. kcforestmgr create [ -otr] [ -onl| -otl| -onr] [ -tc] [ -bnum num] [ -psiz num] [ -rcd| -rcld| -rcdd] path Creates a database file. kcforestmgr inform [ -onl| -otl| -onr] [ -st] path Prints status information. kcforestmgr set [ -onl| -otl| -onr] [ -add| -app| -rep| -inci| -incd] [ -sx] path key value Stores a record. kcforestmgr remove [ -onl| -otl| -onr] [ -sx] path key Removes a record. kcforestmgr get [ -onl| -otl| -onr] [ -rm] [ -sx] [ -px] [ -pz] path key Prints the value of a record. kcforestmgr list [ -onl| -otl| -onr] [ -des] [ -max num] [ -rm] [ -sx] [ -pv] [ -px] path [ key] Prints keys of all records, separated by line feeds. kcforestmgr clear [ -onl| -otl| -onr] path Removes all records of a database. kcforestmgr import [ -onl| -otl| -onr] [ -sx] path [ file] Imports records from a TSV file. kcforestmgr copy [ -onl| -otl| -onr] path file Copies the whole database. kcforestmgr dump [ -onl| -otl| -onr] path [ file] Dumps records into a snapshot file. kcforestmgr load [ -otr] [ -onl| -otl| -onr] path [ file] Loads records from a snapshot file. kcforestmgr setbulk [ -onl| -otl| -onr] path key value ... Store records at once. kcforestmgr removebulk [ -onl| -otl| -onr] [ -sx] path key ... Remove records at once. kcforestmgr getbulk [ -onl| -otl| -onr] [ -sx] [ -px] path key ... Retrieve records at once. kcforestmgr check [ -onl| -otl| -onr] path Checks consistency. Options feature the following. -otr : opens the database with the truncation option. -onl : opens the database with the no locking option. -otl : opens the database with the try locking option. -onr : opens the database with the no auto repair option. -tc : tunes the database with the compression option. -bnum num : specifies the number of buckets of the hash table. -psiz num : specifies the size of each page. -rcd : use the decimal comparator instead of the lexical one. -rcld : use the lexical descending comparator instead of the ascending one. -rcdd : use the decimal descending comparator instead of the lexical one. -st : prints miscellaneous information. -add : performs adding operation. -app : performs appending operation. -rep : performs replacing operation. -inci : performs integer increment operation. -incd : performs real number increment operation. -sx : the input data is evaluated as a hexadecimal data string. -rm : removes the record. -px : the output data is converted into a hexadecimal data string. -pz : does not append line feed at the end of the output. -des : visits records in descending order. -max num : specifies the maximum number of shown records. -pv : prints values of records also. This command returns 0 on success, another on failure.","Process Name":"kcforestmgr","Link":"https:\/\/linux.die.net\/man\/1\/kcforestmgr"}},{"Process":{"Description":null,"Process Name":"kcforesttest","Link":"https:\/\/linux.die.net\/man\/1\/kcforesttest"}},{"Process":{"Description":"The command 'kcgrasstest' is a utility for facility test and performance test of the cache tree database. This command is used in the following format. 'rnum' specifies the number of iterations. kcgrasstest order [ -th num] [ -rnd] [ -etc] [ -tran] [ -tc] [ -bnum num] [ -psiz num][ -pccap num] [ -rcd| -rcld| -rcdd] [ -lv] rnum Performs in-order tests. kcgrasstest queue [ -th num] [ -it num] [ -rnd] [ -tc] [ -bnum num] [ -psiz num] [ -pccap num] [ -rcd| -rcld| -rcdd] [ -lv] rnum Performs queuing operations. kcgrasstest wicked [ -th num] [ -it num] [ -tc] [ -bnum num] [ -psiz num] [ -pccap num] [ -rcd| -rcld| -rcdd] [ -lv] rnum Performs mixed operations selected at random. kcgrasstest tran [ -th num] [ -it num] [ -tc] [ -bnum num] [ -psiz num] [ -pccap num][ -rcd| -rcld| -rcdd] [ -lv] rnum Performs test of transaction. Options feature the following. -th num : specifies the number of worker threads. -rnd : performs random test. -etc : performs miscellaneous operations. -tran : performs transaction. -tc : tunes the database with the compression option. -bnum num : specifies the number of buckets of the hash table. -psiz num : specifies the size of each page. -pccap num : specifies the capacity size of the page cache. -rcd : use the decimal comparator instead of the lexical one. -rcld : use the lexical descending comparator instead of the ascending one. -rcdd : use the decimal descending comparator instead of the lexical one. -lv : reports all errors. -it num : specifies the number of repetition. This command returns 0 on success, another on failure. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"kcgrasstest","Link":"https:\/\/linux.die.net\/man\/1\/kcgrasstest"}},{"Process":{"Description":"The command 'kchashmgr' is a utility for test and debugging of the file hash database and its applications. 'path' specifies the path of a database file. 'key' specifies the key of a record. 'value' specifies the value of a record. 'file' specifies the input\/output file. kchashmgr create [ -otr] [ -onl| -otl| -onr] [ -apow num] [ -fpow num] [ -ts] [ -tl] [ -tc][ -bnum num] path Creates a database file. kchashmgr inform [ -onl| -otl| -onr] [ -st] path Prints status information. kchashmgr set [ -onl| -otl| -onr] [ -add| -app| -rep| -inci| -incd] [ -sx] path key value Stores a record. kchashmgr remove [ -onl| -otl| -onr] [ -sx] path key Removes a record. kchashmgr get [ -onl| -otl| -onr] [ -rm] [ -sx] [ -px] [ -pz] path key Prints the value of a record. kchashmgr list [ -onl| -otl| -onr] [ -max num] [ -rm] [ -sx] [ -pv] [ -px] path [ key] Prints keys of all records, separated by line feeds. kchashmgr clear [ -onl| -otl| -onr] path Removes all records of a database. kchashmgr import [ -onl| -otl| -onr] [ -sx] path [ file] Imports records from a TSV file. kchashmgr copy [ -onl| -otl| -onr] path file Copies the whole database. kchashmgr dump [ -onl| -otl| -onr] path [ file] Dumps records into a snapshot file. kchashmgr load [ -otr] [ -onl| -otl| -onr] path [ file] Loads records from a snapshot file. kchashmgr defrag [ -onl| -otl| -onr] path Performs defragmentation. kchashmgr setbulk [ -onl| -otl| -onr] path key value ... Store records at once. kchashmgr removebulk [ -onl| -otl| -onr] [ -sx] path key ... Remove records at once. kchashmgr getbulk [ -onl| -otl| -onr] [ -sx] [ -px] path key ... Retrieve records at once. kchashmgr check [ -onl| -otl| -onr] path Checks consistency. Options feature the following. -otr : opens the database with the truncation option. -onl : opens the database with the no locking option. -otl : opens the database with the try locking option. -onr : opens the database with the no auto repair option. -apow num : specifies the power of the alignment of record size. -fpow num : specifies the power of the capacity of the free block pool. -ts : tunes the database with the small option. -tl : tunes the database with the linear option. -tc : tunes the database with the compression option. -bnum num : specifies the number of buckets of the hash table. -st : prints miscellaneous information. -add : performs adding operation. -app : performs appending operation. -rep : performs replacing operation. -inci : performs integer increment operation. -incd : performs real number increment operation. -sx : the input data is evaluated as a hexadecimal data string. -rm : removes the record. -px : the output data is converted into a hexadecimal data string. -pz : does not append line feed at the end of the output. -max num : specifies the maximum number of shown records. -pv : prints values of records also. This command returns 0 on success, another on failure.","Process Name":"kchashmgr","Link":"https:\/\/linux.die.net\/man\/1\/kchashmgr"}},{"Process":{"Description":"The command 'kchashtest' is a utility for facility test and performance test of the file hash database. This command is used in the following format. 'path' specifies the path of a database file. 'rnum' specifies the number of iterations. kchashtest order [ -th num] [ -rnd] [ -set| -get| -getw| -rem| -etc] [ -tran] [ -oat| -onl| -onl| -otl| -onr][ -apow num] [ -fpow num] [ -ts] [ -tl] [ -tc] [ -bnum num] [ -msiz num] [ -dfunit num][ -lv] path rnum Performs in-order tests. kchashtest queue [ -th num] [ -it num] [ -rnd] [ -oat| -onl| -onl| -otl| -onr] [ -apow num] [ -fpow num] [ -ts] [ -tl] [ -tc] [ -bnum num] [ -msiz num] [ -dfunit num] [ -lv] path rnum Performs queuing operations. kchashtest wicked [ -th num] [ -it num] [ -oat| -onl| -onl| -otl| -onr] [ -apow num] [ -fpow num] [ -ts] [ -tl] [ -tc] [ -bnum num] [ -msiz num] [ -dfunit num] [ -lv] path rnum Performs mixed operations selected at random. kchashtest tran [ -th num] [ -it num] [ -hard] [ -oat| -onl| -onl| -otl| -onr] [ -apow num] [ -fpow num] [ -ts] [ -tl] [ -tc] [ -bnum num] [ -msiz num] [ -dfunit num] [ -lv] path rnum Performs test of transaction. Options feature the following. -th num : specifies the number of worker threads. -rnd : performs random test. -set : performs setting operation only. -get : performs getting operation only. -getw : performs getting with a buffer operation only. -rem : performs removing operation only. -etc : performs miscellaneous operations. -tran : performs transaction. -oat : opens the database with the auto transaction option. -oas : opens the database with the auto synchronization option. -onl : opens the database with the no locking option. -otl : opens the database with the try locking option. -onr : opens the database with the no auto repair option. -apow num : specifies the power of the alignment of record size. -fpow num : specifies the power of the capacity of the free block pool. -ts : tunes the database with the small option. -tl : tunes the database with the linear option. -tc : tunes the database with the compression option. -bnum num : specifies the number of buckets of the hash table. -msiz num : specifies the size of the memory-mapped region. -dfunit num : specifies the unit step number of auto defragmentation. -lv : reports all errors. -it num : specifies the number of repetition. -hard : performs physical synchronization. This command returns 0 on success, another on failure.","Process Name":"kchashtest","Link":"https:\/\/linux.die.net\/man\/1\/kchashtest"}},{"Process":{"Description":"The command 'kclangctest' is a utility for facility test and performance test of the C language binding. This command is used in the following format. 'path' specifies the path of a database file. 'rnum' specifies the number of iterations. kclangctest order [ -rnd] [ -etc] [ -tran] [ -oat| -onl| -onl| -otl| -onr] path rnum Performs in-order tests. kclangctest index [ -rnd] [ -etc] [ -oat| -onl| -onl| -otl| -onr] path rnum Performs indexing operations. kclangctest map [ -rnd] [ -etc] [ -bnum num] rnum Performs test of memory-saving hash map. kclangctest list [ -rnd] [ -etc] rnum Performs test of memory-saving array list. Options feature the following. -rnd : performs random test. -etc : performs miscellaneous operations. -tran : performs transaction. -oat : opens the database with the auto transaction option. -oas : opens the database with the auto synchronization option. -onl : opens the database with the no locking option. -otl : opens the database with the try locking option. -onr : opens the database with the no auto repair option. -bnum num : specifies the number of buckets of the hash table. This command returns 0 on success, another on failure.","Process Name":"kclangctest","Link":"https:\/\/linux.die.net\/man\/1\/kclangctest"}},{"Process":{"Description":"The command 'kcpolymgr' is a utility for test and debugging of the polymorphic database and its applications. 'path' specifies the path of a database file. 'key' specifies the key of a record. 'value' specifies the value of a record. 'file' specifies the input\/output file. 'src' specifies other database files. kcpolymgr create [ -otr] [ -onl| -otl| -onr] path Creates a database file. kcpolymgr inform [ -onl| -otl| -onr] [ -st] path Prints status information. kcpolymgr set [ -onl| -otl| -onr] [ -add| -app| -rep| -inci| -incd] [ -sx] path key value Stores a record. kcpolymgr remove [ -onl| -otl| -onr] [ -sx] path key Removes a record. kcpolymgr get [ -onl| -otl| -onr] [ -rm] [ -sx] [ -px] [ -pz] path key Prints the value of a record. kcpolymgr list [ -onl| -otl| -onr] [ -mp| -mr| -ms] [ -des] [ -max num] [ -rm] [ -sx] [ -pv] [ -px] path [ key] Prints keys of all records, separated by line feeds. kcpolymgr clear [ -onl| -otl| -onr] path Removes all records of a database. kcpolymgr import [ -onl| -otl| -onr] [ -sx] path [ file] Imports records from a TSV file. kcpolymgr copy [ -onl| -otl| -onr] path file Copies the whole database. kcpolymgr dump [ -onl| -otl| -onr] path [ file] Dumps records into a snapshot file. kcpolymgr load [ -otr] [ -onl| -otl| -onr] path [ file] Loads records from a snapshot file. kcpolymgr merge [ -onl| -otl| -onr] [ -add| -app| -rep] path src... Merge records from other databases. kcpolymgr setbulk [ -onl| -otl| -onr] path key value ... Store records at once. kcpolymgr removebulk [ -onl| -otl| -onr] [ -sx] path key ... Remove records at once. kcpolymgr getbulk [ -onl| -otl| -onr] [ -sx] [ -px] path key ... Retrieve records at once. kcpolymgr check [ -onl| -otl| -onr] path Checks consistency. Options feature the following. -otr : opens the database with the truncation option. -onl : opens the database with the no locking option. -otl : opens the database with the try locking option. -onr : opens the database with the no auto repair option. -st : prints miscellaneous information. -add : performs adding operation. -app : performs appending operation. -rep : performs replacing operation. -inci : performs integer increment operation. -incd : performs real number increment operation. -sx : the input data is evaluated as a hexadecimal data string. -rm : removes the record. -px : the output data is converted into a hexadecimal data string. -pz : performs not append line feed at the end of the output. -mp : performs prefix matching instead of usual scan. -mr : performs regular expression matching instead of usual scan. -ms : performs similar matching instead of usual scan. -des : visits records in descending order. -max num : specifies the maximum number of shown records. -pv : prints values of records also. This command returns 0 on success, another on failure.","Process Name":"kcpolymgr","Link":"https:\/\/linux.die.net\/man\/1\/kcpolymgr"}},{"Process":{"Description":"The command 'kcpolytest' is a utility for facility test and performance test of the polymorphic database. This command is used in the following format. 'path' specifies the path of a database file. 'rnum' specifies the number of iterations. kcpolytest order [ -th num] [ -rnd] [ -set| -get| -getw| -rem| -etc] [ -tran] [ -oat| -onl| -onl| -otl| -onr][ -lv] path rnum Performs in-order tests. kcpolytest queue [ -th num] [ -it num] [ -rnd] [ -oat| -onl| -onl| -otl| -onr] [ -lv] path rnum Performs queuing operations. kcpolytest wicked [ -th num] [ -it num] [ -oat| -onl| -onl| -otl| -onr] [ -lv] path rnum Performs mixed operations selected at random. kcpolytest tran [ -th num] [ -it num] [ -hard] [ -oat| -onl| -onl| -otl| -onr] [ -lv] path rnum Performs test of transaction. kcpolytest mapred [ -rnd] [ -ru] [ -oat| -onl| -onl| -otl| -onr] [ -lv] [ -tmp str] [ -dbnum num][ -clim num] [ -cbnum num] [ -xnl] [ -xpm] [ -xpr] [ -xpf] [ -xnc] path rnum Performs MapReduce operations. kcpolytest index [ -th num] [ -rnd] [ -set| -get| -rem| -etc] [ -tran] [ -oat| -onl| -onl| -otl| -onr][ -lv] path rnum Performs indexing operations. kcpolytest misc path Performs miscellaneous tests. Options feature the following. -th num : specifies the number of worker threads. -rnd : performs random test. -set : performs setting operation only. -get : performs getting operation only. -getw : performs getting with a buffer operation only. -rem : performs removing operation only. -etc : performs miscellaneous operations. -tran : performs transaction. -oat : opens the database with the auto transaction option. -oas : opens the database with the auto synchronization option. -onl : opens the database with the no locking option. -otl : opens the database with the try locking option. -onr : opens the database with the no auto repair option. -lv : reports all errors. -it num : specifies the number of repetition. -hard : performs physical synchronization. -ru : reuses the existing database. -tmp str : specifies the path of a directory for temporary storage. -dbnum num : specifies the number of temporary databases. -clim num : specifies the limit size of cache memory. -cbnum num : specifies the bucket number of cache memory. -xnl : executes with the no locking option. -xpm : executes with the parallel mapper option. -xpr : executes with the parallel reducer option. -xpf : executes with the parallel flusher option. -xnc : executes with the no compression option. This command returns 0 on success, another on failure.","Process Name":"kcpolytest","Link":"https:\/\/linux.die.net\/man\/1\/kcpolytest"}},{"Process":{"Description":null,"Process Name":"kcprototest","Link":"https:\/\/linux.die.net\/man\/1\/kcprototest"}},{"Process":{"Description":"The command 'kcstashtest' is a utility for facility test and performance test of the stash database. This command is used in the following format. 'rnum' specifies the number of iterations. kccachetest order [ -th num] [ -rnd] [ -etc] [ -tran] [ -bnum num] [ -lv] rnum Performs in-order tests. kccachetest queue [ -th num] [ -it num] [ -rnd] [ -bnum num] [ -lv] rnum Performs queuing operations. kccachetest wicked [ -th num] [ -it num] [ -bnum num] [ -lv] rnum Performs mixed operations selected at random. kccachetest tran [ -th num] [ -it num] [ -bnum num] [ -lv] rnum Performs test of transaction. Options feature the following. -th num : specifies the number of worker threads. -rnd : performs random test. -etc : performs miscellaneous operations. -tran : performs transaction. -bnum num : specifies the number of buckets of the hash table. -lv : reports all errors. -it num : specifies the number of repetition. This command returns 0 on success, another on failure. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"kcstashtest","Link":"https:\/\/linux.die.net\/man\/1\/kcstashtest"}},{"Process":{"Description":"The command 'kctreemgr' is a utility for test and debugging of the file tree database and its applications. 'path' specifies the path of a database file. 'key' specifies the key of a record. 'value' specifies the value of a record. 'file' specifies the input\/output file. kctreemgr create [ -otr] [ -onl| -otl| -onr] [ -apow num] [ -fpow num] [ -ts] [ -tl] [ -tc][ -bnum num] [ -psiz num] [ -rcd| -rcld| -rcdd] path Creates a database file. kctreemgr inform [ -onl| -otl| -onr] [ -st] path Prints status information. kctreemgr set [ -onl| -otl| -onr] [ -add| -app| -rep| -inci| -incd] [ -sx] path key value Stores a record. kctreemgr remove [ -onl| -otl| -onr] [ -sx] path key Removes a record. kctreemgr get [ -onl| -otl| -onr] [ -rm] [ -sx] [ -px] [ -pz] path key Prints the value of a record. kctreemgr list [ -onl| -otl| -onr] [ -des] [ -max num] [ -rm] [ -sx] [ -pv] [ -px] path [ key] Prints keys of all records, separated by line feeds. kctreemgr clear [ -onl| -otl| -onr] path Removes all records of a database. kctreemgr import [ -onl| -otl| -onr] [ -sx] path [ file] Imports records from a TSV file. kctreemgr copy [ -onl| -otl| -onr] path file Copies the whole database. kctreemgr dump [ -onl| -otl| -onr] path [ file] Dumps records into a snapshot file. kctreemgr load [ -otr] [ -onl| -otl| -onr] path [ file] Loads records from a snapshot file. kctreemgr defrag [ -onl| -otl| -onr] path Performs defragmentation. kctreemgr setbulk [ -onl| -otl| -onr] path key value ... Store records at once. kctreemgr removebulk [ -onl| -otl| -onr] [ -sx] path key ... Remove records at once. kctreemgr getbulk [ -onl| -otl| -onr] [ -sx] [ -px] path key ... Retrieve records at once. kctreemgr check [ -onl| -otl| -onr] path Checks consistency. Options feature the following. -otr : opens the database with the truncation option. -onl : opens the database with the no locking option. -otl : opens the database with the try locking option. -onr : opens the database with the no auto repair option. -apow num : specifies the power of the alignment of record size. -fpow num : specifies the power of the capacity of the free block pool. -ts : tunes the database with the small option. -tl : tunes the database with the linear option. -tc : tunes the database with the compression option. -bnum num : specifies the number of buckets of the hash table. -psiz num : specifies the size of each page. -rcd : use the decimal comparator instead of the lexical one. -rcld : use the lexical descending comparator instead of the ascending one. -rcdd : use the decimal descending comparator instead of the lexical one. -st : prints miscellaneous information. -add : performs adding operation. -app : performs appending operation. -rep : performs replacing operation. -inci : performs integer increment operation. -incd : performs real number increment operation. -sx : the input data is evaluated as a hexadecimal data string. -rm : removes the record. -px : the output data is converted into a hexadecimal data string. -pz : does not append line feed at the end of the output. -des : visits records in descending order. -max num : specifies the maximum number of shown records. -pv : prints values of records also. This command returns 0 on success, another on failure.","Process Name":"kctreemgr","Link":"https:\/\/linux.die.net\/man\/1\/kctreemgr"}},{"Process":{"Description":"The command 'kctreetest' is a utility for facility test and performance test of the file tree database. This command is used in the following format. 'path' specifies the path of a database file. 'rnum' specifies the number of iterations. kctreetest order [ -th num] [ -rnd] [ -set| -get| -getw| -rem| -etc] [ -tran] [ -oat| -onl| -onl| -otl| -onr][ -apow num] [ -fpow num] [ -ts] [ -tl] [ -tc] [ -bnum num] [ -psiz num] [ -msiz num] [ -dfunit num] [ -pccap num] [ -rcd| -rcld| -rcdd] [ -lv] path rnum Performs in-order tests. kctreetest queue [ -th num] [ -it num] [ -rnd] [ -oat| -onl| -onl| -otl| -onr] [ -apow num] [ -fpow num] [ -ts] [ -tl] [ -tc] [ -bnum num] [ -psiz num] [ -msiz num] [ -dfunit num] [ -pccap num] [ -rcd| -rcld| -rcdd] [ -lv] path rnum Performs queuing operations. kctreetest wicked [ -th num] [ -it num] [ -oat| -onl| -onl| -otl| -onr] [ -apow num] [ -fpow num] [ -ts] [ -tl] [ -tc] [ -bnum num] [ -psiz num] [ -msiz num] [ -dfunit num] [ -pccap num] [ -rcd| -rcld| -rcdd] [ -lv] path rnum Performs mixed operations selected at random. kctreetest tran [ -th num] [ -it num] [ -hard] [ -oat| -onl| -onl| -otl| -onr] [ -apow num] [ -fpow num] [ -ts] [ -tl] [ -tc] [ -bnum num] [ -psiz num] [ -msiz num] [ -dfunit num] [ -pccap num] [ -rcd| -rcld| -rcdd] [ -lv] path rnum Performs test of transaction. Options feature the following. -th num : specifies the number of worker threads. -rnd : performs random test. -set : performs setting operation only. -get : performs getting operation only. -getw : performs getting with a buffer operation only. -rem : performs removing operation only. -etc : performs miscellaneous operations. -tran : performs transaction. -oat : opens the database with the auto transaction option. -oas : opens the database with the auto synchronization option. -onl : opens the database with the no locking option. -otl : opens the database with the try locking option. -onr : opens the database with the no auto repair option. -apow num : specifies the power of the alignment of record size. -fpow num : specifies the power of the capacity of the free block pool. -ts : tunes the database with the small option. -tl : tunes the database with the linear option. -tc : tunes the database with the compression option. -bnum num : specifies the number of buckets of the hash table. -psiz num : specifies the size of each page. -msiz num : specifies the size of the memory-mapped region. -dfunit num : specifies the unit step number of auto defragmentation. -pccap num : specifies the capacity size of the page cache. -rcd : use the decimal comparator instead of the lexical one. -rcld : use the lexical descending comparator instead of the ascending one. -rcdd : use the decimal descending comparator instead of the lexical one. -lv : reports all errors. -it num : specifies the number of repetition. -hard : performs physical synchronization. This command returns 0 on success, another on failure.","Process Name":"kctreetest","Link":"https:\/\/linux.die.net\/man\/1\/kctreetest"}},{"Process":{"Description":null,"Process Name":"kcutilmgr","Link":"https:\/\/linux.die.net\/man\/1\/kcutilmgr"}},{"Process":{"Description":"The command 'kcutiltest' is a utility for facility test and performance test of the utility functions. This command is used in the following format. 'rnum' specifies the number of iterations. 'path' specifies the path of a file. kcutiltest mutex [ -th num] [ -iv num] rnum Performs test of lock primitives. kcutiltest cond [ -th num] [ -iv num] rnum Performs test of condition variable primitives. kcutiltest para [ -th num] [ -iv num] rnum Performs test of parallel processing. kcutiltest file [ -th num] [ -rnd] [ -msiz num] path rnum Performs test of the file system abstraction. kcutiltest lhmap [ -rnd] [ -bnum num] rnum Performs test of doubly-linked hash map. kcutiltest thmap [ -rnd] [ -bnum num] rnum Performs test of memory-saving hash map. kcutiltest talist [ -rnd] rnum Performs test of memory-saving array list. kcutiltest misc rnum Performs test of miscellaneous mechanisms. Options feature the following. -th num : specifies the number of worker threads. -iv num : specifies the interval between iterations. -rnd : performs random test. -msiz num : specifies the size of the memory-mapped region. -bnum num : specifies the number of buckets of the hash table. This command returns 0 on success, another on failure.","Process Name":"kcutiltest","Link":"https:\/\/linux.die.net\/man\/1\/kcutiltest"}},{"Process":{"Description":"kde-build has been designed to keep a local copy of several KDE modules up to date and recompile them. Those modules have to be saved in a common directory, e.g. something like ~\/kde-src\/\n  │\n  +-> kdelibs\/\n  │\n  +-> kdebase\/\n  │\n  \\-> kdenetwork\/ In this case, the KDE source directory would be ~\/kde-src\/. The script will take care of compiling them in the correct order, checks for dependencies and resolves them as far as possible. Please note that, prior to first invocation of the script, the configuration file 'kde-buildrc' has to be modified to reflect the local environment, such as paths etc.","Process Name":"kde-build","Link":"https:\/\/linux.die.net\/man\/1\/kde-build"}},{"Process":{"Description":"kde4-config is a command line program used to retrieve information about KDE installation or user paths. Use this program to determine where the various aspects of the KDE installation reside on your system.","Process Name":"kde4-config","Link":"https:\/\/linux.die.net\/man\/1\/kde4-config"}},{"Process":{"Description":null,"Process Name":"kdecmake","Link":"https:\/\/linux.die.net\/man\/1\/kdecmake"}},{"Process":{"Description":"","Process Name":"kdestroy","Link":"https:\/\/linux.die.net\/man\/1\/kdestroy"}},{"Process":{"Description":"KDE su is a graphical front end for the UNIX® su command for the K Desktop Environment. It allows you to run a program as different user by supplying the password for that user. KDE su is an unprivileged program; it uses the system's su. KDE su has one additional feature: it can optionally remember passwords for you. If you are using this feature, you only need to enter the password once for each command. This program is meant to be started from the command line or from .desktop files.","Process Name":"kdesu","Link":"https:\/\/linux.die.net\/man\/1\/kdesu"}},{"Process":{"Description":"A Subversion client for KDE (standalone application)","Process Name":"kdesvn","Link":"https:\/\/linux.die.net\/man\/1\/kdesvn"}},{"Process":{"Description":"The kdesvn-build script is used to automate the download, build, and install process for KDE (using Subversion). It is recommended that you first setup a .kdesvn-buildrc file in your home directory. Please refer to kdesvn-build help file in KDE help for information on how to write .kdesvn-buildrc, or consult the sample file which should have been included with this program. If you don't setup a .kdesvn-buildrc, a default set of options will be used, and a few modules will be built by default. After setting up .kdesvn-buildrc, you can run this program from either the command-line or from cron. It will automatically download the modules from Subversion, create the build system, and configure and make the modules you tell it to. You can use this program to install KDE as well, if you are building KDE for a single user. Note that kdesvn-build will try to install the modules by default. If you DO specify a package name, then your settings will still be read, but the script will try to build \/ install the package regardless of .kdesvn-buildrc kdesvn-build reads options in the following order: 1. From the command line. 2. From the file kdesvn-buildrc in the current directory. Note that the file is not a hidden file. 3. From the file ~\/.kdesvn-buildrc. 4. From a set of internal options. This utility is part of the KDE Software Development Kit.","Process Name":"kdesvn-build","Link":"https:\/\/linux.die.net\/man\/1\/kdesvn-build"}},{"Process":{"Description":null,"Process Name":"kdesvnaskpass","Link":"https:\/\/linux.die.net\/man\/1\/kdesvnaskpass"}},{"Process":{"Description":"This manual page documents briefly the kdiff3 tool. This manual page was written for the Debian distribution because the original program does not have a manual page. For comprehensive help, please see khelpcenter help:\/kdiff3. kdiff3 is a program that compares two or three input files shows the differences line by line and character by character provides an automatic merge-facility and an integrated editor for comfortable solving of merge-conflicts and has an intuitive graphical user interface and allows directory comparison and merge.","Process Name":"kdiff3","Link":"https:\/\/linux.die.net\/man\/1\/kdiff3"}},{"Process":{"Description":"The Kerberos system authenticates individual users in a network environment. After authenticating yourself to Kerberos, you can use Kerberos-enabled programs without having to present passwords. If you enter your username and kinit responds with this message: kinit(v5): Client not found in Kerberos database while getting initial credentials you haven't been registered as a Kerberos user. See your system administrator. A Kerberos name usually contains three parts. The first is the primary, which is usually a user's or service's name. The second is the instance, which in the case of a user is usually null. Some users may have privileged instances, however, such as ''root'' or ''admin''. In the case of a service, the instance is the fully qualified name of the machine on which it runs; i.e. there can be an rlogin service running on the machine ABC, which is different from the rlogin service running on the machine XYZ. The third part of a Kerberos name is the realm. The realm corresponds to the Kerberos service providing authentication for the principal. When writing a Kerberos name, the principal name is separated from the instance (if not null) by a slash, and the realm (if not the local realm) follows, preceded by an ''@'' sign. The following are examples of valid Kerberos names: david\njennifer\/admin\njoeuser@BLEEP.COM\ncbrown\/root@FUBAR.ORG When you authenticate yourself with Kerberos you get an initial Kerberos ticket. (A Kerberos ticket is an encrypted protocol message that provides authentication.) Kerberos uses this ticket for network utilities such as rlogin and rcp. The ticket transactions are done transparently, so you don't have to worry about their management. Note, however, that tickets expire. Privileged tickets, such as those with the instance ''root'', expire in a few minutes, while tickets that carry more ordinary privileges may be good for several hours or a day, depending on the installation's policy. If your login session extends beyond the time limit, you will have to re-authenticate yourself to Kerberos to get new tickets. Use the kinit command to re-authenticate yourself. If you use the kinit command to get your tickets, make sure you use the kdestroy command to destroy your tickets before you end your login session. You should put the kdestroy command in your .logout file so that your tickets will be destroyed automatically when you logout. For more information about the kinit and kdestroy commands, see the kinit(1) and kdestroy(1) manual pages. Kerberos tickets can be forwarded. In order to forward tickets, you must request forwardable tickets when you kinit. Once you have forwardable tickets, most Kerberos programs have a command line option to forward them to the remote host.","Process Name":"kerberos","Link":"https:\/\/linux.die.net\/man\/1\/kerberos"}},{"Process":{"Description":null,"Process Name":"kermit","Link":"https:\/\/linux.die.net\/man\/1\/kermit"}},{"Process":{"Description":"The keyarch program archives old KSK and ZSK keys. Keys are considered old if they are revoked or obsolete. Keys marked as either kskrev or zskrev are revoked; keys marked as either kskobs or zskobs are obsolete. Archived keys are prefixed with the seconds-since-epoch as a means of distinguishing a zone's keys that have the same five digit number. If the required file argument is a keyrec file, then expired keys listed in that file are archived. If the file argument is a rollrec file, the keyrec files of the zones in that file are checked for expired keys. If the -zone option is given, then only revoked and obsolete keys belonging to the specified zone will be archived. The archive directory is either zone-specific (listed in the zone's keyrec record in the zone's keyrec file) or the default archive directory given in the DNSSEC-Tools configuration file. The count of archived keys is given as the program's exit code. Error exit codes are negative.","Process Name":"keyarch","Link":"https:\/\/linux.die.net\/man\/1\/keyarch"}},{"Process":{"Description":"keychain is a manager for ssh-agent, typically run from ~\/.bash_profile. It allows your shells and cron jobs to share a single ssh-agent process. By default, the ssh-agent started by keychain is long-running and will continue to run, even after you have logged out from the system. If you want to change this behavior, take a look at the --clear and --timeout options, described below. When keychain is run, it checks for a running ssh-agent, otherwise it starts one. It saves the ssh-agent environment variables to ~\/.keychain\/${ HOSTNAME }-sh, so that subsequent logins and non-interactive shells such as cron jobs can source the file and make passwordless ssh connections. In addition, when keychain runs, it verifies that the key files specified on the command-line are known to ssh-agent, otherwise it loads them, prompting you for a password if necessary. Keychain also supports gpg-agent in the same ways that ssh-agent is supported. By default keychain attempts to start all available agents but will fall back to only gpg-agent or only ssh-agent if either is unavailable. You can specifically limit keychain using the --agents option. keychain supports most UNIX-like operating systems, including Cygwin. It works with Bourne-compatible, csh-compatible and fish shells.","Process Name":"keychain","Link":"https:\/\/linux.die.net\/man\/1\/keychain"}},{"Process":{"Description":"This program is used to control the key management facility in various ways using a variety of subcommands.","Process Name":"keyctl","Link":"https:\/\/linux.die.net\/man\/1\/keyctl"}},{"Process":{"Description":"Change the names of keywords in FITS or IRAF image headers. Each current image keyword whose entry is to be modified should be followed by an equal sign and a second keyword, with no intervening spaces. If the -r option is used, the value of the second keyword is transfered to that of the first. Otherwise, the name of the first keyword is changed to the second keyword. To change keywords in a list of files, substitute @<listfile> for the file names on the command line. To change a lot of keywords, put them, one pair separated by an = sign with no spaces per line, in a file and substitute @<keylistfile> on the command line. If two @ commands are present, the program will figure out which contains file names and which contains keywords. Lines in a keyword list file which do not contain an = are ignored.","Process Name":"keyhead","Link":"https:\/\/linux.die.net\/man\/1\/keyhead"}},{"Process":{"Description":null,"Process Name":"keymod","Link":"https:\/\/linux.die.net\/man\/1\/keymod"}},{"Process":{"Description":"keyrand is a tool which collects a given number of random bits from the kernel random number generator, presenting a text-based user interface showing progress. The random data is read from \/dev\/random and appended to the output file outfile, which must already exist.","Process Name":"keyrand","Link":"https:\/\/linux.die.net\/man\/1\/keyrand"}},{"Process":{"Description":"","Process Name":"keystone-all","Link":"https:\/\/linux.die.net\/man\/1\/keystone-all"}},{"Process":{"Description":"","Process Name":"keystone-manage","Link":"https:\/\/linux.die.net\/man\/1\/keystone-manage"}},{"Process":{"Description":"keytool is a key and certificate management utility. It allows users to administer their own public\/private key pairs and associated certificates for use in self-authentication (where the user authenticates himself\/herself to other users\/services) or data integrity and authentication services, using digital signatures. It also allows users to cache the public keys (in the form of certificates) of their communicating peers. A certificate is a digitally signed statement from one entity (person, company, etc.), saying that the public key (and some other information) of some other entity has a particular value. (See Certificates.) When data is digitally signed, the signature can be verified to check the data integrity and authenticity. Integrity means that the data has not been modified or tampered with, and authenticity means the data indeed comes from whoever claims to have created and signed it. keytool also enables users to administer secret keys used in symmetric encryption\/decryption (e.g. DES). keytool stores the keys and certificates in a keystore.","Process Name":"keytool-java-1.6.0-openjdk","Link":"https:\/\/linux.die.net\/man\/1\/keytool-java-1.6.0-openjdk"}},{"Process":{"Description":null,"Process Name":"keytool-java-1.7.0-openjdk","Link":"https:\/\/linux.die.net\/man\/1\/keytool-java-1.7.0-openjdk"}},{"Process":{"Description":"The Find Files tool is a useful method of searching for specific files on your computer, or for searching for files that match a pattern. An example of this could include searching for files of a particular type or with certain letters in the filename, or that contain a certain piece of text in their contents. KFind is a graphical tool, and not normally run from the command line.","Process Name":"kfind","Link":"https:\/\/linux.die.net\/man\/1\/kfind"}},{"Process":{"Description":null,"Process Name":"kflickr","Link":"https:\/\/linux.die.net\/man\/1\/kflickr"}},{"Process":{"Description":"khotswap is a KDE frontend for the hotswap(1) program. It allows you to interactively register and unregister hotswappable IDE devices, for example notebook computer modules, with the Linux kernel.","Process Name":"khotswap","Link":"https:\/\/linux.die.net\/man\/1\/khotswap"}},{"Process":{"Description":null,"Process Name":"kibitz","Link":"https:\/\/linux.die.net\/man\/1\/kibitz"}},{"Process":{"Description":"This manual page documents briefly the KildClient program. KildClient is a MUD Client written with the GTK+ windowing toolkit. It supports many common features of other clients, such as triggers, gags, aliases, macros, timers, and much more. But its main feature is the built-in Perl interpreter. You can at any moment execute Perl statements and functions to do things much more powerful than simply sending text the the mud. Perl statements can also be run, for example, as the action of a trigger, allowing you to do complex things. Some built-in functions of KildClient allow interaction with the world, such as sending commands to it. You can specify the name of one or more saved Worlds in the command line, this\/these World(s) will be automatically opened. If you do not specify any World, you are prompted for the MUD to connect to. You can enter the host and port directly, or you can select from a list of saved MUDs. Once connected, type commands in the separate entry box and press ENTER to send them to the MUD. You can edit the commands before sending, since they only get sent when ENTER is pressed. You can recall previous commands with the arrow keys, or by pressing the button to the right of the command entry box. There are many more features, many options for configuring the program's behaviour. For more details, see the KildClient manual, which is usually installed in the \/usr\/share\/doc\/kildclient directory.","Process Name":"kildclient","Link":"https:\/\/linux.die.net\/man\/1\/kildclient"}},{"Process":{"Description":null,"Process Name":"kill","Link":"https:\/\/linux.die.net\/man\/1\/kill"}},{"Process":{"Description":null,"Process Name":"killall","Link":"https:\/\/linux.die.net\/man\/1\/killall"}},{"Process":{"Description":null,"Process Name":"kinit","Link":"https:\/\/linux.die.net\/man\/1\/kinit"}},{"Process":{"Description":"kino allows you to import movies from DV camcorders, to edit, and play them. file may be a DV encoded file that will be loaded at startup. Alternatively, you can specify a SMIL playlist of DV files that was previously created with kino. DV is a special kind of video encoding, commonly used in digital camcorders. Differently coded movies, like DivX or mjpeg, need to be converted to DV before they can be fed into kino. A video file either holds the raw DV-coded data, or wraps it in a certain container format. Kino currently supports AVI, and QuickTime containers, and distinguishes between the different formats by file extension. Therefore, file names need to end in .dv or .dif for raw files, .avi for AVI, and .mov for QuickTime files, respectively. Anything else is treated as a SMIL playlist.","Process Name":"kino","Link":"https:\/\/linux.die.net\/man\/1\/kino"}},{"Process":{"Description":null,"Process Name":"kino2raw","Link":"https:\/\/linux.die.net\/man\/1\/kino2raw"}},{"Process":{"Description":"Kinput2 is an X window application to input Japanese text. It acts as a front-end for other applications that want kana-kanji conversion. When invoked, after some initialization (which will take about a few to 30 seconds depending on your machine) kinput2 waits quietly for a Japanese text input request from another client (i.e. no windows appear). When kinput2 receives a request, it pops up a window and starts conversion process. It sends the converted text back to the client when the text is fixed. Kinput2 has some big improvements over its predecessor, kinput, which was contributed to X11R4. Over-the-spot\/On-the-spot Input These features enable conversion process to be done at cursor position, avoiding unnecessary movement of eyes between cursor position and conversion window. Kinput2 also supports root window style input and off-the-spot style input. Multiple Protocol Support Kinput2 supports several conversion protocols between front-end and client. Supported protocols are:     kinput protocol\n    kinput2 protocol\n    Matsushita jinput protocol\n    Sony xlc protocol\n    XIMP protocol\n    X Input Method Protocol (X Consortium standard) Multiple Conversion Engine Support Kinput2 can use 4 different conversion engines, Wnn, Canna, Sj3 and Atok. You can choose one at compilation time, or at run time. Kinput Compatibility Kinput2 is fully upward-compatible with kinput, so applications which use kinput as the front-end can also use kinput2. In this case, the applications cannot take advantage of over-the-spot conversion, though.","Process Name":"kinput2","Link":"https:\/\/linux.die.net\/man\/1\/kinput2"}},{"Process":{"Description":"Kismet is an 802.11 layer2 wireless network detector, sniffer, and intrusion detection system. Kismet will work with any wireless card which supports raw monitoring (rfmon) mode, and can sniff 802.11b, 802.11a, and 802.11g traffic. Kismet identifies networks by passively collecting packets and detecting standard named networks, detecting (and given time, decloaking) hidden networks, and inferring the presence of nonbeaconing networks via data traffic. kismet supports logging to the wtapfile packet format (readable by tcpdump and ethereal) and saves detected network informat as plaintext, CSV, and XML. kismet is capable of using any GPS supported by gpsd and logs and plots network data. kismet is divided into three basic programs, kismet_server kismet_client and gpsmap","Process Name":"kismet","Link":"https:\/\/linux.die.net\/man\/1\/kismet"}},{"Process":{"Description":"kismet_drone supports all the capture sources available to Kismet. Instead of processing packets locally, kismet_drone makes them available via TCP to a remote kismet_server using the 'drone' capture source.","Process Name":"kismet_drone","Link":"https:\/\/linux.die.net\/man\/1\/kismet_drone"}},{"Process":{"Description":null,"Process Name":"kjs","Link":"https:\/\/linux.die.net\/man\/1\/kjs"}},{"Process":{"Description":"kjscmd is a tool for launching KJSEmbed scripts from the command line. It will run the scripts contained in the named file using KJSEmbed. It does not accept - (stdin) as a file.","Process Name":"kjscmd","Link":"https:\/\/linux.die.net\/man\/1\/kjscmd"}},{"Process":{"Description":null,"Process Name":"klammern","Link":"https:\/\/linux.die.net\/man\/1\/klammern"}},{"Process":{"Description":"Klavaro is a program that teachs you to touch type and\/or helps you to improve your skills with the keyboard. There is an advanced manual at: http:\/\/klavaro.sourceforge.net","Process Name":"klavaro","Link":"https:\/\/linux.die.net\/man\/1\/klavaro"}},{"Process":{"Description":"Klavaro Helper is a program to help the Klavaro program on managing scorings saved at \/var\/games\/klavaro. You're not supposed to use it directly, as its name suggests, it's just a \"helper\" for klavaro. http:\/\/klavaro.sourceforge.net","Process Name":"klavaro_helper","Link":"https:\/\/linux.die.net\/man\/1\/klavaro_helper"}},{"Process":{"Description":null,"Process Name":"klein","Link":"https:\/\/linux.die.net\/man\/1\/klein"}},{"Process":{"Description":"Klist lists the Kerberos principal and Kerberos tickets held in a credentials cache, or the keys held in a keytab file.","Process Name":"klist","Link":"https:\/\/linux.die.net\/man\/1\/klist"}},{"Process":{"Description":"The klpc program performs control operations on a LPRng print server.","Process Name":"klpc","Link":"https:\/\/linux.die.net\/man\/1\/klpc"}},{"Process":{"Description":"The program prints a short printer status message. It uses SNMP to retrieve the printer status, the OIDs ''HOST-RESOURCES-MIB::hrDeviceStatus'' and ''HOST-RESOURCES-MIB::hrPrinterStatus'' are retrieved. No snmpyalc.cfg file is needed but in yanolc.cfg we need an ''snmp'' entry for the print queue to find host, SNMP version and SNMP community. A dummy SNMP type name can be used.","Process Name":"klpinfo","Link":"https:\/\/linux.die.net\/man\/1\/klpinfo"}},{"Process":{"Description":null,"Process Name":"klpq","Link":"https:\/\/linux.die.net\/man\/1\/klpq"}},{"Process":{"Description":"The klpr programs sends a file to a print server. Depending on the print server type ( LPR , LPRng or raw socket) the file is either spooled for printing or printed directly.","Process Name":"klpr","Link":"https:\/\/linux.die.net\/man\/1\/klpr"}},{"Process":{"Description":"The klprm program removes the specified print jobs from the queue.","Process Name":"klprm","Link":"https:\/\/linux.die.net\/man\/1\/klprm"}},{"Process":{"Description":null,"Process Name":"kls","Link":"https:\/\/linux.die.net\/man\/1\/kls"}},{"Process":{"Description":"kmag, also known as KMagnifier is a screen magnifier. You can use KMagnifier to magnify a part of the screen just as you would use a lens to magnify a newspaper fine-print or a photograph. This application is useful for a variety of people: from researchers to artists to web-designers to people with low vision.","Process Name":"kmag","Link":"https:\/\/linux.die.net\/man\/1\/kmag"}},{"Process":{"Description":null,"Process Name":"kml2gmt","Link":"https:\/\/linux.die.net\/man\/1\/kml2gmt"}},{"Process":{"Description":"KMouseTool clicks the mouse whenever the mouse cursor pauses briefly. It was designed to help those with repetitive strain injuries, for whom pressing buttons hurts. KMouseTool can also be configured to wait for a specified time for a drag to begin, before unclicking the mouse. This way, you can use it for drag and drop operations as well.","Process Name":"kmousetool","Link":"https:\/\/linux.die.net\/man\/1\/kmousetool"}},{"Process":{"Description":null,"Process Name":"kmouth","Link":"https:\/\/linux.die.net\/man\/1\/kmouth"}},{"Process":{"Description":"KMuddy is a feature-rich MUD(Multi-User Dungeon) client for KDE. Currently supported features include ANSI color, tabbed connection window, MCCP v1\/v2 compression, configurable colors and short-cuts, split-screen output history, command history, connection profiles, intelligent word-wrapping, flexible aliases and triggers with POSIX regular expressions, session transcripts, macro keys, external scripting, scripting variables, Mud Sound Protocol, and more. For more detailed information, see the KMuddy Handbook in the KDE help section.","Process Name":"kmuddy","Link":"https:\/\/linux.die.net\/man\/1\/kmuddy"}},{"Process":{"Description":null,"Process Name":"kmymoney2","Link":"https:\/\/linux.die.net\/man\/1\/kmymoney2"}},{"Process":{"Description":"knock is a port-knock client. It sends TCP\/UDP packets to each specified port on host, creating a special knock sequence on the listening server (see the knockd manpage for more info on this).","Process Name":"knock","Link":"https:\/\/linux.die.net\/man\/1\/knock"}},{"Process":{"Description":null,"Process Name":"knockd","Link":"https:\/\/linux.die.net\/man\/1\/knockd"}},{"Process":{"Description":"Koan stands for \"kickstart-over-a-network\" and is a client-side helper program for use with Cobbler. koan allows for both network provisioning of new virtualized guests (Xen, QEMU\/KVM , VMware) and re-installation of an existing system. When invoked, koan requests install information from a remote cobbler boot server, it then kicks off installations based on what is retrieved from cobbler and fed in on the koan command line. The examples below show the various use cases.","Process Name":"koan","Link":"https:\/\/linux.die.net\/man\/1\/koan"}},{"Process":{"Description":"1. What are Kth order co-occurrences? Co-occurrences are the words which occur together in the same context. All words which co-occur with a given target word are called its co-occurrences. The concept of 2nd order co-occurrences is explained in the paper Automatic word Sense Discrimination [Schutze98]. According to this paper, the words which co-occur with the co-occurring words of a target word are called as the 2nd order co-occurrences of that word. So with each increasing order of co-occurrences, we introduce an extra level of indirection and find words co-occurring with the previous order co-occurrences. We generalize the concept of 2nd order co-occurrences from [Schutze98] to find the Kth order co-occurrences of a word. These are the words that co-occur with the (K-1)th order co-occurrences of a given target word. We have also found [Niwa&Nitta94] to be related to kocos. While we do not exactly reimplement the co-occurrence vectors they propose, we feel that kocos is at least similar in spirit. 2. Usage Usage: kocos.pl [ OPTIONS ] BIGRAM 3. Input 3.1 BIGRAM Specify the BIGRAM file name on the command line after the program name and options (if any) as shown in the usage note. BIGRAM should be a bigram output(normal or extended) created by NSP programs - count.pl, statistic.pl or combig.pl. When count.pl and statistic.pl are run for creating bigrams (--ngram set to 2 or not specified), the programs list the bigrams of all words which co-occur together(in certain window). So we can say that if a bigram 'word1<>word2<>' is listed in the output of count.pl or statistic.pl program, it means that the words word1 and word2 are the co-occurrences of each other. In general you may want to consider the use of stop lists (--stop option in count.pl) to remove very common words such as \"the\" and \"for\", and also eliminate low frequency bigrams (--remove option in count.pl). The stop list is particularly important as high frequency words such as \"the\" or \"for\" will co-occur with many different words, and greatly expand the search needed to find kth order co-occurrences. If you want to run kocos.pl on a source file not created by either count or statistic program of this package, just make sure that each line of BIGRAM file will list two words WORD1 and WORD2 as WORD1<>WORD2<> The program minimally requires that there are exactly two words and they are separated by delimiter '<>' with an extra delimiter '<>' after the second word. So you may convert any non NSP input to this format where two words occurring in the same context are '<>' separated and provide it to kocos. Controlling scope of the context You may like to call two words as co-occurrences of each other if they occur within a specific distance from each other. We encourage in this case that you use --window w option of NSP program count.pl while creating a BIGRAM file. This will create bigrams of all words which co-occur within a distance w from each other. Thus --window w sets the maximum distance allowed between two words to call them co-occurrences of each other. Note that if the --window option is not used while creating BIGRAM input for kocos, only those words which come immediately next to each other will be considered as the co-occurrences (default window size being 2 for bigrams). 4. Options 4.1 --literal WORD With this option, the target WORD whose kth order co-occurrences are to be found can be directly specified on the command line. e.g. kocos.pl --literal line test.input will find the 1st order co-occurrences (by default) of the word 'line' using Bigrams listed in file test.input.         kocos.pl --literal , --order 3 test.input\nwill find 3rd order co-occurrences of ',' from file test.input. 4.2 --regex REGEXFILE With this option, target word can be specified using Perl regular expression\/s. The regex\/s should be written in a file and multiple regex\/s should either appear on separate lines or should be Perl ' OR ' (|) separated. We provide this option to allow user to specify various morphological variants of the target word e.g. line, lines, Line,Lines etc. e.g. (1) let test.regex contains a regular expression for target word which is - \/^[Ll]ines?$\/ To use this for finding kocos, run kocos.pl with command kocos.pl --regex test.regex --order K test.input (2) To find say 2nd order co-occurrences of any general target word which occurs in Data in <head> tags like Senseval Format, we use a regular expression \/^<head.*>\\w+<\/head>$\/ in our regex file say test.regex and run kocos.pl using command kocos.pl --regex test.regex --order 2 eng-lex-sample.training.xml (3) To find 3rd order co-occurrences of any word that contains period '.' run kocos.pl using kocos.pl --literal . --order 3 test.input Or write a regex \/\\.\/ in file say test.regex and run kocos using kocos.pl --regex test.regex --order 3 test.input (4) To find 2nd order co-occurrences of all words that are numbers, write a regex like \/^\\d+$\/ to a regexfile say test.regex and run kocos using, kocos.pl --regex test.regex --order 2 test.input Note: writing a regex \/\\d+\/ will also match words like line20.1.cord, or art%10.fine456 that include numbers. Regex\/s that should exactly match as target words should be delimited by ^ and $ as in \/^[Ll]ines?$\/. Specifying something like \/[Ll]ines?\/ will match with 'incline'. Note - The program kocos.pl requires that the target word is specified using either of the options --literal or --regex 4.3 --order K If the value of K is specified using the command line option --order K, kocos.pl will find the Kth order co-occurrences of the target word. K can take any integer value greater than 0. If the value of K is not specified, the program will set K to 1 and will simply find the co-occurrences of the target (the word co-occurrence generally means first order co-occurrences). 4.4 --trace TRACEFILE To see a detailed report of how each Kth order co-occurrence is reached as a sequence of K words, specify the name of a TRACEFILE on the command line using --trace TRACEFILE option. TRACEFILE will show the chains of K+1 words where the first word is the TARGET word and every ith word in the chain is a (i-1)th order co-occurrence of target which co-occurs with (i-1)th word in the chain. So a chain of K+1 words, TARGET->COC1->COC2->COC3....->COCK-1->COCK shows that COC1 is a first order co-occurrence of the TARGET . COC2 is a second order co-occurrence such that COC2 co-occurs with\nCOC1 which in turn co-occurs with the TARGET.\nCOC3 is a third order co-occurrence such that COC3 co-occurs with\nCOC2 which in turn co-occurs with COC1 which co-occurs with TARGET. and so on...... 4.6 --help This option will display the help message. 4.7 --version This option will display version information of the program. 5. Output The program will display a list of Kth order co-occurrences to standard output such that each co-occurrence occurs on a separate line and is followed by '<>' (just to be compatible with other programs in NSP ). Note that the output of kocos.pl could be directly used by the program nsp2regex of the SenseTools Package (by Satanjeev Banerjee and Ted Pedersen) to convert Senseval data instances into feature vectors in ARFF format where our Kth order co-occurrences are used as features. For more information on SenseTools you can refer to its README: http:\/\/www.d.umn.edu\/~tpederse\/sensetools.html IMPORTANT NOTE If there are some kth order co-occurrences which are also the ith order co-occurrences (0<i<k) of the target word, program kocos.pl will not display them as the Kth order co-occurrences. kocos.pl displays only those words as Kth order co-occurrences whose minimum distance from target word is K in the co-occurrence graph. [Co-occurrence graph shows a network of words where a word is connected to all words it co-occurs with.] 6. Usage examples (a) Using default value of order To find the (1st order) co-occurrences of a word 'line' from the BIGRAM file test.input, run kocos.pl using the following command. kocos.pl --literal line test.input (b) Using option order To find the 2nd order co-occurrences of a word 'line' from the BIGRAM file test.input, run kocos.pl using the following command. kocos.pl --literal line --order 2 test.input (c) Using the trace option To see how the 4th order co-occurrences of a word 'line' is reached as a sequence of words which form a co-occurrence chain, run kocos.pl using the following command. kocos.pl --literal line --order 4 --trace test.trace test.input (d) Using a Regex to specify the target word To find Kth order co-occurrences of a target word 'line' which is specified as a Perl regular expression say \/^[Ll]ines?$\/ in a file test.regex, run kocos.pl using kocos.pl --regex test.regex --order K test.input (e) Using a generic Regex for Data like Senseval-2, To find 2nd order co-occurrences of a target word that occurs in <head> tags in the data file eng-lex-sample.training.xml, use a regular expression like \/<head>\\w+<\/head>\/ from a file say test.regex, and run kocos.pl using kocos.pl --regex test.regex --order 2 test.input 7. General Recommendations (a) Create a BIGRAM file using programs count.pl, statistic.pl or combig.pl of NSP Package. (b) Use --window W option of program count.pl to specify the scope of the context. Any word that occurs within a distance W from a target word will be treated as its co-occurrence. (c) Use either --literal or --regex option to specify the target word. We recommend use of regex support to detect forms of target word other than its base form. 8. Examples of Kth order co-occurrences In all the following examples, we assume that the input comes from the file test.input and word 'line' is a target word. test.input =>\n----------------\nprint<>in<>    |\nprint<>line<>  |\ntext<>the<>    |\ntext<>line<>   |\nfile<>the<>    |\nfile<>in<>     |\nline<>file     |\n---------------- (Note that test.input doesn't look like a valid count\/statistic output because kocos.pl will minimally require two words WORD1 and WORD2 separated by '<>' with an extra '<>' after WORD2 as described in Section 3.1 of this README ) (a) The 1st order co-occurrences of word 'line' can be found by running kocos.pl with either of the following commands - kocos.pl --literal line test.input\n        OR\nkocos.pl --order 1 --literal line test.input This will display the co-occurrences of 'line' to standard output as shown below in the box. --------\ntext<> |\nfile<> |\nprint<>|\n-------- This is because the program finds the bigrams print<>line<>\ntext<>line<>\nline<>file<> where word 'line' co-occurs with the words print, text and file which become the 1st order co-occurrences. (b) The 2nd order co-occurrences of word 'line' can be found by running kocos.pl with the following command - kocos.pl --literal line --order 2 test.input This will display the 2nd order co-occurrences of 'line' to standard output as shown below in the box. --------\nthe<>  |\nin<>   |\n-------- This is because the program finds the words print, text and file as the first order co-occurrences (as explained in case a) and finds bigrams print<>in<>\ntext<>the<>\nfile<>the<>\nfile<>in where 'the' and 'in' co-occur with the words print, text, file. (c) To see how the 2nd order co-occurrences of word 'line' are reached run the program using the following command - kocos.pl --order 2 --trace test.trace test.input line This will display the 2nd order co-occurrences of 'line' to standard output as shown below in the box. --------\nthe<>   |\nin<>    |\n-------- and a detailed report of co-occurrence chains in test.trace file as shown in the box below. test.trace =>\n\n----------------\nline->text->the|\nline->file->the|\nline->file->in |\nline->print->in|\n---------------- where the first line shows that the word 'line' co-occurred with 'text' which co-occurred with 'the'. Hence 'the' became a 2nd order co-occurrence. Similarly, 'line' co-occurred with 'file' which in turn co-occurred with 'the' and 'in' which are therefore the 2nd order co-occurrences of 'line'. 11. References [Niwa&Nitta94] Y. Niwa and Y. Nitta. Co-occurrence vectors from corpora vs. distance vectors from dictionaries. COLING-1994 . [Schutze98] H. Schutze. Automatic word sense discrimination. Computational Linguistics,24(1):97-123,1998.","Process Name":"kocos.pl","Link":"https:\/\/linux.die.net\/man\/1\/kocos.pl"}},{"Process":{"Description":null,"Process Name":"koi8rxterm","Link":"https:\/\/linux.die.net\/man\/1\/koi8rxterm"}},{"Process":{"Description":null,"Process Name":"kombine","Link":"https:\/\/linux.die.net\/man\/1\/kombine"}},{"Process":{"Description":"KON is a program to display Kanji characters on a virtual console of Linux and FreeBSD. KON uses pty(4) to hook the I\/O for console, and displays Kanji characters by drawing the image of them on VGA or DCGA. KON can be invoked from another KON. In this situation, new KON runs on newly opened virtual console.","Process Name":"kon","Link":"https:\/\/linux.die.net\/man\/1\/kon"}},{"Process":{"Description":null,"Process Name":"konve","Link":"https:\/\/linux.die.net\/man\/1\/konve"}},{"Process":{"Description":"The kpasswd command is used to change a Kerberos principal's password. Kpasswd prompts for the current Kerberos password, which is used to obtain a changepw ticket from the KDC for the user's Kerberos realm. If kpasswd successfully obtains the changepw ticket, the user is prompted twice for the new password, and the password is changed. If the principal is governed by a policy that specifies the length and\/or number of character classes required in the new password, the new password must conform to the policy. (The five character classes are lower case, upper case, numbers, punctuation, and all other characters.)","Process Name":"kpasswd","Link":"https:\/\/linux.die.net\/man\/1\/kpasswd"}},{"Process":{"Description":null,"Process Name":"kpseaccess","Link":"https:\/\/linux.die.net\/man\/1\/kpseaccess"}},{"Process":{"Description":null,"Process Name":"kpsepath","Link":"https:\/\/linux.die.net\/man\/1\/kpsepath"}},{"Process":{"Description":"If file is a symbolic link, print its contents (what it links to), and exit successfully. Exit with a failure otherwise. On systems that do not support symbolic links, kpsereadlink will always fail.","Process Name":"kpsereadlink","Link":"https:\/\/linux.die.net\/man\/1\/kpsereadlink"}},{"Process":{"Description":"kpsestat prints the octal permission of file modified according to mode on standard output. The mode parameter accepts a subset of the symbolic permissions accepted by chmod(1). Use = as the mode to obtain the unchanged permissions.","Process Name":"kpsestat","Link":"https:\/\/linux.die.net\/man\/1\/kpsestat"}},{"Process":{"Description":null,"Process Name":"kpsetool","Link":"https:\/\/linux.die.net\/man\/1\/kpsetool"}},{"Process":{"Description":"kpsewhere is an extension to kpsewhich (as where is for which in tcsh). The intention is to provide a way to check for conflicts\/shadowed files. It will, however, only find one file per TEXMF tree.","Process Name":"kpsewhere","Link":"https:\/\/linux.die.net\/man\/1\/kpsewhere"}},{"Process":{"Description":null,"Process Name":"kpsewhich","Link":"https:\/\/linux.die.net\/man\/1\/kpsewhich"}},{"Process":{"Description":"kpsetool is a Bourne shell script that makes a TeXLive-style kpsetool, kpsexpand, and kpsepath available.","Process Name":"kpsexpand","Link":"https:\/\/linux.die.net\/man\/1\/kpsexpand"}},{"Process":{"Description":"The krb5-auth-dialog application will periodically check (every 30 seconds) if the user has Kerberos credentials, and if so, if they will expire soon (in less than 30 minutes). If it determines that this is the case, krb5-auth-dialog will attempt to obtain fresh credentials, prompting the user for whatever information is necessary.","Process Name":"krb5-auth-dialog","Link":"https:\/\/linux.die.net\/man\/1\/krb5-auth-dialog"}},{"Process":{"Description":"krb5-config tells the application programmer what special flags to use to compile and link programs against the installed Kerberos libraries.","Process Name":"krb5-config","Link":"https:\/\/linux.die.net\/man\/1\/krb5-config"}},{"Process":{"Description":"krb5-send-pr is a tool used to submit problem reports (PRs) to a central support site. In most cases the correct site will be the default. This argument indicates the support site which is responsible for the category of problem involved. Some sites may use a local address as a default. site values are defined by using the aliases(5). krb5-send-pr invokes an editor on a problem report template (after trying to fill in some fields with reasonable default values). When you exit the editor, krb5-send-pr sends the completed form to the Problem Report Management System (GNATS) at a central support site. At the support site, the PR is assigned a unique number and is stored in the GNATS database according to its category and submitter-id. GNATS automatically replies with an acknowledgement, citing the category and the PR number. To ensure that a PR is handled promptly, it should contain your (unique) submitter-id and one of the available categories to identify the problem area. (Use 'krb5-send-pr -L' to see a list of categories.) The krb5-send-pr template at your site should already be customized with your submitter-id (running 'install-sid submitter-id' to accomplish this is part of the installation procedures for krb5-send-pr). If this hasn't been done, see your system administrator for your submitter-id, or request one from your support site by invoking 'krb5-send-pr --request-id'. If your site does not distinguish between different user sites, or if you are not affiliated with the support site, use 'net' for this field. The more precise your problem description and the more complete your information, the faster your support team can solve your problems.","Process Name":"krb5-send-pr","Link":"https:\/\/linux.die.net\/man\/1\/krb5-send-pr"}},{"Process":{"Description":null,"Process Name":"krb524init","Link":"https:\/\/linux.die.net\/man\/1\/krb524init"}},{"Process":{"Description":null,"Process Name":"krenew","Link":"https:\/\/linux.die.net\/man\/1\/krenew"}},{"Process":{"Description":"This script checks a keyrec file for problems, potential problems, and inconsistencies. Recognized problems include: \u2022 no zones defined The keyrec file does not contain any zone keyrecs. \u2022 no sets defined The keyrec file does not contain any set keyrecs. \u2022 no keys defined The keyrec file does not contain any key keyrecs. \u2022 unknown zone keyrecs A set keyrec or a key keyrec references a non-existent zone keyrec. \u2022 missing key from zone keyrec A zone keyrec does not have both a KSK key and a ZSK key. \u2022 missing key from set keyrec A key listed in a set keyrec does not have a key keyrec. \u2022 expired zone keyrecs A zone has expired. \u2022 mislabeled key A key is labeled as a KSK (or ZSK ) and its owner zone has it labeled as the opposite. \u2022 invalid zone data values A zone's keyrec data are checked to ensure that they are valid. The following conditions are checked: existence of the zone file, existence of the KSK file, existence of the KSK and ZSK directories, the end-time is greater than one day, and the seconds-count and date string match. \u2022 invalid key data values A key's keyrec data are checked to ensure that they are valid. The following conditions are checked: valid encryption algorithm, key length falls within algorithm's size range, random generator file exists, and the seconds-count and date string match. Recognized potential problems include: \u2022 imminent zone expiration A zone will expire within one week. \u2022 odd zone-signing date A zone's recorded signing date is later than the current system clock. \u2022 orphaned keys A key keyrec is unreferenced by any set keyrec. \u2022 missing key directories A zone keyrec's key directories ( kskdirectory or zskdirectory) does not exist. Recognized inconsistencies include: \u2022 key-specific fields in a zone keyrec A zone keyrec contains key-specific entries. To allow for site-specific extensibility, krfcheck does not check for undefined keyrec fields. \u2022 zone-specific fields in a key keyrec A key keyrec contains zone-specific entries. To allow for site-specific extensibility, krfcheck does not check for undefined keyrec fields. \u2022 mismatched zone timestamp A zone's seconds-count timestamp does not match its textual timestamp. \u2022 mismatched set timestamp A set's seconds-count timestamp does not match its textual timestamp. \u2022 mismatched key timestamp A key's seconds-count timestamp does not match its textual timestamp.","Process Name":"krfcheck","Link":"https:\/\/linux.die.net\/man\/1\/krfcheck"}},{"Process":{"Description":null,"Process Name":"kross","Link":"https:\/\/linux.die.net\/man\/1\/kross"}},{"Process":{"Description":"Krusader is an advanced twin panel (commander style) file manager for KDE and other desktops in the *nix world, similar to Midnight or Total Commander. It provides all the file management features you could possibly want. Plus: extensive archive handling, mounted filesystem support, FTP, advanced search module, viewer\/editor, directory synchronisation, file content comparisons, powerful batch renaming and much much more. It supports the following archive formats: ace, arj, bzip2, deb, gzip, iso, lha, rar, rpm, tar, zip and 7-zip and can handle other KIOSlaves such as smb:\/\/ or fish:\/\/ It is (almost) completely customizable, very user friendly, fast and looks great on your desktop! :-) You should give it a try.","Process Name":"krusader","Link":"https:\/\/linux.die.net\/man\/1\/krusader"}},{"Process":{"Description":"","Process Name":"ksc","Link":"https:\/\/linux.die.net\/man\/1\/ksc"}},{"Process":{"Description":"ksh is a command interpreter that is intended for both interactive and shell script use. Its command language is a superset of the sh(1) shell language. Shell Startup The following options can be specified only on the command line: -c command-string the shell executes the command(s) contained in command-string -i interactive mode - see below -l login shell - see below interactive mode - see below -s the shell reads commands from standard input; all non-option arguments are positional parameters -r restricted mode - see below In addition to the above, the options described in the set built-in command can also be used on the command line. If neither the -c nor the -s options are specified, the first non-option argument specifies the name of a file the shell reads commands from; if there are no non-option arguments, the shell reads commands from standard input. The name of the shell (i.e., the contents of the $0) parameter is determined as follows: if the -c option is used and there is a non-option argument, it is used as the name; if commands are being read from a file, the file is used as the name; otherwise the name the shell was called with (i.e., argv[0]) is used. A shell is interactive if the -i option is used or if both standard input and standard error are attached to a tty. An interactive shell has job control enabled (if available), ignores the INT, QUIT and TERM signals, and prints prompts before reading input (see PS1 and PS2 parameters). For non-interactive shells, the trackall option is on by default (see set command below). A shell is restricted if the -r option is used or if either the basename of the name the shell is invoked with or the SHELL parameter match the pattern *r*sh (e.g., rsh, rksh, rpdksh, etc.). The following restrictions come into effect after the shell processes any profile and $ENV files: \u2022 the cd command is disabled \u2022 the SHELL, ENV and PATH parameters can't be changed \u2022 command names can't be specified with absolute or relative paths \u2022 the -p option of the command built-in can't be used \u2022 redirections that create files can't be used (i.e., >, >|, >>, <>) A shell is privileged if the -p option is used or if the real user-id or group-id does not match the effective user-id or group-id (see getuid(2), getgid(2)). A privileged shell does not process $HOME\/.profile nor the ENV parameter (see below), instead the file \/etc\/suid_profile is processed. Clearing the privileged option causes the shell to set its effective user-id (group-id) to its real user-id (group-id). If the basename of the name the shell is called with (i.e., argv[0]) starts with - or if the -l option is used, the shell is assumed to be a login shell and the shell reads and executes the contents of \/etc\/profile and $HOME\/.profile if they exist and are readable. If the ENV parameter is set when the shell starts (or, in the case of login shells, after any profiles are processed), its value is subjected to parameter, command, arithmetic and tilde substitution and the resulting file (if any) is read and executed. If ENV parameter is not set (and not null) and pdksh was compiled with the DEFAULT_ENV macro defined, the file named in that macro is included (after the above mentioned substitutions have been performed). The exit status of the shell is 127 if the command file specified on the command line could not be opened, or non-zero if a fatal syntax error occurred during the execution of a script. In the absence of fatal errors, the exit status is that of the last command executed, or zero, if no command is executed. Command Syntax The shell begins parsing its input by breaking it into words. Words, which are sequences of characters, are delimited by unquoted white-space characters (space, tab and newline) or meta-characters ( <, >, |, ;, &, ( and )). Aside from delimiting words, spaces and tabs are ignored, while newlines usually delimit commands. The meta-characters are used in building the following tokens: <, <&, <<, >, >&, >>, etc. are used to specify redirections (see Input\/Output Redirection below); | is used to create pipelines; |& is used to create co-processes (see Co-Processes below); ; is used to separate commands; & is used to create asynchronous pipelines; && and || are used to specify conditional execution; ;; is used in case statements; (( .. )) are used in arithmetic expressions; and lastly, ( .. ) are used to create subshells. White-space and meta-characters can be quoted individually using backslash (\\), or in groups using double (\") or single (') quotes. Note that the following characters are also treated specially by the shell and must be quoted if they are to represent themselves: \\, \", ', #, $, ', ~, {, }, *, ? and [. The first three of these are the above mentioned quoting characters (see Quoting below); #, if used at the beginning of a word, introduces a comment - everything after the # up to the nearest newline is ignored; $ is used to introduce parameter, command and arithmetic substitutions (see Substitution below); ' introduces an old-style command substitution (see Substitution below); ~ begins a directory expansion (see Tilde Expansion below); { and } delimit csh(1) style alternations (see Brace Expansion below); and, finally, *, ? and [ are used in file name generation (see File Name Patterns below). As words and tokens are parsed, the shell builds commands, of which there are two basic types: simple-commands, typically programs that are executed, and compound-commands, such as for and if statements, grouping constructs and function definitions. A simple-command consists of some combination of parameter assignments (see Parameters below), input\/output redirections (see Input\/Output Redirections below), and command words; the only restriction is that parameter assignments come before any command words. The command words, if any, define the command that is to be executed and its arguments. The command may be a shell built-in command, a function or an external command, i.e., a separate executable file that is located using the PATH parameter (see Command Execution below). Note that all command constructs have an exit status: for external commands, this is related to the status returned by wait(2) (if the command could not be found, the exit status is 127, if it could not be executed, the exit status is 126); the exit status of other command constructs (built-in commands, functions, compound-commands, pipelines, lists, etc.) are all well defined and are described where the construct is described. The exit status of a command consisting only of parameter assignments is that of the last command substitution performed during the parameter assignment or zero if there were no command substitutions. Commands can be chained together using the | token to form pipelines, in which the standard output of each command but the last is piped (see pipe(2)) to the standard input of the following command. The exit status of a pipeline is that of its last command. A pipeline may be prefixed by the ! reserved word which causes the exit status of the pipeline to be logically complemented: if the original status was 0 the complemented status will be 1, and if the original status was not 0, then the complemented status will be 0. Lists of commands can be created by separating pipelines by any of the following tokens: &&, ||, &, |& and ;. The first two are for conditional execution: cmd1 && cmd2 executes cmd2 only if the exit status of cmd1 is zero; || is the opposite - cmd2 is executed only if the exit status of cmd1 is non-zero. && and || have equal precedence which is higher than that of &, |& and ;, which also have equal precedence. The & token causes the preceding command to be executed asynchronously, that is, the shell starts the command, but does not wait for it to complete (the shell does keep track of the status of asynchronous commands - see Job Control below). When an asynchronous command is started when job control is disabled (i.e., in most scripts), the command is started with signals INT and QUIT ignored and with input redirected from \/dev\/null (however, redirections specified in the asynchronous command have precedence). The |& operator starts a co-process which is special kind of asynchronous process (see Co-Processes below). Note that a command must follow the && and || operators, while a command need not follow &, |& and ;. The exit status of a list is that of the last command executed, with the exception of asynchronous lists, for which the exit status is 0. Compound commands are created using the following reserved words - these words are only recognized if they are unquoted and if they are used as the first word of a command (i.e., they can't be preceded by parameter assignments or redirections): Note: Some shells (but not this one) execute control structure commands in a subshell when one or more of their file descriptors are redirected, so any environment changes inside them may fail. To be portable, the exec statement should be used instead to redirect file descriptors before the control structure. In the following compound command descriptions, command lists (denoted as list) that are followed by reserved words must end with a semi-colon, a newline or a (syntactically correct) reserved word. For example, { echo foo; echo bar; } { echo foo; echo bar<newline>} { { echo foo; echo bar; } } are all valid, but { echo foo; echo bar } is not. ( list ) Execute list in a subshell. There is no implicit way to pass environment changes from a subshell back to its parent. { list } Compound construct; list is executed, but not in a subshell. Note that { and } are reserved words, not meta-characters. case word in [ [ (] pattern [ | pattern] ... ) list ;; ] ... esac The case statement attempts to match word against the specified patterns; the list associated with the first successfully matched pattern is executed. Patterns used in case statements are the same as those used for file name patterns except that the restrictions regarding . and \/ are dropped. Note that any unquoted space before and after a pattern is stripped; any space with a pattern must be quoted. Both the word and the patterns are subject to parameter, command, and arithmetic substitution as well as tilde substitution. For historical reasons, open and close braces may be used instead of in and esac ( e.g., case $foo { *) echo bar; }). The exit status of a case statement is that of the executed list; if no list is executed, the exit status is zero. for name [ in word ... term ] do list done where term is either a newline or a ;. For each word in the specified word list, the parameter name is set to the word and list is executed. If in is not used to specify a word list, the positional parameters ( \"$1\", \"$2\", etc.) are used instead. For historical reasons, open and close braces may be used instead of do and done ( e.g., for i; { echo $i; }). The exit status of a for statement is the last exit status of list; if list is never executed, the exit status is zero. if list then list [ elif list then list] ... [ else list] fi If the exit status of the first list is zero, the second list is executed; otherwise the list following the elif, if any, is executed with similar consequences. If all the lists following the if and elifs fail ( i.e., exit with non-zero status), the list following the else is executed. The exit status of an if statement is that of non-conditional list that is executed; if no non-conditional list is executed, the exit status is zero. select name [ in word ... term ] do list done where term is either a newline or a ;. The select statement provides an automatic method of presenting the user with a menu and selecting from it. An enumerated list of the specified words is printed on standard error, followed by a prompt ( PS3, normally ' #? '). A number corresponding to one of the enumerated words is then read from standard input, name is set to the selected word (or is unset if the selection is not valid), REPLY is set to what was read (leading\/trailing space is stripped), and list is executed. If a blank line ( i.e., zero or more IFS characters) is entered, the menu is re-printed without executing list. When list completes, the enumerated list is printed if REPLY is null, the prompt is printed and so on. This process is continues until an end-of-file is read, an interrupt is received or a break statement is executed inside the loop. If in word ... is omitted, the positional parameters are used ( i.e., \"$1\", \"$2\", etc.). For historical reasons, open and close braces may be used instead of do and done ( e.g., select i; { echo $i; }). The exit status of a select statement is zero if a break statement is used to exit the loop, non-zero otherwise. until list do list done This works like while, except that the body is executed only while the exit status of the first list is non-zero. while list do list done A while is a prechecked loop. Its body is executed as often as the exit status of the first list is zero. The exit status of a while statement is the last exit status of the list in the body of the loop; if the body is not executed, the exit status is zero. function name { list } Defines the function name. See Functions below. Note that redirections specified after a function definition are performed whenever the function is executed, not when the function definition is executed. name () command Mostly the same as function. See Functions below. time [ -p ] [ pipeline ] The time reserved word is described in the Command Execution section. (( expression )) The arithmetic expression expression is evaluated; equivalent to let \" expression \". See Arithmetic Expressions and the let command below. [[ expression ]] Similar to the test and [ ... ] commands (described later), with the following exceptions: \u2022 Field splitting and file name generation are not performed on arguments. \u2022 The -a (and) and -o (or) operators are replaced with && and ||, respectively. \u2022 Operators (e.g., -f, =, !, etc.) must be unquoted. \u2022 The second operand of != and = expressions are patterns (e.g., the comparison in [[ foobar = f*r ]] succeeds). \u2022 There are two additional binary operators: < and > which return true if their first string operand is less than, or greater than, their second string operand, respectively. \u2022 The single argument form of test, which tests if the argument has non-zero length, is not valid - explicit operators must be always be used, e.g., instead of [ str ] use [[ -n str ]] \u2022 Parameter, command and arithmetic substitutions are performed as expressions are evaluated and lazy expression evaluation is used for the && and || operators. This means that in the statement [[ -r foo && $(< foo) = b*r ]] the $(< foo) is evaluated if and only if the file foo exists and is readable. Quoting Quoting is used to prevent the shell from treating characters or words specially. There are three methods of quoting: First, \\ quotes the following character, unless it is at the end of a line, in which case both the \\ and the newline are stripped. Second, a single quote ( ') quotes everything up to the next single quote (this may span lines). Third, a double quote ( \") quotes all characters, except $, ' and \\, up to the next unquoted double quote. $ and ' inside double quotes have their usual meaning ( i.e., parameter, command or arithmetic substitution) except no field splitting is carried out on the results of double-quoted substitutions. If a \\ inside a double-quoted string is followed by \\, $, ' or \", it is replaced by the second character; if it is followed by a newline, both the \\ and the newline are stripped; otherwise, both the \\ and the character following are unchanged. Note: see POSIX Mode below for a special rule regarding sequences of the form \"...'...\\\"...'..\". Aliases There are two types of aliases: normal command aliases and tracked aliases. Command aliases are normally used as a short hand for a long or often used command. The shell expands command aliases ( i.e., substitutes the alias name for its value) when it reads the first word of a command. An expanded alias is re-processed to check for more aliases. If a command alias ends in a space or tab, the following word is also checked for alias expansion. The alias expansion process stops when a word that is not an alias is found, when a quoted word is found or when an alias word that is currently being expanded is found. The following command aliases are defined automatically by the shell: autoload='typeset -fu' functions='typeset -f' hash='alias -t' history='fc -l' integer='typeset -i' local='typeset' login='exec login' newgrp='exec newgrp' nohup='nohup ' r='fc -e -' stop='kill -STOP' suspend='kill -STOP $$' type='whence -v' Tracked aliases allow the shell to remember where it found a particular command. The first time the shell does a path search for a command that is marked as a tracked alias, it saves the full path of the command. The next time the command is executed, the shell checks the saved path to see that it is still valid, and if so, avoids repeating the path search. Tracked aliases can be listed and created using alias -t. Note that changing the PATH parameter clears the saved paths for all tracked aliases. If the trackall option is set ( i.e., set -o trackall or set -h), the shell tracks all commands. This option is set automatically for non-interactive shells. For interactive shells, only the following commands are automatically tracked: cat, cc, chmod, cp, date, ed, emacs, grep, ls, mail, make, mv, pr, rm, sed, sh, vi and who. Substitution The first step the shell takes in executing a simple-command is to perform substitutions on the words of the command. There are three kinds of substitution: parameter, command and arithmetic. Parameter substitutions, which are described in detail in the next section, take the form $name or ${... }; command substitutions take the form $( command ) or ' command '; and arithmetic substitutions take the form $(( expression )). If a substitution appears outside of double quotes, the results of the substitution are generally subject to word or field splitting according to the current value of the IFS parameter. The IFS parameter specifies a list of characters which are used to break a string up into several words; any characters from the set space, tab and newline that appear in the IFS characters are called IFS white space. Sequences of one or more IFS white space characters, in combination with zero or one non-IFS white space characters delimit a field. As a special case, leading and trailing IFS white space is stripped (i.e., no leading or trailing empty field is created by it); leading or trailing non-IFS white space does create an empty field. Example: if IFS is set to '<space>:', the sequence of characters '<space>A<space>:<space><space>B::D' contains four fields: 'A', 'B', '' and 'D'. Note that if the IFS parameter is set to the null string, no field splitting is done; if the parameter is unset, the default value of space, tab and newline is used. The results of substitution are, unless otherwise specified, also subject to brace expansion and file name expansion (see the relevant sections below). A command substitution is replaced by the output generated by the specified command, which is run in a subshell. For $(command) substitutions, normal quoting rules are used when command is parsed, however, for the 'command' form, a \\ followed by any of $, ' or \\ is stripped (a \\ followed by any other character is unchanged). As a special case in command substitutions, a command of the form < file is interpreted to mean substitute the contents of file ($(< foo) has the same effect as $(cat foo), but it is carried out more efficiently because no process is started). NOTE: $(command) expressions are currently parsed by finding the matching parenthesis, regardless of quoting. This will hopefully be fixed soon. Arithmetic substitutions are replaced by the value of the specified expression. For example, the command echo $((2+3*4)) prints 14. See Arithmetic Expressions for a description of an expression. Parameters Parameters are shell variables; they can be assigned values and their values can be accessed using a parameter substitution. A parameter name is either one of the special single punctuation or digit character parameters described below, or a letter followed by zero or more letters or digits ('_' counts as a letter). The later form can be treated as arrays by appending an array index of the form: [ expr ] where expr is an arithmetic expression. Array indicies are currently limited to the range 0 through 1023, inclusive. Parameter substitutions take the form $ name, ${ name } or ${ name [ expr ]}, where name is a parameter name. If substitution is performed on a parameter (or an array parameter element) that is not set, a null string is substituted unless the nounset option ( set -o nounset or set -u) is set, in which case an error occurs. Parameters can be assigned values in a number of ways. First, the shell implicitly sets some parameters like #, PWD, etc.; this is the only way the special single character parameters are set. Second, parameters are imported from the shell's environment at startup. Third, parameters can be assigned values on the command line, for example, 'FOO=bar' sets the parameter FOO to bar; multiple parameter assignments can be given on a single command line and they can be followed by a simple-command, in which case the assignments are in effect only for the duration of the command (such assignments are also exported, see below for implications of this). Note that both the parameter name and the = must be unquoted for the shell to recognize a parameter assignment. The fourth way of setting a parameter is with the export, readonly and typeset commands; see their descriptions in the Command Execution section. Fifth, for and select loops set parameters as well as the getopts, read and set -A commands. Lastly, parameters can be assigned values using assignment operators inside arithmetic expressions (see Arithmetic Expressions below) or using the ${name=value} form of parameter substitution (see below). Parameters with the export attribute (set using the export or typeset -x commands, or by parameter assignments followed by simple commands) are put in the environment (see environ(5)) of commands run by the shell as name=value pairs. The order in which parameters appear in the environment of a command is unspecified. When the shell starts up, it extracts parameters and their values from its environment and automatically sets the export attribute for those parameters. Modifiers can be applied to the ${name} form of parameter substitution: ${ name :- word } if name is set and not null, it is substituted, otherwise word is substituted. ${ name :+ word } if name is set and not null, word is substituted, otherwise nothing is substituted. ${ name := word } if name is set and not null, it is substituted, otherwise it is assigned word and the resulting value of name is substituted. ${ name :? word } if name is set and not null, it is substituted, otherwise word is printed on standard error (preceded by name:) and an error occurs (normally causing termination of a shell script, function or .-script). If word is omitted the string 'parameter null or not set' is used instead. In the above modifiers, the : can be omitted, in which case the conditions only depend on name being set (as opposed to set and not null). If word is needed, parameter, command, arithmetic and tilde substitution are performed on it; if word is not needed, it is not evaluated. The following forms of parameter substitution can also be used: ${# name } The number of positional parameters if name is *, @ or is not specified, or the length of the string value of parameter name. ${# name [*]}, ${# name [@]} The number of elements in the array name. ${ name # pattern }, ${ name ## pattern } If pattern matches the beginning of the value of parameter name, the matched text is deleted from the result of substitution. A single # results in the shortest match, two #'s results in the longest match. ${ name % pattern }, ${ name %% pattern } Like ${.. #.. } substitution, but it deletes from the end of the value. The following special parameters are implicitly set by the shell and cannot be set directly using assignments: ! Process id of the last background process started. If no background processes have been started, the parameter is not set. # The number of positional parameters (i.e., $1, $2, etc.). $ The process ID of the shell, or the PID of the original shell if it is a subshell. - The concatenation of the current single letter options (see set command below for list of options). ? The exit status of the last non-asynchronous command executed. If the last command was killed by a signal, $? is set to 128 plus the signal number. 0 The name the shell was invoked with (i.e., argv[0]), or the command-name if it was invoked with the -c option and the command-name was supplied, or the file argument, if it was supplied. If the posix option is not set, $0 is the name of the current function or script. 1 ... 9 The first nine positional parameters that were supplied to the shell, function or .-script. Further positional parameters may be accessed using ${ number }. * All positional parameters (except parameter 0), i.e., $1 $2 $3.... If used outside of double quotes, parameters are separate words (which are subjected to word splitting); if used within double quotes, parameters are separated by the first character of the IFS parameter (or the empty string if IFS is null). @ Same as $*, unless it is used inside double quotes, in which case a separate word is generated for each positional parameter - if there are no positional parameters, no word is generated (\"$@\" can be used to access arguments, verbatim, without loosing null arguments or splitting arguments with spaces). The following parameters are set and\/or used by the shell: _ (underscore) When an external command is executed by the shell, this parameter is set in the environment of the new process to the path of the executed command. In interactive use, this parameter is also set in the parent shell to the last word of the previous command. When MAILPATH messages are evaluated, this parameter contains the name of the file that changed (see MAILPATH parameter below). CDPATH Search path for the cd built-in command. Works the same way as PATH for those directories not beginning with \/ in cd commands. Note that if CDPATH is set and does not contain . nor an empty path, the current directory is not searched. COLUMNS Set to the number of columns on the terminal or window. Currently set to the cols value as reported by stty(1) if that value is non-zero. This parameter is used by the interactive line editing modes, and by select, set -o and kill -l commands to format information in columns. EDITOR If the VISUAL parameter is not set, this parameter controls the command line editing mode for interactive shells. See VISUAL parameter below for how this works. ENV If this parameter is found to be set after any profile files are executed, the expanded value is used as a shell start-up file. It typically contains function and alias definitions. ERRNO Integer value of the shell's errno variable - indicates the reason the last system call failed. Not implemented yet. EXECSHELL If set, this parameter is assumed to contain the shell that is to be used to execute commands that execve(2) fails to execute and which do not start with a ' #! shell' sequence. FCEDIT The editor used by the fc command (see below). FPATH Like PATH, but used when an undefined function is executed to locate the file defining the function. It is also searched when a command can't be found using PATH. See Functions below for more information. HISTFILE The name of the file used to store history. When assigned to, history is loaded from the specified file. Also, several invocations of the shell running on the same machine will share history if their HISTFILE parameters all point at the same file. NOTE: if HISTFILE isn't set, no history file is used. This is different from the original Korn shell, which uses $HOME\/.sh_history; in future, pdksh may also use a default history file. HISTSIZE The number of commands normally stored for history, default 128. HOME The default directory for the cd command and the value substituted for an unqualified ~ (see Tilde Expansion below). IFS Internal field separator, used during substitution and by the read command, to split values into distinct arguments; normally set to space, tab and newline. See Substitution above for details. Note: this parameter is not imported from the environment when the shell is started. KSH_VERSION The version of shell and the date the version was created (readonly). See also the version commands in Emacs Editing Mode and Vi Editing Mode sections, below. LINENO The line number of the function or shell script that is currently being executed. LINES Set to the number of lines on the terminal or window. Not implemented yet. MAIL If set, the user will be informed of the arrival of mail in the named file. This parameter is ignored if the MAILPATH parameter is set. MAILCHECK How often, in seconds, the shell will check for mail in the file(s) specified by MAIL or MAILPATH. If 0, the shell checks before each prompt. The default is 600 (10 minutes). MAILPATH A list of files to be checked for mail. The list is colon separated, and each file may be followed by a ? and a message to be printed if new mail has arrived. Command, parameter and arithmetic substitution is performed on the message, and, during substitution, the parameter $_ contains the name of the file. The default message is you have mail in $_. OLDPWD The previous working directory. Unset if cd has not successfully changed directories since the shell started, or if the shell doesn't know where it is. OPTARG When using getopts, it contains the argument for a parsed option, if it requires one. OPTIND The index of the last argument processed when using getopts. Assigning 1 to this parameter causes getopts to process arguments from the beginning the next time it is invoked. PATH A colon separated list of directories that are searched when looking for commands and .'d files. An empty string resulting from a leading or trailing colon, or two adjacent colons is treated as a '.', the current directory. POSIXLY_CORRECT If set, this parameter causes the posix option to be enabled. See POSIX Mode below. PPID The process ID of the shell's parent (readonly). PS1 PS1 is the primary prompt for interactive shells. Parameter, command and arithmetic substitutions are performed, and ! is replaced with the current command number (see fc command below). A literal ! can be put in the prompt by placing !! in PS1. Note that since the command line editors try to figure out how long the prompt is (so they know how far it is to edge of the screen), escape codes in the prompt tend to mess things up. You can tell the shell not to count certain sequences (such as escape codes) by prefixing your prompt with a non-printing character (such as control-A) followed by a carriage return and then delimiting the escape codes with this non-printing character. If you don't have any non-printing characters, you're out of luck... BTW, don't blame me for this hack; it's in the original ksh. Default is '$ ' for non-root users, '# ' for root.. PS2 Secondary prompt string, by default '> ', used when more input is needed to complete a command. PS3 Prompt used by select statement when reading a menu selection. Default is '#? '. PS4 Used to prefix commands that are printed during execution tracing (see set -x command below). Parameter, command and arithmetic substitutions are performed before it is printed. Default is '+ '. PWD The current working directory. Maybe unset or null if shell doesn't know where it is. RANDOM A simple random number generator. Every time RANDOM is referenced, it is assigned the next number in a random number series. The point in the series can be set by assigning a number to RANDOM (see rand(3)). REPLY Default parameter for the read command if no names are given. Also used in select loops to store the value that is read from standard input. SECONDS The number of seconds since the shell started or, if the parameter has been assigned an integer value, the number of seconds since the assignment plus the value that was assigned. TMOUT If set to a positive integer in an interactive shell, it specifies the maximum number of seconds the shell will wait for input after printing the primary prompt (PS1). If the time is exceeded, the shell exits. TMPDIR The directory shell temporary files are created in. If this parameter is not set, or does not contain the absolute path of a writable directory, temporary files are created in \/tmp. VISUAL If set, this parameter controls the command line editing mode for interactive shells. If the last component of the path specified in this parameter contains the string vi, emacs or gmacs, the vi, emacs or gmacs (Gosling emacs) editing mode is enabled, respectively. Tilde Expansion Tilde expansion, which is done in parallel with parameter substitution, is done on words starting with an unquoted ~. The characters following the tilde, up to the first \/, if any, are assumed to be a login name. If the login name is empty, + or -, the value of the HOME, PWD, or OLDPWD parameter is substituted, respectively. Otherwise, the password file is searched for the login name, and the tilde expression is substituted with the user's home directory. If the login name is not found in the password file or if any quoting or parameter substitution occurs in the login name, no substitution is performed. In parameter assignments (those preceding a simple-command or those occurring in the arguments of alias, export, readonly, and typeset), tilde expansion is done after any unquoted colon (:), and login names are also delimited by colons. The home directory of previously expanded login names are cached and re-used. The alias -d command may be used to list, change and add to this cache (e.g., 'alias -d fac=\/usr\/local\/facilities; cd ~fac\/bin'). Brace Expansion (alternation) Brace expressions, which take the form prefix { str1 ,... , strN } suffix are expanded to N words, each of which is the concatenation of prefix, stri and suffix ( e.g., 'a{c,b{X,Y},d}e' expands to four word: ace, abXe, abYe, and ade). As noted in the example, brace expressions can be nested and the resulting words are not sorted. Brace expressions must contain an unquoted comma ( ,) for expansion to occur ( i.e., {} and {foo} are not expanded). Brace expansion is carried out after parameter substitution and before file name generation. File Name Patterns A file name pattern is a word containing one or more unquoted ? or * characters or [.. ] sequences. Once brace expansion has been performed, the shell replaces file name patterns with the sorted names of all the files that match the pattern (if no files match, the word is left unchanged). The pattern elements have the following meaning: ? matches any single character. * matches any sequence of characters. [..] matches any of the characters inside the brackets. Ranges of characters can be specified by separating two characters by a -, e.g., [a0-9] matches the letter a or any digit. In order to represent itself, a - must either be quoted or the first or last character in the character list. Similarly, a ] must be quoted or the first character in the list if it is represent itself instead of the end of the list. Also, a ! appearing at the start of the list has special meaning (see below), so to represent itself it must be quoted or appear later in the list. [!..] like [..], except it matches any character not inside the brackets. *( pattern | ... | pattern ) matches any string of characters that matches zero or more occurances of the specified patterns. Example: the pattern *(foo|bar) matches the strings '', 'foo', 'bar', 'foobarfoo', etc.. +( pattern | ... | pattern ) matches any string of characters that matches one or more occurances of the specified patterns. Example: the pattern +(foo|bar) matches the strings 'foo', 'bar', 'foobarfoo', etc.. ?( pattern | ... | pattern ) matches the empty string or a string that matches one of the specified patterns. Example: the pattern ?(foo|bar) only matches the strings '', 'foo' and 'bar'. @( pattern | ... | pattern ) matches a string that matches one of the specified patterns. Example: the pattern @(foo|bar) only matches the strings 'foo' and 'bar'. !( pattern | ... | pattern ) matches any string that does not match one of the specified patterns. Examples: the pattern !(foo|bar) matches all strings except 'foo' and 'bar'; the pattern !(*) matches no strings; the pattern !(?)* matches all strings (think about it). Note that pdksh currently never matches . and .., but the original ksh, Bourne sh and bash do, so this may have to change (too bad). Note that none of the above pattern elements match either a period (.) at the start of a file name or a slash (\/), even if they are explicitly used in a [..] sequence; also, the names . and .. are never matched, even by the pattern .*. If the markdirs option is set, any directories that result from file name generation are marked with a trailing \/. The POSIX character classes (i.e., [:class-name:] inside a [..] expression) are not yet implemented. Input\/Output Redirection When a command is executed, its standard input, standard output and standard error (file descriptors 0, 1 and 2, respectively) are normally inherited from the shell. Three exceptions to this are commands in pipelines, for which standard input and\/or standard output are those set up by the pipeline, asynchronous commands created when job control is disabled, for which standard input is initially set to be from \/dev\/null, and commands for which any of the following redirections have been specified: > file standard output is redirected to file. If file does not exist, it is created; if it does exist, is a regular file and the noclobber option is set, an error occurs, otherwise the file is truncated. Note that this means the command cmd < foo > foo will open foo for reading and then truncate it when it opens it for writing, before cmd gets a chance to actually read foo. >| file same as >, except the file is truncated, even if the noclobber option is set. >> file same as >, except the file an existing file is appended to instead of being truncated. Also, the file is opened in append mode, so writes always go to the end of the file (see open(2)). < file standard input is redirected from file, which is opened for reading. <> file same as <, except the file is opened for reading and writing. << marker after reading the command line containing this kind of redirection (called a here document), the shell copies lines from the command source into a temporary file until a line matching marker is read. When the command is executed, standard input is redirected from the temporary file. If marker contains no quoted characters, the contents of the temporary file are processed as if enclosed in double quotes each time the command is executed, so parameter, command and arithmetic substitutions are performed, along with backslash ( \\) escapes for $, ', \\ and \\newline. If multiple here documents are used on the same command line, they are saved in order. <<- marker same as <<, except leading tabs are stripped from lines in the here document. <& fd standard input is duplicated from file descriptor fd. fd can be a single digit, indicating the number of an existing file descriptor, the letter p, indicating the file descriptor associated with the output of the current co-process, or the character -, indicating standard input is to be closed. >& fd same as <&, except the operation is done on standard output. In any of the above redirections, the file descriptor that is redirected ( i.e., standard input or standard output) can be explicitly given by preceding the redirection with a single digit. Parameter, command and arithmetic substitutions, tilde substitutions and (if the shell is interactive) file name generation are all performed on the file, marker and fd arguments of redirections. Note however, that the results of any file name generation are only used if a single file is matched; if multiple files match, the word with the unexpanded file name generation characters is used. Note that in restricted shells, redirections which can create files cannot be used. For simple-commands, redirections may appear anywhere in the command, for compound-commands (if statements, etc.), any redirections must appear at the end. Redirections are processed after pipelines are created and in the order they are given, so cat \/foo\/bar 2>&1 > \/dev\/null | cat -n will print an error with a line number prepended to it. Arithmetic Expressions Integer arithmetic expressions can be used with the let command, inside $((.. )) expressions, inside array references ( e.g., name [ expr ]), as numeric arguments to the test command, and as the value of an assignment to an integer parameter. Expression may contain alpha-numeric parameter identifiers, array references, and integer constants and may be combined with the following C operators (listed and grouped in increasing order of precedence). Unary operators: + - ! ~ ++ -- Binary operators: , = *= \/= %= += -= <<= >>= &= ^= |= || && | ^ & == != < <= >= > << >> + - * \/ % Ternary operator: ?: (precedence is immediately higher than assignment) Grouping operators: ( ) Integer constants may be specified with arbitrary bases using the notation base # number, where base is a decimal integer specifying the base, and number is a number in the specified base. The operators are evaluated as follows: unary + result is the argument (included for completeness). unary - negation. ! logical not; the result is 1 if argument is zero, 0 if not. ~ arithmetic (bit-wise) not. ++ increment; must be applied to a parameter (not a literal or other expression) - the parameter is incremented by 1. When used as a prefix operator, the result is the incremented value of the parameter, when used as a postfix operator, the result is the original value of the parameter. ++ similar to ++, except the paramter is decremented by 1. , separates two arithmetic expressions; the left hand side is evaluated first, then the right. The result is value of the expression on the right hand side. = assignment; variable on the left is set to the value on the right. *= \/= %= += -= <<= >>= &= ^= |= assignment operators; <var> <op>= <expr> is the same as <var> = <var> <op> ( <expr> ). || logical or; the result is 1 if either argument is non-zero, 0 if not. The right argument is evaluated only if the left argument is zero. && logical and; the result is 1 if both arguments are non-zero, 0 if not. The right argument is evaluated only if the left argument is non-zero. | arithmetic (bit-wise) or. ^ arithmetic (bit-wise) exclusive-or. & arithmetic (bit-wise) and. == equal; the result is 1 if both arguments are equal, 0 if not. != not equal; the result is 0 if both arguments are equal, 1 if not. < less than; the result is 1 if the left argument is less than the right, 0 if not. <= >= > less than or equal, greater than or equal, greater than. See <. << >> shift left (right); the result is the left argument with its bits shifted left (right) by the amount given in the right argument. + - * \/ addition, subtraction, multiplication, and division. % remainder; the result is the remainder of the division of the left argument by the right. The sign of the result is unspecified if either argument is negative. <arg1> ? <arg2> : <arg3> if <arg1> is non-zero, the result is <arg2>, otherwise <arg3>. Co-Processes A co-process, which is a pipeline created with the |& operator, is an asynchronous process that the shell can both write to (using print -p) and read from (using read -p). The input and output of the co-process can also be manipulated using >&p and <&p redirections, respectively. Once a co-process has been started, another can't be started until the co-process exits, or until the co-process input has been redirected using an exec n >&p redirection. If a co-process's input is redirected in this way, the next co-process to be started will share the output with the first co-process, unless the output of the initial co-process has been redirected using an exec n <&p redirection. Some notes concerning co-processes: \u2022 the only way to close the co-process input (so the co-process reads an end-of-file) is to redirect the input to a numbered file descriptor and then close that file descriptor ( e.g., exec 3>&p;exec 3>&-). \u2022 in order for co-processes to share a common output, the shell must keep the write portion of the output pipe open. This means that end of file will not be detected until all co-processes sharing the co-process output have exited (when they all exit, the shell closes its copy of the pipe). This can be avoided by redirecting the output to a numbered file descriptor (as this also causes the shell to close its copy). Note that this behaviour is slightly different from the original Korn shell which closes its copy of the write portion of the co-processs output when the most recently started co-process (instead of when all sharing co-processes) exits. \u2022 print -p will ignore SIGPIPE signals during writes if the signal is not being trapped or ignored; the same is not true if the co-process input has been duplicated to another file descriptor and print -un is used. Functions Functions are defined using either Korn shell function name syntax or the Bourne\/POSIX shell name () syntax (see below for the difference between the two forms). Functions are like .-scripts in that they are executed in the current environment, however, unlike .-scripts, shell arguments ( i.e., positional parameters, $1, etc.) are never visible inside them. When the shell is determining the location of a command, functions are searched after special built-in commands, and before regular and non-regular built-ins, and before the PATH is searched. An existing function may be deleted using unset -f function-name. A list of functions can be obtained using typeset +f and the function definitions can be listed using typeset -f. autoload (which is an alias for typeset -fu) may be used to create undefined functions; when an undefined function is executed, the shell searches the path specified in the FPATH parameter for a file with the same name as the function, which, if found is read and executed. If after executing the file, the named function is found to be defined, the function is executed, otherwise, the normal command search is continued (i.e., the shell searches the regular built-in command table and PATH). Note that if a command is not found using PATH, an attempt is made to autoload a function using FPATH (this is an undocumented feature of the original Korn shell). Functions can have two attributes, trace and export, which can be set with typeset -ft and typeset -fx, respectively. When a traced function is executed, the shell's xtrace option is turned on for the functions duration, otherwise the xtrace option is turned off. The export attribute of functions is currently not used. In the original Korn shell, exported functions are visible to shell scripts that are executed. Since functions are executed in the current shell environment, parameter assignments made inside functions are visible after the function completes. If this is not the desired effect, the typeset command can be used inside a function to create a local parameter. Note that special parameters (e.g., $$, $!) can't be scoped in this way. The exit status of a function is that of the last command executed in the function. A function can be made to finish immediately using the return command; this may also be used to explicitly specify the exit status. Functions defined with the function reserved word are treated differently in the following ways from functions defined with the () notation: \u2022 the $0 parameter is set to the name of the function (Bourne-style functions leave $0 untouched). \u2022 parameter assignments preceeding function calls are not kept in the shell environment (executing Bourne-style functions will keep assignments). \u2022 OPTIND is saved\/reset and restored on entry and exit from the function so getopts can be used properly both inside and outside the function (Bourne-style functions leave OPTIND untouched, so using getopts inside a function interferes with using getopts outside the function). In the future, the following differences will also be added: \u2022 A separate trap\/signal environment will be used during the execution of functions. This will mean that traps set inside a function will not affect the shell's traps and signals that are not ignored in the shell (but may be trapped) will have their default effect in a function. \u2022 The EXIT trap, if set in a function, will be executed after the function returns. POSIX Mode The shell is intended to be POSIX compliant, however, in some cases, POSIX behaviour is contrary either to the original Korn shell behaviour or to user convenience. How the shell behaves in these cases is determined by the state of the posix option ( set -o posix) - if it is on, the POSIX behaviour is followed, otherwise it is not. The posix option is set automatically when the shell starts up if the environment contains the POSIXLY_CORRECT parameter. (The shell can also be compiled so that it is in POSIX mode by default, however this is usually not desirable). The following is a list of things that are affected by the state of the posix option: \u2022 \\\" inside double quoted '.. ' command substitutions: in posix mode, the \\\" is interpreted when the command is interpreted; in non-posix mode, the backslash is stripped before the command substitution is interpreted. For example, echo \"'echo \\\"hi\\\"'\" produces '\"hi\"' in posix mode, 'hi' in non-posix mode. To avoid problems, use the $(...) form of command substitution. \u2022 kill -l output: in posix mode, signal names are listed one a single line; in non-posix mode, signal numbers, names and descriptions are printed in columns. In future, a new option (-v perhaps) will be added to distinguish the two behaviours. \u2022 fg exit status: in posix mode, the exit status is 0 if no errors occur; in non-posix mode, the exit status is that of the last foregrounded job. \u2022 eval exit status: if eval gets to see an empty command (e.g., eval \"'false'\"), its exit status in posix mode will be 0. In non-posix mode, it will be the exit status of the last command substitution that was done in the processing of the arguments to eval (or 0 if there were no command substitutions). \u2022 getopts: in posix mode, options must start with a -; in non-posix mode, options can start with either - or +. \u2022 brace expansion (also known as alternation): in posix mode, brace expansion is disabled; in non-posix mode, brace expansion enabled. Note that set -o posix (or setting the POSIXLY_CORRECT parameter) automatically turns the braceexpand option off, however it can be explicitly turned on later. \u2022 set -: in posix mode, this does not clear the verbose or xtrace options; in non-posix mode, it does. \u2022 set exit status: in posix mode, the exit status of set is 0 if there are no errors; in non-posix mode, the exit status is that of any command substitutions performed in generating the set command. For example, 'set -- 'false'; echo $?' prints 0 in posix mode, 1 in non-posix mode. This construct is used in most shell scripts that use the old getopt(1) command. \u2022 argument expansion of alias, export, readonly, and typeset commands: in posix mode, normal argument expansion done; in non-posix mode, field splitting, file globing, brace expansion and (normal) tilde expansion are turned off, and assignment tilde expansion is turned on. \u2022 signal specification: in posix mode, signals can be specified as digits only if signal numbers match POSIX values (i.e., HUP=1, INT=2, QUIT=3, ABRT=6, KILL=9, ALRM=14, and TERM=15); in non-posix mode, signals can be always digits. \u2022 alias expansion: in posix mode, alias expansion is only carried out when reading command words; in non-posix mode, alias expansion is carried out on any word following an alias that ended in a space. For example, the following for loop alias a='for ' i='j' a i in 1 2; do echo i=$i j=$j; done uses parameter i in posix mode, j in non-posix mode. \u2022 test: in posix mode, the expression \" -t\" (preceded by some number of \" !\" arguments) is always true as it is a non-zero length string; in non-posix mode, it tests if file descriptor 1 is a tty ( i.e., the fd argument to the -t test may be left out and defaults to 1). Command Execution After evaluation of command line arguments, redirections and parameter assignments, the type of command is determined: a special built-in, a function, a regular built-in or the name of a file to execute found using the PATH parameter. The checks are made in the above order. Special built-in commands differ from other commands in that the PATH parameter is not used to find them, an error during their execution can cause a non-interactive shell to exit and parameter assignments that are specified before the command are kept after the command completes. Just to confuse things, if the posix option is turned off (see set command below) some special commands are very special in that no field splitting, file globing, brace expansion nor tilde expansion is preformed on arguments that look like assignments. Regular built-in commands are different only in that the PATH parameter is not used to find them. The original ksh and POSIX differ somewhat in which commands are considered special or regular: POSIX special commands Additional ksh special commands Very special commands (non-posix mode) POSIX regular commands Additional ksh regular commands In the future, the additional ksh special and regular commands may be treated differently from the POSIX special and regular commands. Once the type of the command has been determined, any command line parameter assignments are performed and exported for the duration of the command. The following describes the special and regular built-in commands: . file [ arg1 ...] Execute the commands in file in the current environment. The file is searched for in the directories of PATH. If arguments are given, the positional parameters may be used to access them while file is being executed. If no arguments are given, the positional parameters are those of the environment the command is used in. : [ ... ] The null command. Exit status is set to zero. alias [ -d | ±t [ -r] ] [ ±px] [ ±] [ name1[ = value1] ...] Without arguments, alias lists all aliases. For any name without a value, the existing alias is listed. Any name with a value defines an alias (see Aliases above). When listing aliases, one of two formats is used: normally, aliases are listed as name=value, where value is quoted; if options were preceded with + or a lone + is given on the command line, only name is printed. In addition, if the -p option is used, each alias is prefixed with the string \"alias \". The -x option sets (+x clears) the export attribute of an alias, or, if no names are given, lists the aliases with the export attribute (exporting an alias has no affect). The -t option indicates that tracked aliases are to be listed\/set (values specified on the command line are ignored for tracked aliases). The -r option indicates that all tracked aliases are to be reset. The -d causes directory aliases, which are used in tilde expansion, to be listed or set (see Tilde Expansion above). bg [ job ...] Resume the specified stopped job(s) in the background. If no jobs are specified, %+ is assumed. This command is only available on systems which support job control. See Job Control below for more information. bind [ -m] [ key[ = editing-command] ...] Set or view the current emacs command editing key bindings\/macros. See Emacs Editing Mode below for a complete description. break [ level] break exits the levelth inner most for, select, until, or while loop. level defaults to 1. builtin command [ arg1 ...] Execute the built-in command command. cd [ -LP] [ dir] Set the working directory to dir. If the parameter CDPATH is set, it lists directories to search in for dir. dir. An empty entry in the CDPATH entry means the current directory. If a non-empty directory from CDPATH is used, the resulting full path is printed to standard output. If dir is missing, the home directory $HOME is used. If dir is -, the previous working directory is used (see OLDPWD parameter). If -L option (logical path) is used or if the physical option (see set command below) isn't set, references to .. in dir are relative to the path used get to the directory. If -P option (physical path) is used or if the physical option is set, .. is relative to the filesystem directory tree. The PWD and OLDPWD parameters are updated to reflect the current and old wording directory, respectively. cd [ -LP] old new The string new is substituted for old in the current directory, and the shell attempts to change to the new directory. command [ -pvV] cmd [ arg1 ...] If neither the -v nor -V options are given, cmd is executed exactly as if the command had not been specified, with two exceptions: first, cmd cannot be a shell function, and second, special built-in commands lose their specialness ( i.e., redirection and utility errors do not cause the shell to exit, and command assignments are not permanent). If the -p option is given, a default search path is used instead of the current value of PATH (the actual value of the default path is system dependent: on POSIXish systems, it is the value returned by getconf CS_PATH ). If the -v option is given, instead of executing cmd, information about what would be executed is given (and the same is done for arg1 ...): for special and regular built-in commands and functions, their names are simply printed, for aliases, a command that defines them is printed, and for commands found by searching the PATH parameter, the full path of the command is printed. If no command is be found, (i.e., the path search fails), nothing is printed and command exits with a non-zero status. The -V option is like the -v option, except it is more verbose. continue [ levels] continue jumps to the beginning of the levelth inner most for, select, until, or while loop. level defaults to 1. echo [ -neE] [ arg ...] Prints its arguments (separated by spaces) followed by a newline, to standard out. The newline is suppressed if any of the arguments contain the backslash sequence \\c. See print command below for a list of other backslash sequences that are recognized. The options are provided for compatibility with BSD shell scripts: -n suppresses the trailing newline, -e enables backslash interpretation (a no-op, since this is normally done), and -E which suppresses backslash interpretation. eval command ... The arguments are concatenated (with spaces between them) to form a single string which the shell then parses and executes in the current environment. exec [ command [ arg ...]] The command is executed without forking, replacing the shell process. If no arguments are given, any IO redirection is permanent and the shell is not replaced. Any file descriptors greater than 2 which are opened or dup(2)-ed in this way are not made available to other executed commands (i.e., commands that are not built-in to the shell). Note that the Bourne shell differs here: it does pass these file descriptors on. exit [ status] The shell exits with the specified exit status. If status is not specified, the exit status is the current value of the ? parameter. export [ -p] [ parameter[ = value]] ... Sets the export attribute of the named parameters. Exported parameters are passed in the environment to executed commands. If values are specified, the named parameters also assigned. If no parameters are specified, the names of all parameters with the export attribute are printed one per line, unless the -p option is used, in which case export commands defining all exported parameters, including their values, are printed. false A command that exits with a non-zero status. fc [ -e editor | -l [ -n]] [ -r] [ first [ last]] first and last select commands from the history. Commands can be selected by history number, or a string specifying the most recent command starting with that string. The -l option lists the command on stdout, and -n inhibits the default command numbers. The -r option reverses the order of the list. Without -l, the selected commands are edited by the editor specified with the -e option, or if no -e is specified, the editor specified by the FCEDIT parameter (if this parameter is not set, \/bin\/ed is used), and then executed by the shell. fc [ -e - | -s] [ -g] [ old = new] [ prefix] Re-execute the selected command (the previous command by default) after performing the optional substitution of old with new. If -g is specified, all occurrences of old are replaced with new. This command is usually accessed with the predefined alias r='fc -e -'. fg [ job ...] Resume the specified job(s) in the foreground. If no jobs are specified, %+ is assumed. This command is only available on systems which support job control. See Job Control below for more information. getopts optstring name [ arg ...] getopts is used by shell procedures to parse the specified arguments (or positional parameters, if no arguments are given) and to check for legal options. optstring contains the option letters that getopts is to recognize. If a letter is followed by a colon, the option is expected to have an argument. Options that do not take arguments may be grouped in a single argument. If an option takes an argument and the option character is not the last character of the argument it is found in, the remainder of the argument is taken to be the option's argument, otherwise, the next argument is the option's argument. Each time getopts is invoked, it places the next option in the shell parameter name and the index of the next argument to be processed in the shell parameter OPTIND. If the option was introduced with a +, the option placed in name is prefixed with a +. When an option requires an argument, getopts places it in the shell parameter OPTARG. When an illegal option or a missing option argument is encountered a question mark or a colon is placed in name (indicating an illegal option or missing argument, respectively) and OPTARG is set to the option character that caused the problem. An error message is also printed to standard error if optstring does not begin with a colon. When the end of the options is encountered, getopts exits with a non-zero exit status. Options end at the first (non-option argument) argument that does not start with a -, or when a -- argument is encountered. Option parsing can be reset by setting OPTIND to 1 (this is done automatically whenever the shell or a shell procedure is invoked). Warning: Changing the value of the shell parameter OPTIND to a value other than 1, or parsing different sets of arguments without resetting OPTIND may lead to unexpected results. hash [ -r] [ name ...] Without arguments, any hashed executable command pathnames are listed. The -r option causes all hashed commands to be removed from the hash table. Each name is searched as if it where a command name and added to the hash table if it is an executable command. jobs [ -lpn] [ job ...] Display information about the specified jobs; if no jobs are specified, all jobs are displayed. The -n option causes information to be displayed only for jobs that have changed state since the last notification. If the -l option is used, the process-id of each process in a job is also listed. The -p option causes only the process group of each job to be printed. See Job Control below for the format of job and the displayed job. kill [ -s signame | -signum | -signame ] { job | pid | - pgrp } ... Send the specified signal to the specified jobs, process ids, or process groups. If no signal is specified, the signal TERM is sent. If a job is specified, the signal is sent to the job's process group. See Job Control below for the format of job. kill -l [ exit-status ...] Print the name of the signal that killed a process which exited with the specified exit-statuses. If no arguments are specified, a list of all the signals, their numbers and a short description of them are printed. let [ expression ...] Each expression is evaluated, see Arithmetic Expressions above. If all expressions are successfully evaluated, the exit status is 0 (1) if the last expression evaluated to non-zero (zero). If an error occurs during the parsing or evaluation of an expression, the exit status is greater than 1. Since expressions may need to be quoted, (( expr )) is syntactic sugar for let \" expr \". print [ -nprsu n | -R [ -en]] [ argument ...] Print prints its arguments on the standard output, separated by spaces, and terminated with a newline. The -n option suppresses the newline. By default, certain C escapes are translated. These include \\b, \\f, \\n, \\r, \\t, \\v, and \\0### (# is an octal digit, of which there may be 0 to 3). \\c is equivalent to using the -n option. \\ expansion may be inhibited with the -r option. The -s option prints to the history file instead of standard output, the -u option prints to file descriptor n ( n defaults to 1 if omitted), and the -p option prints to the co-process (see Co-Processes above). The -R option is used to emulate, to some degree, the BSD echo command, which does not process \\ sequences unless the -e option is given. As above, the -n option suppresses the trailing newline. pwd [ -LP] Print the present working directory. If -L option is used or if the physical option (see set command below) isn't set, the logical path is printed ( i.e., the path used to cd to the current directory). If -P option (physical path) is used or if the physical option is set, the path determined from the filesystem (by following .. directories to the root directory) is printed. read [ -prsu n] [ parameter ...] Reads a line of input from standard input, separate the line into fields using the IFS parameter (see Substitution above), and assign each field to the specified parameters. If there are more parameters than fields, the extra parameters are set to null, or alternatively, if there are more fields than parameters, the last parameter is assigned the remaining fields (inclusive of any separating spaces). If no parameters are specified, the REPLY parameter is used. If the input line ends in a backslash and the -r option was not used, the backslash and newline are stripped and more input is read. If no input is read, read exits with a non-zero status. The first parameter may have a question mark and a string appended to it, in which case the string is used as a prompt (printed to standard error before any input is read) if the input is a tty (e.g., read nfoo?'number of foos: '). The -un and -p options cause input to be read from file descriptor n or the current co-process (see Co-Processes above for comments on this), respectively. If the -s option is used, input is saved to the history file. readonly [ -p] [ parameter[ = value]] ... Sets the readonly attribute of the named parameters. If values are given, parameters are set to them before setting the attribute. Once a parameter is made readonly, it cannot be unset and its value cannot be changed. If no parameters are specified, the names of all parameters with the readonly attribute are printed one per line, unless the -p option is used, in which case readonly commands defining all readonly parameters, including their values, are printed. return [ status] Returns from a function or . script, with exit status status. If no status is given, the exit status of the last executed command is used. If used outside of a function or . script, it has the same effect as exit. Note that pdksh treats both profile and $ENV files as . scripts, while the original Korn shell only treats profiles as . scripts. set [ ±abCefhkmnpsuvxX] [ ±o [ option]] [ ±A name] [ --] [ arg ...] The set command can be used to set ( -) or clear ( +) shell options, set the positional parameters, or set an array parameter. Options can be changed using the ±o option syntax, where option is the long name of an option, or using the ± letter syntax, where letter is the option's single letter name (not all options have a single letter name). The following table lists both option letters (if they exist) and long names along with a description of what the option does. These options can also be used upon invocation of the shell. The current set of options (with single letter names) can be found in the parameter -. set -o with no option name will list all the options and whether each is on or off; set +o will print the long names of all options that are currently on. Remaining arguments, if any, are positional parameters and are assigned, in order, to the positional parameters (i.e., 1, 2, etc.). If options are ended with -- and there are no remaining arguments, all positional parameters are cleared. If no options or arguments are given, then the values of all names are printed. For unknown historical reasons, a lone - option is treated specially: it clears both the -x and -v options. shift [ number] The positional parameters number+1, number+2 etc. are renamed to 1, 2, etc. number defaults to 1. test expression [ expression ] test evaluates the expression and returns zero status if true, and 1 status if false and greater than 1 if there was an error. It is normally used as the condition command of if and while statements. The following basic expressions are available: The above basic expressions, in which unary operators have precedence over binary operators, may be combined with the following operators (listed in increasing order of precedence): On operating systems not supporting \/dev\/fd\/ n devices (where n is a file descriptor number), the test command will attempt to fake it for all tests that operate on files (except the -e test). I.e., [ -w \/dev\/fd\/2 ] tests if file descriptor 2 is writable. Note that some special rules are applied (courtesy of POSIX) if the number of arguments to test or [ ... ] is less than five: if leading ! arguments can be stripped such that only one argument remains then a string length test is performed (again, even if the argument is a unary operator); if leading ! arguments can be stripped such that three arguments remain and the second argument is a binary operator, then the binary operation is performed (even if first argument is a unary operator, including an unstripped !). Note: A common mistake is to use if [ $foo = bar ] which fails if parameter foo is null or unset, if it has embedded spaces (i.e., IFS characters), or if it is a unary operator like ! or -n. Use tests like if [ \"X$foo\" = Xbar ] instead. time [ -p] [ pipeline ] If a pipeline is given, the times used to execute the pipeline are reported. If no pipeline is given, then the user and system time used by the shell itself, and all the commands it has run since it was started, are reported. The times reported are the real time (elapsed time from start to finish), the user cpu time (time spent running in user mode) and the system cpu time (time spent running in kernel mode). Times are reported to standard error; the format of the output is: 0.00s real     0.00s user     0.00s system unless the -p option is given (only possible if pipeline is a simple command), in which case the output is slightly longer: real   0.00\nuser   0.00\nsys    0.00 (the number of digits after the decimal may vary from system to system). Note that simple redirections of standard error do not effect the output of the time command: time sleep 1 2> afile { time sleep 1; } 2> afile times for the first command do not go to afile, but those of the second command do. times Print the accumulated user and system times used by the shell and by processes which have exited that the shell started. trap [ handler signal ...] Sets trap handler that is to be executed when any of the specified signals are received. Handler is either a null string, indicating the signals are to be ignored, a minus ( -), indicating that the default action is to be taken for the signals (see signal(2 or 3)), or a string containing shell commands to be evaluated and executed at the first opportunity ( i.e., when the current command completes, or before printing the next PS1 prompt) after receipt of one of the signals. Signal is the name of a signal ( e.g., PIPE or ALRM) or the number of the signal (see kill -l command above). There are two special signals: EXIT (also known as 0), which is executed when the shell is about to exit, and ERR which is executed after an error occurs (an error is something that would cause the shell to exit if the -e or errexit option were set - see set command above). EXIT handlers are executed in the environment of the last executed command. Note that for non-interactive shells, the trap handler cannot be changed for signals that were ignored when the shell started. With no arguments, trap lists, as a series of trap commands, the current state of the traps that have been set since the shell started. Note that the output of trap can not be usefully piped to another process (an artifact of the fact that traps are cleared when subprocesses are created). The original Korn shell's DEBUG trap and the handling of ERR and EXIT traps in functions are not yet implemented. true A command that exits with a zero value. typeset [[±Ulprtux] [ -L[ n]] [ -R[ n]] [ -Z[ n]] [ -i[ n]] | -f [ -tux]] [ name[ = value] ...] Display or set parameter attributes. With no name arguments, parameter attributes are displayed: if no options arg used, the current attributes of all parameters are printed as typeset commands; if an option is given (or - with no option letter) all parameters and their values with the specified attributes are printed; if options are introduced with +, parameter values are not printed. If name arguments are given, the attributes of the named parameters are set (-) or cleared (+). Values for parameters may optionally be specified. If typeset is used inside a function, any newly created parameters are local to the function. When -f is used, typeset operates on the attributes of functions. As with parameters, if no names are given, functions are listed with their values (i.e., definitions) unless options are introduced with +, in which case only the function names are reported. ulimit [ -acdfHlmnpsStvw] [ value] Display or set process limits. If no options are used, the file size limit (-f) is assumed. value, if specified, may be either be an arithmetic expression or the word unlimited. The limits affect the shell and any processes created by the shell after a limit is imposed. Note that some systems may not allow limits to be increased once they are set. Also note that the types of limits available are system dependent - some systems have only the -f limit. -a Displays all limits; unless -H is used, soft limits are displayed. -H Set the hard limit only (default is to set both hard and soft limits). -S Set the soft limit only (default is to set both hard and soft limits). -c Impose a size limit of n blocks on the size of core dumps. -d Impose a size limit of n kbytes on the size of the data area. -f Impose a size limit of n blocks on files written by the shell and its child processes (files of any size may be read). -l Impose a limit of n kbytes on the amount of locked (wired) physical memory. -m Impose a limit of n kbytes on the amount of physical memory used. -n Impose a limit of n file descriptors that can be open at once. -p Impose a limit of n processes that can be run by the user at any one time. -s Impose a size limit of n kbytes on the size of the stack area. -t Impose a time limit of n cpu seconds to be used by each process. -v Impose a limit of n kbytes on the amount of virtual memory used; on some systems this is the maximum allowable virtual address (in bytes, not kbytes). -w Impose a limit of n kbytes on the amount of swap space used. As far as ulimit is concerned, a block is 512 bytes. umask [ -S] [ mask] Display or set the file permission creation mask, or umask (see umask(2)). If the -S option is used, the mask displayed or set is symbolic, otherwise it is an octal number. Symbolic masks are like those used by chmod(1): [ugoa]{{=+-}{rwx}*}+[,...] in which the first group of characters is the who part, the second group is the op part, and the last group is the perm part. The who part specifies which part of the umask is to be modified. The letters mean: u the user permissions g the group permissions o the other permissions (non-user, non-group) a all permissions (user, group and other) The op part indicates how the who permissions are to be modified: = set + added to - removed from The perm part specifies which permissions are to be set, added or removed: r read permission w write permission x execute permission When symbolic masks are used, they describe what permissions may be made available (as opposed to octal masks in which a set bit means the corresponding bit is to be cleared). Example: 'ug=rwx,o=' sets the mask so files will not be readable, writable or executable by 'others', and is equivalent (on most systems) to the octal mask '07'. unalias [ -adt] [ name1 ...] The aliases for the given names are removed. If the -a option is used, all aliases are removed. If the -t or -d options are used, the indicated operations are carried out on tracked or directory aliases, respectively. unset [ -fv] parameter ... Unset the named parameters ( -v, the default) or functions ( -f). The exit status is non-zero if any of the parameters were already unset, zero otherwise. wait [ job] Wait for the specified job(s) to finish. The exit status of wait is that of the last specified job: if the last job is killed by a signal, the exit status is 128 + the number of the signal (see kill -l exit-status above); if the last specified job can't be found (because it never existed, or had already finished), the exit status of wait is 127. See Job Control below for the format of job. Wait will return if a signal for which a trap has been set is received, or if a HUP, INT or QUIT signal is received. If no jobs are specified, wait waits for all currently running jobs (if any) to finish and exits with a zero status. If job monitoring is enabled, the completion status of jobs is printed (this is not the case when jobs are explicitly specified). whence [ -pv] [name ...] For each name, the type of command is listed (reserved word, built-in, alias, function, tracked alias or executable). If the -p option is used, a path search done even if name is a reserved word, alias, etc. Without the -v option, whence is similar to command -v except that whence will find reserved words and won't print aliases as alias commands; with the -v option, whence is the same as command -V. Note that for whence, the -p option does not affect the search path used, as it does for command. If the type of one or more of the names could not be determined, the exit status is non-zero. Job Control Job control refers to the shell's ability to monitor and control jobs, which are processes or groups of processes created for commands or pipelines. At a minimum, the shell keeps track of the status of the background ( i.e., asynchronous) jobs that currently exist; this information can be displayed using the jobs command. If job control is fully enabled (using set -m or set -o monitor), as it is for interactive shells, the processes of a job are placed in their own process group, foreground jobs can be stopped by typing the suspend character from the terminal (normally ^Z), jobs can be restarted in either the foreground or background, using the fg and bg commands, respectively, and the state of the terminal is saved or restored when a foreground job is stopped or restarted, respectively. Note that only commands that create processes (e.g., asynchronous commands, subshell commands, and non-built-in, non-function commands) can be stopped; commands like read cannot be. When a job is created, it is assigned a job-number. For interactive shells, this number is printed inside [..], followed by the process-ids of the processes in the job when an asynchronous command is run. A job may be referred to in bg, fg, jobs, kill and wait commands either by the process id of the last process in the command pipeline (as stored in the $! parameter) or by prefixing the job-number with a percent sign (%). Other percent sequences can also be used to refer to jobs: When a job changes state ( e.g., a background job finishes or foreground job is stopped), the shell prints the following status information: [ number ] flag status command where number is the job-number of the job. flag is + or - if the job is the %+ or %- job, respectively, or space if it is neither. status indicates the current state of the job and can be Running the job has neither stopped or exited (note that running does not necessarily mean consuming CPU time - the process could be blocked waiting for some event). Done [ ( number )] the job exited. number is the exit status of the job, which is omitted if the status is zero. Stopped [ ( signal )] the job was stopped by the indicated signal (if no signal is given, the job was stopped by SIGTSTP). signal-description [ (core dumped)] the job was killed by a signal (e.g., Memory fault, Hangup, etc. - use kill -l for a list of signal descriptions). The (core dumped) message indicates the process created a core file. command is the command that created the process. If there are multiple processes in the job, then each process will have a line showing its command and possibly its status, if it is different from the status of the previous process. When an attempt is made to exit the shell while there are jobs in the stopped state, the shell warns the user that there are stopped jobs and does not exit. If another attempt is immediately made to exit the shell, the stopped jobs are sent a HUP signal and the shell exits. Similarly, if the nohup option is not set and there are running jobs when an attempt is made to exit a login shell, the shell warns the user and does not exit. If another attempt is immediately made to exit the shell, the running jobs are sent a HUP signal and the shell exits. Interactive Input Line Editing The shell supports three modes of reading command lines from a tty in an interactive session. Which is used is controlled by the emacs, gmacs and vi set options (at most one of these can be set at once). If none of these options is enabled, the shell simply reads lines using the normal tty driver. If the emacs or gmacs option is set, the shell allows emacs like editing of the command; similarly, if the vi option is set, the shell allows vi like editing of the command. These modes are described in detail in the following sections. In these editing modes, if a line is longer that the screen width (see COLUMNS parameter), a >, + or < character is displayed in the last column indicating that there are more characters after, before and after, or before the current position, respectively. The line is scrolled horizontally as necessary. Emacs Editing Mode When the emacs option is set, interactive input line editing is enabled. Warning: This mode is slightly different from the emacs mode in the original Korn shell and the 8th bit is stripped in emacs mode. In this mode various editing commands (typically bound to one or more control characters) cause immediate actions without waiting for a new-line. Several editing commands are bound to particular control characters when the shell is invoked; these bindings can be changed using the following commands: bind The current bindings are listed. bind string =[ editing-command] The specified editing command is bound to the given string, which should consist of a control character (which may be written using caret notation ^ X), optionally preceded by one of the two prefix characters. Future input of the string will cause the editing command to be immediately invoked. Note that although only two prefix characters (usually ESC and ^X) are supported, some multi-character sequences can be supported. The following binds the arrow keys on an ANSI terminal, or xterm (these are in the default bindings). Of course some escape sequences won't work out quite this nicely: bind '^[['=prefix-2 bind '^XA'=up-history bind '^XB'=down-history bind '^XC'=forward-char bind '^XD'=backward-char bind -l Lists the names of the functions to which keys may be bound. bind -m string =[ substitute] The specified input string will afterwards be immediately replaced by the given substitute string, which may contain editing commands. The following is a list of editing commands available. Each description starts with the name of the command, a n, if the command can be prefixed with a count, and any keys the command is bound to by default (written using caret notation, e.g., ASCII ESC character is written as ^[). A count prefix for a command is entered using the sequence ^[ n, where n is a sequence of 1 or more digits; unless otherwise specified, if a count is omitted, it defaults to 1. Note that editing command names are used only with the bind command. Furthermore, many editing commands are useful only on terminals with a visible cursor. The default bindings were chosen to resemble corresponding EMACS key bindings. The users tty characters ( e.g., ERASE) are bound to reasonable substitutes and override the default bindings. abort ^G Useful as a response to a request for a search-history pattern in order to abort the search. auto-insert n Simply causes the character to appear as literal input. Most ordinary characters are bound to this. backward-char n ^B Moves the cursor backward n characters. backward-word n ^[B Moves the cursor backward to the beginning of a word; words consist of alphanumerics, underscore (_) and dollar ($). beginning-of-history ^[< Moves to the beginning of the history. beginning-of-line ^A Moves the cursor to the beginning of the edited input line. capitalize-word n ^[c, ^[C Uppercase the first character in the next n words, leaving the cursor past the end of the last word. If the current line does not begin with a comment character, one is added at the beginning of the line and the line is entered (as if return had been pressed), otherwise the existing comment characters are removed and the cursor is placed at the beginning of the line. complete ^[^[ Automatically completes as much as is unique of the command name or the file name containing the cursor. If the entire remaining command or file name is unique a space is printed after its completion, unless it is a directory name in which case \/ is appended. If there is no command or file name with the current partial word as its prefix, a bell character is output (usually causing a audio beep). complete-command ^X^[ Automatically completes as much as is unique of the command name having the partial word up to the cursor as its prefix, as in the complete command described above. complete-file ^[^X Automatically completes as much as is unique of the file name having the partial word up to the cursor as its prefix, as in the complete command described above. complete-list ^[= List the possible completions for the current word. delete-char-backward n ERASE, ^?, ^H Deletes n characters before the cursor. delete-char-forward n Deletes n characters after the cursor. delete-word-backward n ^[ERASE, ^[^?, ^[^H, ^[h Deletes n words before the cursor. delete-word-forward n ^[d Deletes characters after the cursor up to the end of n words. down-history n ^N Scrolls the history buffer forward n lines (later). Each input line originally starts just after the last entry in the history buffer, so down-history is not useful until either search-history or up-history has been performed. downcase-word n ^[L, ^[l Lowercases the next n words. end-of-history ^[> Moves to the end of the history. end-of-line ^E Moves the cursor to the end of the input line. eot ^_ Acts as an end-of-file; this is useful because edit-mode input disables normal terminal input canonicalization. eot-or-delete n ^D Acts as eot if alone on a line; otherwise acts as delete-char-forward. error Error (ring the bell). exchange-point-and-mark ^X^X Places the cursor where the mark is, and sets the mark to where the cursor was. expand-file ^[* Appends a * to the current word and replaces the word with the result of performing file globbing on the word. If no files match the pattern, the bell is rung. forward-char n ^F Moves the cursor forward n characters. forward-word n ^[f Moves the cursor forward to the end of the nth word. goto-history n ^[g Goes to history number n. kill-line KILL Deletes the entire input line. kill-region ^W Deletes the input between the cursor and the mark. kill-to-eol n ^K Deletes the input from the cursor to the end of the line if n is not specified, otherwise deletes characters between the cursor and column n. list ^[? Prints a sorted, columnated list of command names or file names (if any) that can complete the partial word containing the cursor. Directory names have \/ appended to them. list-command ^X? Prints a sorted, columnated list of command names (if any) that can complete the partial word containing the cursor. list-file ^X^Y Prints a sorted, columnated list of file names (if any) that can complete the partial word containing the cursor. File type indicators are appended as described under list above. newline ^J, ^M Causes the current input line to be processed by the shell. The current cursor position may be anywhere on the line. newline-and-next ^O Causes the current input line to be processed by the shell, and the next line from history becomes the current line. This is only useful after an up-history or search-history. no-op QUIT This does nothing. prefix-1 ^[ Introduces a 2-character command sequence. prefix-2 ^X prefix-2 ^[[ Introduces a 2-character command sequence. prev-hist-word n ^[., ^[_ The last ( nth) word of the previous command is inserted at the cursor. quote ^^ The following character is taken literally rather than as an editing command. redraw ^L Reprints the prompt string and the current input line. search-character-backward n ^[^] Search backward in the current line for the nth occurance of the next character typed. search-character-forward n ^] Search forward in the current line for the nth occurance of the next character typed. search-history ^R Enter incremental search mode. The internal history list is searched backwards for commands matching the input. An initial ^ in the search string anchors the search. The abort key will leave search mode. Other commands will be executed after leaving search mode. Successive search-history commands continue searching backward to the next previous occurrence of the pattern. The history buffer retains only a finite number of lines; the oldest are discarded as necessary. set-mark-command ^[<space> Set the mark at the cursor position. stuff On systems supporting it, pushes the bound character back onto the terminal input where it may receive special processing by the terminal handler. This is useful for the BRL ^T mini-systat feature, for example. stuff-reset Acts like stuff, then aborts input the same as an interrupt. transpose-chars ^T If at the end of line, or if the gmacs option is set, this exchanges the two previous characters; otherwise, it exchanges the previous and current characters and moves the cursor one character to the right. up-history n ^P Scrolls the history buffer backward n lines (earlier). upcase-word n ^[U, ^[u Uppercases the next n words. version ^V Display the version of ksh. The current edit buffer is restored as soon as any key is pressed (the key is then processed, unless it is a space). yank ^Y Inserts the most recently killed text string at the current cursor position. yank-pop ^[y Immediately after a yank, replaces the inserted text string with the next previous killed text string. Vi Editing Mode The vi command line editor in ksh has basically the same commands as the vi editor (see vi(1)), with the following exceptions: \u2022 you start out in insert mode, \u2022 there are file name and command completion commands (=, \\, *, ^X, ^E, ^F and, optionally, <tab>), \u2022 the _ command is different (in ksh it is the last argument command, in vi it goes to the start of the current line), \u2022 the \/ and G commands move in the opposite direction as the j command \u2022 and commands which don't make sense in a single line editor are not available (e.g., screen movement commands, ex : commands, etc.). Note that the ^X stands for control-X; also <esc>, <space> and <tab> are used for escape, space and tab, respectively (no kidding). Like vi, there are two modes: insert mode and command mode. In insert mode, most characters are simply put in the buffer at the current cursor position as they are typed, however, some characters are treated specially. In particular, the following characters are taken from current tty settings (see stty(1)) and have their usual meaning (normal values are in parentheses): kill (^U), erase (^?), werase (^W), eof (^D), intr (^C) and quit (^\\). In addition to the above, the following characters are also treated specially in insert mode: In command mode, each character is interpreted as a command. Characters that don't correspond to commands, are illegal combinations of commands or are commands that can't be carried out all cause beeps. In the following command descriptions, a n indicates the command may be prefixed by a number ( e.g., 10l moves right 10 characters); if no number prefix is used, n is assumed to be 1 unless otherwise specified. The term 'current position' refers to the position between the cursor and the character preceding the cursor. A 'word' is a sequence of letters, digits and underscore characters or a sequence of non-letter, non-digit, non-underscore, non-white-space characters ( e.g., ab2*&^ contains two words) and a 'big-word' is a sequence of non-white-space characters. Special ksh vi commands The following commands are not in, or are different from, the normal vi file editor: n _ insert a space followed by the nth big-word from the last command in the history at the current position and enter insert mode; if n is not specified, the last word is inserted. # insert the comment character (#) at the start of the current line and return the line to the shell (equivalent to I#^J). ng like G, except if n is not specified, it goes to the most recent remembered line. nv edit line n using the vi editor; if n is not specified, the current line is edited. The actual command executed is 'fc -e ${VISUAL:-${EDITOR:-vi}} n'. * and ^X command or file name expansion is applied to the current big-word (with an appended *, if the word contains no file globing characters) - the big-word is replaced with the resulting words. If the current big-word is the first on the line (or follows one of the following characters: ;, |, &, (, )) and does not contain a slash (\/) then command expansion is done, otherwise file name expansion is done. Command expansion will match the big-word against all aliases, functions and built-in commands as well as any executable files found by searching the directories in the PATH parameter. File name expansion matches the big-word against the files in the current directory. After expansion, the cursor is placed just past the last word and the editor is in insert mode. n \\, n ^F, n <tab> and n <esc> command\/file name completion: replace the current big-word with the longest unique match obtained after performing command\/file name expansion. <tab> is only recognized if the vi-tabcomplete option is set, while <esc> is only recognized if the vi-esccomplete option is set (see set -o). If n is specified, the nth possible completion is selected (as reported by the command\/file name enumeration command). = and ^E command\/file name enumeration: list all the commands or files that match the current big-word. ^V display the version of pdksh; it is displayed until another key is pressed (this key is ignored). @c macro expansion: execute the commands found in the alias _c. Intra-line movement commands n h and n ^H move left n characters. n l and n <space> move right n characters. 0 move to column 0. ^ move to the first non white-space character. n| move to column n. $ move to the last character. nb move back n words. nB move back n big-words. ne move forward to the end the word, n times. nE move forward to the end the big-word, n times. nw move forward n words. nW move forward n big-words. % find match: the editor looks forward for the nearest parenthesis, bracket or brace and then moves the to the matching parenthesis, bracket or brace. nfc move forward to the nth occurrence of the character c. nFc move backward to the nth occurrence of the character c. ntc move forward to just before the nth occurrence of the character c. nTc move backward to just before the nth occurrence of the character c. n; repeats the last f, F, t or T command. n, repeats the last f, F, t or T command, but moves in the opposite direction. Inter-line movement commands n j and n + and n ^N move to the nth next line in the history. n k and n - and n ^P move to the nth previous line in the history. n G move to line n in the history; if n is not specified, the number first remembered line is used. ng like G, except if n is not specified, it goes to the most recent remembered line. n \/ string search backward through the history for the nth line containing string; if string starts with ^, the remainder of the string must appear at the start of the history line for it to match. n ? string same as \/, except it searches forward through the history. n n search for the nth occurrence of the last search string; the direction of the search is the same as the last search. nN search for the nth occurrence of the last search string; the direction of the search is the opposite of the last search. Edit commands n a append text n times: goes into insert mode just after the current position. The append is only replicated if command mode is re-entered (i.e., <esc> is used). nA same as a, except it appends at the end of the line. ni insert text n times: goes into insert mode at the current position. The insertion is only replicated if command mode is re-entered (i.e., <esc> is used). nI same as i, except the insertion is done just before the first non-blank character. ns substitute the next n characters (i.e., delete the characters and go into insert mode). S substitute whole line: all characters from the first non-blank character to the end of line are deleted and insert mode is entered. n c move-cmd change from the current position to the position resulting from n move-cmds (i.e., delete the indicated region and go into insert mode); if move-cmd is c, the line starting from the first non-blank character is changed. C change from the current position to the end of the line (i.e., delete to the end of the line and go into insert mode). nx delete the next n characters. nX delete the previous n characters. D delete to the end of the line. n d move-cmd delete from the current position to the position resulting from n move-cmds; move-cmd is a movement command (see above) or d, in which case the current line is deleted. n r c replace the next n characters with the character c. nR replace: enter insert mode but overwrite existing characters instead of inserting before existing characters. The replacement is repeated n times. n~ change the case of the next n characters. n y move-cmd yank from the current position to the position resulting from n move-cmds into the yank buffer; if move-cmd is y, the whole line is yanked. Y yank from the current position to the end of the line. np paste the contents of the yank buffer just after the current position, n times. nP same as p, except the buffer is pasted at the current position. Miscellaneous vi commands ^J and ^M the current line is read, parsed and executed by the shell. ^L and ^R redraw the current line. n . redo the last edit command n times. u undo the last edit command. U undo all changes that have been made to the current line. intr and quit the interrupt and quit terminal characters cause the current line to be deleted and a new prompt to be printed.","Process Name":"ksh","Link":"https:\/\/linux.die.net\/man\/1\/ksh"}},{"Process":{"Description":null,"Process Name":"ksh93","Link":"https:\/\/linux.die.net\/man\/1\/ksh93"}},{"Process":{"Description":"This program sorts input linewise and writes the result to standard output or a name specified in the option. It is mainly intended for users on operating systems shipped without a \"native\" sort program.","Process Name":"ksort","Link":"https:\/\/linux.die.net\/man\/1\/ksort"}},{"Process":{"Description":"kshaskpass is a KDE-based passphrase dialog for use with OpenSSH. It is intended to be called by the ssh-add(1) program and not invoked directly. It allows ssh-add(1) to obtain a passphrase from a user, even if not connected to a terminal (assuming that an X display is available). This happens automatically in the case where ssh-add is invoked from one's ~\/.xsession or as one of the KDE startup programs, for example. In order to be called automatically by ssh-add, ksshaskpass should be installed as \/usr\/bin\/ssh-askpass.","Process Name":"ksshaskpass","Link":"https:\/\/linux.die.net\/man\/1\/ksshaskpass"}},{"Process":{"Description":"kstats is a tool designed to show the FMS algorithm votes for an ivs dump (intialization vectors) with a specified WEP key. The ivs dump can be get by using the combinaison of both airodump(1) and ivstools(1).","Process Name":"kstats","Link":"https:\/\/linux.die.net\/man\/1\/kstats"}},{"Process":{"Description":null,"Process Name":"ksu","Link":"https:\/\/linux.die.net\/man\/1\/ksu"}},{"Process":{"Description":"kswitch makes the specified credential cache the primary cache for the collection, if a cache collection is available.","Process Name":"kswitch","Link":"https:\/\/linux.die.net\/man\/1\/kswitch"}},{"Process":{"Description":"ktcheck verifies a client's command file with the radmind server host. The command file is downloaded from host if it is missing or has the wrong size. With the -c option, checksums are also used to verify files. Reading the command file line-by-line, ktcheck verifies each command file and transcript listed, downloading it from host if it is missing or out of date. ktcheck ignors blank lines and comments ( lines starting with '#' ). Included command files are read are verified using the same method. Each special file listed in the command file is converted into a transcript line in special.T with information provided by host. See radmind(8) for details of the STAT command. If checksuming is turned on, the special transcript is verified using the checksum and file size. If either are wrong, the special transcript is updated. If checksuming is turned off, the special transcript is always updated. Files updated by ktcheck must be regular files and the user must have access to modify them. When run with the -n option, ktcheck verifies but never downloads the command files or transcripts. A temporary special.T is created for verification and is removed on exit.","Process Name":"ktcheck","Link":"https:\/\/linux.die.net\/man\/1\/ktcheck"}},{"Process":{"Description":"This manual page documents briefly the ktoblzcheck application. ktoblzcheck is a program that will check a given account and blz for the bank being valid and the account being valid using some checksum calculations, if supported for that particular bank. The output is the clear-text name of the bank specified by <bank-id>, and whether the given <account-id> is a valid account number at this bank.","Process Name":"ktoblzcheck","Link":"https:\/\/linux.die.net\/man\/1\/ktoblzcheck"}},{"Process":{"Description":null,"Process Name":"ktutil","Link":"https:\/\/linux.die.net\/man\/1\/ktutil"}},{"Process":{"Description":null,"Process Name":"kuesvr","Link":"https:\/\/linux.die.net\/man\/1\/kuesvr"}},{"Process":{"Description":"kuipc, the Kit for a User Interface Package Compiler, is a tool to simplify the writing of a program's user interface code. It takes as input a Command Definition File (CDF) that describes the commands to be understood by the program, and outputs C or FORTRAN code that makes the appropriate function calls to set up the user interface. This code can then be compiled and linked with the rest of the program. Since the generated code uses KUIP routines, the program must also be linked against the Packlib library that contains them. If no output file is specified, kuipc will output generated code to a file whose name is the same as the input file's, with the ending '.cdf' replaced by '.f' or '.c' as appropriate. If neither input nor output file are given, kuipc will prompt for them. Be careful because kuipc overwrites existing files with no warning.","Process Name":"kuipc","Link":"https:\/\/linux.die.net\/man\/1\/kuipc"}},{"Process":{"Description":"Spiraling, spinning, and very, very fast splashes of color rush toward the screen.","Process Name":"kumppa","Link":"https:\/\/linux.die.net\/man\/1\/kumppa"}},{"Process":{"Description":"This utility is used to upload files to kernel.org and other systems using the same upload system (kup-server). Each upload is required to have a PGP signature, and the server will generate multiple compressed formats if the content uploaded is intended to be compressed. Additionally, if the user has content from a git(1) tree already on server, it is possible to reproduce the content server-side, thereby reducing bandwidth needs. The user still has to generate the content locally and sign it.","Process Name":"kup","Link":"https:\/\/linux.die.net\/man\/1\/kup"}},{"Process":{"Description":"The program kup-server is expected to be the receiver of an ssh shell, configured with the following or similar options in ~\/.ssh\/authorized_keys: command=\"\/usr\/bin\/kup-server\",no-agent-forwarding,no-port-forwarding,no-pty,no-user-rc,no-X11-forwarding ssh-rsa AAAA[...] Each user should have their own UID, as Unix user permissions are used for specific tree access control. On the client side, a corresponding client-side utility kup is used to initiate the connection and perform the uploads.","Process Name":"kup-server","Link":"https:\/\/linux.die.net\/man\/1\/kup-server"}},{"Process":{"Description":"KVIrc is a Visual Internet Relay Chat client based on the Qt library. It is intended to be an \"user friendly\" interface to the IRC protocol (see RFC1459) and its extensions.","Process Name":"kvirc","Link":"https:\/\/linux.die.net\/man\/1\/kvirc"}},{"Process":{"Description":null,"Process Name":"kvno","Link":"https:\/\/linux.die.net\/man\/1\/kvno"}},{"Process":{"Description":"Kwiki is a simple extendable wiki framework, written in Perl. See Kwiki::Command for more information on using the command line tool.","Process Name":"kwiki","Link":"https:\/\/linux.die.net\/man\/1\/kwiki"}},{"Process":{"Description":null,"Process Name":"kwiki-install","Link":"https:\/\/linux.die.net\/man\/1\/kwiki-install"}},{"Process":{"Description":"kxterm is a terminal emulator combining the best features of the (now defunct) Apollo DM pads (like: input and transcript pads, automatic file backup of transcript pad, string search in pads, etc.) and the Korn shell emacs-style command line editing and command line recall mechanism. For more detailed information about the program, please see the online help available from the kxterm Help menu. kxterm has a number of X resources which can be set by the user; these are listed in the online help and in the file \/etc\/X11\/app-defaults\/KXterm, where the default values are set. It should be noted that when kxterm is acting as a client for another application, the desired X resource should be prefixed by \"Kx\" plus the class name of the application. So for application \"Foo\" the kxterm resource class would be KxFoo, and one would set KxFoo*background, etc. One can also set the resource class of a kxterm window via the command-line with the class argument.","Process Name":"kxterm","Link":"https:\/\/linux.die.net\/man\/1\/kxterm"}}]