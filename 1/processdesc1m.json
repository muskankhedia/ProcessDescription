[{"Process":{"Description":null,"Process Name":"m2","Link":"https:\/\/linux.die.net\/man\/1\/m2"}},{"Process":{"Description":"addr2line translates addresses into file names and line numbers. Given an address in an executable or an offset in a section of a relocatable object, it uses the debugging information to figure out which file name and line number are associated with it. The executable or relocatable object to use is specified with the -e option. The default is the file a.out. The section in the relocatable object to use is specified with the -j option. addr2line has two modes of operation. In the first, hexadecimal addresses are specified on the command line, and addr2line displays the file name and line number for each address. In the second, addr2line reads hexadecimal addresses from standard input, and prints the file name and line number for each address on standard output. In this mode, addr2line may be used in a pipe to convert dynamically chosen addresses. The format of the output is FILENAME:LINENO . The file name and line number for each input address is printed on separate lines. If the -f option is used, then each FILENAME:LINENO line is preceded by FUNCTIONNAME which is the name of the function containing the address. If the -i option is used and the code at the given address is present there because of inlining by the compiler then the { FUNCTIONNAME } FILENAME:LINENO information for the inlining function will be displayed afterwards. This continues recursively until there is no more inlining to report. If the -a option is used then the output is prefixed by the input address. If the -p option is used then the output for each input address is displayed on one, possibly quite long, line. If -p is not used then the output is broken up into multiple lines, based on the paragraphs above. If the file name or function name can not be determined, addr2line will print two question marks in their place. If the line number can not be determined, addr2line will print 0.","Process Name":"m32r-linux-gnu-addr2line","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-addr2line"}},{"Process":{"Description":"The GNU ar program creates, modifies, and extracts from archives. An archive is a single file holding a collection of other files in a structure that makes it possible to retrieve the original individual files (called members of the archive). The original files' contents, mode (permissions), timestamp, owner, and group are preserved in the archive, and can be restored on extraction. GNU ar can maintain archives whose members have names of any length; however, depending on how ar is configured on your system, a limit on member-name length may be imposed for compatibility with archive formats maintained with other tools. If it exists, the limit is often 15 characters (typical of formats related to a.out) or 16 characters (typical of formats related to coff). ar is considered a binary utility because archives of this sort are most often used as libraries holding commonly needed subroutines. ar creates an index to the symbols defined in relocatable object modules in the archive when you specify the modifier s. Once created, this index is updated in the archive whenever ar makes a change to its contents (save for the q update operation). An archive with such an index speeds up linking to the library, and allows routines in the library to call each other without regard to their placement in the archive. You may use nm -s or nm --print-armap to list this index table. If an archive lacks the table, another form of ar called ranlib can be used to add just the table. GNU ar can optionally create a thin archive, which contains a symbol index and references to the original copies of the member files of the archives. Such an archive is useful for building libraries for use within a local build, where the relocatable objects are expected to remain available, and copying the contents of each object would only waste time and space. Thin archives are also flattened, so that adding one or more archives to a thin archive will add the elements of the nested archive individually. The paths to the elements of the archive are stored relative to the archive itself. GNU ar is designed to be compatible with two different facilities. You can control its activity using command-line options, like the different varieties of ar on Unix systems; or, if you specify the single command-line option -M, you can control it with a script supplied via standard input, like the MRI \"librarian\" program.","Process Name":"m32r-linux-gnu-ar","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-ar"}},{"Process":{"Description":null,"Process Name":"m32r-linux-gnu-as","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-as"}},{"Process":{"Description":"The C ++ and Java languages provide function overloading, which means that you can write many functions with the same name, providing that each function takes parameters of different types. In order to be able to distinguish these similarly named functions C ++ and Java encode them into a low-level assembler name which uniquely identifies each different version. This process is known as mangling. The c++filt [1] program does the inverse mapping: it decodes (demangles) low-level names into user-level names so that they can be read. Every alphanumeric word (consisting of letters, digits, underscores, dollars, or periods) seen in the input is a potential mangled name. If the name decodes into a C ++ name, the C ++ name replaces the low-level name in the output, otherwise the original word is output. In this way you can pass an entire assembler source file, containing mangled names, through c++filt and see the same source file containing demangled names. You can also use c++filt to decipher individual symbols by passing them on the command line: c++filt <symbol> If no symbol arguments are given, c++filt reads symbol names from the standard input instead. All the results are printed on the standard output. The difference between reading names from the command line versus reading names from the standard input is that command line arguments are expected to be just mangled names and no checking is performed to separate them from surrounding text. Thus for example: c++filt -n _Z1fv will work and demangle the name to \"f()\" whereas: c++filt -n _Z1fv, will not work. (Note the extra comma at the end of the mangled name which makes it invalid). This command however will work: echo _Z1fv, | c++filt -n and will display \"f(),\", i.e., the demangled name followed by a trailing comma. This behaviour is because when the names are read from the standard input it is expected that they might be part of an assembler source file where there might be extra, extraneous characters trailing after a mangled name. For example: .type   _Z1fv, @function","Process Name":"m32r-linux-gnu-c++filt","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-c++filt"}},{"Process":{"Description":"The C preprocessor, often known as cpp, is a macro processor that is used automatically by the C compiler to transform your program before compilation. It is called a macro processor because it allows you to define macros, which are brief abbreviations for longer constructs. The C preprocessor is intended to be used only with C, C ++ , and Objective-C source code. In the past, it has been abused as a general text processor. It will choke on input which does not obey C's lexical rules. For example, apostrophes will be interpreted as the beginning of character constants, and cause errors. Also, you cannot rely on it preserving characteristics of the input which are not significant to C-family languages. If a Makefile is preprocessed, all the hard tabs will be removed, and the Makefile will not work. Having said that, you can often get away with using cpp on things which are not C. Other Algol-ish programming languages are often safe (Pascal, Ada, etc.) So is assembly, with caution. -traditional-cpp mode preserves more white space, and is otherwise more permissive. Many of the problems can be avoided by writing C or C ++ style comments instead of native language comments, and keeping macros simple. Wherever possible, you should use a preprocessor geared to the language you are writing in. Modern versions of the GNU assembler have macro facilities. Most high level programming languages have their own conditional compilation and inclusion mechanism. If all else fails, try a true general text processor, such as GNU M4. C preprocessors vary in some details. This manual discusses the GNU C preprocessor, which provides a small superset of the features of ISO Standard C. In its default mode, the GNU C preprocessor does not do a few things required by the standard. These are features which are rarely, if ever, used, and may cause surprising changes to the meaning of a program which does not expect them. To get strict ISO Standard C, you should use the -std=c90, -std=c99 or -std=c11 options, depending on which version of the standard you want. To get all the mandatory diagnostics, you must also use -pedantic. This manual describes the behavior of the ISO preprocessor. To minimize gratuitous differences, where the ISO preprocessor's behavior does not conflict with traditional semantics, the traditional preprocessor should behave the same way. The various differences that do exist are detailed in the section Traditional Mode. For clarity, unless noted otherwise, references to CPP in this manual refer to GNU CPP .","Process Name":"m32r-linux-gnu-cpp","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-cpp"}},{"Process":{"Description":"dlltool reads its inputs, which can come from the -d and -b options as well as object files specified on the command line. It then processes these inputs and if the -e option has been specified it creates a exports file. If the -l option has been specified it creates a library file and if the -z option has been specified it creates a def file. Any or all of the -e, -l and -z options can be present in one invocation of dlltool. When creating a DLL , along with the source for the DLL , it is necessary to have three other files. dlltool can help with the creation of these files. The first file is a .def file which specifies which functions are exported from the DLL , which functions the DLL imports, and so on. This is a text file and can be created by hand, or dlltool can be used to create it using the -z option. In this case dlltool will scan the object files specified on its command line looking for those functions which have been specially marked as being exported and put entries for them in the .def file it creates. In order to mark a function as being exported from a DLL , it needs to have an -export:<name_of_function> entry in the .drectve section of the object file. This can be done in C by using the asm() operator: asm (\".section .drectve\");\nasm (\".ascii \\\"-export:my_func\\\"\");\n\nint my_func (void) { ... } The second file needed for DLL creation is an exports file. This file is linked with the object files that make up the body of the DLL and it handles the interface between the DLL and the outside world. This is a binary file and it can be created by giving the -e option to dlltool when it is creating or reading in a .def file. The third file needed for DLL creation is the library file that programs will link with in order to access the functions in the DLL (an 'import library'). This file can be created by giving the -l option to dlltool when it is creating or reading in a .def file. If the -y option is specified, dlltool generates a delay-import library that can be used instead of the normal import library to allow a program to link to the dll only as soon as an imported function is called for the first time. The resulting executable will need to be linked to the static delayimp library containing __delayLoadHelper2(), which in turn will import LoadLibraryA and GetProcAddress from kernel32. dlltool builds the library file by hand, but it builds the exports file by creating temporary files containing assembler statements and then assembling these. The -S command line option can be used to specify the path to the assembler that dlltool will use, and the -f option can be used to pass specific flags to that assembler. The -n can be used to prevent dlltool from deleting these temporary assembler files when it is done, and if -n is specified twice then this will prevent dlltool from deleting the temporary object files it used to build the library. Here is an example of creating a DLL from a source file dll.c and also creating a program (from an object file called program.o) that uses that DLL: gcc -c dll.c\ndlltool -e exports.o -l dll.lib dll.o\ngcc dll.o exports.o -o dll.dll\ngcc program.o dll.lib -o program dlltool may also be used to query an existing import library to determine the name of the DLL to which it is associated. See the description of the -I or --identify option.","Process Name":"m32r-linux-gnu-dlltool","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-dlltool"}},{"Process":{"Description":null,"Process Name":"m32r-linux-gnu-elfedit","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-elfedit"}},{"Process":{"Description":"When you invoke GCC , it normally does preprocessing, compilation, assembly and linking. The \"overall options\" allow you to stop this process at an intermediate stage. For example, the -c option says not to run the linker. Then the output consists of object files output by the assembler. Other options are passed on to one stage of processing. Some options control the preprocessor and others the compiler itself. Yet other options control the assembler and linker; most of these are not documented here, since you rarely need to use any of them. Most of the command-line options that you can use with GCC are useful for C programs; when an option is only useful with another language (usually C ++ ), the explanation says so explicitly. If the description for a particular option does not mention a source language, you can use that option with all supported languages. The gcc program accepts options and file names as operands. Many options have multi-letter names; therefore multiple single-letter options may not be grouped: -dv is very different from -d -v. You can mix options and other arguments. For the most part, the order you use doesn't matter. Order does matter when you use several options of the same kind; for example, if you specify -L more than once, the directories are searched in the order specified. Also, the placement of the -l option is significant. Many options have long names starting with -f or with -W---for example, -fmove-loop-invariants, -Wformat and so on. Most of these have both positive and negative forms; the negative form of -ffoo would be -fno-foo. This manual documents only one of these two forms, whichever one is not the default.","Process Name":"m32r-linux-gnu-gcc","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-gcc"}},{"Process":{"Description":"gcov is a test coverage program. Use it in concert with GCC to analyze your programs to help create more efficient, faster running code and to discover untested parts of your program. You can use gcov as a profiling tool to help discover where your optimization efforts will best affect your code. You can also use gcov along with the other profiling tool, gprof, to assess which parts of your code use the greatest amount of computing time. Profiling tools help you analyze your code's performance. Using a profiler such as gcov or gprof, you can find out some basic performance statistics, such as: \u2022 how often each line of code executes \u2022 what lines of code are actually executed \u2022 how much computing time each section of code uses Once you know these things about how your code works when compiled, you can look at each module to see which modules should be optimized. gcov helps you determine where to work on optimization. Software developers also use coverage testing in concert with testsuites, to make sure software is actually good enough for a release. Testsuites can verify that a program works as expected; a coverage program tests to see how much of the program is exercised by the testsuite. Developers can then determine what kinds of test cases need to be added to the testsuites to create both better testing and a better final product. You should compile your code without optimization if you plan to use gcov because the optimization, by combining some lines of code into one function, may not give you as much information as you need to look for 'hot spots' where the code is using a great deal of computer time. Likewise, because gcov accumulates statistics by line (at the lowest resolution), it works best with a programming style that places only one statement on each line. If you use complicated macros that expand to loops or to other control structures, the statistics are less helpful---they only report on the line where the macro call appears. If your complex macros behave like functions, you can replace them with inline functions to solve this problem. gcov creates a logfile called sourcefile.gcov which indicates how many times each line of a source file sourcefile.c has executed. You can use these logfiles along with gprof to aid in fine-tuning the performance of your programs. gprof gives timing information you can use along with the information you get from gcov. gcov works only on code compiled with GCC . It is not compatible with any other profiling or test coverage mechanism.","Process Name":"m32r-linux-gnu-gcov","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-gcov"}},{"Process":{"Description":null,"Process Name":"m32r-linux-gnu-gprof","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-gprof"}},{"Process":{"Description":"ld combines a number of object and archive files, relocates their data and ties up symbol references. Usually the last step in compiling a program is to run ld. ld accepts Linker Command Language files written in a superset of AT&T 's Link Editor Command Language syntax, to provide explicit and total control over the linking process. This man page does not describe the command language; see the ld entry in \"info\" for full details on the command language and on other aspects of the GNU linker. This version of ld uses the general purpose BFD libraries to operate on object files. This allows ld to read, combine, and write object files in many different formats---for example, COFF or \"a.out\". Different formats may be linked together to produce any available kind of object file. Aside from its flexibility, the GNU linker is more helpful than other linkers in providing diagnostic information. Many linkers abandon execution immediately upon encountering an error; whenever possible, ld continues executing, allowing you to identify other errors (or, in some cases, to get an output file in spite of the error). The GNU linker ld is meant to cover a broad range of situations, and to be as compatible as possible with other linkers. As a result, you have many choices to control its behavior.","Process Name":"m32r-linux-gnu-ld","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-ld"}},{"Process":{"Description":"nlmconv converts the relocatable i386 object file infile into the NetWare Loadable Module outfile, optionally reading headerfile for NLM header information. For instructions on writing the NLM command file language used in header files, see the linkers section, NLMLINK in particular, of the NLM Development and Tools Overview, which is part of the NLM Software Developer's Kit (\" NLM SDK \"), available from Novell, Inc. nlmconv uses the GNU Binary File Descriptor library to read infile; nlmconv can perform a link step. In other words, you can list more than one object file for input if you list them in the definitions file (rather than simply specifying one input file on the command line). In this case, nlmconv calls the linker for you.","Process Name":"m32r-linux-gnu-nlmconv","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-nlmconv"}},{"Process":{"Description":"GNU nm lists the symbols from object files objfile.... If no object files are listed as arguments, nm assumes the file a.out. For each symbol, nm shows: \u2022 The symbol value, in the radix selected by options (see below), or hexadecimal by default. \u2022 The symbol type. At least the following types are used; others are, as well, depending on the object file format. If lowercase, the symbol is usually local; if uppercase, the symbol is global (external). There are however a few lowercase symbols that are shown for special global symbols (\"u\", \"v\" and \"w\"). \"A\" The symbol's value is absolute, and will not be changed by further linking. \"B\" \"b\" The symbol is in the uninitialized data section (known as BSS ). \"C\" The symbol is common. Common symbols are uninitialized data. When linking, multiple common symbols may appear with the same name. If the symbol is defined anywhere, the common symbols are treated as undefined references. \"D\" \"d\" The symbol is in the initialized data section. \"G\" \"g\" The symbol is in an initialized data section for small objects. Some object file formats permit more efficient access to small data objects, such as a global int variable as opposed to a large global array. \"i\" For PE format files this indicates that the symbol is in a section specific to the implementation of DLLs. For ELF format files this indicates that the symbol is an indirect function. This is a GNU extension to the standard set of ELF symbol types. It indicates a symbol which if referenced by a relocation does not evaluate to its address, but instead must be invoked at runtime. The runtime execution will then return the value to be used in the relocation. \"N\" The symbol is a debugging symbol. \"p\" The symbols is in a stack unwind section. \"R\" \"r\" The symbol is in a read only data section. \"S\" \"s\" The symbol is in an uninitialized data section for small objects. \"T\" \"t\" The symbol is in the text (code) section. \"U\" The symbol is undefined. \"u\" The symbol is a unique global symbol. This is a GNU extension to the standard set of ELF symbol bindings. For such a symbol the dynamic linker will make sure that in the entire process there is just one symbol with this name and type in use. \"V\" \"v\" The symbol is a weak object. When a weak defined symbol is linked with a normal defined symbol, the normal defined symbol is used with no error. When a weak undefined symbol is linked and the symbol is not defined, the value of the weak symbol becomes zero with no error. On some systems, uppercase indicates that a default value has been specified. \"W\" \"w\" The symbol is a weak symbol that has not been specifically tagged as a weak object symbol. When a weak defined symbol is linked with a normal defined symbol, the normal defined symbol is used with no error. When a weak undefined symbol is linked and the symbol is not defined, the value of the symbol is determined in a system-specific manner without error. On some systems, uppercase indicates that a default value has been specified. \"-\" The symbol is a stabs symbol in an a.out object file. In this case, the next values printed are the stabs other field, the stabs desc field, and the stab type. Stabs symbols are used to hold debugging information. \"?\" The symbol type is unknown, or object file format specific. \u2022 The symbol name.","Process Name":"m32r-linux-gnu-nm","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-nm"}},{"Process":{"Description":null,"Process Name":"m32r-linux-gnu-objcopy","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-objcopy"}},{"Process":{"Description":"objdump displays information about one or more object files. The options control what particular information to display. This information is mostly useful to programmers who are working on the compilation tools, as opposed to programmers who just want their program to compile and work. objfile... are the object files to be examined. When you specify archives, objdump shows information on each of the member object files.","Process Name":"m32r-linux-gnu-objdump","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-objdump"}},{"Process":{"Description":null,"Process Name":"m32r-linux-gnu-ranlib","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-ranlib"}},{"Process":{"Description":"readelf displays information about one or more ELF format object files. The options control what particular information to display. elffile... are the object files to be examined. 32-bit and 64-bit ELF files are supported, as are archives containing ELF files. This program performs a similar function to objdump but it goes into more detail and it exists independently of the BFD library, so if there is a bug in BFD then readelf will not be affected.","Process Name":"m32r-linux-gnu-readelf","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-readelf"}},{"Process":{"Description":"The GNU size utility lists the section sizes---and the total size---for each of the object or archive files objfile in its argument list. By default, one line of output is generated for each object file or each module in an archive. objfile... are the object files to be examined. If none are specified, the file \"a.out\" will be used.","Process Name":"m32r-linux-gnu-size","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-size"}},{"Process":{"Description":null,"Process Name":"m32r-linux-gnu-strings","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-strings"}},{"Process":{"Description":null,"Process Name":"m32r-linux-gnu-strip","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-strip"}},{"Process":{"Description":"windmc reads message definitions from an input file (.mc) and translate them into a set of output files. The output files may be of four kinds: \"h\" A C header file containing the message definitions. \"rc\" A resource file compilable by the windres tool. \"bin\" One or more binary files containing the resource data for a specific message language. \"dbg\" A C include file that maps message id's to their symbolic name. The exact description of these different formats is available in documentation from Microsoft. When windmc converts from the \"mc\" format to the \"bin\" format, \"rc\", \"h\", and optional \"dbg\" it is acting like the Windows Message Compiler.","Process Name":"m32r-linux-gnu-windmc","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-windmc"}},{"Process":{"Description":null,"Process Name":"m32r-linux-gnu-windres","Link":"https:\/\/linux.die.net\/man\/1\/m32r-linux-gnu-windres"}},{"Process":{"Description":"Process macros in FILEs. If no FILE or if FILE is '-', standard input is read. Mandatory or optional arguments to long options are mandatory or optional for short options too. Operation modes: --help display this help and exit --version output version information and exit -E, --fatal-warnings once: warnings become errors, twice: stop execution at first error -i, --interactive unbuffer output, ignore interrupts -P, --prefix-builtins force a 'm4_' prefix to all builtins -Q, --quiet, --silent suppress some warnings for builtins --warn-macro-sequence[= REGEXP] warn if macro definition matches REGEXP, default \\$\\({[^}]*}\\|[0-9][0-9]+\\) Preprocessor features: -D, --define=NAME[= VALUE] define NAME as having VALUE, or empty -I, --include= DIRECTORY append DIRECTORY to include path -s, --synclines generate '#line NUM \"FILE\"' lines -U, --undefine= NAME undefine NAME Limits control: -g, --gnu override -G to re-enable GNU extensions -G, --traditional suppress all GNU extensions -H, --hashsize= PRIME set symbol lookup hash table size [509] -L, --nesting-limit= NUMBER change nesting limit, 0 for unlimited [0] Frozen state files: -F, --freeze-state= FILE produce a frozen state on FILE at end -R, --reload-state= FILE reload a frozen state from FILE at start Debugging: -d, --debug[= FLAGS] set debug level (no FLAGS implies 'aeq') --debugfile[= FILE] redirect debug and trace output to FILE (default stderr, discard if empty string) -l, --arglength= NUM restrict macro tracing size -t, --trace= NAME trace NAME when it is defined FLAGS is any of: a show actual arguments c show before collect, after collect and after call e show expansion f say current input file name i show changes in input files l say current input line number p show results of path searches q quote values as necessary, with a or e flag t trace for all macro calls, not only traceon'ed x add a unique macro call id, useful with c flag V shorthand for all of the above flags If defined, the environment variable 'M4PATH' is a colon-separated list of directories included after any specified by '-I'. Exit status is 0 for success, 1 for failure, 63 for frozen file version mismatch, or whatever value was passed to the m4exit macro.","Process Name":"m4","Link":"https:\/\/linux.die.net\/man\/1\/m4"}},{"Process":{"Description":"addr2line translates addresses into file names and line numbers. Given an address in an executable or an offset in a section of a relocatable object, it uses the debugging information to figure out which file name and line number are associated with it. The executable or relocatable object to use is specified with the -e option. The default is the file a.out. The section in the relocatable object to use is specified with the -j option. addr2line has two modes of operation. In the first, hexadecimal addresses are specified on the command line, and addr2line displays the file name and line number for each address. In the second, addr2line reads hexadecimal addresses from standard input, and prints the file name and line number for each address on standard output. In this mode, addr2line may be used in a pipe to convert dynamically chosen addresses. The format of the output is FILENAME:LINENO . The file name and line number for each input address is printed on separate lines. If the -f option is used, then each FILENAME:LINENO line is preceded by FUNCTIONNAME which is the name of the function containing the address. If the -i option is used and the code at the given address is present there because of inlining by the compiler then the { FUNCTIONNAME } FILENAME:LINENO information for the inlining function will be displayed afterwards. This continues recursively until there is no more inlining to report. If the -a option is used then the output is prefixed by the input address. If the -p option is used then the output for each input address is displayed on one, possibly quite long, line. If -p is not used then the output is broken up into multiple lines, based on the paragraphs above. If the file name or function name can not be determined, addr2line will print two question marks in their place. If the line number can not be determined, addr2line will print 0.","Process Name":"m68k-linux-gnu-addr2line","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-addr2line"}},{"Process":{"Description":null,"Process Name":"m68k-linux-gnu-ar","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-ar"}},{"Process":{"Description":"GNU as is really a family of assemblers. If you use (or have used) the GNU assembler on one architecture, you should find a fairly similar environment when you use it on another architecture. Each version has much in common with the others, including object file formats, most assembler directives (often called pseudo-ops) and assembler syntax. as is primarily intended to assemble the output of the GNU C compiler \"gcc\" for use by the linker \"ld\". Nevertheless, we've tried to make as assemble correctly everything that other assemblers for the same machine would assemble. Any exceptions are documented explicitly. This doesn't mean as always uses the same syntax as another assembler for the same architecture; for example, we know of several incompatible versions of 680x0 assembly language syntax. Each time you run as it assembles exactly one source program. The source program is made up of one or more files. (The standard input is also a file.) You give as a command line that has zero or more input file names. The input files are read (from left file name to right). A command line argument (in any position) that has no special meaning is taken to be an input file name. If you give as no file names it attempts to read one input file from the as standard input, which is normally your terminal. You may have to type ctl-D to tell as there is no more program to assemble. Use -- if you need to explicitly name the standard input file in your command line. If the source is empty, as produces a small, empty object file. as may write warnings and error messages to the standard error file (usually your terminal). This should not happen when a compiler runs as automatically. Warnings report an assumption made so that as could keep assembling a flawed program; errors report a grave problem that stops the assembly. If you are invoking as via the GNU C compiler, you can use the -Wa option to pass arguments through to the assembler. The assembler arguments must be separated from each other (and the -Wa) by commas. For example: gcc -c -g -O -Wa,-alh,-L file.c This passes two options to the assembler: -alh (emit a listing to standard output with high-level and assembly source) and -L (retain local symbols in the symbol table). Usually you do not need to use this -Wa mechanism, since many compiler command-line options are automatically passed to the assembler by the compiler. (You can call the GNU compiler driver with the -v option to see precisely what options it passes to each compilation pass, including the assembler.)","Process Name":"m68k-linux-gnu-as","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-as"}},{"Process":{"Description":"The C ++ and Java languages provide function overloading, which means that you can write many functions with the same name, providing that each function takes parameters of different types. In order to be able to distinguish these similarly named functions C ++ and Java encode them into a low-level assembler name which uniquely identifies each different version. This process is known as mangling. The c++filt [1] program does the inverse mapping: it decodes (demangles) low-level names into user-level names so that they can be read. Every alphanumeric word (consisting of letters, digits, underscores, dollars, or periods) seen in the input is a potential mangled name. If the name decodes into a C ++ name, the C ++ name replaces the low-level name in the output, otherwise the original word is output. In this way you can pass an entire assembler source file, containing mangled names, through c++filt and see the same source file containing demangled names. You can also use c++filt to decipher individual symbols by passing them on the command line: c++filt <symbol> If no symbol arguments are given, c++filt reads symbol names from the standard input instead. All the results are printed on the standard output. The difference between reading names from the command line versus reading names from the standard input is that command line arguments are expected to be just mangled names and no checking is performed to separate them from surrounding text. Thus for example: c++filt -n _Z1fv will work and demangle the name to \"f()\" whereas: c++filt -n _Z1fv, will not work. (Note the extra comma at the end of the mangled name which makes it invalid). This command however will work: echo _Z1fv, | c++filt -n and will display \"f(),\", i.e., the demangled name followed by a trailing comma. This behaviour is because when the names are read from the standard input it is expected that they might be part of an assembler source file where there might be extra, extraneous characters trailing after a mangled name. For example: .type   _Z1fv, @function","Process Name":"m68k-linux-gnu-c++filt","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-c++filt"}},{"Process":{"Description":null,"Process Name":"m68k-linux-gnu-cpp","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-cpp"}},{"Process":{"Description":null,"Process Name":"m68k-linux-gnu-dlltool","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-dlltool"}},{"Process":{"Description":"elfedit updates the ELF header of ELF files which have the matching ELF machine and file types. The options control how and which fields in the ELF header should be updated. elffile... are the ELF files to be updated. 32-bit and 64-bit ELF files are supported, as are archives containing ELF files.","Process Name":"m68k-linux-gnu-elfedit","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-elfedit"}},{"Process":{"Description":null,"Process Name":"m68k-linux-gnu-gcc","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-gcc"}},{"Process":{"Description":"gcov is a test coverage program. Use it in concert with GCC to analyze your programs to help create more efficient, faster running code and to discover untested parts of your program. You can use gcov as a profiling tool to help discover where your optimization efforts will best affect your code. You can also use gcov along with the other profiling tool, gprof, to assess which parts of your code use the greatest amount of computing time. Profiling tools help you analyze your code's performance. Using a profiler such as gcov or gprof, you can find out some basic performance statistics, such as: \u2022 how often each line of code executes \u2022 what lines of code are actually executed \u2022 how much computing time each section of code uses Once you know these things about how your code works when compiled, you can look at each module to see which modules should be optimized. gcov helps you determine where to work on optimization. Software developers also use coverage testing in concert with testsuites, to make sure software is actually good enough for a release. Testsuites can verify that a program works as expected; a coverage program tests to see how much of the program is exercised by the testsuite. Developers can then determine what kinds of test cases need to be added to the testsuites to create both better testing and a better final product. You should compile your code without optimization if you plan to use gcov because the optimization, by combining some lines of code into one function, may not give you as much information as you need to look for 'hot spots' where the code is using a great deal of computer time. Likewise, because gcov accumulates statistics by line (at the lowest resolution), it works best with a programming style that places only one statement on each line. If you use complicated macros that expand to loops or to other control structures, the statistics are less helpful---they only report on the line where the macro call appears. If your complex macros behave like functions, you can replace them with inline functions to solve this problem. gcov creates a logfile called sourcefile.gcov which indicates how many times each line of a source file sourcefile.c has executed. You can use these logfiles along with gprof to aid in fine-tuning the performance of your programs. gprof gives timing information you can use along with the information you get from gcov. gcov works only on code compiled with GCC . It is not compatible with any other profiling or test coverage mechanism.","Process Name":"m68k-linux-gnu-gcov","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-gcov"}},{"Process":{"Description":null,"Process Name":"m68k-linux-gnu-gprof","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-gprof"}},{"Process":{"Description":null,"Process Name":"m68k-linux-gnu-ld","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-ld"}},{"Process":{"Description":"nlmconv converts the relocatable i386 object file infile into the NetWare Loadable Module outfile, optionally reading headerfile for NLM header information. For instructions on writing the NLM command file language used in header files, see the linkers section, NLMLINK in particular, of the NLM Development and Tools Overview, which is part of the NLM Software Developer's Kit (\" NLM SDK \"), available from Novell, Inc. nlmconv uses the GNU Binary File Descriptor library to read infile; nlmconv can perform a link step. In other words, you can list more than one object file for input if you list them in the definitions file (rather than simply specifying one input file on the command line). In this case, nlmconv calls the linker for you.","Process Name":"m68k-linux-gnu-nlmconv","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-nlmconv"}},{"Process":{"Description":null,"Process Name":"m68k-linux-gnu-nm","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-nm"}},{"Process":{"Description":"The GNU objcopy utility copies the contents of an object file to another. objcopy uses the GNU BFD Library to read and write the object files. It can write the destination object file in a format different from that of the source object file. The exact behavior of objcopy is controlled by command-line options. Note that objcopy should be able to copy a fully linked file between any two formats. However, copying a relocatable object file between any two formats may not work as expected. objcopy creates temporary files to do its translations and deletes them afterward. objcopy uses BFD to do all its translation work; it has access to all the formats described in BFD and thus is able to recognize most formats without being told explicitly. objcopy can be used to generate S-records by using an output target of srec (e.g., use -O srec). objcopy can be used to generate a raw binary file by using an output target of binary (e.g., use -O binary). When objcopy generates a raw binary file, it will essentially produce a memory dump of the contents of the input object file. All symbols and relocation information will be discarded. The memory dump will start at the load address of the lowest section copied into the output file. When generating an S-record or a raw binary file, it may be helpful to use -S to remove sections containing debugging information. In some cases -R will be useful to remove sections which contain information that is not needed by the binary file. Note---objcopy is not able to change the endianness of its input files. If the input format has an endianness (some formats do not), objcopy can only copy the inputs into file formats that have the same endianness or which have no endianness (e.g., srec). (However, see the --reverse-bytes option.)","Process Name":"m68k-linux-gnu-objcopy","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-objcopy"}},{"Process":{"Description":null,"Process Name":"m68k-linux-gnu-objdump","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-objdump"}},{"Process":{"Description":"ranlib generates an index to the contents of an archive and stores it in the archive. The index lists each symbol defined by a member of an archive that is a relocatable object file. You may use nm -s or nm --print-armap to list this index. An archive with such an index speeds up linking to the library and allows routines in the library to call each other without regard to their placement in the archive. The GNU ranlib program is another form of GNU ar; running ranlib is completely equivalent to executing ar -s.","Process Name":"m68k-linux-gnu-ranlib","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-ranlib"}},{"Process":{"Description":"readelf displays information about one or more ELF format object files. The options control what particular information to display. elffile... are the object files to be examined. 32-bit and 64-bit ELF files are supported, as are archives containing ELF files. This program performs a similar function to objdump but it goes into more detail and it exists independently of the BFD library, so if there is a bug in BFD then readelf will not be affected.","Process Name":"m68k-linux-gnu-readelf","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-readelf"}},{"Process":{"Description":"The GNU size utility lists the section sizes---and the total size---for each of the object or archive files objfile in its argument list. By default, one line of output is generated for each object file or each module in an archive. objfile... are the object files to be examined. If none are specified, the file \"a.out\" will be used.","Process Name":"m68k-linux-gnu-size","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-size"}},{"Process":{"Description":"For each file given, GNU strings prints the printable character sequences that are at least 4 characters long (or the number given with the options below) and are followed by an unprintable character. By default, it only prints the strings from the initialized and loaded sections of object files; for other types of files, it prints the strings from the whole file. strings is mainly useful for determining the contents of non-text files.","Process Name":"m68k-linux-gnu-strings","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-strings"}},{"Process":{"Description":null,"Process Name":"m68k-linux-gnu-strip","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-strip"}},{"Process":{"Description":"windmc reads message definitions from an input file (.mc) and translate them into a set of output files. The output files may be of four kinds: \"h\" A C header file containing the message definitions. \"rc\" A resource file compilable by the windres tool. \"bin\" One or more binary files containing the resource data for a specific message language. \"dbg\" A C include file that maps message id's to their symbolic name. The exact description of these different formats is available in documentation from Microsoft. When windmc converts from the \"mc\" format to the \"bin\" format, \"rc\", \"h\", and optional \"dbg\" it is acting like the Windows Message Compiler.","Process Name":"m68k-linux-gnu-windmc","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-windmc"}},{"Process":{"Description":null,"Process Name":"m68k-linux-gnu-windres","Link":"https:\/\/linux.die.net\/man\/1\/m68k-linux-gnu-windres"}},{"Process":{"Description":"Maatkit is a collection of command-line utilities that provide missing functionality for MySQL. Some of the tools implement lacking server functionality, such as online consistency checks for master\/slave replication; others are client-side utilities such as a query profiler. The following tools are included:    $Revision: 7332 $\nmk-archiver 1.0.26\nmk-deadlock-logger 1.0.21\nmk-duplicate-key-checker 1.2.14\nmk-error-log 1.0.3\nmk-fifo-split 1.0.7\nmk-find 0.9.23\nmk-heartbeat 1.0.22\nmk-index-usage 0.9.4\nmk-kill 0.9.9\nmk-loadavg 0.9.7\nmk-log-player 1.0.9\nmk-parallel-dump 1.0.28\nmk-parallel-restore 1.0.24\nmk-purge-logs 0.9.0\nmk-query-advisor 1.0.4\nmk-query-digest 0.9.27\nmk-query-profiler 1.1.22\nmk-show-grants 1.0.23\nmk-slave-delay 1.0.23\nmk-slave-find 1.0.15\nmk-slave-move 0.9.12\nmk-slave-prefetch 1.0.21\nmk-slave-restart 1.0.22\nmk-table-checksum 1.2.20\nmk-table-sync 1.0.31\nmk-upgrade 0.9.8\nmk-variable-advisor 1.0.2\nmk-visual-explain 1.0.22 mk-archiver Archive rows from a MySQL table into another table or a file. See mk-archiver. mk-checksum-filter Filter checksums from mk-table-checksum. See mk-checksum-filter. mk-deadlock-logger Extract and log MySQL deadlock information. See mk-deadlock-logger. mk-duplicate-key-checker Find duplicate indexes and foreign keys on MySQL tables. See mk-duplicate-key-checker. mk-error-log Find new and different MySQL error log entries. See mk-error-log. mk-fifo-split Split files and pipe lines to a fifo without really splitting. See mk-fifo-split. mk-find Find MySQL tables and execute actions, like GNU find. See mk-find. mk-heartbeat Monitor MySQL replication delay. See mk-heartbeat. mk-index-usage Read queries from a log and analyze how they use indexes. See mk-index-usage. mk-kill Kill MySQL queries that match certain criteria. See mk-kill. mk-loadavg Watch MySQL load and take action when it gets too high. See mk-loadavg. mk-log-player Replay MySQL query logs. See mk-log-player. mk-merge-mqd-results Merge multiple mk-query-digest reports into one. See mk-merge-mqd-results. mk-parallel-dump ( DEPRECATED ) Dump MySQL tables in parallel. See mk-parallel-dump. mk-parallel-restore ( DEPRECATED ) Load files into MySQL in parallel. See mk-parallel-restore. mk-profile-compact Compact the output from mk-query-profiler. See mk-profile-compact. mk-purge-logs Purge binary logs on a master based on purge rules. See mk-purge-logs. mk-query-advisor Analyze queries and advise on possible problems. See mk-query-advisor. mk-query-digest Analyze query execution logs and generate a query report, filter, replay, or transform queries for MySQL, PostgreSQL, memcached, and more. See mk-query-digest. mk-query-profiler Execute SQL statements and print statistics, or measure activity caused by other processes. See mk-query-profiler. mk-show-grants Canonicalize and print MySQL grants so you can effectively replicate, compare and version-control them. See mk-show-grants. mk-slave-delay Make a MySQL slave server lag behind its master. See mk-slave-delay. mk-slave-find Find and print replication hierarchy tree of MySQL slaves. See mk-slave-find. mk-slave-move Move a MySQL slave around in the replication hierarchy. See mk-slave-move. mk-slave-prefetch Pipeline relay logs on a MySQL slave to pre-warm caches. See mk-slave-prefetch. mk-slave-restart Watch and restart MySQL replication after errors. See mk-slave-restart. mk-table-checksum Perform an online replication consistency check, or checksum MySQL tables efficiently on one or many servers. See mk-table-checksum. mk-table-sync Synchronize MySQL table data efficiently. See mk-table-sync. mk-upgrade Execute queries on multiple servers and check for differences. See mk-upgrade. mk-variable-advisor Analyze MySQL variables and advise on possible problems. See mk-variable-advisor. mk-visual-explain Format EXPLAIN output as a tree. See mk-visual-explain.","Process Name":"maatkit","Link":"https:\/\/linux.die.net\/man\/1\/maatkit"}},{"Process":{"Description":null,"Process Name":"mac2unix","Link":"https:\/\/linux.die.net\/man\/1\/mac2unix"}},{"Process":{"Description":"megatron is used to transform files from BinHex, MacBinary, AppleSingle, or netatalk style AppleDouble formats into MacBinary or netatalk style AppleDouble formats. The netatalk style AppleDouble format is the file format used by afpd, the netatalk Apple Filing Protocol (AppleShare) server. BinHex, MacBinary, and AppleSingle are commonly used formats for transferring Macintosh files between machines via email or file transfer protocols. megatron uses its name to determine what type of tranformation is being asked of it. If megatron is called as unhex , unbin or unsingle, it tries to convert file(s) from BinHex, MacBinary, or AppleSingle into AppleDouble format. BinHex is the format most often used to send Macintosh files by e-mail. Usually these files have an extension of \".hqx\". MacBinary is the format most often used by terminal emulators \"on the fly\" when transferring Macintosh files in binary mode. MacBinary files often have an extension of \".bin\". Some Macintosh LAN-based email packages use uuencoded AppleSingle format to \"attach\" or \"enclose\" files in email. AppleSingle files don't have a standard filename extension. If megatron is called as hqx2bin, single2bin, or macbinary, it will try to convert the file(s) from BinHex, AppleSingle, or AppleDouble into MacBinary. This last translation may be useful in moving Macintosh files from your afpd server to some other machine when you can't copy them from the server using a Macintosh for some reason. If megatron is called with any other name, it uses the default translation, namely unhex. If no source file is given, or if sourcefile is '-', and if the conversion is from a BinHex or MacBinary file, megatron will read from standard input. The filename used to store any output file is the filename that is encoded in the source file. MacBinary files are created with a \".bin\" extension. In the case of conflicts, the old file is overwritten!","Process Name":"macbinary","Link":"https:\/\/linux.die.net\/man\/1\/macbinary"}},{"Process":{"Description":"macpack is a tool used to package managed assemblies (like System.Windows.Forms or Cocoa#) that require gui availability for deployment on Mac OS X. macpack will prepare a OS X compatible bundle from the provided assembly and resources. The bundle will include the specified assembly as well as any of the provided resources (specified with the -resource: switch). Developers can specify the kind of application to produce using the -mode: argument. This controls how the environment in the Mono class libraries is setup.","Process Name":"macpack","Link":"https:\/\/linux.die.net\/man\/1\/macpack"}},{"Process":{"Description":"This program is part of Netpbm(1). macptopbmreads a MacPaint file as input and produces a PBM image as output.","Process Name":"macptopbm","Link":"https:\/\/linux.die.net\/man\/1\/macptopbm"}},{"Process":{"Description":null,"Process Name":"mag","Link":"https:\/\/linux.die.net\/man\/1\/mag"}},{"Process":{"Description":"Magic is an interactive editor for VLSI layouts that runs under all variants of UNIX, including Mac OS-X and Cygwin. This man page is a reference manual; if you are a first-time user, you should use the Magic tutorials to get acquainted with the system (see the online resources links below). Magic uses two windows: one for text and a separate window for displaying layouts. Magic runs under the window system X11 (use under Cygwin requires the presence of an X11 server in Windows; the server that comes packaged with Cygwin works well). The command line switch \"-d\" can be used to tell Magic which kind of display you are running. Specifically, this is useful to tell magic to use OpenGL graphics instead of plain X11 (\"-d OGL\"), or to use 24 bit plane graphics instead of 8 bit planes (\"-d 24BITS\") if both are available on a video card with overlay support. Here are the options accepted by Magic: -T The next argument is the name of a technology. The tile types, display information, and design rules for this technology are read by Magic from a technology file when it starts up. The technology defaults to ''scmos''. -d The next argument is the type of workstation or graphics display being used. Magic supports these types: NULL A null device for running Magic without using a graphics display, such as a batch job. Note that the special case \"-dnull\" (lowercase, no space) has a more streamlined startup specifically for batch processing. X11 X-windows, version 11. The is the preferred interface. Magic acts as a client to the X window server and interfaces to all graphics terminals supported by the X server. OGL OpenGL graphics running under X11. This is the preferred interface on systems having hardware-accelerated 3D graphics video cards and drivers. Addition information on Magic's X11 driver, including options for .Xdefaults files, may be found in ''Magic Maintainer's Manual #4: Using Magic Under X Windows''. XWIND Simply another name for the X11 driver. If no device is specified, Magic tries to guess which driver is appropriate (by checking the environment variables and by poking around in \/dev). When Magic starts up it looks for a command file in ${CAD_ROOT}\/magic\/sys\/.magicrc and processes it if it exists. Then Magic looks for a file with the name ''.magicrc'' in the home directory and processes it if it exists. Finally, Magic looks for a .magicrc file in the current directory and reads it as a command file if it exists. The .magicrc file format is described under the source command. If magic is compiled with Tcl\/Tk support, then any magic or Tcl\/Tk commands may be used inside the startup file. The startup file name was changed to \".magicrc\" to avoid conflicts with a common system file named \".magic\". However, the name \".magic\" will be searched after \".magicrc\" for backward compatibility.","Process Name":"magic","Link":"https:\/\/linux.die.net\/man\/1\/magic"}},{"Process":{"Description":null,"Process Name":"magick++-config","Link":"https:\/\/linux.die.net\/man\/1\/magick++-config"}},{"Process":{"Description":"Magick-config prints the compiler and linker flags required to compile and link programs that use the ImageMagick Application Programmer Interface.","Process Name":"magick-config","Link":"https:\/\/linux.die.net\/man\/1\/magick-config"}},{"Process":{"Description":null,"Process Name":"magickcore-config","Link":"https:\/\/linux.die.net\/man\/1\/magickcore-config"}},{"Process":{"Description":"MagickWand-config prints the compiler and linker flags required to compile and link programs that use the Wand Application Programmer Interface.","Process Name":"magickwand-config","Link":"https:\/\/linux.die.net\/man\/1\/magickwand-config"}},{"Process":{"Description":null,"Process Name":"magnifier","Link":"https:\/\/linux.die.net\/man\/1\/magnifier"}},{"Process":{"Description":"Mailx is an intelligent mail processing system, which has a command syntax reminiscent of ed(1) with lines replaced by messages. It is based on Berkeley Mail 8.1, is intended to provide the functionality of the POSIX mailx command, and offers extensions for MIME, IMAP, POP3, SMTP, and S\/MIME. Mailx provides enhanced features for interactive use, such as caching and disconnected operation for IMAP, message threading, scoring, and filtering. It is also usable as a mail batch language, both for sending and receiving mail. The following options are accepted: -A name Executes an account command (see below) for name after the startup files have been read. -a file Attach the given file to the message. -B Make standard input and standard output line-buffered. -b address Send blind carbon copies to list. List should be a comma-separated list of names. -c address Send carbon copies to list of users. -D Start in disconnected mode; see the description for the disconnected variable option. -d Enables debugging messages and disables the actual delivery of messages. Unlike -v, this option is intended for mailx development only. -e Just check if mail is present in the system mailbox. If yes, return an exit status of zero, else, a non-zero value. -E If an outgoing message does not contain any text in its first or only message part, do not send it but discard it silently, effectively setting the skipemptybody variable at program startup. This is useful for sending messages from scripts started by cron(8). -f [ file] Read in the contents of the user's mbox (or the specified file) for processing; when mailx is quit, it writes undeleted messages back to this file. The string file is handled as described for the folder command below. -F Save the message to send in a file named after the local part of the first recipient's address. -H Print header summaries for all messages and exit. -h hops Invoke sendmail with the specified hop count. This option has no effect when SMTP is used for sending mail. -i Ignore tty interrupt signals. This is particularly useful when using mailx on noisy phone lines. -I Shows the 'Newsgroup:' or 'Article-Id:' fields in the header summary. Only applicable in combination with -f. -n Inhibits reading \/etc\/mail.rc upon startup. This option should be activated for mailx scripts that are invoked on more than one machine, because the contents of that file may differ between them. -N Inhibits the initial display of message headers when reading mail or editing a mail folder. -q file Start the message with the contents of the specified file. May be given in send mode only. -r address Sets the From address. Overrides any from variable specified in environment or startup files. Tilde escapes are disabled. The -r address options are passed to the mail transfer agent unless SMTP is used. This option exists for compatibility only; it is recommended to set the from variable directly instead. -R Opens any folders read-only. -s subject Specify subject on command line (only the first argument after the -s flag is used as a subject; be careful to quote subjects containing spaces). -S variable[ = value] Sets the internal option variable and, in case of a string option, assigns value to it. -T name Writes the 'Message-Id:' and 'Article-Id:' header fields of each message read in the file name. Implies -I. Compressed files are handled as described for the folder command below. -t The message to be sent is expected to contain a message header with 'To:', 'Cc:', or 'Bcc:' fields giving its recipients. Recipients specified on the command line are ignored. -u user Reads the mailbox of the given user name. -v Verbose mode. The details of delivery are displayed on the user's terminal. -V Print mailx's version and exit. -~ Enable tilde escapes even if not in interactive mode. Sending mail To send a message to one or more people, mailx can be invoked with arguments which are the names of people to whom the mail will be sent. The user is then expected to type in his message, followed by an 'control-D' at the beginning of a line. The section below Replying to or originating mail, describes some features of mailx available to help when composing letters. Reading mail In normal usage mailx is given no arguments and checks the user's mail out of the post office, then prints out a one line header of each message found. The current message is initially the first message (numbered 1) and can be printed using the print command which can be abbreviated 'p'). The user can move among the messages much as he moves between lines in ed(1), with the commands '+' and '-' moving backwards and forwards, and simple numbers. Disposing of mail After examining a message the user can delete 'd') the message or reply 'r') to it. Deletion causes the mailx program to forget about the message. This is not irreversible; the message can be undeleted 'u') by giving its number, or the mailx session can be aborted by giving the exit 'x') command. Deleted messages will, however, usually disappear never to be seen again. Specifying messages Commands such as print and delete can be given a list of message numbers as arguments to apply to a number of messages at once. Thus ' delete 1 2' deletes messages 1 and 2, while ' delete 1-5' deletes messages 1 through 5. In sorted or threaded mode (see the sort and thread commands), ' delete 1-5' deletes the messages that are located between (and including) messages 1 through 5 in the sorted\/threaded order, as shown in the header summary. The following special message names exist: :n All new messages. :o All old messages (any not in state read or new). :u All unread messages. :d All deleted messages (for the undelete command). :r All read messages. :f All 'flagged' messages. :a All answered messages (cf. the markanswered variable). :t All messages marked as draft. :k All 'killed' messages. :j All messages classified as junk. . The current message. ; The message that was previously the current message. , The parent message of the current message, that is the message with the Message-ID given in the 'In-Reply-To:' field or the last entry of the 'References:' field of the current message. - The next previous undeleted message, or the next previous deleted message for the undelete command. In sorted\/threaded mode, the next previous such message in the sorted\/threaded order. + The next undeleted message, or the next deleted message for the undelete command. In sorted\/threaded mode, the next such message in the sorted\/threaded order. ^ The first undeleted message, or the first deleted message for the undelete command. In sorted\/threaded mode, the first such message in the sorted\/threaded order. $ The last message. In sorted\/threaded mode, the last message in the sorted\/threaded order. &x In threaded mode, selects the message addressed with x, where x is any other message specification, and all messages from the thread that begins at it. Otherwise, it is identical to x. If x is omitted, the thread beginning with the current message is selected. * All messages. ' All messages that were included in the message list for the previous command. \/ string All messages that contain string in the subject field (case ignored). See also the searchheaders variable. If string is empty, the string from the previous specification of that type is used again. address All messages from address. ( criterion ) All messages that satisfy the given IMAP-style SEARCH criterion. This addressing mode is available with all types of folders; for folders not located on IMAP servers, or for servers unable to execute the SEARCH command, mailx will perform the search locally. Strings must be enclosed by double quotes '\"' in their entirety if they contain white space or parentheses; within the quotes, only backslash '\\' is recognized as an escape character. All string searches are case-insensitive. When the description indicates that the 'envelope' representation of an address field is used, this means that the search string is checked against both a list constructed as (\"real name\" \"source-route\" \"local-part\" \"domain-part\")\n\n for each address, and the addresses without real names from the respective header field. Criteria can be nested using parentheses. ( criterion1 criterion2 ... criterionN ) All messages that satisfy all of the given criteria. (or criterion1 criterion2 ) All messages that satisfy either criterion1 or criterion2, or both. To connect more than two criteria using 'or', (or) specifications have to be nested using additional parentheses, as with '(or a (or b c))'; '(or a b c)' means ((a or b) and c). For a simple 'or' operation of independent criteria on the lowest nesting level, it is possible to achieve similar effects by using three separate criteria, as with '(a) (b) (c)'. (not criterion ) All messages that do not satisfy criterion. (bcc string ) All messages that contain string in the 'envelope' representation of the Bcc: field. (cc string ) All messages that contain string in the 'envelope' representation of the Cc: field. (from string ) All messages that contain string in the 'envelope' representation of the From: field. (subject string ) All messages that contain string in the Subject: field. (to string ) All messages that contain string in the 'envelope' representation of the To: field. (header name string ) All messages that contain string in the specified Name: field. (body string ) All messages that contain string in their body. (text string ) All messages that contain string in their header or body. (larger size ) All messages that are larger than size (in bytes). (smaller size ) All messages that are smaller than size (in bytes). (before date ) All messages that were received before date; date must be in the form d[ d] - mon - yyyy, where d[ d] is the day of the month as one or two digits, mon is the name of the month-one of 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', or 'Dec', and yyyy is the year as four digits; e.g. \"30-Aug-2004\". (on date ) All messages that were received on the specified date. (since date ) All messages that were received since the specified date. (sentbefore date ) All messages that were sent on the specified date. (senton date ) All messages that were sent on the specified date. (sentsince date ) All messages that were sent since the specified date. () The same criterion as for the previous search. This specification cannot be used as part of another criterion. If the previous command line contained more than one independent criterion, the last of those criteria is used. A practical method to read a set of messages is to issue a from command with the search criteria first to check for appropriate messages, and to read each single message then by typing ' '' repeatedly. Replying to or originating mail The reply command can be used to set up a response to a message, sending it back to the person who it was from. Text the user types in then, up to an end-of-file, defines the contents of the message. While the user is composing a message, mailx treats lines beginning with the character '~' specially. For instance, typing '~m' (alone on a line) will place a copy of the current message into the response right shifting it by a tabstop (see indentprefix variable, below). Other escapes will set up subject fields, add and delete recipients to the message, attach files to it and allow the user to escape to an editor to revise the message or to a shell to run some commands. (These options are given in the summary below.) Ending a mail processing session The user can end a mailx session with the quit ('q') command. Messages which have been examined go to the user's mbox file unless they have been deleted in which case they are discarded. Unexamined messages go back to the post office. (See the -f option above). Personal and systemwide distribution lists It is also possible to create a personal distribution lists so that, for instance, the user can send mail to ' cohorts' and have it go to a group of people. Such lists can be defined by placing a line like         alias cohorts bill ozalp jkf mark kridle@ucbcory\n\n in the file .mailrc in the user's home directory. The current list of such aliases can be displayed with the alias command in mailx. System wide distribution lists can be created by editing \/etc\/aliases, see aliases(5) and sendmail(8); these are kept in a different syntax. In mail the user sends, personal aliases will be expanded in mail sent to others so that they will be able to reply to the recipients. System wide aliases are not expanded when the mail is sent, but any reply returned to the machine will have the system wide alias expanded as all mail goes through sendmail. Recipient address specifications When an address is used to name a recipient (in any of To, Cc, or Bcc), names of local mail folders and pipes to external commands can also be specified; the message text is then written to them. The rules are: Any name which starts with a ' |' character specifies a pipe, the command string following the '|' is executed and the message is sent to its standard input; any other name which contains a ' @' character is treated as a mail address; any other name which starts with a ' +' character specifies a folder name; any other name which contains a ' \/' character but no ' !' or ' %' character before also specifies a folder name; what remains is treated as a mail address. Compressed folders are handled as described for the folder command below. Network mail (Internet \/ ARPA, UUCP, Berknet) See mailaddr(7) for a description of network addresses. Mailx has a number of options which can be set in the .mailrc file to alter its behavior; thus ' set askcc' enables the askcc feature. (These options are summarized below). MIME types For any outgoing attachment, mailx tries to determine the content type. It does this by reading MIME type files whose lines have the following syntax:         type\/subtype      extension [extension . . .] where type\/subtype are strings describing the file contents, and extension is the part of a filename starting after the last dot. Any line not immediately beginning with an ASCII alphabetical character is ignored by mailx. If there is a match with the extension of the file to attach, the given type\/subtype pair is used. Otherwise, or if the filename has no extension, the content types text\/plain or application\/octet-stream are used, the first for text or international text files, the second for any file that contains formatting characters other than newlines and horizontal tabulators. Character sets Mailx normally detects the character set of the terminal using the LC_CTYPE locale setting. If the locale cannot be used appropriately, the ttycharset variable should be set to provide an explicit value. When reading messages, their text is converted to the terminal character set if possible. Unprintable characters and illegal byte sequences are detected and replaced by Unicode substitute characters or question marks unless the print-all-chars is set at initialization time. The character set for outgoing messages is not necessarily the same as the one used on the terminal. If an outgoing text message contains characters not representable in US-ASCII, the character set being used must be declared within its header. Permissible values can be declared using the sendcharsets variable, separated by commas; mailx tries each of the values in order and uses the first appropriate one. If the message contains characters that cannot be represented in any of the given character sets, the message will not be sent, and its text will be saved to the 'dead.letter' file. Messages that contain NUL bytes are not converted. Outgoing attachments are converted if they are plain text. If the sendcharsets variable contains more than one character set name, the ~@ tilde escape will ask for the character sets for individual attachments if it is invoked without arguments. Best results are usually achieved when mailx is run in a UTF-8 locale on a UTF-8 capable terminal. In this setup, characters from various countries can be displayed, while it is still possible to use more simple character sets for sending to retain maximum compatibility with older mail clients. Commands Each command is typed on a line by itself, and may take arguments following the command word. The command need not be typed in its entirety - the first command which matches the typed prefix is used. For commands which take message lists as arguments, if no message list is given, then the next message forward which satisfies the command's requirements is used. If there are no messages forward of the current message, the search proceeds backwards, and if there are no good messages at all, mailx types ' applicable messages' and aborts the command. If the command begins with a # sign, the line is ignored. The arguments to commands can be quoted, using the following methods: \u2022 An argument can be enclosed between paired double-quotes \"\" or single-quotes ''; any white space, shell word expansion, or backslash characters within the quotes are treated literally as part of the argument. A double-quote will be treated literally within single-quotes and vice versa. These special properties of the quote marks occur only when they are paired at the beginning and end of the argument. \u2022 A backslash outside of the enclosing quotes is discarded and the following character is treated literally as part of the argument. \u2022 An unquoted backslash at the end of a command line is discarded and the next line continues the command. Filenames, where expected, are subjected to the following transformations, in sequence: \u2022 If the filename begins with an unquoted plus sign, and the folder variable is defined, the plus sign will be replaced by the value of the folder variable followed by a slash. If the folder variable is unset or is set to null, the filename will be unchanged. \u2022 Shell word expansions are applied to the filename. If more than a single pathname results from this expansion and the command is expecting one file, an error results. The following commands are provided: - Print out the preceding message. If given a numeric argument n, goes to the n'th previous message and prints it. ? Prints a brief summary of commands. ! Executes the shell (see sh(1) and csh(1)) command which follows. | A synonym for the pipe command. account (ac) Creates, selects or lists an email account. An account is formed by a group of commands, primarily of those to set variables. With two arguments, of which the second is a '{', the first argument gives an account name, and the following lines create a group of commands for that account until a line containing a single '}' appears. With one argument, the previously created group of commands for the account name is executed, and a folder command is executed for the system mailbox or inbox of that account. Without arguments, the list of accounts and their contents are printed. As an example,     account myisp {\n        set folder=imaps:\/\/mylogin@imap.myisp.example\n        set record=+Sent\n        set from=\"myname@myisp.example (My Name)\"\n        set smtp=smtp.myisp.example\n    }\n creates an account named 'myisp' which can later be selected by specifying 'account myisp'. alias (a) With no arguments, prints out all currently-defined aliases. With one argument, prints out that alias. With more than one argument, creates a new alias or changes an old one. alternates (alt) The alternates command is useful if the user has accounts on several machines. It can be used to inform mailx that the listed addresses all belong to the invoking user. When he replies to messages, mailx will not send a copy of the message to any of the addresses listed on the alternates list. If the alternates command is given with no argument, the current set of alternate names is displayed. answered (ans) Takes a message list and marks each message as a having been answered. This mark has no technical meaning in the mail system; it just causes messages to be marked in the header summary, and makes them specially addressable. cache Only applicable to cached IMAP mailboxes; takes a message list and reads the specified messages into the IMAP cache. call Calls a macro (see the define command). cd Same as chdir. certsave Only applicable to S\/MIME signed messages. Takes a message list and a file name and saves the certificates contained within the message signatures to the named file in both human-readable and PEM format. The certificates can later be used to send encrypted messages to the messages' originators by setting the smime-encrypt-user@host variable. chdir (ch) Changes the user's working directory to that specified, if given. If no directory is given, then changes to the user's login directory. classify (cl) Takes a list of messages and examines their contents for characteristics of junk mail using Bayesian filtering. Messages considered to be junk are then marked as such. The junk mail database is not changed. collapse (coll) Only applicable to threaded mode. Takes a message list and makes all replies to these messages invisible in header summaries, unless they are in state 'new'. connect (conn) If operating in disconnected mode on an IMAP mailbox, switch to online mode and connect to the mail server while retaining the mailbox status. See the description of the disconnected variable for more information. copy (c) The copy command does the same thing that save does, except that it does not mark the messages it is used on for deletion when the user quits. Compressed files and IMAP mailboxes are handled as described for the folder command. Copy (C) Similar to copy, but saves the messages in a file named after the local part of the sender address of the first message. decrypt (dec) For unencrypted messages, this command is identical to copy. Encrypted messages are first decrypted, if possible, and then copied. Decrypt (Dec) Similar to decrypt, but saves the messages in a file named after the local part of the sender address of the first message. define (def) Defines a macro. A macro definition is a sequence of commands in the following form: define name { command1 command2 ... commandN } Once defined, a macro can be explicitly invoked using the call command, or can be implicitly invoked by setting the folder-hook or folder-hook-fullname variables. defines Prints the currently defined macros including their contents. delete (d) Takes a list of messages as argument and marks them all as deleted. Deleted messages will not be saved in mbox, nor will they be available for most other commands. discard Same as ignore. disconnect (disco) If operating in online mode on an IMAP mailbox, switch to disconnected mode while retaining the mailbox status. See the description of the disconnected variable for more information. A list of messages may optionally be given as argument; the respective messages are then read into the cache before the connection is closed. Thus 'disco *' makes the entire current mailbox available for disconnected use. dp or dt Deletes the current message and prints the next message. If there is no next message, mailx says ' at EOF'. draft Takes a message list and marks each message as a draft. This mark has no technical meaning in the mail system; it just causes messages to be marked in the header summary, and makes them specially addressable. echo Echoes its arguments, resolving special names as documented for the folder command. The escape sequences '\\a', '\\b', '\\c', '\\f', '\\n', '\\r', '\\t', '\\v', '\\\\', and '\\0num' are interpreted as with the echo(1) command. edit (e) Takes a list of messages and points the text editor at each one in turn. Modified contents are discarded unless the writebackedited variable is set. else Marks the end of the then-part of an if statement and the beginning of the part to take effect if the condition of the if statement is false. endif Marks the end of an if statement. exit (ex or x) Effects an immediate return to the Shell without modifying the user's system mailbox, his mbox file, or his edit file in -f. file (fi) The same as folder. flag (fl) Takes a message list and marks the messages as 'flagged' for urgent\/special attention. This mark has no technical meaning in the mail system; it just causes messages to be highlighted in the header summary, and makes them specially addressable. folders With no arguments, list the names of the folders in the folder directory. With an existing folder as an argument, lists then names of folders below the named folder; e.g. the command 'folders @' lists the folders on the base level of the current IMAP server. See also the imap-list-depth variable. folder (fold) The folder command switches to a new mail file or folder. With no arguments, it tells the user which file he is currently reading. If an argument is given, it will write out changes (such as deletions) the user has made in the current file and read in the new file. Some special conventions are recognized for the name. # means the previous file, % means the invoking user's system mailbox, %user means user's system mailbox, & means the invoking user's mbox file, and +file means a file in the folder directory. %:filespec expands to the same value as filespec, but the file is handled as a system mailbox e. g. by the mbox and save commands. If the name matches one of the strings defined with the shortcut command, it is replaced by its long form and expanded. If the name ends with .gz or .bz2, it is treated as compressed with gzip(1) or bzip2(1), respectively. Likewise, if name does not exist, but either name.gz or name.bz2 exists, the compressed file is used. If name refers to a directory with the subdirectories 'tmp', 'new', and 'cur', it is treated as a folder in maildir format. A name of the form protocol :\/\/[ user @] host[ : port][ \/ file] is taken as an Internet mailbox specification. The supported protocols are currently imap (IMAP v4r1), imaps (IMAP with SSL\/TLS encryption), pop3 (POP3), and pop3s (POP3 with SSL\/TLS encryption). If user contains special characters, in particular '\/' or '%', they must be escaped in URL notation, as '%2F' or '%25'. The optional file part applies to IMAP only; if it is omitted, the default 'INBOX' is used. If mailx is connected to an IMAP server, a name of the form @mailbox refers to the mailbox on that server. If the 'folder' variable refers to an IMAP account, the special name '%' selects the 'INBOX' on that account. Followup (F) Similar to Respond, but saves the message in a file named after the local part of the first recipient's address. followup (fo) Similar to respond, but saves the message in a file named after the local part of the first recipient's address. followupall Similar to followup, but responds to all recipients regardless of the flipr and Replyall variables. followupsender Similar to Followup, but responds to the sender only regardless of the flipr and Replyall variables. forward (fwd) Takes a message and the address of a recipient and forwards the message to him. The text of the original message is included in the new one, with the value of the fwdheading variable printed before. The fwdignore and fwdretain commands specify which header fields are included in the new message. Only the first part of a multipart message is included unless the forward-as-attachment option is set. Forward (Fwd) Similar to forward, but saves the message in a file named after the local part of the recipient's address. from (f) Takes a list of messages and prints their message headers, piped through the pager if the output does not fit on the screen. fwdignore Specifies which header fields are to be ignored with the forward command. This command has no effect when the forward-as-attachment option is set. fwdretain Specifies which header fields are to be retained with the forward command. fwdretain overrides fwdignore. This command has no effect when the forward-as-attachment option is set. good (go) Takes a list of messages and marks all of them as not being junk mail. Data from these messages is then inserted into the junk mail database for future classification. headers (h) Lists the current range of headers, which is an 18-message group. If a '+' argument is given, then the next 18-message group is printed, and if a '-' argument is given, the previous 18-message group is printed. help A synonym for ?. hold (ho, also preserve) Takes a message list and marks each message therein to be saved in the user's system mailbox instead of in mbox. Does not override the delete command. mailx deviates from the POSIX standard with this command, as a 'next' command issued after 'hold' will display the following message, not the current one. if Commands in mailx's startup files can be executed conditionally depending on whether the user is sending or receiving mail with the if command. For example: if receive commands . . . endif An else form is also available:         if receive\n                commands . . .\n        else\n                commands . . .\n        endif\n\n Note that the only allowed conditions are receive, send, and term (execute command if standard input is a tty). ignore Add the list of header fields named to the ignored list. Header fields in the ignore list are not printed on the terminal when a message is printed. This command is very handy for suppression of certain machine-generated header fields. The Type and Print commands can be used to print a message in its entirety, including ignored fields. If ignore is executed with no arguments, it lists the current set of ignored fields. imap Sends command strings directly to the current IMAP server. Mailx operates always in IMAP selected state on the current mailbox; commands that change this will produce undesirable results and should be avoided. Useful IMAP commands are: create Takes the name of an IMAP mailbox as an argument and creates it. getquotaroot Takes the name of an IMAP mailbox as an argument and prints the quotas that apply to the mailbox. Not all IMAP servers support this command. namespace Takes no arguments and prints the Personal Namespaces, the Other User's Namespaces, and the Shared Namespaces. Each namespace type is printed in parentheses; if there are multiple namespaces of the same type, inner parentheses separate them. For each namespace, a namespace prefix and a hierarchy separator is listed. Not all IMAP servers support this command. inc Same as newmail. junk (j) Takes a list of messages and marks all of them as junk mail. Data from these messages is then inserted into the junk mail database for future classification. kill (k) Takes a list of messages and 'kills' them. Killed messages are not printed in header summaries, and are ignored by the next command. The kill command also sets the score of the messages to negative infinity, so that subsequent score commands will not unkill them again. Killing is only effective for the current session on a folder; when it is quit, all messages are automatically unkilled. list Prints the names of all available commands. Mail (M) Similar to mail, but saves the message in a file named after the local part of the first recipient's address. mail (m) Takes as argument login names and distribution group names and sends mail to those people. mbox Indicate that a list of messages be sent to mbox in the user's home directory when mailx is quit. This is the default action for messages if unless the hold option is set. mailx deviates from the POSIX standard with this command, as a 'next' command issued after 'mbox' will display the following message, not the current one. move (mv) Acts like copy, but marks the messages for deletion if they were transferred successfully. Move (Mv) Similar to move, but moves the messages to a file named after the local part of the sender address of the first message. newmail Checks for new mail in the current folder without committing any changes before. If new mail is present, a message is printed. If the header variable is set, the headers of each new message are also printed. next (n) like + or CR) Goes to the next message in sequence and types it. With an argument list, types the next matching message. New Same as unread. new Same as unread. online Same as connect. noop If the current folder is located on an IMAP or POP3 server, a NOOP command is sent. Otherwise, no operation is performed. Pipe (Pi) Like pipe but also pipes ignored header fields and all parts of MIME multipart\/alternative messages. pipe (pi) Takes a message list and a shell command and pipes the messages through the command. Without an argument, the current message is piped through the command given by the cmd variable. If the page variable is set, every message is followed by a formfeed character. preserve (pre) A synonym for hold. Print (P) Like print but also prints out ignored header fields and all parts of MIME multipart\/alternative messages. See also print, ignore, and retain. print (p) Takes a message list and types out each message on the user's terminal. If the message is a MIME multipart message, all parts with a content type of 'text' or 'message' are shown, the other are hidden except for their headers. Messages are decrypted and converted to the terminal character set if necessary. probability (prob) For each word given as argument, the contents of its junk mail database entry are printed. quit (q) Terminates the session, saving all undeleted, unsaved messages in the user's mbox file in his login directory, preserving all messages marked with hold or preserve or never referenced in his system mailbox, and removing all other messages from his system mailbox. If new mail has arrived during the session, the message 'You have new mail' is given. If given while editing a mailbox file with the -f flag, then the edit file is rewritten. A return to the Shell is effected, unless the rewrite of edit file fails, in which case the user can escape with the exit command. redirect (red) Same as resend. Redirect (Red) Same as Resend. remove (rem) Removes the named folders. The user is asked for confirmation in interactive mode. rename (ren) Takes the name of an existing folder and the name for the new folder and renames the first to the second one. Both folders must be of the same type and must be located on the current server for IMAP. Reply (R) Reply to originator. Does not reply to other recipients of the original message. reply (r) Takes a message list and sends mail to the sender and all recipients of the specified message. The default message must not be deleted. replyall Similar to reply, but responds to all recipients regardless of the flipr and Replyall variables. replysender Similar to Reply, but responds to the sender only regardless of the flipr and Replyall variables. Resend Like resend, but does not add any header lines. This is not a way to hide the sender's identity, but useful for sending a message again to the same recipients. resend Takes a list of messages and a user name and sends each message to the named user. 'Resent-From:' and related header fields are prepended to the new copy of the message. Respond Same as Reply. respond Same as reply. respondall Same as replyall. respondsender Same as replysender. retain Add the list of header fields named to the retained list. Only the header fields in the retain list are shown on the terminal when a message is printed. All other header fields are suppressed. The Type and Print commands can be used to print a message in its entirety. If retain is executed with no arguments, it lists the current set of retained fields. Save (S) Similar to save, but saves the messages in a file named after the local part of the sender of the first message instead of taking a filename argument. save (s) Takes a message list and a filename and appends each message in turn to the end of the file. If no filename is given, the mbox file is used. The filename in quotes, followed by the line count and character count is echoed on the user's terminal. If editing a system mailbox, the messages are marked for deletion. Compressed files and IMAP mailboxes are handled as described for the -f command line option above. savediscard Same as saveignore. saveignore Saveignore is to save what ignore is to print and type. Header fields thus marked are filtered out when saving a message by save or when automatically saving to mbox. This command should only be applied to header fields that do not contain information needed to decode the message, as MIME content fields do. If saving messages on an IMAP account, ignoring fields makes it impossible to copy the data directly on the server, thus operation usually becomes much slower. saveretain Saveretain is to save what retain is to print and type. Header fields thus marked are the only ones saved with a message when saving by save or when automatically saving to mbox. Saveretain overrides saveignore. The use of this command is strongly discouraged since it may strip header fields that are needed to decode the message correctly. score (sc) Takes a message list and a floating point number and adds the number to the score of each given message. All messages start at score 0 when a folder is opened. When the score of a message becomes negative, it is 'killed' with the effects described for the kill command; otherwise if it was negative before and becomes positive, it is 'unkilled'. Scores only refer to the currently opened instance of a folder. set (se) With no arguments, prints all variable values, piped through the pager if the output does not fit on the screen. Otherwise, sets option. Arguments are of the form option=value (no space before or after =) or option. Quotation marks may be placed around any part of the assignment statement to quote blanks or tabs, i.e. 'set indentprefix=\"->\"'. If an argument begins with no, as in 'set nosave', the effect is the same as invoking the unset command with the remaining part of the variable ('unset save'). seen Takes a message list and marks all messages as having been read. shell (sh) Invokes an interactive version of the shell. shortcut Defines a shortcut name and its string for expansion, as described for the folder command. With no arguments, a list of defined shortcuts is printed. show (Sh) Like print, but performs neither MIME decoding nor decryption so that the raw message text is shown. size Takes a message list and prints out the size in characters of each message. sort Create a sorted representation of the current folder, and change the next command and the addressing modes such that they refer to messages in the sorted order. Message numbers are the same as in regular mode. If the header variable is set, a header summary in the new order is also printed. Possible sorting criteria are: date Sort the messages by their 'Date:' field, that is by the time they were sent. from Sort messages by the value of their 'From:' field, that is by the address of the sender. If the showname variable is set, the sender's real name (if any) is used. size Sort the messages by their size. score Sort the messages by their score. status Sort the messages by their message status (new, read, old, etc.). subject Sort the messages by their subject. thread Create a threaded order, as with the thread command. to Sort messages by the value of their 'To:' field, that is by the address of the recipient. If the showname variable is set, the recipient's real name (if any) is used. If no argument is given, the current sorting criterion is printed. source The source command reads commands from a file. thread (th) Create a threaded representation of the current folder, i.e. indent messages that are replies to other messages in the header display, and change the next command and the addressing modes such that they refer to messages in the threaded order. Message numbers are the same as in unthreaded mode. If the header variable is set, a header summary in threaded order is also printed. top Takes a message list and prints the top few lines of each. The number of lines printed is controlled by the variable toplines and defaults to five. touch Takes a message list and marks the messages for saving in the mbox file. mailx deviates from the POSIX standard with this command, as a 'next' command issued after 'mbox' will display the following message, not the current one. Type (T) Identical to the Print command. type (t) A synonym for print. unalias Takes a list of names defined by alias commands and discards the remembered groups of users. The group names no longer have any significance. unanswered Takes a message list and marks each message as not having been answered. uncollapse (unc) Only applicable to threaded mode. Takes a message list and makes the message and all replies to it visible in header summaries again. When a message becomes the current message, it is automatically made visible. Also when a message with collapsed replies is printed, all of these are automatically uncollapsed. undef Undefines each of the named macros. It is not an error to use a name that does not belong to one of the currently defined macros. undelete (u) Takes a message list and marks each message as not being deleted. undraft Takes a message list and marks each message as a draft. unflag Takes a message list and marks each message as not being 'flagged'. unfwdignore Removes the header field names from the list of ignored fields for the forward command. unfwdretain Removes the header field names from the list of retained fields for the forward command. ungood Takes a message list and undoes the effect of a good command that was previously applied on exactly these messages. unignore Removes the header field names from the list of ignored fields. unjunk Takes a message list and undoes the effect of a junk command that was previously applied on exactly these messages. unkill Takes a message list and 'unkills' each message. Also sets the score of the messages to 0. Unread Same as unread. unread (U) Takes a message list and marks each message as not having been read. unretain Removes the header field names from the list of retained fields. unsaveignore Removes the header field names from the list of ignored fields for saving. unsaveretain Removes the header field names from the list of retained fields for saving. unset Takes a list of option names and discards their remembered values; the inverse of set. unshortcut Deletes the shortcut names given as arguments. unsort Disable sorted or threaded mode (see the sort and thread commands), return to normal message order and, if the header variable is set, print a header summary. unthread (unth) Same as unsort. verify (verif) Takes a message list and verifies each message. If a message is not an S\/MIME signed message, verification will fail for it. The verification process checks if the message was signed using a valid certificate, if the message sender's email address matches one of those contained within the certificate, and if the message content has been altered. visual (v) Takes a message list and invokes the display editor on each message. Modified contents are discarded unless the writebackedited variable is set. write (w) For conventional messages, the body without all headers is written. The output is decrypted and converted to its native format, if necessary. If the output file exists, the text is appended.-If a message is in MIME multipart format, its first part is written to the specified file as for conventional messages, and the user is asked for a filename to save each other part; if the contents of the first part are not to be saved, 'write \/dev\/null' can be used. For the second and subsequent parts, if the filename given starts with a '|' character, the part is piped through the remainder of the filename interpreted as a shell command. In non-interactive mode, only the parts of the multipart message that have a filename given in the part header are written, the other are discarded. The original message is never marked for deletion in the originating mail folder. For attachments, the contents of the destination file are overwritten if the file previously existed. No special handling of compressed files is performed. xit (x) A synonym for exit. z Mailx presents message headers in windowfuls as described under the headers command. The z command scrolls to the next window of messages. If an argument is given, it specifies the window to use. A number prefixed by '+' or '-' indicates that the window is calculated in relation to the current position. A number without a prefix specifies an absolute window number, and a '$' lets mailx scroll to the last window of messages. Z Similar to z, but scrolls to the next or previous window that contains at least one new or 'flagged' message. Tilde escapes Here is a summary of the tilde escapes, which are used when composing messages to perform special functions. Tilde escapes are only recognized at the beginning of lines. The name ' tilde escape' is somewhat of a misnomer since the actual escape character can be set by the option escape. ~! command Execute the indicated shell command, then return to the message. ~. Same effect as typing the end-of-file character. ~< filename Identical to ~r. ~<! command Command is executed using the shell. Its standard output is inserted into the message. ~@ [ filename . . . ] With no arguments, edit the attachment list. First, the user can edit all existing attachment data. If an attachment's file name is left empty, that attachment is deleted from the list. When the end of the attachment list is reached, mailx will ask for further attachments, until an empty file name is given. If filename arguments are specified, all of them are appended to the end of the attachment list. Filenames which contain white space can only be specified with the first method (no filename arguments). ~A Inserts the string contained in the Sign variable (same as '~i Sign'). The escape sequences '\\t' (tabulator) and '\\n' (newline) are understood. ~a Inserts the string contained in the sign variable (same as '~i sign'). The escape sequences '\\t' (tabulator) and '\\n' (newline) are understood. ~b name . . . Add the given names to the list of carbon copy recipients but do not make the names visible in the Cc: line ('blind' carbon copy). ~c name . . . Add the given names to the list of carbon copy recipients. ~d Read the file 'dead.letter' from the user's home directory into the message. ~e Invoke the text editor on the message collected so far. After the editing session is finished, the user may continue appending text to the message. ~f messages Read the named messages into the message being sent. If no messages are specified, read in the current message. Message headers currently being ignored (by the ignore or retain command) are not included. For MIME multipart messages, only the first printable part is included. ~F messages Identical to ~f, except all message headers and all MIME parts are included. ~h Edit the message header fields 'To:', 'Cc:', 'Bcc:', and 'Subject:' by typing each one in turn and allowing the user to append text to the end or modify the field by using the current terminal erase and kill characters. ~H Edit the message header fields 'From:', 'Reply-To:', 'Sender:', and 'Organization:' in the same manner as described for ~h. The default values for these fields originate from the from, replyto, and ORGANIZATION variables. If this tilde command has been used, changing the variables has no effect on the current message anymore. ~i variable Insert the value of the specified variable into the message adding a newline character at the end. If the variable is unset or empty, the message remains unaltered. The escape sequences ' \\t' (tabulator) and ' \\n' (newline) are understood. ~m messages Read the named messages into the message being sent, indented by a tab or by the value of indentprefix. If no messages are specified, read the current message. Message headers currently being ignored (by the ignore or retain command) are not included. For MIME multipart messages, only the first printable part is included. ~M messages Identical to ~m, except all message headers and all MIME parts are included. ~p Print out the message collected so far, prefaced by the message header fields and followed by the attachment list, if any. If the message text is longer than the screen size, it is piped through the pager. ~q Abort the message being sent, copying the message to 'dead.letter' in the user's home directory if save is set. ~r filename Read the named file into the message. ~s string Cause the named string to become the current subject field. ~t name . . . Add the given names to the direct recipient list. ~v Invoke an alternate editor (defined by the VISUAL option) on the message collected so far. Usually, the alternate editor will be a screen editor. After the editor is quit, the user may resume appending text to the end of the message. ~w filename Write the message onto the named file. If the file exists, the message is appended to it. ~x Same as ~q, except that the message is not saved to the 'dead.letter' file. ~| command Pipe the message through the command as a filter. If the command gives no output or terminates abnormally, retain the original text of the message. The command fmt(1) is often used as command to rejustify the message. ~: mailx-command Execute the given mailx command. Not all commands, however, are allowed. ~_ mailx-command Identical to ~:. ~~ string Insert the string of text in the message prefaced by a single ~. If the escape character has been changed, that character must be doubled in order to send it at the beginning of a line. Variable options Options are controlled via set and unset commands, see their entries for a syntax description. An option is also set if it is passed to mailx as part of the environment (this is not restricted to specific variables as in the POSIX standard). A value given in a startup file overrides a value imported from the environment. Options may be either binary, in which case it is only significant to see whether they are set or not; or string, in which case the actual value is of interest. Binary options The binary options include the following: allnet Causes only the local part to be evaluated when comparing addresses. append Causes messages saved in mbox to be appended to the end rather than prepended. This should always be set. ask or asksub Causes mailx to prompt for the subject of each message sent. If the user responds with simply a newline, no subject field will be sent. askatend Causes the prompts for 'Cc:' and 'Bcc:' lists to appear after the message has been edited. askattach If set, mailx asks for files to attach at the end of each message. Responding with a newline indicates not to include an attachment. askcc Causes the user to be prompted for additional carbon copy recipients (at the end of each message if askatend or bsdcompat is set). Responding with a newline indicates the user's satisfaction with the current list. askbcc Causes the user to be prompted for additional blind carbon copy recipients (at the end of each message if askatend or bsdcompat is set). Responding with a newline indicates the user's satisfaction with the current list. asksign Causes the user to be prompted if the message is to be signed at the end of each message. The smime-sign variable is ignored when this variable is set. autocollapse Causes threads to be collapsed automatically when threaded mode is entered (see the collapse command). autoinc Same as newmail. autoprint Causes the delete command to behave like dp - thus, after deleting a message, the next one will be typed automatically. autothread Causes threaded mode (see the thread command) to be entered automatically when a folder is opened. bang Enables the substitution of '!' by the contents of the last command line in shell escapes. bsdannounce Causes automatic display of a header summary after executing a folder command. bsdcompat Sets some cosmetical features to traditional BSD style; has the same affect as setting 'askatend' and all other variables prefixed with 'bsd', setting prompt to '& ', and changing the default pager to more. bsdflags Changes the letters printed in the first column of a header summary to traditional BSD style. bsdheadline Changes the display of columns in a header summary to traditional BSD style. bsdmsgs Changes some informational messages to traditional BSD style. bsdorder Causes the 'Subject:' field to appear immediately after the 'To:' field in message headers and with the ~h tilde command. bsdset Changes the output format of the set command to traditional BSD style. chained-junk-tokens Normally, the Bayesian junk mail filter bases its classifications on single word tokens extracted from messages. If this option is set, adjacent words are combined to pairs, which are then used as additional tokens. This usually improves the accuracy of the filter, but also increases the junk mail database five- to tenfold. datefield The date in a header summary is normally the date of the mailbox 'From ' line of the message. If this variable is set, the date as given in the 'Date:' header field is used, converted to local time. debug Prints debugging messages and disables the actual delivery of messages. Unlike verbose, this option is intended for mailx development only. disconnected When an IMAP mailbox is selected and this variable is set, no connection to the server is initiated. Instead, data is obtained from the local cache (see imap-cache). Mailboxes that are not present in the cache and messages that have not yet entirely been fetched from the server are not available; to fetch all messages in a mailbox at once, the command 'copy * \/dev\/null' can be used while still in online mode. Changes that are made to IMAP mailboxes in disconnected mode are queued and committed later when a connection to that server is opened in online mode. This procedure is not completely reliable since it cannot be guaranteed that the IMAP unique identifiers (UIDs) on the server still match the ones in the cache at that time. Data is saved to 'dead.letter' when this problem occurs. disconnected- user @ host The specified account is handled as described for the disconnected variable above, but other accounts are not affected. dot The binary option dot causes mailx to interpret a period alone on a line as the terminator of a message the user is sending. editheaders When a message is edited while being composed, its header is included in the editable text. 'To:', 'Cc:', 'Bcc:', 'Subject:', 'From:', 'Reply-To:', 'Sender:', and 'Organization:' fields are accepted within the header, other fields are ignored. emptybox If set, an empty mailbox file is not removed. This may improve the interoperability with other mail user agents when using a common folder directory. emptystart If the mailbox is empty, mailx normally prints 'No mail for user' and exits immediately. If this option is set, mailx starts even with an empty mailbox. flipr Exchanges the Respond with the respond commands and vice-versa. forward-as-attachment Original messages are normally sent as inline text with the forward command, and only the first part of a multipart message is included. With this option, messages are sent as MIME message\/rfc822 attachments, and all of their parts are included. The fwdignore and fwdretain options are ignored when the forward-as-attachment option is set. fullnames When replying to a message, mailx normally removes the comment parts of email addresses, which by convention contain the full names of the recipients. If this variable is set, such stripping is not performed, and comments are retained. header Causes the header summary to be written at startup and after commands that affect the number of messages or the order of messages in the current folder; enabled by default. hold This option is used to hold messages in the system mailbox by default. ignore Causes interrupt signals from the terminal to be ignored and echoed as @'s. ignoreeof An option related to dot is ignoreeof which makes mailx refuse to accept a control-d as the end of a message. Ignoreeof also applies to mailx command mode. imap-use-starttls Causes mailx to issue a STARTTLS command to make an unencrypted IMAP session SSL\/TLS encrypted. This functionality is not supported by all servers, and is not used if the session is already encrypted by the IMAPS method. imap-use-starttls- user @ host Activates imap-use-starttls for a specific account. keep This option causes mailx to truncate the user's system mailbox instead of deleting it when it is empty. This should always be set, since it prevents malicious users from creating fake mail folders in a world-writable spool directory. keepsave When a message is saved, it is usually discarded from the originating folder when mailx is quit. Setting this option causes all saved message to be retained. markanswered When a message is replied to and this variable is set, it is marked as having been answered. This mark has no technical meaning in the mail system; it just causes messages to be marked in the header summary, and makes them specially addressable. metoo Usually, when a group is expanded that contains the sender, the sender is removed from the expansion. Setting this option causes the sender to be included in the group. newmail Checks for new mail in the current folder each time the prompt is printed. For IMAP mailboxes, the server is then polled for new mail, which may result in delayed operation if the connection to the server is slow. A maildir folder must be re-scanned to determine if new mail has arrived. If this variable is set to the special value nopoll, an IMAP server is not actively asked for new mail, but new mail may still be detected and announced with any other IMAP command that is sent to the server. A maildir folder is not scanned then. In any case, the IMAP server may send notifications about messages that have been deleted on the server by another process or client. In this case, 'Expunged n messages' is printed regardless of this variable, and message numbers may have changed. noheader Setting the option noheader is the same as giving the -N flag on the command line. outfolder Causes the filename given in the record variable and the sender-based filenames for the Copy and Save commands to be interpreted relative to the directory given in the folder variable rather than to the current directory unless it is an absolute pathname. page If set, each message the pipe command prints out is followed by a formfeed character. piperaw Send messages to the pipe command without performing MIME and character set conversions. pop3-use-apop If this variable is set, the APOP authentication method is used when a connection to a POP3 server is initiated. The advantage of this method over the usual USER\/PASS authentication is that the password is not sent over the network in clear text. The connection fails if the server does not support the APOP command. pop3-use-apop- user @ host Enables pop3-use-apop for a specific account. pop3-use-starttls Causes mailx to issue a STLS command to make an unencrypted POP3 session SSL\/TLS encrypted. This functionality is not supported by all servers, and is not used if the session is already encrypted by the POP3S method. pop3-use-starttls- user @ host Activates pop3-use-starttls for a specific account. print-all-chars This option causes all characters to be considered printable. It is only effective if given in a startup file. With this option set, some character sequences in messages may put the user's terminal in an undefined state when printed; it should only be used as a last resort if no working system locale can be found. print-alternatives When a MIME message part of type multipart\/alternative is displayed and it contains a subpart of type text\/plain, other parts are normally discarded. Setting this variable causes all subparts to be displayed, just as if the surrounding part was of type multipart\/mixed. quiet Suppresses the printing of the version when first invoked. record-resent If both this variable and the record variable are set, the resend and Resend commands save messages to the record folder as it is normally only done for newly composed messages. reply-in-same-charset If this variable is set, mailx first tries to use the same character set of the original message for replies. If this fails, the sendcharsets variable is evaluated as usual. Replyall Reverses the sense of reply and Reply commands. save When the user aborts a message with two RUBOUT (interrupt characters) mailx copies the partial letter to the file 'dead.letter' in the home directory. This option is set by default. searchheaders If this option is set, then a message-list specifier in the form ' \/x:y' will expand to all messages containing the substring ' y' in the header field ' x'. The string search is case insensitive. sendwait When sending a message, wait until the mail transfer agent exits before accepting further commands. If the mail transfer agent returns a non-zero exit status, the exit status of mailx will also be non-zero. showlast Setting this option causes mailx to start at the last message instead of the first one when opening a mail folder. showname Causes mailx to use the sender's real name instead of the plain address in the header field summary and in message specifications. showto Causes the recipient of the message to be shown in the header summary if the message was sent by the user. skipemptybody If an outgoing message does not contain any text in its first or only message part, do not send it but discard it silently (see also the -E option). smime-force-encryption Causes mailx to refuse sending unencrypted messages. smime-sign If this variable is set, outgoing messages are S\/MIME signed with the user's private key. Signing a message enables a recipient to verify that the sender used a valid certificate, that the email addresses in the certificate match those in the message header, and that the message content has not been altered. It does not change the message text, and people will be able to read the message as usual. smime-no-default-ca Do not load the default CA locations when verifying S\/MIME signed messages. Only applicable if S\/MIME support is built using OpenSSL. smtp-use-starttls Causes mailx to issue a STARTTLS command to make an SMTP session SSL\/TLS encrypted. Not all servers support this command; because of common implementation defects, it cannot be automatically determined whether a server supports it or not. ssl-no-default-ca Do not load the default CA locations to verify SSL\/TLS server certificates. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-v2-allow Accept SSLv2 connections. These are normally not allowed because this protocol version is insecure. stealthmua Inhibits the generation of the 'Message-Id:' and 'User-Agent:' header fields that include obvious references to mailx. There are two pitfalls associated with this: First, the message id of outgoing messages is not known anymore. Second, an expert may still use the remaining information in the header to track down the originating mail user agent. verbose Setting the option verbose is the same as using the -v flag on the command line. When mailx runs in verbose mode, details of the actual message delivery and protocol conversations for IMAP, POP3, and SMTP, as well as of other internal processes, are displayed on the user's terminal, This is sometimes useful to debug problems. Mailx prints all data that is sent to remote servers in clear texts, including passwords, so care should be taken that no unauthorized option can view the screen if this option is enabled. writebackedited If this variable is set, messages modified using the edit or visual commands are written back to the current folder when it is quit. This is only possible for writable folders in mbox format. Setting this variable also disables MIME decoding and decryption for the editing commands. String Options The string options include the following: attrlist A sequence of characters to print in the 'attribute' column of a header summary, each for one type of messages in the following order: new, unread but old, new but read, read and old, saved, preserved, mboxed, flagged, answered, draft, killed, start of a collapsed thread, collapsed, classified as junk. The default is 'NUROSPMFATK+-J', or 'NU *HMFATK+-J' if bsdflags or the SYSV3 environment variable are set. autobcc Specifies a list of recipients to which a blind carbon copy of each outgoing message will be sent automatically. autocc Specifies a list of recipients to which a carbon copy of each outgoing message will be sent automatically. autosort Causes sorted mode (see the sort command) to be entered automatically with the value of this option as sorting method when a folder is opened. cmd The default value for the pipe command. crt The valued option crt is used as a threshold to determine how long a message must be before PAGER is used to read it. If crt is set without a value, then the height of the terminal screen stored in the system is used to compute the threshold (see stty(1)). DEAD The name of the file to use for saving aborted messages. This defaults to 'dead.letter' in the user's home directory. EDITOR Pathname of the text editor to use in the edit command and ~e escape. If not defined, then a default editor is used. encoding The default MIME encoding to use in outgoing text messages and message parts. Valid values are 8bit or quoted-printable. The default is 8bit. In case the mail transfer system is not ESMTP compliant, quoted-printable should be used instead. If there is no need to encode a message, 7bit transfer mode is used, without regard to the value of this variable. Binary data is always encoded in base64 mode. escape If defined, the first character of this option gives the character to use in the place of ~ to denote escapes. folder The name of the directory to use for storing folders of messages. All folder names that begin with '+' refer to files below that directory. If the directory name begins with a '\/', mailx considers it to be an absolute pathname; otherwise, the folder directory is found relative to the user's home directory. The directory name may also refer to an IMAP account; any names that begin with '+' then refer to IMAP mailboxes on that account. An IMAP folder is normally given in the form imaps:\/\/mylogin@imap.myisp.example In this case, the '+' and '@' prefixes for folder names have the same effect (see the folder command). Some IMAP servers do not accept the creation of mailboxes in the hierarchy base; they require that they are created as subfolders of 'INBOX'. With such servers, a folder name of the form imaps:\/\/mylogin@imap.myisp.example\/INBOX. should be used (the last character is the server's hierarchy delimiter). Folder names prefixed by '+' will then refer to folders below 'INBOX', while folder names prefixed by '@' refer to folders below the hierarchy base. See the imap namespace command for a method to detect the appropriate prefix and delimiter. folder-hook When a folder is opened and this variable is set, the macro corresponding to the value of this variable is executed. The macro is also invoked when new mail arrives, but message lists for commands executed from the macro only include newly arrived messages then. folder-hook- fullname When a folder named fullname is opened, the macro corresponding to the value of this variable is executed. Unlike other folder specifications, the fully expanded name of a folder, without metacharacters, is used to avoid ambiguities. The macro specified with folder-hook is not executed if this variable is effective for a folder (unless it is explicitly invoked within the called macro). from The address (or a list of addresses) to put into the 'From:' field of the message header. If replying to a message, these addresses are handled as if they were in the alternates list. If the machine's hostname is not valid at the Internet (for example at a dialup machine), either this variable or hostname have to be set to get correct Message-ID header fields. If from contains more than one address, the sender variable must also be set. fwdheading The string to print before the text of a message with the forward command (unless the forward-as-attachment variable is set). Defaults to ''-------- Original Message --------'' if unset. If it is set to the empty string, no heading is printed. headline A format string to use for the header summary, similar to printf formats. A '%' character introduces a format specifier. It may be followed by a number indicating the field width. If the field is a number, the width may be negative, which indicates that it is to be left-aligned. Valid format specifiers are: The default is '%>%a%m %18f %16d %4l\/%-5o %i%s', or '%>%a%m %20f %16d %3l\/%-5o %i%S' if bsdcompat is set. hostname Use this string as hostname when expanding local addresses instead of the value obtained from uname(2) and getaddrinfo(3). imap-auth Sets the IMAP authentication method. Valid values are 'login' for the usual password-based authentication (the default), 'cram-md5', which is a password-based authentication that does not send the password over the network in clear text, and 'gssapi' for GSSAPI-based authentication. imap-auth- user @ host Sets the IMAP authentication method for a specific account. imap-cache Enables caching of IMAP mailboxes. The value of this variable must point to a directory that is either existent or can be created by mailx. All contents of the cache can be deleted by mailx at any time; it is not safe to make assumptions about them. imap-keepalive IMAP servers may close the connection after a period of inactivity; the standard requires this to be at least 30 minutes, but practical experience may vary. Setting this variable to a numeric value greater than 0 causes a NOOP command to be sent each value seconds if no other operation is performed. imap-list-depth When retrieving the list of folders on an IMAP server, the folders command stops after it has reached a certain depth to avoid possible infinite loops. The value of this variable sets the maximum depth allowed. The default is 2. If the folder separator on the current IMAP server is a slash '\/', this variable has no effect, and the folders command does not descend to subfolders. indentprefix String used by the ' ~m' and ' ~M' tilde escapes and by the quote option for indenting messages, in place of the normal tab character (^I). Be sure to quote the value if it contains spaces or tabs. junkdb The location of the junk mail database. The string is treated like a folder name, as described for the folder command. The files in the junk mail database are normally stored in compress(1) format for saving space. If processing time is considered more important, uncompress(1) can be used to store them in plain form. Mailx will then work using the uncompressed files. LISTER Pathname of the directory lister to use in the folders command when operating on local mailboxes. Default is \/bin\/ls. MAIL Is used as the user's mailbox, if set. Otherwise, a system-dependent default is used. Can be a protocol:\/\/ string (see the folder command for more information). MAILX_HEAD A string to put at the beginning of each new message. The escape sequences ' \\t' (tabulator) and ' \\n' (newline) are understood. MAILX_TAIL A string to put at the end of each new message. The escape sequences ' \\t' (tabulator) and ' \\n' (newline) are understood. maximum-unencoded-line-length Messages that contain lines longer than the value of this variable are encoded in quoted-printable even if they contain only ASCII characters. The maximum effective value is 950. If set to 0, all ASCII text messages are encoded in quoted-printable. S\/MIME signed messages are always encoded in quoted-printable regardless of the value of this variable. MBOX The name of the mbox file. It can be the name of a folder. The default is 'mbox' in the user's home directory. NAIL_EXTRA_RC The name of an optional startup file to be read after ~\/.mailrc. This variable is ignored if it is imported from the environment; it has an effect only if it is set in \/etc\/mail.rc or ~\/.mailrc to allow bypassing the configuration with e. g. 'MAILRC=\/dev\/null'. Use this file for commands that are not understood by other mailx implementations. newfolders If this variable has the value maildir, newly created local folders will be in maildir format. nss-config-dir A directory that contains the files cert N.db to retrieve certificates, key N.db to retrieve private keys, and secmod.db, where N is a digit. These are usually taken from Mozilla installations, so an appropriate value might be '~\/.mozilla\/firefox\/default.clm'. Mailx opens these files read-only and does not modify them. However, if the files are modified by Mozilla while mailx is running, it will print a 'Bad database' message. It may be necessary to create copies of these files that are exclusively used by mailx then. Only applicable if S\/MIME and SSL\/TLS support is built using Network Security Services (NSS). ORGANIZATION The value to put into the 'Organization:' field of the message header. PAGER Pathname of the program to use in the more command or when crt variable is set. The default paginator pg(1) or, in BSD compatibility mode, more(1) is used if this option is not defined. password- user @ host Set the password for user when connecting to host. If no such variable is defined for a host, the user will be asked for a password on standard input. Specifying passwords in a startup file is generally a security risk, the file should be readable by the invoking user only. pipe- content\/subcontent When a MIME message part of content\/subcontent type is displayed or it is replied to, its text is filtered through the value of this variable interpreted as a shell command. Special care must be taken when using such commands as mail viruses may be distributed by this method; if messages of type application\/x-sh were filtered through the shell, for example, a message sender could easily execute arbitrary code on the system mailx is running on. pop3-keepalive POP3 servers may close the connection after a period of inactivity; the standard requires this to be at least 10 minutes, but practical experience may vary. Setting this variable to a numeric value greater than 0 causes a NOOP command to be sent each value seconds if no other operation is performed. prompt The string printed when a command is accepted. Defaults to '? ', or to '& ' if the bsdcompat variable is set. quote If set, mailx starts a replying message with the original message prefixed by the value of the variable indentprefix. Normally, a heading consisting of 'Fromheaderfield wrote:' is printed before the quotation. If the string noheading is assigned to the quote variable, this heading is omitted. If the string headers is assigned, the headers selected by the ignore\/retain commands are printed above the message body, thus quote acts like an automatic ~m command then. If the string allheaders is assigned, all headers are printed above the message body, and all MIME parts are included, thus quote acts like an automatic ~M command then. record If defined, gives the pathname of the folder used to record all outgoing mail. If not defined, then outgoing mail is not so saved. When saving to this folder fails, the message is not sent but saved to the 'dead.letter' file instead. replyto A list of addresses to put into the 'Reply-To:' field of the message header. If replying to a message, such addresses are handled as if they were in the alternates list. screen When mailx initially prints the message headers, it determines the number to print by looking at the speed of the terminal. The faster the terminal, the more it prints. This option overrides this calculation and specifies how many message headers are printed. This number is also used for scrolling with the z command. sendcharsets A comma-separated list of character set names that can be used in Internet mail. When a message that contains characters not representable in US-ASCII is prepared for sending, mailx tries to convert its text to each of the given character sets in order and uses the first appropriate one. The default is 'utf-8'. Character sets assigned to this variable should be ordered in ascending complexity. That is, the list should start with e.g. 'iso-8859-1' for compatibility with older mail clients, might contain some other language-specific character sets, and should end with 'utf-8' to handle messages that combine texts in multiple languages. sender An address that is put into the 'Sender:' field of outgoing messages. This field needs not normally be present. It is, however, required if the 'From:' field contains more than one address. It can also be used to indicate that a message was sent on behalf of somebody other; in this case, 'From:' should contain the address of the person that took responsibility for the message, and 'Sender:' should contain the address of the person that actually sent the message. The sender address is handled as if it were in the alternates list. sendmail To use an alternate mail delivery system, set this option to the full pathname of the program to use. This should be used with care. SHELL Pathname of the shell to use in the ! command and the ~! escape. A default shell is used if this option is not defined. Sign A string for use with the ~A command. sign A string for use with the ~a command. signature Must correspond to the name of a readable file if set. The file's content is then appended to each singlepart message and to the first part of each multipart message. Be warned that there is no possibility to edit the signature for an individual message. smime-ca-dir Specifies a directory with CA certificates for verification of S\/MIME signed messages. The format is the same as described in ssl_ctx_load_verify_locations(3). Only applicable if S\/MIME support is built using OpenSSL. smime-ca-file Specifies a file with CA certificates for verification of S\/MIME signed messages. The format is the same as described in ssl_ctx_load_verify_locations(3). Only applicable if S\/MIME support is built using OpenSSL. smime-cipher- user@host Specifies a cipher to use when generating S\/MIME encrypted messages for user@host. Valid ciphers are rc2-40 (RC2 with 40 bits), rc2-64 (RC2 with 64 bits), des (DES, 56 bits) and des-ede3 (3DES, 112\/168 bits). The default is 3DES. It is not recommended to use the other ciphers unless a recipient's client is actually unable to handle 3DES since they are comparatively weak; but even so, the recipient should upgrade his software in preference. smime-crl-file Specifies a file that contains a CRL in PEM format to use when verifying S\/MIME messages. Only applicable if S\/MIME support is built using OpenSSL. smime-crl-dir Specifies a directory that contains files with CRLs in PEM format to use when verifying S\/MIME messages. Only applicable if S\/MIME support is built using OpenSSL. smime-encrypt- user@host If this variable is set, messages to user@host are encrypted before sending. If S\/MIME support is built using OpenSSL, the value of the variable must be set to the name of a file that contains a certificate in PEM format. If S\/MIME support is built using NSS, the value of this variable is ignored, but if multiple certificates for user@host are available, the smime-nickname-user@host variable should be set. Otherwise a certificate for the recipient is automatically retrieved from the certificate database, if possible. If a message is sent to multiple recipients, each of them for whom a corresponding variable is set will receive an individually encrypted message; other recipients will continue to receive the message in plain text unless the smime-force-encryption variable is set. It is recommended to sign encrypted messages, i.e. to also set the smime-sign variable. smime-nickname- user@host Specifies the nickname of a certificate to be used when encrypting messages for user@host . Only applicable if S\/MIME support is built using NSS. smime-sign-cert Points to a file in PEM format that contains the user's private key as well as his certificate. Both are used with S\/MIME for signing and decrypting messages. Only applicable if S\/MIME support is built using OpenSSL. smime-sign-cert- user@host Overrides smime-sign-cert for the specific addresses. When signing messages and the value of the from variable is set to user@host, the specific file is used. When decrypting messages, their recipient fields (To: and Cc:) are searched for addresses for which such a variable is set. Mailx always uses the first address that matches, so if the same message is sent to more than one of the user's addresses using different encryption keys, decryption might fail. Only applicable if S\/MIME support is built using OpenSSL. smime-sign-nickname Specifies that the named certificate be used for signing mail. If this variable is not set, but a single certificate matching the current from address is found in the database, that one is used automatically. Only applicable if S\/MIME support is built using NSS. smime-sign-nickname- user@host Overrides smime-sign-nickname for a specific address. Only applicable if S\/MIME support is built using NSS. smtp Normally, mailx invokes sendmail(8) directly to transfer messages. If the smtp variable is set, a SMTP connection to the server specified by the value of this variable is used instead. If the SMTP server does not use the standard port, a value of server:port can be given, with port as a name or as a number. There are two possible methods to get SSL\/TLS encrypted SMTP sessions: First, the STARTTLS command can be used to encrypt a session after it has been initiated, but before any user-related data has been sent; see smtp-use-starttls above. Second, some servers accept sessions that are encrypted from their beginning on. This mode is configured by assigning smtps:\/\/ server[ : port] to the smtp variable. The SMTP transfer is executed in a child process; unless either the sendwait or the verbose variable is set, this process runs asynchronously. If it receives a TERM signal, it will abort and save the message to the 'dead.letter' file. smtp-auth Sets the SMTP authentication method. If set to 'login', or if unset and smtp-auth-user is set, AUTH LOGIN is used. If set to 'cram-md5', AUTH CRAM-MD5 is used; if set to 'plain', AUTH PLAIN is used. Otherwise, no SMTP authentication is performed. smtp-auth- user @ host Overrides smtp-auth for specific values of sender addresses, depending on the from variable. smtp-auth-password Sets the global password for SMTP AUTH. Both user and password have to be given for AUTH LOGIN and AUTH CRAM-MD5. smtp-auth-password- user @ host Overrides smtp-auth-password for specific values of sender addresses, depending on the from variable. smtp-auth-user Sets the global user name for SMTP AUTH. Both user and password have to be given for AUTH LOGIN and AUTH CRAM-MD5. If this variable is set but neither smtp-auth-password or a matching smtp-auth-password-user@host can be found, mailx will as for a password on the user's terminal. smtp-auth-user- user @ host Overrides smtp-auth-user for specific values of sender addresses, depending on the from variable. ssl-ca-dir Specifies a directory with CA certificates for verification of SSL\/TLS server certificates. See ssl_ctx_load_verify_locations(3) for more information. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-ca-file Specifies a file with CA certificates for verification of SSL\/TLS server certificates. See ssl_ctx_load_verify_locations(3) for more information. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-cert Sets the file name for a SSL\/TLS client certificate required by some servers. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-cert- user @ host Sets an account-specific file name for a SSL\/TLS client certificate required by some servers. Overrides ssl-cert for the specified account. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-cipher-list Specifies a list of ciphers for SSL\/TLS connections. See ciphers(1) for more information. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-crl-file Specifies a file that contains a CRL in PEM format to use when verifying SSL\/TLS server certificates. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-crl-dir Specifies a directory that contains files with CRLs in PEM format to use when verifying SSL\/TLS server certificates. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-key Sets the file name for the private key of a SSL\/TLS client certificate. If unset, the name of the certificate file is used. The file is expected to be in PEM format. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-key- user @ host Sets an account-specific file name for the private key of a SSL\/TLS client certificate. Overrides ssl-key for the specified account. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-method Selects a SSL\/TLS protocol version; valid values are 'ssl2', 'ssl3', and 'tls1'. If unset, the method is selected automatically, if possible. ssl-method- user @ host Overrides ssl-method for a specific account. ssl-rand-egd Gives the pathname to an entropy daemon socket, see rand_egd(3). ssl-rand-file Gives the pathname to a file with entropy data, see rand_load_file(3). If the file is a regular file writable by the invoking user, new data is written to it after it has been loaded. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-verify Sets the action to be performed if an error occurs during SSL\/TLS server certificate validation. Valid values are 'strict' (fail and close connection immediately), 'ask' (ask whether to continue on standard input), 'warn' (print a warning and continue), 'ignore' (do not perform validation). The default is 'ask'. ssl-verify- user @ host Overrides ssl-verify for a specific account. toplines If defined, gives the number of lines of a message to be printed out with the top command; normally, the first five lines are printed. ttycharset The character set of the terminal mailx operates on. There is normally no need to set this variable since mailx can determine this automatically by looking at the LC_CTYPE locale setting; if this succeeds, the value is assigned at startup and will be displayed by the set command. Note that this is not necessarily a character set name that can be used in Internet messages. VISUAL Pathname of the text editor to use in the visual command and ~v escape.","Process Name":"mail","Link":"https:\/\/linux.die.net\/man\/1\/mail"}},{"Process":{"Description":null,"Process Name":"mail-lock","Link":"https:\/\/linux.die.net\/man\/1\/mail-lock"}},{"Process":{"Description":"Lockfile-progs provides a set a programs that can be used to lock and unlock mailboxes and files safely (via liblockfile): mail-lock - lock the current user's mailbox\nmail-unlock - unlock the current user's mailbox\nmail-touchlock - touch the lock on the current user's mailbox\nlockfile-create - lock a given file\nlockfile-remove - remove the lock on a given file\nlockfile-touch - touch the lock on a given file\nlockfile-check - check the lock on a given file By default, the filename argument refers to the name of the file to be locked, and the name of the lockfile will be filename .lock. However, if the --lock-name argument is specified, then filename will be taken as the name of the lockfile itself. Each of the mail locking commands attempts to lock \/var\/spool\/mail\/<user>, where <user> is the name associated with the effective user ID, as determined by via geteuid(2). Once a file is locked, the lock must be touched at least once every five minutes or the lock will be considered stale, and subsequent lock attempts will succeed. Also see the --use-pid option and the lockfile_create(3) manpage. The lockfile-check command tests whether or not a valid lock already exists.","Process Name":"mail-touchlock","Link":"https:\/\/linux.die.net\/man\/1\/mail-touchlock"}},{"Process":{"Description":null,"Process Name":"mail-unlock","Link":"https:\/\/linux.die.net\/man\/1\/mail-unlock"}},{"Process":{"Description":"Mailfeeder is a tool designed to inject a mailpack back into a MTA (mail server, ie, Sendmail, Postfix) using socket calls. Currently it is used in a variety of projects such as Inflex and Xamime to perform post-filtered queue injection or delivery.","Process Name":"mailfeeder","Link":"https:\/\/linux.die.net\/man\/1\/mailfeeder"}},{"Process":{"Description":"mailmail reads RFC822 message text from standard input and delivers them, using SMTP, to a Mail Transfer Agent listening at 127.0.0.1:25. It accepts (but does not necessarily implement) many of the standard sendmail(1) options, but it is preferable to list only the recipient addresses on the command line, and include a From header within the message text indicating the sender.","Process Name":"mailmail","Link":"https:\/\/linux.die.net\/man\/1\/mailmail"}},{"Process":{"Description":null,"Process Name":"mailq.postfix","Link":"https:\/\/linux.die.net\/man\/1\/mailq.postfix"}},{"Process":{"Description":"Mailq prints a summary of the mail messages queued for future delivery. The first line printed for each message shows the internal identifier used on this host for the message with a possible status character, the size of the message in bytes, the date and time the message was accepted into the queue, and the envelope sender of the message. The second line shows the error message that caused this message to be retained in the queue; it will not be present if the message is being processed for the first time. The status characters are either * to indicate the job is being processed; X to indicate that the load is too high to process the job; and - to indicate that the job is too young to process. The following lines show message recipients, one per line. Mailq is identical to ''sendmail -bp''. The relevant options are as follows: -Ac Show the mail submission queue specified in \/etc\/mail\/submit.cf instead of the MTA queue specified in \/etc\/mail\/sendmail.cf. -qL Show the \"lost\" items in the mail queue instead of the normal queue items. -qQ Show the quarantined items in the mail queue instead of the normal queue items. -q[ !]I substr Limit processed jobs to those containing substr as a substring of the queue id or not when ! is specified. -q[ !]Q substr Limit processed jobs to quarantined jobs containing substr as a substring of the quarantine reason or not when ! is specified. -q[ !]R substr Limit processed jobs to those containing substr as a substring of one of the recipients or not when ! is specified. -q[ !]S substr Limit processed jobs to those containing substr as a substring of the sender or not when ! is specified. -v Print verbose information. This adds the priority of the message and a single character indicator (''+'' or blank) indicating whether a warning message has been sent on the first line of the message. Additionally, extra lines may be intermixed with the recipients indicating the ''controlling user'' information; this shows who will own any programs that are executed on behalf of this message and the name of the alias this command expanded from, if any. Moreover, status messages for each recipient are printed if available. Several sendmail.cf options influence the behavior of the mailq utility: The number of items printed per queue group is restricted by MaxQueueRunSize if that value is set. The status character * is not printed for some values of QueueSortOrder, e.g., filename, random, modification, and none, unless a -q option is used to limit the processed jobs. The mailq utility exits 0 on success, and >0 if an error occurs.","Process Name":"mailq.sendmail","Link":"https:\/\/linux.die.net\/man\/1\/mailq.sendmail"}},{"Process":{"Description":null,"Process Name":"mailq.ssmtp","Link":"https:\/\/linux.die.net\/man\/1\/mailq.ssmtp"}},{"Process":{"Description":"mailstat parses a procmail-generated $LOGFILE and displays a summary about the messages delivered to all folders (total size, average size, nr of messages). The $LOGFILE is truncated to zero length, unless the -k option is used. Exit code 0 if mail arrived, 1 if no mail arrived.","Process Name":"mailstat","Link":"https:\/\/linux.die.net\/man\/1\/mailstat"}},{"Process":{"Description":"mailstat.pl example program using Log::Procmail to mimic mailstat(1) mailstat parses a procmail-generated $LOGFILE and displays a summary about the messages delivered to all folders (total size, average size, nr of messages). The $LOGFILE is truncated to zero length, unless the -k option is used. Exit code 0 if mail arrived, 1 if no mail arrived.","Process Name":"mailstat.pl","Link":"https:\/\/linux.die.net\/man\/1\/mailstat.pl"}},{"Process":{"Description":null,"Process Name":"mailutil","Link":"https:\/\/linux.die.net\/man\/1\/mailutil"}},{"Process":{"Description":"Mailx is an intelligent mail processing system, which has a command syntax reminiscent of ed(1) with lines replaced by messages. It is based on Berkeley Mail 8.1, is intended to provide the functionality of the POSIX mailx command, and offers extensions for MIME, IMAP, POP3, SMTP, and S\/MIME. Mailx provides enhanced features for interactive use, such as caching and disconnected operation for IMAP, message threading, scoring, and filtering. It is also usable as a mail batch language, both for sending and receiving mail. The following options are accepted: -A name Executes an account command (see below) for name after the startup files have been read. -a file Attach the given file to the message. -B Make standard input and standard output line-buffered. -b address Send blind carbon copies to list. List should be a comma-separated list of names. -c address Send carbon copies to list of users. -D Start in disconnected mode; see the description for the disconnected variable option. -d Enables debugging messages and disables the actual delivery of messages. Unlike -v, this option is intended for mailx development only. -e Just check if mail is present in the system mailbox. If yes, return an exit status of zero, else, a non-zero value. -E If an outgoing message does not contain any text in its first or only message part, do not send it but discard it silently, effectively setting the skipemptybody variable at program startup. This is useful for sending messages from scripts started by cron(8). -f [ file] Read in the contents of the user's mbox (or the specified file) for processing; when mailx is quit, it writes undeleted messages back to this file. The string file is handled as described for the folder command below. -F Save the message to send in a file named after the local part of the first recipient's address. -H Print header summaries for all messages and exit. -h hops Invoke sendmail with the specified hop count. This option has no effect when SMTP is used for sending mail. -i Ignore tty interrupt signals. This is particularly useful when using mailx on noisy phone lines. -I Shows the 'Newsgroup:' or 'Article-Id:' fields in the header summary. Only applicable in combination with -f. -n Inhibits reading \/etc\/mail.rc upon startup. This option should be activated for mailx scripts that are invoked on more than one machine, because the contents of that file may differ between them. -N Inhibits the initial display of message headers when reading mail or editing a mail folder. -q file Start the message with the contents of the specified file. May be given in send mode only. -r address Sets the From address. Overrides any from variable specified in environment or startup files. Tilde escapes are disabled. The -r address options are passed to the mail transfer agent unless SMTP is used. This option exists for compatibility only; it is recommended to set the from variable directly instead. -R Opens any folders read-only. -s subject Specify subject on command line (only the first argument after the -s flag is used as a subject; be careful to quote subjects containing spaces). -S variable[ = value] Sets the internal option variable and, in case of a string option, assigns value to it. -T name Writes the 'Message-Id:' and 'Article-Id:' header fields of each message read in the file name. Implies -I. Compressed files are handled as described for the folder command below. -t The message to be sent is expected to contain a message header with 'To:', 'Cc:', or 'Bcc:' fields giving its recipients. Recipients specified on the command line are ignored. -u user Reads the mailbox of the given user name. -v Verbose mode. The details of delivery are displayed on the user's terminal. -V Print mailx's version and exit. -~ Enable tilde escapes even if not in interactive mode. Sending mail To send a message to one or more people, mailx can be invoked with arguments which are the names of people to whom the mail will be sent. The user is then expected to type in his message, followed by an 'control-D' at the beginning of a line. The section below Replying to or originating mail, describes some features of mailx available to help when composing letters. Reading mail In normal usage mailx is given no arguments and checks the user's mail out of the post office, then prints out a one line header of each message found. The current message is initially the first message (numbered 1) and can be printed using the print command which can be abbreviated 'p'). The user can move among the messages much as he moves between lines in ed(1), with the commands '+' and '-' moving backwards and forwards, and simple numbers. Disposing of mail After examining a message the user can delete 'd') the message or reply 'r') to it. Deletion causes the mailx program to forget about the message. This is not irreversible; the message can be undeleted 'u') by giving its number, or the mailx session can be aborted by giving the exit 'x') command. Deleted messages will, however, usually disappear never to be seen again. Specifying messages Commands such as print and delete can be given a list of message numbers as arguments to apply to a number of messages at once. Thus ' delete 1 2' deletes messages 1 and 2, while ' delete 1-5' deletes messages 1 through 5. In sorted or threaded mode (see the sort and thread commands), ' delete 1-5' deletes the messages that are located between (and including) messages 1 through 5 in the sorted\/threaded order, as shown in the header summary. The following special message names exist: :n All new messages. :o All old messages (any not in state read or new). :u All unread messages. :d All deleted messages (for the undelete command). :r All read messages. :f All 'flagged' messages. :a All answered messages (cf. the markanswered variable). :t All messages marked as draft. :k All 'killed' messages. :j All messages classified as junk. . The current message. ; The message that was previously the current message. , The parent message of the current message, that is the message with the Message-ID given in the 'In-Reply-To:' field or the last entry of the 'References:' field of the current message. - The next previous undeleted message, or the next previous deleted message for the undelete command. In sorted\/threaded mode, the next previous such message in the sorted\/threaded order. + The next undeleted message, or the next deleted message for the undelete command. In sorted\/threaded mode, the next such message in the sorted\/threaded order. ^ The first undeleted message, or the first deleted message for the undelete command. In sorted\/threaded mode, the first such message in the sorted\/threaded order. $ The last message. In sorted\/threaded mode, the last message in the sorted\/threaded order. &x In threaded mode, selects the message addressed with x, where x is any other message specification, and all messages from the thread that begins at it. Otherwise, it is identical to x. If x is omitted, the thread beginning with the current message is selected. * All messages. ' All messages that were included in the message list for the previous command. \/ string All messages that contain string in the subject field (case ignored). See also the searchheaders variable. If string is empty, the string from the previous specification of that type is used again. address All messages from address. ( criterion ) All messages that satisfy the given IMAP-style SEARCH criterion. This addressing mode is available with all types of folders; for folders not located on IMAP servers, or for servers unable to execute the SEARCH command, mailx will perform the search locally. Strings must be enclosed by double quotes '\"' in their entirety if they contain white space or parentheses; within the quotes, only backslash '\\' is recognized as an escape character. All string searches are case-insensitive. When the description indicates that the 'envelope' representation of an address field is used, this means that the search string is checked against both a list constructed as (\"real name\" \"source-route\" \"local-part\" \"domain-part\")\n\n for each address, and the addresses without real names from the respective header field. Criteria can be nested using parentheses. ( criterion1 criterion2 ... criterionN ) All messages that satisfy all of the given criteria. (or criterion1 criterion2 ) All messages that satisfy either criterion1 or criterion2, or both. To connect more than two criteria using 'or', (or) specifications have to be nested using additional parentheses, as with '(or a (or b c))'; '(or a b c)' means ((a or b) and c). For a simple 'or' operation of independent criteria on the lowest nesting level, it is possible to achieve similar effects by using three separate criteria, as with '(a) (b) (c)'. (not criterion ) All messages that do not satisfy criterion. (bcc string ) All messages that contain string in the 'envelope' representation of the Bcc: field. (cc string ) All messages that contain string in the 'envelope' representation of the Cc: field. (from string ) All messages that contain string in the 'envelope' representation of the From: field. (subject string ) All messages that contain string in the Subject: field. (to string ) All messages that contain string in the 'envelope' representation of the To: field. (header name string ) All messages that contain string in the specified Name: field. (body string ) All messages that contain string in their body. (text string ) All messages that contain string in their header or body. (larger size ) All messages that are larger than size (in bytes). (smaller size ) All messages that are smaller than size (in bytes). (before date ) All messages that were received before date; date must be in the form d[ d] - mon - yyyy, where d[ d] is the day of the month as one or two digits, mon is the name of the month-one of 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', or 'Dec', and yyyy is the year as four digits; e.g. \"30-Aug-2004\". (on date ) All messages that were received on the specified date. (since date ) All messages that were received since the specified date. (sentbefore date ) All messages that were sent on the specified date. (senton date ) All messages that were sent on the specified date. (sentsince date ) All messages that were sent since the specified date. () The same criterion as for the previous search. This specification cannot be used as part of another criterion. If the previous command line contained more than one independent criterion, the last of those criteria is used. A practical method to read a set of messages is to issue a from command with the search criteria first to check for appropriate messages, and to read each single message then by typing ' '' repeatedly. Replying to or originating mail The reply command can be used to set up a response to a message, sending it back to the person who it was from. Text the user types in then, up to an end-of-file, defines the contents of the message. While the user is composing a message, mailx treats lines beginning with the character '~' specially. For instance, typing '~m' (alone on a line) will place a copy of the current message into the response right shifting it by a tabstop (see indentprefix variable, below). Other escapes will set up subject fields, add and delete recipients to the message, attach files to it and allow the user to escape to an editor to revise the message or to a shell to run some commands. (These options are given in the summary below.) Ending a mail processing session The user can end a mailx session with the quit ('q') command. Messages which have been examined go to the user's mbox file unless they have been deleted in which case they are discarded. Unexamined messages go back to the post office. (See the -f option above). Personal and systemwide distribution lists It is also possible to create a personal distribution lists so that, for instance, the user can send mail to ' cohorts' and have it go to a group of people. Such lists can be defined by placing a line like         alias cohorts bill ozalp jkf mark kridle@ucbcory\n\n in the file .mailrc in the user's home directory. The current list of such aliases can be displayed with the alias command in mailx. System wide distribution lists can be created by editing \/etc\/aliases, see aliases(5) and sendmail(8); these are kept in a different syntax. In mail the user sends, personal aliases will be expanded in mail sent to others so that they will be able to reply to the recipients. System wide aliases are not expanded when the mail is sent, but any reply returned to the machine will have the system wide alias expanded as all mail goes through sendmail. Recipient address specifications When an address is used to name a recipient (in any of To, Cc, or Bcc), names of local mail folders and pipes to external commands can also be specified; the message text is then written to them. The rules are: Any name which starts with a ' |' character specifies a pipe, the command string following the '|' is executed and the message is sent to its standard input; any other name which contains a ' @' character is treated as a mail address; any other name which starts with a ' +' character specifies a folder name; any other name which contains a ' \/' character but no ' !' or ' %' character before also specifies a folder name; what remains is treated as a mail address. Compressed folders are handled as described for the folder command below. Network mail (Internet \/ ARPA, UUCP, Berknet) See mailaddr(7) for a description of network addresses. Mailx has a number of options which can be set in the .mailrc file to alter its behavior; thus ' set askcc' enables the askcc feature. (These options are summarized below). MIME types For any outgoing attachment, mailx tries to determine the content type. It does this by reading MIME type files whose lines have the following syntax:         type\/subtype      extension [extension . . .] where type\/subtype are strings describing the file contents, and extension is the part of a filename starting after the last dot. Any line not immediately beginning with an ASCII alphabetical character is ignored by mailx. If there is a match with the extension of the file to attach, the given type\/subtype pair is used. Otherwise, or if the filename has no extension, the content types text\/plain or application\/octet-stream are used, the first for text or international text files, the second for any file that contains formatting characters other than newlines and horizontal tabulators. Character sets Mailx normally detects the character set of the terminal using the LC_CTYPE locale setting. If the locale cannot be used appropriately, the ttycharset variable should be set to provide an explicit value. When reading messages, their text is converted to the terminal character set if possible. Unprintable characters and illegal byte sequences are detected and replaced by Unicode substitute characters or question marks unless the print-all-chars is set at initialization time. The character set for outgoing messages is not necessarily the same as the one used on the terminal. If an outgoing text message contains characters not representable in US-ASCII, the character set being used must be declared within its header. Permissible values can be declared using the sendcharsets variable, separated by commas; mailx tries each of the values in order and uses the first appropriate one. If the message contains characters that cannot be represented in any of the given character sets, the message will not be sent, and its text will be saved to the 'dead.letter' file. Messages that contain NUL bytes are not converted. Outgoing attachments are converted if they are plain text. If the sendcharsets variable contains more than one character set name, the ~@ tilde escape will ask for the character sets for individual attachments if it is invoked without arguments. Best results are usually achieved when mailx is run in a UTF-8 locale on a UTF-8 capable terminal. In this setup, characters from various countries can be displayed, while it is still possible to use more simple character sets for sending to retain maximum compatibility with older mail clients. Commands Each command is typed on a line by itself, and may take arguments following the command word. The command need not be typed in its entirety - the first command which matches the typed prefix is used. For commands which take message lists as arguments, if no message list is given, then the next message forward which satisfies the command's requirements is used. If there are no messages forward of the current message, the search proceeds backwards, and if there are no good messages at all, mailx types ' applicable messages' and aborts the command. If the command begins with a # sign, the line is ignored. The arguments to commands can be quoted, using the following methods: \u2022 An argument can be enclosed between paired double-quotes \"\" or single-quotes ''; any white space, shell word expansion, or backslash characters within the quotes are treated literally as part of the argument. A double-quote will be treated literally within single-quotes and vice versa. These special properties of the quote marks occur only when they are paired at the beginning and end of the argument. \u2022 A backslash outside of the enclosing quotes is discarded and the following character is treated literally as part of the argument. \u2022 An unquoted backslash at the end of a command line is discarded and the next line continues the command. Filenames, where expected, are subjected to the following transformations, in sequence: \u2022 If the filename begins with an unquoted plus sign, and the folder variable is defined, the plus sign will be replaced by the value of the folder variable followed by a slash. If the folder variable is unset or is set to null, the filename will be unchanged. \u2022 Shell word expansions are applied to the filename. If more than a single pathname results from this expansion and the command is expecting one file, an error results. The following commands are provided: - Print out the preceding message. If given a numeric argument n, goes to the n'th previous message and prints it. ? Prints a brief summary of commands. ! Executes the shell (see sh(1) and csh(1)) command which follows. | A synonym for the pipe command. account (ac) Creates, selects or lists an email account. An account is formed by a group of commands, primarily of those to set variables. With two arguments, of which the second is a '{', the first argument gives an account name, and the following lines create a group of commands for that account until a line containing a single '}' appears. With one argument, the previously created group of commands for the account name is executed, and a folder command is executed for the system mailbox or inbox of that account. Without arguments, the list of accounts and their contents are printed. As an example,     account myisp {\n        set folder=imaps:\/\/mylogin@imap.myisp.example\n        set record=+Sent\n        set from=\"myname@myisp.example (My Name)\"\n        set smtp=smtp.myisp.example\n    }\n creates an account named 'myisp' which can later be selected by specifying 'account myisp'. alias (a) With no arguments, prints out all currently-defined aliases. With one argument, prints out that alias. With more than one argument, creates a new alias or changes an old one. alternates (alt) The alternates command is useful if the user has accounts on several machines. It can be used to inform mailx that the listed addresses all belong to the invoking user. When he replies to messages, mailx will not send a copy of the message to any of the addresses listed on the alternates list. If the alternates command is given with no argument, the current set of alternate names is displayed. answered (ans) Takes a message list and marks each message as a having been answered. This mark has no technical meaning in the mail system; it just causes messages to be marked in the header summary, and makes them specially addressable. cache Only applicable to cached IMAP mailboxes; takes a message list and reads the specified messages into the IMAP cache. call Calls a macro (see the define command). cd Same as chdir. certsave Only applicable to S\/MIME signed messages. Takes a message list and a file name and saves the certificates contained within the message signatures to the named file in both human-readable and PEM format. The certificates can later be used to send encrypted messages to the messages' originators by setting the smime-encrypt-user@host variable. chdir (ch) Changes the user's working directory to that specified, if given. If no directory is given, then changes to the user's login directory. classify (cl) Takes a list of messages and examines their contents for characteristics of junk mail using Bayesian filtering. Messages considered to be junk are then marked as such. The junk mail database is not changed. collapse (coll) Only applicable to threaded mode. Takes a message list and makes all replies to these messages invisible in header summaries, unless they are in state 'new'. connect (conn) If operating in disconnected mode on an IMAP mailbox, switch to online mode and connect to the mail server while retaining the mailbox status. See the description of the disconnected variable for more information. copy (c) The copy command does the same thing that save does, except that it does not mark the messages it is used on for deletion when the user quits. Compressed files and IMAP mailboxes are handled as described for the folder command. Copy (C) Similar to copy, but saves the messages in a file named after the local part of the sender address of the first message. decrypt (dec) For unencrypted messages, this command is identical to copy. Encrypted messages are first decrypted, if possible, and then copied. Decrypt (Dec) Similar to decrypt, but saves the messages in a file named after the local part of the sender address of the first message. define (def) Defines a macro. A macro definition is a sequence of commands in the following form: define name { command1 command2 ... commandN } Once defined, a macro can be explicitly invoked using the call command, or can be implicitly invoked by setting the folder-hook or folder-hook-fullname variables. defines Prints the currently defined macros including their contents. delete (d) Takes a list of messages as argument and marks them all as deleted. Deleted messages will not be saved in mbox, nor will they be available for most other commands. discard Same as ignore. disconnect (disco) If operating in online mode on an IMAP mailbox, switch to disconnected mode while retaining the mailbox status. See the description of the disconnected variable for more information. A list of messages may optionally be given as argument; the respective messages are then read into the cache before the connection is closed. Thus 'disco *' makes the entire current mailbox available for disconnected use. dp or dt Deletes the current message and prints the next message. If there is no next message, mailx says ' at EOF'. draft Takes a message list and marks each message as a draft. This mark has no technical meaning in the mail system; it just causes messages to be marked in the header summary, and makes them specially addressable. echo Echoes its arguments, resolving special names as documented for the folder command. The escape sequences '\\a', '\\b', '\\c', '\\f', '\\n', '\\r', '\\t', '\\v', '\\\\', and '\\0num' are interpreted as with the echo(1) command. edit (e) Takes a list of messages and points the text editor at each one in turn. Modified contents are discarded unless the writebackedited variable is set. else Marks the end of the then-part of an if statement and the beginning of the part to take effect if the condition of the if statement is false. endif Marks the end of an if statement. exit (ex or x) Effects an immediate return to the Shell without modifying the user's system mailbox, his mbox file, or his edit file in -f. file (fi) The same as folder. flag (fl) Takes a message list and marks the messages as 'flagged' for urgent\/special attention. This mark has no technical meaning in the mail system; it just causes messages to be highlighted in the header summary, and makes them specially addressable. folders With no arguments, list the names of the folders in the folder directory. With an existing folder as an argument, lists then names of folders below the named folder; e.g. the command 'folders @' lists the folders on the base level of the current IMAP server. See also the imap-list-depth variable. folder (fold) The folder command switches to a new mail file or folder. With no arguments, it tells the user which file he is currently reading. If an argument is given, it will write out changes (such as deletions) the user has made in the current file and read in the new file. Some special conventions are recognized for the name. # means the previous file, % means the invoking user's system mailbox, %user means user's system mailbox, & means the invoking user's mbox file, and +file means a file in the folder directory. %:filespec expands to the same value as filespec, but the file is handled as a system mailbox e. g. by the mbox and save commands. If the name matches one of the strings defined with the shortcut command, it is replaced by its long form and expanded. If the name ends with .gz or .bz2, it is treated as compressed with gzip(1) or bzip2(1), respectively. Likewise, if name does not exist, but either name.gz or name.bz2 exists, the compressed file is used. If name refers to a directory with the subdirectories 'tmp', 'new', and 'cur', it is treated as a folder in maildir format. A name of the form protocol :\/\/[ user @] host[ : port][ \/ file] is taken as an Internet mailbox specification. The supported protocols are currently imap (IMAP v4r1), imaps (IMAP with SSL\/TLS encryption), pop3 (POP3), and pop3s (POP3 with SSL\/TLS encryption). If user contains special characters, in particular '\/' or '%', they must be escaped in URL notation, as '%2F' or '%25'. The optional file part applies to IMAP only; if it is omitted, the default 'INBOX' is used. If mailx is connected to an IMAP server, a name of the form @mailbox refers to the mailbox on that server. If the 'folder' variable refers to an IMAP account, the special name '%' selects the 'INBOX' on that account. Followup (F) Similar to Respond, but saves the message in a file named after the local part of the first recipient's address. followup (fo) Similar to respond, but saves the message in a file named after the local part of the first recipient's address. followupall Similar to followup, but responds to all recipients regardless of the flipr and Replyall variables. followupsender Similar to Followup, but responds to the sender only regardless of the flipr and Replyall variables. forward (fwd) Takes a message and the address of a recipient and forwards the message to him. The text of the original message is included in the new one, with the value of the fwdheading variable printed before. The fwdignore and fwdretain commands specify which header fields are included in the new message. Only the first part of a multipart message is included unless the forward-as-attachment option is set. Forward (Fwd) Similar to forward, but saves the message in a file named after the local part of the recipient's address. from (f) Takes a list of messages and prints their message headers, piped through the pager if the output does not fit on the screen. fwdignore Specifies which header fields are to be ignored with the forward command. This command has no effect when the forward-as-attachment option is set. fwdretain Specifies which header fields are to be retained with the forward command. fwdretain overrides fwdignore. This command has no effect when the forward-as-attachment option is set. good (go) Takes a list of messages and marks all of them as not being junk mail. Data from these messages is then inserted into the junk mail database for future classification. headers (h) Lists the current range of headers, which is an 18-message group. If a '+' argument is given, then the next 18-message group is printed, and if a '-' argument is given, the previous 18-message group is printed. help A synonym for ?. hold (ho, also preserve) Takes a message list and marks each message therein to be saved in the user's system mailbox instead of in mbox. Does not override the delete command. mailx deviates from the POSIX standard with this command, as a 'next' command issued after 'hold' will display the following message, not the current one. if Commands in mailx's startup files can be executed conditionally depending on whether the user is sending or receiving mail with the if command. For example: if receive commands . . . endif An else form is also available:         if receive\n                commands . . .\n        else\n                commands . . .\n        endif\n\n Note that the only allowed conditions are receive, send, and term (execute command if standard input is a tty). ignore Add the list of header fields named to the ignored list. Header fields in the ignore list are not printed on the terminal when a message is printed. This command is very handy for suppression of certain machine-generated header fields. The Type and Print commands can be used to print a message in its entirety, including ignored fields. If ignore is executed with no arguments, it lists the current set of ignored fields. imap Sends command strings directly to the current IMAP server. Mailx operates always in IMAP selected state on the current mailbox; commands that change this will produce undesirable results and should be avoided. Useful IMAP commands are: create Takes the name of an IMAP mailbox as an argument and creates it. getquotaroot Takes the name of an IMAP mailbox as an argument and prints the quotas that apply to the mailbox. Not all IMAP servers support this command. namespace Takes no arguments and prints the Personal Namespaces, the Other User's Namespaces, and the Shared Namespaces. Each namespace type is printed in parentheses; if there are multiple namespaces of the same type, inner parentheses separate them. For each namespace, a namespace prefix and a hierarchy separator is listed. Not all IMAP servers support this command. inc Same as newmail. junk (j) Takes a list of messages and marks all of them as junk mail. Data from these messages is then inserted into the junk mail database for future classification. kill (k) Takes a list of messages and 'kills' them. Killed messages are not printed in header summaries, and are ignored by the next command. The kill command also sets the score of the messages to negative infinity, so that subsequent score commands will not unkill them again. Killing is only effective for the current session on a folder; when it is quit, all messages are automatically unkilled. list Prints the names of all available commands. Mail (M) Similar to mail, but saves the message in a file named after the local part of the first recipient's address. mail (m) Takes as argument login names and distribution group names and sends mail to those people. mbox Indicate that a list of messages be sent to mbox in the user's home directory when mailx is quit. This is the default action for messages if unless the hold option is set. mailx deviates from the POSIX standard with this command, as a 'next' command issued after 'mbox' will display the following message, not the current one. move (mv) Acts like copy, but marks the messages for deletion if they were transferred successfully. Move (Mv) Similar to move, but moves the messages to a file named after the local part of the sender address of the first message. newmail Checks for new mail in the current folder without committing any changes before. If new mail is present, a message is printed. If the header variable is set, the headers of each new message are also printed. next (n) like + or CR) Goes to the next message in sequence and types it. With an argument list, types the next matching message. New Same as unread. new Same as unread. online Same as connect. noop If the current folder is located on an IMAP or POP3 server, a NOOP command is sent. Otherwise, no operation is performed. Pipe (Pi) Like pipe but also pipes ignored header fields and all parts of MIME multipart\/alternative messages. pipe (pi) Takes a message list and a shell command and pipes the messages through the command. Without an argument, the current message is piped through the command given by the cmd variable. If the page variable is set, every message is followed by a formfeed character. preserve (pre) A synonym for hold. Print (P) Like print but also prints out ignored header fields and all parts of MIME multipart\/alternative messages. See also print, ignore, and retain. print (p) Takes a message list and types out each message on the user's terminal. If the message is a MIME multipart message, all parts with a content type of 'text' or 'message' are shown, the other are hidden except for their headers. Messages are decrypted and converted to the terminal character set if necessary. probability (prob) For each word given as argument, the contents of its junk mail database entry are printed. quit (q) Terminates the session, saving all undeleted, unsaved messages in the user's mbox file in his login directory, preserving all messages marked with hold or preserve or never referenced in his system mailbox, and removing all other messages from his system mailbox. If new mail has arrived during the session, the message 'You have new mail' is given. If given while editing a mailbox file with the -f flag, then the edit file is rewritten. A return to the Shell is effected, unless the rewrite of edit file fails, in which case the user can escape with the exit command. redirect (red) Same as resend. Redirect (Red) Same as Resend. remove (rem) Removes the named folders. The user is asked for confirmation in interactive mode. rename (ren) Takes the name of an existing folder and the name for the new folder and renames the first to the second one. Both folders must be of the same type and must be located on the current server for IMAP. Reply (R) Reply to originator. Does not reply to other recipients of the original message. reply (r) Takes a message list and sends mail to the sender and all recipients of the specified message. The default message must not be deleted. replyall Similar to reply, but responds to all recipients regardless of the flipr and Replyall variables. replysender Similar to Reply, but responds to the sender only regardless of the flipr and Replyall variables. Resend Like resend, but does not add any header lines. This is not a way to hide the sender's identity, but useful for sending a message again to the same recipients. resend Takes a list of messages and a user name and sends each message to the named user. 'Resent-From:' and related header fields are prepended to the new copy of the message. Respond Same as Reply. respond Same as reply. respondall Same as replyall. respondsender Same as replysender. retain Add the list of header fields named to the retained list. Only the header fields in the retain list are shown on the terminal when a message is printed. All other header fields are suppressed. The Type and Print commands can be used to print a message in its entirety. If retain is executed with no arguments, it lists the current set of retained fields. Save (S) Similar to save, but saves the messages in a file named after the local part of the sender of the first message instead of taking a filename argument. save (s) Takes a message list and a filename and appends each message in turn to the end of the file. If no filename is given, the mbox file is used. The filename in quotes, followed by the line count and character count is echoed on the user's terminal. If editing a system mailbox, the messages are marked for deletion. Compressed files and IMAP mailboxes are handled as described for the -f command line option above. savediscard Same as saveignore. saveignore Saveignore is to save what ignore is to print and type. Header fields thus marked are filtered out when saving a message by save or when automatically saving to mbox. This command should only be applied to header fields that do not contain information needed to decode the message, as MIME content fields do. If saving messages on an IMAP account, ignoring fields makes it impossible to copy the data directly on the server, thus operation usually becomes much slower. saveretain Saveretain is to save what retain is to print and type. Header fields thus marked are the only ones saved with a message when saving by save or when automatically saving to mbox. Saveretain overrides saveignore. The use of this command is strongly discouraged since it may strip header fields that are needed to decode the message correctly. score (sc) Takes a message list and a floating point number and adds the number to the score of each given message. All messages start at score 0 when a folder is opened. When the score of a message becomes negative, it is 'killed' with the effects described for the kill command; otherwise if it was negative before and becomes positive, it is 'unkilled'. Scores only refer to the currently opened instance of a folder. set (se) With no arguments, prints all variable values, piped through the pager if the output does not fit on the screen. Otherwise, sets option. Arguments are of the form option=value (no space before or after =) or option. Quotation marks may be placed around any part of the assignment statement to quote blanks or tabs, i.e. 'set indentprefix=\"->\"'. If an argument begins with no, as in 'set nosave', the effect is the same as invoking the unset command with the remaining part of the variable ('unset save'). seen Takes a message list and marks all messages as having been read. shell (sh) Invokes an interactive version of the shell. shortcut Defines a shortcut name and its string for expansion, as described for the folder command. With no arguments, a list of defined shortcuts is printed. show (Sh) Like print, but performs neither MIME decoding nor decryption so that the raw message text is shown. size Takes a message list and prints out the size in characters of each message. sort Create a sorted representation of the current folder, and change the next command and the addressing modes such that they refer to messages in the sorted order. Message numbers are the same as in regular mode. If the header variable is set, a header summary in the new order is also printed. Possible sorting criteria are: date Sort the messages by their 'Date:' field, that is by the time they were sent. from Sort messages by the value of their 'From:' field, that is by the address of the sender. If the showname variable is set, the sender's real name (if any) is used. size Sort the messages by their size. score Sort the messages by their score. status Sort the messages by their message status (new, read, old, etc.). subject Sort the messages by their subject. thread Create a threaded order, as with the thread command. to Sort messages by the value of their 'To:' field, that is by the address of the recipient. If the showname variable is set, the recipient's real name (if any) is used. If no argument is given, the current sorting criterion is printed. source The source command reads commands from a file. thread (th) Create a threaded representation of the current folder, i.e. indent messages that are replies to other messages in the header display, and change the next command and the addressing modes such that they refer to messages in the threaded order. Message numbers are the same as in unthreaded mode. If the header variable is set, a header summary in threaded order is also printed. top Takes a message list and prints the top few lines of each. The number of lines printed is controlled by the variable toplines and defaults to five. touch Takes a message list and marks the messages for saving in the mbox file. mailx deviates from the POSIX standard with this command, as a 'next' command issued after 'mbox' will display the following message, not the current one. Type (T) Identical to the Print command. type (t) A synonym for print. unalias Takes a list of names defined by alias commands and discards the remembered groups of users. The group names no longer have any significance. unanswered Takes a message list and marks each message as not having been answered. uncollapse (unc) Only applicable to threaded mode. Takes a message list and makes the message and all replies to it visible in header summaries again. When a message becomes the current message, it is automatically made visible. Also when a message with collapsed replies is printed, all of these are automatically uncollapsed. undef Undefines each of the named macros. It is not an error to use a name that does not belong to one of the currently defined macros. undelete (u) Takes a message list and marks each message as not being deleted. undraft Takes a message list and marks each message as a draft. unflag Takes a message list and marks each message as not being 'flagged'. unfwdignore Removes the header field names from the list of ignored fields for the forward command. unfwdretain Removes the header field names from the list of retained fields for the forward command. ungood Takes a message list and undoes the effect of a good command that was previously applied on exactly these messages. unignore Removes the header field names from the list of ignored fields. unjunk Takes a message list and undoes the effect of a junk command that was previously applied on exactly these messages. unkill Takes a message list and 'unkills' each message. Also sets the score of the messages to 0. Unread Same as unread. unread (U) Takes a message list and marks each message as not having been read. unretain Removes the header field names from the list of retained fields. unsaveignore Removes the header field names from the list of ignored fields for saving. unsaveretain Removes the header field names from the list of retained fields for saving. unset Takes a list of option names and discards their remembered values; the inverse of set. unshortcut Deletes the shortcut names given as arguments. unsort Disable sorted or threaded mode (see the sort and thread commands), return to normal message order and, if the header variable is set, print a header summary. unthread (unth) Same as unsort. verify (verif) Takes a message list and verifies each message. If a message is not an S\/MIME signed message, verification will fail for it. The verification process checks if the message was signed using a valid certificate, if the message sender's email address matches one of those contained within the certificate, and if the message content has been altered. visual (v) Takes a message list and invokes the display editor on each message. Modified contents are discarded unless the writebackedited variable is set. write (w) For conventional messages, the body without all headers is written. The output is decrypted and converted to its native format, if necessary. If the output file exists, the text is appended.-If a message is in MIME multipart format, its first part is written to the specified file as for conventional messages, and the user is asked for a filename to save each other part; if the contents of the first part are not to be saved, 'write \/dev\/null' can be used. For the second and subsequent parts, if the filename given starts with a '|' character, the part is piped through the remainder of the filename interpreted as a shell command. In non-interactive mode, only the parts of the multipart message that have a filename given in the part header are written, the other are discarded. The original message is never marked for deletion in the originating mail folder. For attachments, the contents of the destination file are overwritten if the file previously existed. No special handling of compressed files is performed. xit (x) A synonym for exit. z Mailx presents message headers in windowfuls as described under the headers command. The z command scrolls to the next window of messages. If an argument is given, it specifies the window to use. A number prefixed by '+' or '-' indicates that the window is calculated in relation to the current position. A number without a prefix specifies an absolute window number, and a '$' lets mailx scroll to the last window of messages. Z Similar to z, but scrolls to the next or previous window that contains at least one new or 'flagged' message. Tilde escapes Here is a summary of the tilde escapes, which are used when composing messages to perform special functions. Tilde escapes are only recognized at the beginning of lines. The name ' tilde escape' is somewhat of a misnomer since the actual escape character can be set by the option escape. ~! command Execute the indicated shell command, then return to the message. ~. Same effect as typing the end-of-file character. ~< filename Identical to ~r. ~<! command Command is executed using the shell. Its standard output is inserted into the message. ~@ [ filename . . . ] With no arguments, edit the attachment list. First, the user can edit all existing attachment data. If an attachment's file name is left empty, that attachment is deleted from the list. When the end of the attachment list is reached, mailx will ask for further attachments, until an empty file name is given. If filename arguments are specified, all of them are appended to the end of the attachment list. Filenames which contain white space can only be specified with the first method (no filename arguments). ~A Inserts the string contained in the Sign variable (same as '~i Sign'). The escape sequences '\\t' (tabulator) and '\\n' (newline) are understood. ~a Inserts the string contained in the sign variable (same as '~i sign'). The escape sequences '\\t' (tabulator) and '\\n' (newline) are understood. ~b name . . . Add the given names to the list of carbon copy recipients but do not make the names visible in the Cc: line ('blind' carbon copy). ~c name . . . Add the given names to the list of carbon copy recipients. ~d Read the file 'dead.letter' from the user's home directory into the message. ~e Invoke the text editor on the message collected so far. After the editing session is finished, the user may continue appending text to the message. ~f messages Read the named messages into the message being sent. If no messages are specified, read in the current message. Message headers currently being ignored (by the ignore or retain command) are not included. For MIME multipart messages, only the first printable part is included. ~F messages Identical to ~f, except all message headers and all MIME parts are included. ~h Edit the message header fields 'To:', 'Cc:', 'Bcc:', and 'Subject:' by typing each one in turn and allowing the user to append text to the end or modify the field by using the current terminal erase and kill characters. ~H Edit the message header fields 'From:', 'Reply-To:', 'Sender:', and 'Organization:' in the same manner as described for ~h. The default values for these fields originate from the from, replyto, and ORGANIZATION variables. If this tilde command has been used, changing the variables has no effect on the current message anymore. ~i variable Insert the value of the specified variable into the message adding a newline character at the end. If the variable is unset or empty, the message remains unaltered. The escape sequences ' \\t' (tabulator) and ' \\n' (newline) are understood. ~m messages Read the named messages into the message being sent, indented by a tab or by the value of indentprefix. If no messages are specified, read the current message. Message headers currently being ignored (by the ignore or retain command) are not included. For MIME multipart messages, only the first printable part is included. ~M messages Identical to ~m, except all message headers and all MIME parts are included. ~p Print out the message collected so far, prefaced by the message header fields and followed by the attachment list, if any. If the message text is longer than the screen size, it is piped through the pager. ~q Abort the message being sent, copying the message to 'dead.letter' in the user's home directory if save is set. ~r filename Read the named file into the message. ~s string Cause the named string to become the current subject field. ~t name . . . Add the given names to the direct recipient list. ~v Invoke an alternate editor (defined by the VISUAL option) on the message collected so far. Usually, the alternate editor will be a screen editor. After the editor is quit, the user may resume appending text to the end of the message. ~w filename Write the message onto the named file. If the file exists, the message is appended to it. ~x Same as ~q, except that the message is not saved to the 'dead.letter' file. ~| command Pipe the message through the command as a filter. If the command gives no output or terminates abnormally, retain the original text of the message. The command fmt(1) is often used as command to rejustify the message. ~: mailx-command Execute the given mailx command. Not all commands, however, are allowed. ~_ mailx-command Identical to ~:. ~~ string Insert the string of text in the message prefaced by a single ~. If the escape character has been changed, that character must be doubled in order to send it at the beginning of a line. Variable options Options are controlled via set and unset commands, see their entries for a syntax description. An option is also set if it is passed to mailx as part of the environment (this is not restricted to specific variables as in the POSIX standard). A value given in a startup file overrides a value imported from the environment. Options may be either binary, in which case it is only significant to see whether they are set or not; or string, in which case the actual value is of interest. Binary options The binary options include the following: allnet Causes only the local part to be evaluated when comparing addresses. append Causes messages saved in mbox to be appended to the end rather than prepended. This should always be set. ask or asksub Causes mailx to prompt for the subject of each message sent. If the user responds with simply a newline, no subject field will be sent. askatend Causes the prompts for 'Cc:' and 'Bcc:' lists to appear after the message has been edited. askattach If set, mailx asks for files to attach at the end of each message. Responding with a newline indicates not to include an attachment. askcc Causes the user to be prompted for additional carbon copy recipients (at the end of each message if askatend or bsdcompat is set). Responding with a newline indicates the user's satisfaction with the current list. askbcc Causes the user to be prompted for additional blind carbon copy recipients (at the end of each message if askatend or bsdcompat is set). Responding with a newline indicates the user's satisfaction with the current list. asksign Causes the user to be prompted if the message is to be signed at the end of each message. The smime-sign variable is ignored when this variable is set. autocollapse Causes threads to be collapsed automatically when threaded mode is entered (see the collapse command). autoinc Same as newmail. autoprint Causes the delete command to behave like dp - thus, after deleting a message, the next one will be typed automatically. autothread Causes threaded mode (see the thread command) to be entered automatically when a folder is opened. bang Enables the substitution of '!' by the contents of the last command line in shell escapes. bsdannounce Causes automatic display of a header summary after executing a folder command. bsdcompat Sets some cosmetical features to traditional BSD style; has the same affect as setting 'askatend' and all other variables prefixed with 'bsd', setting prompt to '& ', and changing the default pager to more. bsdflags Changes the letters printed in the first column of a header summary to traditional BSD style. bsdheadline Changes the display of columns in a header summary to traditional BSD style. bsdmsgs Changes some informational messages to traditional BSD style. bsdorder Causes the 'Subject:' field to appear immediately after the 'To:' field in message headers and with the ~h tilde command. bsdset Changes the output format of the set command to traditional BSD style. chained-junk-tokens Normally, the Bayesian junk mail filter bases its classifications on single word tokens extracted from messages. If this option is set, adjacent words are combined to pairs, which are then used as additional tokens. This usually improves the accuracy of the filter, but also increases the junk mail database five- to tenfold. datefield The date in a header summary is normally the date of the mailbox 'From ' line of the message. If this variable is set, the date as given in the 'Date:' header field is used, converted to local time. debug Prints debugging messages and disables the actual delivery of messages. Unlike verbose, this option is intended for mailx development only. disconnected When an IMAP mailbox is selected and this variable is set, no connection to the server is initiated. Instead, data is obtained from the local cache (see imap-cache). Mailboxes that are not present in the cache and messages that have not yet entirely been fetched from the server are not available; to fetch all messages in a mailbox at once, the command 'copy * \/dev\/null' can be used while still in online mode. Changes that are made to IMAP mailboxes in disconnected mode are queued and committed later when a connection to that server is opened in online mode. This procedure is not completely reliable since it cannot be guaranteed that the IMAP unique identifiers (UIDs) on the server still match the ones in the cache at that time. Data is saved to 'dead.letter' when this problem occurs. disconnected- user @ host The specified account is handled as described for the disconnected variable above, but other accounts are not affected. dot The binary option dot causes mailx to interpret a period alone on a line as the terminator of a message the user is sending. editheaders When a message is edited while being composed, its header is included in the editable text. 'To:', 'Cc:', 'Bcc:', 'Subject:', 'From:', 'Reply-To:', 'Sender:', and 'Organization:' fields are accepted within the header, other fields are ignored. emptybox If set, an empty mailbox file is not removed. This may improve the interoperability with other mail user agents when using a common folder directory. emptystart If the mailbox is empty, mailx normally prints 'No mail for user' and exits immediately. If this option is set, mailx starts even with an empty mailbox. flipr Exchanges the Respond with the respond commands and vice-versa. forward-as-attachment Original messages are normally sent as inline text with the forward command, and only the first part of a multipart message is included. With this option, messages are sent as MIME message\/rfc822 attachments, and all of their parts are included. The fwdignore and fwdretain options are ignored when the forward-as-attachment option is set. fullnames When replying to a message, mailx normally removes the comment parts of email addresses, which by convention contain the full names of the recipients. If this variable is set, such stripping is not performed, and comments are retained. header Causes the header summary to be written at startup and after commands that affect the number of messages or the order of messages in the current folder; enabled by default. hold This option is used to hold messages in the system mailbox by default. ignore Causes interrupt signals from the terminal to be ignored and echoed as @'s. ignoreeof An option related to dot is ignoreeof which makes mailx refuse to accept a control-d as the end of a message. Ignoreeof also applies to mailx command mode. imap-use-starttls Causes mailx to issue a STARTTLS command to make an unencrypted IMAP session SSL\/TLS encrypted. This functionality is not supported by all servers, and is not used if the session is already encrypted by the IMAPS method. imap-use-starttls- user @ host Activates imap-use-starttls for a specific account. keep This option causes mailx to truncate the user's system mailbox instead of deleting it when it is empty. This should always be set, since it prevents malicious users from creating fake mail folders in a world-writable spool directory. keepsave When a message is saved, it is usually discarded from the originating folder when mailx is quit. Setting this option causes all saved message to be retained. markanswered When a message is replied to and this variable is set, it is marked as having been answered. This mark has no technical meaning in the mail system; it just causes messages to be marked in the header summary, and makes them specially addressable. metoo Usually, when a group is expanded that contains the sender, the sender is removed from the expansion. Setting this option causes the sender to be included in the group. newmail Checks for new mail in the current folder each time the prompt is printed. For IMAP mailboxes, the server is then polled for new mail, which may result in delayed operation if the connection to the server is slow. A maildir folder must be re-scanned to determine if new mail has arrived. If this variable is set to the special value nopoll, an IMAP server is not actively asked for new mail, but new mail may still be detected and announced with any other IMAP command that is sent to the server. A maildir folder is not scanned then. In any case, the IMAP server may send notifications about messages that have been deleted on the server by another process or client. In this case, 'Expunged n messages' is printed regardless of this variable, and message numbers may have changed. noheader Setting the option noheader is the same as giving the -N flag on the command line. outfolder Causes the filename given in the record variable and the sender-based filenames for the Copy and Save commands to be interpreted relative to the directory given in the folder variable rather than to the current directory unless it is an absolute pathname. page If set, each message the pipe command prints out is followed by a formfeed character. piperaw Send messages to the pipe command without performing MIME and character set conversions. pop3-use-apop If this variable is set, the APOP authentication method is used when a connection to a POP3 server is initiated. The advantage of this method over the usual USER\/PASS authentication is that the password is not sent over the network in clear text. The connection fails if the server does not support the APOP command. pop3-use-apop- user @ host Enables pop3-use-apop for a specific account. pop3-use-starttls Causes mailx to issue a STLS command to make an unencrypted POP3 session SSL\/TLS encrypted. This functionality is not supported by all servers, and is not used if the session is already encrypted by the POP3S method. pop3-use-starttls- user @ host Activates pop3-use-starttls for a specific account. print-all-chars This option causes all characters to be considered printable. It is only effective if given in a startup file. With this option set, some character sequences in messages may put the user's terminal in an undefined state when printed; it should only be used as a last resort if no working system locale can be found. print-alternatives When a MIME message part of type multipart\/alternative is displayed and it contains a subpart of type text\/plain, other parts are normally discarded. Setting this variable causes all subparts to be displayed, just as if the surrounding part was of type multipart\/mixed. quiet Suppresses the printing of the version when first invoked. record-resent If both this variable and the record variable are set, the resend and Resend commands save messages to the record folder as it is normally only done for newly composed messages. reply-in-same-charset If this variable is set, mailx first tries to use the same character set of the original message for replies. If this fails, the sendcharsets variable is evaluated as usual. Replyall Reverses the sense of reply and Reply commands. save When the user aborts a message with two RUBOUT (interrupt characters) mailx copies the partial letter to the file 'dead.letter' in the home directory. This option is set by default. searchheaders If this option is set, then a message-list specifier in the form ' \/x:y' will expand to all messages containing the substring ' y' in the header field ' x'. The string search is case insensitive. sendwait When sending a message, wait until the mail transfer agent exits before accepting further commands. If the mail transfer agent returns a non-zero exit status, the exit status of mailx will also be non-zero. showlast Setting this option causes mailx to start at the last message instead of the first one when opening a mail folder. showname Causes mailx to use the sender's real name instead of the plain address in the header field summary and in message specifications. showto Causes the recipient of the message to be shown in the header summary if the message was sent by the user. skipemptybody If an outgoing message does not contain any text in its first or only message part, do not send it but discard it silently (see also the -E option). smime-force-encryption Causes mailx to refuse sending unencrypted messages. smime-sign If this variable is set, outgoing messages are S\/MIME signed with the user's private key. Signing a message enables a recipient to verify that the sender used a valid certificate, that the email addresses in the certificate match those in the message header, and that the message content has not been altered. It does not change the message text, and people will be able to read the message as usual. smime-no-default-ca Do not load the default CA locations when verifying S\/MIME signed messages. Only applicable if S\/MIME support is built using OpenSSL. smtp-use-starttls Causes mailx to issue a STARTTLS command to make an SMTP session SSL\/TLS encrypted. Not all servers support this command; because of common implementation defects, it cannot be automatically determined whether a server supports it or not. ssl-no-default-ca Do not load the default CA locations to verify SSL\/TLS server certificates. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-v2-allow Accept SSLv2 connections. These are normally not allowed because this protocol version is insecure. stealthmua Inhibits the generation of the 'Message-Id:' and 'User-Agent:' header fields that include obvious references to mailx. There are two pitfalls associated with this: First, the message id of outgoing messages is not known anymore. Second, an expert may still use the remaining information in the header to track down the originating mail user agent. verbose Setting the option verbose is the same as using the -v flag on the command line. When mailx runs in verbose mode, details of the actual message delivery and protocol conversations for IMAP, POP3, and SMTP, as well as of other internal processes, are displayed on the user's terminal, This is sometimes useful to debug problems. Mailx prints all data that is sent to remote servers in clear texts, including passwords, so care should be taken that no unauthorized option can view the screen if this option is enabled. writebackedited If this variable is set, messages modified using the edit or visual commands are written back to the current folder when it is quit. This is only possible for writable folders in mbox format. Setting this variable also disables MIME decoding and decryption for the editing commands. String Options The string options include the following: attrlist A sequence of characters to print in the 'attribute' column of a header summary, each for one type of messages in the following order: new, unread but old, new but read, read and old, saved, preserved, mboxed, flagged, answered, draft, killed, start of a collapsed thread, collapsed, classified as junk. The default is 'NUROSPMFATK+-J', or 'NU *HMFATK+-J' if bsdflags or the SYSV3 environment variable are set. autobcc Specifies a list of recipients to which a blind carbon copy of each outgoing message will be sent automatically. autocc Specifies a list of recipients to which a carbon copy of each outgoing message will be sent automatically. autosort Causes sorted mode (see the sort command) to be entered automatically with the value of this option as sorting method when a folder is opened. cmd The default value for the pipe command. crt The valued option crt is used as a threshold to determine how long a message must be before PAGER is used to read it. If crt is set without a value, then the height of the terminal screen stored in the system is used to compute the threshold (see stty(1)). DEAD The name of the file to use for saving aborted messages. This defaults to 'dead.letter' in the user's home directory. EDITOR Pathname of the text editor to use in the edit command and ~e escape. If not defined, then a default editor is used. encoding The default MIME encoding to use in outgoing text messages and message parts. Valid values are 8bit or quoted-printable. The default is 8bit. In case the mail transfer system is not ESMTP compliant, quoted-printable should be used instead. If there is no need to encode a message, 7bit transfer mode is used, without regard to the value of this variable. Binary data is always encoded in base64 mode. escape If defined, the first character of this option gives the character to use in the place of ~ to denote escapes. folder The name of the directory to use for storing folders of messages. All folder names that begin with '+' refer to files below that directory. If the directory name begins with a '\/', mailx considers it to be an absolute pathname; otherwise, the folder directory is found relative to the user's home directory. The directory name may also refer to an IMAP account; any names that begin with '+' then refer to IMAP mailboxes on that account. An IMAP folder is normally given in the form imaps:\/\/mylogin@imap.myisp.example In this case, the '+' and '@' prefixes for folder names have the same effect (see the folder command). Some IMAP servers do not accept the creation of mailboxes in the hierarchy base; they require that they are created as subfolders of 'INBOX'. With such servers, a folder name of the form imaps:\/\/mylogin@imap.myisp.example\/INBOX. should be used (the last character is the server's hierarchy delimiter). Folder names prefixed by '+' will then refer to folders below 'INBOX', while folder names prefixed by '@' refer to folders below the hierarchy base. See the imap namespace command for a method to detect the appropriate prefix and delimiter. folder-hook When a folder is opened and this variable is set, the macro corresponding to the value of this variable is executed. The macro is also invoked when new mail arrives, but message lists for commands executed from the macro only include newly arrived messages then. folder-hook- fullname When a folder named fullname is opened, the macro corresponding to the value of this variable is executed. Unlike other folder specifications, the fully expanded name of a folder, without metacharacters, is used to avoid ambiguities. The macro specified with folder-hook is not executed if this variable is effective for a folder (unless it is explicitly invoked within the called macro). from The address (or a list of addresses) to put into the 'From:' field of the message header. If replying to a message, these addresses are handled as if they were in the alternates list. If the machine's hostname is not valid at the Internet (for example at a dialup machine), either this variable or hostname have to be set to get correct Message-ID header fields. If from contains more than one address, the sender variable must also be set. fwdheading The string to print before the text of a message with the forward command (unless the forward-as-attachment variable is set). Defaults to ''-------- Original Message --------'' if unset. If it is set to the empty string, no heading is printed. headline A format string to use for the header summary, similar to printf formats. A '%' character introduces a format specifier. It may be followed by a number indicating the field width. If the field is a number, the width may be negative, which indicates that it is to be left-aligned. Valid format specifiers are: The default is '%>%a%m %18f %16d %4l\/%-5o %i%s', or '%>%a%m %20f %16d %3l\/%-5o %i%S' if bsdcompat is set. hostname Use this string as hostname when expanding local addresses instead of the value obtained from uname(2) and getaddrinfo(3). imap-auth Sets the IMAP authentication method. Valid values are 'login' for the usual password-based authentication (the default), 'cram-md5', which is a password-based authentication that does not send the password over the network in clear text, and 'gssapi' for GSSAPI-based authentication. imap-auth- user @ host Sets the IMAP authentication method for a specific account. imap-cache Enables caching of IMAP mailboxes. The value of this variable must point to a directory that is either existent or can be created by mailx. All contents of the cache can be deleted by mailx at any time; it is not safe to make assumptions about them. imap-keepalive IMAP servers may close the connection after a period of inactivity; the standard requires this to be at least 30 minutes, but practical experience may vary. Setting this variable to a numeric value greater than 0 causes a NOOP command to be sent each value seconds if no other operation is performed. imap-list-depth When retrieving the list of folders on an IMAP server, the folders command stops after it has reached a certain depth to avoid possible infinite loops. The value of this variable sets the maximum depth allowed. The default is 2. If the folder separator on the current IMAP server is a slash '\/', this variable has no effect, and the folders command does not descend to subfolders. indentprefix String used by the ' ~m' and ' ~M' tilde escapes and by the quote option for indenting messages, in place of the normal tab character (^I). Be sure to quote the value if it contains spaces or tabs. junkdb The location of the junk mail database. The string is treated like a folder name, as described for the folder command. The files in the junk mail database are normally stored in compress(1) format for saving space. If processing time is considered more important, uncompress(1) can be used to store them in plain form. Mailx will then work using the uncompressed files. LISTER Pathname of the directory lister to use in the folders command when operating on local mailboxes. Default is \/bin\/ls. MAIL Is used as the user's mailbox, if set. Otherwise, a system-dependent default is used. Can be a protocol:\/\/ string (see the folder command for more information). MAILX_HEAD A string to put at the beginning of each new message. The escape sequences ' \\t' (tabulator) and ' \\n' (newline) are understood. MAILX_TAIL A string to put at the end of each new message. The escape sequences ' \\t' (tabulator) and ' \\n' (newline) are understood. maximum-unencoded-line-length Messages that contain lines longer than the value of this variable are encoded in quoted-printable even if they contain only ASCII characters. The maximum effective value is 950. If set to 0, all ASCII text messages are encoded in quoted-printable. S\/MIME signed messages are always encoded in quoted-printable regardless of the value of this variable. MBOX The name of the mbox file. It can be the name of a folder. The default is 'mbox' in the user's home directory. NAIL_EXTRA_RC The name of an optional startup file to be read after ~\/.mailrc. This variable is ignored if it is imported from the environment; it has an effect only if it is set in \/etc\/mail.rc or ~\/.mailrc to allow bypassing the configuration with e. g. 'MAILRC=\/dev\/null'. Use this file for commands that are not understood by other mailx implementations. newfolders If this variable has the value maildir, newly created local folders will be in maildir format. nss-config-dir A directory that contains the files cert N.db to retrieve certificates, key N.db to retrieve private keys, and secmod.db, where N is a digit. These are usually taken from Mozilla installations, so an appropriate value might be '~\/.mozilla\/firefox\/default.clm'. Mailx opens these files read-only and does not modify them. However, if the files are modified by Mozilla while mailx is running, it will print a 'Bad database' message. It may be necessary to create copies of these files that are exclusively used by mailx then. Only applicable if S\/MIME and SSL\/TLS support is built using Network Security Services (NSS). ORGANIZATION The value to put into the 'Organization:' field of the message header. PAGER Pathname of the program to use in the more command or when crt variable is set. The default paginator pg(1) or, in BSD compatibility mode, more(1) is used if this option is not defined. password- user @ host Set the password for user when connecting to host. If no such variable is defined for a host, the user will be asked for a password on standard input. Specifying passwords in a startup file is generally a security risk, the file should be readable by the invoking user only. pipe- content\/subcontent When a MIME message part of content\/subcontent type is displayed or it is replied to, its text is filtered through the value of this variable interpreted as a shell command. Special care must be taken when using such commands as mail viruses may be distributed by this method; if messages of type application\/x-sh were filtered through the shell, for example, a message sender could easily execute arbitrary code on the system mailx is running on. pop3-keepalive POP3 servers may close the connection after a period of inactivity; the standard requires this to be at least 10 minutes, but practical experience may vary. Setting this variable to a numeric value greater than 0 causes a NOOP command to be sent each value seconds if no other operation is performed. prompt The string printed when a command is accepted. Defaults to '? ', or to '& ' if the bsdcompat variable is set. quote If set, mailx starts a replying message with the original message prefixed by the value of the variable indentprefix. Normally, a heading consisting of 'Fromheaderfield wrote:' is printed before the quotation. If the string noheading is assigned to the quote variable, this heading is omitted. If the string headers is assigned, the headers selected by the ignore\/retain commands are printed above the message body, thus quote acts like an automatic ~m command then. If the string allheaders is assigned, all headers are printed above the message body, and all MIME parts are included, thus quote acts like an automatic ~M command then. record If defined, gives the pathname of the folder used to record all outgoing mail. If not defined, then outgoing mail is not so saved. When saving to this folder fails, the message is not sent but saved to the 'dead.letter' file instead. replyto A list of addresses to put into the 'Reply-To:' field of the message header. If replying to a message, such addresses are handled as if they were in the alternates list. screen When mailx initially prints the message headers, it determines the number to print by looking at the speed of the terminal. The faster the terminal, the more it prints. This option overrides this calculation and specifies how many message headers are printed. This number is also used for scrolling with the z command. sendcharsets A comma-separated list of character set names that can be used in Internet mail. When a message that contains characters not representable in US-ASCII is prepared for sending, mailx tries to convert its text to each of the given character sets in order and uses the first appropriate one. The default is 'utf-8'. Character sets assigned to this variable should be ordered in ascending complexity. That is, the list should start with e.g. 'iso-8859-1' for compatibility with older mail clients, might contain some other language-specific character sets, and should end with 'utf-8' to handle messages that combine texts in multiple languages. sender An address that is put into the 'Sender:' field of outgoing messages. This field needs not normally be present. It is, however, required if the 'From:' field contains more than one address. It can also be used to indicate that a message was sent on behalf of somebody other; in this case, 'From:' should contain the address of the person that took responsibility for the message, and 'Sender:' should contain the address of the person that actually sent the message. The sender address is handled as if it were in the alternates list. sendmail To use an alternate mail delivery system, set this option to the full pathname of the program to use. This should be used with care. SHELL Pathname of the shell to use in the ! command and the ~! escape. A default shell is used if this option is not defined. Sign A string for use with the ~A command. sign A string for use with the ~a command. signature Must correspond to the name of a readable file if set. The file's content is then appended to each singlepart message and to the first part of each multipart message. Be warned that there is no possibility to edit the signature for an individual message. smime-ca-dir Specifies a directory with CA certificates for verification of S\/MIME signed messages. The format is the same as described in ssl_ctx_load_verify_locations(3). Only applicable if S\/MIME support is built using OpenSSL. smime-ca-file Specifies a file with CA certificates for verification of S\/MIME signed messages. The format is the same as described in ssl_ctx_load_verify_locations(3). Only applicable if S\/MIME support is built using OpenSSL. smime-cipher- user@host Specifies a cipher to use when generating S\/MIME encrypted messages for user@host. Valid ciphers are rc2-40 (RC2 with 40 bits), rc2-64 (RC2 with 64 bits), des (DES, 56 bits) and des-ede3 (3DES, 112\/168 bits). The default is 3DES. It is not recommended to use the other ciphers unless a recipient's client is actually unable to handle 3DES since they are comparatively weak; but even so, the recipient should upgrade his software in preference. smime-crl-file Specifies a file that contains a CRL in PEM format to use when verifying S\/MIME messages. Only applicable if S\/MIME support is built using OpenSSL. smime-crl-dir Specifies a directory that contains files with CRLs in PEM format to use when verifying S\/MIME messages. Only applicable if S\/MIME support is built using OpenSSL. smime-encrypt- user@host If this variable is set, messages to user@host are encrypted before sending. If S\/MIME support is built using OpenSSL, the value of the variable must be set to the name of a file that contains a certificate in PEM format. If S\/MIME support is built using NSS, the value of this variable is ignored, but if multiple certificates for user@host are available, the smime-nickname-user@host variable should be set. Otherwise a certificate for the recipient is automatically retrieved from the certificate database, if possible. If a message is sent to multiple recipients, each of them for whom a corresponding variable is set will receive an individually encrypted message; other recipients will continue to receive the message in plain text unless the smime-force-encryption variable is set. It is recommended to sign encrypted messages, i.e. to also set the smime-sign variable. smime-nickname- user@host Specifies the nickname of a certificate to be used when encrypting messages for user@host . Only applicable if S\/MIME support is built using NSS. smime-sign-cert Points to a file in PEM format that contains the user's private key as well as his certificate. Both are used with S\/MIME for signing and decrypting messages. Only applicable if S\/MIME support is built using OpenSSL. smime-sign-cert- user@host Overrides smime-sign-cert for the specific addresses. When signing messages and the value of the from variable is set to user@host, the specific file is used. When decrypting messages, their recipient fields (To: and Cc:) are searched for addresses for which such a variable is set. Mailx always uses the first address that matches, so if the same message is sent to more than one of the user's addresses using different encryption keys, decryption might fail. Only applicable if S\/MIME support is built using OpenSSL. smime-sign-nickname Specifies that the named certificate be used for signing mail. If this variable is not set, but a single certificate matching the current from address is found in the database, that one is used automatically. Only applicable if S\/MIME support is built using NSS. smime-sign-nickname- user@host Overrides smime-sign-nickname for a specific address. Only applicable if S\/MIME support is built using NSS. smtp Normally, mailx invokes sendmail(8) directly to transfer messages. If the smtp variable is set, a SMTP connection to the server specified by the value of this variable is used instead. If the SMTP server does not use the standard port, a value of server:port can be given, with port as a name or as a number. There are two possible methods to get SSL\/TLS encrypted SMTP sessions: First, the STARTTLS command can be used to encrypt a session after it has been initiated, but before any user-related data has been sent; see smtp-use-starttls above. Second, some servers accept sessions that are encrypted from their beginning on. This mode is configured by assigning smtps:\/\/ server[ : port] to the smtp variable. The SMTP transfer is executed in a child process; unless either the sendwait or the verbose variable is set, this process runs asynchronously. If it receives a TERM signal, it will abort and save the message to the 'dead.letter' file. smtp-auth Sets the SMTP authentication method. If set to 'login', or if unset and smtp-auth-user is set, AUTH LOGIN is used. If set to 'cram-md5', AUTH CRAM-MD5 is used; if set to 'plain', AUTH PLAIN is used. Otherwise, no SMTP authentication is performed. smtp-auth- user @ host Overrides smtp-auth for specific values of sender addresses, depending on the from variable. smtp-auth-password Sets the global password for SMTP AUTH. Both user and password have to be given for AUTH LOGIN and AUTH CRAM-MD5. smtp-auth-password- user @ host Overrides smtp-auth-password for specific values of sender addresses, depending on the from variable. smtp-auth-user Sets the global user name for SMTP AUTH. Both user and password have to be given for AUTH LOGIN and AUTH CRAM-MD5. If this variable is set but neither smtp-auth-password or a matching smtp-auth-password-user@host can be found, mailx will as for a password on the user's terminal. smtp-auth-user- user @ host Overrides smtp-auth-user for specific values of sender addresses, depending on the from variable. ssl-ca-dir Specifies a directory with CA certificates for verification of SSL\/TLS server certificates. See ssl_ctx_load_verify_locations(3) for more information. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-ca-file Specifies a file with CA certificates for verification of SSL\/TLS server certificates. See ssl_ctx_load_verify_locations(3) for more information. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-cert Sets the file name for a SSL\/TLS client certificate required by some servers. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-cert- user @ host Sets an account-specific file name for a SSL\/TLS client certificate required by some servers. Overrides ssl-cert for the specified account. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-cipher-list Specifies a list of ciphers for SSL\/TLS connections. See ciphers(1) for more information. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-crl-file Specifies a file that contains a CRL in PEM format to use when verifying SSL\/TLS server certificates. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-crl-dir Specifies a directory that contains files with CRLs in PEM format to use when verifying SSL\/TLS server certificates. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-key Sets the file name for the private key of a SSL\/TLS client certificate. If unset, the name of the certificate file is used. The file is expected to be in PEM format. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-key- user @ host Sets an account-specific file name for the private key of a SSL\/TLS client certificate. Overrides ssl-key for the specified account. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-method Selects a SSL\/TLS protocol version; valid values are 'ssl2', 'ssl3', and 'tls1'. If unset, the method is selected automatically, if possible. ssl-method- user @ host Overrides ssl-method for a specific account. ssl-rand-egd Gives the pathname to an entropy daemon socket, see rand_egd(3). ssl-rand-file Gives the pathname to a file with entropy data, see rand_load_file(3). If the file is a regular file writable by the invoking user, new data is written to it after it has been loaded. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-verify Sets the action to be performed if an error occurs during SSL\/TLS server certificate validation. Valid values are 'strict' (fail and close connection immediately), 'ask' (ask whether to continue on standard input), 'warn' (print a warning and continue), 'ignore' (do not perform validation). The default is 'ask'. ssl-verify- user @ host Overrides ssl-verify for a specific account. toplines If defined, gives the number of lines of a message to be printed out with the top command; normally, the first five lines are printed. ttycharset The character set of the terminal mailx operates on. There is normally no need to set this variable since mailx can determine this automatically by looking at the LC_CTYPE locale setting; if this succeeds, the value is assigned at startup and will be displayed by the set command. Note that this is not necessarily a character set name that can be used in Internet messages. VISUAL Pathname of the text editor to use in the visual command and ~v escape.","Process Name":"mailx","Link":"https:\/\/linux.die.net\/man\/1\/mailx"}},{"Process":{"Description":"The purpose of the make utility is to determine automatically which pieces of a large program need to be recompiled, and issue the commands to recompile them. The manual describes the GNU implementation of make, which was written by Richard Stallman and Roland McGrath, and is currently maintained by Paul Smith. Our examples show C programs, since they are most common, but you can use make with any programming language whose compiler can be run with a shell command. In fact, make is not limited to programs. You can use it to describe any task where some files must be updated automatically from others whenever the others change. To prepare to use make, you must write a file called the makefile that describes the relationships among files in your program, and the states the commands for updating each file. In a program, typically the executable file is updated from object files, which are in turn made by compiling source files. Once a suitable makefile exists, each time you change some source files, this simple shell command: make suffices to perform all necessary recompilations. The make program uses the makefile data base and the last-modification times of the files to decide which of the files need to be updated. For each of those files, it issues the commands recorded in the data base. make executes commands in the makefile to update one or more target names, where name is typically a program. If no -f option is present, make will look for the makefiles GNUmakefile, makefile, and Makefile, in that order. Normally you should call your makefile either makefile or Makefile. (We recommend Makefile because it appears prominently near the beginning of a directory listing, right near other important files such as README.) The first name checked, GNUmakefile, is not recommended for most makefiles. You should use this name if you have a makefile that is specific to GNU make, and will not be understood by other versions of make. If makefile is '-', the standard input is read. make updates a target if it depends on prerequisite files that have been modified since the target was last modified, or if the target does not exist.","Process Name":"make","Link":"https:\/\/linux.die.net\/man\/1\/make"}},{"Process":{"Description":null,"Process Name":"make-lingua-identify-language","Link":"https:\/\/linux.die.net\/man\/1\/make-lingua-identify-language"}},{"Process":{"Description":"","Process Name":"make2build","Link":"https:\/\/linux.die.net\/man\/1\/make2build"}},{"Process":{"Description":"make_encmap creates a XML encmap file with a given name from an Unicode mapping file, received e.g. from ftp:\/\/ftp.unicode.org. The result by default is output to stdout.","Process Name":"make_encmap","Link":"https:\/\/linux.die.net\/man\/1\/make_encmap"}},{"Process":{"Description":null,"Process Name":"make_method","Link":"https:\/\/linux.die.net\/man\/1\/make_method"}},{"Process":{"Description":"make_services builds a validated cache of service information for use by programs that want to access the GNUstep services facility. Additionally, it builds a list of applications and service bundles found in the standard directories. This cache is usually stored in the file named .GNUstepServices in the user's GNUstep directory. Most commonly, make_services is called from within the GNUstep.sh or GNUstep.csh script to update the service information everytime the GNUstep environmet is set up, i.e. in a login script. But of course it is possible to run make_services from the command line whenever you wish, for example after having installed a new application or service. The Services menu in an application's mainmenu is usually updated automatically. However, it may be neccessary to close an open or torn off menu for the changes to appear. Also, the workspace manager may have to be closed and restarted for file association changes to take effect.","Process Name":"make_services","Link":"https:\/\/linux.die.net\/man\/1\/make_services"}},{"Process":{"Description":"This utility creates a bootable FAT filesystem and populates it with files and boot tools. It is mainly designed to create bootable USB and Fixed disk for the AdvanceCD project. The official site of AdvanceCD and makebootfat is: http:\/\/advancemame.sourceforge.net\/","Process Name":"makebootfat","Link":"https:\/\/linux.die.net\/man\/1\/makebootfat"}},{"Process":{"Description":null,"Process Name":"makecert","Link":"https:\/\/linux.die.net\/man\/1\/makecert"}},{"Process":{"Description":"makeconv converts the ICU converter table convertertable into a binary file. The binary file has the same base name as convertertable but has a .cnv extension (instead of the typical .ucm extension of the convertertable file). This binary file can then be read directly by ICU, or used by pkgdata(1) for incorporation into a larger archive or library. The convertertable must be in the ICU ucm (Unicode Codepage Mapping) format in order to be understood by makeconv. The ICU ucm format is similar to the IBM NLTC upmap\/tpmap\/rpmap files. Comments in the convertable are handled as follows. If a comment (starting with a '#' sign) that is after some text does contain the fallback indicator '|' then only the text starting with the '#' sign, and ending before the '|' sign, is ignored. Otherwise, or if the comment is the first thing on the line, the comment runs up to the end of the line. This special handling of comments is to accomodate the practice of putting fallback information in comments in the strict IBM NLTC ucmap format. Note that new converters will be automatically found by ICU after their installation in ICU's data directory. They do not need to be listed in the convrtrs.txt(5) converters aliases file in order to be available to applications using ICU. They do need to be listed there if one wants to give them aliases, or tags, though.","Process Name":"makeconv","Link":"https:\/\/linux.die.net\/man\/1\/makeconv"}},{"Process":{"Description":"makecpt is a utility that will help you make color palette tables (cpt files). You define an equidistant set of contour intervals or pass your own z-table, and create a new cpt file based on an existing master cpt file. The resulting cpt file can be reversed relative to the master cpt, and can be made continuous or discrete. The color palette includes three additional colors beyond the range of z-values. These are the background color (B) assigned to values lower than the lowest z-value, the foreground color (F) assigned to values higher than the highest z-value, and the NaN color (N) painted whereever values are undefined. If the master cpt file includes B, F, and N entries, these will be copied into the new master file. If not, the parameters COLOR_BACKGROUND, COLOR_FOREGROUND, and COLOR_NAN from the .gmtdefaults4 file or the command line will be used. This default behavior can be overruled using the options -D, -M or -N. The color model (RGB, HSV or CMYK) of the palette created by makecpt will be the same as specified in the header of the master cpt file. When there is no COLOR_MODEL entry in the master cpt file, the COLOR_MODEL specified in the .gmtdefaults4 file or on the command line will be used.","Process Name":"makecpt","Link":"https:\/\/linux.die.net\/man\/1\/makecpt"}},{"Process":{"Description":null,"Process Name":"makedepend","Link":"https:\/\/linux.die.net\/man\/1\/makedepend"}},{"Process":{"Description":"makedepf90 is a program for automatic creation of dependency lists and compilation rules for Makefiles. The original idea was to provide the same functionality for Fortran as gcc -MM *.c does for C. Nowadays makedepf90 actually supersedes this functionality, making me wonder if I should extend makedepf90 to support C and C++ too ;-). makedepf90 supports both modules, include:s, cpp(1) #include:s, f90ppr(1) $include:s and coco(1) ??includes and set-files. makedepf90 reads Fortran source files given on the command line, and writes a dependency list to stdout; for every file it writes a line with the following format: targets : prerequisites Targets are the files that will be the result of compiling the file with the -c option, and prerequisites are files that are needed to compile the file. In addition, makedepf90 can optionally create the dependency line and make-rule needed to link the final executable. Fortran dependencies The files needed to compile a file, i.e the prerequisites of the file are: - The source file itself - Files with interface information about USEd modules, created by the compiler while compiling the modules (often named modulename.mod or something similar, hereafter called mod-files). - Include-files (including files included and mod-files of modules USEd from these include-files). - Coco set-files, if coco(1) is being used and set-files exist. Since different compilers use different naming conventions for the mod-files, listing them in the dependency list results in non-portable makefiles. Therefore it's common practise to list the object file ( filename.o) corresponding to the sourcefile containing the USEd modules instead. This is the default behaviour of makedepf90. To change this, use the -m option (e.g -m \"%m.mod\" if your compiler names the mod files modulename.mod) Include files not found in the working directory will not be listed in the dependency list, assuming they are part of a (seldom changing) library not part of the program. Neither will mod-files of modules whose definitions aren't found be listed by the same reason.","Process Name":"makedepf90","Link":"https:\/\/linux.die.net\/man\/1\/makedepf90"}},{"Process":{"Description":null,"Process Name":"makeg","Link":"https:\/\/linux.die.net\/man\/1\/makeg"}},{"Process":{"Description":"The program makeindex is a general purpose hierarchical index generator; it accepts one or more input files (often produced by a text formatter such as TeX (tex(1L)) or troff(1), sorts the entries, and produces an output file which can be formatted. The index can have up to three levels (0, 1, and 2) of subitem nesting. The way in which words are flagged for indexing within the main document is specific to the formatter used; makeindex does not automate the process of selecting these words. As the output index is hierarchical, makeindex can be considered complimentary to the awk(1)-based make.index(1L) system of Bentley and Kernighan, which is specific to troff(1), generates non-hierarchical indices, and employs a much simpler syntax for indicating index entries. For illustration of use with troff and TeX, see the section EXAMPLES below. The formats of the input and output files are specified in a style file; by default, input is assumed to be a .idx file, as generated by LaTeX. Unless specified explicitly, the base name of the first input file (idx0) is used to determine the names of other files. For each input file name specified, a file of that name is sought. If this file is not found and the file name has no extension, the extension .idx is appended. If no file with this name is found, makeindex aborts. If exactly one input file was given and no explicit style file was specified using -s, makeindex uses a file with the extension .mst as default style file (when present). For important notes on how to select index keywords, see the document by Lamport cited below. As an issue separate from selecting index keywords, a systematic mechanism for placing index terms in a document is suggested in Index Preparation and Processing, a paper cited below.","Process Name":"makeindex","Link":"https:\/\/linux.die.net\/man\/1\/makeindex"}},{"Process":{"Description":null,"Process Name":"makeinfo","Link":"https:\/\/linux.die.net\/man\/1\/makeinfo"}},{"Process":{"Description":"makeivs is a tool designed to generate an IVS dump file with an inputed WEP key. The aim of is tools is to provide a way to create dumps with a known encryption key for tests.","Process Name":"makeivs","Link":"https:\/\/linux.die.net\/man\/1\/makeivs"}},{"Process":{"Description":"This manual page is not meant to be exhaustive. The complete documentation for this version of TeX can be found in the info file or manual Web2C: A TeX implementation. If mpxfile is older than mpfile, translate the labels from the MetaPost input file mpfile to low-level commands in MPXFILE, by running mpto -tex, tex, and dvitomp by default; or, if -troff is specified, mpto -troff, eqn -d\\$\\$ | troff -Tpost, and dmp. The current directory is used for writing temporary files. Errors are left in mpxerr.{tex,log,dvi}. If the file named in $MPTEXPRE (mptexpre.tex by default) exists, it is prepended to the output in tex mode. makempx is typically called by mpost, not from the command line.","Process Name":"makempx","Link":"https:\/\/linux.die.net\/man\/1\/makempx"}},{"Process":{"Description":null,"Process Name":"makempy","Link":"https:\/\/linux.die.net\/man\/1\/makempy"}},{"Process":{"Description":null,"Process Name":"makepage","Link":"https:\/\/linux.die.net\/man\/1\/makepage"}},{"Process":{"Description":"makepattern reads either a Sun 1-bit rasterfile OR a Sun icon file. It then accepts color choices for the foreground and background pixels and colorizes the pattern, writing it as a 8-bit Sun rasterfile on stdout. These patterns may then be used in GMT (3.1 or later) -Gp settings or by psimage. 1bit.ras | iconfile Either a 1-bit Sun rasterfile (standard format, no RLE) or a Sun icon file (as used in GMT 3.0). -Cf Sets the color for the foreground pixels (the ones) [black]. -Cb Sets the color for the background pixels (the zeros) [white].","Process Name":"makepattern","Link":"https:\/\/linux.die.net\/man\/1\/makepattern"}},{"Process":{"Description":null,"Process Name":"makepsres","Link":"https:\/\/linux.die.net\/man\/1\/makepsres"}},{"Process":{"Description":null,"Process Name":"makesimple","Link":"https:\/\/linux.die.net\/man\/1\/makesimple"}},{"Process":{"Description":"makeskel scans a Free Pascal unit source file and generates a skeleton description file for it. It generates nodes for all identifiers found in the interface section of the unit, although this behaviour can be adjusted with some options. It can also update an existing XML file, and then emits only nodes for identifiers for which no node exists yet.","Process Name":"makeskel","Link":"https:\/\/linux.die.net\/man\/1\/makeskel"}},{"Process":{"Description":null,"Process Name":"makestrs","Link":"https:\/\/linux.die.net\/man\/1\/makestrs"}},{"Process":{"Description":"makeswf is a command line interface to the Ming library actionscript compiler. Bytecode resulting from compilation of each given source file will be stored in a separate frame of the output.","Process Name":"makeswf","Link":"https:\/\/linux.die.net\/man\/1\/makeswf"}},{"Process":{"Description":"The generaterecords script generates a zone file, given a domain name, which is then signed and modified to invalidate portions of the data in particular ways. Each generated record is named appropriately to how the security data is modified (the gooda record will contain a A record with valid DNSSEC data, but the badseca record will contain an A record where the signature has been modified to invalidate it). The results of this process can then be served and test secure validators, applications, and other software can be thrown at it to see if they properly fail or succeed under the dns security policies being deployed. After the files are generated, consider running donuts on them to see how the data in them has been tampered with to be invalid.","Process Name":"maketestzone","Link":"https:\/\/linux.die.net\/man\/1\/maketestzone"}},{"Process":{"Description":null,"Process Name":"maketexpk","Link":"https:\/\/linux.die.net\/man\/1\/maketexpk"}},{"Process":{"Description":"The \"maketext\" script translates a natural language message into the user's language, by looking up the translation in a message MO file, and process the plural transformation with Maketext. The \"maketext\" script is a command-line interface to Locale::Maketext::Gettext(3) (and Locale::Maketext(3)). It can be used in shell scripts, etc, to translate, maketext and return the result. By this way, it enables Maketext to be integrated into other programming languages\/systems, like bash\/csh, python, PHP , C, etc. It works like the command-line program gettext. For example: % maketext -s \"[*,_1,virus was,viruses were] found in [*,_2,file,files].\" 0 1\n0 viruses were found in 1 file.\n% maketext -s \"[*,_1,virus was,viruses were] found in [*,_2,file,files].\" 1 3\n1 virus was found in 3 files.\n%","Process Name":"maketext","Link":"https:\/\/linux.die.net\/man\/1\/maketext"}},{"Process":{"Description":null,"Process Name":"maketx","Link":"https:\/\/linux.die.net\/man\/1\/maketx"}},{"Process":{"Description":null,"Process Name":"makeweb","Link":"https:\/\/linux.die.net\/man\/1\/makeweb"}},{"Process":{"Description":"Malaga is a development environment for natural-language grammars based on the Left-Associative Grammar formalism. Malaga grammars can be used for automatic morphological and\/or syntactic analysis. The program malaga is Malaga's user interface for analysing word forms and sentences, displaying the results and finding bugs in a grammar. malaga requires the name of a language-dependent project-file as a command-line argument. If no command line options are given, malaga starts in interactive mode, and you can enter commands. If you are not sure about the name of a command, use the command help to get an overview of all malaga commands. If you want to quit malaga, enter the command quit. See info Malaga for details.","Process Name":"malaga","Link":"https:\/\/linux.die.net\/man\/1\/malaga"}},{"Process":{"Description":"Malaga is a development environment for natural-language grammars based on the Left-Associative Grammar formalism. Malaga grammars can be used for automatic morphological and\/or syntactic analysis. The program mallex generates a Malaga run-time lexicon by letting allomorph rules process a base-form lexicon. It can be started in interactive mode to help find bugs in the base-form lexicon or in the allomorph rules. mallex uses the following grammar components: symbol-file The symbol-file has the suffix .sym and contains the symbols that are used in the lexicon and\/or the allomorph rules. rule-file The rule-file has the suffix .all and contains the allomorph rules used to create the runtime-lexicon. lexicon-file The lexicon-file has the suffix .lex and contains the base-form lexicon entries that are used as input for the allomorph rules. prelex-file (optional) The prelex-file has the suffix .prelex and contains precompiled allomorph entries, which have been created by a former run of mallex with the option -prelex. You can give the names of the grammar components as command line arguments, in any order. Alternatively, you can describe these components in a project-file and use the name of the project file as mallex' single command-line argument. A project file has the suffix .pro. If no command line options are given, mallex runs in interactive mode, and you can enter commands. The lexicon-file and prelex-file are not used in interactive mode. If you are not sure about the name of a command, use the command help to get an overview of all mallex commands. If you want to quit mallex, enter the command quit. See info Malaga for details.","Process Name":"mallex","Link":"https:\/\/linux.die.net\/man\/1\/mallex"}},{"Process":{"Description":"Malaga is a development environment for natural-language grammars based on the Left-Associative Grammar formalism. Malaga grammars can be used for automatic morphological and\/or syntactic analysis. The program malmake reads a project file, checks if all grammar files needed do exist, and translates all grammar files that have not yet been translated or whose source files have changed since they have been translated. It calls the programs malsym(1), mallex(1) and malrul(1) if needed. It is in essence a make(1) for the Malaga programming language. See info Malaga for details.","Process Name":"malmake","Link":"https:\/\/linux.die.net\/man\/1\/malmake"}},{"Process":{"Description":"Malaga is a development environment for natural-language grammars based on the Left-Associative Grammar formalism. Malaga grammars can be used for automatic morphological and\/or syntactic analysis. The program malrul compiles a Malaga rule file. Give it the rule file that is to be translated (suffix .mor, .syn or .all) and the associated symbol file (suffix .sym or .esym) as command-line arguments. The order of the arguments is arbitrary. See info Malaga for details.","Process Name":"malrul","Link":"https:\/\/linux.die.net\/man\/1\/malrul"}},{"Process":{"Description":"Malaga is a development environment for natural-language grammars based on the Left-Associative Grammar formalism. Malaga grammars can be used for automatic morphological and\/or syntactic analysis. The program malshow is usually called by malaga(1) or mallex(1). It's a GUI to display their results and\/or debugging states. malshow reads the data to display from standard input. See info Malaga for details.","Process Name":"malshow","Link":"https:\/\/linux.die.net\/man\/1\/malshow"}},{"Process":{"Description":"Malaga is a development environment for natural-language grammars based on the Left-Associative Grammar formalism. Malaga grammars can be used for automatic morphological and\/or syntactic analysis. The program malsym compiles a Malaga symbol file. Give it the symbol file (suffix .sym or .esym) that is to be translated as argument. If an extended-symbol-file (suffix .esym) is to be compiled, you must add the option -use. See info Malaga for details.","Process Name":"malsym","Link":"https:\/\/linux.die.net\/man\/1\/malsym"}},{"Process":{"Description":"man formats and displays the on-line manual pages. If you specify section, man only looks in that section of the manual. name is normally the name of the manual page, which is typically the name of a command, function, or file. However, if name contains a slash (\/) then man interprets it as a file specification, so that you can do man .\/foo.5 or even man \/cd\/foo\/bar.1.gz. See below for a description of where man looks for the manual page files.","Process Name":"man","Link":"https:\/\/linux.die.net\/man\/1\/man"}},{"Process":{"Description":"man2html converts a manual page as found in file (or stdin, in case no file argument, or the argument \"-\", is given) from man-style nroff into html, and prints the result on stdout. It does support tbl but does not know about eqn. The exit status is 0. If something goes wrong, an error page is printed on stdout. This can be used as a stand-alone utility, but is mainly intended as an auxiliary, to enable users to browse their man pages using a html browser like lynx(1), xmosaic(1) or netscape(1). The main part of man2html is the troff-to-html engine written by Richard Verhoeven (rcb5@win.tue.nl). It adds hyperlinks for the following constructs: (The first of these can be tuned by options - see below.) No lookup is done - the links generated need not exist. Also an index with internal hyperlinks to the various sections is generated, so that it is easier to find one's way in large man pages like bash(1).","Process Name":"man2html","Link":"https:\/\/linux.die.net\/man\/1\/man2html"}},{"Process":{"Description":"manhole is a GTK interface to Twisted Manhole services. You can execute python code as if at an interactive Python console inside a running Twisted process with this.","Process Name":"manhole","Link":"https:\/\/linux.die.net\/man\/1\/manhole"}},{"Process":{"Description":"manpage-alert searches the given list of paths for binaries without corresponding manpages. If no paths are specified on the command line, the path list \/bin \/sbin \/usr\/bin \/usr\/sbin \/usr\/games will be assumed.","Process Name":"manpage-alert","Link":"https:\/\/linux.die.net\/man\/1\/manpage-alert"}},{"Process":{"Description":"man formats and displays the on-line manual pages. If you specify section, man only looks in that section of the manual. name is normally the name of the manual page, which is typically the name of a command, function, or file. However, if name contains a slash (\/) then man interprets it as a file specification, so that you can do man .\/foo.5 or even man \/cd\/foo\/bar.1.gz. See below for a description of where man looks for the manual page files.","Process Name":"manpath","Link":"https:\/\/linux.die.net\/man\/1\/manpath"}},{"Process":{"Description":"manweb displays reference documentation via quick shell commands. It is a replacement for the well-known man.","Process Name":"manweb","Link":"https:\/\/linux.die.net\/man\/1\/manweb"}},{"Process":{"Description":"Maps text from one character set representation to another. This work is actually long time very well done by \"recode\", but unfortunately recode does not support Unicode and eastern asia character sets. But, if you have pure 8 bit things to do, recode will still be the best solution. Examples: Conversion from ISO-8859-1 to Unicode: map --to unicode < iso-8859-1.txt > unicode.txt Conversion from GB2312 to CP936: map --from cp936 --to GB2312 < gb2312.txt > cp936.txt Conversion from CP850 to Unicode: map --from cp850 --to unicode < cp850.txt > unicode.txt","Process Name":"map","Link":"https:\/\/linux.die.net\/man\/1\/map"}},{"Process":{"Description":"","Process Name":"mapfile","Link":"https:\/\/linux.die.net\/man\/1\/mapfile"}},{"Process":{"Description":"mapiprofile is a command line tool designed to provide administrative support for OpenChange MAPI profiles. A profile in this context represents a single user's connection to a server. It can be thought of as a user's account information stored on the client side. Most OpenChange utilities make use of the profile information stored in the local profile database, often by referring to the name of the profile. In addition, because most users only have a single account, it is possible to designate one profile as the default profile. If a profile is not specified, other utilities will use the default profile (if any) to establish a connection. mapiprofile is designed so it also provides sample code for developers interested in adding OpenChange MAPI profile support to their applications.","Process Name":"mapiprofile","Link":"https:\/\/linux.die.net\/man\/1\/mapiprofile"}},{"Process":{"Description":"mapitest is a test harness \/ utility used for verifying correct operation of various ExchangeRPC calls \/ MAPI functions provided by the OpenChange MAPI libraries. mapitest is not normally required by users, but you may be asked to provide the output of mapitest for some kinds of bug investigations. Note that mapitest performs a lot of transactions, including deleting folders and messages. Unless you're very familiar with mapitest, we recommend only using it with a test account.","Process Name":"mapitest","Link":"https:\/\/linux.die.net\/man\/1\/mapitest"}},{"Process":{"Description":"This application creates a graphical map of one or more zone files. The output gives a graphical representation of a DNS zone or zones. The output is written in the PNG format. The result can be useful for getting a more intuitive view of a zone or set of zones. It is extremely useful for visualizing DNSSEC deployment within a given zone as well as to help discover problem spots.","Process Name":"mapper","Link":"https:\/\/linux.die.net\/man\/1\/mapper"}},{"Process":{"Description":"mapproject reads (longitude, latitude) positions from infiles [or standard input] and computes (x,y) coordinates using the specified map projection and scales. Optionally, it can read (x,y) positions and compute (longitude, latitude) values doing the inverse transformation. This can be used to transform linear (x,y) points obtained by digitizing a map of known projection to geographical coordinates. May also calculate distances along track, to a fixed point, or closest approach to a line. Finally, can be used to perform various datum conversions. Additional data fields are permitted after the first 2 columns which must have (longitude,latitude) or (x,y). See option -: on how to read (latitude,longitude) files. infiles Data file(s) to be transformed. If not given, standard input is read. -J Selects the map projection. The following character determines the projection. If the character is upper case then the argument(s) supplied as scale(s) is interpreted to be the map width (or axis lengths), else the scale argument(s) is the map scale (see its definition for each projection). UNIT is cm, inch, or m, depending on the MEASURE_UNIT setting in .gmtdefaults4, but this can be overridden on the command line by appending c, i, or m to the scale or width values. Append h, +, or - to the given width if you instead want to set map height, the maximum dimension, or the minimum dimension, respectively [Default is w for width]. In case the central meridian is an optional parameter and it is being omitted, then the center of the longitude range given by the -R option is used. The default standard parallel is the equator. The ellipsoid used in the map projections is user-definable by editing the .gmtdefaults4 file in your home directory. 73 commonly used ellipsoids and spheroids are currently supported, and users may also specify their own custum ellipsoid parameters [Default is WGS-84]. Several GMT parameters can affect the projection: ELLIPSOID, INTERPOLANT, MAP_SCALE_FACTOR, and MEASURE_UNIT; see the gmtdefaults man page for details. Choose one of the following projections (The E or C after projection names stands for Equal-Area and Conformal, respectively): CYLINDRICAL PROJECTIONS: -Jc lon0\/lat0\/scale or -JC lon0\/lat0\/width (Cassini). Give projection center lon0\/lat0 and scale ( 1: xxxx or UNIT\/degree). -Jcyl_stere\/[ lon0\/[ lat0\/]] scale or -JCyl_stere\/[ lon0\/[ lat0\/]] width (Cylindrical Stereographic). Give central meridian lon0 (optional), standard parallel lat0 (optional), and scale along parallel ( 1: xxxx or UNIT\/degree). The standard parallel is typically one of these (but can be any value): 66.159467 - Miller's modified Gall 55 - Kamenetskiy's First 45 - Gall's Stereographic 30 - Bolshoi Sovietskii Atlas Mira or Kamenetskiy's Second 0 - Braun's Cylindrical -Jj[ lon0\/] scale or -JJ[ lon0\/] width (Miller Cylindrical Projection). Give the central meridian lon0 (optional) and scale ( 1: xxxx or UNIT\/degree). -Jm[ lon0\/[ lat0\/]] scale or -JM[ lon0\/[ lat0\/]] width Give central meridian lon0 (optional), standard parallel lat0 (optional), and scale along parallel ( 1: xxxx or UNIT\/degree). -Jo parameters (Oblique Mercator [C]). Specify one of: -Jo[ a] lon0\/lat0\/azimuth\/scale or -JO[ a] lon0\/lat0\/azimuth\/width Set projection center lon0\/lat0, azimuth of oblique equator, and scale. -Jo[ b] lon0\/lat0\/lon1\/lat1\/scale or -JO[ b] lon0\/lat0\/lon1\/lat1\/scale Set projection center lon0\/lat0, another point on the oblique equator lon1\/lat1, and scale. -Joc lon0\/lat0\/lonp\/latp\/scale or -JOc lon0\/lat0\/lonp\/latp\/scale Set projection center lon0\/lat0, pole of oblique projection lonp\/latp, and scale. Give scale along oblique equator (1:xxxx or UNIT\/degree). -Jq[ lon0\/[ lat0\/]] scale or -JQ[ lon0\/[ lat0\/]] width (Cylindrical Equidistant). Give the central meridian lon0 (optional), standard parallel lat0 (optional), and scale ( 1: xxxx or UNIT\/degree). The standard parallel is typically one of these (but can be any value): 61.7 - Grafarend and Niermann, minimum linear distortion 50.5 - Ronald Miller Equirectangular 43.5 - Ronald Miller, minimum continental distortion 42 - Grafarend and Niermann 37.5 - Ronald Miller, minimum overall distortion 0 - Plate Carree, Simple Cylindrical, Plain\/Plane Chart -Jt lon0\/[ lat0\/] scale or -JT lon0\/[ lat0\/] width Give the central meridian lon0, central parallel lat0 (optional), and scale ( 1: xxxx or UNIT\/degree). -Ju zone\/scale or -JU zone\/width (UTM - Universal Transverse Mercator [C]). Give the UTM zone (A,B,1-60[C-X],Y,Z)) and scale ( 1: xxxx or UNIT\/degree). Zones: If C-X not given, prepend - or + to enforce southern or northern hemisphere conventions [northern if south > 0]. -Jy[ lon0\/[ lat0\/]] scale or -JY[ lon0\/[ lat0\/]] width (Cylindrical Equal-Area [E]). Give the central meridian lon0 (optional), standard parallel lat0 (optional), and scale ( 1: xxxx or UNIT\/degree). The standard parallel is typically one of these (but can be any value): 50 - Balthasart 45 - Gall-Peters 37.0666 - Caster 37.4 - Trystan Edwards 37.5 - Hobo-Dyer 30 - Behrman 0 - Lambert (default) CONIC PROJECTIONS: -Jb lon0\/lat0\/lat1\/lat2\/scale or -JB lon0\/lat0\/lat1\/lat2\/width (Albers [E]). Give projection center lon0\/lat0, two standard parallels lat1\/lat2, and scale ( 1: xxxx or UNIT\/degree). -Jd lon0\/lat0\/lat1\/lat2\/scale or -JD lon0\/lat0\/lat1\/lat2\/width (Conic Equidistant) Give projection center lon0\/lat0, two standard parallels lat1\/lat2, and scale ( 1: xxxx or UNIT\/degree). -Jl lon0\/lat0\/lat1\/lat2\/scale or -JL lon0\/lat0\/lat1\/lat2\/width (Lambert [C]) Give origin lon0\/lat0, two standard parallels lat1\/lat2, and scale along these ( 1: xxxx or UNIT\/degree). -Jpoly\/[ lon0\/[ lat0\/]] scale or -JPoly\/[ lon0\/[ lat0\/]] width ((American) Polyconic). Give the central meridian lon0 (optional), reference parallel lat0 (optional, default = equator), and scale along central meridian ( 1: xxxx or UNIT\/degree). AZIMUTHAL PROJECTIONS: Except for polar aspects, -Rw\/e\/s\/n will be reset to -Rg. Use -R<...>r for smaller regions. -Ja lon0\/lat0[ \/horizon] \/scale or -JA lon0\/lat0[ \/horizon] \/width (Lambert [E]). lon0\/lat0 specifies the projection center. horizon specifies the max distance from projection center (in degrees, <= 180, default 90). Give scale as 1: xxxx or radius\/lat, where radius is distance in UNIT from origin to the oblique latitude lat. -Je lon0\/lat0[ \/horizon] \/scale or -JE lon0\/lat0[ \/horizon] \/width (Azimuthal Equidistant). lon0\/lat0 specifies the projection center. horizon specifies the max distance from projection center (in degrees, <= 180, default 180). Give scale as 1: xxxx or radius\/lat, where radius is distance in UNIT from origin to the oblique latitude lat. -Jf lon0\/lat0[ \/horizon] \/scale or -JF lon0\/lat0[ \/horizon] \/width (Gnomonic). lon0\/lat0 specifies the projection center. horizon specifies the max distance from projection center (in degrees, < 90, default 60). Give scale as 1: xxxx or radius\/lat, where radius is distance in UNIT from origin to the oblique latitude lat. -Jg lon0\/lat0[ \/horizon] \/scale or -JG lon0\/lat0[ \/horizon] \/width (Orthographic). lon0\/lat0 specifies the projection center. horizon specifies the max distance from projection center (in degrees, <= 90, default 90). Give scale as 1: xxxx or radius\/lat, where radius is distance in UNIT from origin to the oblique latitude lat. -Jg lon0\/lat0\/altitude\/azimuth\/tilt\/twist\/Width\/Height\/scale or -JG lon0\/lat0\/altitude\/azimuth\/tilt\/twist\/Width\/Height\/width (General Perspective). lon0\/lat0 specifies the projection center. altitude is the height (in km) of the viewpoint above local sea level. If altitude is less than 10, then it is the distance from the center of the earth to the viewpoint in earth radii. If altitude has a suffix r then it is the radius from the center of the earth in kilometers. azimuth is measured to the east of north of view. tilt is the upward tilt of the plane of projection. If tilt is negative, then the viewpoint is centered on the horizon. Further, specify the clockwise twist, Width, and Height of the viewpoint in degrees. Give scale as 1: xxxx or radius\/lat, where radius is distance in UNIT from origin to the oblique latitude lat. -Js lon0\/lat0[ \/horizon] \/scale or -JS lon0\/lat0[ \/horizon] \/width (General Stereographic [C]). lon0\/lat0 specifies the projection center. horizon specifies the max distance from projection center (in degrees, < 180, default 90). Give scale as 1: xxxx (true at pole) or lat\/ 1: xxxx (true at standard parallel lat0) or radius\/lat ( radius in UNIT from origin to the oblique latitude lat). Note if 1: xxxx is used then to specify horizon you must also specify the lat0 as +-90 to avoid ambiguity. MISCELLANEOUS PROJECTIONS: -Jh[ lon0\/] scale or -JH[ lon0\/] width (Hammer [E]). Give the central meridian lon0 (optional) and scale along equator ( 1: xxxx or UNIT\/degree). -Ji[ lon0\/] scale or -JI[ lon0\/] width (Sinusoidal [E]). Give the central meridian lon0 (optional) and scale along equator ( 1: xxxx or UNIT\/degree). -Jkf[ lon0\/] scale or -JKf[ lon0\/] width (Eckert IV) [E]). Give the central meridian lon0 (optional) and scale along equator ( 1: xxxx or UNIT\/degree). -Jk[ s][ lon0\/] scale or -JK[ s][ lon0\/] width (Eckert VI) [E]). Give the central meridian lon0 (optional) and scale along equator ( 1: xxxx or UNIT\/degree). -Jn[ lon0\/] scale or -JN[ lon0\/] width (Robinson). Give the central meridian lon0 (optional) and scale along equator ( 1: xxxx or UNIT\/degree). -Jr[ lon0\/] scale -JR[ lon0\/] width (Winkel Tripel). Give the central meridian lon0 (optional) and scale along equator ( 1: xxxx or UNIT\/degree). -Jv[ lon0\/] scale or -JV[ lon0\/] width (Van der Grinten). Give the central meridian lon0 (optional) and scale along equator ( 1: xxxx or UNIT\/degree). -Jw[ lon0\/] scale or -JW[ lon0\/] width (Mollweide [E]). Give the central meridian lon0 (optional) and scale along equator ( 1: xxxx or UNIT\/degree). NON-GEOGRAPHICAL PROJECTIONS: -Jp[ a] scale[ \/origin][ r| z] or -JP[ a] width[ \/origin][ r| z] (Polar coordinates (theta,r)) Optionally insert a after -Jp [ or -JP] for azimuths CW from North instead of directions CCW from East [Default]. Optionally append \/ origin in degrees to indicate an angular offset [0]). Finally, append r if r is elevations in degrees (requires s >= 0 and n <= 90) or z if you want to annotate depth rather than radius [Default]. Give scale in UNIT\/r-unit. -Jx x-scale[ \/y-scale] or -JX width[ \/height] (Linear, log, and power scaling) Give x-scale ( 1: xxxx or UNIT\/x-unit) and\/or y-scale ( 1: xxxx or UNIT\/y-unit); or specify width and\/or height in UNIT. y-scale= x-scale if not specified separately and using 1: xxxx implies that x-unit and y-unit are in meters. Use negative scale(s) to reverse the direction of an axis (e.g., to have y be positive down). Set height or width to 0 to have it recomputed based on the implied scale of the other axis. Optionally, append to x-scale, y-scale, width or height one of the following: d Data are geographical coordinates (in degrees). l Take log10 of values before scaling. p power Raise values to power before scaling. t Input coordinates are time relative to TIME_EPOCH. T Input coordinates are absolute time. Default axis lengths (see gmtdefaults) can be invoked using -JXh (for landscape); -JXv (for portrait) will swap the x- and y-axis lengths. The default unit for this installation is either cm or inch, as defined in the file share\/gmt.conf. However, you may change this by editing your .gmtdefaults4 file(s). -R xmin, xmax, ymin, and ymax specify the Region of interest. For geographic regions, these limits correspond to west, east, south, and north and you may specify them in decimal degrees or in [+-]dd:mm[:ss.xxx][W|E|S|N] format. Append r if lower left and upper right map coordinates are given instead of w\/e\/s\/n. The two shorthands -Rg and -Rd stand for global domain (0\/360 and -180\/+180 in longitude respectively, with -90\/+90 in latitude). Alternatively, specify the name of an existing grid file and the -R settings (and grid spacing, if applicable) are copied from the grid. For calendar time coordinates you may either give (a) relative time (relative to the selected TIME_EPOCH and in the selected TIME_UNIT; append t to -JX| x), or (b) absolute time of the form [ date] T[ clock] (append T to -JX| x). At least one of date and clock must be present; the T is always required. The date string must be of the form [-]yyyy[-mm[-dd]] (Gregorian calendar) or yyyy[-Www[-d]] (ISO week calendar), while the clock string must be of the form hh:mm:ss[.xxx]. The use of delimiters and their type and positions must be exactly as indicated (however, input, output and plot formats are customizable; see gmtdefaults). Special case for the UTM projection: If -C is used and -R is not given then the region is set to coincide with the given UTM zone so as to preserve the full ellipsoidal solution (See RESTRICTIONS for more information).","Process Name":"mapproject","Link":"https:\/\/linux.die.net\/man\/1\/mapproject"}},{"Process":{"Description":"","Process Name":"marcdump","Link":"https:\/\/linux.die.net\/man\/1\/marcdump"}},{"Process":{"Description":"The markdown utility reads the markdown(7)-formatted textfile (or stdin if not specified,) compiles it, and writes the html output to stdout. The options are as follows:        -b url-base Links in source beginning with \/ will be prefixed with url-base in the output. -C' When processing markdown extra-style footnotes, use the given prefix instead of the default of fn. -d' Instead of writing the html file, dump a parse tree to stdout. -f flags Set or clear various translation flags. The flags are in a comma-delimited list, with an optional + (enable), - (disable), or no (disable) lprefix on each flag. links' Allow links. image' Allow images. smarty' Enable smartypants. pants' Enable smartypants. html' Allow raw html. strict' Disable superscript, strikethrough & relaxed emphasis. ext' Enable pseudo-protocols. cdata' Generate code for xml ![CDATA[...]]. superscript' Enable superscript processing. emphasis' Emphasis happens everywhere. tables' Don't process PHP Markdown Extra tables. del' Enable ~~strikethrough~~. strikethrough Enable ~~strikethrough~~. toc' Enable table-of-contents processing. 1.0' Compatibility with MarkdownTest_1.0 autolink' Make http:\/\/foo.com a link even without <>. safelink' Paranoid check for link protocol. header' Process pandoc-style header blocks. tabstop' Expand tabs to 4 spaces. divquote' Allow >%class% blocks. alphalist' Allow alphabetic lists. definitionlist Allow definition lists. footnote' Allow markdown extra-style footnotes. As an example, the option -f nolinks,smarty tells markdown to not allow <a tags, and to do smarty pants processing. -F bitmap Set translation flags. Bitmap is a bit map of the various configuration options described in markdown(3) (the flag values are defined in mkdio.h) -V' Show the version# and compile-time configuration data. If the version includes the string DEBUG, markdown was configured with memory allocation debugging. If the version includes the string TAB, markdown was configured to use the specified tabstop. -VV' Show the version#, the compile-time configuration, and the run-time configuration. -o file Write the generated html to file. -t text Use mkd_text(3) to format text instead of processing stdin with the markdown(3) function. -T' If run with the table-of-content flag on, dump the table of contents before the formatted text. -s text Use the markdown(3) function to format text.","Process Name":"markdown","Link":"https:\/\/linux.die.net\/man\/1\/markdown"}},{"Process":{"Description":"masktest is a utility for detecting differences in behaviour between Samba's own implementation and that of a remote server. It will run generate random filenames\/masks and check if these match the same files they do on the remote file as they do on the local server. It will display any differences it finds. This utility is used by the Samba team to find differences in behaviour between Samba and Windows servers.","Process Name":"masktest","Link":"https:\/\/linux.die.net\/man\/1\/masktest"}},{"Process":{"Description":"","Process Name":"math","Link":"https:\/\/linux.die.net\/man\/1\/math"}},{"Process":{"Description":"This manual page documents briefly the math2oogl command. math2oogl converts Mathematica graphics objects, read from standard input, to OOGL format, written to standard output. SurfaceGraphics and MeshGraphics objects are converted to an OOGL MESH; a Graphics3D object is converted to OFF; and a BezierPatch is converted to a BEZuvn. Note that we expect the graphics objects to have been processed as in OOGL.m, i.e. provide dimension and meshrange information and print out the colors before the points for SurfaceGraphics objects, and convert the characters \"(){}, \" to a newline.","Process Name":"math2oogl","Link":"https:\/\/linux.die.net\/man\/1\/math2oogl"}},{"Process":{"Description":"Mathomatic is a portable Computer Algebra System (CAS) that can symbolically solve, simplify, combine, and compare equations, perform general complex number and polynomial arithmetic, etc. It does some calculus and handles all elementary algebra, except logarithms. This program is an interactive symbolic-numeric mathematics interpreter. The numerical arithmetic is double precision floating point with up to 14 decimal digits accuracy. Many results will be exact. Mathomatic is entirely hand-written in the C programming language. It does not permit extremely large expressions, which can take too much memory and time. Instead reliability, ease of use, and speed are its features.","Process Name":"mathomatic","Link":"https:\/\/linux.die.net\/man\/1\/mathomatic"}},{"Process":{"Description":"Mattrib is used to change MS-DOS file attribute flags. It has the following syntax: mattrib [-a|+a] [-h|+h] [-r|+r] [-s|+s] [-\/] [-p] [-X] msdosfile [ msdosfiles ... ] Mattrib adds attribute flags to an MS-DOS file (with the '+' operator) or remove attribute flags (with the '-' operator). Mattrib supports the following attribute bits: a Archive bit. Used by some backup programs to indicate a new file. r Read-only bit. Used to indicate a read-only file. Files with this bit set cannot be erased by DEL nor modified. s System bit. Used by MS-DOS to indicate a operating system file. h Hidden bit. Used to make files hidden from DIR. Mattrib supports the following command line flags: \/ Recursive. Recursively list the attributes of the files in the subdirectories. X Concise. Prints the attributes whithout any whitespace padding. If neither the \"\/\" option is given, nor the msdosfile contains a wildcard, and there is only one Msdos file parameter on the command line, only the attribute is printed, and not the filename. This option is convenient for scripts p Replay mode. Outputs a series of mformat commands that will reproduce the current situation, starting from a situation as left by untarring the Dos filesystem. Commands are only output for attribute settings that differ from the default (archive bit set for files, unset for directories). This option is intended to be used in addition to tar. The readonly attribute is not taken into account, as tar can set that one itself.","Process Name":"mattrib","Link":"https:\/\/linux.die.net\/man\/1\/mattrib"}},{"Process":{"Description":"mawk is an interpreter for the AWK Programming Language. The AWK language is useful for manipulation of data files, text retrieval and processing, and for prototyping and experimenting with algorithms. mawk is a new awk meaning it implements the AWK language as defined in Aho, Kernighan and Weinberger, The AWK Programming Language, Addison-Wesley Publishing, 1988 (hereafter referred to as the AWK book.) mawk conforms to the Posix 1003.2 (draft 11.3) definition of the AWK language which contains a few features not described in the AWK book, and mawk provides a small number of extensions. An AWK program is a sequence of pattern {action} pairs and function definitions. Short programs are entered on the command line usually enclosed in ' ' to avoid shell interpretation. Longer programs can be read in from a file with the -f option. Data input is read from the list of files on the command line or from standard input when the list is empty. The input is broken into records as determined by the record separator variable, RS. Initially, RS = \"\\n\" and records are synonymous with lines. Each record is compared against each pattern and if it matches, the program text for {action} is executed.","Process Name":"mawk","Link":"https:\/\/linux.die.net\/man\/1\/mawk"}},{"Process":{"Description":"Maxima is a version of the MIT-developed MACSYMA system, modified to run under . It is an interactive expert system and programming environment for symbolic and numerical mathematical manipulation. Written in i, it allows differentiation, integration, solution of linear or polynomial equations, factoring of polynomials, expansion of functions in Laurent or Taylor series, computation of Poisson series, matrix and tensor manipulations, and two- and three-dimensional graphics. Procedures may be written using an ALGOL-like syntax, and both i-like functions and pattern matching facilities are provided. Files containing Maxima objects may be read from and written to disk files. Pre-written Maxima commands may be read from a file and executed, allowing batch-mode use.","Process Name":"maxima","Link":"https:\/\/linux.die.net\/man\/1\/maxima"}},{"Process":{"Description":"The maze program creates a \"random\" maze and then solves it with graphical feedback.","Process Name":"maze","Link":"https:\/\/linux.die.net\/man\/1\/maze"}},{"Process":{"Description":"The mbadblocks command is used to scan an MS-DOS floppy and mark its unused bad blocks as bad. It uses the following syntax: mbadblocks drive: Mbadblocks scans an MS-DOS floppy for bad blocks. All unused bad blocks are marked as such in the FAT. This is intended to be used right after mformat. It is not intended to salvage bad disks.","Process Name":"mbadblocks","Link":"https:\/\/linux.die.net\/man\/1\/mbadblocks"}},{"Process":{"Description":"Check if the format of FILE complies with the Multiboot Specification. -q, --quiet suppress all normal output -h, --help display this help and exit -v, --version output version information and exit.","Process Name":"mbchk","Link":"https:\/\/linux.die.net\/man\/1\/mbchk"}},{"Process":{"Description":"MBK_CATA_LIB sets the directories that are to be searched thru for reading. When instanciating a cell for example, the first cell that is found with the given name is loaded in memory. The seaching mecanism first look in mbk_work_lib(1), and then, in path1 thru pathn, in the order defined by the user when typing the setenv command. This directories are considered to be, from a mbk point of view, read only. The pathi arguments must be actually accessible pathes on your host machine.","Process Name":"mbk_cata_lib","Link":"https:\/\/linux.die.net\/man\/1\/mbk_cata_lib"}},{"Process":{"Description":"MBK_CATAL_NAME sets the name of the catalog file, that contains information about the cells of a design. The catalog file syntax is a cellname, plus a flag. The cellname may appear many times with a different flag. Three flags are available: C : tells the flatten functions to stop a this level. G : informs the user that this is a phantom cell. F : says that this is a feed through. The seaching mecanism first look in mbk_work_lib(1), and then in mbk_cata_lib(1). So it is recommended to have a catalog file in the mbk_work_lib(1).","Process Name":"mbk_catal_name","Link":"https:\/\/linux.die.net\/man\/1\/mbk_catal_name"}},{"Process":{"Description":"MBK_CK sets the pattern to be matched in a name to indicate a clock for the tools based upon mbk. Its default value is ck. Therefore all names of the form '*ck*' indicates a clock.","Process Name":"mbk_ck","Link":"https:\/\/linux.die.net\/man\/1\/mbk_ck"}},{"Process":{"Description":"MBK_FILTER_SFX tells to Alliance the extention set by compression tools. This variable must be set in order to activate filters. Note the leading points of extention must be set if necessary.","Process Name":"mbk_filter_sfx","Link":"https:\/\/linux.die.net\/man\/1\/mbk_filter_sfx"}},{"Process":{"Description":"MBK_IN_FILTER set the input filter for reading compressed Alliance files. Filter is typically a string containing filename and options. This filter must read compressed data flow on it standard input and write non compressed data flow on it standard output. Files are taken in the first directory where they are found according to the environment variable MBK_CATA_LIB. If a file compressed version and a file non compressed version exist booth in the same directory, the non compressed is opended, and a warning message is supllyed. To activate filters, variable MBK_FILTER_SFX must be set.","Process Name":"mbk_in_filter","Link":"https:\/\/linux.die.net\/man\/1\/mbk_in_filter"}},{"Process":{"Description":"MBK_IN_LO sets the logical input format of the mbk database. The database will be filled with informations found in the given format file. valid formats are : - al, alx, that are alliance logical formats - edi, that is edif standart netlist format - hns, fns, fne, fdn, hdn, that are vti logical formats - spi, that's spice netlist - vst, that structural vhdl description","Process Name":"mbk_in_lo","Link":"https:\/\/linux.die.net\/man\/1\/mbk_in_lo"}},{"Process":{"Description":"MBK_IN_PH sets the physical input format of the mbk data structure. The data structure will be filled with informations found in the given format file. valid formats are : - ap, alliance physical format - cp, vti physical format","Process Name":"mbk_in_ph","Link":"https:\/\/linux.die.net\/man\/1\/mbk_in_ph"}},{"Process":{"Description":"MBK_OUT_FILTER sets the output filter for writting compressed Alliance files. Filter is typically a string containing filename and options. This filter must read non compressed data flow on it standard input and write compressed data flow on it standard output. If a non compressed version of a file exist in the same target directory the designer want the save a file's compressed version, to ensure that file will be read later and not the non compressed one, the non compressed file is DELETED. To activate filters, variable MBK_FILTER_SFX must be set.","Process Name":"mbk_out_filter","Link":"https:\/\/linux.die.net\/man\/1\/mbk_out_filter"}},{"Process":{"Description":"MBK_OUT_LO sets the logical output format of the mbk data structure. The files resulting of the work on mbk will have the given format. valid formats are : - al, alx, that are alliance logical formats - cct, that is genrad hilo netlist format - edi, that is edif standart netlist format - hns, fns, fne, fdn, hdn, that are vti logical formats - spi, that's spice netlist - vst, that is structural vhdl description","Process Name":"mbk_out_lo","Link":"https:\/\/linux.die.net\/man\/1\/mbk_out_lo"}},{"Process":{"Description":"MBK_OUT_PH sets the physical output format of the mbk data structure. The files resulting of the work on mbk will have the given format. valid formats are : - ap, for alliance physical output - cp, in order to obtain a vti physical file","Process Name":"mbk_out_ph","Link":"https:\/\/linux.die.net\/man\/1\/mbk_out_ph"}},{"Process":{"Description":"MBK_SEPAR sets the character that is to be used while concatening names, during a flatten, for example.","Process Name":"mbk_separ","Link":"https:\/\/linux.die.net\/man\/1\/mbk_separ"}},{"Process":{"Description":"If MBK_TRACE_GETENV is set to \"yes\", all alliance tools will print debug info to stdout each time a getenv() syscall is done.","Process Name":"mbk_trace_getenv","Link":"https:\/\/linux.die.net\/man\/1\/mbk_trace_getenv"}},{"Process":{"Description":"MBK_VDD sets the pattern to be matched in a name to indicate a power supply for the tools based upon mbk. Its default value is vdd. Therefore all names of the form '*vdd*' indicates a power supply.","Process Name":"mbk_vdd","Link":"https:\/\/linux.die.net\/man\/1\/mbk_vdd"}},{"Process":{"Description":"MBK_VSS sets the pattern to be matched in a name to indicate a ground node for the tools based upon Its default value is vss. Therefore all names of the form '*vss*' in indicates a ground node.","Process Name":"mbk_vss","Link":"https:\/\/linux.die.net\/man\/1\/mbk_vss"}},{"Process":{"Description":"MBK_WORK_LIB sets the directory where are saved the results of an invocation of mbk or genlib. This directory is considered to be, from an mbk point of view, read and write. Also, when a file is searched for reading, the first directory to be looked at is the MBK_WORK_LIB, and then the one defined in mbk_cata_lib(1). The unix path argument must be a actually accessible path on your host machine.","Process Name":"mbk_work_lib","Link":"https:\/\/linux.die.net\/man\/1\/mbk_work_lib"}},{"Process":{"Description":"This manual page documents briefly the mbrowse command. This manual page was written for the Debian distribution because the original program does not have a manual page. mbrowse is a SNMP MIB browser tool. It relies on GTK+ and net-snmp. It is able to display as a tree view the content of a MIB, and to query MIB objects on any machine through get, set and walk methods. It includes a search function, bookmarking of MIB entries, ability to support additional MIBs, ... Once mbrowse is open, it displays the MIB tree. You can browse this tree like any other one. Once you have selected a MIB object, you can get details about it by going in the Details page. Its SNMP identifier is also update on the fly in the Object Identifier field. You can also directly enter the object identifier, and the tree will be browsed to the right place. To query a SNMP object, select it, enter the host name (IP address or DNS entry) of the machine you want to query in the right field. Also enter the read community to get or walk a value, and the write community to set it. Click on the right button and the objects and their values will be displayed. By clicking the Search page, you can search MIb entries by MIB name or description. In the Options page, you can set a few general options: whether to save the session on exit of the program, set the style of the tree view, the version of SNMP to use, and a few SNMP-related values. You can also use bookmarks to quickly find SNMP objects. Select the object you want to save, and click on Add Bookmark in the Bookmark menu. You will be prompted a name and the bookmark will be added to the menu. You can now click it to be positioned on the object back. To delete a bookmark, click on Delete Bookmark, and then, click on the bookmark to delete. You can also import MIBs at runtime, by clicking Open MIB in the File menu. Select the MIB file in the dialog box and the values contained in the file will be integrated in the tree view. For this MIB to be automatically opened at startup, you must put the MIB file in net-nsmp MIB files directory (usually \/usr\/share\/snmp\/mibs on Debian [and also on Fedora]). Mbrowse will open the MIB at its next startup.","Process Name":"mbrowse","Link":"https:\/\/linux.die.net\/man\/1\/mbrowse"}},{"Process":{"Description":"mbsync is a command line application which synchronizes mailboxes; currently Maildir and IMAP4 mailboxes are supported. New messages, message deletions and flag changes can be propagated both ways; the operation set can be selected in a fine-grained manner. Synchronization is based on unique message identifiers (UIDs), so no identification conflicts can occur (as opposed to some other mail synchronizers). OTOH, mbsync is susceptible to UID validity changes (that should never happen, but see \"Compatibility\" in the README). Synchronization state is kept in one local text file per mailbox pair; multiple replicas of a mailbox can be maintained.","Process Name":"mbsync","Link":"https:\/\/linux.die.net\/man\/1\/mbsync"}},{"Process":{"Description":"GNU Midnight Commander is a directory browser\/file manager for Unix-like operating systems.","Process Name":"mc","Link":"https:\/\/linux.die.net\/man\/1\/mc"}},{"Process":{"Description":null,"Process Name":"mcabber","Link":"https:\/\/linux.die.net\/man\/1\/mcabber"}},{"Process":{"Description":"The mcat command is used to copy an entire disk image from or to the floppy device. It uses the following syntax: mcat [-w] drive: Mcat performs the same task as the unix cat command. It is included into the mtools package, since cat cannot access remote floppy devices offered by the mtools floppy daemon. Now it is possible to create boot floppies remotely. The default operation is reading. The output is written to stdout. If the -w option is specified, mcat reads a disk-image from stdin and writes it to the given device. Use this carefully! Because of the lowlevel nature of this command, it will happily destroy any data written before on the disk without warning!","Process Name":"mcat","Link":"https:\/\/linux.die.net\/man\/1\/mcat"}},{"Process":{"Description":null,"Process Name":"mcd","Link":"https:\/\/linux.die.net\/man\/1\/mcd"}},{"Process":{"Description":"mcedit is a link to mc, the main GNU Midnight Commander executable. Executing GNU Midnight Commander under this name requests staring the internal editor and opening the file specified on the command line. The editor is based on the terminal version of cooledit - standalone editor for X Window System.","Process Name":"mcedit","Link":"https:\/\/linux.die.net\/man\/1\/mcedit"}},{"Process":{"Description":"Establishes a set of RDMA multicast communication paths between nodes using the librdmacm, optionally transfers datagrams to receiving nodes, then tears down the communication.","Process Name":"mckey","Link":"https:\/\/linux.die.net\/man\/1\/mckey"}},{"Process":{"Description":null,"Process Name":"mclasserase","Link":"https:\/\/linux.die.net\/man\/1\/mclasserase"}},{"Process":{"Description":"mconfig can be used to edit .NET configuration files, by adding \"features\" (that is sets of xml statements) defined in one of the config files read by mconfig. The config file can also define layouts of default configuration files, which may be useful for bootstrapping your .NET projects. To see the list of recognized commands, default configuration files and features, run mconfig without passing any parameters.","Process Name":"mconfig","Link":"https:\/\/linux.die.net\/man\/1\/mconfig"}},{"Process":{"Description":"mcookie generates a 128-bit random hexadecimal number for use with the X authority system. Typical usage: xauth add :0 . 'mcookie' The \"random\" number generated is actually the output of the MD5 message digest fed with various pieces of random information: the current time, the process id, the parent process id, the contents of an input file (if -f is specified), and several bytes of information from the first of the following devices which is present: \/dev\/random, \/dev\/urandom, files in \/proc, \/dev\/audio.","Process Name":"mcookie","Link":"https:\/\/linux.die.net\/man\/1\/mcookie"}},{"Process":{"Description":"The mcopy command is used to copy MS-DOS files to and from Unix. It uses the following syntax:    mcopy [-bspanvmQT] [-D clash_option] sourcefile targetfile\n   mcopy [-bspanvmQT] [-D clash_option] sourcefile [ sourcefiles... ] targetdirectory\n   mcopy [-tnvm] MSDOSsourcefile\n Mcopy copies the specified file to the named file, or copies multiple files to the named directory. The source and target can be either MS-DOS or Unix files. The use of a drive letter designation on the MS-DOS files, 'a:' for example, determines the direction of the transfer. A missing drive designation implies a Unix file whose path starts in the current directory. If a source drive letter is specified with no attached file name (e.g. mcopy a: .), all files are copied from that drive. If only a single, MS-DOS source parameter is provided (e.g. \"mcopy a:foo.exe\"), an implied destination of the current directory ('.') is assumed. A filename of '-' means standard input or standard output, depending on its position on the command line. Mcopy accepts the following command line options: t Text file transfer. Mcopy translates incoming carriage return\/line feeds to line feeds when copying from Dos to Unix, and vice-versa when copying from Unix to Dos. b Batch mode. Optimized for huge recursive copies, but less secure if a crash happens during the copy. s Recursive copy. Also copies directories and their contents p Preserves the attributes of the copied files Q When mcopying multiple files, quits as soon as one copy fails (for example due to lacking storage space on the target disk) a Text (Ascii) file transfer. Mcopy translates incoming carriage return\/line feeds to line feeds. T Text (Ascii) file transfer with charset conversion. Differs from -a in the Mcopy also translates incoming PC-8 characters to ISO-8859-1 equivalents as far as possible. When reading DOS files, untranslatable characters are replaced by '#'; when writing DOS files, untranslatable characters are replaced by '.'. n No confirmation when overwriting Unix files. Mcopy doesn't warn the user when overwriting an existing Unix file. If the target file already exists, and the -n option is not in effect, mcopy asks whether to overwrite the file or to rename the new file ('name clashes') for details). In order to switch off confirmation for DOS files, use -o. m Preserve the file modification time. v Verbose. Displays the name of each file as it is copied.","Process Name":"mcopy","Link":"https:\/\/linux.die.net\/man\/1\/mcopy"}},{"Process":{"Description":"mcpp is a C\/C++ preprocessor with the highest conformance which implements C90, C99 and C++98. mcpp has plentiful diagnostics and many #pragmas. It is useful to check portability of your program, and also useful to debug complicated macro. This is a man-page for mcpp of compiler-independent-build.","Process Name":"mcpp","Link":"https:\/\/linux.die.net\/man\/1\/mcpp"}},{"Process":{"Description":null,"Process Name":"mcrypt","Link":"https:\/\/linux.die.net\/man\/1\/mcrypt"}},{"Process":{"Description":"mcs is the Mono C# compiler, an implementation of the ECMA-334 language specification. You can pass one or more options to drive the compiler, and a set of source files. Extra options or arguments can be provided in a response file. Response files are referenced by prepending the @ symbol to the response file name. The mcs compiler is used to compile against the 1.x profile and implements C# 1.0 and parts of C# 2.0 and C# 3.0 specification which do not depend on generics. The gmcs compiler is used to compile against the 2.0 profile and implements the complete C# 3.0 specification. The smcs compiler is used to compile against the Silverlight\/Moonlight profile. This profile is designed to be used for creating Silverlight\/Moonlight applications that will run on a web browser. The API exposed by this profile is a small subset of the 3.5 API (even if it is commonly referred as the 2.1 API, this API is a small subset of 2.0 with a few extensions). See the section on packages for more information. The Mono C# compiler accepts the same command line options that the Microsoft C# compiler does. Those options can start with a slash or a dash (\/checked is the same as -checked). Additionally some GNU-like options are supported, those begin with \"--\". All MCS-specific flags which are not available in the Microsoft C# compiler are available only with the GNU-style options. C# source files must end with a \".cs\" extension. Compilation of C# source code requires all the files that make up a library, module or executable to be provided on the command line. There is no support for partial compilation. To achieve the benefits of partial compilation, you should compile programs into their own assemblies, and later reference them with the \"-r\" flag. The Mono C# compiler generates images (.exe files) that contain CIL byte code that can be executed by any system that implements a Common Language Infrastructure virtual machine such as the Microsoft .NET runtime engine on Windows or the Mono runtime engine on Unix systems. Executables are not bound to a specific CPU or operating system. The Mono C# compiler by default only references three assemblies: mscorlib.dll, System.dll and System.Xml.dll. If you want to reference extra libraries you must manually specify them using the -pkg: command line option or the -r: command line option. Alternatively if you want to get all of the System libraries, you can use the -pkg:dotnet command line option.","Process Name":"mcs","Link":"https:\/\/linux.die.net\/man\/1\/mcs"}},{"Process":{"Description":"MCU 8051 IDE is tool for developing programs in assembly language and C languge (with SDCC) for micronstollers based on industrial standard MCS-51. It consist of editor with syntax highlight, auto completion, syntax validation and command line, compiler with support for macro-instructions (even macro in macro), simulator, scientific calculator, (rich) text editor for writing to do lists, hexadecimal editor and many other tools.","Process Name":"mcu8051ide","Link":"https:\/\/linux.die.net\/man\/1\/mcu8051ide"}},{"Process":{"Description":null,"Process Name":"mcview","Link":"https:\/\/linux.die.net\/man\/1\/mcview"}},{"Process":{"Description":"The digest functions output the message digest of a supplied file or files in hexadecimal form. They can also be used for digital signing and verification.","Process Name":"md2","Link":"https:\/\/linux.die.net\/man\/1\/md2"}},{"Process":{"Description":"The digest functions output the message digest of a supplied file or files in hexadecimal form. They can also be used for digital signing and verification.","Process Name":"md4","Link":"https:\/\/linux.die.net\/man\/1\/md4"}},{"Process":{"Description":null,"Process Name":"md5","Link":"https:\/\/linux.die.net\/man\/1\/md5"}},{"Process":{"Description":"Computes the hashes, or message digest, for any number of files while optionally recursively digging through the directory structure. Can also take a list of known hashes and display the filenames of input files whose hashes either do or do not match any of the known hashes. Errors are reported to standard error. If no FILES are specified, reads from standard input. -p <size> Piecewise mode. Breaks files into chunks before hashing. Chunks may be specified using multiplers b, k, m, g, t, p, or e. (Never let it be said that the author didn't plan ahead!) This mode cannot be used with the -z mode. -i|-I <size> Size threshold mode. Only hash files smaller than the given the threshold. In -i mode, simply omits those files larger than the threshold. In -I mode, displays all files, but uses asterisks for the hashes of files larger than the threshold. Sizes may be specified using multiplers b, k, m, g, t, p, or e. -r Enables recursive mode. All subdirectories are traversed. Please note that recursive mode cannot be used to examine all files of a given file extension. For example, calling md5deep -r *.txt will examine all files in directories that end in .txt. -e Displays a progress indicator and estimate of time remaining for each file being processed. Time estimates for files larger than 4GB are not available on Windows. This mode may not be used with th -p mode. -m <file> Enables matching mode. The file given should be a list of known hashes. The input files are examined one at a time, and only those files that match the list of known hashes are output. This flag may be used more than once to add multiple sets of known hashes. Acceptable formats for lists of known hashes are plain (such as those generated by md5deep or md5sum), Hashkeeper files, iLook, and the National Software Reference Library (NSRL) as produced by the National Institute for Standards in Technology. If standard input is used with the -m flag, displays \"stdin\" if the input matches one of the hashes in the list of known hashes. If the hash does not match, the program displays no output. This flag may not be used in conjunction with the -x, -X, or -A flags. See the section \"UNICODE SUPPORT\" below. -x <file> Same as the -m flag above, but does negative matching. That is, only those files NOT in the list of known hashes are displayed. This flag may not be used in conjunction with the -m, -M, or -a flags. See the section \"UNICODE SUPPORT\" below. -M and -X <file> Same as -m and -x above, but displays the hash for each file that does (or does not) match the list of known hashes. -a <hash> Adds a single hash to the list of known hashes used for matching mode, and if not already enabled, enables matching mode. Adding single hashes cannot, by itself, be used to print the hashes of matching files like the -M flag does. When used in conjunction with the -w flag, the filename displayed is just the hash submitted on the command line. This flag may not be used in conjunction with the -x, -X, or -A flags. -A <hash> Same as -a above, but does negative matching. This flag may not be used in conjunction with the -m, -M, or -A flags. -f <file> Takes a list of files to be hashed from the specified file. Each line is assumed to be a filename. This flag can only be used once per invocation. If it's used a second time, the second instance will clobber the first. -w During any of the matching modes (-m,-M,-x,or -X), displays the filename of the known hash that matched the input file. See the section \"UNICODE SUPPORT\" below. -t Display a timestamp in GMT with each result. On Windows this timestamp will be the file's creation time. On all other systems it should be the file's change time. -n During any of the matching modes (-m,-M,-x,or -X), displays only the filenames of any known hashes that were not matched by any of the input files. -s Enables silent mode. All error messages are supressed. -S Like silent mode, but still displays warnings on improperly formatted hashes in the list of known hashes. -z Enables file size mode. Prepends the hash with a ten digit representation of the size of each file processed. If the file size is greater than 9999999999 bytes (about 9.3GB) the program displays 9999999999 for the size. -q Quiet mode. File names are omitted from the output. -Z Produces output in Triage format. Each line contans the file's size, a tab, a hash of the first 512 bytes, a tab, the hash of the complete file, a tab, and the file name. These values are intended in increasing order of specificity. That is, two files with different sizes cannot possibly match. This is a fast comparison and should be done first. Next, two files with different partial hashes cannot possibly match. This is often faster than hashing the whole file. Finally, if those two pieces align, then it's worth reading and hashing the entire file. -0 Uses a NULL character (\/0) to terminate each line instead of a newline. Useful for processing filenames with strange characters. -l Enables relative file paths. Instead of printing the absolute path for each file, displays the relative file path as indicated on the command line. This flag may not be used in conjunction with the -b flag. -b Enables bare mode. Strips any leading directory information from displayed filenames. This flag may not be used in conjunction with the -l flag. -k Enables asterisk mode. An asterisk is inserted in lieu of a second space between the filename and the hash, just like md5sum in its binary (-b) mode. -c Enables comma separated values output, or CSV mode. This mode has the side effect of removing the 10 digit size limitation from -z mode. Also note that asterisks from -k mode are not displayed when in CSV mode. -o <bcpflsd> Enables expert mode. Allows the user specify which (and only which) types of files are processed. Directory processing is still controlled with the -r flag. The expert mode options allowed are: f - Regular files b - Block Devices c - Character Devices p - Named Pipes l - Symbolic Links s - Sockets d - Solaris Doors -h Show a help screen and exit. -v Show the version number and exit. -V Show copyright information and exit.","Process Name":"md5deep","Link":"https:\/\/linux.die.net\/man\/1\/md5deep"}},{"Process":{"Description":"Print or check MD5 (128-bit) checksums. With no FILE, or when FILE is -, read standard input. -b, --binary read in binary mode -c, --check read MD5 sums from the FILEs and check them -t, --text read in text mode (default) Note: There is no difference between binary and text mode option on GNU system. The following three options are useful only when verifying checksums: --quiet don't print OK for each successfully verified file --status don't output anything, status code shows success -w, --warn warn about improperly formatted checksum lines --help display this help and exit --version output version information and exit The sums are computed as described in RFC 1321. When checking, the input should be a former output of this program. The default mode is to print a line with checksum, a character indicating type ('*' for binary, ' ' for text), and name for each FILE.","Process Name":"md5sum","Link":"https:\/\/linux.die.net\/man\/1\/md5sum"}},{"Process":{"Description":null,"Process Name":"mdassembler","Link":"https:\/\/linux.die.net\/man\/1\/mdassembler"}},{"Process":{"Description":"This program is part of Netpbm(1). mdatopbm reads a MicroDesign file as input and Produces a PBM image as output. If you don't specify mdafile, mdatopbm takes its input from Standard Input.","Process Name":"mdatopbm","Link":"https:\/\/linux.die.net\/man\/1\/mdatopbm"}},{"Process":{"Description":null,"Process Name":"mdb-export","Link":"https:\/\/linux.die.net\/man\/1\/mdb-export"}},{"Process":{"Description":"mdb-schema is a utility program distributed with MDB Tools. It produces DDL (data definition language) output for the given database. This can be passed to another database to create a replica of the original access table format.","Process Name":"mdb-schema","Link":"https:\/\/linux.die.net\/man\/1\/mdb-schema"}},{"Process":{"Description":null,"Process Name":"mdb-sql","Link":"https:\/\/linux.die.net\/man\/1\/mdb-sql"}},{"Process":{"Description":"mdb-tables is a utility program distributed with MDB Tools. It produces a list of tables contained within an MDB database in a format suitable for use in shell scripts.","Process Name":"mdb-tables","Link":"https:\/\/linux.die.net\/man\/1\/mdb-tables"}},{"Process":{"Description":null,"Process Name":"mdb-ver","Link":"https:\/\/linux.die.net\/man\/1\/mdb-ver"}},{"Process":{"Description":"The digest functions output the message digest of a supplied file or files in hexadecimal form. They can also be used for digital signing and verification.","Process Name":"mdc2","Link":"https:\/\/linux.die.net\/man\/1\/mdc2"}},{"Process":{"Description":null,"Process Name":"mdconvert","Link":"https:\/\/linux.die.net\/man\/1\/mdconvert"}},{"Process":{"Description":"The mdel command is used to delete an MS-DOS file. Its syntax is: mdel [-v] msdosfile [ msdosfiles ...  ] Mdel deletes files on an MS-DOS filesystem. Mdel asks for verification prior to removing a read-only file.","Process Name":"mdel","Link":"https:\/\/linux.die.net\/man\/1\/mdel"}},{"Process":{"Description":"The mdeltree command is used to delete an MS-DOS file. Its syntax is: mdeltree [-v] msdosdirectory [msdosdirectories...] Mdeltree removes a directory and all the files and subdirectories it contains from an MS-DOS filesystem. An error occurs if the directory to be removed does not exist.","Process Name":"mdeltree","Link":"https:\/\/linux.die.net\/man\/1\/mdeltree"}},{"Process":{"Description":null,"Process Name":"mdir","Link":"https:\/\/linux.die.net\/man\/1\/mdir"}},{"Process":{"Description":"","Process Name":"mdoc","Link":"https:\/\/linux.die.net\/man\/1\/mdoc"}},{"Process":{"Description":"mdoc assemble creates .tree and .zip files from PATHS for use in the monodoc(1) documentation browser. The input files must have a supported format, specified with the --format option. The .tree and .zip files are copied into monodoc's sources directory, alongside a .source file which is used by monodoc(1) to specify where the documentation should be displayed. The .source file has the following format: <?xml version=\"1.0\"?>\n<monodoc>\n  <node label=\"LABEL\" name=\"PATH\" parent=\"PARENT\">\n    <node label=\"LABEL2\" name=\"PATH2\" \/>\n    <!-- ... -->\n  <\/node>\n  <source provider=\"PROVIDER\" basefile=\"BASEFILE\" path=\"PATH\" \/>\n  <!-- other <source\/> elements -->\n<\/monodoc> The \/monodoc\/node node is an optional node that specifies where in the monodoc tree the documentation should be displayed, and \/\/node elements may be nested to any depth to create trees. \/\/node\/@label is the label that will be displayed within the monodoc tree. \/\/node\/@name is the name of the monodoc tree node, and may be used as the value of the \/monodoc\/source\/@path value. \/\/node\/@parent is the node name to use as the parent node. $MONO_INSTALL_PREFIX\/lib\/monodoc\/monodoc.xml contains a list of such names, and this can be any \/\/node\/@name value. If the \/\/node\/@parent value isn't found, then it's inserted under the \"Various\" tree node. The \/monodoc\/source\/@provider attribute specifies which format provider should be used when reading the .tree and .zip files; this must correspond to one of the --format values. The \/monodoc\/source\/@basefile attribute specifies the filename prefix for the documentation files. This must be the same prefix as used with the --out parameter. There should be no filename extension on this value. The \/monodoc\/source\/@path attribute specifies the parent node in monodoc(1)'s tree view where the documentation will be inserted. See the $MONO_INSTALL_PREFIX\/lib\/monodoc\/monodoc.xml file for a list of PATH values (the \/\/node\/@name values), or it may be a \/\/node\/@name value in the same .source file. Once the BASEFILE.source has been written, the documentation can be installed so that monodoc(1) will display the documentation with the command: cp BASEFILE.source BASEFILE.tree BASEFILE.zip \\\n  'pkg-config monodoc --variable=sourcesdir'","Process Name":"mdoc-assemble","Link":"https:\/\/linux.die.net\/man\/1\/mdoc-assemble"}},{"Process":{"Description":"mdoc export-html creates HTML files from the mdoc(5)-formatted documentation XML files within DIRECTORIES.","Process Name":"mdoc-export-html","Link":"https:\/\/linux.die.net\/man\/1\/mdoc-export-html"}},{"Process":{"Description":"mdoc export-msxdoc creates Microsoft XML Documentation (as produced by csc \/doc) from the mdoc(5)-formatted documentation XML files within DIRECTORIES.","Process Name":"mdoc-export-msxdoc","Link":"https:\/\/linux.die.net\/man\/1\/mdoc-export-msxdoc"}},{"Process":{"Description":"mdoc update is responsible for the following: * Creating documentation stubs based on ASSEMBLIES. The stub-creation process will create new mdoc(5) XML files for each type within ASSEMBLIES, and provide documentation stubs for each member of those types. * Update documentation stubs based on ASSEMBLIES. Existing mdoc(5) documentation can be updated to reflect changes within ASSEMBLIES, such as added types and members, while preserving existing documentation. In some limited circumstances, renames will be tracked, minimizing the documentation burden when e.g. a parameter is renamed. mdoc update does not rely on documentation found within source code, though it can import XML Documentation Comments via the -i option. See mdoc(1) and mdoc(5) for more information.","Process Name":"mdoc-update","Link":"https:\/\/linux.die.net\/man\/1\/mdoc-update"}},{"Process":{"Description":"mdoc validate validates the specified PATHS against a specified format schema.","Process Name":"mdoc-validate","Link":"https:\/\/linux.die.net\/man\/1\/mdoc-validate"}},{"Process":{"Description":null,"Process Name":"mdu","Link":"https:\/\/linux.die.net\/man\/1\/mdu"}},{"Process":{"Description":"mdvalidator has been obsoleted by mdoc(1). See the mdoc-validate(1) man page. mdvalidator is a program that validates the specified FILES against the ECMA Documentation Schema. The Schema also supports the index.xml and namespace-name.xml files generated by monodocer , so all output produced by monodocer can be validated.","Process Name":"mdvalidater","Link":"https:\/\/linux.die.net\/man\/1\/mdvalidater"}},{"Process":{"Description":"\"ME.wrapper.pl\" is a command-line interface to \"Statistics::MaxEntropy\" and \"Statistics::Candidates\". The wrapper and its command line options provide an easy-to-use and transparent connection to the MaxEntropy modules. Below we explain the meaning of the options.","Process Name":"me.wrapper.pl","Link":"https:\/\/linux.die.net\/man\/1\/me.wrapper.pl"}},{"Process":{"Description":"The meanbias command compose a set of bias frames and makes one bias frame called 'master-bias'. Applying this function, you can achieve high quality correction frame and thus reducing the noise of a result. The bias correction is applied in advanced calibration scheme only, please refer to documentation about the calibration of CCD frames. All source frames must be in the FITS format and of same dimensions. The output file is written in the FITS format too.","Process Name":"meanbias","Link":"https:\/\/linux.die.net\/man\/1\/meanbias"}},{"Process":{"Description":null,"Process Name":"meandark","Link":"https:\/\/linux.die.net\/man\/1\/meandark"}},{"Process":{"Description":"","Process Name":"mech-dump","Link":"https:\/\/linux.die.net\/man\/1\/mech-dump"}},{"Process":{"Description":"med is a frame-level, metafile editor designed to resemble syntactically UNIX's sed(1) and ed(1). med operates on a copy of filename, called a buffer, and overwrites a file only when you issue the w (write) command. med provides line oriented editing commands to display or delete frames from the buffer, to move, copy or merge frames within the buffer, or to write frames from and read frames into the buffer. By default med reads in commands from standard input.","Process Name":"med","Link":"https:\/\/linux.die.net\/man\/1\/med"}},{"Process":{"Description":"The bibutils program set inter-converts between various bibliography formats using Library of Congress [1] 's Metadata Object Description Schema (MODS) [2] version 3.1. For example, one can convert RIS-format files to Bibtex by doing two transformations: RIS->MODS->Bibtex.","Process Name":"med2xml","Link":"https:\/\/linux.die.net\/man\/1\/med2xml"}},{"Process":{"Description":null,"Process Name":"mediatomb","Link":"https:\/\/linux.die.net\/man\/1\/mediatomb"}},{"Process":{"Description":"megatron is used to transform files from BinHex, MacBinary, AppleSingle, or netatalk style AppleDouble formats into MacBinary or netatalk style AppleDouble formats. The netatalk style AppleDouble format is the file format used by afpd, the netatalk Apple Filing Protocol (AppleShare) server. BinHex, MacBinary, and AppleSingle are commonly used formats for transferring Macintosh files between machines via email or file transfer protocols. megatron uses its name to determine what type of tranformation is being asked of it. If megatron is called as unhex , unbin or unsingle, it tries to convert file(s) from BinHex, MacBinary, or AppleSingle into AppleDouble format. BinHex is the format most often used to send Macintosh files by e-mail. Usually these files have an extension of \".hqx\". MacBinary is the format most often used by terminal emulators \"on the fly\" when transferring Macintosh files in binary mode. MacBinary files often have an extension of \".bin\". Some Macintosh LAN-based email packages use uuencoded AppleSingle format to \"attach\" or \"enclose\" files in email. AppleSingle files don't have a standard filename extension. If megatron is called as hqx2bin, single2bin, or macbinary, it will try to convert the file(s) from BinHex, AppleSingle, or AppleDouble into MacBinary. This last translation may be useful in moving Macintosh files from your afpd server to some other machine when you can't copy them from the server using a Macintosh for some reason. If megatron is called with any other name, it uses the default translation, namely unhex. If no source file is given, or if sourcefile is '-', and if the conversion is from a BinHex or MacBinary file, megatron will read from standard input. The filename used to store any output file is the filename that is encoded in the source file. MacBinary files are created with a \".bin\" extension. In the case of conflicts, the old file is overwritten!","Process Name":"megatron","Link":"https:\/\/linux.die.net\/man\/1\/megatron"}},{"Process":{"Description":"Compresses the specified files or standard input. Each file is replaced by a file with the extension .F, but only if the file got smaller. If no files are specified, the compression is applied to the standard input and is written to standard output regardless of the results. Compressed files can be restored to their original form by specifying the -d option, or by running melt or unfreeze (both linked to freeze), on the .F files or the standard input. If the output file exists, it will not be overwritten unless the -f flag is given. If -f is not specified and freeze is run in the foreground, the user is prompted as to whether the file should be overwritten. If the -g flag is given, a slightly less powerful (compression rate is 1.5% less), but somewhat faster heuristic is used. This flag can be used more than once (this mode is quite useful when freezing bitmaps) for additional speedup. If you want to improve compression rate at the cost of speed, use -x flag. It means \"maximum compression\" (the speed may degrade substantially when freezing bitmaps). If the -f flag is given, all files specified are replaced with .F files - even if the file didn't get smaller. When file names are given, the ownership (if run by root), modes, accessed and modified times are maintained between the file and its .F version. In this respect, freeze can be used for archival purposes, yet can still be used with make(1) after melting. The -c option causes the results of the freeze\/melt operation to be written to stdout; no files are changed. The fcat program is the same as specifying -c to melt (all files are unpacked and written to stdout). The -v (verbose) option causes the diagnostics (at the end of each file processing) to be printed to stderr, and the -vv option causes the progress indicator to be drawn to the same place. Type is a token preceded by a '+' or a '--', which defines the type of following files in the command string. An explicite definition of the file's type can give up to 2% of additional compression. The list of types is stored in file \/usr\/lib\/freeze.cnf. Types may be abbreviated while not ambigious. You can also determine values for the static Huffman table by using a list of 8 numbers separated by commas instead of type. Freeze uses the Lempel-Ziv algorithm on the first pass and the dynamic Huffman algorithm on the second one. The size of sliding window is 8K, and the maximum length of matched string is 256. The positions on the window are coded using a static Huffman table. A two byte magic number is prepended to the file to ensure that neither melting of random text nor refreezing of already frozen text are attempted. In addition, the characteristics of the static Huffman table being used during freeze is written to the file so that these characteristics may be adapted to concrete conditions. The amount of compression obtained depends on the size of the input file and the distribution of character substrings and their probabilities. Typically, text files, such as C programs, are reduced by 60-75%, executable files are reduced by 50%. Compression is generally much better than that achieved by LZW coding (as used in compress), or Huffman coding (pack), though takes more time to compute. If the -V (version) flag is given, the program's version number and compilation options are printed. The exit status is normally 0; if the last file gets bigger after freezing, the exit status is 2; if an error occurs, the exit status is 1.","Process Name":"melt","Link":"https:\/\/linux.die.net\/man\/1\/melt"}},{"Process":{"Description":"This manual page documents briefly the members commands. This manual page was written for the Debian GNU\/Linux distribution. members is a program that sends a space-separated list of secondary member names to its standard output.","Process Name":"members","Link":"https:\/\/linux.die.net\/man\/1\/members"}},{"Process":{"Description":null,"Process Name":"memcached","Link":"https:\/\/linux.die.net\/man\/1\/memcached"}},{"Process":{"Description":"memcat outputs to stdout the value a single or mutiple set of keys stored in a memcached(1) server. It is similar to the standard UNIX cat(1) utility. You can specify servers via the --servers option or via the environment variable \"MEMCACHED_SERVERS\". For a full list of operations run the tool with the --help option.","Process Name":"memcat","Link":"https:\/\/linux.die.net\/man\/1\/memcat"}},{"Process":{"Description":"memcp copies one or more files into memcached(1) servers. It is similar to the standard UNIX cp(1) command. The key names will be the names of the files, without any directory path part. You can specify servers via the --servers option or via the environment variable \"MEMCACHED_SERVERS\". If you specify neither of these, the final value in the command line list is the name of a server(s). For a full list of operations run the tool with the --help option.","Process Name":"memcp","Link":"https:\/\/linux.die.net\/man\/1\/memcp"}},{"Process":{"Description":null,"Process Name":"memdump","Link":"https:\/\/linux.die.net\/man\/1\/memdump"}},{"Process":{"Description":"memerror translate an error code from libmemcached(3) to a human readable string. For a full list of operations run the tool with the --help option.","Process Name":"memerror","Link":"https:\/\/linux.die.net\/man\/1\/memerror"}},{"Process":{"Description":null,"Process Name":"memflush","Link":"https:\/\/linux.die.net\/man\/1\/memflush"}},{"Process":{"Description":"memos is used to read your Palm Memos database and read\/write the entries to STDOUT, or to individual files on disk, in a directory you specify, one memo per file in that named directory.","Process Name":"memos","Link":"https:\/\/linux.die.net\/man\/1\/memos"}},{"Process":{"Description":null,"Process Name":"memprobe","Link":"https:\/\/linux.die.net\/man\/1\/memprobe"}},{"Process":{"Description":"memrm removes items, specified by key, from memcached(1) servers. You can specify servers via the --servers option or via the environment variable \"MEMCACHED_SERVERS\". For a full list of operations run the tool with the --help option.","Process Name":"memrm","Link":"https:\/\/linux.die.net\/man\/1\/memrm"}},{"Process":{"Description":"The memscroller program scrolls a dump of its own process memory across the screen in three windows at three different rates.","Process Name":"memscroller","Link":"https:\/\/linux.die.net\/man\/1\/memscroller"}},{"Process":{"Description":"memslap is a load generation and benchmark tool for memcached(1) servers. It simulates loads on memcached server clusters. You can specify servers via the --servers option or via the environment variable \"MEMCACHED_SERVERS\". For a full list of operations run the tool with the --help option.","Process Name":"memslap","Link":"https:\/\/linux.die.net\/man\/1\/memslap"}},{"Process":{"Description":"memstat dumps the state of memcached(1) servers. It displays all data to stdout. You can specify servers via the --servers option or via the environment variable \"MEMCACHED_SERVERS\". For a full list of operations run the tool with the --help option.","Process Name":"memstat","Link":"https:\/\/linux.die.net\/man\/1\/memstat"}},{"Process":{"Description":"mplayer is a movie player for Linux (runs on many other platforms and CPU architectures, see the documentation). It plays most MPEG\/VOB, AVI, ASF\/WMA\/WMV, RM, QT\/MOV\/MP4, Ogg\/OGM, MKV, VIVO, FLI, NuppelVideo, yuv4mpeg, FILM and RoQ files, supported by many native and binary codecs. You can watch VCD, SVCD, DVD, 3ivx, DivX 3\/4\/5, WMV and even H.264 movies, too. MPlayer supports a wide range of video and audio output drivers. It works with X11, Xv, DGA, OpenGL, SVGAlib, fbdev, AAlib, libcaca, DirectFB, Quartz, Mac OS X CoreVideo, but you can also use GGI, SDL (and all their drivers), VESA (on every VESA-compatible card, even without X11), some low-level card-specific drivers (for Matrox, 3dfx and ATI) and some hardware MPEG decoder boards, such as the Siemens DVB, Hauppauge PVR (IVTV), DXR2 and DXR3\/Hollywood+. Most of them support software or hardware scaling, so you can enjoy movies in fullscreen mode. MPlayer has an onscreen display (OSD) for status information, nice big antialiased shaded subtitles and visual feedback for keyboard controls. European\/ISO8859-1,2 (Hungarian, English, Czech, etc), Cyrillic and Korean fonts are supported along with 12 subtitle formats (MicroDVD, SubRip, OGM, SubViewer, Sami, VPlayer, RT, SSA, AQTitle, JACOsub, PJS and our own: MPsub) and DVD subtitles (SPU streams, VOBsub and Closed Captions). mencoder (MPlayer's Movie Encoder) is a simple movie encoder, designed to encode MPlayer-playable movies (see above) to other MPlayer-playable formats (see below). It encodes to MPEG-4 (DivX\/Xvid), one of the libavcodec codecs and PCM\/MP3\/VBRMP3 audio in 1, 2 or 3 passes. Furthermore it has stream copying abilities, a powerful filter system (crop, expand, flip, postprocess, rotate, scale, noise, RGB\/YUV conversion) and more. gmplayer is MPlayer with a graphical user interface. It has the same options as MPlayer, however they might not all work correctly due to conflicts with the configuration via the GUI (stored in gui.conf). In particular some options might be overwritten by settings in gui.conf while others might end up stored permanently in gui.conf. Usage examples to get you started quickly can be found at the end of this man page. Also see the HTML documentation!","Process Name":"mencoder","Link":"https:\/\/linux.die.net\/man\/1\/mencoder"}},{"Process":{"Description":"This draws the three-dimensional variant of the recursive Menger Gasket, a cube-based fractal object analagous to the Sierpinski Tetrahedron.","Process Name":"menger","Link":"https:\/\/linux.die.net\/man\/1\/menger"}},{"Process":{"Description":null,"Process Name":"merge","Link":"https:\/\/linux.die.net\/man\/1\/merge"}},{"Process":{"Description":null,"Process Name":"mergecap","Link":"https:\/\/linux.die.net\/man\/1\/mergecap"}},{"Process":{"Description":null,"Process Name":"mergelib","Link":"https:\/\/linux.die.net\/man\/1\/mergelib"}},{"Process":{"Description":"The mergelog program is a tool which merges by date http log files in 'Common Log Format'. The result is sent to the standard output. It is useful if you want to create a single log file for multiple hosts using round-robin DNS.","Process Name":"mergelog","Link":"https:\/\/linux.die.net\/man\/1\/mergelog"}},{"Process":{"Description":null,"Process Name":"mergelogs","Link":"https:\/\/linux.die.net\/man\/1\/mergelogs"}},{"Process":{"Description":"mergerepo is a program that allows you merge multiple repositories into a single repository while referring to the remote location for all packages.","Process Name":"mergerepo","Link":"https:\/\/linux.die.net\/man\/1\/mergerepo"}},{"Process":{"Description":"Mesg controls the access to your terminal by others. It's typically used to allow or disallow other users to write to your terminal (see write(1)).","Process Name":"mesg","Link":"https:\/\/linux.die.net\/man\/1\/mesg"}},{"Process":{"Description":null,"Process Name":"message_group","Link":"https:\/\/linux.die.net\/man\/1\/message_group"}},{"Process":{"Description":"meta is a simple front-end to Acme::MetaSyntactic. A few examples should make it easy to understand what it does and how it works: $ meta\nbaz\n$ meta batman\npowie\n$ meta donmartin 3\nkloong\nthoof_foing\nweeooweeeoooo\n$ meta -ws browser 4\narachne netscape voyager w3m In short, the default theme is \"foo\", the default count is 1, the default separator is $\/, but you can replace it by whitespace with --ws.","Process Name":"meta","Link":"https:\/\/linux.die.net\/man\/1\/meta"}},{"Process":{"Description":"This hack draws 2D metaballs to the screen by calculating the sum of the colors of all metaballs covering a pixel. Ported from the demo effects collection ( http:\/\/demo-effects.sourceforge.net)","Process Name":"metaballs","Link":"https:\/\/linux.die.net\/man\/1\/metaballs"}},{"Process":{"Description":"metacam supports all standard EXIF fields in addition to (known) vendor specific blocks from Nikon, Olympus and Canon.","Process Name":"metacam","Link":"https:\/\/linux.die.net\/man\/1\/metacam"}},{"Process":{"Description":null,"Process Name":"metacity","Link":"https:\/\/linux.die.net\/man\/1\/metacity"}},{"Process":{"Description":"This manual page documents briefly the metacity-message. This manual page was written for the Debian distribution because the original program does not have a manual page. metacity-message send a specified message to metacity(1).","Process Name":"metacity-message","Link":"https:\/\/linux.die.net\/man\/1\/metacity-message"}},{"Process":{"Description":"metacity-theme-viewer allows you to preview any installed Metacity theme. When designing a new Metacity theme, you can use metacity-theme-viewer to measure the performance of a window frame option, and to preview the option.","Process Name":"metacity-theme-viewer","Link":"https:\/\/linux.die.net\/man\/1\/metacity-theme-viewer"}},{"Process":{"Description":null,"Process Name":"metacity-window-demo","Link":"https:\/\/linux.die.net\/man\/1\/metacity-window-demo"}},{"Process":{"Description":"Use metaflac to list, add, remove, or edit metadata in one or more FLAC files. You may perform one major operation, or many shorthand operations at a time.","Process Name":"metaflac","Link":"https:\/\/linux.die.net\/man\/1\/metaflac"}},{"Process":{"Description":null,"Process Name":"metapage","Link":"https:\/\/linux.die.net\/man\/1\/metapage"}},{"Process":{"Description":"This manual page documents briefly the metapixel and metapixel-prepare commands. For more information check the README file included in the distribution. metapixel is a program for generating photomosaics. It can generate classical photomosaics, in which the source image is viewed as a matrix of equally sized rectangles for each of which a matching image is substitued, as well as collage-style photomosaics, in which rectangular parts of the source image at arbitrary positions (i.e. not aligned to a matrix) are substituted by matching images. metapixel-prepare is a utility that needs to be run before metapixel can be used. It prepares your source images so that they can be used by metapixel to create the actual photomosaic.","Process Name":"metapixel","Link":"https:\/\/linux.die.net\/man\/1\/metapixel"}},{"Process":{"Description":"The 'mev' program is part of the gpm package. The information below is extracted from the texinfo file, which is the preferred source of information. The mev program is modeled after xev. It prints to stdout the mouse console events it gets. mev's default behaviour is to get anything, but command line switches can be used to set the various fields in the Gpm_Connect structure, in order to customize the program's behaviour. I'm using mev to handle mouse events to Emacs. Command line switches for mev are the following: -C number Select a virtual console to get events from. This is intended to be used for debugging. -d number Choose a default mask. By default the server gets any events not belonging to the event mask. The mask can be provided either as a decimal number, or as a symbolic string. -e number Choose the event mask. By default any event is received. The mask can be provided either as a decimal number, or as a symbolic string. -E Enter emacs mode. In emacs mode events are reported as lisp forms rather than numbers. This is the format used by the t-mouse package within emacs. -f Fit events inside the screen before reporting them. This options re-fits drag events, which are allowed to exit the screen border, -i Interactive. Accepts input from stdin to change connection parameters. -m number Choose the minimum modifier mask. Any event with fewer modifiers will not be reported to mev. It defaults to 0. The mask must be provided either as a decimal number, or as a symbolic string. -M number Choose the maximum modifier mask. Any event with more modifier than specified will not be reported to mev. It defaults to ~0, i.e. all events are received. The mask must be provided either as a decimal number, or as a symbolic string. -p Requests to draw the pointer during drags. This option is used by emacs to avoid invoking ioctl() from lisp code. When the arguments are not decimal integers, they are considered lists of alphanumeric characters, separated by a single non-alphanumeric character. I use the comma (,), but any will do. Allowed names for events are move, drag, down or press, up or release, motion (which is both move and drag), and hard. Allowed names for modifiers are shift, leftAlt, rightAlt, anyAlt (one or the other), control. When the -i switch is specified, mev looks at its standard input as command lines rather than events. The input lines are parsed, and the commands push and pop are recognized. The push command, then, accepts the options -d, -e, -m and -M, with the same meaning described above. Unspecified options retain the previous value and the resulting masks are used to reopen the connection with the server. pop is used to pop the connection stack. If an empty stack is popped the program exits. Other commands recognized are info, used to return the stack depth; quit to prematurely terminate the program; and snapshot to get some configuration information from the server.","Process Name":"mev","Link":"https:\/\/linux.die.net\/man\/1\/mev"}},{"Process":{"Description":"Metafont reads the program in the specified files and outputs font rasters (in gf format) and font metrics (in tfm format). The Metafont language is described in The Metafontbook. Like TeX, Metafont is normally used with a large body of precompiled macros, and font generation in particular requires the support of several macro files. This version of Metafont looks at its command line to see what name it was called under. Both inimf and virmf are symlinks to the mf executable. When called as inimf (or when the -ini option is given) it can be used to precompile macros into a .base file. When called as virmf it will use the plain base. When called under any other name, Metafont will use that name as the name of the base to use. For example, when called as mf the mf base is used, which is identical to the plain base. Other bases than plain are rarely used. The commands given on the command line to the Metafont program are passed to it as the first input line. (But it is often easier to type extended arguments as the first input line, since UNIX shells tend to gobble up or misinterpret Metafont's favorite symbols, like semicolons, unless you quote them.) As described in The Metafontbook, that first line should begin with a filename, a \\controlsequence, or a &basename. The normal usage is to say mf '\\mode=<printengine>; [mag=magstep( n);]' input font to start processing font.mf. The single quotes are the best way of keeping the Unix shell from misinterpreting the semicolons and from removing the \\ character, which is needed here to keep Metafont from thinking that you want to produce a font called mode. (Or you can just say mf and give the other stuff on the next line, without quotes.) Other control sequences, such as batchmode (for silent operation) can also appear. The name font will be the ''jobname'', and is used in forming output file names. If Metafont doesn't get a file name in the first line, the jobname is mfput. The default extension, .mf, can be overridden by specifying an extension explicitly. A log of error messages goes into the file jobname.log. The output files are jobname.tfm and jobname.<number>gf, where <number> depends on the resolution and magnification of the font. The mode in this example is shown generically as <printengine>, a symbolic term for which the name of an actual device or, most commonly, the name localfont (see below) must be substituted. If the mode is not specified or is not valid for your site, Metafont will default to proof mode which produces large character images for use in font design and refinement. Proof mode can be recognized by the suffix .2602gf after the jobname. Examples of proof mode output can be found in Computer Modern Typefaces (Volume E of Computers and Typesetting). The system of magsteps is identical to the system used by TeX, with values generally in the range 0.5, 1.0, 2.0, 3.0, 4.0 and 5.0. A listing of gf numbers for 118-dpi, 240-dpi and 300-dpi fonts is shown below. Magnification can also be specified not as a magstep but as an arbitrary value, such as 1.315, to create special character sizes. Before font production can begin, it is necessary to set up the appropriate base files. The minimum set of components for font production for a given print-engine is the plain.mf macro file and the local mode_def file. The macros in plain.mf can be studied in an appendix to the Metafontbook; they were developed by Donald E. Knuth, and this file should never be altered except when it is officially upgraded. Each mode_def specification helps adapt fonts to a particular print-engine. There is a regular discussion of mode_defs in TUGboat, the journal of the TeX Users Group. The local ones in use on this computer should be in modes.mf. The e response to Metafont's error-recovery mode invokes the system default editor at the erroneous line of the source file. There is an environment variable, MFEDIT, that overrides the default editor. It should contain a string with \"%s\" indicating where the filename goes and \"%d\" indicating where the decimal linenumber (if any) goes. For example, an MFEDIT string for the vi editor can be set with the csh command setenv MFEDIT \"vi +%d %s\" A convenient file in the library is null.mf, containing nothing. When mf can't find the file it thinks you want to input, it keeps asking you for another file name; responding 'null' gets you out of the loop if you don't want to input anything.","Process Name":"mf","Link":"https:\/\/linux.die.net\/man\/1\/mf"}},{"Process":{"Description":null,"Process Name":"mf-nowin","Link":"https:\/\/linux.die.net\/man\/1\/mf-nowin"}},{"Process":{"Description":"The mformat command is used to add an MS-DOS filesystem to a low-level formatted diskette. Its syntax is: mformat [-t cylinders] [-h heads] [-s sectors]\n  [-f size] [-1] [-4] [-8]\n  [-v volume_label]\n  [-F] [-S sizecode] [-X]\n  [-2 sectors_on_track_0] [-3]\n  [-0 rate_on_track_0] [-A rate_on_other_tracks]\n  [-M software_sector_size]\n  [-N serial_number] [-a]\n  [-C] [-H hidden_sectors] [-I fsVersion]\n  [-r root_sectors] [-L fat_len]\n  [-B boot_sector] [-k]\n  [-m media_descriptor]\n  drive:\n Mformat adds a minimal MS-DOS filesystem (boot sector, FAT, and root directory) to a diskette that has already been formatted by a Unix low-level format. The following options are supported: (The S, 2, 1 and M options may not exist if this copy of mtools has been compiled without the USE_2M option) The following options are the same as for Dos's format command:","Process Name":"mformat","Link":"https:\/\/linux.die.net\/man\/1\/mformat"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfsappendchunks","Link":"https:\/\/linux.die.net\/man\/1\/mfsappendchunks"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfscheckfile","Link":"https:\/\/linux.die.net\/man\/1\/mfscheckfile"}},{"Process":{"Description":null,"Process Name":"mfsdeleattr","Link":"https:\/\/linux.die.net\/man\/1\/mfsdeleattr"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfsdirinfo","Link":"https:\/\/linux.die.net\/man\/1\/mfsdirinfo"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfsfileinfo","Link":"https:\/\/linux.die.net\/man\/1\/mfsfileinfo"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfsfilerepair","Link":"https:\/\/linux.die.net\/man\/1\/mfsfilerepair"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfsgeteattr","Link":"https:\/\/linux.die.net\/man\/1\/mfsgeteattr"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfsgetgoal","Link":"https:\/\/linux.die.net\/man\/1\/mfsgetgoal"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfsgettrashtime","Link":"https:\/\/linux.die.net\/man\/1\/mfsgettrashtime"}},{"Process":{"Description":null,"Process Name":"mfsmakesnapshot","Link":"https:\/\/linux.die.net\/man\/1\/mfsmakesnapshot"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfsrgetgoal","Link":"https:\/\/linux.die.net\/man\/1\/mfsrgetgoal"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfsrgettrashtime","Link":"https:\/\/linux.die.net\/man\/1\/mfsrgettrashtime"}},{"Process":{"Description":null,"Process Name":"mfsrsetgoal","Link":"https:\/\/linux.die.net\/man\/1\/mfsrsetgoal"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfsrsettrashtime","Link":"https:\/\/linux.die.net\/man\/1\/mfsrsettrashtime"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfsseteattr","Link":"https:\/\/linux.die.net\/man\/1\/mfsseteattr"}},{"Process":{"Description":null,"Process Name":"mfssetgoal","Link":"https:\/\/linux.die.net\/man\/1\/mfssetgoal"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfssettrashtime","Link":"https:\/\/linux.die.net\/man\/1\/mfssettrashtime"}},{"Process":{"Description":"mfsgetgoal and mfssetgoal operate on object's goal value, i.e. the number of copies in which all file data are stored. It means that file should survive failure of one less chunkservers than its goal value. Goal must be set between 1 and 9 (note that 1 is strongly unadvised). mfsgetgoal prints current goal value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current goal value of all contained objects (files and directories). mfssetgoal changes current goal value of given object(s). If new value is specified in + N form, goal value is increased to N for objects with lower goal value and unchanged for the rest. Similarly, if new value is specified as - N, goal value is decreased to N for objects with higher goal value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted ( trash) file. mfsrgetgoal and mfsrsetgoal are deprecated aliases for mfsgetgoal -r and mfssetgoal -r respectively. mfsgettrashtime and mfssettrashtime operate on object's trashtime value, i.e. the number of seconds the file is preserved in special trash directory before it's finally removed from filesystem. Trashtime must be non-negative integer value. mfsgettrashtime prints current trashtime value of given object(s). -r option enables recursive mode, which works as usual for every given file, but for every given directory additionally prints current trashtime value of all contained objects (files and directories). mfssettrashtime changes current trashtime value of given object(s). If new value is specified in +N form, trashtime value is increased to N for objects with lower trashtime value and unchanged for the rest. Similarly, if new value is specified as -N, trashtime value is decreased to N for objects with higher trashtime value and unchanged for the rest. -r option enables recursive mode. These tools can be used on any file, directory or deleted (trash) file. mfsrgettrashtime and mfsrsettrashtime are deprecated aliases for mfsgettrashtime -r and mfssettrashtime -r respectively. mfsgeteattr, mfsseteattr and mfsdeleattr tools are used to get, set or delete some extra attributes. Attributes are described below. mfscheckfile checks and prints number of chunks and number of chunk copies belonging to specified file(s). It can be used on any file, included deleted (trash). mfsfileinfo prints location (chunkserver host and port) of each chunk copy belonging to specified file(s). It can be used on any file, included deleted (trash). mfsdirinfo is extended, MooseFS-specific equivalent of du -s command. It prints summary for each specified object (single file or directory tree). mfsfilerepair deals with broken files (those which cause I\/O errors on read operations) to make them partially readable. In case of missing chunk it fills missing parts of file with zeros; in case of chunk version mismatch it sets chunk version known to mfsmaster to highest one found on chunkservers. Note: because in the second case content mismatch can occur in chunks with the same version, it's advised to make a copy (not a snapshot!) and delete original file after \"repairing\". mfsappendchunks (equivalent of mfssnapshot from MooseFS 1.5) appends a lazy copy of specified file(s) to specified snapshot file (\"lazy\" means that creation of new chunks is delayed to the moment one copy is modified). If multiple files are given, they are merged into one target file in the way that each file begins at chunk (64MB) boundary; padding space is left empty. mfsmakesnapshots makes a \"real\" snapshot (lazy copy, like in case of mfsappendchunks) of some object(s) or subtree (similarly to cp -r command). It's atomic with respect to each SOURCE argument separately. If DESTINATION points to already existing file, error will be reported unless -o (overwrite) option is given. Note: if SOURCE is a directory, it's copied as a whole; but if it's followed by trailing slash, only directory content is copied.","Process Name":"mfstools","Link":"https:\/\/linux.die.net\/man\/1\/mfstools"}},{"Process":{"Description":"This manual page is not meant to be exhaustive. The complete documentation for this version of TeX can be found in the info file or manual Web2C: A TeX implementation. The mft program creates a TeX file from a Metafont program. It takes appropriate care of typographic details like page layout and the use of indentation, italics, boldface, etc., as illustrated in the book Computer Modern Typefaces. Special conventions in Metafont comments allow you to control things that would not otherwise come out right; section 1 of the MFT source program in the Metafontware report explains these rules. The command line has one required file name and two optional file names. The required one is a Metafont source file; there is also an optional change file (which works just as the change files to tangle(1) and weave(1) do) and an optional style file (which is prepended to everything). A file name that doesn't contain a dot is always given an extension, either .mf (Metafont) or .ch (change) or .mft (style). If no style file is specified, the style file plain.mft is automatically used. The change_file_name is not searched for using any paths. The .mf file is searched for using the MFINPUTS environment variable if you have set it, or else the system default. The style file is searched for using the TEXINPUTS environment variable. See tex(1) for the details of the searching. The output TeX file name is formed by using .tex in place of the extension of mf_file_name.","Process Name":"mft","Link":"https:\/\/linux.die.net\/man\/1\/mft"}},{"Process":{"Description":"mg is intended to be a small, fast, and portable editor for people who can't (or don't want to) run emacs for one reason or another, or are not familiar with the vi(1) editor. It is compatible with emacs because there shouldn't be any reason to learn more editor types than emacs or vi(1). The options are as follows: +number Go to the line specified by number (do not insert a space between the '+' sign and the number). If a negative number is specified, the line number counts backwards from the end of the file i.e. +-1 will be the last line of the file, +-2 will be second last, and so on. -f mode Run the mode command for all buffers created from arguments on the command line, including the scratch buffer and all files. -n' Turn off backup file generation.","Process Name":"mg","Link":"https:\/\/linux.die.net\/man\/1\/mg"}},{"Process":{"Description":null,"Process Name":"mgd77convert","Link":"https:\/\/linux.die.net\/man\/1\/mgd77convert"}},{"Process":{"Description":"mgd77info reads <legid>.[mgd77|nc] files and produces a single record of information about each cruise specified. The information includes beginning and end times, total track distances in km, longitude and latitude range, and the total number of geophysical observations. Optionally, choose instead to see the original MGD77 header meta-data section or its individual members. If you need to know which tracks are crossing through a given region and what kinds of geophysical observations are available, consider using the x2sys tools to set up a tracks index data base (see x2sys_init for more information). NGDC-ids Can be one or more of five kinds of specifiers: 1) 8-character NGDC IDs, e.g., 01010083, JA010010etc., etc. 2) 2-character <agency> codes which will return all cruises from each agency. 3) 4-character <agency><vessel> codes, which will return all cruises from those vessels. 4) =<list>, where <list> is a table with NGDC IDs, one per line. 5) If nothing is specified we return all cruises in the data base. (See mgd77info -L for agency and vessel codes). The \".mgd77\" or \".nc\" extensions will automatically be appended, if needed (use -I to ignore certain file types). Cruise files will be looked for first in the current directory and second in all directories listed in $MGD77_HOME\/mgd77_paths.txt [If $MGD77_HOME is not set it will default to $GMT_SHAREDIR\/mgd77].","Process Name":"mgd77info","Link":"https:\/\/linux.die.net\/man\/1\/mgd77info"}},{"Process":{"Description":"mgd77list reads <NGDC-id>.[mgd77|nc] files and produces an ASCII [or binary] table. The <NGDC-id>.[mgd77|nc] files contain track information such as leg-id, time and position, geophysical observables such as gravity, magnetics, and bathymetry, and control codes and corrections such as Eotvos and diurnal corrections. The MGD77+ extended netCDF files may also contain additional user columns (for a listing of available columns, use mgd77info -C, and to learn how to add your own custom columns, see mgd77manage). The user may extract any combination of these parameters, any of six computed quantities (distance, heading, velocity, Carter correction, and gravity and magnetic global reference fields), calendar sub-units of time (year, month, day, hour, min, sec), the NGDC id, and finally a preset weight (see -W). A sub-section can be specified by passing time- or distance-intervals along track or by selecting a geographical region. Finally, each output record may be required to pass any number of logical tests involving data values or bit flags. NGDC-ids Can be one or more of five kinds of specifiers: 1) 8-character NGDC IDs, e.g., 01010083, JA010010etc., etc. 2) 2-character <agency> codes which will return all cruises from each agency. 3) 4-character <agency><vessel> codes, which will return all cruises from those vessels. 4) =<list>, where <list> is a table with NGDC IDs, one per line. 5) If nothing is specified we return all cruises in the data base. (See mgd77info -L for agency and vessel codes). The \".mgd77\" or \".nc\" extensions will automatically be appended, if needed (use -I to ignore certain file types). Cruise files will be looked for first in the current directory and second in all directories listed in $MGD77_HOME\/mgd77_paths.txt [If $MGD77_HOME is not set it will default to $GMT_SHAREDIR\/mgd77]. -F The required columns string must be a comma-separated list of parameter abbreviations given in the desired output order. Any parameters given in UPPER case must not be NaN in a record for output to occur. Unless specified separately, the output format (if ASCII) is controlled by the GMT parameter D_FORMAT. The available abbreviations are: drt The digital record type, usually 3 or 5 (for Y2K-compliant cruises). id The survey ID string (leg name). tz The time zone adjustment (in hours from -13 to +12) ngdcid The 8-character NGDC cruise ID string (usually the file prefix). time Choose between Absolute calendar time ( atime, the default) in the format dictated by the GMT parameters OUTPUT_DATE_FORMAT and OUTPUT_CLOCK_FORMAT, Relative time ( rtime) in the format dictated by the GMT parameters D_FORMAT and TIME_SYSTEM (or TIME_EPOCH and TIME_UNIT)), or Fractional year ( ytime) in the format dictated by D_FORMAT. lon Longitude in the format dictated by the GMT parameter OUTPUT_DEGREE_FORMAT. lat Longitude in the format dictated by the GMT parameter OUTPUT_DEGREE_FORMAT. twt Two-Way Travel time (in s). depth Corrected bathymetry (in m, positive below sealevel). mtf1 Magnetic Total Field intensity from sensor 1 (in nTesla). mtf2 Magnetic Total Field intensity from sensor 2 (in nTesla). mag Residual magnetic anomaly (in nTesla). gobs Observed gravity (in mGal). faa Free-air gravity anomaly (in mGal). ptc Position Type Code (1 = fix, 3 = interpolated, 9 = unspecified). bcc Bathymetric Correction Code, indicating the procedure used to convert travel time to depth. (01-55 = Matthews' zone used to correct the depth, 59 = Matthews' corrections used but the zones is unspecified in the data record, 60 = S. Kuwahara formula for T-S, 61 = Wilson formula for T-S, 62 = Del Grosso formula for T-S, 63 = Carter's tables, 88 = Other, described in header sections, 99 = unspecified). btc Bathymetric Type Code, indicating how the bathymetry value was obtained (1 = observed, 3 = interpolated, 9 = unspecified). msens Magnetic sensor for used to evaluate the residual field (1 = 1st or leading sensor, 2 = 2nd or trailing sensor, 9 = unspecified). msd Depth (or altitude) of the magnetic sensor (in m, positive below sealevel). diur Magnetic diurnal correction (in nTesla). eot Eotvos correction (in mGal). sln Seismic Line Number string. sspn Seismic Shot Point Number string. nqc Navigation Quality Code (5 = suspected, by source institution, 6 = suspected, by NGDC, 9 = no problems identified). bqc Bathymetry Quality Code (1 = good, 2 = fair, 3 = poor, 4 = bad, 5 = bad, suspected by source institution, 6 = bad, suspected by NGDC, 9 = not set). mqc Magnetics Quality Code (1 = good, 2 = fair, 3 = poor, 4 = bad, 5 = bad, suspected by source institution, 6 = bad, suspected by NGDC, 9 = not set). gqc Gravity Quality Code (1 = good, 2 = fair, 3 = poor, 4 = bad, 5 = bad, suspected by source institution, 6 = bad, suspected by NGDC, 9 = not set). In addition, the following derived quantities can be requested: year The year of each record. month The month of each record. day The day of the month of each record. hour The hour of each record. min The minutes of each record. sec The decimal seconds of each record. date The date in yyyymmdd string format. hhmm The clock in hhmm.xxxx format (0-2359.xxxx). dmin The decimal minutes of each record (0-59.xxxx). dist Along-track distance from start of leg. For method of calculation, see -C [spherical great circle distances], and for distance units, see -N [km]. az Ship azimuth (heading) measured clockwise from north (in degrees). vel Ship speed; see -N for units [m\/s]. weight Weight assigned to this data set (see -W). carter Carter depth correction, if twt is present in file (in m). Sign: Correction is to be subtracted from uncorrected depths to yield a corrected depth. igrf International geomagnetic reference field (total field) (in nTesla). ngrav International Gravity reference Field (\"normal gravity\") (in mGal). Field is selected based on the parameter Gravity Theoretical Formula Code in the cruise's MGD77 header. If this is not set or is invalid we default to the IGF 1980. Alternatively, specify the field directly using -Af (see that option for more details). The following short-hand flags are also recognized: mgd77 This results in all 27 MGD77 fields being written out in the official MGD77 order. mgd77t This results in all 26 MGD77T fields being written out in the official MGD77T order. all as mgd77 or mgd77t but time is written as a single date-time string. geo This limits the output to 10 fields ( time, lon, lat plus the seven geophysical observations twt, depth, mtf1, mtf2, mag, gobs, and faa). By appending + to either of these set we will also append dist, azim, vel, and weight as listed above. As an option, logical tests may be added for any of the observations by appending ,logic, which is itself composed of one or more comma-separated instructions of the form parOPvalue, where par is one of the parameters listed above, OP is a logical operator (<, <=, =, !=, >=, >, |), and value is a constant used in the comparison. Floating point parameters are compared numerically; character parameters are compared lexically (after leading and trailing blanks have been removed). The bit comparison (|) means that at least one of the bits in value must be turned on in par. At least one of the tests must be true for the record to be output, except for tests using UPPER case parameters which all must be true for output to occur. Note that specifying a test does not imply that the corresponding column will be included in the output stream; it must be present in columns for that to occur. Note: some of the operators are special UNIX characters and you are advised to place quotes around the entire argument to -F. Finally, for MGD77+ files you may optionally append :bittests which is : (a colon) followed by one or more comma-separated +-col terms. This compares specific bitflags only for each listed column. Here, + means the chosen bit must be 1 (ON) whereas - means it must be 0 (OFF). All bit tests given must be passed. By default, MGD77+ files that have the special MGD77_flags column present will use those flags, and observations associated with ON-bits (meaning they are flagged as bad) will be set to NaN; append : with no trailing information to turn this behavior off (i.e., no bit flags will be consulted).","Process Name":"mgd77list","Link":"https:\/\/linux.die.net\/man\/1\/mgd77list"}},{"Process":{"Description":"mgd77magref will evaluate the IGRF or the CM4 geomagnetic models at the specified locations and times.","Process Name":"mgd77magref","Link":"https:\/\/linux.die.net\/man\/1\/mgd77magref"}},{"Process":{"Description":"mgd77manage deals with maintaining extra custom columns in MGD77+ netCDF files. You can either delete one or more columns, add a new column, update an existing column with new data, or supply error correction information (*.e77 files). New data may come from a table (ASCII unless -b is used), be based on existing columns and certain theoretical expressions, or they may be obtained by sampling a grid (choose between GMT grid or a Sandwell\/Smith Mercator *.img grid) along track. The new data will be appended to the MGD77+ file in the form of an extra data column of specified type. The data file will be modified; no new file will be created. For the big issues, see the DISCUSSION section below. NGDC-ids Can be one or more of five kinds of specifiers: 1) 8-character NGDC IDs, e.g., 01010083, JA010010etc., etc. 2) 2-character <agency> codes which will return all cruises from each agency. 3) 4-character <agency><vessel> codes, which will return all cruises from those vessels. 4) =<list>, where <list> is a table with NGDC IDs, one per line. 5) If nothing is specified we return all cruises in the data base. (See mgd77info -L for agency and vessel codes). The \".mgd77\" or \".nc\" extensions will automatically be appended, if needed (use -I to ignore certain file types). Cruise files will be looked for first in the current directory and second in all directories listed in $MGD77_HOME\/mgd77_paths.txt [If $MGD77_HOME is not set it will default to $GMT_SHAREDIR\/mgd77].","Process Name":"mgd77manage","Link":"https:\/\/linux.die.net\/man\/1\/mgd77manage"}},{"Process":{"Description":"mgd77path returns the full pathname to one or more MGD77 files. The pathname returned for a given cruise may change with time due to reshuffling of disks\/subdirectories. NGDC-ids Can be one or more of five kinds of specifiers: 1) 8-character NGDC IDs, e.g., 01010083, JA010010etc., etc. 2) 2-character <agency> codes which will return all cruises from each agency. 3) 4-character <agency><vessel> codes, which will return all cruises from those vessels. 4) =<list>, where <list> is a table with NGDC IDs, one per line. 5) If nothing is specified we return all cruises in the data base. (See mgd77info -L for agency and vessel codes). The \".mgd77\" or \".nc\" extensions will automatically be appended, if needed (use -I to ignore certain file types). Cruise files will be looked for first in the current directory and second in all directories listed in $MGD77_HOME\/mgd77_paths.txt [If $MGD77_HOME is not set it will default to $GMT_SHAREDIR\/mgd77].","Process Name":"mgd77path","Link":"https:\/\/linux.die.net\/man\/1\/mgd77path"}},{"Process":{"Description":null,"Process Name":"mgd77sniffer","Link":"https:\/\/linux.die.net\/man\/1\/mgd77sniffer"}},{"Process":{"Description":null,"Process Name":"mgd77togmt","Link":"https:\/\/linux.die.net\/man\/1\/mgd77togmt"}},{"Process":{"Description":"mgd77track reads NGDC MGD77 cruises and creates PostScript code that will plot one or more ship tracks on a map using the specified projection. The PostScript code is written to standard output. NGDC-ids Can be one or more of five kinds of specifiers: 1) 8-character NGDC IDs, e.g., 01010083, JA010010etc., etc. 2) 2-character <agency> codes which will return all cruises from each agency. 3) 4-character <agency><vessel> codes, which will return all cruises from those vessels. 4) =<list>, where <list> is a table with NGDC IDs, one per line. 5) If nothing is specified we return all cruises in the data base. (See mgd77info -L for agency and vessel codes). The \".mgd77\" or \".nc\" extensions will automatically be appended, if needed (use -I to ignore certain file types). Cruise files will be looked for first in the current directory and second in all directories listed in $MGD77_HOME\/mgd77_paths.txt [If $MGD77_HOME is not set it will default to $GMT_SHAREDIR\/mgd77]. -J Selects the map projection. Scale is UNIT\/degree, 1:xxxxx, or width in UNIT (upper case modifier). UNIT is cm, inch, or m, depending on the MEASURE_UNIT setting in .gmtdefaults4, but this can be overridden on the command line by appending c, i, or m to the scale\/width value. When central meridian is optional, default is center of longitude range on -R option. Default standard parallel is the equator. For map height, max dimension, or min dimension, append h, +, or - to the width, respectively. More details can be found in the psbasemap man pages. CYLINDRICAL PROJECTIONS: -Jclon0\/lat0\/scale (Cassini) -Jcyl_stere\/[lon0\/[lat0\/]]scale (Cylindrical Stereographic) -Jj[lon0\/]scale (Miller) -Jm[lon0\/[lat0\/]]scale (Mercator) -Jmlon0\/lat0\/scale (Mercator - Give meridian and standard parallel) -Jo[a]lon0\/lat0\/azimuth\/scale (Oblique Mercator - point and azimuth) -Jo[b]lon0\/lat0\/lon1\/lat1\/scale (Oblique Mercator - two points) -Joclon0\/lat0\/lonp\/latp\/scale (Oblique Mercator - point and pole) -Jq[lon0\/[lat0\/]]scale (Cylindrical Equidistant) -Jtlon0\/[lat0\/]scale (TM - Transverse Mercator) -Juzone\/scale (UTM - Universal Transverse Mercator) -Jy[lon0\/[lat0\/]]scale (Cylindrical Equal-Area) CONIC PROJECTIONS: -Jblon0\/lat0\/lat1\/lat2\/scale (Albers) -Jdlon0\/lat0\/lat1\/lat2\/scale (Conic Equidistant) -Jllon0\/lat0\/lat1\/lat2\/scale (Lambert Conic Conformal) -Jpoly\/[lon0\/[lat0\/]]scale ((American) Polyconic) AZIMUTHAL PROJECTIONS: -Jalon0\/lat0[\/horizon]\/scale (Lambert Azimuthal Equal-Area) -Jelon0\/lat0[\/horizon]\/scale (Azimuthal Equidistant) -Jflon0\/lat0[\/horizon]\/scale (Gnomonic) -Jglon0\/lat0[\/horizon]\/scale (Orthographic) -Jglon0\/lat0\/altitude\/azimuth\/tilt\/twist\/Width\/Height\/scale (General Perspective). -Jslon0\/lat0[\/horizon]\/scale (General Stereographic) MISCELLANEOUS PROJECTIONS: -Jh[lon0\/]scale (Hammer) -Ji[lon0\/]scale (Sinusoidal) -Jkf[lon0\/]scale (Eckert IV) -Jk[s][lon0\/]scale (Eckert VI) -Jn[lon0\/]scale (Robinson) -Jr[lon0\/]scale (Winkel Tripel) -Jv[lon0\/]scale (Van der Grinten) -Jw[lon0\/]scale (Mollweide) NON-GEOGRAPHICAL PROJECTIONS: -Jp[a]scale[\/origin][r|z] (Polar coordinates (theta,r)) -Jxx-scale[d|l|ppow|t|T][\/y-scale[d|l|ppow|t|T]] (Linear, log, and power scaling) -R west, east, south, and north specify the Region of interest, and you may specify them in decimal degrees or in [+-]dd:mm[:ss.xxx][W|E|S|N] format. Append r if lower left and upper right map coordinates are given instead of w\/e\/s\/n. The two shorthands -Rg and -Rd stand for global domain (0\/360 and -180\/+180 in longitude respectively, with -90\/+90 in latitude). Alternatively, specify the name of an existing grid file and the -R settings (and grid spacing, if applicable) are copied from the grid.","Process Name":"mgd77track","Link":"https:\/\/linux.die.net\/man\/1\/mgd77track"}},{"Process":{"Description":null,"Process Name":"mgetty_fax","Link":"https:\/\/linux.die.net\/man\/1\/mgetty_fax"}},{"Process":{"Description":"mgp is an X11 based presentation tool. It is designed to make simple presentations easy while to make complicated presentations possible. Its presentation file (whose suffix is typically .mgp) is just text so that you can create presentation files quickly with your favorite editor (such as Emacs). The .mgp file consists of text and control commands (such as pagebreak, centering, and\/or inline image). Control commands are specified on the beginning of lines started with one % sign. You can include numerous kinds of image format files onto the presentation file. mgp uses Japanese\/English fonts in various sizes. mgp uses X11 scalable fonts provided by X11 servers. mgp can also utilize the Japanese outline font library, \"VFlib\", if configured to do so at compilation time. The following options are available:        -b bgcolor Set background color to bgcolor. (The default value is black) -c vfcap Specify a VFlib configuration file. -d [interval] Demonstration mode. Browse all page automatically, spending interval secounds on each page and terminate. If interval is not specified, it will be set to 0. -f vfont Specify the font name to be used by VFlib. (The default value is minsl) -g geometry Set the size and location of the window. Please note that -g implies -o. mgp will not override the window manager if you specify the geometry. -h' Display the usage and exit without performing a presentation. -l' There are two kind of fonts available by VFlib; They are outline font and bitmap font. By specifying -l, you can disable the use of outline fonts. -n' mgp accepts any key inputs from invoked terminal as KEY OPERATION described below. -n disables this feature. (This option may be removed in the future release) -o' Do not override window manager. (By default, mgp overrides window manager and occupies the whole display) -p page Start presentation from page, rather than the first page. -q' Do not beep on errors. -t timeslot Specify the timeslot assigned to the presentation in minute. The timer is invoked when the second page is displayed and the remaining presentation time is indicated by the length of bar shown at the bottom of the display. The timebar is updated when some X11 event is raised, for instance some keypress. Timebar will be green if you have more than 50% of the timeslot, yellow while you have more than 30% of the timeslot, and red for the other cases. When the assigned timeslot is expired, exceeding time is also shown as a timebar growing from left to right. Current page is indicated by the position of a small vertical bar; the vertical bar is drawn at the leftend when the first page is displayed while the bar is drawn at the rightend when the last page is displayed. --title name Set the title of the window to name. -v' Display the MagicPoint version and exit without performing a presentation. -w wdir specifies the working directory used for store embedded images if any. To generate an embedded MGP file, use mgpembed(1). -x engine Do not use rendering engine, specified by engine. engine can be VFlib or FreeType. -B' Omit background image. -C' Use private colormap. -D htmldir Generate html pages of the presentation into htmldir. You will need xwintoppm(1) (included in mgp kit), and pnmscale(1), cjpeg(1), and djpeg(1) ( included in netpbm and Independent Jpeg Group jpeg package). -E htmlimage Specifies html image type. Now \"jpg\" and \"png\" are supported. default value is \"jpg\". It works when -D option is set. -F mode,effect,value Specifies forward page cache options. Mode, effect and value are numbers. Mode specifies caching mode. Mode 0 means caching is executed after 2 seconds idle. Mode 1 means caching is executed immediately. Effect specifies 'special effect' for the forward page cache. Currently, two special effects are supported. Effect 1 means that the next page will come in from the left side. Effect 2 means that the current page will go out to the left side. Effect 0 means no special effect. Value specifies speed of special effect. Value 1 means the highest speed. A higher value for value decreases effect speed. -G' Specifies to turn on page guide function. At the bottom of the screen, the titles of next page and previous page are displayed to assist the presentation. Page guide can be turned on and off by keyboard too. -O' Obey to the window manager, but with less decoration around the window. The behavior of this option is affected by how the window manager is implemented; this option may have no effect on some of the window managers. -Q quality Set background image quality(0-100). -R' mgp will usually reload the presentation file if it gets updated, based on the file modification time taken by stat(2). -R disables this auto-reloading feature. -S' Be secure. Skip directives that fork\/exec the child process. It is suggested to use this option if you got some presentation file from others. This is enabled by default. -U' Be unsecure. Enable directives that fork\/exec the child process. -T timestampfile If the option is specified, mgp will modify the content of timestampfile every time it updates the presentation window. This option is useful for external process to understand when mgp modifies the window. -V' Be verbose. Generate debugging output to standard output. -X gsdevice mgp sometimes invokes ghostscript(1) to render postscript images. -X enables you to specify the device to be used by ghostscript(1). If you specify gsdevice with a trailing '+', pnmscale(1) and pnmdepth(1) will be invoked for anti-aliasing. The default gsdevice is \"pnmraw+\".","Process Name":"mgp","Link":"https:\/\/linux.die.net\/man\/1\/mgp"}},{"Process":{"Description":null,"Process Name":"mgp2ps","Link":"https:\/\/linux.die.net\/man\/1\/mgp2ps"}},{"Process":{"Description":"mgpembed is a converter from a MagicPoint file mgpfile to a embedded MagicPoint file. A embedded MagicPoint file is suitable to give a presentation file to other guys via Email or via Web because external references (except shell commands) are resolved. -o option specifies that the output will be saved to outfile. Otherwise, the standard output is used.","Process Name":"mgpembed","Link":"https:\/\/linux.die.net\/man\/1\/mgpembed"}},{"Process":{"Description":"mgpnet is a small http server to be executed on the presenter's notebook computer. It lets audience read MagicPoint presentation foils on her notebook computers, over the net. When a presenter performs a presentation, she should invoke mgpnet instead of mgp, with the same argument. mgpnet will become an http server running on tcp port 9999 (by default), and invokes mgp as a child process. By accessing URL http:\/\/hostname:9999\/, audience will be able to read the MagicPoint window currently displayed on the presenter's notebook. The webpage provided by mgpnet is designed in \"client pull\" manner; audience's notebook will reload the page, several times a minute. If no option is specified, mgpnet will print the URL to be accessed by the audience to the standard output. This is useful for indicating the URL to be accessed on the presentation, like: %filter \"mgpnet\"\n%endfilter","Process Name":"mgpnet","Link":"https:\/\/linux.die.net\/man\/1\/mgpnet"}},{"Process":{"Description":"This program is part of Netpbm(1). mgrtopbm reads a MGR bitmap as input and produces a PBM image as output. MGR(1)is a window manager that is a smaller alternative to the X Windows System.","Process Name":"mgrtopbm","Link":"https:\/\/linux.die.net\/man\/1\/mgrtopbm"}},{"Process":{"Description":"mha-dbedit is a utility program that is part of the MHonArc software package. The program allows archive database edits to be made without causing HTML pages to be touched. The documentation for MHonArc is distributed in HTML format. Due to its size and organization, it is not suited for manpage format. Consult your system administrator for where the documentation has been installed, or see \" AVAILABILITY \" on where you can access the documentation on the web.","Process Name":"mha-dbedit","Link":"https:\/\/linux.die.net\/man\/1\/mha-dbedit"}},{"Process":{"Description":"mha-dbrecover is a utility program that is part of the MHonArc software package. The program allows can be used to rebuild a MHonArc archive database from the HTML message files. This allows database recovery if the database gets corrupted or accidentally deleted. The documentation for MHonArc is distributed in HTML format. Due to its size and organization, it is not suited for manpage format. Consult your system administrator for where the documentation has been installed, or see \" AVAILABILITY \" on where you can access the documentation on the web.","Process Name":"mha-dbrecover","Link":"https:\/\/linux.die.net\/man\/1\/mha-dbrecover"}},{"Process":{"Description":"mha-decode is a utility program that is part of the MHonArc software package. mha-decode provides basic MIME decoding for mail messages. If given mail folders as input, all messages within in the mail folders will be decoded. All message parts are written to files. If a filename is specified for a message part, that filename will be used when writing the part to a file. If no filename is specified in the message, a unique name will be used based upon the content-type of the message part. A single message can be decoded by using the \"-single\" option.","Process Name":"mha-decode","Link":"https:\/\/linux.die.net\/man\/1\/mha-decode"}},{"Process":{"Description":"MHonArc is a Perl program for converting mail, or news, messages into HTML archives. MHonArc can also be used to convert individual messages into HTML documents. The documentation for MHonArc is distributed in HTML format. Due to its size and organization, it is not suited for manpage format. Consult your system administrator for where the documentation has been installed, or see \" AVAILABILITY \" on where you can access the documentation on the web. Running \"\"mhonarc -help\"\" will give a summary of the command-line options available.","Process Name":"mhonarc","Link":"https:\/\/linux.die.net\/man\/1\/mhonarc"}},{"Process":{"Description":null,"Process Name":"mi","Link":"https:\/\/linux.die.net\/man\/1\/mi"}},{"Process":{"Description":"","Process Name":"miau","Link":"https:\/\/linux.die.net\/man\/1\/miau"}},{"Process":{"Description":"The mib2c tool is designed to take a portion of the MIB tree (as defined by a MIB file) and generate the template C code necessary to implement the relevant management objects within it. In order to implement a new MIB module, three files are necessary: - MIB definition file - C header file - C implementation file. The mib2c tool uses the MIB definition file to produce the two C code files. Thus, mib2c generates a template that you can edit to add logic necessary to obtain information from the operating system or application to complete the module. MIBNODE is the top level mib node you want to generate code for. You must give mib2c a mib node (e.g. ifTable) on the command line, not a mib file. This is the single most common mistake. The mib2c tool accepts both SMIv1 and SMIv2 MIBs. mib2c needs to be able to find and load a MIB file in order to generate C code for the MIB. To enable mib2c to find the MIB file, set the MIBS environment variable to include the MIB file you are using. An example of setting this environment variable is: MIBS=+NET-SNMP-TUTORIAL-MIB or MIBS=ALL The first example ensures that mib2c finds the NET-SNMP-TUTORIAL-MIB mib, in addition to the default MIB modules. The default list of MIB modules is set when the suite is first configured and built and basically corresponds to the list of modules that the agent supports. The second example ensures that mib2c finds all MIBs in the search location for MIB files. The default search location for MIB files is \/usr\/share\/snmp\/mibs. This search location can be modified by the MIBDIRS environment variable. Both the MIB files to be loaded and the MIB file search location can also be configured in the snmp.conf file. Please see snmp.conf(5) for more information. The generated *.c and *.h files will be created in the current working directory.","Process Name":"mib2c","Link":"https:\/\/linux.die.net\/man\/1\/mib2c"}},{"Process":{"Description":"merges custom code into updated mib2c code Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"mib2c-update","Link":"https:\/\/linux.die.net\/man\/1\/mib2c-update"}},{"Process":{"Description":null,"Process Name":"micq","Link":"https:\/\/linux.die.net\/man\/1\/micq"}},{"Process":{"Description":"addr2line translates addresses into file names and line numbers. Given an address in an executable or an offset in a section of a relocatable object, it uses the debugging information to figure out which file name and line number are associated with it. The executable or relocatable object to use is specified with the -e option. The default is the file a.out. The section in the relocatable object to use is specified with the -j option. addr2line has two modes of operation. In the first, hexadecimal addresses are specified on the command line, and addr2line displays the file name and line number for each address. In the second, addr2line reads hexadecimal addresses from standard input, and prints the file name and line number for each address on standard output. In this mode, addr2line may be used in a pipe to convert dynamically chosen addresses. The format of the output is FILENAME:LINENO . The file name and line number for each input address is printed on separate lines. If the -f option is used, then each FILENAME:LINENO line is preceded by FUNCTIONNAME which is the name of the function containing the address. If the -i option is used and the code at the given address is present there because of inlining by the compiler then the { FUNCTIONNAME } FILENAME:LINENO information for the inlining function will be displayed afterwards. This continues recursively until there is no more inlining to report. If the -a option is used then the output is prefixed by the input address. If the -p option is used then the output for each input address is displayed on one, possibly quite long, line. If -p is not used then the output is broken up into multiple lines, based on the paragraphs above. If the file name or function name can not be determined, addr2line will print two question marks in their place. If the line number can not be determined, addr2line will print 0.","Process Name":"microblaze-linux-gnu-addr2line","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-addr2line"}},{"Process":{"Description":"The GNU ar program creates, modifies, and extracts from archives. An archive is a single file holding a collection of other files in a structure that makes it possible to retrieve the original individual files (called members of the archive). The original files' contents, mode (permissions), timestamp, owner, and group are preserved in the archive, and can be restored on extraction. GNU ar can maintain archives whose members have names of any length; however, depending on how ar is configured on your system, a limit on member-name length may be imposed for compatibility with archive formats maintained with other tools. If it exists, the limit is often 15 characters (typical of formats related to a.out) or 16 characters (typical of formats related to coff). ar is considered a binary utility because archives of this sort are most often used as libraries holding commonly needed subroutines. ar creates an index to the symbols defined in relocatable object modules in the archive when you specify the modifier s. Once created, this index is updated in the archive whenever ar makes a change to its contents (save for the q update operation). An archive with such an index speeds up linking to the library, and allows routines in the library to call each other without regard to their placement in the archive. You may use nm -s or nm --print-armap to list this index table. If an archive lacks the table, another form of ar called ranlib can be used to add just the table. GNU ar can optionally create a thin archive, which contains a symbol index and references to the original copies of the member files of the archives. Such an archive is useful for building libraries for use within a local build, where the relocatable objects are expected to remain available, and copying the contents of each object would only waste time and space. Thin archives are also flattened, so that adding one or more archives to a thin archive will add the elements of the nested archive individually. The paths to the elements of the archive are stored relative to the archive itself. GNU ar is designed to be compatible with two different facilities. You can control its activity using command-line options, like the different varieties of ar on Unix systems; or, if you specify the single command-line option -M, you can control it with a script supplied via standard input, like the MRI \"librarian\" program.","Process Name":"microblaze-linux-gnu-ar","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-ar"}},{"Process":{"Description":null,"Process Name":"microblaze-linux-gnu-as","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-as"}},{"Process":{"Description":"The C ++ and Java languages provide function overloading, which means that you can write many functions with the same name, providing that each function takes parameters of different types. In order to be able to distinguish these similarly named functions C ++ and Java encode them into a low-level assembler name which uniquely identifies each different version. This process is known as mangling. The c++filt [1] program does the inverse mapping: it decodes (demangles) low-level names into user-level names so that they can be read. Every alphanumeric word (consisting of letters, digits, underscores, dollars, or periods) seen in the input is a potential mangled name. If the name decodes into a C ++ name, the C ++ name replaces the low-level name in the output, otherwise the original word is output. In this way you can pass an entire assembler source file, containing mangled names, through c++filt and see the same source file containing demangled names. You can also use c++filt to decipher individual symbols by passing them on the command line: c++filt <symbol> If no symbol arguments are given, c++filt reads symbol names from the standard input instead. All the results are printed on the standard output. The difference between reading names from the command line versus reading names from the standard input is that command line arguments are expected to be just mangled names and no checking is performed to separate them from surrounding text. Thus for example: c++filt -n _Z1fv will work and demangle the name to \"f()\" whereas: c++filt -n _Z1fv, will not work. (Note the extra comma at the end of the mangled name which makes it invalid). This command however will work: echo _Z1fv, | c++filt -n and will display \"f(),\", i.e., the demangled name followed by a trailing comma. This behaviour is because when the names are read from the standard input it is expected that they might be part of an assembler source file where there might be extra, extraneous characters trailing after a mangled name. For example: .type   _Z1fv, @function","Process Name":"microblaze-linux-gnu-c++filt","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-c++filt"}},{"Process":{"Description":null,"Process Name":"microblaze-linux-gnu-dlltool","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-dlltool"}},{"Process":{"Description":"elfedit updates the ELF header of ELF files which have the matching ELF machine and file types. The options control how and which fields in the ELF header should be updated. elffile... are the ELF files to be updated. 32-bit and 64-bit ELF files are supported, as are archives containing ELF files.","Process Name":"microblaze-linux-gnu-elfedit","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-elfedit"}},{"Process":{"Description":"ld combines a number of object and archive files, relocates their data and ties up symbol references. Usually the last step in compiling a program is to run ld. ld accepts Linker Command Language files written in a superset of AT&T 's Link Editor Command Language syntax, to provide explicit and total control over the linking process. This man page does not describe the command language; see the ld entry in \"info\" for full details on the command language and on other aspects of the GNU linker. This version of ld uses the general purpose BFD libraries to operate on object files. This allows ld to read, combine, and write object files in many different formats---for example, COFF or \"a.out\". Different formats may be linked together to produce any available kind of object file. Aside from its flexibility, the GNU linker is more helpful than other linkers in providing diagnostic information. Many linkers abandon execution immediately upon encountering an error; whenever possible, ld continues executing, allowing you to identify other errors (or, in some cases, to get an output file in spite of the error). The GNU linker ld is meant to cover a broad range of situations, and to be as compatible as possible with other linkers. As a result, you have many choices to control its behavior.","Process Name":"microblaze-linux-gnu-ld","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-ld"}},{"Process":{"Description":"ld combines a number of object and archive files, relocates their data and ties up symbol references. Usually the last step in compiling a program is to run ld. ld accepts Linker Command Language files written in a superset of AT&T 's Link Editor Command Language syntax, to provide explicit and total control over the linking process. This man page does not describe the command language; see the ld entry in \"info\" for full details on the command language and on other aspects of the GNU linker. This version of ld uses the general purpose BFD libraries to operate on object files. This allows ld to read, combine, and write object files in many different formats---for example, COFF or \"a.out\". Different formats may be linked together to produce any available kind of object file. Aside from its flexibility, the GNU linker is more helpful than other linkers in providing diagnostic information. Many linkers abandon execution immediately upon encountering an error; whenever possible, ld continues executing, allowing you to identify other errors (or, in some cases, to get an output file in spite of the error). The GNU linker ld is meant to cover a broad range of situations, and to be as compatible as possible with other linkers. As a result, you have many choices to control its behavior.","Process Name":"microblaze-linux-gnu-ld.bfd","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-ld.bfd"}},{"Process":{"Description":"nlmconv converts the relocatable i386 object file infile into the NetWare Loadable Module outfile, optionally reading headerfile for NLM header information. For instructions on writing the NLM command file language used in header files, see the linkers section, NLMLINK in particular, of the NLM Development and Tools Overview, which is part of the NLM Software Developer's Kit (\" NLM SDK \"), available from Novell, Inc. nlmconv uses the GNU Binary File Descriptor library to read infile; nlmconv can perform a link step. In other words, you can list more than one object file for input if you list them in the definitions file (rather than simply specifying one input file on the command line). In this case, nlmconv calls the linker for you.","Process Name":"microblaze-linux-gnu-nlmconv","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-nlmconv"}},{"Process":{"Description":"GNU nm lists the symbols from object files objfile.... If no object files are listed as arguments, nm assumes the file a.out. For each symbol, nm shows: \u2022 The symbol value, in the radix selected by options (see below), or hexadecimal by default. \u2022 The symbol type. At least the following types are used; others are, as well, depending on the object file format. If lowercase, the symbol is usually local; if uppercase, the symbol is global (external). There are however a few lowercase symbols that are shown for special global symbols (\"u\", \"v\" and \"w\"). \"A\" The symbol's value is absolute, and will not be changed by further linking. \"B\" \"b\" The symbol is in the uninitialized data section (known as BSS ). \"C\" The symbol is common. Common symbols are uninitialized data. When linking, multiple common symbols may appear with the same name. If the symbol is defined anywhere, the common symbols are treated as undefined references. \"D\" \"d\" The symbol is in the initialized data section. \"G\" \"g\" The symbol is in an initialized data section for small objects. Some object file formats permit more efficient access to small data objects, such as a global int variable as opposed to a large global array. \"i\" For PE format files this indicates that the symbol is in a section specific to the implementation of DLLs. For ELF format files this indicates that the symbol is an indirect function. This is a GNU extension to the standard set of ELF symbol types. It indicates a symbol which if referenced by a relocation does not evaluate to its address, but instead must be invoked at runtime. The runtime execution will then return the value to be used in the relocation. \"N\" The symbol is a debugging symbol. \"p\" The symbols is in a stack unwind section. \"R\" \"r\" The symbol is in a read only data section. \"S\" \"s\" The symbol is in an uninitialized data section for small objects. \"T\" \"t\" The symbol is in the text (code) section. \"U\" The symbol is undefined. \"u\" The symbol is a unique global symbol. This is a GNU extension to the standard set of ELF symbol bindings. For such a symbol the dynamic linker will make sure that in the entire process there is just one symbol with this name and type in use. \"V\" \"v\" The symbol is a weak object. When a weak defined symbol is linked with a normal defined symbol, the normal defined symbol is used with no error. When a weak undefined symbol is linked and the symbol is not defined, the value of the weak symbol becomes zero with no error. On some systems, uppercase indicates that a default value has been specified. \"W\" \"w\" The symbol is a weak symbol that has not been specifically tagged as a weak object symbol. When a weak defined symbol is linked with a normal defined symbol, the normal defined symbol is used with no error. When a weak undefined symbol is linked and the symbol is not defined, the value of the symbol is determined in a system-specific manner without error. On some systems, uppercase indicates that a default value has been specified. \"-\" The symbol is a stabs symbol in an a.out object file. In this case, the next values printed are the stabs other field, the stabs desc field, and the stab type. Stabs symbols are used to hold debugging information. \"?\" The symbol type is unknown, or object file format specific. \u2022 The symbol name.","Process Name":"microblaze-linux-gnu-nm","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-nm"}},{"Process":{"Description":"The GNU objcopy utility copies the contents of an object file to another. objcopy uses the GNU BFD Library to read and write the object files. It can write the destination object file in a format different from that of the source object file. The exact behavior of objcopy is controlled by command-line options. Note that objcopy should be able to copy a fully linked file between any two formats. However, copying a relocatable object file between any two formats may not work as expected. objcopy creates temporary files to do its translations and deletes them afterward. objcopy uses BFD to do all its translation work; it has access to all the formats described in BFD and thus is able to recognize most formats without being told explicitly. objcopy can be used to generate S-records by using an output target of srec (e.g., use -O srec). objcopy can be used to generate a raw binary file by using an output target of binary (e.g., use -O binary). When objcopy generates a raw binary file, it will essentially produce a memory dump of the contents of the input object file. All symbols and relocation information will be discarded. The memory dump will start at the load address of the lowest section copied into the output file. When generating an S-record or a raw binary file, it may be helpful to use -S to remove sections containing debugging information. In some cases -R will be useful to remove sections which contain information that is not needed by the binary file. Note---objcopy is not able to change the endianness of its input files. If the input format has an endianness (some formats do not), objcopy can only copy the inputs into file formats that have the same endianness or which have no endianness (e.g., srec). (However, see the --reverse-bytes option.)","Process Name":"microblaze-linux-gnu-objcopy","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-objcopy"}},{"Process":{"Description":null,"Process Name":"microblaze-linux-gnu-objdump","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-objdump"}},{"Process":{"Description":"ranlib generates an index to the contents of an archive and stores it in the archive. The index lists each symbol defined by a member of an archive that is a relocatable object file. You may use nm -s or nm --print-armap to list this index. An archive with such an index speeds up linking to the library and allows routines in the library to call each other without regard to their placement in the archive. The GNU ranlib program is another form of GNU ar; running ranlib is completely equivalent to executing ar -s.","Process Name":"microblaze-linux-gnu-ranlib","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-ranlib"}},{"Process":{"Description":"readelf displays information about one or more ELF format object files. The options control what particular information to display. elffile... are the object files to be examined. 32-bit and 64-bit ELF files are supported, as are archives containing ELF files. This program performs a similar function to objdump but it goes into more detail and it exists independently of the BFD library, so if there is a bug in BFD then readelf will not be affected.","Process Name":"microblaze-linux-gnu-readelf","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-readelf"}},{"Process":{"Description":"The GNU size utility lists the section sizes---and the total size---for each of the object or archive files objfile in its argument list. By default, one line of output is generated for each object file or each module in an archive. objfile... are the object files to be examined. If none are specified, the file \"a.out\" will be used.","Process Name":"microblaze-linux-gnu-size","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-size"}},{"Process":{"Description":null,"Process Name":"microblaze-linux-gnu-strings","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-strings"}},{"Process":{"Description":"GNU strip discards all symbols from object files objfile. The list of object files may include archives. At least one object file must be given. strip modifies the files named in its argument, rather than writing modified copies under different names.","Process Name":"microblaze-linux-gnu-strip","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-strip"}},{"Process":{"Description":"windmc reads message definitions from an input file (.mc) and translate them into a set of output files. The output files may be of four kinds: \"h\" A C header file containing the message definitions. \"rc\" A resource file compilable by the windres tool. \"bin\" One or more binary files containing the resource data for a specific message language. \"dbg\" A C include file that maps message id's to their symbolic name. The exact description of these different formats is available in documentation from Microsoft. When windmc converts from the \"mc\" format to the \"bin\" format, \"rc\", \"h\", and optional \"dbg\" it is acting like the Windows Message Compiler.","Process Name":"microblaze-linux-gnu-windmc","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-windmc"}},{"Process":{"Description":"windres reads resources from an input file and copies them into an output file. Either file may be in one of three formats: \"rc\" A text format read by the Resource Compiler. \"res\" A binary format generated by the Resource Compiler. \"coff\" A COFF object or executable. The exact description of these different formats is available in documentation from Microsoft. When windres converts from the \"rc\" format to the \"res\" format, it is acting like the Windows Resource Compiler. When windres converts from the \"res\" format to the \"coff\" format, it is acting like the Windows \"CVTRES\" program. When windres generates an \"rc\" file, the output is similar but not identical to the format expected for the input. When an input \"rc\" file refers to an external filename, an output \"rc\" file will instead include the file contents. If the input or output format is not specified, windres will guess based on the file name, or, for the input file, the file contents. A file with an extension of .rc will be treated as an \"rc\" file, a file with an extension of .res will be treated as a \"res\" file, and a file with an extension of .o or .exe will be treated as a \"coff\" file. If no output file is specified, windres will print the resources in \"rc\" format to standard output. The normal use is for you to write an \"rc\" file, use windres to convert it to a COFF object file, and then link the COFF file into your application. This will make the resources described in the \"rc\" file available to Windows.","Process Name":"microblaze-linux-gnu-windres","Link":"https:\/\/linux.die.net\/man\/1\/microblaze-linux-gnu-windres"}},{"Process":{"Description":null,"Process Name":"mid3iconv","Link":"https:\/\/linux.die.net\/man\/1\/mid3iconv"}},{"Process":{"Description":"mid3v2 is a Mutagen-based replacement for id3lib's id3v2. It supports ID3v2.4 and more frames; it also does not have the numerous bugs that plague id3v2. This program exists mostly for compatibility with programs that want to tag files using id3v2. For a more usable interface, we recommend Ex Falso.","Process Name":"mid3v2","Link":"https:\/\/linux.die.net\/man\/1\/mid3v2"}},{"Process":{"Description":"migratecred migrates credentials from one Directory Server instance to the other. New plugin path defaults to [libdir\/dirsrv\/plugins] if not given migratecred is a program that migrates credentials used for replication and chaining. That is the password used by the server to perform the simple BIND operation for server to server communications.","Process Name":"migratecred","Link":"https:\/\/linux.die.net\/man\/1\/migratecred"}},{"Process":{"Description":"MikMod is a very portable module player based on libmikmod, written originally by Jean-Paul Mikkers (MikMak). It will play the IT, XM, MOD, MTM, S3M, STM, ULT, FAR, MED, DSM, AMF, IMF and 669 module formats. It works under AIX, FreeBSD, HP-UX, IRIX, Linux, NetBSD, OpenBSD, OSF\/1, SunOS, Solaris and OS\/2. It is controllable via an easy-to-use curses interface and will extract and play modules from a variety of different archive formats.","Process Name":"mikmod","Link":"https:\/\/linux.die.net\/man\/1\/mikmod"}},{"Process":{"Description":null,"Process Name":"mime-construct","Link":"https:\/\/linux.die.net\/man\/1\/mime-construct"}},{"Process":{"Description":null,"Process Name":"mimedb","Link":"https:\/\/linux.die.net\/man\/1\/mimedb"}},{"Process":{"Description":"This script provides some debug tools formerly provided as part of mimedefang.pl","Process Name":"mimedefang-util","Link":"https:\/\/linux.die.net\/man\/1\/mimedefang-util"}},{"Process":{"Description":"Read a MIME stream from the stdin, and dump its contents to the stdout.","Process Name":"mimedump","Link":"https:\/\/linux.die.net\/man\/1\/mimedump"}},{"Process":{"Description":"Encode (or, with -d, decode) stdin with the given encoding, writing results to stdout. This does not do MIME parsing; it merely exercises the decoder modules.","Process Name":"mimeencode","Link":"https:\/\/linux.die.net\/man\/1\/mimeencode"}},{"Process":{"Description":"Takes one or more files from the command line that contain MIME messages, and explodes their contents out into subdirectories of the current working directory. The subdirectories are just called \"msg0\", \"msg1\", \"msg2\", etc. Existing directories are skipped over. The message information is output to the stdout, like this: Message: msg3 (inputfile1.msg)\n    Part: msg3\/filename-1.dat (text\/plain)\n    Part: msg3\/filename-2.dat (text\/plain)\nMessage: msg5 (input-file2.msg)\n    Part: msg5\/dir.gif (image\/gif)\n    Part: msg5\/face.jpg (image\/jpeg)\nMessage: msg6 (infile3)\n    Part: msg6\/filename-1.dat (text\/plain) This was written as an example of the MIME:: modules in the MIME-parser package I wrote. It may prove useful as a quick-and-dirty way of splitting a MIME message if you need to decode something, and you don't have a MIME mail reader on hand.","Process Name":"mimeexplode","Link":"https:\/\/linux.die.net\/man\/1\/mimeexplode"}},{"Process":{"Description":"This script tries to determine the mimetype of a file and open it with the default desktop application. If no default application is configured the user is prompted with an \"open with\" menu in the terminal. To use this script you need the freedestop mime-info database and the freedesktop desktop-file-utils package. See File::MimeInfo::Applications(3) for more details.","Process Name":"mimeopen","Link":"https:\/\/linux.die.net\/man\/1\/mimeopen"}},{"Process":{"Description":null,"Process Name":"mimepostcard","Link":"https:\/\/linux.die.net\/man\/1\/mimepostcard"}},{"Process":{"Description":"","Process Name":"mimesend","Link":"https:\/\/linux.die.net\/man\/1\/mimesend"}},{"Process":{"Description":"This is a very trivial use of Crypt::Mimetic module but I think that could be useful as demo.","Process Name":"mimetic","Link":"https:\/\/linux.die.net\/man\/1\/mimetic"}},{"Process":{"Description":"This script tries to determine the mime type of a file using the Shared MIME-info database. It is intended as a kind of file(1) work-alike, but uses mimetypes instead of descriptions. If one symlinks the file command to mimetype it will behave a little more compatible, see \"--file-compat\". Commandline options to specify alternative magic files are not implemented the same because of the conflicting data formats. Also the wording of the descriptions will differ. For naming switches I followed the manpage of file(1) version 4.02 when possible. They seem to differ completely from the spec in the 'utilities' chapter of IEEE Std 1003.1-2001 ( POSIX ).","Process Name":"mimetype","Link":"https:\/\/linux.die.net\/man\/1\/mimetype"}},{"Process":{"Description":null,"Process Name":"min12xxw","Link":"https:\/\/linux.die.net\/man\/1\/min12xxw"}},{"Process":{"Description":null,"Process Name":"mined","Link":"https:\/\/linux.die.net\/man\/1\/mined"}},{"Process":{"Description":"The minfo command prints the parameters of a Dos filesystem, such as number of sectors, heads and cylinders. It also prints an mformat command line which can be used to create a similar Dos filesystem on another media. However, this doesn't work with 2m or Xdf media, and with Dos 1.0 filesystems minfo drive: Mlabel supports the following option: v Prints a hexdump of the bootsector, in addition to the other information","Process Name":"minfo","Link":"https:\/\/linux.die.net\/man\/1\/minfo"}},{"Process":{"Description":"mini-inetd listens for TCP\/IP connections on port. For each connection, program is started with standard input and standard output connected to the socket. If localaddr is given, mini-inetd only listens for connections on the interface specified by that hostname or IP address, otherwise, it listens to all IP interfaces on the machine.","Process Name":"mini-inetd","Link":"https:\/\/linux.die.net\/man\/1\/mini-inetd"}},{"Process":{"Description":"minicom is a communication program which somewhat resembles the shareware program TELIX but is free with source code and runs under most unices. Features include dialing directory with auto-redial, support for UUCP-style lock files on serial devices, a separate script language interpreter, capture to file, multiple users with individual configurations, and more.","Process Name":"minicom","Link":"https:\/\/linux.die.net\/man\/1\/minicom"}},{"Process":{"Description":null,"Process Name":"minismoker","Link":"https:\/\/linux.die.net\/man\/1\/minismoker"}},{"Process":{"Description":"Mined is a text editor with Interactive features \u2022 Intuitive user interface \u2022 Logical and consistent concept of navigating and editing text (without ancient line-end handling limitations or insert\/append confusion) \u2022 Supports various control styles: \u2022 Editing with command control, function key control, or menu control \u2022 Navigation by cursor keys, control keys, mouse or scrollbar \u2022 Concise and comprehensive menus (driven by keyboard or mouse) \u2022 \"HOP\" key paradigm doubles the number of navigation functions that can be most easily reached and remembered by intuitively amplifying or expanding the associated function \u2022 →NEW→ Interactive file chooser and →NEW→ interactive file switcher \u2022 Proper handling of window size changes in any state of interaction Versatile character encoding support \u2022 Extensive Unicode support, including double-width and combining characters, script highlighting, various methods of character input support (mapped keyboard input methods, mnemonic and numeric input), supporting CJK, Vietnamese, Hebrew, Arabic, and other scripts \u2022 →NEW→ Character information updated to Unicode 6.1 \u2022 Extensive accented character input support, including multiple accent prefix keys \u2022 Support for Greek (monotonic and polytonic) \u2022 Support for Cyrillic accented characters \u2022 Support of bidirectional terminals \u2022 Support of Arabic ligature joining on all terminals \u2022 East Asian character set support: handling of major CJK encodings (including GB18030 and full EUC-JP with combining characters) \u2022 Support for a large number of 8 bit encodings (with combining characters for Vietnamese, Thai, Arabic, Hebrew) \u2022 Support of CJK input methods by enhanced keyboard mapping including multiple choice mappings (handled by a pick list menu); characters in the pick list being sorted by relevance of Unicode ranges \u2022 Han character information with description and pronunciation \u2022 Auto-detection of text character encoding, edits files with mixed character encoding sections (e.g. mailboxes), transparent handling and auto-detection of UTF-16 encoded files \u2022 Auto-detection of UTF-8 \/ CJK \/ 8 bit terminal mode and detailed features (like different Unicode width and combining data versions) \u2022 Comprehensive and flexible (though standard-conformant) set of mechanisms to specify both text and terminal encodings with useful precedences \u2022 Flexible combination of any text encoding with any terminal encoding \u2022 Encoding support tested with: xterm, mlterm, rxvt, cxterm, kterm, hanterm, KDE konsole, gnome-terminal, Linux console, cygwin console, mintty, PuTTY Text editing features \u2022 Many text editing features, e.g. paragraph wrapping, auto-indentation and back-tab, smart quotes (with quotation marks style selection and auto-detection) and smart dashes \u2022 Search and replacement patterns can have multiple lines \u2022 Cross-session paste buffer (copy\/paste between multiple - even subsequent or remote - invocations of mined) \u2022 Optional Unicode paste buffer mode with implicit conversion \u2022 Marker stack for quick return to previous text positions \u2022 Multiple paste buffers (emacs-style) \u2022 Optional rectangular copy\/paste area \u2022 Interactive selection highlighting (with mouse or keyboard selection), standard dual-mode Del key behaviour \u2022 Program editing features, HTML support and syntax highlighting, identifier and function definition search, also across files; structure input support \u2022 Text and program layout features; auto-indentation and undent function (back-tab), numbered item justification \u2022 Systematic text and file handling safety, avoiding loss of data \u2022 Visible indications of special text contents (TAB characters, different line-end types, character codes that cannot be displayed in the current mode) \u2022 Full binary transparent editing with visible indications (illegal UTF-8 or CJK, mixed line end types, NUL characters, ...) \u2022 Print function that works in all text encodings \u2022 Optional password hiding \u2022 Optional emacs command mode Small-footprint operation, portability and interworking \u2022 Plain text mode (terminal) operation \u2022 Optimized use of terminal features for a wide range of terminals, including large terminal support (2015x2015) of recent xterm and mintty \u2022 Instant start-up \u2022 Runs on many platforms (including legacy systems): Linux, →NEW→ Android, Unix (SunOS, BSD, Mac OS X, QNX, GNU Hurd, HP-UX, IBM AIX, SCO UnixWare, Ultrix, Tru64), DOS (djgpp), Windows (cygwin, Interix), →NEW→ OpenVMS, Haiku This manual contains the main topics \u2022 Command line options \u2022 Editing text with mined, an overview \u2022 Keypad layout \u2022 The HOP function \u2022 Mouse control and Menus \u2022 Paste buffers \u2022 Visual selection and →NEW→ Keypad modes \u2022 Rectangular copy\/paste \u2022 Text position marker stack \u2022 Paragraph justification \u2022 Auto indentation and Structure input support \u2022 Search and replace multiple lines \u2022 Overview: input support features \u2022 Handling files with mined \u2022 Tags file support \u2022 Data safety and security, →NEW→ Backup and recovery files and File locking \u2022 Line end modes and binary-transparent editing \u2022 File info: Memory of file position and editing style parameters \u2022 →NEW→ File chooser and File switcher \u2022 Version control integration \u2022 Printing \u2022 Working with mined \u2022 Quick Options (Mode indication) flags \u2022 Structured editing support \u2022 Password hiding \u2022 Visible indication of line contents Language support \u2022 Character handling support \u2022 Combining characters \u2022 Character information display \u2022 Character conversion features \u2022 Smart quotes \u2022 Character input support \u2022 Accented and mnemonic input support \u2022 Combining character input \u2022 Special character input shortcuts \u2022 Character input mnemonics \u2022 Keyboard Mapping and Input Methods \u2022 Character encoding support \u2022 Auto-detected character encodings \u2022 CJK and mapped 8 bit encoding support \u2022 Combining characters \u2022 Unicode support \u2022 Character input support \u2022 Encoding conversion support \u2022 Bidirectional terminal support \u2022 Joining characters \u2022 CJK support \u2022 CJK input method support \u2022 Han character information display \u2022 Terminal encoding support Mined Command reference (command and key function assignments) \u2022 Generic command modifiers (esp. HOP key) \u2022 Cursor and screen motion \u2022 Entering text \u2022 Input support commands \u2022 Modifying text \u2022 Text block and buffer operations \u2022 Search \u2022 File operations \u2022 Menu \u2022 Miscellaneous \u2022 MSDOS keyboard functions \u2022 Emacs mode \u2022 Windows keyboard mode \u2022 WordStar mode \u2022 Configuration of user preferences \u2022 Environment interworking and configuration hints \u2022 Mined runtime support library \u2022 PC versions \u2022 VMS version \u2022 Android version \u2022 Terminal environment \u2022 Locale configuration \u2022 PC terminals \u2022 Terminal setup and configuration \u2022 Terminal interworking problems \u2022 Keyboard Mapping \/ Input Method pre-selection \u2022 Smart Quotes style configuration \u2022 Han info configuration \u2022 Common paste buffer configuration \u2022 Keypad configuration \u2022 Printing configuration \u2022 Mined configuration \u2022 Environment variables \u2022 Author and Acknowledgements Interactive help is available with F1.","Process Name":"minmacs","Link":"https:\/\/linux.die.net\/man\/1\/minmacs"}},{"Process":{"Description":"minmax reads its standard input [or from files] and finds the extreme values in each of the columns. It recognizes NaNs and will print warnings if the number of columns vary from record to record. As an option, minmax will find the extent of the first n columns rounded up and down to the nearest multiple of the supplied increments. By default, this output will be in the form -R w\/e\/s\/n which can be used directly in the command line for other programs (hence only dx and dy are needed), or the output will be in column form for as many columns as there are increments provided. A similar option ( -T) will provide a -T zmin\/zmax\/dz string for makecpt. xyzfile ASCII [or binary, see -b] file(s) holding a fixed number of data columns.","Process Name":"minmax","Link":"https:\/\/linux.die.net\/man\/1\/minmax"}},{"Process":{"Description":"Mobile IPv6 and NEMO Basic Support implementation","Process Name":"mip6d","Link":"https:\/\/linux.die.net\/man\/1\/mip6d"}},{"Process":{"Description":"addr2line translates addresses into file names and line numbers. Given an address in an executable or an offset in a section of a relocatable object, it uses the debugging information to figure out which file name and line number are associated with it. The executable or relocatable object to use is specified with the -e option. The default is the file a.out. The section in the relocatable object to use is specified with the -j option. addr2line has two modes of operation. In the first, hexadecimal addresses are specified on the command line, and addr2line displays the file name and line number for each address. In the second, addr2line reads hexadecimal addresses from standard input, and prints the file name and line number for each address on standard output. In this mode, addr2line may be used in a pipe to convert dynamically chosen addresses. The format of the output is FILENAME:LINENO . The file name and line number for each input address is printed on separate lines. If the -f option is used, then each FILENAME:LINENO line is preceded by FUNCTIONNAME which is the name of the function containing the address. If the -i option is used and the code at the given address is present there because of inlining by the compiler then the { FUNCTIONNAME } FILENAME:LINENO information for the inlining function will be displayed afterwards. This continues recursively until there is no more inlining to report. If the -a option is used then the output is prefixed by the input address. If the -p option is used then the output for each input address is displayed on one, possibly quite long, line. If -p is not used then the output is broken up into multiple lines, based on the paragraphs above. If the file name or function name can not be determined, addr2line will print two question marks in their place. If the line number can not be determined, addr2line will print 0.","Process Name":"mips64-linux-gnu-addr2line","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-addr2line"}},{"Process":{"Description":"The GNU ar program creates, modifies, and extracts from archives. An archive is a single file holding a collection of other files in a structure that makes it possible to retrieve the original individual files (called members of the archive). The original files' contents, mode (permissions), timestamp, owner, and group are preserved in the archive, and can be restored on extraction. GNU ar can maintain archives whose members have names of any length; however, depending on how ar is configured on your system, a limit on member-name length may be imposed for compatibility with archive formats maintained with other tools. If it exists, the limit is often 15 characters (typical of formats related to a.out) or 16 characters (typical of formats related to coff). ar is considered a binary utility because archives of this sort are most often used as libraries holding commonly needed subroutines. ar creates an index to the symbols defined in relocatable object modules in the archive when you specify the modifier s. Once created, this index is updated in the archive whenever ar makes a change to its contents (save for the q update operation). An archive with such an index speeds up linking to the library, and allows routines in the library to call each other without regard to their placement in the archive. You may use nm -s or nm --print-armap to list this index table. If an archive lacks the table, another form of ar called ranlib can be used to add just the table. GNU ar can optionally create a thin archive, which contains a symbol index and references to the original copies of the member files of the archives. Such an archive is useful for building libraries for use within a local build, where the relocatable objects are expected to remain available, and copying the contents of each object would only waste time and space. Thin archives are also flattened, so that adding one or more archives to a thin archive will add the elements of the nested archive individually. The paths to the elements of the archive are stored relative to the archive itself. GNU ar is designed to be compatible with two different facilities. You can control its activity using command-line options, like the different varieties of ar on Unix systems; or, if you specify the single command-line option -M, you can control it with a script supplied via standard input, like the MRI \"librarian\" program.","Process Name":"mips64-linux-gnu-ar","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-ar"}},{"Process":{"Description":null,"Process Name":"mips64-linux-gnu-as","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-as"}},{"Process":{"Description":"The C ++ and Java languages provide function overloading, which means that you can write many functions with the same name, providing that each function takes parameters of different types. In order to be able to distinguish these similarly named functions C ++ and Java encode them into a low-level assembler name which uniquely identifies each different version. This process is known as mangling. The c++filt [1] program does the inverse mapping: it decodes (demangles) low-level names into user-level names so that they can be read. Every alphanumeric word (consisting of letters, digits, underscores, dollars, or periods) seen in the input is a potential mangled name. If the name decodes into a C ++ name, the C ++ name replaces the low-level name in the output, otherwise the original word is output. In this way you can pass an entire assembler source file, containing mangled names, through c++filt and see the same source file containing demangled names. You can also use c++filt to decipher individual symbols by passing them on the command line: c++filt <symbol> If no symbol arguments are given, c++filt reads symbol names from the standard input instead. All the results are printed on the standard output. The difference between reading names from the command line versus reading names from the standard input is that command line arguments are expected to be just mangled names and no checking is performed to separate them from surrounding text. Thus for example: c++filt -n _Z1fv will work and demangle the name to \"f()\" whereas: c++filt -n _Z1fv, will not work. (Note the extra comma at the end of the mangled name which makes it invalid). This command however will work: echo _Z1fv, | c++filt -n and will display \"f(),\", i.e., the demangled name followed by a trailing comma. This behaviour is because when the names are read from the standard input it is expected that they might be part of an assembler source file where there might be extra, extraneous characters trailing after a mangled name. For example: .type   _Z1fv, @function","Process Name":"mips64-linux-gnu-c++filt","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-c++filt"}},{"Process":{"Description":"The C preprocessor, often known as cpp, is a macro processor that is used automatically by the C compiler to transform your program before compilation. It is called a macro processor because it allows you to define macros, which are brief abbreviations for longer constructs. The C preprocessor is intended to be used only with C, C ++ , and Objective-C source code. In the past, it has been abused as a general text processor. It will choke on input which does not obey C's lexical rules. For example, apostrophes will be interpreted as the beginning of character constants, and cause errors. Also, you cannot rely on it preserving characteristics of the input which are not significant to C-family languages. If a Makefile is preprocessed, all the hard tabs will be removed, and the Makefile will not work. Having said that, you can often get away with using cpp on things which are not C. Other Algol-ish programming languages are often safe (Pascal, Ada, etc.) So is assembly, with caution. -traditional-cpp mode preserves more white space, and is otherwise more permissive. Many of the problems can be avoided by writing C or C ++ style comments instead of native language comments, and keeping macros simple. Wherever possible, you should use a preprocessor geared to the language you are writing in. Modern versions of the GNU assembler have macro facilities. Most high level programming languages have their own conditional compilation and inclusion mechanism. If all else fails, try a true general text processor, such as GNU M4. C preprocessors vary in some details. This manual discusses the GNU C preprocessor, which provides a small superset of the features of ISO Standard C. In its default mode, the GNU C preprocessor does not do a few things required by the standard. These are features which are rarely, if ever, used, and may cause surprising changes to the meaning of a program which does not expect them. To get strict ISO Standard C, you should use the -std=c90, -std=c99 or -std=c11 options, depending on which version of the standard you want. To get all the mandatory diagnostics, you must also use -pedantic. This manual describes the behavior of the ISO preprocessor. To minimize gratuitous differences, where the ISO preprocessor's behavior does not conflict with traditional semantics, the traditional preprocessor should behave the same way. The various differences that do exist are detailed in the section Traditional Mode. For clarity, unless noted otherwise, references to CPP in this manual refer to GNU CPP .","Process Name":"mips64-linux-gnu-cpp","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-cpp"}},{"Process":{"Description":"dlltool reads its inputs, which can come from the -d and -b options as well as object files specified on the command line. It then processes these inputs and if the -e option has been specified it creates a exports file. If the -l option has been specified it creates a library file and if the -z option has been specified it creates a def file. Any or all of the -e, -l and -z options can be present in one invocation of dlltool. When creating a DLL , along with the source for the DLL , it is necessary to have three other files. dlltool can help with the creation of these files. The first file is a .def file which specifies which functions are exported from the DLL , which functions the DLL imports, and so on. This is a text file and can be created by hand, or dlltool can be used to create it using the -z option. In this case dlltool will scan the object files specified on its command line looking for those functions which have been specially marked as being exported and put entries for them in the .def file it creates. In order to mark a function as being exported from a DLL , it needs to have an -export:<name_of_function> entry in the .drectve section of the object file. This can be done in C by using the asm() operator: asm (\".section .drectve\");\nasm (\".ascii \\\"-export:my_func\\\"\");\n\nint my_func (void) { ... } The second file needed for DLL creation is an exports file. This file is linked with the object files that make up the body of the DLL and it handles the interface between the DLL and the outside world. This is a binary file and it can be created by giving the -e option to dlltool when it is creating or reading in a .def file. The third file needed for DLL creation is the library file that programs will link with in order to access the functions in the DLL (an 'import library'). This file can be created by giving the -l option to dlltool when it is creating or reading in a .def file. If the -y option is specified, dlltool generates a delay-import library that can be used instead of the normal import library to allow a program to link to the dll only as soon as an imported function is called for the first time. The resulting executable will need to be linked to the static delayimp library containing __delayLoadHelper2(), which in turn will import LoadLibraryA and GetProcAddress from kernel32. dlltool builds the library file by hand, but it builds the exports file by creating temporary files containing assembler statements and then assembling these. The -S command line option can be used to specify the path to the assembler that dlltool will use, and the -f option can be used to pass specific flags to that assembler. The -n can be used to prevent dlltool from deleting these temporary assembler files when it is done, and if -n is specified twice then this will prevent dlltool from deleting the temporary object files it used to build the library. Here is an example of creating a DLL from a source file dll.c and also creating a program (from an object file called program.o) that uses that DLL: gcc -c dll.c\ndlltool -e exports.o -l dll.lib dll.o\ngcc dll.o exports.o -o dll.dll\ngcc program.o dll.lib -o program dlltool may also be used to query an existing import library to determine the name of the DLL to which it is associated. See the description of the -I or --identify option.","Process Name":"mips64-linux-gnu-dlltool","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-dlltool"}},{"Process":{"Description":"elfedit updates the ELF header of ELF files which have the matching ELF machine and file types. The options control how and which fields in the ELF header should be updated. elffile... are the ELF files to be updated. 32-bit and 64-bit ELF files are supported, as are archives containing ELF files.","Process Name":"mips64-linux-gnu-elfedit","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-elfedit"}},{"Process":{"Description":null,"Process Name":"mips64-linux-gnu-gcc","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-gcc"}},{"Process":{"Description":"gcov is a test coverage program. Use it in concert with GCC to analyze your programs to help create more efficient, faster running code and to discover untested parts of your program. You can use gcov as a profiling tool to help discover where your optimization efforts will best affect your code. You can also use gcov along with the other profiling tool, gprof, to assess which parts of your code use the greatest amount of computing time. Profiling tools help you analyze your code's performance. Using a profiler such as gcov or gprof, you can find out some basic performance statistics, such as: \u2022 how often each line of code executes \u2022 what lines of code are actually executed \u2022 how much computing time each section of code uses Once you know these things about how your code works when compiled, you can look at each module to see which modules should be optimized. gcov helps you determine where to work on optimization. Software developers also use coverage testing in concert with testsuites, to make sure software is actually good enough for a release. Testsuites can verify that a program works as expected; a coverage program tests to see how much of the program is exercised by the testsuite. Developers can then determine what kinds of test cases need to be added to the testsuites to create both better testing and a better final product. You should compile your code without optimization if you plan to use gcov because the optimization, by combining some lines of code into one function, may not give you as much information as you need to look for 'hot spots' where the code is using a great deal of computer time. Likewise, because gcov accumulates statistics by line (at the lowest resolution), it works best with a programming style that places only one statement on each line. If you use complicated macros that expand to loops or to other control structures, the statistics are less helpful---they only report on the line where the macro call appears. If your complex macros behave like functions, you can replace them with inline functions to solve this problem. gcov creates a logfile called sourcefile.gcov which indicates how many times each line of a source file sourcefile.c has executed. You can use these logfiles along with gprof to aid in fine-tuning the performance of your programs. gprof gives timing information you can use along with the information you get from gcov. gcov works only on code compiled with GCC . It is not compatible with any other profiling or test coverage mechanism.","Process Name":"mips64-linux-gnu-gcov","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-gcov"}},{"Process":{"Description":"\"gprof\" produces an execution profile of C, Pascal, or Fortran77 programs. The effect of called routines is incorporated in the profile of each caller. The profile data is taken from the call graph profile file (gmon.out default) which is created by programs that are compiled with the -pg option of \"cc\", \"pc\", and \"f77\". The -pg option also links in versions of the library routines that are compiled for profiling. \"Gprof\" reads the given object file (the default is \"a.out\") and establishes the relation between its symbol table and the call graph profile from gmon.out. If more than one profile file is specified, the \"gprof\" output shows the sum of the profile information in the given profile files. \"Gprof\" calculates the amount of time spent in each routine. Next, these times are propagated along the edges of the call graph. Cycles are discovered, and calls into a cycle are made to share the time of the cycle. Several forms of output are available from the analysis. The flat profile shows how much time your program spent in each function, and how many times that function was called. If you simply want to know which functions burn most of the cycles, it is stated concisely here. The call graph shows, for each function, which functions called it, which other functions it called, and how many times. There is also an estimate of how much time was spent in the subroutines of each function. This can suggest places where you might try to eliminate function calls that use a lot of time. The annotated source listing is a copy of the program's source code, labeled with the number of times each line of the program was executed.","Process Name":"mips64-linux-gnu-gprof","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-gprof"}},{"Process":{"Description":"ld combines a number of object and archive files, relocates their data and ties up symbol references. Usually the last step in compiling a program is to run ld. ld accepts Linker Command Language files written in a superset of AT&T 's Link Editor Command Language syntax, to provide explicit and total control over the linking process. This man page does not describe the command language; see the ld entry in \"info\" for full details on the command language and on other aspects of the GNU linker. This version of ld uses the general purpose BFD libraries to operate on object files. This allows ld to read, combine, and write object files in many different formats---for example, COFF or \"a.out\". Different formats may be linked together to produce any available kind of object file. Aside from its flexibility, the GNU linker is more helpful than other linkers in providing diagnostic information. Many linkers abandon execution immediately upon encountering an error; whenever possible, ld continues executing, allowing you to identify other errors (or, in some cases, to get an output file in spite of the error). The GNU linker ld is meant to cover a broad range of situations, and to be as compatible as possible with other linkers. As a result, you have many choices to control its behavior.","Process Name":"mips64-linux-gnu-ld","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-ld"}},{"Process":{"Description":"nlmconv converts the relocatable i386 object file infile into the NetWare Loadable Module outfile, optionally reading headerfile for NLM header information. For instructions on writing the NLM command file language used in header files, see the linkers section, NLMLINK in particular, of the NLM Development and Tools Overview, which is part of the NLM Software Developer's Kit (\" NLM SDK \"), available from Novell, Inc. nlmconv uses the GNU Binary File Descriptor library to read infile; nlmconv can perform a link step. In other words, you can list more than one object file for input if you list them in the definitions file (rather than simply specifying one input file on the command line). In this case, nlmconv calls the linker for you.","Process Name":"mips64-linux-gnu-nlmconv","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-nlmconv"}},{"Process":{"Description":null,"Process Name":"mips64-linux-gnu-nm","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-nm"}},{"Process":{"Description":"The GNU objcopy utility copies the contents of an object file to another. objcopy uses the GNU BFD Library to read and write the object files. It can write the destination object file in a format different from that of the source object file. The exact behavior of objcopy is controlled by command-line options. Note that objcopy should be able to copy a fully linked file between any two formats. However, copying a relocatable object file between any two formats may not work as expected. objcopy creates temporary files to do its translations and deletes them afterward. objcopy uses BFD to do all its translation work; it has access to all the formats described in BFD and thus is able to recognize most formats without being told explicitly. objcopy can be used to generate S-records by using an output target of srec (e.g., use -O srec). objcopy can be used to generate a raw binary file by using an output target of binary (e.g., use -O binary). When objcopy generates a raw binary file, it will essentially produce a memory dump of the contents of the input object file. All symbols and relocation information will be discarded. The memory dump will start at the load address of the lowest section copied into the output file. When generating an S-record or a raw binary file, it may be helpful to use -S to remove sections containing debugging information. In some cases -R will be useful to remove sections which contain information that is not needed by the binary file. Note---objcopy is not able to change the endianness of its input files. If the input format has an endianness (some formats do not), objcopy can only copy the inputs into file formats that have the same endianness or which have no endianness (e.g., srec). (However, see the --reverse-bytes option.)","Process Name":"mips64-linux-gnu-objcopy","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-objcopy"}},{"Process":{"Description":null,"Process Name":"mips64-linux-gnu-objdump","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-objdump"}},{"Process":{"Description":"ranlib generates an index to the contents of an archive and stores it in the archive. The index lists each symbol defined by a member of an archive that is a relocatable object file. You may use nm -s or nm --print-armap to list this index. An archive with such an index speeds up linking to the library and allows routines in the library to call each other without regard to their placement in the archive. The GNU ranlib program is another form of GNU ar; running ranlib is completely equivalent to executing ar -s.","Process Name":"mips64-linux-gnu-ranlib","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-ranlib"}},{"Process":{"Description":"readelf displays information about one or more ELF format object files. The options control what particular information to display. elffile... are the object files to be examined. 32-bit and 64-bit ELF files are supported, as are archives containing ELF files. This program performs a similar function to objdump but it goes into more detail and it exists independently of the BFD library, so if there is a bug in BFD then readelf will not be affected.","Process Name":"mips64-linux-gnu-readelf","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-readelf"}},{"Process":{"Description":"The GNU size utility lists the section sizes---and the total size---for each of the object or archive files objfile in its argument list. By default, one line of output is generated for each object file or each module in an archive. objfile... are the object files to be examined. If none are specified, the file \"a.out\" will be used.","Process Name":"mips64-linux-gnu-size","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-size"}},{"Process":{"Description":"For each file given, GNU strings prints the printable character sequences that are at least 4 characters long (or the number given with the options below) and are followed by an unprintable character. By default, it only prints the strings from the initialized and loaded sections of object files; for other types of files, it prints the strings from the whole file. strings is mainly useful for determining the contents of non-text files.","Process Name":"mips64-linux-gnu-strings","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-strings"}},{"Process":{"Description":"GNU strip discards all symbols from object files objfile. The list of object files may include archives. At least one object file must be given. strip modifies the files named in its argument, rather than writing modified copies under different names.","Process Name":"mips64-linux-gnu-strip","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-strip"}},{"Process":{"Description":null,"Process Name":"mips64-linux-gnu-windmc","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-windmc"}},{"Process":{"Description":"windres reads resources from an input file and copies them into an output file. Either file may be in one of three formats: \"rc\" A text format read by the Resource Compiler. \"res\" A binary format generated by the Resource Compiler. \"coff\" A COFF object or executable. The exact description of these different formats is available in documentation from Microsoft. When windres converts from the \"rc\" format to the \"res\" format, it is acting like the Windows Resource Compiler. When windres converts from the \"res\" format to the \"coff\" format, it is acting like the Windows \"CVTRES\" program. When windres generates an \"rc\" file, the output is similar but not identical to the format expected for the input. When an input \"rc\" file refers to an external filename, an output \"rc\" file will instead include the file contents. If the input or output format is not specified, windres will guess based on the file name, or, for the input file, the file contents. A file with an extension of .rc will be treated as an \"rc\" file, a file with an extension of .res will be treated as a \"res\" file, and a file with an extension of .o or .exe will be treated as a \"coff\" file. If no output file is specified, windres will print the resources in \"rc\" format to standard output. The normal use is for you to write an \"rc\" file, use windres to convert it to a COFF object file, and then link the COFF file into your application. This will make the resources described in the \"rc\" file available to Windows.","Process Name":"mips64-linux-gnu-windres","Link":"https:\/\/linux.die.net\/man\/1\/mips64-linux-gnu-windres"}},{"Process":{"Description":"Miro is a platform for Internet television and video. An intuitive interface lets users subscribe to channels, watch video, and build a video library.","Process Name":"miro","Link":"https:\/\/linux.die.net\/man\/1\/miro"}},{"Process":{"Description":"Draws a wobbling blob, making use of alpha blending, fog, textures, and lighting, plus a ''frames per second'' meter so that you can tell how fast your graphics card is... Requires OpenGL.","Process Name":"mirrorblob","Link":"https:\/\/linux.die.net\/man\/1\/mirrorblob"}},{"Process":{"Description":"mirrordir is a set of useful utilities for manipulating and mirroring directories. Included is also the command pslogin - an alternative to ssh(1), and forward(1) for forwarding arbitrary TCP socket connections over encrypted secure channels. mirrordir copies files that are different between the directories control and mirror to the directory mirror. Files whose modification times or sizes differ are copied. File permissions, ownerships, modification times, access times (only if --access-times is used), sticky bits, and device types are duplicated. Symlinks are duplicated without any translation. Symlink modification and access times (of the symlink itself, not the file it points to) are not preserved. Hard linked files are merely copied. Creation times cannot be set with Unix as far as I can see. mirrordir is a DANGEROUS command because files or directories that exist in mirror that don't exist in control are deleted. If control is entirely empty, then all files and directories in mirror will be deleted. If mirror is entirely empty, then all files and directories in control will be copied. In short, mirrordir forces mirror to be an exact replica of the directory tree control in every possible detail suitable for purposes of timed backup. It naturally descends into subdirectories to all their depths. mirrordir tries to be as efficient as possible by making the minimal set of changes necessary to mirror the directory. Access time duplication is not usually required and creates unnecessary load. Hence it is given as an option. The directory control is left untouched. If --restore-access is given then access times are reset to their original with each read. If the the --strict-locking option is on, files in control that are copied are locked for 'shared reading'. This will ensure, if another process is busy writing to that file, that the file is not copied in its incomplete or corrupted state. Usually mirrordir will not exit, but will give error messages to stderr to report any problems, and then will continue. The directory mirror or dest must exist, even if it is empty. Before erasing all the files in a directory, mirrordir checks for the file *--keep-me (where * is zero or one characters). If this file is present it will abort with an error message. Hence such a file can be created in all directories that you are fearful of being recursively erased. copydir is equivalent to mirrordir -ck --no-erase-directories ... (although -c implies -k anyway), so copydir is very much like a rigorous version of cp(1) where filenames can also be URLs, and only outdated files are replaced. Use copydir instead of mirrordir for most file transfers. Only use mirrordir, when you really want to delete things. recursdir is a further program that does nothing but descend into the directories on the command line. It is equivalent to mirrordir --recurs-mode ... It was born after the -C option was added, and can be used as a more rigorous version of find(1) and can also pack all the files it finds into a tar file. pslogin is yet a further program which has almost nothing to do with the previous three. It envokes a secure login session using secure-mcserv. It is equivalent to mirrordir --login-mode --secure ... pslogin should be called logindir. See --login-mode below. forward is yet a further program which has almost nothing to do with first three. It can do forwarding of arbitrary services over a secure channel. See forward(1) for details. The importance of this package is that you can use URL's instead of normal filenames, and hence manipulate files over a network. The URL types currently supported are ftp:\/\/ and mc:\/\/ (http:\/\/ is not a filesystem and therefore is not supported). mc:\/\/ is the Midnight Commander filesystem and is served by the secure-mcserv daemon. It has the advantage of serving cryptographically strong secure file transfers and logins. You can also use glob expressions in filenames for the recursdir and copydir commands. These will be recursively expanded.","Process Name":"mirrordir","Link":"https:\/\/linux.die.net\/man\/1\/mirrordir"}},{"Process":{"Description":"The mismunch program is a creatively broken misimplementation of the classic munching squares graphics hack.","Process Name":"mismunch","Link":"https:\/\/linux.die.net\/man\/1\/mismunch"}},{"Process":{"Description":"mispipe pipes two commands together like the shell does, but unlike piping in the shell, the exit status of the first command is returned. Note that some shells, notably bash, do offer a pipefail option, however, that option does not behave the same since it makes a failure of any command in the pipeline be returned, not just the exit status of the first.","Process Name":"mispipe","Link":"https:\/\/linux.die.net\/man\/1\/mispipe"}},{"Process":{"Description":null,"Process Name":"missidentify","Link":"https:\/\/linux.die.net\/man\/1\/missidentify"}},{"Process":{"Description":"","Process Name":"mjpegtools","Link":"https:\/\/linux.die.net\/man\/1\/mjpegtools"}},{"Process":{"Description":"mk-archiver is the tool I use to archive tables as described in <http:\/\/tinyurl.com\/mysql-archiving>. The goal is a low-impact, forward-only job to nibble old data out of the table without impacting OLTP queries much. You can insert the data into another table, which need not be on the same server. You can also write it to a file in a format suitable for LOAD DATA INFILE . Or you can do neither, in which case it's just an incremental DELETE . mk-archiver is extensible via a plugin mechanism. You can inject your own code to add advanced archiving logic that could be useful for archiving dependent data, applying complex business rules, or building a data warehouse during the archiving process. You need to choose values carefully for some options. The most important are \"--limit\", \"--retries\", and \"--txn-size\". The strategy is to find the first row(s), then scan some index forward-only to find more rows efficiently. Each subsequent query should not scan the entire table; it should seek into the index, then scan until it finds more archivable rows. Specifying the index with the 'i' part of the \"--source\" argument can be crucial for this; use \"--dry-run\" to examine the generated queries and be sure to EXPLAIN them to see if they are efficient (most of the time you probably want to scan the PRIMARY key, which is the default). Even better, profile mk-archiver with mk-query-profiler and make sure it is not scanning the whole table every query. You can disable the seek-then-scan optimizations partially or wholly with \"--no-ascend\" and \"--ascend-first\". Sometimes this may be more efficient for multi-column keys. Be aware that mk-archiver is built to start at the beginning of the index it chooses and scan it forward-only. This might result in long table scans if you're trying to nibble from the end of the table by an index other than the one it prefers. See \"--source\" and read the documentation on the \"i\" part if this applies to you.","Process Name":"mk-archiver","Link":"https:\/\/linux.die.net\/man\/1\/mk-archiver"}},{"Process":{"Description":"This program takes the unsorted, verbose output from mk-table-checksum and sorts it, then filters it so you only see lines that have different checksums or counts. You can pipe input directly into it from mk-table-checksum, or you can save the mk-table-checksum's output and run mk-checksum-filter on the resulting file(s). If you run it against just one file, or pipe output directly into it, it'll output results during processing. Processing multiple files is slightly more expensive, and you won't see any output until they're all read.","Process Name":"mk-checksum-filter","Link":"https:\/\/linux.die.net\/man\/1\/mk-checksum-filter"}},{"Process":{"Description":null,"Process Name":"mk-deadlock-logger","Link":"https:\/\/linux.die.net\/man\/1\/mk-deadlock-logger"}},{"Process":{"Description":"This program examines the output of SHOW CREATE TABLE on MySQL tables, and if it finds indexes that cover the same columns as another index in the same order, or cover an exact leftmost prefix of another index, it prints out the suspicious indexes. By default, indexes must be of the same type, so a BTREE index is not a duplicate of a FULLTEXT index, even if they have the same colums. You can override this. It also looks for duplicate foreign keys. A duplicate foreign key covers the same columns as another in the same table, and references the same parent table.","Process Name":"mk-duplicate-key-checker","Link":"https:\/\/linux.die.net\/man\/1\/mk-duplicate-key-checker"}},{"Process":{"Description":null,"Process Name":"mk-error-log","Link":"https:\/\/linux.die.net\/man\/1\/mk-error-log"}},{"Process":{"Description":"mk-fifo-split lets you read from a file as though it contains only some of the lines in the file. When you read from it again, it contains the next set of lines; when you have gone all the way through it, the file disappears. This works only on Unix-like operating systems. You can specify multiple files on the command line. If you don't specify any, or if you use the special filename \"-\", lines are read from standard input.","Process Name":"mk-fifo-split","Link":"https:\/\/linux.die.net\/man\/1\/mk-fifo-split"}},{"Process":{"Description":"mk-find looks for MySQL tables that pass the tests you specify, and executes the actions you specify. The default action is to print the database and table name to STDOUT . mk-find is simpler than GNU find. It doesn't allow you to specify complicated expressions on the command line. mk-find uses SHOW TABLES when possible, and SHOW TABLE STATUS when needed.","Process Name":"mk-find","Link":"https:\/\/linux.die.net\/man\/1\/mk-find"}},{"Process":{"Description":"mk-heartbeat is a two-part MySQL and PostgreSQL replication delay monitoring system that measures delay by looking at actual replicated data. This avoids reliance on the replication mechanism itself, which is unreliable. (For example, \"SHOW SLAVE STATUS\" on MySQL). The first part is an instance of mk-heartbeat that connects to the master and updates a timestamp (\"heartbeat record\") every second with \"--update\". The second part is another mk-heartbeat instance that connects to the slave, examines the replicated heartbeat with \"--monitor\" or \"--check\", and computes the difference from the current system time. If the slave's replication is delayed or broken, the heartbeat will become stale. You must either manually create a heartbeat table on the master and insert one row, or use \"--create-table\". See \"--create-table\" for the proper heartbeat table structure. The \"MEMORY\" storage engine is suggested, but not required of course, for MySQL. mk-heartbeat depends only on the heartbeat record being replicated to the slave, so it works regardless of the replication mechanism (built-in replication, a system such as Continuent Tungsten, etc). It works at any depth in the replication hierarchy; for example, it will reliably report how far a slave lags its master's master's master. And if replication is stopped, it will continue to work and report (accurately!) that the slave is falling further and further behind the master. mk-heartbeat has a one-second resolution. It depends on the clocks on the master and slave servers being closely synchronized via NTP . \"--update\" checks happen on the edge of the second, and \"--monitor\" checks happen halfway between seconds. As long as the servers' clocks aren't skewed much and the replication events are propagating in less than half a second, mk-heartbeat will report zero seconds of delay. mk-heartbeat will try to reconnect if the connection has an error, but will not retry if it can't get a connection when it first starts. The \"--dbi-driver\" option lets you use mk-heartbeat to monitor PostgreSQL as well. It is reported to work well with Slony-1 replication.","Process Name":"mk-heartbeat","Link":"https:\/\/linux.die.net\/man\/1\/mk-heartbeat"}},{"Process":{"Description":"This tool connects to a MySQL database server, reads through a query log, and uses EXPLAIN to ask MySQL how it will use each query. When it is finished, it prints out a report on indexes that the queries didn't use. The query log needs to be in MySQL's slow query log format. If you need to input a different format, you can use mk-query-digest to translate the formats. If you don't specify a filename, the tool reads from STDIN . The tool runs two stages. In the first stage, the tool takes inventory of all the tables and indexes in your database, so it can compare the existing indexes to those that were actually used by the queries in the log. In the second stage, it runs EXPLAIN on each query in the query log. It uses separate database connections to inventory the tables and run EXPLAIN , so it opens two connections to the database. If a query is not a SELECT , it tries to transform it to a roughly equivalent SELECT query so it can be EXPLAINed. This is not a perfect process, but it is good enough to be useful. The tool skips the EXPLAIN step for queries that are exact duplicates of those seen before. It assumes that the same query will generate the same EXPLAIN plan as it did previously (usually a safe assumption, and generally good for performance), and simply increments the count of times that the indexes were used. However, queries that have the same fingerprint but different checksums will be re-EXPLAINed. Queries that have different literal constants can have different execution plans, and this is important to measure. After EXPLAIN-ing the query, it is necessary to try to map aliases in the query back to the original table names. For example, consider the EXPLAIN plan for the following query: SELECT * FROM tbl1 AS foo; The EXPLAIN output will show access to table \"foo\", and that must be translated back to \"tbl1\". This process involves complex parsing. It is generally very accurate, but there is some chance that it might not work right. If you find cases where it fails, submit a bug report and a reproducible test case. Queries that cannot be EXPLAINed will cause all subsequent queries with the same fingerprint to be blacklisted. This is to reduce the work they cause, and prevent them from continuing to print error messages. However, at least in this stage of the tool's development, it is my opinion that it's not a good idea to pre-emtively silence these, or prevent them from being EXPLAINed at all. I am looking for lots of feedback on how to improve things like the query parsing. So please submit your test cases based on the errors the tool prints!","Process Name":"mk-index-usage","Link":"https:\/\/linux.die.net\/man\/1\/mk-index-usage"}},{"Process":{"Description":null,"Process Name":"mk-kill","Link":"https:\/\/linux.die.net\/man\/1\/mk-kill"}},{"Process":{"Description":"mk-loadavg watches a MySQL server and takes action when a defined threshold is exceeded. One or more items can be watched including MySQL status values from SHOW STATUS , SHOW INNODB STATUS and SHOW SLAVE STATUS , the three system load averages from \"uptime\", and values from \"vmstat\". Watched items and their threshold values are specified by \"--watch\". Every item is checked at intervals (see \"--interval\"). By default, if any one item's check returns true (i.e. its threshold is exceeded), then \"--execute-command\" is executed. Specifying \"--and\" requires that every item has exceeded its threshold before \"--execute-command\" is executed.","Process Name":"mk-loadavg","Link":"https:\/\/linux.die.net\/man\/1\/mk-loadavg"}},{"Process":{"Description":null,"Process Name":"mk-log-player","Link":"https:\/\/linux.die.net\/man\/1\/mk-log-player"}},{"Process":{"Description":"This is a light-weight script for merging and reporting on results saved by mk-query-digest --save-results.","Process Name":"mk-merge-mqd-results","Link":"https:\/\/linux.die.net\/man\/1\/mk-merge-mqd-results"}},{"Process":{"Description":"mk-parallel-dump connects to a MySQL server, finds database and table names, and dumps them in parallel for speed. Only tables and data are dumped; view definitions or any kind of stored code (triggers, events, routines, procedures, etc.) are not dumped. However, if you dump the \"mysql\" database, you'll be dumping the stored routines anyway. Exit status is 0 if everything went well, 1 if any chunks failed, and any other value indicates an internal error. To dump all tables to uncompressed text files in the current directory, each database with its own directory, with a global read lock, flushing and recording binary log positions, each table in a single file: mk-parallel-dump To dump tables elsewhere: mk-parallel-dump --base-dir \/path\/to\/elsewhere To dump to tab-separated files with \"SELECT INTO OUTFILE\", each table with separate data and SQL files: mk-parallel-dump --tab mk-parallel-dump doesn't clean out any destination directories before dumping into them. You can move away the old destination, then remove it after a successful dump, with a shell script like the following: #!\/bin\/sh\nCNT=`ls | grep -c old`;\nif [ -d default ]; then mv default default.old.$CNT;\nmk-parallel-dump\nif [ $? != 0 ]\nthen\n   echo \"There were errors, not purging old sets.\"\nelse\n   echo \"No errors during dump, purging old sets.\"\n   rm -rf default.old.*\nfi mk-parallel-dump checks whether files have been created before dumping. If the file has been created, it skips the table or chunk that would have created the file. This makes it possible to resume dumps. If you don't want this behavior, and instead you want a full dump, then move away the old files or specify \"--[no]resume\".","Process Name":"mk-parallel-dump","Link":"https:\/\/linux.die.net\/man\/1\/mk-parallel-dump"}},{"Process":{"Description":"mk-parallel-restore is a way to load SQL or delimited-file dumps into MySQL in parallel at high speed. It is especially designed for restoring files dumped by mk-parallel-dump. It automatically detects whether a file contains SQL or delimited data from the filename extension, and either shells out to \"mysql\" or executes \"LOAD DATA INFILE\" with the file. On UNIX-like systems, it will even make a FIFO to decompress gzipped files for \"LOAD DATA INFILE\". By default it discovers all files in the directory you specify on the command line. It uses the file's parent directory as the database name and the file's name (up to the first dot) as the table name. It can deal with files named like the following: dir\/tbl.sql\ndir\/tbl.txt\ndir\/tbl.csv It is also happy with files that look like this, where \"EXT\" is one of the extensions just listed. dir\/tbl.EXT.000\ndir\/tbl.EXT.000.gz By default, it loads \"SQL\" files first, if they exist, then loads \"CSV\" or \"TXT\" files next, in order of the numbers in the filename extension as just shown. This makes it easy for you to reload a table's definition followed by its data, in case you dumped them into separate files (as happens with \"mysqldump\"'s \"--tab\" option). See mk-parallel-dump for details on how data is dumped. Exit status is 0 if everything went well, 1 if any files failed, and any other value indicates an internal error.","Process Name":"mk-parallel-restore","Link":"https:\/\/linux.die.net\/man\/1\/mk-parallel-restore"}},{"Process":{"Description":null,"Process Name":"mk-profile-compact","Link":"https:\/\/linux.die.net\/man\/1\/mk-profile-compact"}},{"Process":{"Description":"mk-purge-logs purges binary logs on a master based on \"--purge-rules\" by executing \"PURGE BINARY LOGS TO\".","Process Name":"mk-purge-logs","Link":"https:\/\/linux.die.net\/man\/1\/mk-purge-logs"}},{"Process":{"Description":"mk-query-advisor examines queries and applies rules to them, trying to find queries that look bad according to the rules. It reports on queries that match the rules, so you can find bad practices or hidden problems in your SQL . By default, it accepts a MySQL slow query log as input.","Process Name":"mk-query-advisor","Link":"https:\/\/linux.die.net\/man\/1\/mk-query-advisor"}},{"Process":{"Description":"This tool was formerly known as mk-log-parser. \"mk-query-digest\" is a framework for doing things with events from a query source such as the slow query log or PROCESSLIST . By default it acts as a very sophisticated log analysis tool. You can group and sort queries in many different ways simultaneously and find the most expensive queries, or create a timeline of queries in the log, for example. It can also do a \"query review,\" which means to save a sample of each type of query into a MySQL table so you can easily see whether you've reviewed and analyzed a query before. The benefit of this is that you can keep track of changes to your server's queries and avoid repeated work. You can also save other information with the queries, such as comments, issue numbers in your ticketing system, and so on. Note that this is a work in *very* active progress and you should expect incompatible changes in the future.","Process Name":"mk-query-digest","Link":"https:\/\/linux.die.net\/man\/1\/mk-query-digest"}},{"Process":{"Description":"mk-query-profiler reads a file containing one or more SQL statements or shell commands, executes them, and analyzes the output of SHOW STATUS afterwards. It then prints statistics about how the batch performed. For example, it can show how many table scans the batch caused, how many page reads, how many temporary tables, and so forth. All command-line arguments are optional, but you must either specify a file containing the batch to profile as the last argument, or specify that you're profiling an external program with the \"--external\" option, or provide input to STDIN . If the file contains multiple statements, they must be separated by blank lines. If you don't do that, mk-query-profiler won't be able to split the file into individual queries, and MySQL will complain about syntax errors. If the MySQL server version is before 5.0.2, you should make sure the server is completely unused before trying to profile a batch. Prior to this version, SHOW STATUS showed only global status variables, so other queries will interfere and produce false results. mk-query-profiler will try to detect if anything did interfere, but there can be no guarantees. Prior to MySQL 5.0.2, InnoDB status variables are not available, and prior to version 5.0.3, InnoDB row lock status variables are not available. mk-query-profiler will omit any output related to these variables if they're not available. For more information about SHOW STATUS , read the relevant section of the MySQL manual at <http:\/\/dev.mysql.com\/doc\/en\/server-status-variables.html>","Process Name":"mk-query-profiler","Link":"https:\/\/linux.die.net\/man\/1\/mk-query-profiler"}},{"Process":{"Description":"mk-show-grants extracts, orders, and then prints grants for MySQL user accounts. Why would you want this? There are several reasons. The first is to easily replicate users from one server to another; you can simply extract the grants from the first server and pipe the output directly into another server. The second use is to place your grants into version control. If you do a daily automated grant dump into version control, you'll get lots of spurious changesets for grants that don't change, because MySQL prints the actual grants out in a seemingly random order. For instance, one day it'll say GRANT DELETE, INSERT, UPDATE ON `test`.* TO 'foo'@'%'; And then another day it'll say GRANT INSERT, DELETE, UPDATE ON `test`.* TO 'foo'@'%'; The grants haven't changed, but the order has. This script sorts the grants within the line, between ' GRANT ' and ' ON '. If there are multiple rows from SHOW GRANTS , it sorts the rows too, except that it always prints the row with the user's password first, if it exists. This removes three kinds of inconsistency you'll get from running SHOW GRANTS , and avoids spurious changesets in version control. Third, if you want to diff grants across servers, it will be hard without \"canonicalizing\" them, which mk-show-grants does. The output is fully diff-able. With the \"--revoke\", \"--separate\" and other options, mk-show-grants also makes it easy to revoke specific privileges from users. This is tedious otherwise.","Process Name":"mk-show-grants","Link":"https:\/\/linux.die.net\/man\/1\/mk-show-grants"}},{"Process":{"Description":null,"Process Name":"mk-slave-delay","Link":"https:\/\/linux.die.net\/man\/1\/mk-slave-delay"}},{"Process":{"Description":"mk-slave-find connects to a MySQL replication master and finds its slaves. Currently the only thing it can do is print a tree-like view of the replication hierarchy. The master host can be specified using one of two methods. The first method is to use the standard connection-related command line options: \"--defaults-file\", \"--password\", \"--host\", \"--port\", \"--socket\" or \"--user\". The second method to specifiy the master host is a DSN . A DSN is a special syntax that can be either just a hostname (like \"server.domain.com\" or 1.2.3.4), or a \"key=value,key=value\" string. Keys are a single letter: KEY MEANING\n=== =======\nh   Connect to host\nP   Port number to use for connection\nS   Socket file to use for connection\nu   User for login if not current user\np   Password to use when connecting\nF   Only read default options from the given file \"mk-slave-find\" reads all normal MySQL option files, such as ~\/.my.cnf, so you may not need to specify username, password and other common options at all.","Process Name":"mk-slave-find","Link":"https:\/\/linux.die.net\/man\/1\/mk-slave-find"}},{"Process":{"Description":"This tool knows how to disconnect and reconnect slaves to each other, compare replication positions, and so on. This makes it able to move a slave around the replication hierarchy safely and correctly. It doesn't do anything you can't do by hand, but it is tedious and error-prone to do this by hand. The hosts are given by a DSN . A DSN is a special syntax that can be either just a hostname (like \"server.domain.com\" or 1.2.3.4), or a \"key=value,key=value\" string. Keys are a single letter: KEY MEANING\n=== =======\nh   Connect to host\nP   Port number to use for connection\nS   Socket file to use for connection\nu   User for login if not current user\np   Password to use when connecting\nF   Only read default options from the given file If you omit any values in the sibling or uncle host, they are filled in with defaults from the slave host, so you don't need to specify them in both places. \"mk-slave-move\" reads all normal MySQL option files, such as ~\/.my.cnf, so you may not need to specify username, password and other common options at all.","Process Name":"mk-slave-move","Link":"https:\/\/linux.die.net\/man\/1\/mk-slave-move"}},{"Process":{"Description":"mk-slave-prefetch reads the slave's relay log slightly ahead of where the slave's SQL thread is reading, converts statements into \"SELECT\", and executes them. In theory, this should help alleviate the effects of the slave's single-threaded SQL execution. It will help take advantage of multiple CPUs and disks by pre-reading the data from disk, so the data is already in the cache when the slave SQL thread executes the un-modified version of the statement. \"mk-slave-prefetch\" learns how long it takes statements to execute, and doesn't try to execute those that take a very long time. You can ask it to print what it has learned after it executes. You can also specify a filename on the command line. The file should contain the statistics printed by a previous run. These will be used to pre-populate the statistics so it doesn't have to re-learn. This program is based on concepts I heard Paul Tuckfield explain at the November 2006 MySQL Camp un-conference. However, the code is my own work. I have not seen any other implementation of Paul's idea.","Process Name":"mk-slave-prefetch","Link":"https:\/\/linux.die.net\/man\/1\/mk-slave-prefetch"}},{"Process":{"Description":null,"Process Name":"mk-slave-restart","Link":"https:\/\/linux.die.net\/man\/1\/mk-slave-restart"}},{"Process":{"Description":"mk-table-checksum generates table checksums for MySQL tables, typically useful for verifying your slaves are in sync with the master. The checksums are generated by a query on the server, and there is very little network traffic as a result. Checksums typically take about twice as long as COUNT (*) on very large InnoDB tables in my tests. For smaller tables, COUNT (*) is a good bit faster than the checksums. See \"--algorithm\" for more details on performance. If you specify more than one server, mk-table-checksum assumes the first server is the master and others are slaves. Checksums are parallelized for speed, forking off a child process for each table. Duplicate server names are ignored, but if you want to checksum a server against itself you can use two different forms of the hostname (for example, \"localhost 127.0.0.1\", or \"h=localhost,P=3306 h=localhost,P=3307\"). If you want to compare the tables in one database to those in another database on the same server, just checksum both databases: mk-table-checksum --databases db1,db2 You can then use mk-checksum-filter to compare the results in both databases easily. mk-table-checksum examines table structure only on the first host specified, so if anything differs on the others, it won't notice. It ignores views. The checksums work on MySQL version 3.23.58 through 6.0-alpha. They will not necessarily produce the same values on all versions. Differences in formatting and\/or space-padding between 4.1 and 5.0, for example, will cause the checksums to be different.","Process Name":"mk-table-checksum","Link":"https:\/\/linux.die.net\/man\/1\/mk-table-checksum"}},{"Process":{"Description":"mk-table-sync does one-way and bidirectional synchronization of table data. It does not synchronize table structures, indexes, or any other schema objects. The following describes one-way synchronization. \" BIDIRECTIONAL SYNCING \" is described later. This tool is complex and functions in several different ways. To use it safely and effectively, you should understand three things: the purpose of \"--replicate\", finding differences, and specifying hosts. These three concepts are closely related and determine how the tool will run. The following is the abbreviated logic: if DSN has a t part, sync only that table:\n   if 1 DSN:\n      if --sync-to-master:\n         The DSN is a slave.  Connect to its master and sync.\n   if more than 1 DSN:\n      The first DSN is the source.  Sync each DSN in turn.\nelse if --replicate:\n   if --sync-to-master:\n      The DSN is a slave.  Connect to its master, find records\n      of differences, and fix.\n   else:\n      The DSN is the master.  Find slaves and connect to each,\n      find records of differences, and fix.\nelse:\n   if only 1 DSN and --sync-to-master:\n      The DSN is a slave.  Connect to its master, find tables and\n      filter with --databases etc, and sync each table to the master.\n   else:\n      find tables, filtering with --databases etc, and sync each\n      DSN to the first. mk-table-sync can run in one of two ways: with \"--replicate\" or without. The default is to run without \"--replicate\" which causes mk-table-sync to automatically find differences efficiently with one of several algorithms (see \" ALGORITHMS \"). Alternatively, the value of \"--replicate\", if specified, causes mk-table-sync to use the differences already found by having previously ran mk-table-checksum with its own \"--replicate\" option. Strictly speaking, you don't need to use \"--replicate\" because mk-table-sync can find differences, but many people use \"--replicate\" if, for example, they checksum regularly using mk-table-checksum then fix differences as needed with mk-table-sync. If you're unsure, read each tool's documentation carefully and decide for yourself, or consult with an expert. Regardless of whether \"--replicate\" is used or not, you need to specify which hosts to sync. There are two ways: with \"--sync-to-master\" or without. Specifying \"--sync-to-master\" makes mk-table-sync expect one and only slave DSN on the command line. The tool will automatically discover the slave's master and sync it so that its data is the same as its master. This is accomplished by making changes on the master which then flow through replication and update the slave to resolve its differences. Be careful though: although this option specifies and syncs a single slave, if there are other slaves on the same master, they will receive via replication the changes intended for the slave that you're trying to sync. Alternatively, if you do not specify \"--sync-to-master\", the first DSN given on the command line is the source host. There is only ever one source host. If you do not also specify \"--replicate\", then you must specify at least one other DSN as the destination host. There can be one or more destination hosts. Source and destination hosts must be independent; they cannot be in the same replication topology. mk-table-sync will die with an error if it detects that a destination host is a slave because changes are written directly to destination hosts (and it's not safe to write directly to slaves). Or, if you specify \"--replicate\" (but not \"--sync-to-master\") then mk-table-sync expects one and only one master DSN on the command line. The tool will automatically discover all the master's slaves and sync them to the master. This is the only way to sync several (all) slaves at once (because \"--sync-to-master\" only specifies one slave). Each host on the command line is specified as a DSN . The first DSN (or only DSN for cases like \"--sync-to-master\") provides default values for other DSNs, whether those other DSNs are specified on the command line or auto-discovered by the tool. So in this example, mk-table-sync --execute h=host1,u=msandbox,p=msandbox h=host2 the host2 DSN inherits the \"u\" and \"p\" DSN parts from the host1 DSN . Use the \"--explain-hosts\" option to see how mk-table-sync will interpret the DSNs given on the command line.","Process Name":"mk-table-sync","Link":"https:\/\/linux.die.net\/man\/1\/mk-table-sync"}},{"Process":{"Description":"mk-upgrade executes queries from slowlogs on one or more MySQL server to find differences in query time, warnings, results, and other aspects of the querys' execution. This helps to evaluate upgrades, migrations and configuration changes. The comparisons specified by \"--compare\" determine what differences can be found. A report is printed which outlines all the differences found; see \" OUTPUT \" below. The first DSN (host) specified on the command line is authoritative; it defines the results to which the other DSNs are compared. You can \"compare\" only one host, in which case there will be no differences but the output can be saved to be diffed later against the output of another single host \"comparison\". At present, mk-upgrade only reads slowlogs. Use \"mk-query-digest --print\" to transform other log formats to slowlog. DSNs and slowlog files can be specified in any order. mk-upgrade will automatically determine if an argument is a DSN or a slowlog file. If no slowlog files are given and \"--query\" is not specified then mk-upgrade will read from \"STDIN\".","Process Name":"mk-upgrade","Link":"https:\/\/linux.die.net\/man\/1\/mk-upgrade"}},{"Process":{"Description":"mk-variable-advisor examines \"SHOW VARIABLES\" for bad values and settings according to the \" RULES \" described below. It reports on variables that match the rules, so you can find bad settings in your MySQL server. At the time of this release, mk-variable-advisor only examples \"SHOW VARIABLES\", but other input sources are planned like \"SHOW STATUS\" and \"SHOW SLAVE STATUS\".","Process Name":"mk-variable-advisor","Link":"https:\/\/linux.die.net\/man\/1\/mk-variable-advisor"}},{"Process":{"Description":"mk-visual-explain reverse-engineers MySQL's EXPLAIN output into a query execution plan, which it then formats as a left-deep tree -- the same way the plan is represented inside MySQL. It is possible to do this by hand, or to read EXPLAIN 's output directly, but it requires patience and expertise. Many people find a tree representation more understandable. You can pipe input into mk-visual-explain or specify a filename at the command line, including the magical '-' filename, which will read from standard input. It can do two things with the input: parse it for something that looks like EXPLAIN output, or connect to a MySQL instance and run EXPLAIN on the input. When parsing its input, mk-visual-explain understands three formats: tabular like that shown in the mysql command-line client, vertical like that created by using the \\G line terminator in the mysql command-line client, and tab separated. It ignores any lines it doesn't know how to parse. When executing the input, mk-visual-explain replaces everything in the input up to the first SELECT keyword with ' EXPLAIN SELECT ,' and then executes the result. You must specify \"--connect\" to execute the input as a query. Either way, it builds a tree from the result set and prints it to standard output. For the following query, select * from sakila.film_actor join sakila.film using(film_id); mk-visual-explain generates this query plan: JOIN\n+- Bookmark lookup\n|  +- Table\n|  |  table          film_actor\n|  |  possible_keys  idx_fk_film_id\n|  +- Index lookup\n|     key            film_actor->idx_fk_film_id\n|     possible_keys  idx_fk_film_id\n|     key_len        2\n|     ref            sakila.film.film_id\n|     rows           2\n+- Table scan\n   rows           952\n   +- Table\n      table          film\n      possible_keys  PRIMARY The query plan is left-deep, depth-first search, and the tree's root is the output node -- the last step in the execution plan. In other words, read it like this: 1. Table scan the 'film' table, which accesses an estimated 952 rows. 2. For each row, find matching rows by doing an index lookup into the film_actor->idx_fk_film_id index with the value from sakila.film.film_id, then a bookmark lookup into the film_actor table. For more information on how to read EXPLAIN output, please see < http:\/\/dev.mysql.com\/doc\/en\/explain.html>, and this talk titled \"Query Optimizer Internals and What's New in the MySQL 5.2 Optimizer,\" from Timour Katchaounov, one of the MySQL developers: < http:\/\/maatkit.org\/presentations\/katchaounov_timour.pdf>.","Process Name":"mk-visual-explain","Link":"https:\/\/linux.die.net\/man\/1\/mk-visual-explain"}},{"Process":{"Description":"Mk_cmds converts a table listing command names and associated help messages into a C source file suitable for use with the ss(3) library. The source file name must end with a suffix of ''.ct''; the file consists of a declaration supplying the name of the command table: command_table name followed by entries of the form: [ request | unimplemented ] name, \" string \"[, abbrev]...; and a final end to indicate the end of the table. A C source file is generated which should be compiled and linked with the object files use the ss library. A ''#'' in the source file is treated as a comment character, and all remaining text to the end of the source line will be ignored.","Process Name":"mk_cmds","Link":"https:\/\/linux.die.net\/man\/1\/mk_cmds"}},{"Process":{"Description":"A collection of one or more Performance Co-Pilot (see pcpintro(1)) archive logs may be combined with mkaf to produce a PCP archive folio and the associated archive folio control file. Some PCP tools use mkaf to create archive folios, e.g. the ''record'' facility in the pmchart(1) and pmview(1) tools, to facilitate playback with pmafm(1). mkaf processes each filename argument, and if this is a component file from a PCP archive that archive is added to the folio. If filename is a directory, then this is searched recursively using find(1). Any filename argument beginning with a ''-'' is assumed to be a find(1) command line option (findopts); the default is -follow if no findopts are specified. The first named archive in the folio is assumed to be associated with the default host for any tool that tries to replay multiple archives from the folio. The folio control file is written to standard output, and has the following format. 1. The first line contains the word PCPFolio. 2. The second line contains the tag Version: followed by the format version number (currently 1). 3. For subsequent lines, blank lines and lines beginning with ''#'' are ignored. 4. The line beginning with the tag Created: documents where and when the folio was created. 5. The line beginning with the tag Creator: identifies the tool which created the folio (and is assumed to know how to replay the archive folio). If present, the second argument is the name of a configuration file that the creator tool could use to replay the archive folio, e.g. with the replay command for pmafm(1). In the case of mkaf (unlike pmchart(1) or pmview(1)) there is no knowledge of the contents of the archives, so the ''creator'' cannot replay the archive, however pmchart(1) is able to replay any archive, and so this tool is identified as the Creator: for archive folios created by mkaf(1). 6. This is then followed by one or more lines beginning with the tag Archive: followed by the hostname and base name of the archive. For example $ mkaf mydir\/gonzo might produce the following folio control file. PCPFolio\nVersion: 1\n# use pmafm(1) to process this PCP archive folio\n#\nCreated: on gonzo at Tue Jul  2 03:35:54 EST 1996\nCreator: pmchart\n#               Host                    Basename\n#\nArchive:        gonzo                   mydir\/gonzo\/960627\nArchive:        gonzo                   mydir\/gonzo\/960628\nArchive:        gonzo                   mydir\/gonzo\/960629\nArchive:        gonzo                   mydir\/gonzo\/960630\nArchive:        gonzo                   mydir\/gonzo\/960701\nArchive:        gonzo                   mydir\/gonzo\/960701.00.10\nArchive:        gonzo                   mydir\/gonzo\/960701.05.25\nArchive:        gonzo                   mydir\/gonzo\/960702.00.10","Process Name":"mkaf","Link":"https:\/\/linux.die.net\/man\/1\/mkaf"}},{"Process":{"Description":"mkbindic creates a binary-form dictionary (with extension .cbd or dicname) from a text-form dictionary textfile. With -c mkbindic creates old format dictionary. Current supported versions are 3.0 and 3.7.","Process Name":"mkbindic","Link":"https:\/\/linux.die.net\/man\/1\/mkbindic"}},{"Process":{"Description":null,"Process Name":"mkbitmap","Link":"https:\/\/linux.die.net\/man\/1\/mkbitmap"}},{"Process":{"Description":"mkbundle generates an executable program that will contain static copies of the assemblies listed on the command line. By default only the assemblies specified in the command line will be included in the bundle. To automatically include all of the dependencies referenced, use the \"--deps\" command line option. Use mkbundleFP when you want the startup runtime to load the 1.0 profile, and use mkbundle2 when you want the startup runtime to load the 2.0 profile. For example, to create a bundle for hello world, use the following command:     $ mkbundle -o hello hello.exe The above will pull hello.exe into a native program called \"hello\". Notice that the produced image still contains the CIL image and no precompilation is done. In addition, it is possible to control whether mkbundle should compile the resulting executable or not with the -c option. This is useful if you want to link additional libraries or control the generated output in more detail. For example, this could be used to link some libraries statically:     $ mkbundle -c -o host.c -oo bundles.o --deps hello.exe\n    $ cc host.c bundles.o \/usr\/lib\/libmono.a -lc -lrt You may also use mkbundle to generate a bundle you can use when embedding the Mono runtime in a native application. In that case, use both the -c and --nomain options. The resulting host.c file will not have a main() function. Call mono_mkbundle_init() before initializing the JIT in your code so that the bundled assemblies are available to the embedded runtime.","Process Name":"mkbundle","Link":"https:\/\/linux.die.net\/man\/1\/mkbundle"}},{"Process":{"Description":"mkc_check_custom takes a file and tries to compile or runs it. If file is an executable file, mkc_check_custom runs it and outputs 1 if it succeeded or 0 otherwise. If file is not executable, mkc_check_custom tries to compile and (if -r applied ) run a generated executable. Again, if compilation\/run succeeded, 1 is output, otherwise -- 0. What type of compiler to use depend on file extension. '.c' corresponds to ${CC} (C language), '.cc', '.cxx', '.C' and '.cpp' correspond to ${CXX} (C++ language), '.f' -- to ${FC} (Fortran).","Process Name":"mkc_check_custom","Link":"https:\/\/linux.die.net\/man\/1\/mkc_check_custom"}},{"Process":{"Description":null,"Process Name":"mkc_check_decl","Link":"https:\/\/linux.die.net\/man\/1\/mkc_check_decl"}},{"Process":{"Description":"mkc_check_funclib detects presense of function in a library by compiling and linking a test program. As a result it prints either 1 (true) or 0 (false) to stdout.","Process Name":"mkc_check_funclib","Link":"https:\/\/linux.die.net\/man\/1\/mkc_check_funclib"}},{"Process":{"Description":"mkc_check_header detects presense of header file by compiling a test program. As a result it prints either 1 (true) or 0 (false) to stdout.","Process Name":"mkc_check_header","Link":"https:\/\/linux.die.net\/man\/1\/mkc_check_header"}},{"Process":{"Description":null,"Process Name":"mkc_check_prog","Link":"https:\/\/linux.die.net\/man\/1\/mkc_check_prog"}},{"Process":{"Description":"mkc_check_sizeof detects sizeof( type ) by compiling a test program. mkc_check_sizeof doesn't run a generated executable and therefore is ready for using a cross-compiler. headers are #include-d.","Process Name":"mkc_check_sizeof","Link":"https:\/\/linux.die.net\/man\/1\/mkc_check_sizeof"}},{"Process":{"Description":"There is usually only one CID font directory on the X font path. It is usually called \/usr\/X11R6\/lib\/X11\/fonts\/CID. If you do not specify an argument, mkcfm will try to go through the subdirectories of that directory, and create one summary of font metric files for each CIDFont (character descriptions) file and each CMap (Character Maps) file it finds. The summaries of font metric files are put in the existing CFM subdirectory. The CFM subdirectories are created when CID-keyed fonts are installed. If you specify a CID font directory as an argument, mkcfm will try to go through the subdirectories of that directory, and create one summary of font metric files for each CIDFont file and each CMap file it finds. mkcfm will calculate the summaries of the font metric files stored in AFM subdirectories of the CID font directory. Those summaries are needed by the rasterizer of CID-keyed fonts to speed up the response to X font calls. If those files do not exist, CID rasterizer will have to go through usually large font metric files, and calculate the summaries itself each time the font is called. You will notice a substantial wait on a call to a large CID-keyed font.","Process Name":"mkcfm","Link":"https:\/\/linux.die.net\/man\/1\/mkcfm"}},{"Process":{"Description":null,"Process Name":"mkcmake","Link":"https:\/\/linux.die.net\/man\/1\/mkcmake"}},{"Process":{"Description":"mkd2html utility parses a markdown(7)-formatted textfile (or stdin if not specified,) and generates a web page. It reads file or file.text and writes the result in file.html (where file is the passed argument.) mkd2html is part of discount.","Process Name":"mkd2html","Link":"https:\/\/linux.die.net\/man\/1\/mkd2html"}},{"Process":{"Description":"mkdep takes a set of flags for the C compiler and a list of C source files as arguments and constructs a set of include file dependencies which are written into the file ''.depend''. An example of its use in a Makefile might be:  CFLAGS= -O -I..\/include\n SRCS= file1.c file2.c\n\ndepend: mkdep ${CFLAGS} ${SRCS} where the macro SRCS is the list of C source files and the macro CFLAGS is the list of flags for the C compiler. The options are as follows:       -a'        Append to the output file, so that multiple mkdep's may berun from a single Makefile. -f file Write the include file dependencies to file, instead of the default ''.depend''. -p' Cause mkdep to produce dependencies of the form: program: program.c so that subsequent makes will produce program directly from its C module rather than using an intermediate .o module. This is useful for programs whose source is contained in a single module.","Process Name":"mkdep","Link":"https:\/\/linux.die.net\/man\/1\/mkdep"}},{"Process":{"Description":"mkdic creates user dictionary named remote-dic in the user dictionary directory of the remote host, on which cannaserver(1M) is in operation. Dictionary file name remote-dic is assigned to this file at this time. If the - and -l option isn't specified, mkdic creates an empty dictionary. If the - option is specified, the standard input will be used as the dictionary file. If the -l option is specified, local-file will be used as the dictionary file. If the user dictionary directory does not exist, it will be created. Dictionary directory file -- dics.dir -- is rewritten automatically after the registering. The registered dictionary can thus be used by writing the dictionary name into the customize file.","Process Name":"mkdic","Link":"https:\/\/linux.die.net\/man\/1\/mkdic"}},{"Process":{"Description":"Create the DIRECTORY(ies), if they do not already exist. Mandatory arguments to long options are mandatory for short options too. -m, --mode= MODE set file mode (as in chmod), not a=rwx - umask -p, --parents no error if existing, make parent directories as needed -v, --verbose print a message for each created directory -Z, --context= CTX set the SELinux security context of each created directory to CTX --help display this help and exit --version output version information and exit","Process Name":"mkdir","Link":"https:\/\/linux.die.net\/man\/1\/mkdir"}},{"Process":{"Description":null,"Process Name":"mkdirhier","Link":"https:\/\/linux.die.net\/man\/1\/mkdirhier"}},{"Process":{"Description":"The mkeot command writes an EOT (Embedded OpenType) file on standard output that contains the given font file (OpenType or TrueType) and the given URLs. mkeot handles TrueType files, OpenType files with TrueType outlines, and OpenType files with Postscript outlines. (Technically: all files with the \"sfnt\" format.) However, Microsoft's Web browser Internet Explorer (version 8) cannot handle Postscript outlines. To use EOT files with that browser, OpenType files with Postscript outlines must be converted to TrueType files first. Several prgrams are able to do that, including the free fontforge. The URLs that are added to the EOT file list the Web pages on which the EOT font may be used. They act as prefixes, which means that, e.g., a URL such as http:\/\/example.org\/foo enables a font not only for that precise page, but also for http:\/\/example.org\/foo2 or http:\/\/example.org\/foo\/bar or any other pages whose URL starts with the prefix. The EOT specification allows EOT files without any URLs, but is not clear on the meaning of such a file. In practice, at least in Microsoft's Internet Explorer (version 8), an empty list of URLs means the font applies to no Web page at all. EOT font are typically used for Web pages. To that end, a link (URL) to the EOT file must appear in the Web page's style sheet. A typical rule in CSS looks like this: @font-face {\n  font-family: My Fancy Font;\n  font-style: normal;\n  font-weight: normal;\n  src: url(http:\/\/example.org\/fonts\/fancy-roman.eot);\n}\nbody {\n  font-family: My Fancy Font, serif;\n} This downloads the EOT file from the given URL and declares it to be a font of normal weight and roman style with the family name \"My Fancy Font.\" That font can then be used in style rules, such as, in this example, to set the font of body text. See the \"CSS Fonts Module level 3\" for details on CSS. TrueType files typically have the extension .ttf, OpenType files typically have the extension .otf and EOT files typically end in .eot.","Process Name":"mkeot","Link":"https:\/\/linux.die.net\/man\/1\/mkeot"}},{"Process":{"Description":null,"Process Name":"mkfifo","Link":"https:\/\/linux.die.net\/man\/1\/mkfifo"}},{"Process":{"Description":"For each directory argument, mkfontdir reads all of the font files in the directory searching for properties named \"FONT\", or (failing that) the name of the file stripped of its suffix. These are converted to lower case and used as font names, and, along with the name of the font file, are written out to the file \"fonts.dir\" in the directory. The X server and font server use \"fonts.dir\" to find font files. The kinds of font files read by mkfontdir depend on configuration parameters, but typically include PCF (suffix \".pcf\"), SNF (suffix \".snf\") and BDF (suffix \".bdf\"). If a font exists in multiple formats, mkfontdir will first choose PCF, then SNF and finally BDF. The first line of fonts.dir gives the number of fonts in the file. The remaining lines list the fonts themselves, one per line, in two fields. First is the name of the font file, followed by a space and the name of the font.","Process Name":"mkfontdir","Link":"https:\/\/linux.die.net\/man\/1\/mkfontdir"}},{"Process":{"Description":"For each directory argument, mkfontscale reads all of the scalable font files in the directory. For every font file found, an X11 font name (XLFD) is generated, and is written together with the file name to a file fonts.scale in the directory. The resulting fonts.scale file should be checked and possibly manually edited before being used as input for the mkfontdir(1) program.","Process Name":"mkfontscale","Link":"https:\/\/linux.die.net\/man\/1\/mkfontscale"}},{"Process":{"Description":"mkfs.cpm makes a CP\/M file system on an image file or device.","Process Name":"mkfs.cpm","Link":"https:\/\/linux.die.net\/man\/1\/mkfs.cpm"}},{"Process":{"Description":null,"Process Name":"mkhtmlindex","Link":"https:\/\/linux.die.net\/man\/1\/mkhtmlindex"}},{"Process":{"Description":"This is an alpha version of this program. Please let me know what you think and what additional features would be nice. Future version will most likely perform the same but have different output. One idea i've been thinking about is letting you specify filters which short perl snippets instead of just regexes. This program kills long running queries based on several criteria including query time, host, user, database, state, and query content. The following keys are active while mkill is running: q - quit A log of killed queries is sent to STDERR , watched queries are sent to STDOUT . A typical command line would be: mkill -sl 180 -fi 'select.*from bad_table' > \/var\/log\/mkill.out 2> \/var\/log\/mkill.kill","Process Name":"mkill","Link":"https:\/\/linux.die.net\/man\/1\/mkill"}},{"Process":{"Description":"The mkimage command is used to create images for use with the U-Boot boot loader. Thes eimages can contain the linux kernel, device tree blob, root file system image, firmware images etc., either separate or combined. mkimage supports two different formats: The old, legacy image format concatenates the individual parts (for example, kernel image, device tree blob and ramdisk image) and adds a 64 bytes header containing information about target architecture, operating system, image type, compression method, entry points, time stamp, checksums, etc. The new, FIT (Flattened Image Tree) format allows for more flexibility in handling images of various and also enhances integrity protection of images with stronger checksums.","Process Name":"mkimage","Link":"https:\/\/linux.die.net\/man\/1\/mkimage"}},{"Process":{"Description":null,"Process Name":"mkindex","Link":"https:\/\/linux.die.net\/man\/1\/mkindex"}},{"Process":{"Description":"The mkmanifest command is used to create a shell script (packing list) to restore Unix filenames. Its syntax is: mkmanifest [ files ] Mkmanifest creates a shell script that aids in the restoration of Unix filenames that got clobbered by the MS-DOS filename restrictions. MS-DOS filenames are restricted to 8 character names, 3 character extensions, upper case only, no device names, and no illegal characters. The mkmanifest program is compatible with the methods used in pcomm, arc, and mtools to change perfectly good Unix filenames to fit the MS-DOS restrictions. This command is only useful if the target system which will read the diskette cannot handle vfat long names.","Process Name":"mkmanifest","Link":"https:\/\/linux.die.net\/man\/1\/mkmanifest"}},{"Process":{"Description":null,"Process Name":"mkmapfile","Link":"https:\/\/linux.die.net\/man\/1\/mkmapfile"}},{"Process":{"Description":"The mkmupfnt program creates an outfile that can be used with the Mup \"fontfile\" statement to override a Mup font. The PostScript_font_name is the name of the font you want Mup to use. This would be something that could be given as a name to the PostScript findfont procedure. The Mup_font_name is the name of the Mup font you want to override, either an abbreviated name, like \"PR\" or a full name, like \"palatino rom\". The outfile is the file that will be generated, which will contain character size and other information, to use with Mup's \"fontfile\" statement. The final optional file argument is the name of a file that contains PostScript to be placed at the end of the Mup PostScript prolog. This might be useful if you have a font whose implementation PostScript could not find on its own. For example, if you've written your own font implementation, you could put it in the given file. The actual characters produced by the font need not be similar to those in the font being replaced; they could be in some other alphabet, or hieroglyphics or whatever you wish. However, see the CAVEATS section for limitations. An an example, suppose you want Mup to use the Helvetica-Narrow font rather than the plain Helvetica font. You could use: mkmupfnt Helvetica-Narrow HR helvnarr to generate a Mup fontfile, then in your Mup program put: fontfile \"helvnarr\" Then anything that would normally be printed in Helvetica will come out in Helvetica-Narrow instead.","Process Name":"mkmupfnt","Link":"https:\/\/linux.die.net\/man\/1\/mkmupfnt"}},{"Process":{"Description":"Create the special file NAME of the given TYPE. Mandatory arguments to long options are mandatory for short options too. -m, --mode= MODE set file permission bits to MODE, not a=rw - umask -Z, --context= CTX set the SELinux security context of NAME to CTX --help display this help and exit --version output version information and exit Both MAJOR and MINOR must be specified when TYPE is b, c, or u, and they must be omitted when TYPE is p. If MAJOR or MINOR begins with 0x or 0X, it is interpreted as hexadecimal; otherwise, if it begins with 0, as octal; otherwise, as decimal. TYPE may be: b create a block (buffered) special file c, u create a character (unbuffered) special file p create a FIFO NOTE: your shell may have its own version of mknod, which usually supersedes the version described here. Please refer to your shell's documentation for details about the options it supports.","Process Name":"mknod","Link":"https:\/\/linux.die.net\/man\/1\/mknod"}},{"Process":{"Description":null,"Process Name":"mkocp","Link":"https:\/\/linux.die.net\/man\/1\/mkocp"}},{"Process":{"Description":"mkoctfile is used to compile C, C++, or Fortran source code in to a dynamically loadable .oct file for octave(1).","Process Name":"mkoctfile","Link":"https:\/\/linux.die.net\/man\/1\/mkoctfile"}},{"Process":{"Description":null,"Process Name":"mkofm","Link":"https:\/\/linux.die.net\/man\/1\/mkofm"}},{"Process":{"Description":"","Process Name":"mkpasswd","Link":"https:\/\/linux.die.net\/man\/1\/mkpasswd"}},{"Process":{"Description":null,"Process Name":"mkrfc2734","Link":"https:\/\/linux.die.net\/man\/1\/mkrfc2734"}},{"Process":{"Description":"mkromdic compiles a text file file, which defines the translation rule between romaji and kana. In addition to the following options, it is possible to pass cpp(1) options.","Process Name":"mkromdic","Link":"https:\/\/linux.die.net\/man\/1\/mkromdic"}},{"Process":{"Description":null,"Process Name":"mksh","Link":"https:\/\/linux.die.net\/man\/1\/mksh"}},{"Process":{"Description":"This utility build the \/proc like file tree for the given node based on the guids dump file produced by the simulator.","Process Name":"mksimnodedir","Link":"https:\/\/linux.die.net\/man\/1\/mksimnodedir"}},{"Process":{"Description":"The --help prints out a usage message to standard output. --debug, -d Show debug information for plugin loading. --progress, -p Show progress information for plugin loading. --encrypted, -e Encrypt file before writing (will make the extension of the resultant file begin with 'e'). --uid, -u <uid> Application belongs to this uid, and should run with its permissions. --gid, -d <gid> Application belongs to this gid, and should run with its permissions. --append, -a <file> Append given servers to given file, instead of creating a new one. File should be be a tap file. --appname, -n <name> Use the specified name as the process name when the application is run with twistd(1). This option also causes some initialization code to be duplicated when twistd(1) is run. --type, -t <type> Specify the output file type. Available types are: pickle - (default) Output as a python pickle file. xml - Output as a .tax XML file. source - Output as a .tas (AOT Python source) file. apptype Can be 'web', 'portforward', 'toc', 'coil', 'words', 'manhole', 'im', 'news', 'socks', 'telnet', 'parent', 'sibling', 'ftp', and 'mail'. Each of those support different options.","Process Name":"mktap","Link":"https:\/\/linux.die.net\/man\/1\/mktap"}},{"Process":{"Description":"Create a temporary file or directory, safely, and print its name. TEMPLATE must contain at least 3 consecutive 'X's in last component. If TEMPLATE is not specified, use tmp.XXXXXXXXXX, and --tmpdir is implied. -d, --directory create a directory, not a file -u, --dry-run do not create anything; merely print a name (unsafe) -q, --quiet suppress diagnostics about file\/dir-creation failure --suffix= SUFF append SUFF to TEMPLATE. SUFF must not contain slash. This option is implied if TEMPLATE does not end in X. --tmpdir[= DIR] interpret TEMPLATE relative to DIR. If DIR is not specified, use $TMPDIR if set, else \/tmp. With this option, TEMPLATE must not be an absolute name. Unlike with -t, TEMPLATE may contain slashes, but mktemp creates only the final component. -p DIR use DIR as a prefix; implies -t [deprecated] -t interpret TEMPLATE as a single file name component, relative to a directory: $TMPDIR, if set; else the directory specified via -p; else \/tmp [deprecated] --help display this help and exit --version output version information and exit","Process Name":"mktemp","Link":"https:\/\/linux.die.net\/man\/1\/mktemp"}},{"Process":{"Description":null,"Process Name":"mktemplate_gis","Link":"https:\/\/linux.die.net\/man\/1\/mktemplate_gis"}},{"Process":{"Description":"fmtutil is used to create or recreate format and hyphenation files or show information about format files. COMMAND is one of: --all recreate all format files --byfmt formatname (re)create the format for format formatname --byhyphen hyphenfile (re)create formats that depend on the hyphenation file hyphenfile --help print a summary of commands and options --missing create any missing format files --showhyphen formatname print the name of the hyphenation file for the format formatname","Process Name":"mktexfmt","Link":"https:\/\/linux.die.net\/man\/1\/mktexfmt"}},{"Process":{"Description":"This manual page is not meant to be exhaustive. The complete documentation for this version of TeX can be found in the info file or manual Kpathsea: A library for path searching. mktexlsr is used to generate the ls-R databases used by the kpathsea library. It will create them for the specified directories, or for a default list if no directories are specified.","Process Name":"mktexlsr","Link":"https:\/\/linux.die.net\/man\/1\/mktexlsr"}},{"Process":{"Description":"This manual page is not meant to be exhaustive. The complete documentation for this version of TeX can be found in the info file or manual Kpathsea: A library for path searching. mktexmf is used to generate the Metafont source file for font, if possible. For example, ecrm1200 or cmr11. The name of the generated file is printed on standard output. mktexmf is typically called by other programs, rather than from the command line.","Process Name":"mktexmf","Link":"https:\/\/linux.die.net\/man\/1\/mktexmf"}},{"Process":{"Description":null,"Process Name":"mktexpk","Link":"https:\/\/linux.die.net\/man\/1\/mktexpk"}},{"Process":{"Description":"This manual page is not meant to be exhaustive. The complete documentation for this version of TeX can be found in the info file or manual Kpathsea: A library for path searching. mktextfm is used to generate a tfm file from the Metafont source files for font, if possible. If destdir is given, the generated file will be installed there, otherwise a (rather complicated) heuristic is used. The name of the generated file is printed on standard output. mktextfm is typically called by other programs, rather than from the command line.","Process Name":"mktextfm","Link":"https:\/\/linux.die.net\/man\/1\/mktextfm"}},{"Process":{"Description":null,"Process Name":"mkvextract","Link":"https:\/\/linux.die.net\/man\/1\/mkvextract"}},{"Process":{"Description":"This program lists all elements contained in a Matroska(TM). The output can be limited to a list of tracks in the file including information about the codecs used. -g, --gui Start the GUI. This option is only available if mkvinfo was compiled with GUI support. -c, --checksums Calculates and display the Adler32 checksum for each frame. Useful for debugging only. -s, --summary Only show a terse summary of what mkvinfo(1) finds and not each element. -t, --track-info Show statistics for each track in verbose mode. Also sets verbosity to 1 if it was at level 0 before. -x, --hexdump Show the first 16 bytes of each frame as a hex dump. -X, --full-hexdump Show all bytes of each frame as a hex dump. -z, --size Show the size of each element including its header. --command-line-charset character-set Sets the character set to convert strings given on the command line from. It defaults to the character set given by system's current locale. --output-charset character-set Sets the character set to which strings are converted that are to be output. It defaults to the character set given by system's current locale. -r, --redirect-output file-name Writes all messages to the file file-name instead of to the console. While this can be done easily with output redirection there are cases in which this option is needed: when the terminal reinterprets the output before writing it to a file. The character set set with --output-charset is honored. --ui-language code Forces the translations for the language code to be used (e.g. 'de_DE' for the German translations). It is preferable to use the environment variables LANG, LC_MESSAGES and LC_ALL though. Entering 'list' as the code will cause mkvinfo(1) to output a list of available translations. -v, --verbose Be more verbose. See the section about verbosity levels for a description which information will be output at which level. -h, --help Show usage information and exit. -V, --version Show version information and exit. --check-for-updates Checks online for new releases by downloading the URL http:\/\/mkvtoolnix-releases.bunkus.org\/latest-release.xml. Four lines will be output in key=value style: the URL from where the information was retrieved (key version_check_url), the currently running version (key running_version), the latest release's version (key available_version) and the download URL (key download_url). Afterwards the program exists with an exit code of 0 if no newer release is available, with 1 if a newer release is available and with 2 if an error occured (e.g. if the update information could not be retrieved). This option is only available if the program was built with support for libcurl. @options-file Reads additional command line arguments from the file options-file. Lines whose first non-whitespace character is a hash mark ('#') are treated as comments and ignored. White spaces at the start and end of a line will be stripped. Each line must contain exactly one option. Several chars can be escaped, e.g. if you need to start a non-comment line with '#'. The rules are described in the section about escaping text. The command line 'mkvinfo -v -v input.mkv --redirect-output info.txt' could be converted into the following option file: # Be more verbose\n-v\n-v\n# Parse input.mkv\ninput.mkv\n# and write the output to info.txt\n--redirect-output\ninfo.txt","Process Name":"mkvinfo","Link":"https:\/\/linux.die.net\/man\/1\/mkvinfo"}},{"Process":{"Description":"This program takes the input from several media files and joins their streams (all of them or just a selection) into a Matroska(TM) file; see the Matroska(TM) website [1] . Important The order of command line options is important. Please read the section \"Option order\" if you're new to the program. Global options: -v, --verbose Increase verbosity. -q, --quiet Suppress status output. -o, --output file-name Write to the file file-name. If splitting is used then this parameter is treated a bit differently. See the explanation for the --split option for details. -w, --webm Create a WebM compliant file. This is also turned on if the output file name's extension is \"webm\". This mode enforces several restrictions. The only allowed codecs are VP8 video and Vorbis audio tracks. Neither chapters nor tags are allowed. The DocType header item is changed to \"webm\". --title title Sets the general title for the output file, e.g. the movie name. --default-language language-code Sets the default language code that will be used for all tracks unless overwritten with the --language option. The default language code is 'und' for 'undefined'. Segment info handling: (global options) --segmentinfo filename.xml Read segment information from a XML file. This file can contain the segment family UID, segment UID, previous and next segment UID elements. An example file and a DTD are included in the MKVToolNix distribution. --segment-uid SID1,SID2,... Sets the segment UIDs to use. This is a comma-separated list of 128bit segment UIDs in the usual UID form: hex numbers with or without the \"0x\" prefix, with or without spaces, exactly 32 digits. Each file created contains one segment, and each segment has one segment UID. If more segment UIDs are specified than segments are created then the surplus UIDs are ignored. If fewer UIDs are specified than segments are created then random UIDs will be created for them. Chapter and tag handling: (global options) --chapter-language language-code Sets the ISO639-2 language code that is written for each chapter entry. Defaults to 'eng'. See the section about chapters below for details. This option can be used both for simple chapter files and for source files that contain chapters but no information about the chapters' language, e.g. MP4 and OGM files. --chapter-charset character-set Sets the character set that is used for the conversion to UTF-8 for simple chapter files. See the section about text files and character sets for an explanation how mkvmerge(1) converts between character sets. This switch does also apply to chapters that are copied from certain container types, e.g. Ogg\/OGM and MP4 files. See the section about chapters below for details. --cue-chapter-name-format format mkvmerge(1) supports reading CUE sheets for audio files as the input for chapters. CUE sheets usually contain the entries PERFORMER and TITLE for each index entry. mkvmerge(1) uses these two strings in order to construct the chapter name. With this option the format used for this name can be set. If this option is not given then mkvmerge(1) defaults to the format '%p - %t' (the performer, followed by a space, a dash, another space and the title). If the format is given then everything except the following meta characters is copied as-is, and the meta characters are replaced like this: \u2022 %p is replaced by the current entry's PERFORMER string, \u2022 %t is replaced by the current entry's TITLE string, \u2022 %n is replaced by the current track number and \u2022 %N is replaced by the current track number padded with a leading zero if it is < 10. --chapters file-name Read chapter information from the file file-name. See the section about chapters below for details. --global-tags file-name Read global tags from the file file-name. See the section about tags below for details. General output control (advanced global options): --track-order FID1:TID1,FID2:TID2,... This option changes the order in which the tracks for an input file are created. The argument is a comma separated list of pairs IDs. Each pair contains first the file ID (FID1) which is simply the number of the file on the command line starting at 0. The second is a track ID (TID1) from that file. If some track IDs are omitted then those tracks are created after the ones given with this option have been created. --cluster-length spec Limit the number of data blocks or the duration of data in each cluster. The spec parameter can either be a number n without a unit or a number d postfixed with 'ms'. If no unit is used then mkvmerge(1) will put at most n data blocks into each cluster. The maximum number of blocks is 65535. If the number d is postfixed with 'ms' then mkvmerge(1) puts at most d milliseconds of data into each cluster. The minimum for d is '100ms', and the maximum is '32000ms'. mkvmerge(1) defaults to putting at most 65535 data blocks and 5000ms of data into a cluster. Programs trying to find a certain frame can only seek directly to a cluster and have to read the whole cluster afterwards. Therefore creating larger clusters may lead to imprecise or slow seeking. --no-cues Tells mkvmerge(1) not to create and write the cue data which can be compared to an index in an AVI. Matroska(TM) files can be played back without the cue data, but seeking will probably be imprecise and slower. Use this only if you're really desperate for space or for testing purposes. See also option --cues which can be specified for each input file. --clusters-in-meta-seek Tells mkvmerge(1) to create a meta seek element at the end of the file containing all clusters. See also the section about the Matroska(TM) file layout. --disable-lacing Disables lacing for all tracks. This will increase the file's size, especially if there are many audio tracks. This option is not intended for everyday use. --enable-durations Write durations for all blocks. This will increase file size and does not offer any additional value for players at the moment. --timecode-scale factor Forces the timecode scale factor to factor. Valid values are in the range 1000..10000000 or the special value -1. Normally mkvmerge(1) will use a value of 1000000 which means that timecodes and durations will have a precision of 1ms. For files that will not contain a video track but at least one audio track mkvmerge(1) will automatically chose a timecode scale factor so that all timecodes and durations have a precision of one audio sample. This causes bigger overhead but allows precise seeking and extraction. If the special value -1 is used then mkvmerge(1) will use sample precision even if a video track is present. File splitting, linking and appending (more global options): --split specification Splits the output file after a given size or a given time. Please note that tracks can only be split right before a key frame. Due to buffering mkvmerge(1) will split right before the next key frame after the split point has been reached. Therefore the split point may be a bit off from what the user has specified. At the moment mkvmerge(1) supports three different modes. 1. Splitting by size. Syntax: --split [size:]d[k|m|g] Examples: --split size:700m or --split 150000000 The parameter d may end with 'k', 'm' or 'g' to indicate that the size is in KB, MB or GB respectively. Otherwise a size in Bytes is assumed. After the current output file has reached this size limit a new one will be started. The 'size:' prefix may be omitted for compatibility reasons. 2. Splitting after a duration. Syntax: --split [duration:]HH:MM:SS.nnnnnnnnn|ds Examples: --split duration:00:60:00.000 or --split 3600s The parameter must either have the form HH:MM:SS.nnnnnnnnn for specifying the duration in up to nano-second precision or be a number d followed by the letter 's' for the duration in seconds. HH is the number of hours, MM the number of minutes, SS the number of seconds and nnnnnnnnn the number of nanoseconds. Both the number of hours and the number of nanoseconds can be omitted. There can be up to nine digits after the decimal point. After the duration of the contents in the current output has reached this limit a new output file will be started. The 'duration:' prefix may be omitted for compatibility reasons. 3. Splitting after specific timecodes. Syntax: --split timecodes:A[,B[,C...]] Example: --split timecodes:00:45:00.000,01:20:00.250,6300s The parameters A, B, C etc must all have the same format as the ones used for the duration (see above). The list of timecodes is separated by commas. After the input stream has reached the current split point's timecode a new file is created. Then the next split point given in this list is used. The 'timecodes:' prefix must not be omitted. For this splitting mode the output filename is treated differently than for the normal operation. It may contain a printf like expression '%d' including an optional field width, e.g. '%02d'. If it does then the current file number will be formatted appropriately and inserted at that point in the filename. If there is no such pattern then a pattern of '-%03d' is assumed right before the file's extension: '-o output.mkv' would result in 'output-001.mkv' and so on. If there's no extension then '-%03d' will be appended to the name. --link Link files to one another when splitting the output file. See the section on file linking below for details. --link-to-previous segment-UID Links the first output file to the segment with the segment UID given by the segment-UID parameter. See the section on file linking below for details. --link-to-next segment-UID Links the last output file to the segment with the segment UID given by the segment-UID parameter. See the section on file linking below for details. --append-mode mode Determines how timecodes are calculated when appending files. The parameter mode can have two values: 'file' which is also the default and 'track'. When mkvmerge appends a track (called 'track2_1' from now on) from a second file (called 'file2') to a track (called 'track1_1') from the first file (called 'file1') then it has to offset all timecodes for 'track2_1' by an amount. For 'file' mode this amount is the highest timecode encountered in 'file1' even if that timecode was from a different track than 'track1_1'. In track mode the offset is the highest timecode of 'track1_1'. Unfortunately mkvmerge cannot detect which mode to use reliably. Therefore it defaults to 'file' mode. 'file' mode usually works better for files that have been created independently of each other; e.g. when appending AVI or MP4 files. 'track' mode may work better for sources that are essentially just parts of one big file, e.g. for VOB and EVO files. Subtitle tracks are always treated as if 'file' mode were active even if 'track' mode actually is. --append-to SFID1:STID1:DFID1:DTID1[,...] This option controls to which track another track is appended. Each spec contains four IDs: a file ID, a track ID, a second file ID and a second track ID. The first pair, \"source file ID\" and \"source track ID\", identifies the track that is to be appended. The second pair, \"destination file ID\" and \"destination track ID\", identifies the track the first one is appended to. If this option has been omitted then a standard mapping is used. This standard mapping appends each track from the current file to a track from the previous file with the same track ID. This allows for easy appending if a movie has been split into two parts and both file have the same number of tracks and track IDs with the command mkvmerge -o output.mkv part1.mkv +part2.mkv. + A single '+' causes the next file to be appended instead of added. The '+' can also be put in front of the next file name. Therefore the following two commands are equivalent: $ mkvmerge -o full.mkv file1.mkv + file2.mkv\n$ mkvmerge -o full.mkv file1.mkv +file2.mkv\n\n = Normally mkvmerge looks for files in the same directory as an input file that have the same base name and only differ in their running number (e.g. 'VTS_01_1.VOB', 'VTS_01_2.VOB', 'VTS_01_3.VOB' etc). This option, a single '=', causes mkvmerge not to look for those additional files. The '=' can also be put in front of the next file name. Therefore the following two commands are equivalent: $ mkvmerge -o full.mkv = file1.mkv\n$ mkvmerge -o full.mkv =file1.mkv\n\n Attachment support (more global options): --attachment-description description Plain text description of the following attachment. Applies to the next --attach-file or --attach-file-once option. --attachment-mime-type MIME type MIME type of the following attachment. Applies to the next --attach-file or --attach-file-once option. A list of officially recognized MIME types can be found e.g. at the IANA homepage [2] . The MIME type is mandatory for an attachment. --attachment-name name Sets the name that will be stored in the output file for this attachment. If this option is not given then the name will be derived from the file name of the attachment as given with the --attach-file or the --attach-file-once option. --attach-file file-name, --attach-file-once file-name Creates a file attachment inside the Matroska(TM) file. The MIME type must have been set before this option can used. The difference between the two forms is that during splitting the files attached with --attach-file are attached to all output files while the ones attached with --attach-file-once are only attached to the first file created. If splitting is not used then both do the same. mkvextract(1) can be used to extract attached files from a Matroska(TM) file. Options that can be used for each input file: -a, --audio-tracks [!]n,m,... Copy the audio tracks n, m etc. The numbers are track IDs which can be obtained with the --identify switch. They're not simply the track numbers (see section track IDs). Default: copy all audio tracks. If the IDs are prefixed with ! then the meaning is reversed: copy everything but the IDs listed after the !. -d, --video-tracks [!]n,m,... Copy the video tracks n, m etc. The numbers are track IDs which can be obtained with the --identify switch. They're not simply the track numbers (see section track IDs). Default: copy all video tracks. If the IDs are prefixed with ! then the meaning is reversed: copy everything but the IDs listed after the !. -s, --subtitle-tracks [!]n,m,... Copy the subtitle tracks n, m etc. The numbers are track IDs which can be obtained with the --identify switch. They're not simply the track numbers (see section track IDs). Default: copy all subtitle tracks. If the IDs are prefixed with ! then the meaning is reversed: copy everything but the IDs listed after the !. -b, --button-tracks [!]n,m,... Copy the button tracks n, m etc. The numbers are track IDs which can be obtained with the --identify switch. They're not simply the track numbers (see section track IDs). Default: copy all button tracks. If the IDs are prefixed with ! then the meaning is reversed: copy everything but the IDs listed after the !. --track-tags [!]n,m,... Copy the tags for tracks n, m etc. The numbers are track IDs which can be obtained with the --identify switch (see section track IDs). They're not simply the track numbers. Default: copy tags for all tracks. If the IDs are prefixed with ! then the meaning is reversed: copy everything but the IDs listed after the !. -m, --attachments [!]n[:all|first],m[:all|first],... Copy the attachments with the IDs n, m etc to all or only the first output file. Each ID can be followed by either ':all' (which is the default if neither is entered) or ':first'. If splitting is active then those attachments whose IDs are specified with ':all' are copied to all of the resulting output files while the others are only copied into the first output file. If splitting is not active then both variants have the same effect. The default is to copy all attachments to all output files. If the IDs are prefixed with ! then the meaning is reversed: copy everything but the IDs listed after the !. -A, --no-audio Don't copy any audio track from this file. -D, --no-video Don't copy any video track from this file. -S, --no-subtitles Don't copy any subtitle track from this file. -B, --no-buttons Don't copy any button track from this file. -T, --no-track-tags Don't copy any track specific tags from this file. --no-chapters Don't copy chapters from this file. -M, --no-attachments Don't copy attachments from this file. --no-global-tags Don't copy global tags from this file. --chapter-charset character-set Sets the charset that is used for the conversion to UTF-8 for chapter information contained in the source file. See the section about text files and character sets for an explanation how mkvmerge(1) converts between character sets. --chapter-language language-code Sets the ISO639-2 language code that is written for each chapter entry. This option can be used for source files that contain chapters but no information about the chapters' languages, e.g. for MP4 and OGM files. -y, --sync TID:d[,o[\/p]] Adjust the timecodes of the track with the id TID by d ms. The track IDs are the same as the ones given with --identify (see section track IDs). o\/p: adjust the timestamps by o\/p to fix linear drifts. p defaults to 1 if omitted. Both o and p can be floating point numbers. Defaults: no manual sync correction (which is the same as d = 0 and o\/p = 1.0). This option can be used multiple times for an input file applying to several tracks by selecting different track IDs each time. --cues TID:none|iframes|all Controls for which tracks cue (index) entries are created for the given track (see section track IDs). 'none' inhibits the creation of cue entries. For 'iframes' only blocks with no backward or forward references ( = I frames in video tracks) are put into the cue sheet. 'all' causes mkvmerge(1) to create cue entries for all blocks which will make the file very big. The default is 'iframes' for video tracks and 'none' for all others. See also option --no-cues which inhibits the creation of cue entries regardless of the --cues options used. This option can be used multiple times for an input file applying to several tracks by selecting different track IDs each time. --default-track TID[:bool] Sets the 'default' flag for the given track (see section track IDs) if the optional argument bool is not present. If the user does not explicitly select a track himself then the player should prefer the track that has his 'default' flag set. Only one track of each kind (audio, video, subtitles, buttons) can have his 'default' flag set. If the user wants no track to have the default track flag set then he has to set bool to 0 for all tracks. This option can be used multiple times for an input file applying to several tracks by selecting different track IDs each time. --forced-track TID[:bool] Sets the 'forced' flag for the given track (see section track IDs) if the optional argument bool is not present. A player must play all tracks for which this flag is set to 1. This option can be used multiple times for an input file applying to several tracks by selecting different track IDs each time. --blockadd TID:level Keep only the BlockAdditions up to the level level for the given track. The default is to keep all levels. This option only affects certain kinds of codecs like WAVPACK4. --track-name TID:name Sets the track name for the given track (see section track IDs) to name. --language TID:language Sets the language for the given track (see section track IDs). Both ISO639-2 language codes and ISO639-1 country codes are allowed. The country codes will be converted to language codes automatically. All languages including their ISO639-2 codes can be listed with the --list-languages option. This option can be used multiple times for an input file applying to several tracks by selecting different track IDs each time. -t, --tags TID:file-name Read tags for the track with the number TID from the file file-name. See the section about tags below for details. --aac-is-sbr TID[:0|1] Tells mkvmerge(1) that the track with the ID TID is SBR AAC (also known as HE-AAC or AAC+). This options is needed if a) the source file is an AAC file (not for a Matroska(TM) file) and b) the AAC file contains SBR AAC data. The reason for this switch is that it is technically impossible to automatically tell normal AAC data from SBR AAC data without decoding a complete AAC frame. As there are several patent issues with AAC decoders mkvmerge(1) will never contain this decoding stage. So for SBR AAC files this switch is mandatory. The resulting file might not play back correctly or even not at all if the switch was omitted. If the source file is a Matroska(TM) file then the CodecID should be enough to detect SBR AAC. However, if the CodecID is wrong then this switch can be used to correct that. If mkvmerge wrongfully detects that an AAC file is SBR then you can add ':0' to the track ID. --timecodes TID:file-name Read the timecodes to be used for the specific track ID from file-name. These timecodes forcefully override the timecodes that mkvmerge(1) normally calculates. Read the section about external timecode files. --default-duration TID:x Forces the default duration of a given track to the specified value. Also modifies the track's timecodes to match the default duration. The argument x must be postfixed with 's', 'ms', 'us', 'ns' or 'fps' to specify the default duration in seconds, milliseconds, microseconds, nanoseconds or 'frames per second' respectively. The number x itself can be a floating point number or a fraction. If the default duration is not forced then mkvmerge will try to derive the track's default duration from the container and\/or codec used. One case in which this option is of use is when adding AVC\/h.264 elementary streams because these do not contain information about their number of frames or a default duration for each frame. For such files mkvmerge(1) will assume a default duration of '25fps' unless overridden. This option can also be used to change the FPS of video tracks without having to use an external timecode file. --nalu-size-length TID:n Forces the NALU size length to n bytes. This parameter is only used if the AVC\/h.264 elementary stream packetizer is used. If left out it defaults to 4 bytes, but there are files that contain frames or slices that are all smaller than 65536 bytes. For such files you can use this parameter and decrease the size to 2. --compression TID:n Selects the compression method to be used for the track. Note that the player also has to support this method. Valid values are 'none', 'zlib', 'lzo'\/'lxo1x', 'bz2'\/'bzlib' and 'mpeg4_p2'\/'mpeg4p2'. The values 'lzo'\/'lxo1x' and 'bz2'\/'bzlib' are only available if mkvmerge(1) has been compiled with support for the liblzo(TM) and bzlib(TM) compression libraries, respectively. The compression method 'mpeg4_p2'\/'mpeg4p2' is a special compression method called 'header removal' that is only available for MPEG4 part 2 video tracks. The default for some subtitle tracks is 'zlib' compression. This compression method is also the one that most if not all playback applications support. Support for other compression methods other than 'none' is not assured. Options that only apply to video tracks: -f, --fourcc TID:FourCC Forces the FourCC to the specified value. Works only for video tracks in the 'MS compatibility mode'. --display-dimensions TID:widthxheight Matroska(TM) files contain two values that set the display properties that a player should scale the image on playback to: display width and display height. These values can be set with this option, e.g. '1:640x480'. Another way to specify the values is to use the --aspect-ratio or the --aspect-ratio-factor option (see below). These options are mutually exclusive. --aspect-ratio TID:ratio|width\/height Matroska(TM) files contain two values that set the display properties that a player should scale the image on playback to: display width and display height. With this option mkvmerge(1) will automatically calculate the display width and display height based on the image's original width and height and the aspect ratio given with this option. The ratio can be given either as a floating point number ratio or as a fraction 'width\/height', e.g. '16\/9'. Another way to specify the values is to use the --aspect-ratio-factor or --display-dimensions options (see above and below). These options are mutually exclusive. --aspect-ratio-factor TID:factor|n\/d Another way to set the aspect ratio is to specify a factor. The original aspect ratio is first multiplied with this factor and used as the target aspect ratio afterwards. Another way to specify the values is to use the --aspect-ratio or --display-dimensions options (see above). These options are mutually exclusive. --cropping TID:left,top,right,bottom Sets the pixel cropping parameters of a video track to the given values. --stereo-mode TID:n|keyword Sets the stereo mode for the video track with the track ID TID. The mode can either be a number n between 0 and 11 or one of these keywords: 'mono', 'side_by_side_left_first', 'top_bottom_right_first', 'top_bottom_left_first', 'checkerboard_right_first', 'checkerboard_left_first', 'row_interleaved_right_first', 'row_interleaved_left_first', 'column_interleaved_right_first', 'column_interleaved_left_first', 'anaglyph', 'side_by_side_right_first'. Options that only apply to text subtitle tracks: --sub-charset TID:character-set Sets the character set for the conversion to UTF-8 for UTF-8 subtitles for the given track ID. If not specified the charset will be derived from the current locale settings. Note that a charset is not needed for subtitles read from Matroska(TM) files or from Kate streams, as these are always stored in UTF-8. See the section about text files and character sets for an explanation how mkvmerge(1) converts between character sets. This option can be used multiple times for an input file applying to several tracks by selecting different track IDs each time. Other options: -i, --identify file-name Will let mkvmerge(1) probe the single file and report its type, the tracks contained in the file and their track IDs. If this option is used then the only other option allowed is the filename. -I, --identify-verbose file-name Will let mkvmerge(1) probe the single file and report its type, the tracks contained in the file and their track IDs. If this option is used then the only other option allowed is the filename. This option causes mkvmerge(1) to output additional information about the container and each track within. The extra information is surronded by square brackets. It consists of space-saparated key\/value pairs where keys and values are separated by a colon. Each value is escaped according to the rules described in the section about escaping special characters in text. -l, --list-types Lists supported input file types. --list-languages Lists all languages and their ISO639-2 code which can be used with the --language option. --priority priority Sets the process priority that mkvmerge(1) runs with. Valid values are 'lowest', 'lower', 'normal', 'higher' and 'highest'. If nothing is given then 'normal' is used. On Unix like systems mkvmerge(1) will use the nice(2) function. Therefore only the super user can use 'higher' and 'highest'. On Windows all values are useable for every user. --command-line-charset character-set Sets the character set to convert strings given on the command line from. It defaults to the character set given by system's current locale. This settings applies to arguments of the following options: --title, --track-name and --attachment-description. --output-charset character-set Sets the character set to which strings are converted that are to be output. It defaults to the character set given by system's current locale. -r, --redirect-output file-name Writes all messages to the file file-name instead of to the console. While this can be done easily with output redirection there are cases in which this option is needed: when the terminal reinterprets the output before writing it to a file. The character set set with --output-charset is honored. --ui-language code Forces the translations for the language code to be used (e.g. 'de_DE' for the German translations). It is preferable to use the environment variables LANG, LC_MESSAGES and LC_ALL though. Entering 'list' as the code will cause mkvmerge(1) to output a list of available translations. @options-file Reads additional command line arguments from the file options-file. Lines whose first non-whitespace character is a hash mark ('#') are treated as comments and ignored. White spaces at the start and end of a line will be stripped. Each line must contain exactly one option. Several chars can be escaped, e.g. if you need to start a non-comment line with '#'. The rules are described in the section about escaping text. The command line 'mkvmerge -o \"my file.mkv\" -A \"a movie.avi\" sound.ogg' could be converted into the following option file: # Write to the file \"my file.mkv\".\n-o\nmy file.mkv\n# Only take the video from \"a movie.avi\".\n-A\na movie.avi\nsound.ogg\n\n --capabilities Lists information about optional features that have been compiled in and exit. The first line output will be the version information. All following lines contain exactly one word whose presence indicates that the feature has been compiled in. These features are: \u2022 'BZ2' -- the bzlib(TM) compression library. Affects the available compression methods for the --compression option. \u2022 'LZO' -- the lzo(TM) compression library. Affects the available compression methods for the --compression option. \u2022 'FLAC' -- reading raw FLAC files and handling FLAC tracks in other containers, e.g. Ogg(TM) or Matroska(TM). -h, --help Show usage information and exit. -V, --version Show version information and exit. --check-for-updates Checks online for new releases by downloading the URL http:\/\/mkvtoolnix-releases.bunkus.org\/latest-release.xml. Four lines will be output in key=value style: the URL from where the information was retrieved (key version_check_url), the currently running version (key running_version), the latest release's version (key available_version) and the download URL (key download_url). Afterwards the program exists with an exit code of 0 if no newer release is available, with 1 if a newer release is available and with 2 if an error occured (e.g. if the update information could not be retrieved). This option is only available if the program was built with support for libcurl.","Process Name":"mkvmerge","Link":"https:\/\/linux.die.net\/man\/1\/mkvmerge"}},{"Process":{"Description":"mmg(1) is a wxWindows(TM) based GUI for mkvmerge(1). It offers easy access to all of mkvmerge(1)'s options. All settings (e.g. source files, track options etc) can be saved and restored. Included is a chapter editor that can read OGM style and XML style chapter files, write XML style chapter files and even read chapters from Matroska(TM) files and write chapters directly to Matroska(TM) files. Included is also a header editor that can be used to quickly change properties of existing Matroska(TM) files without needing a complete remux. mmg(1) knows few options. The first possibility is to start it with a single file name. If that file name's extenion is '.mmg' then it will be treated as a preferences file and mmg(1) will load its setting when it starts. Otherwise the name is interpreted as being the name of an input file which will be added. The second operation mode is invoked with the option --edit-headers and a file name. This lets mmg(1) run its header editor and load the file. The full documentation is available in HTML form (doc\/mkvmerge-gui.html).","Process Name":"mkvmerge-gui","Link":"https:\/\/linux.die.net\/man\/1\/mkvmerge-gui"}},{"Process":{"Description":"This program analyses an existing Matroska(TM) file and modifies some of its properties. Then it writes those modifications to the existing file. Among the properties that can be changed are the segment information elements (e.g. the title) and the track headers (e.g. the language code, 'default track' flag or the name). Options: -l, --list-property-names Lists all known and editable property names, their type (string, integer, boolean etc) and a short description. The program exits afterwards. Therefore the source-filename parameter does not have to be supplied. -p, --parse-mode mode Sets the parse mode. The parameter ' mode' can either be 'fast' (which is also the default) or 'full'. The 'fast' mode does not parse the whole file but uses the meta seek elements for locating the required elements of a source file. In 99% of all cases this is enough. But for files that do not contain meta seek elements or which are damaged the user might have to set the 'full' parse mode. A full scan of a file can take a couple of minutes while a fast scan only takes seconds. Actions: -e, --edit selector Sets the Matroska(TM) file section (segment information or a certain track's headers) that all following add, set and delete actions operate on. This option can be used multiple times in order to make modifications to more than one element. By default mkvpropedit(1) will edit the segment information section. See the section about edit selectors for a full description of the syntax. -a, --add name= value Adds a property name with the value value. The property will be added even if such a property exists already. Note that most properties are unique and cannot occur more than once. -s, --set name= value Sets all occurrences of the property name to the value value. If no such property exists then it will be added. -d, --delete name Deletes all occurrences of the property name. Note that some properties are required and cannot be deleted. -t, --tags selector: filename Add or replace tags in the file with the ones from filename or remove them if filename is empty. mkvpropedit(1) reads the same XML tag format that mkvmerge(1) reads as well. The selector must be one of the words all, global or track. For all mkvpropedit(1) will replace or remove all tags in a file. With global only global tags will be replaced or removed. With track mkvpropedit(1) will replace tags for a specific track. Additionally the tags read from filename will be assigned to the same track. The track is specified in the same way edit selectors are specified (see below), e.g. --tags track:a1:new-audio-tags.xml. -c, --chapters filename Add or replace chapters in the file with the ones from filename or remove them if filename is empty. mkvpropedit(1) reads the same XML and simple chapter formats that mkvmerge(1) reads as well. Other options: --command-line-charset character-set Sets the character set to convert strings given on the command line from. It defaults to the character set given by system's current locale. --output-charset character-set Sets the character set to which strings are converted that are to be output. It defaults to the character set given by system's current locale. -r, --redirect-output file-name Writes all messages to the file file-name instead of to the console. While this can be done easily with output redirection there are cases in which this option is needed: when the terminal reinterprets the output before writing it to a file. The character set set with --output-charset is honored. --ui-language code Forces the translations for the language code to be used (e.g. 'de_DE' for the German translations). It is preferable to use the environment variables LANG, LC_MESSAGES and LC_ALL though. Entering 'list' as the code will cause mkvextract(1) to output a list of available translations. -v, --verbose Be verbose and show all the important Matroska(TM) elements as they're read. -h, --help Show usage information and exit. -V, --version Show version information and exit. --check-for-updates Checks online for new releases by downloading the URL http:\/\/mkvtoolnix-releases.bunkus.org\/latest-release.xml. Four lines will be output in key=value style: the URL from where the information was retrieved (key version_check_url), the currently running version (key running_version), the latest release's version (key available_version) and the download URL (key download_url). Afterwards the program exists with an exit code of 0 if no newer release is available, with 1 if a newer release is available and with 2 if an error occured (e.g. if the update information could not be retrieved). This option is only available if the program was built with support for libcurl. @options-file Reads additional command line arguments from the file options-file. Lines whose first non-whitespace character is a hash mark ('#') are treated as comments and ignored. White spaces at the start and end of a line will be stripped. Each line must contain exactly one option. Several chars can be escaped, e.g. if you need to start a non-comment line with '#'. The rules are described in the section about escaping text. The command line 'mkvpropedit source.mkv --edit track:a2 --set name=Comments' could be converted into the following option file: # Modify source.mkv\nsource.mkv\n# Edit the second audio track\n--edit\ntrack:a2\n# and set the title to 'Comments'\n--set\ntitle=Comments","Process Name":"mkvpropedit","Link":"https:\/\/linux.die.net\/man\/1\/mkvpropedit"}},{"Process":{"Description":"mkxauth aids in the creation and maintenance of X authentication databases (.Xauthority files). Use it to create a ~\/.Xauthority file or merge keys from another local or remote .Xauthority file. Remote .Xauthority files can be retrieved via FTP (using ncftp(1)) or via rsh(1). For a slight measure of security, mkxauth does not create any temporary files containing authentication keys (although anyone spying on network packets can see the authentication key data as they pass through the network; for secure network communications, use ssh(1)). Creating and Adding to a .Xauthority File To create a .Xauthority file, use mkxauth -c (see (1) above). mkxauth creates a .Xauthority file in the user's home directory (~\/), containing a 'key' or 'magic cookie' for the host it was run on (the one returned by hostname(1)). If a .Xauthority file already exists, the keys are added to it. If keys for that host already exist, they are replaced. To create or add to a .Xauthority file for another user, use mkxauth -u login -c. mkxauth adds keys to ~login\/.Xauthority (only the root user is allowed to do this). To add a key for more than one host, specify all hosts on the command line: mkxauth -c daffy porky bugs. All hosts specified on the same command line receive the same key. To create different keys for multiple hosts, run mkxauth for each host in succession: mkxauth -c daffy mkxauth -c porky mkxauth -c bugs Merging Keys from Local .Xauthority Files To merge keys from another local user's .Xauthority file, use mkxauth -m login (see (2) above). mkxauth adds the keys in ~ login\/.Xauthority to ~\/.Xauthority, replacing any keys which already exist. ~ login\/.Xauthority must be readable by the user running mkxauth (normally only the root user can read other people's .Xauthority files). Merging Keys via FTP To merge keys from a remote .Xauthority file via FTP, use mkxauth -f host (see (3) above). mkxauth retrieves the remote .Xauthority from host using ncftp(1) and adds those keys to ~\/.Xauthority, replacing any keys which already exist. [ NOTE: you must have a ~\/.netrc file set up to automatically log you into host, otherwise the FTP login attempt will fail.] Merging Keys via rsh(1) To merge keys from remote .Xauthority file via rsh(1), use mkxauth -r host (see (4) above). mkxauth retrieves the remote .Xauthority from host using rsh(1) and adds those keys to ~\/.Xauthority, replacing any keys which already exist. To login as a different user, use -l login. [ NOTE: you must have a .rhosts file set up properly for this to work, otherwise the remote login attempt will fail]. Merging Keys via rsh(1) and gzip(1) If your remote .Xauthority file is large, or to make it slightly less obvious that you're transferring authentication keys over the network, mkxauth can gzip(1) your .Xauthority file before retrieving it via rsh(1). To do this, use mkxauth -z host (see (5) above). mkxauth retrieves the remote .Xauthority from host using rsh(1) and adds those keys to ~\/.Xauthority, replacing any keys which already exist. To login as a different user, use -l login. [ NOTE: you must have a .rhosts file set up properly for this to work, otherwise the remote login attempt will fail]. Options To make mkxauth operate quietly, use the -q option. To add to ~login\/.Xauthority, use the -u login option. To use login for the remote login in mkxauth -f, mkxauth -r, and mkxauth -z, use the -l login option. Getting Help To get quick help about mkxauth, use mkxauth --help.","Process Name":"mkxauth","Link":"https:\/\/linux.die.net\/man\/1\/mkxauth"}},{"Process":{"Description":"Creates an XML-RPC wrapper for a pascal interface. mkxmlrpc TO BE FILLED.","Process Name":"mkxmlrpc","Link":"https:\/\/linux.die.net\/man\/1\/mkxmlrpc"}},{"Process":{"Description":"Takes an input file tree (INPUT) and create a corresponding compressed file tree (OUTPUT) that can be used with an appropriately patched mkisofs(8) to create a transparent-compression ISO 9660\/Rock Ridge filesystem using the \"ZF\" compression records.","Process Name":"mkzftree","Link":"https:\/\/linux.die.net\/man\/1\/mkzftree"}},{"Process":{"Description":"The mlabel command adds a volume label to a disk. Its syntax is: mlabel [-vcsn] [-N serial] drive:[new_label] Mlabel displays the current volume label, if present. If new_label is not given, and if neither the c nor the s options are set, it prompts the user for a new volume label. To delete an existing volume label, press return at the prompt. Reasonable care is taken to create a valid MS-DOS volume label. If an invalid label is specified, mlabel changes the label (and displays the new label if the verbose mode is set). Mlabel returns 0 on success or 1 on failure. Mlabel supports the following options: c Clears an existing label, without prompting the user s Shows the existing label, without prompting the user. n Assigns a new (random) serial number to the disk N serial Sets the supplied serial number. The serial number should be supplied as an 8 digit hexadecimal number, without spaces","Process Name":"mlabel","Link":"https:\/\/linux.die.net\/man\/1\/mlabel"}},{"Process":{"Description":null,"Process Name":"mlmmj-bounce","Link":"https:\/\/linux.die.net\/man\/1\/mlmmj-bounce"}},{"Process":{"Description":"","Process Name":"mlmmj-list","Link":"https:\/\/linux.die.net\/man\/1\/mlmmj-list"}},{"Process":{"Description":"This is the program doing the maintenance for an mlmmj based mailing list. It will unsubscribe people who have bounced for long enough, send out bounce probes, resend mails that couldn't be delivered to relayhost, clean out stale requests for e.g. subscription, resend list mails and clean up leftover files etc. If a directory containing several lists exists, the -d can be used to specify this, making mlmmj-maintd perform a maintenance run in every listdir below the specified one. Only either -d or -L can be specified at the same time. It will run as a daemon, unless the -F switch is specified, in which case it just runs once. The -F option should be used when one wants to avoid running another daemon, and use e.g. cron to control it instead. In case cron is used, mlmmj-maintd should be run every 2 hours or so. An example crontab entry: 0 *\/2 * * * \/usr\/bin\/mlmmj-maintd -F -L \/path\/to\/list","Process Name":"mlmmj-maintd","Link":"https:\/\/linux.die.net\/man\/1\/mlmmj-maintd"}},{"Process":{"Description":"This is an interactive script which creates the mailing list directory and thus the list itself for being run by mlmmj.","Process Name":"mlmmj-make-ml.sh","Link":"https:\/\/linux.die.net\/man\/1\/mlmmj-make-ml.sh"}},{"Process":{"Description":"This is the binary which processes a mail. Examples of what such processing is: Access control Using the access rules specified in <listdir>\/control\/access to perform access control to the list. This is done before headers are stripped, so one can create allow rules based on headers that are later stripped. Header stripping Headers specified in <listdir>\/control\/delheaders are deleted from the mail. Header addition Headers specified in <listdir>\/control\/customheaders are added to the mail. This could be headers like List-ID: or Reply-To: List control In case there's a mail with a recipient delimiter it's not a regular list mail. Processing of these happens in mlmmj-recieve as well. Examples of such are subscription requests, mails to owner etc. It will base it's recipient delimiter detection on the Delivered-To: header if present. If not, the To: header is used. Moderation If the list is moderated, it will happen in mlmmj-process. When processing is done, it will invoke the needed binary according to whatever mail it is. If it's a subscription request it will invoke mlmmj-sub, if it's a regular list mail it will invoke mlmmj-send.","Process Name":"mlmmj-process","Link":"https:\/\/linux.die.net\/man\/1\/mlmmj-process"}},{"Process":{"Description":"The mlmmj-recieve binary is the one specified in the mailserver configuration file (aliases file), which writes the mail to the <listdir>\/incoming directory and invokes mlmmj-process unless the -P option is specified. On systems using mailservers supporting the \/etc\/aliases file, a line to activate an mlmmj managed mailinglist would look like this: list: \"|\/usr\/bin\/mlmmj-recieve -L \/var\/spool\/mlmmj\/list\/\" It's very important to specify the full path to the binary, or the mailinglist will not function. When the -F option is used, it will not fork in the background. The reason it forks is that if delivery of a mail takes longer time than the mail server will allow a command to be idle before presumed dead, the mail server would kill it.","Process Name":"mlmmj-recieve","Link":"https:\/\/linux.die.net\/man\/1\/mlmmj-recieve"}},{"Process":{"Description":"This binary is used to send all kinds of mail to mlmmj managed mailinglists, but can potentially be used standalone for sending mails. The only option that is not self explanatory is the -l list control option: '1' means 'send a single mail' This is used together with -F and -T to send one mail to one recipient. '2' means 'mail to moderators' Used for sending mails to the moderators of a list. '3' means 'resend failed list mail' '4' means 'send to file with recipients' '5' means 'bounceprobe' '6' means 'single listmail to single recipient'","Process Name":"mlmmj-send","Link":"https:\/\/linux.die.net\/man\/1\/mlmmj-send"}},{"Process":{"Description":"This utility is used to subscribe people to the specified mailinglist. It will write the email address in a file with the name of the beginning letter of the email address getting subscribed in the <listdir>\/subscribers.d\/ directory. Unless the -U switch is used it will switch its user id to the user id owning the list directory. This is done to make sure that new files created are having correct permissions. The nomail version of the list is a list version where people are subscribed like usual, but they won't recieve any postings to the list. This is useful for people who read the mailinglist through a news gateway, but want to be able to post to the list. Normally a mail is sent to the subscriber if the address is already subscribed to the list. If the -s switch is used such a mail will not be sent. When neither -c nor -C are specified, subscription silently happens.","Process Name":"mlmmj-sub","Link":"https:\/\/linux.die.net\/man\/1\/mlmmj-sub"}},{"Process":{"Description":"This utility is used to unsubscribe people from the specified mailinglist. It will remove the specified email address from every file in the <listdir>\/subscribers.d\/ directory. Unless the -U switch is used it will switch its user id to the user id owning the list directory. This is done to make sure that new files created are having correct permissions. Normally a mail is sent to the person being unsubscribed if the address is not subscribed to the list. If the -s switch is used such a mail will not be sent. When neither -c nor -C are specified, unsubscription silently happens.","Process Name":"mlmmj-unsub","Link":"https:\/\/linux.die.net\/man\/1\/mlmmj-unsub"}},{"Process":{"Description":"This program will calculate the all k-furthest-neighbors of a set of points. You may specify a separate set of reference points and query points, or just a reference set which will be used as both the reference and query set. For example, the following will calculate the 5 furthest neighbors of eachpoint in 'input.csv' and store the distances in 'distances.csv' and the neighbors in the file 'neighbors.csv': $ allkfn --k=5 --reference_file=input.csv --distances_file=distances.csv --neighbors_file=neighbors.csv The output files are organized such that row i and column j in the neighbors output file corresponds to the index of the point in the reference set which is the i'th furthest neighbor from the point in the query set with index j. Row i and column j in the distances output file corresponds to the distance between those two points.","Process Name":"mlpack_allkfn","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_allkfn"}},{"Process":{"Description":null,"Process Name":"mlpack_allknn","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_allknn"}},{"Process":{"Description":"This program performs a number of functions related to Density Estimation Trees. The optimal Density Estimation Tree (DET) can be trained on a set of data (specified by --train_file) using cross-validation (with number of folds specified by --folds). In addition, the density of a set of test points (specified by --test_file) can be estimated, and the importance of each dimension can be computed. If class labels are given for the training points (with --labels_file), the class memberships of each leaf in the DET can be calculated. The created DET can be saved to a file, along with the density estimates for the test set and the variable importances.","Process Name":"mlpack_det","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_det"}},{"Process":{"Description":"This program can compute the Euclidean minimum spanning tree of a set of input points using the dual-tree Boruvka algorithm. The output is saved in a three-column matrix, where each row indicates an edge. The first column corresponds to the lesser index of the edge; the second column corresponds to the greater index of the edge; and the third column corresponds to the distance between the two points.","Process Name":"mlpack_emst","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_emst"}},{"Process":{"Description":"This program takes a parametric estimate of a Gaussian mixture model (GMM) using the EM algorithm to find the maximum likelihood estimate. The model is saved to an XML file, which contains information about each Gaussian.","Process Name":"mlpack_gmm","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_gmm"}},{"Process":{"Description":null,"Process Name":"mlpack_hmm_generate","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_hmm_generate"}},{"Process":{"Description":"This utility takes an already-trained HMM (--model_file) and evaluates the log-likelihood of a given sequence of observations (--input_file). The computed log-likelihood is given directly to stdout.","Process Name":"mlpack_hmm_loglik","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_hmm_loglik"}},{"Process":{"Description":"This program allows a Hidden Markov Model to be trained on labeled or unlabeled data. It support three types of HMMs: discrete HMMs, Gaussian HMMs, or GMM HMMs. Either one input sequence can be specified (with --input_file), or, a file containing files in which input sequences can be found (when --input_file and --batch are used together). In addition, labels can be provided in the file specified by --label_file, and if --batch is used, the file given to --label_file should contain a list of files of labels corresponding to the sequences in the file given to --input_file. Optionally, a pre-created HMM model can be used as a guess for the transition matrix and emission probabilities; this is specifiable with --model_file.","Process Name":"mlpack_hmm_train","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_hmm_train"}},{"Process":{"Description":"This utility takes an already-trained HMM (--model_file) and evaluates the most probably hidden state sequence of a given sequence of observations (--input_file), using the Viterbi algorithm. The computed state sequence is saved to the specified output file (--output_file).","Process Name":"mlpack_hmm_viterbi","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_hmm_viterbi"}},{"Process":{"Description":"This program performs Kernel Principal Components Analysis (KPCA) on the specified dataset with the specified kernel. This will transform the data onto the kernel principal components, and optionally reduce the dimensionality by ignoring the kernel principal components with the smallest eigenvalues. For the case where a linear kernel is used, this reduces to regular PCA. The kernels that are supported are listed below: \u2022 'linear': the standard linear dot product (same as normal PCA): K(x, y) = x^T y \u2022 'gaussian': a Gaussian kernel; requires bandwidth: K(x, y) = exp(-(|| x - y || ^ 2) \/ (2 * (bandwidth ^ 2))) \u2022 'polynomial': polynomial kernel; requires offset and degree: K(x, y) = (x^T y + offset) ^ degree \u2022 'hyptan': hyperbolic tangent kernel; requires scale and offset: K(x, y) = tanh(scale * (x^T y) + offset) \u2022 'laplacian': Laplacian kernel; requires bandwidth: K(x, y) = exp(-(|| x - y ||) \/ bandwidth) \u2022 'cosine': cosine distance: K(x, y) = 1 - (x^T y) \/ (|| x || * || y ||) The parameters for each of the kernels should be specified with the options --bandwidth, --kernel_scale, --offset, or --degree (or a combination of those options).","Process Name":"mlpack_kernel_pca","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_kernel_pca"}},{"Process":{"Description":null,"Process Name":"mlpack_kmeans","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_kmeans"}},{"Process":{"Description":"An implementation of LARS: Least Angle Regression (Stagewise\/laSso). This is a stage-wise homotopy-based algorithm for L1-regularized linear regression (LASSO) and L1+L2-regularized linear regression (Elastic Net). Let X be a matrix where each row is a point and each column is a dimension, and let y be a vector of targets. The Elastic Net problem is to solve min_beta 0.5 || X * beta - y ||_2^2 + lambda_1 ||beta||_1 +\n  0.5 lambda_2 ||beta||_2^2 If lambda_1 > 0 and lambda_2 = 0, the problem is the LASSO. If lambda_1 > 0 and lambda_2 > 0, the problem is the Elastic Net. If lambda_1 = 0 and lambda_2 > 0, the problem is Ridge Regression. If lambda_1 = 0 and lambda_2 = 0, the problem is unregularized linear regression. For efficiency reasons, it is not recommended to use this algorithm with lambda_1 = 0.","Process Name":"mlpack_lars","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_lars"}},{"Process":{"Description":"An implementation of simple linear regression using ordinary least squares. This solves the problem y = X * b + e where X ( --input_file) and y (the last row of --input_file, or --input_responses) are known and b is the desired variable. The calculated b is saved to disk ( --output_file). Optionally, the calculated value of b is used to predict the responses for another matrix X' (--test_file): y' = X' * b and these predicted responses, y', are saved to a file ( --output_predictions).","Process Name":"mlpack_linear_regression","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_linear_regression"}},{"Process":{"Description":"An implementation of Local Coordinate Coding (LCC), which codes data that approximately lives on a manifold using a variation of l1-norm regularized sparse coding. Given a dense data matrix X with n points and d dimensions, LCC seeks to find a dense dictionary matrix D with k atoms in d dimensions, and a coding matrix Z with n points in k dimensions. Because of the regularization method used, the atoms in D should lie close to the manifold on which the data points lie. The original data matrix X can then be reconstructed as D * Z. Therefore, this program finds a representation of each point in X as a sparse linear combination of atoms in the dictionary D. The coding is found with an algorithm which alternates between a dictionary step, which updates the dictionary D, and a coding step, which updates the coding matrix Z. To run this program, the input matrix X must be specified (with -i), along with the number of atoms in the dictionary (-k). An initial dictionary may also be specified with the --initial_dictionary option. The l1-norm regularization parameter is specified with -l. For example, to run LCC on the dataset in data.csv using 200 atoms and an l1-regularization parameter of 0.1, saving the dictionary into dict.csv and the codes into codes.csv, use $ local_coordinate_coding -i data.csv -k 200 -l 0.1 -d dict.csv -c codes.csv The maximum number of iterations may be specified with the -n option. Optionally, the input data matrix X can be normalized before coding with the -N option.","Process Name":"mlpack_local_coordinate_coding","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_local_coordinate_coding"}},{"Process":{"Description":null,"Process Name":"mlpack_mvu","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_mvu"}},{"Process":{"Description":"This program trains the Naive Bayes classifier on the given labeled training set and then uses the trained classifier to classify the points in the given test set. Labels are expected to be the last row of the training set (--train_file), but labels can also be passed in separately as their own file (--labels_file).","Process Name":"mlpack_nbc","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_nbc"}},{"Process":{"Description":"This program implements Neighborhood Components Analysis, both a linear dimensionality reduction technique and a distance learning technique. The method seeks to improve k-nearest-neighbor classification on a dataset by scaling the dimensions. The method is nonparametric, and does not require a value of k. It works by using stochastic (\"soft\") neighbor assignments and using optimization techniques over the gradient of the accuracy of the neighbor assignments. To work, this algorithm needs labeled data. It can be given as the last row of the input dataset (--input_file), or alternatively in a separate file (--labels_file). This implementation of NCA uses either stochastic gradient descent or the L_BFGS optimizer. Both of these optimizers do not guarantee global convergence for a nonconvex objective function (NCA's objective function is nonconvex), so the final results could depend on the random seed or other optimizer parameters. Stochastic gradient descent, specified by --optimizer \"sgd\", depends primarily on two parameters: the step size (--step_size) and the maximum number of iterations (--max_iterations). In addition, a normalized starting point can be used (--normalize), which is necessary if many warnings of the form 'Denominator of p_i is 0!' are given. Tuning the step size can be a tedious affair. In general, the step size is too large if the objective is not mostly uniformly decreasing, or if zero-valued denominator warnings are being issued. The step size is too small if the objective is changing very slowly. Setting the termination condition can be done easily once a good step size parameter is found; either increase the maximum iterations to a large number and allow SGD to find a minimum, or set the maximum iterations to 0 (allowing infinite iterations) and set the tolerance (--tolerance) to define the maximum allowed difference between objectives for SGD to terminate. Be careful -- setting the tolerance instead of the maximum iterations can take a very long time and may actually never converge due to the properties of the SGD optimizer. The L-BFGS optimizer, specified by --optimizer \"lbfgs\", uses a back-tracking line search algorithm to minimize a function. The following parameters are used by L-BFGS: --num_basis (specifies the number of memory points used by L-BFGS), --max_iterations, --armijo_constant, --wolfe, --tolerance (the optimization is terminated when the gradient norm is below this value), --max_line_search_trials, --min_step and --max_step (which both refer to the line search routine). For more details on the L-BFGS optimizer, consult either the MLPACK L-BFGS documentation (in lbfgs.hpp) or the vast set of published literature on L-BFGS. By default, the SGD optimizer is used.","Process Name":"mlpack_nca","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_nca"}},{"Process":{"Description":"This program performs non-negative matrix factorization on the given dataset, storing the resulting decomposed matrices in the specified files. For an input dataset V, NMF decomposes V into two matrices W and H such that V = W * H where all elements in W and H are non-negative. If V is of size (n x m), then W will be of size (n x r) and H will be of size (r x m), where r is the rank of the factorization (specified by --rank). Optionally, the desired update rules for each NMF iteration can be chosen from the following list: \u2022 multdist: multiplicative distance-based update rules (Lee and Seung 1999) \u2022 multdiv: multiplicative divergence-based update rules (Lee and Seung 1999) \u2022 als: alternating least squares update rules (Paatero and Tapper 1994) The maximum number of iterations is specified with --max_iterations, and the minimum residue required for algorithm termination is specified with --min_residue.","Process Name":"mlpack_nmf","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_nmf"}},{"Process":{"Description":"This program performs principal components analysis on the given dataset. It will transform the data onto its principal components, optionally performing dimensionality reduction by ignoring the principal components with the smallest eigenvalues.","Process Name":"mlpack_pca","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_pca"}},{"Process":{"Description":"An implementation of RADICAL, a method for independentcomponent analysis (ICA). Assuming that we have an input matrix X, thegoal is to find a square unmixing matrix W such that Y = W * X and the dimensions of Y are independent components. If the algorithm is runningparticularly slowly, try reducing the number of replicates.","Process Name":"mlpack_radical","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_radical"}},{"Process":{"Description":"This program implements range search with a Euclidean distance metric. For a given query point, a given range, and a given set of reference points, the program will return all of the reference points with distance to the query point in the given range. This is performed for an entire set of query points. You may specify a separate set of reference and query points, or only a reference set -- which is then used as both the reference and query set. The given range is taken to be inclusive (that is, points with a distance exactly equal to the minimum and maximum of the range are included in the results). For example, the following will calculate the points within the range [2, 5] of each point in 'input.csv' and store the distances in 'distances.csv' and the neighbors in 'neighbors.csv': $ range_search --min=2 --max=5 --reference_file=input.csv --distances_file=distances.csv --neighbors_file=neighbors.csv The output files are organized such that line i corresponds to the points found for query point i. Because sometimes 0 points may be found in the given range, lines of the output files may be empty. The points are not ordered in any specific manner. Because the number of points returned for each query point may differ, the resultant CSV-like files may not be loadable by many programs. However, at this time a better way to store this non-square result is not known. As a result, any output files will be written as CSVs in this manner, regardless of the given extension.","Process Name":"mlpack_range_search","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_range_search"}},{"Process":{"Description":null,"Process Name":"mlpack_sparse_coding","Link":"https:\/\/linux.die.net\/man\/1\/mlpack_sparse_coding"}},{"Process":{"Description":"wrapper as executable for Pod::MultiLang::Html.","Process Name":"mlpod2html","Link":"https:\/\/linux.die.net\/man\/1\/mlpod2html"}},{"Process":{"Description":null,"Process Name":"mlpod2html_ja","Link":"https:\/\/linux.die.net\/man\/1\/mlpod2html_ja"}},{"Process":{"Description":null,"Process Name":"mlpod2pod","Link":"https:\/\/linux.die.net\/man\/1\/mlpod2pod"}},{"Process":{"Description":"","Process Name":"mlpod2pod_ja","Link":"https:\/\/linux.die.net\/man\/1\/mlpod2pod_ja"}},{"Process":{"Description":"mm2gv converts a sparse matrix of the Matrix Market format to a graph in the GV (formerly DOT) format.","Process Name":"mm2gv","Link":"https:\/\/linux.die.net\/man\/1\/mm2gv"}},{"Process":{"Description":"This manual page documents briefly the mm3d command. mm3d is an OpenGL-based 3D model editor that works with triangle-based models. It supports multi-level undo, skeletal animations, simple texturing, scripting, command-line batch processing, and a plugin system for adding new model and image filters. Complete online help is included. It is designed to be easy to use and easy to extend with plugins and scripts.","Process Name":"mm3d","Link":"https:\/\/linux.die.net\/man\/1\/mm3d"}},{"Process":{"Description":"The mmd command is used to make an MS-DOS subdirectory. Its syntax is: mmd [-D clash_option] msdosdirectory [ msdosdirectories... ] Mmd makes a new directory on an MS-DOS filesystem. An error occurs if the directory already exists.","Process Name":"mmd","Link":"https:\/\/linux.die.net\/man\/1\/mmd"}},{"Process":{"Description":"mmg(1) is a wxWindows(TM) based GUI for mkvmerge(1). It offers easy access to all of mkvmerge(1)'s options. All settings (e.g. source files, track options etc) can be saved and restored. Included is a chapter editor that can read OGM style and XML style chapter files, write XML style chapter files and even read chapters from Matroska(TM) files and write chapters directly to Matroska(TM) files. Included is also a header editor that can be used to quickly change properties of existing Matroska(TM) files without needing a complete remux. mmg(1) knows few options. The first possibility is to start it with a single file name. If that file name's extenion is '.mmg' then it will be treated as a preferences file and mmg(1) will load its setting when it starts. Otherwise the name is interpreted as being the name of an input file which will be added. The second operation mode is invoked with the option --edit-headers and a file name. This lets mmg(1) run its header editor and load the file. The full documentation is available in HTML form (doc\/mkvmerge-gui.html).","Process Name":"mmg","Link":"https:\/\/linux.die.net\/man\/1\/mmg"}},{"Process":{"Description":"This manual page documents briefly the mmldif command.","Process Name":"mmldif","Link":"https:\/\/linux.die.net\/man\/1\/mmldif"}},{"Process":{"Description":null,"Process Name":"mmount","Link":"https:\/\/linux.die.net\/man\/1\/mmount"}},{"Process":{"Description":"The mmove command is used to moves or renames an existing MS-DOS file or subdirectory. mmove [-v] [-D clash_option] sourcefile targetfile\nmmove [-v]  [-D clash_option] sourcefile [ sourcefiles... ] targetdirectory\n Mmove moves or renames an existing MS-DOS file or subdirectory. Unlike the MS-DOS version of MOVE, mmove is able to move subdirectories. Files or directories can only be moved within one filesystem. Data cannot be moved from Dos to Unix or vice-versa. If you omit the drive letter from the target file or directory, the same letter as for the source is assumed. If you omit the drive letter from all parameters, drive a: is assumed by default.","Process Name":"mmove","Link":"https:\/\/linux.die.net\/man\/1\/mmove"}},{"Process":{"Description":"mmroff is a simple preprocessor for groff, it is used for expanding references in mm, see groff_mm(7). groff is executed twice, first with -z and -rRef=1 to collect all references and then to do the real processing when the reference file is up to date. -x Just create the reference file. This can be used to refresh the reference file, it isn't always needed to have accurate references and by using this option groff will only be run once.","Process Name":"mmroff","Link":"https:\/\/linux.die.net\/man\/1\/mmroff"}},{"Process":{"Description":"mmsrip is a client for the proprietary protocol MMS:\/\/. It saves to a file the content being streamed.","Process Name":"mmsrip","Link":"https:\/\/linux.die.net\/man\/1\/mmsrip"}},{"Process":{"Description":"addr2line translates addresses into file names and line numbers. Given an address in an executable or an offset in a section of a relocatable object, it uses the debugging information to figure out which file name and line number are associated with it. The executable or relocatable object to use is specified with the -e option. The default is the file a.out. The section in the relocatable object to use is specified with the -j option. addr2line has two modes of operation. In the first, hexadecimal addresses are specified on the command line, and addr2line displays the file name and line number for each address. In the second, addr2line reads hexadecimal addresses from standard input, and prints the file name and line number for each address on standard output. In this mode, addr2line may be used in a pipe to convert dynamically chosen addresses. The format of the output is FILENAME:LINENO . The file name and line number for each input address is printed on separate lines. If the -f option is used, then each FILENAME:LINENO line is preceded by FUNCTIONNAME which is the name of the function containing the address. If the -i option is used and the code at the given address is present there because of inlining by the compiler then the { FUNCTIONNAME } FILENAME:LINENO information for the inlining function will be displayed afterwards. This continues recursively until there is no more inlining to report. If the -a option is used then the output is prefixed by the input address. If the -p option is used then the output for each input address is displayed on one, possibly quite long, line. If -p is not used then the output is broken up into multiple lines, based on the paragraphs above. If the file name or function name can not be determined, addr2line will print two question marks in their place. If the line number can not be determined, addr2line will print 0.","Process Name":"mn10300-linux-gnu-addr2line","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-addr2line"}},{"Process":{"Description":"The GNU ar program creates, modifies, and extracts from archives. An archive is a single file holding a collection of other files in a structure that makes it possible to retrieve the original individual files (called members of the archive). The original files' contents, mode (permissions), timestamp, owner, and group are preserved in the archive, and can be restored on extraction. GNU ar can maintain archives whose members have names of any length; however, depending on how ar is configured on your system, a limit on member-name length may be imposed for compatibility with archive formats maintained with other tools. If it exists, the limit is often 15 characters (typical of formats related to a.out) or 16 characters (typical of formats related to coff). ar is considered a binary utility because archives of this sort are most often used as libraries holding commonly needed subroutines. ar creates an index to the symbols defined in relocatable object modules in the archive when you specify the modifier s. Once created, this index is updated in the archive whenever ar makes a change to its contents (save for the q update operation). An archive with such an index speeds up linking to the library, and allows routines in the library to call each other without regard to their placement in the archive. You may use nm -s or nm --print-armap to list this index table. If an archive lacks the table, another form of ar called ranlib can be used to add just the table. GNU ar can optionally create a thin archive, which contains a symbol index and references to the original copies of the member files of the archives. Such an archive is useful for building libraries for use within a local build, where the relocatable objects are expected to remain available, and copying the contents of each object would only waste time and space. Thin archives are also flattened, so that adding one or more archives to a thin archive will add the elements of the nested archive individually. The paths to the elements of the archive are stored relative to the archive itself. GNU ar is designed to be compatible with two different facilities. You can control its activity using command-line options, like the different varieties of ar on Unix systems; or, if you specify the single command-line option -M, you can control it with a script supplied via standard input, like the MRI \"librarian\" program.","Process Name":"mn10300-linux-gnu-ar","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-ar"}},{"Process":{"Description":null,"Process Name":"mn10300-linux-gnu-as","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-as"}},{"Process":{"Description":"The C ++ and Java languages provide function overloading, which means that you can write many functions with the same name, providing that each function takes parameters of different types. In order to be able to distinguish these similarly named functions C ++ and Java encode them into a low-level assembler name which uniquely identifies each different version. This process is known as mangling. The c++filt [1] program does the inverse mapping: it decodes (demangles) low-level names into user-level names so that they can be read. Every alphanumeric word (consisting of letters, digits, underscores, dollars, or periods) seen in the input is a potential mangled name. If the name decodes into a C ++ name, the C ++ name replaces the low-level name in the output, otherwise the original word is output. In this way you can pass an entire assembler source file, containing mangled names, through c++filt and see the same source file containing demangled names. You can also use c++filt to decipher individual symbols by passing them on the command line: c++filt <symbol> If no symbol arguments are given, c++filt reads symbol names from the standard input instead. All the results are printed on the standard output. The difference between reading names from the command line versus reading names from the standard input is that command line arguments are expected to be just mangled names and no checking is performed to separate them from surrounding text. Thus for example: c++filt -n _Z1fv will work and demangle the name to \"f()\" whereas: c++filt -n _Z1fv, will not work. (Note the extra comma at the end of the mangled name which makes it invalid). This command however will work: echo _Z1fv, | c++filt -n and will display \"f(),\", i.e., the demangled name followed by a trailing comma. This behaviour is because when the names are read from the standard input it is expected that they might be part of an assembler source file where there might be extra, extraneous characters trailing after a mangled name. For example: .type   _Z1fv, @function","Process Name":"mn10300-linux-gnu-c++filt","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-c++filt"}},{"Process":{"Description":"The C preprocessor, often known as cpp, is a macro processor that is used automatically by the C compiler to transform your program before compilation. It is called a macro processor because it allows you to define macros, which are brief abbreviations for longer constructs. The C preprocessor is intended to be used only with C, C ++ , and Objective-C source code. In the past, it has been abused as a general text processor. It will choke on input which does not obey C's lexical rules. For example, apostrophes will be interpreted as the beginning of character constants, and cause errors. Also, you cannot rely on it preserving characteristics of the input which are not significant to C-family languages. If a Makefile is preprocessed, all the hard tabs will be removed, and the Makefile will not work. Having said that, you can often get away with using cpp on things which are not C. Other Algol-ish programming languages are often safe (Pascal, Ada, etc.) So is assembly, with caution. -traditional-cpp mode preserves more white space, and is otherwise more permissive. Many of the problems can be avoided by writing C or C ++ style comments instead of native language comments, and keeping macros simple. Wherever possible, you should use a preprocessor geared to the language you are writing in. Modern versions of the GNU assembler have macro facilities. Most high level programming languages have their own conditional compilation and inclusion mechanism. If all else fails, try a true general text processor, such as GNU M4. C preprocessors vary in some details. This manual discusses the GNU C preprocessor, which provides a small superset of the features of ISO Standard C. In its default mode, the GNU C preprocessor does not do a few things required by the standard. These are features which are rarely, if ever, used, and may cause surprising changes to the meaning of a program which does not expect them. To get strict ISO Standard C, you should use the -std=c90, -std=c99 or -std=c11 options, depending on which version of the standard you want. To get all the mandatory diagnostics, you must also use -pedantic. This manual describes the behavior of the ISO preprocessor. To minimize gratuitous differences, where the ISO preprocessor's behavior does not conflict with traditional semantics, the traditional preprocessor should behave the same way. The various differences that do exist are detailed in the section Traditional Mode. For clarity, unless noted otherwise, references to CPP in this manual refer to GNU CPP .","Process Name":"mn10300-linux-gnu-cpp","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-cpp"}},{"Process":{"Description":"dlltool reads its inputs, which can come from the -d and -b options as well as object files specified on the command line. It then processes these inputs and if the -e option has been specified it creates a exports file. If the -l option has been specified it creates a library file and if the -z option has been specified it creates a def file. Any or all of the -e, -l and -z options can be present in one invocation of dlltool. When creating a DLL , along with the source for the DLL , it is necessary to have three other files. dlltool can help with the creation of these files. The first file is a .def file which specifies which functions are exported from the DLL , which functions the DLL imports, and so on. This is a text file and can be created by hand, or dlltool can be used to create it using the -z option. In this case dlltool will scan the object files specified on its command line looking for those functions which have been specially marked as being exported and put entries for them in the .def file it creates. In order to mark a function as being exported from a DLL , it needs to have an -export:<name_of_function> entry in the .drectve section of the object file. This can be done in C by using the asm() operator: asm (\".section .drectve\");\nasm (\".ascii \\\"-export:my_func\\\"\");\n\nint my_func (void) { ... } The second file needed for DLL creation is an exports file. This file is linked with the object files that make up the body of the DLL and it handles the interface between the DLL and the outside world. This is a binary file and it can be created by giving the -e option to dlltool when it is creating or reading in a .def file. The third file needed for DLL creation is the library file that programs will link with in order to access the functions in the DLL (an 'import library'). This file can be created by giving the -l option to dlltool when it is creating or reading in a .def file. If the -y option is specified, dlltool generates a delay-import library that can be used instead of the normal import library to allow a program to link to the dll only as soon as an imported function is called for the first time. The resulting executable will need to be linked to the static delayimp library containing __delayLoadHelper2(), which in turn will import LoadLibraryA and GetProcAddress from kernel32. dlltool builds the library file by hand, but it builds the exports file by creating temporary files containing assembler statements and then assembling these. The -S command line option can be used to specify the path to the assembler that dlltool will use, and the -f option can be used to pass specific flags to that assembler. The -n can be used to prevent dlltool from deleting these temporary assembler files when it is done, and if -n is specified twice then this will prevent dlltool from deleting the temporary object files it used to build the library. Here is an example of creating a DLL from a source file dll.c and also creating a program (from an object file called program.o) that uses that DLL: gcc -c dll.c\ndlltool -e exports.o -l dll.lib dll.o\ngcc dll.o exports.o -o dll.dll\ngcc program.o dll.lib -o program dlltool may also be used to query an existing import library to determine the name of the DLL to which it is associated. See the description of the -I or --identify option.","Process Name":"mn10300-linux-gnu-dlltool","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-dlltool"}},{"Process":{"Description":null,"Process Name":"mn10300-linux-gnu-elfedit","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-elfedit"}},{"Process":{"Description":"When you invoke GCC , it normally does preprocessing, compilation, assembly and linking. The \"overall options\" allow you to stop this process at an intermediate stage. For example, the -c option says not to run the linker. Then the output consists of object files output by the assembler. Other options are passed on to one stage of processing. Some options control the preprocessor and others the compiler itself. Yet other options control the assembler and linker; most of these are not documented here, since you rarely need to use any of them. Most of the command-line options that you can use with GCC are useful for C programs; when an option is only useful with another language (usually C ++ ), the explanation says so explicitly. If the description for a particular option does not mention a source language, you can use that option with all supported languages. The gcc program accepts options and file names as operands. Many options have multi-letter names; therefore multiple single-letter options may not be grouped: -dv is very different from -d -v. You can mix options and other arguments. For the most part, the order you use doesn't matter. Order does matter when you use several options of the same kind; for example, if you specify -L more than once, the directories are searched in the order specified. Also, the placement of the -l option is significant. Many options have long names starting with -f or with -W---for example, -fmove-loop-invariants, -Wformat and so on. Most of these have both positive and negative forms; the negative form of -ffoo would be -fno-foo. This manual documents only one of these two forms, whichever one is not the default.","Process Name":"mn10300-linux-gnu-gcc","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-gcc"}},{"Process":{"Description":"gcov is a test coverage program. Use it in concert with GCC to analyze your programs to help create more efficient, faster running code and to discover untested parts of your program. You can use gcov as a profiling tool to help discover where your optimization efforts will best affect your code. You can also use gcov along with the other profiling tool, gprof, to assess which parts of your code use the greatest amount of computing time. Profiling tools help you analyze your code's performance. Using a profiler such as gcov or gprof, you can find out some basic performance statistics, such as: \u2022 how often each line of code executes \u2022 what lines of code are actually executed \u2022 how much computing time each section of code uses Once you know these things about how your code works when compiled, you can look at each module to see which modules should be optimized. gcov helps you determine where to work on optimization. Software developers also use coverage testing in concert with testsuites, to make sure software is actually good enough for a release. Testsuites can verify that a program works as expected; a coverage program tests to see how much of the program is exercised by the testsuite. Developers can then determine what kinds of test cases need to be added to the testsuites to create both better testing and a better final product. You should compile your code without optimization if you plan to use gcov because the optimization, by combining some lines of code into one function, may not give you as much information as you need to look for 'hot spots' where the code is using a great deal of computer time. Likewise, because gcov accumulates statistics by line (at the lowest resolution), it works best with a programming style that places only one statement on each line. If you use complicated macros that expand to loops or to other control structures, the statistics are less helpful---they only report on the line where the macro call appears. If your complex macros behave like functions, you can replace them with inline functions to solve this problem. gcov creates a logfile called sourcefile.gcov which indicates how many times each line of a source file sourcefile.c has executed. You can use these logfiles along with gprof to aid in fine-tuning the performance of your programs. gprof gives timing information you can use along with the information you get from gcov. gcov works only on code compiled with GCC . It is not compatible with any other profiling or test coverage mechanism.","Process Name":"mn10300-linux-gnu-gcov","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-gcov"}},{"Process":{"Description":null,"Process Name":"mn10300-linux-gnu-gprof","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-gprof"}},{"Process":{"Description":"ld combines a number of object and archive files, relocates their data and ties up symbol references. Usually the last step in compiling a program is to run ld. ld accepts Linker Command Language files written in a superset of AT&T 's Link Editor Command Language syntax, to provide explicit and total control over the linking process. This man page does not describe the command language; see the ld entry in \"info\" for full details on the command language and on other aspects of the GNU linker. This version of ld uses the general purpose BFD libraries to operate on object files. This allows ld to read, combine, and write object files in many different formats---for example, COFF or \"a.out\". Different formats may be linked together to produce any available kind of object file. Aside from its flexibility, the GNU linker is more helpful than other linkers in providing diagnostic information. Many linkers abandon execution immediately upon encountering an error; whenever possible, ld continues executing, allowing you to identify other errors (or, in some cases, to get an output file in spite of the error). The GNU linker ld is meant to cover a broad range of situations, and to be as compatible as possible with other linkers. As a result, you have many choices to control its behavior.","Process Name":"mn10300-linux-gnu-ld","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-ld"}},{"Process":{"Description":"nlmconv converts the relocatable i386 object file infile into the NetWare Loadable Module outfile, optionally reading headerfile for NLM header information. For instructions on writing the NLM command file language used in header files, see the linkers section, NLMLINK in particular, of the NLM Development and Tools Overview, which is part of the NLM Software Developer's Kit (\" NLM SDK \"), available from Novell, Inc. nlmconv uses the GNU Binary File Descriptor library to read infile; nlmconv can perform a link step. In other words, you can list more than one object file for input if you list them in the definitions file (rather than simply specifying one input file on the command line). In this case, nlmconv calls the linker for you.","Process Name":"mn10300-linux-gnu-nlmconv","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-nlmconv"}},{"Process":{"Description":"GNU nm lists the symbols from object files objfile.... If no object files are listed as arguments, nm assumes the file a.out. For each symbol, nm shows: \u2022 The symbol value, in the radix selected by options (see below), or hexadecimal by default. \u2022 The symbol type. At least the following types are used; others are, as well, depending on the object file format. If lowercase, the symbol is usually local; if uppercase, the symbol is global (external). There are however a few lowercase symbols that are shown for special global symbols (\"u\", \"v\" and \"w\"). \"A\" The symbol's value is absolute, and will not be changed by further linking. \"B\" \"b\" The symbol is in the uninitialized data section (known as BSS ). \"C\" The symbol is common. Common symbols are uninitialized data. When linking, multiple common symbols may appear with the same name. If the symbol is defined anywhere, the common symbols are treated as undefined references. \"D\" \"d\" The symbol is in the initialized data section. \"G\" \"g\" The symbol is in an initialized data section for small objects. Some object file formats permit more efficient access to small data objects, such as a global int variable as opposed to a large global array. \"i\" For PE format files this indicates that the symbol is in a section specific to the implementation of DLLs. For ELF format files this indicates that the symbol is an indirect function. This is a GNU extension to the standard set of ELF symbol types. It indicates a symbol which if referenced by a relocation does not evaluate to its address, but instead must be invoked at runtime. The runtime execution will then return the value to be used in the relocation. \"N\" The symbol is a debugging symbol. \"p\" The symbols is in a stack unwind section. \"R\" \"r\" The symbol is in a read only data section. \"S\" \"s\" The symbol is in an uninitialized data section for small objects. \"T\" \"t\" The symbol is in the text (code) section. \"U\" The symbol is undefined. \"u\" The symbol is a unique global symbol. This is a GNU extension to the standard set of ELF symbol bindings. For such a symbol the dynamic linker will make sure that in the entire process there is just one symbol with this name and type in use. \"V\" \"v\" The symbol is a weak object. When a weak defined symbol is linked with a normal defined symbol, the normal defined symbol is used with no error. When a weak undefined symbol is linked and the symbol is not defined, the value of the weak symbol becomes zero with no error. On some systems, uppercase indicates that a default value has been specified. \"W\" \"w\" The symbol is a weak symbol that has not been specifically tagged as a weak object symbol. When a weak defined symbol is linked with a normal defined symbol, the normal defined symbol is used with no error. When a weak undefined symbol is linked and the symbol is not defined, the value of the symbol is determined in a system-specific manner without error. On some systems, uppercase indicates that a default value has been specified. \"-\" The symbol is a stabs symbol in an a.out object file. In this case, the next values printed are the stabs other field, the stabs desc field, and the stab type. Stabs symbols are used to hold debugging information. \"?\" The symbol type is unknown, or object file format specific. \u2022 The symbol name.","Process Name":"mn10300-linux-gnu-nm","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-nm"}},{"Process":{"Description":"The GNU objcopy utility copies the contents of an object file to another. objcopy uses the GNU BFD Library to read and write the object files. It can write the destination object file in a format different from that of the source object file. The exact behavior of objcopy is controlled by command-line options. Note that objcopy should be able to copy a fully linked file between any two formats. However, copying a relocatable object file between any two formats may not work as expected. objcopy creates temporary files to do its translations and deletes them afterward. objcopy uses BFD to do all its translation work; it has access to all the formats described in BFD and thus is able to recognize most formats without being told explicitly. objcopy can be used to generate S-records by using an output target of srec (e.g., use -O srec). objcopy can be used to generate a raw binary file by using an output target of binary (e.g., use -O binary). When objcopy generates a raw binary file, it will essentially produce a memory dump of the contents of the input object file. All symbols and relocation information will be discarded. The memory dump will start at the load address of the lowest section copied into the output file. When generating an S-record or a raw binary file, it may be helpful to use -S to remove sections containing debugging information. In some cases -R will be useful to remove sections which contain information that is not needed by the binary file. Note---objcopy is not able to change the endianness of its input files. If the input format has an endianness (some formats do not), objcopy can only copy the inputs into file formats that have the same endianness or which have no endianness (e.g., srec). (However, see the --reverse-bytes option.)","Process Name":"mn10300-linux-gnu-objcopy","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-objcopy"}},{"Process":{"Description":null,"Process Name":"mn10300-linux-gnu-objdump","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-objdump"}},{"Process":{"Description":null,"Process Name":"mn10300-linux-gnu-ranlib","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-ranlib"}},{"Process":{"Description":"readelf displays information about one or more ELF format object files. The options control what particular information to display. elffile... are the object files to be examined. 32-bit and 64-bit ELF files are supported, as are archives containing ELF files. This program performs a similar function to objdump but it goes into more detail and it exists independently of the BFD library, so if there is a bug in BFD then readelf will not be affected.","Process Name":"mn10300-linux-gnu-readelf","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-readelf"}},{"Process":{"Description":"The GNU size utility lists the section sizes---and the total size---for each of the object or archive files objfile in its argument list. By default, one line of output is generated for each object file or each module in an archive. objfile... are the object files to be examined. If none are specified, the file \"a.out\" will be used.","Process Name":"mn10300-linux-gnu-size","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-size"}},{"Process":{"Description":"For each file given, GNU strings prints the printable character sequences that are at least 4 characters long (or the number given with the options below) and are followed by an unprintable character. By default, it only prints the strings from the initialized and loaded sections of object files; for other types of files, it prints the strings from the whole file. strings is mainly useful for determining the contents of non-text files.","Process Name":"mn10300-linux-gnu-strings","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-strings"}},{"Process":{"Description":null,"Process Name":"mn10300-linux-gnu-strip","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-strip"}},{"Process":{"Description":"windmc reads message definitions from an input file (.mc) and translate them into a set of output files. The output files may be of four kinds: \"h\" A C header file containing the message definitions. \"rc\" A resource file compilable by the windres tool. \"bin\" One or more binary files containing the resource data for a specific message language. \"dbg\" A C include file that maps message id's to their symbolic name. The exact description of these different formats is available in documentation from Microsoft. When windmc converts from the \"mc\" format to the \"bin\" format, \"rc\", \"h\", and optional \"dbg\" it is acting like the Windows Message Compiler.","Process Name":"mn10300-linux-gnu-windmc","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-windmc"}},{"Process":{"Description":"windres reads resources from an input file and copies them into an output file. Either file may be in one of three formats: \"rc\" A text format read by the Resource Compiler. \"res\" A binary format generated by the Resource Compiler. \"coff\" A COFF object or executable. The exact description of these different formats is available in documentation from Microsoft. When windres converts from the \"rc\" format to the \"res\" format, it is acting like the Windows Resource Compiler. When windres converts from the \"res\" format to the \"coff\" format, it is acting like the Windows \"CVTRES\" program. When windres generates an \"rc\" file, the output is similar but not identical to the format expected for the input. When an input \"rc\" file refers to an external filename, an output \"rc\" file will instead include the file contents. If the input or output format is not specified, windres will guess based on the file name, or, for the input file, the file contents. A file with an extension of .rc will be treated as an \"rc\" file, a file with an extension of .res will be treated as a \"res\" file, and a file with an extension of .o or .exe will be treated as a \"coff\" file. If no output file is specified, windres will print the resources in \"rc\" format to standard output. The normal use is for you to write an \"rc\" file, use windres to convert it to a COFF object file, and then link the COFF file into your application. This will make the resources described in the \"rc\" file available to Windows.","Process Name":"mn10300-linux-gnu-windres","Link":"https:\/\/linux.die.net\/man\/1\/mn10300-linux-gnu-windres"}},{"Process":{"Description":null,"Process Name":"moc","Link":"https:\/\/linux.die.net\/man\/1\/moc"}},{"Process":{"Description":"Mock is a simple program that will build source RPMs inside a chroot. It doesn't do anything terribly fancy other than populate a chroot with the contents specified by a configuration file, then build any input SRPM(s) in that chroot. The content of a chroot is specified by the configuration specified with the -r option. The default configuration file is \/etc\/mock\/default.cfg, which is usually a symlink to one of the installed configurations. There is a site-wide configuration file, \/etc\/mock\/site-defaults.cfg, which can be used to specify site-wide options. The shipped version of this file has no active options, but does have a list of all of the configuration options, examples of how to set them, and their default values. For backwards compatibility, old-style commands, (\"rebuild\", \"init\", \"clean\", etc.) without leading '--' are still accepted, but are deprecated. See COMMANDS section, below, for detailed listing of all commands. To use mock, a user should become a member of the mock group by adding their username to the mock line in \/etc\/group. This can be done with the following command: sudo \/usr\/sbin\/usermod -a -G mock $USER Note that mock is not intended to be run directly as root.","Process Name":"mock","Link":"https:\/\/linux.die.net\/man\/1\/mock"}},{"Process":{"Description":"mockchain builds a series of srpms in mock one at a time. After each successful build of a package it adds the resulting packages to a local repo which are available to the next package to satisfy buildreqs.","Process Name":"mockchain","Link":"https:\/\/linux.die.net\/man\/1\/mockchain"}},{"Process":{"Description":"The main purpose of these programs is to check operation of your home-brew LIRC receiver hardware and to see the IR waveform of the remote controller without an expensive oscilloscope. Very useful for debugging. Of course this program won't work with hardware that decodes the signals itself like e.g. TV cards or the Irman. mode2 will simply print pulse&space lengths to stdout. -h --help display usage summary -v --version display version -d --device= device read from given device -H --driver= driver use given driver -m --mode enable alternative display mode -r --raw access device directly","Process Name":"mode2","Link":"https:\/\/linux.die.net\/man\/1\/mode2"}},{"Process":{"Description":null,"Process Name":"modemtest","Link":"https:\/\/linux.die.net\/man\/1\/modemtest"}},{"Process":{"Description":"modifyrepo is a program that allows you to insert arbitrary metadata into a repomd (xml-based rpm metadata) repository.","Process Name":"modifyrepo","Link":"https:\/\/linux.die.net\/man\/1\/modifyrepo"}},{"Process":{"Description":null,"Process Name":"modlogan","Link":"https:\/\/linux.die.net\/man\/1\/modlogan"}},{"Process":{"Description":null,"Process Name":"modpods","Link":"https:\/\/linux.die.net\/man\/1\/modpods"}},{"Process":{"Description":"The bibutils program set inter-converts between various bibliography formats using Library of Congress [1] 's Metadata Object Description Schema (MODS) [2] version 3.1. For example, one can convert RIS-format files to Bibtex by doing two transformations: RIS->MODS->Bibtex.","Process Name":"modsclean","Link":"https:\/\/linux.die.net\/man\/1\/modsclean"}},{"Process":{"Description":null,"Process Name":"module","Link":"https:\/\/linux.die.net\/man\/1\/module"}},{"Process":{"Description":"\"module-starter\" is a command-line interface to Module::Starter, which it uses to perform all the work of creating distributions. An alternate backend for \"module-starter\" can be specified with the \"--class\" option. Plugins to the standard Module::Starter module can be specified with one or more \"--plugin\" options. If no directory name is supplied, the distribution name will be used for the directory. If no distribution name is supplied, the first listed module name will be used as the distribution name. Multiple --builder options may be supplied to produce the files for multiple builders.","Process Name":"module-starter","Link":"https:\/\/linux.die.net\/man\/1\/module-starter"}},{"Process":{"Description":null,"Process Name":"module_info","Link":"https:\/\/linux.die.net\/man\/1\/module_info"}},{"Process":{"Description":null,"Process Name":"moebius","Link":"https:\/\/linux.die.net\/man\/1\/moebius"}},{"Process":{"Description":"moggsplit splits a multiplexed Ogg stream into separate files. For example, it can separate an OGM into separate Ogg DivX and Ogg Vorbis streams, or a chained Ogg Vorbis file into two separate files.","Process Name":"moggsplit","Link":"https:\/\/linux.die.net\/man\/1\/moggsplit"}},{"Process":{"Description":"Image Settings: -adjoin join images into a single multi-image file -affine matrix affine transform matrix -antialias remove pixel-aliasing -authenticate value decrypt image with this password -background color background color -bias value add bias when convolving an image -black-point-compensation use black point compensation -blue-primary point chromaticity blue primary point -bordercolor color border color -caption string assign a caption to an image -cdl filename color correct with a color decision list -channel type apply option to select image channels -colors value preferred number of colors in the image -colorspace type alternate image colorspace -comment string annotate image with comment -compose operator set image composite operator -compress type type of pixel compression when writing the image -decipher filename convert cipher pixels to plain pixels -define format:option define one or more image format options -delay value display the next image after pausing -density geometry horizontal and vertical density of the image -depth value image depth -display server get image or font from this X server -dispose method layer disposal method -dither method apply error diffusion to image -encipher filename convert plain pixels to cipher pixels -encoding type text encoding type -endian type endianness (MSB or LSB) of the image -family name render text with this font family -fill color color to use when filling a graphic primitive -filter type use this filter when resizing an image -flatten flatten a sequence of images -font name render text with this font -format type image format type -function name apply a function to the image -fuzz distance colors within this distance are considered equal -gravity type horizontal and vertical text placement -green-primary point chromaticity green primary point -intent type type of rendering intent when managing the image color -interlace type type of image interlacing scheme -interpolate method pixel color interpolation method -label string assign a label to an image -limit type value pixel cache resource limit -loop iterations add Netscape loop extension to your GIF animation -mask filename associate a mask with the image -matte store matte channel if the image has one -mattecolor color frame color -monitor monitor progress -orient type image orientation -origin geometry image origin -page geometry size and location of an image canvas (setting) -path path write images to this path on disk -ping efficiently determine image attributes -pointsize value font point size -preview type image preview type -quality value JPEG\/MIFF\/PNG compression level -quiet suppress all warning messages -red-primary point chromaticity red primary point -regard-warnings pay attention to warning messages -sampling-factor geometry horizontal and vertical sampling factor -scene value image scene number -seed value seed a new sequence of pseudo-random numbers -size geometry width and height of image -stretch type render text with this font stretch -stroke color graphic primitive stroke color -strokewidth value graphic primitive stroke width -style type render text with this font style -support factor resize support: > 1.0 is blurry, < 1.0 is sharp -texture filename name of texture to tile onto the image background -tile-offset geometry tile offset -treedepth value color tree depth -transparent-color color transparent color -undercolor color annotation bounding box color -units type the units of image resolution -verbose print detailed information about the image -view FlashPix viewing transforms -virtual-pixel method virtual pixel access method -weight type render text with this font weight -white-point point chromaticity white point Image Operators: -adaptive-blur geometry adaptively blur pixels; decrease effect near edges -adaptive-resize geometry adaptively resize image with data dependent triangulation -adaptive-sharpen geometry adaptively sharpen pixels; increase effect near edges -annotate geometry text annotate the image with text -auto-orient automatically orient image -black-threshold value force all pixels below the threshold into black -blur geometry reduce image noise and reduce detail levels -border geometry surround image with a border of color -charcoal radius simulate a charcoal drawing -chop geometry remove pixels from the image interior -clip clip along the first path from the 8BIM profile -clip-mask filename associate a clip mask with the image -clip-path id clip along a named path from the 8BIM profile -colorize value colorize the image with the fill color -contrast enhance or reduce the image contrast -contrast-stretch geometry improve contrast by 'stretching' the intensity range -convolve coefficients apply a convolution kernel to the image -cycle amount cycle the image colormap -despeckle reduce the speckles within an image -draw string annotate the image with a graphic primitive -edge radius apply a filter to detect edges in the image -emboss radius emboss an image -enhance apply a digital filter to enhance a noisy image -equalize perform histogram equalization to an image -evaluate operator value evaluate an arithmetic, relational, or logical expression -extent geometry set the image size -extract geometry extract area from image -fft implements the discrete Fourier transform (DFT) -flip flip image vertically -floodfill geometry color floodfill the image with color -flop flop image horizontally -frame geometry surround image with an ornamental border -gamma value level of gamma correction -gaussian-blur geometry reduce image noise and reduce detail levels -geometry geometry perferred size or location of the image -ift implements the inverse discrete Fourier transform (DFT) -help print program options -identify identify the format and characteristics of the image -implode amount implode image pixels about the center -lat geometry local adaptive thresholding -layers method optimize or compare image layers -level value adjust the level of image contrast -linear-stretch geometry improve contrast by 'stretching with saturation' the intensity range -median radius apply a median filter to the image -modulate value vary the brightness, saturation, and hue -monochrome transform image to black and white -motion-blur geometry simulate motion blur -negate replace every pixel with its complementary color -noise radius add or reduce noise in an image -normalize transform image to span the full range of colors -opaque color change this color to the fill color -ordered-dither NxN add a noise pattern to the image with specific amplitudes -paint radius simulate an oil painting -polaroid angle simulate a Polaroid picture -posterize levels reduce the image to a limited number of color levels -print string interpret string and print to console -profile filename add, delete, or apply an image profile -quantize colorspace reduce colors in this colorspace -radial-blur angle radial blur the image -raise value lighten\/darken image edges to create a 3-D effect -random-threshold low,high random threshold the image -recolor matrix translate, scale, shear, or rotate image colors -region geometry apply options to a portion of the image -render render vector graphics -repage geometry size and location of an image canvas -resample geometry change the resolution of an image -resize geometry resize the image -roll geometry roll an image vertically or horizontally -rotate degrees apply Paeth rotation to the image -sample geometry scale image with pixel sampling -scale geometry scale the image -segment values segment an image -selective-blur geometry selectively blur pixels within a contrast threshold -sepia-tone threshold simulate a sepia-toned photo -set property value set an image property -shade degrees shade the image using a distant light source -shadow geometry simulate an image shadow -sharpen geometry sharpen the image -shave geometry shave pixels from the image edges -shear geometry slide one edge of the image along the X or Y axis -sigmoidal-contrast geometry lightness rescaling using sigmoidal contrast enhancement -sketch geometry simulate a pencil sketch -solarize threshold negate all pixels above the threshold level -splice geometry splice the background color into the image -spread amount displace image pixels by a random amount -strip strip image of all profiles and comments -swirl degrees swirl image pixels about the center -threshold value threshold the image -thumbnail geometry create a thumbnail of the image -tile filename tile image when filling a graphic primitive -tint value tint the image with the fill color -transform affine transform image -transparent color make this color transparent within the image -transpose flip image vertically and rotate 90 degrees -transverse flop image horizontally and rotate 270 degrees -trim trim image edges -type type image type -unique-colors discard all but one of any pixel color -unsharp geometry sharpen the image -vignette geometry soften the edges of the image in vignette style -wave geometry alter an image along a sine wave -white-threshold value force all pixels above the threshold into white Image Sequence Operators: -affinity filename transform image colors to match this set of colors -append append an image sequence -average average an image sequence -clut apply a color lookup table to the image -coalesce merge a sequence of images -combine combine a sequence of images -composite composite image -crop geometry cut out a rectangular region of the image -deconstruct break down an image sequence into constituent parts -flatten flatten a sequence of images -fx expression apply mathematical expression to an image channel(s) -hald-clut apply a Hald color lookup table to the image -morph value morph an image sequence -mosaic create a mosaic from an image sequence -process arguments process the image with a custom image filter -separate separate an image channel into a grayscale image -write filename write images to this file Image Stack Operators: -clone index clone an image -delete index delete the image from the image sequence -insert index insert last image into the image sequence -swap indexes swap two images in the image sequence Miscellaneous Options: -debug events display copious debugging information -help print program options -log format format of debugging information -list type print a list of supported option arguments -version print version information By default, the image format of 'file' is determined by its magic number. To specify a particular image format, precede the filename with an image format name and a colon (i.e. ps:image) or specify the image type as the filename suffix (i.e. image.ps). Specify 'file' as '-' for standard input or output.","Process Name":"mogrify","Link":"https:\/\/linux.die.net\/man\/1\/mogrify"}},{"Process":{"Description":"The moire program draws cool circular interference patterns.","Process Name":"moire","Link":"https:\/\/linux.die.net\/man\/1\/moire"}},{"Process":{"Description":"Another example of the fun you can have with moire interference patterns; this hack generates fields of concentric circles or ovals, and combines the planes with various operations. The planes are moving independently of one another, causing the interference lines to ''spray.''","Process Name":"moire2","Link":"https:\/\/linux.die.net\/man\/1\/moire2"}},{"Process":{"Description":null,"Process Name":"moka","Link":"https:\/\/linux.die.net\/man\/1\/moka"}},{"Process":{"Description":"The molecule program draws several different representations of molecules. Some common molecules are built in, and it can read PDB (Protein Data Base) files as input.","Process Name":"molecule","Link":"https:\/\/linux.die.net\/man\/1\/molecule"}},{"Process":{"Description":"moncmd sends commands to the mon server.","Process Name":"moncmd","Link":"https:\/\/linux.die.net\/man\/1\/moncmd"}},{"Process":{"Description":"mongo is a JavaScript shell (with GNU readline capabilities). It supports interactive and non-interactive use. When used interactively, JavaScript can be used to query the database or perform any other function normally available with SpiderMonkey. Database output is displayed in JSON format. If JavaScript files are specified on the command line, the shell will run non-interactively, running each one in sequence and then exiting.","Process Name":"mongo","Link":"https:\/\/linux.die.net\/man\/1\/mongo"}},{"Process":{"Description":null,"Process Name":"mongod","Link":"https:\/\/linux.die.net\/man\/1\/mongod"}},{"Process":{"Description":"mongodump is a tool to output a binary representation of a database. It is mostly used for doing hot backups of a database.","Process Name":"mongodump","Link":"https:\/\/linux.die.net\/man\/1\/mongodump"}},{"Process":{"Description":"mongoexport is a tool to export a MongoDB collection to either JSON or CSV. The query can be filtered or a list of fields to output can be given. If the output is CSV, the fields must be specified in order.","Process Name":"mongoexport","Link":"https:\/\/linux.die.net\/man\/1\/mongoexport"}},{"Process":{"Description":"mongofiles is used to list, get, and insert files in the database. Commands: list list all files. FILENAME is an optional prefix which listed filenames must begin with. search search all files. FILENAME is a substring which listed filenames must contain. put add a file with filename FILENAME get get a file with filename FILENAME delete delete all files with filename FILENAME","Process Name":"mongofiles","Link":"https:\/\/linux.die.net\/man\/1\/mongofiles"}},{"Process":{"Description":"mongoimport is a tool to import a MongoDB collection from JSON, CSV, or TSV. The query can be filtered or a list of fields to input can be given.","Process Name":"mongoimport","Link":"https:\/\/linux.die.net\/man\/1\/mongoimport"}},{"Process":{"Description":"mongoose is small, fast and easy to use web server with CGI, SSL, MD5 authorization, and basic SSI support. mongoose does not detach from terminal, and uses current working directory as the web root, unless -r option is specified. It is possible to specify multiple ports to listen on. For example, to make mongoose listen on HTTP port 80 and HTTPS port 443, one should start it as: mongoose -s cert.pem -p 80,443s Unlike other web servers, mongoose does not require CGI scripts be put in a special directory. CGI scripts can be anywhere. CGI (and SSI) files are recognized by the file name pattern. mongoose uses shell-like glob patterns with the following syntax: **'        Matches everything *' Matches everything but slash character, '\/' ?' Matches any character $' Matches the end of the string |' Matches if pattern on the left side or the right side matches. Pattern on the left side is matched first All other characters in the pattern match themselves. If no arguments are given, mongoose searches for a configuration file called \"mongoose.conf\" in the same directory where mongoose binary is located. Alternatively, a file name could be specified in the command line. Format of the configuration file is the same as for the command line options except that each option must be specified on a separate line, leading dashes for option names must be omitted. Lines beginning with '#' and empty lines are ignored.","Process Name":"mongoose","Link":"https:\/\/linux.die.net\/man\/1\/mongoose"}},{"Process":{"Description":null,"Process Name":"mongorestore","Link":"https:\/\/linux.die.net\/man\/1\/mongorestore"}},{"Process":{"Description":"mongos is used to setup, configure, and get information about sharded databases.","Process Name":"mongos","Link":"https:\/\/linux.die.net\/man\/1\/mongos"}},{"Process":{"Description":"mongosniff is a analyzer tool for analyzing packets coming to your database.","Process Name":"mongosniff","Link":"https:\/\/linux.die.net\/man\/1\/mongosniff"}},{"Process":{"Description":"mongostat prints statistics on a running mongod instance. [SLEEP TIME] is time to wait (in seconds) between calls to servers","Process Name":"mongostat","Link":"https:\/\/linux.die.net\/man\/1\/mongostat"}},{"Process":{"Description":null,"Process Name":"monit","Link":"https:\/\/linux.die.net\/man\/1\/monit"}},{"Process":{"Description":"mono is a runtime implementation of the ECMA Common Language Infrastructure. This can be used to run ECMA and .NET applications. The runtime contains a native code generator that transforms the Common Intermediate Language into native code. The code generator can operate in two modes: just in time compilation (JIT) or ahead of time compilation (AOT). Since code can be dynamically loaded, the runtime environment and the JIT are always present, even if code is compiled ahead of time. The runtime loads the specified file and optionally passes the arguments to it. The file is an ECMA assembly. They typically have a .exe or .dll extension. The runtime provides a number of configuration options for running applications, for developing and debugging, and for testing and debugging the runtime itself.","Process Name":"mono","Link":"https:\/\/linux.die.net\/man\/1\/mono"}},{"Process":{"Description":"mono-cil-strip is a tool which takes an assembly, and empty its method bodies. This is useful to reduce an assembly size when an assembly has already been compiled using Mono's Ahead Of Time compiler (AOT), where the CIL code is no longer necessary, but the metadata still is.","Process Name":"mono-cil-strip","Link":"https:\/\/linux.die.net\/man\/1\/mono-cil-strip"}},{"Process":{"Description":"The mono-service is a host to run services built with the ServiceProcess assembly. Use mono-service to run services that use the 1.0 assemblies and use mono-service2 to run services that use the 2.0 assemblies. Services can be paused by sending the SIGUSR1 signal to the process, and execution can be resumed by sending the SIGUSR2 signal. The service can be cleanly shutdown by sending the SIGTERM signal to the process. Mono programs started with mono-service run with the MONO_DISABLE_SHM variable set. This means that certain Mono features that depend on it are not available to services. The following options can be used to control the service: -d:DIRECTORY Use this option to specify the working directory for the service. The default is the current directory. -l:LOCKFILE Specifies the file to use for locking, the default is a filename constructed in \/tmp based on the name of the program that hosts the service. -m:MESSAGE Name to show in the syslog. -n:NAME Use this to specify the service to be launched (if the program contains more than one service). The default is to run the first defined service. --debug Use this option to prevent mono-service from redirecting stdin and stdout and prevent the program to be sent to the background. Equivalent to --no-daemon --no-daemon Use this option to prevent mono-service from redirecting stdin and stdout and prevent the program to be sent to the background. Equivalent to --debug.","Process Name":"mono-service","Link":"https:\/\/linux.die.net\/man\/1\/mono-service"}},{"Process":{"Description":null,"Process Name":"mono-shlib-cop","Link":"https:\/\/linux.die.net\/man\/1\/mono-shlib-cop"}},{"Process":{"Description":"mono-xmltool is a command line front end for various functions available in the Mono XML class libraries. It currently it offers validation with various different kinds of schemas, xslt transformations and pretty printing.","Process Name":"mono-xmltool","Link":"https:\/\/linux.die.net\/man\/1\/mono-xmltool"}},{"Process":{"Description":"The monodis program is used to dump the contents a CIL image (contained in .EXE files that contain extended PE\/COFF CIL code). To roundtrip assemblies using ilasm, it is best to use the --output argument, as that will make monodis save the embedded resources in files that can later be properly embedded back by ilasm.","Process Name":"monodis","Link":"https:\/\/linux.die.net\/man\/1\/monodis"}},{"Process":{"Description":null,"Process Name":"monodocer","Link":"https:\/\/linux.die.net\/man\/1\/monodocer"}},{"Process":{"Description":"monodocs2html has been obsoleted by mdoc(1). See the mdoc-export-html(1) man page. monodocs2html is a program that creates HTML documentation from the Monodoc documentation XML files.","Process Name":"monodocs2html","Link":"https:\/\/linux.die.net\/man\/1\/monodocs2html"}},{"Process":{"Description":null,"Process Name":"monolinker","Link":"https:\/\/linux.die.net\/man\/1\/monolinker"}},{"Process":{"Description":"Monop is a tool that allows you to view the outline of a class. You can see the signature of each member of the class. Use monop to explore 1.0 assemblies, use monop2 to explore 2.0 assemblies. The tool takes one option, the class to view. You must specify the full name of the class, including namespace. For generic classes, you must specify the generic arguments, for example: monop2 'System.Collections.Generic.List'1' The above is the string representation for the List<T> in System.Collections.Generic If you are unsure of the full name of the class, you can use the '--search' option to search through all known assemblies.","Process Name":"monop","Link":"https:\/\/linux.die.net\/man\/1\/monop"}},{"Process":{"Description":"monotone is a highly reliable, very customizable distributed version control system that provides lightweight branches, history-sensitive merging and a flexible trust setup. monotone has an easy-to-learn command set and comes with a rich interface for scripting purposes and thorough documentation. For more information on monotone, visit http:\/\/www.monotone.ca. The complete documentation, including a tutorial for a quick start with the system, can be found online on http:\/\/www.monotone.ca\/docs.","Process Name":"monotone-server","Link":"https:\/\/linux.die.net\/man\/1\/monotone-server"}},{"Process":{"Description":null,"Process Name":"monshow","Link":"https:\/\/linux.die.net\/man\/1\/monshow"}},{"Process":{"Description":"Image Settings: -adjoin join images into a single multi-image file -affine matrix affine transform matrix -authenticate value decrypt image with this password -blue-primary point chromaticity blue primary point -bordercolor color border color -channel type apply option to select image channels -colors value preferred number of colors in the image -colorspace type alternate image colorsapce -comment string annotate image with comment -compose operator composite operator -compress type type of pixel compression when writing the image -define format:option define one or more image format options -density geometry horizontal and vertical density of the image -depth value image depth -display server query font from this X server -dispose method layer disposal method -dither method apply error diffusion to image -draw string annotate the image with a graphic primitive -encoding type text encoding type -endian type endianness (MSB or LSB) of the image -extract geometry extract area from image -fill color color to use when filling a graphic primitive -filter type use this filter when resizing an image -font name render text with this font -format \"string\" output formatted image characteristics -gamma value level of gamma correction -geometry geometry preferred tile and border sizes -gravity direction which direction to gravitate towards -green-primary point chromaticity green primary point -identify identify the format and characteristics of the image -interlace type type of image interlacing scheme -interpolate method pixel color interpolation method -label string assign a label to an image -limit type value pixel cache resource limit -matte store matte channel if the image has one -mattecolor color frame color -mode type framing style -monitor monitor progress -page geometry size and location of an image canvas (setting) -pointsize value font point size -profile filename add, delete, or apply an image profile -quality value JPEG\/MIFF\/PNG compression level -quantize colorspace reduce colors in this colorspace -quiet suppress all warning messages -red-primary point chromaticity red primary point -regard-warnings pay attention to warning messages -sampling-factor geometry horizontal and vertical sampling factor -scenes range image scene range -seed value seed a new sequence of pseudo-random numbers -set attribute value set an image attribute -shadow add a shadow beneath a tile to simulate depth -size geometry width and height of image -stroke color color to use when stroking a graphic primitive -support factor resize support: > 1.0 is blurry, < 1.0 is sharp -texture filename name of texture to tile onto the image background -thumbnail geometry create a thumbnail of the image -tile geometry number of tiles per row and column -title string decorate the montage image with a title -transparent-color color transparent color -treedepth value color tree depth -trim trim image edges -units type the units of image resolution -verbose print detailed information about the image -virtual-pixel method virtual pixel access method -white-point point chromaticity white point Image Operators: -adaptive-sharpen geometry adaptively sharpen pixels; increase effect near edges -annotate geometry text annotate the image with text -blur geometry reduce image noise and reduce detail levels -border geometry surround image with a border of color -crop geometry preferred size and location of the cropped image -flatten flatten a sequence of images -flip flip image in the vertical direction -flop flop image in the horizontal direction -frame geometry surround image with an ornamental border -monochrome transform image to black and white -polaroid angle simulate a Polaroid picture -repage geometry size and location of an image canvas (operator) -resize geometry resize the image -rotate degrees apply Paeth rotation to the image -strip strip image of all profiles and comments -transform affine transform image -transparent color make this color transparent within the image -type type image type -unsharp geometry sharpen the image Image Sequence Operators: -coalesce merge a sequence of images Miscellaneous Options: -debug events display copious debugging information -help print program options -log format format of debugging information -list type print a list of supported option arguments -version print version information In addition to those listed above, you can specify these standard X resources as command line options: -background, -bordercolor, -borderwidth, -font, -mattecolor, or -title. By default, the image format of 'file' is determined by its magic number. To specify a particular image format, precede the filename with an image format name and a colon (i.e. ps:image) or specify the image type as the filename suffix (i.e. image.ps). Specify 'file' as '-' for standard input or output.","Process Name":"montage","Link":"https:\/\/linux.die.net\/man\/1\/montage"}},{"Process":{"Description":null,"Process Name":"more","Link":"https:\/\/linux.die.net\/man\/1\/more"}},{"Process":{"Description":null,"Process Name":"mork","Link":"https:\/\/linux.die.net\/man\/1\/mork"}},{"Process":{"Description":"mosh (mobile shell) is a remote terminal application that supports intermittent connectivity, allows roaming, and provides speculative local echo and line editing of user keystrokes. Compared with ssh, mosh is more robust - its connections stay up across sleeps and changes in the client's IP address - and more responsive, because the protocol is tolerant of packet loss and the client can echo most keystrokes immediately, without waiting for a network round-trip. mosh uses ssh to establish a connection to the remote host and authenticate with existing means (e.g., public-key authentication or a password). mosh executes the unprivileged mosh-server helper program on the server, then closes the SSH connection and starts the mosh-client, which establishes a long-lived datagram connection over UDP. To improve responsiveness, mosh runs a predictive model of the server's behavior in the background, trying to guess the effect of each keystroke on the screen. It makes predictions for normal typing, backspace, and the left- and right-arrow keys. When it is confident, mosh displays the predictions without waiting for the server. The predictive model must prove itself anew on each row of the terminal and after each control character, so mosh avoids echoing passwords or non-echoing editor commands. By default, mosh shows its predictions only on high-latency connections and to smooth out network glitches. (On longer-latency links, the predicted cells are underlined until confirmed by the server.) Occasional echo mistakes are corrected within a network round-trip and do not cause lasting effect. mosh does not support X forwarding or the non-interactive uses of SSH, including port forwarding or sshfs. mosh works through typical client-side network address translators but requires UDP to pass between client and server. By default, mosh uses the ports between 60000 and 61000, but allows the user to request a particular UDP port instead. mosh will do its best to arrange a UTF-8 character set locale on the client and server. The client must have locale-related environment variables that specify UTF-8. mosh will pass these client variables to the mosh-server on its command line, but in most cases they will not need to be used. mosh-server first attempts to use its own locale-related environment variables, which come from the system default configuration (sometimes \/etc\/default\/locale) or from having been passed over the SSH connection. But if these variables don't call for the use of UTF-8, mosh-server will apply the locale-related environment variables from the client and try again.","Process Name":"mosh","Link":"https:\/\/linux.die.net\/man\/1\/mosh"}},{"Process":{"Description":null,"Process Name":"mosh-client","Link":"https:\/\/linux.die.net\/man\/1\/mosh-client"}},{"Process":{"Description":"mosh-server is a helper program for the mosh(1) remote terminal application. mosh-server binds to a high UDP port and chooses an encryption key to protect the session. It prints both on standard output, detaches from the terminal, and waits for the mosh-client to establish a connection. It will exit if no client has contacted it within 60 seconds. By default, mosh-server binds to a port between 60000 and 61000 and executes the user's login shell. On platforms with utempter, mosh-server maintains an entry in the utmp(5) file to indicate its process ID, whether the session is connected, and the client's current IP address. mosh-server exits when the client terminates the connection.","Process Name":"mosh-server","Link":"https:\/\/linux.die.net\/man\/1\/mosh-server"}},{"Process":{"Description":null,"Process Name":"most","Link":"https:\/\/linux.die.net\/man\/1\/most"}},{"Process":{"Description":"Motion uses a video4linux device to detect motion. If motion is detected both normal and motion pictures will be taken. Motion can also take actions to notify you if needed. Creation of automated snapshots is also possible.","Process Name":"motion","Link":"https:\/\/linux.die.net\/man\/1\/motion"}},{"Process":{"Description":null,"Process Name":"motv","Link":"https:\/\/linux.die.net\/man\/1\/motv"}},{"Process":{"Description":"mount.ecryptfs_private is a mount helper utility for non-root users, who are members of ecryptfs group, to cryptographically mount a private directory, ~\/Private. If, and only if: - the private mount passphrase is in their kernel keyring, and - the current user owns both ~\/.Private and ~\/Private, and - ~\/Private is not already mounted, then This program will: - mount ~\/.Private onto ~\/Private - as an ecryptfs filesystem - using the AES cipher - with a key length of 16 bytes - using the passphrase whose signature is in ~\/.ecryptfs\/Private.sig The only setuid operation in this program is the call to mount(8). The ecryptfs-setup-private(1) utility will create the ~\/.Private and ~\/Private directories, generate a mount passphrase, wrap the passphrase, and write the ~\/.ecryptfs\/Private.sig. The system administrator can add the pam_ecryptfs.so module to the PAM stack which will automatically use the login passphrase to unwrap the mount passphrase, add the passphrase to the user's kernel keyring, and automatically perform the mount. See pam_ecryptfs(8).","Process Name":"mount.ecryptfs_private","Link":"https:\/\/linux.die.net\/man\/1\/mount.ecryptfs_private"}},{"Process":{"Description":null,"Process Name":"mount_afp","Link":"https:\/\/linux.die.net\/man\/1\/mount_afp"}},{"Process":{"Description":"Generates random 3d plots that look vaguely mountainous.","Process Name":"mountain","Link":"https:\/\/linux.die.net\/man\/1\/mountain"}},{"Process":{"Description":null,"Process Name":"mountpoint","Link":"https:\/\/linux.die.net\/man\/1\/mountpoint"}},{"Process":{"Description":"This experimental and incomplete application tries to help in detecting which protocol does your mouse speak. It is able to detect MouseMan devices, and to choose between -t ms (three-buttons aware) and -t bare old two-buttons-only serial mice.","Process Name":"mouse-test","Link":"https:\/\/linux.die.net\/man\/1\/mouse-test"}},{"Process":{"Description":null,"Process Name":"mousetweaks","Link":"https:\/\/linux.die.net\/man\/1\/mousetweaks"}},{"Process":{"Description":"See: http:\/\/translate.sourceforge.net\/wiki\/toolkit\/moz2po for examples and usage instructions","Process Name":"moz2po","Link":"https:\/\/linux.die.net\/man\/1\/moz2po"}},{"Process":{"Description":null,"Process Name":"mozilla","Link":"https:\/\/linux.die.net\/man\/1\/mozilla"}},{"Process":{"Description":"This program downloads the trusted root certificates from the Mozilla LXR web site into the Mono certificate store. Mono by default does not ship with any default certificates and allows the user to pick its trusted certificates. The mozroots command will bring the Mozilla certificates into your local machine.","Process Name":"mozroots","Link":"https:\/\/linux.die.net\/man\/1\/mozroots"}},{"Process":{"Description":null,"Process Name":"mp2enc","Link":"https:\/\/linux.die.net\/man\/1\/mp2enc"}},{"Process":{"Description":"The program prints a message summarizing tag info (obtained via MP3::Tag module) for specified files. It may also update the information in MP3 tags. This happens in three different cases. \u2022 If the information supplied in command-line options \"t a l y g c n\" differs from the content of the corresponding ID3 tags (or there is no corresponding ID3 tags). \u2022 If options \"-d\" or \"-F\" were given. \u2022 if \"MP3::Tag\" obtains the info from other means than MP3 tags, and \"-u\" forces the update of the ID3 tags. (All these ways are disabled by \"-D\" option.) ID3v2 tag is written if needed, or if \"-2\" option is given. (Automatic fill-in of deduceable fields (via the method id3v2_frames_autofill()) is performed unless \"-d\" or \"-N\" options are given.) The option \"-u\" writes (\"u\"pdates) the fetched information to the MP3 ID3 tags. This option is assumed if there are command-line options which explicitly set tag elements (\"-a\", \"-t\" etc., and \"-F\", \"-d\"). (Effects of this option may be overridden by giving \"-D\" option.) If \"-2\" option is also given, forces write of ID3v2 tag even if the info fits the ID3v1 tag (in addition, this option enables auto-update of \"personal name\" fields, and corresponding titles according to values of \"translate_person\", \"person_frames\" etc. configuration settings; see \"Normalization of fields\"). This option is ignored if no change to tags is detected; however, one can force an update by repeating this option (useful if you expect the change the \"format\" of the tag, as opposed to its \"content\"). The option \"-p\" prints a message using the next argument as format (by default \"\\\\\", \"\\t\", \"\\n\" are replaced by backslash, tab and newline; governed by the value of \"-E\" option); see \"interpolate\" in MP3::Tag for details of the format of sprintf()-like escapes. If no option \"-p\" is given, message in default format will be emitted. The value of option \"-e\" is the encoding used for the output; if the value is a number, system-specific encoding is guessed (and used for the output if bit 0x1 is set); if bit 0x2 is set, then, command line options are assumed to be in the guessed encoding; if bit 0x4 is set, then, command line arguments are assumed to be in the guessed encoding. Use the value \"binary\" to do binary output. With option \"-D\" (dry run) no update is performed, no matter what the other options are. With this option, no parsing of tags is performed unless needed. Use options t a l y g c n to overwrite the information (title artist album year genre comment track-number) obtained via \"MP3::Tag\" heuristics ( \"-u\" switch is implied if any one of these arguments differs from what would be found otherwise; use \"-D\" switch to disable auto-update). By default, the values of these options are not \"%\"-interpolated; this may be changed by \"-E\" option. The option \"-d\" should contain the comma-separated list of ID3v2 frames to delete. A frame specification is the same as what might be given to \"%{...}\" frame interpolation command, e.g., \"TIT3\", \"COMM03\", \"COMM(fra)[short title]\"; the difference with modify-access is that ALL (and not the first of) matching frames are deleted. (Option -d may be repeated.) For example, \"-d APIC\" would remove all picture frames. In addition, if the list contains \"ID3v1\" or \"ID3v2\", whole tags will be deleted. Likewise, the option \"-F\" allows setting of arbitrary \"ID3v2\" frames: if one needs to set one frame, use the directive \"FRAME_spec=VALUE\": -F TIT2=The_new_Title Again, on modify, ALL matching frames are deleted first, so be carefull with -F COMM=MyComment Option \"-F\" may be repeated to set more than one frame. If configuration variable \"empty-F-deletes\" is TRUE (default), empty arguments will delete the frame. One can replace \"FRAME_spec=VALUE\" by \"FRAME_spec < FILE\"; in this case the value to set is read from the file named FILE ; if the frame is text-only (meaning: at most \"[encoded]Text URL Language Description\" fields are present), the file is read in text mode (and with starting\/trailing whitespace stripped), otherwise it is read in binary mode. (Whitespace is required about the \"<\" signs.) If \"<\" is replaced by \"?<\", the value is set only if frame is not yet present, and if the file exists; if replaced by \">\", the value (if present) is written to FILE . Additionally, \"FRAME_spec\" may be one of \"ID3v1\" or \"ID3v2\" or \"TAGS\"; in this case, whole tags are written or read. For example, for \"TAGS < FILE\", \"title artist album year genre comment track\" info is calculated from FILE , which may be raw tags, as produced with \">\", or a valid MP3 file. (Likewise, for \"ID3v1 < FILE\", the same info is extracted from \"ID3v1\" tag only.) After this, in case of \"ID3v2\" or \"TAGS\", \"ID3v2\" frames are copied from the \"ID3v2\" tag one-by-one. (With suitable modifications for \"?<\".) By default, the \" VALUE \" for \"-F\" is \"%\"-interpolated; this can be changed by option \"-E\". For user convenience, human-friendlier forms \"composer, text_by, orchestra, conductor\" can be used instead of \"TCOM, TEXT, TPE2, TPE3\". The option \"-P RECIPE\" is a very powerful generalization of what can be done by options \"-F\", \"-d\", and \"-t -a -l -y -g -c -n\". It may be repeated; the values should contain the parse recipes. They become the configuration item \"parse_data\" of \"MP3::Tag\"; eventually this information is processed by MP3::Tag::ParseData module (if the latter is present in the chain of heuristics; see option \"-C\"). The \"RECIPE\" is split into \"$flags, $string, @patterns\" on its first non-alphanumeric character; the first of @patterns which matches $string is going to be executed (for side effects). (See examples: \" EXAMPLES: parse rules\".) If option \"-G\" is specified, the file names on the command line are considered as glob patterns. This may be useful if the maximal command-line length is too low. With the option \"-R\" arguments can be directories, which are searched recursively for audio (default *.mp3) files to process; use option \"-r\" to reset the regular expression to look for (the default is \"(?i:\\.mp3$)\"). The option \"-E\" controls expansion of escape characters. It should contain the letters of the command-line options where \"\\\\, \\n, \\t\" are interpolated; one can append the letters of \"t a l y g c n F\" options requiring \"%\"-interpolation after the separator \"\/i:\" (for \"-F\", only the values are interpolated). The default value is \"p\/i:Fp\": only \"-p\" is \"\\\"-interpolated, and only \"-F\" and \"-p\" are subject to \"%\"-interpolation. If all one wants is to add to the defaults, preceed the value of \"-E\" (containing added options) by \"+\". (Some parts of the value of option \"-P\" are interpolated, but this should be governed by flags, not \"-E\"; do NOT put \"P\" into the \"%\"-interpolated part of \"-E\".) If the option \"-@\" is given, all characters \"@\" in the options are replaced by \"%\". This may be convenient if the shell treats \"%\" specially (e.g., DOSISH shells). If option \"-I\" is given, no guessworking for artist field is performed on typeout. The option \"-C CONFIG_OPT=VALUE1,VALUE2...\" sets \"MP3::Tag\" configuration data the same way as \"MP3::Tag-\"config()> would do (recall that the value is an array; separate elements by commas if more than one). The option may be repeated to set more than one value. Note that since \"ParseData\" is used to process \"-P\" parse recipes, it should be better be kept in the \"autoinfo\" configuration (and related fields \"author\" etc) in presence of \"-P\". If the option \"-x\" is given, the technical information about the audio file is printed ( MP3 level, duration, number of frames, padding, copyright, and the list of ID3v2 frame names in format suitable to \"%{...}\" escapes). If \"-x\" is repeated, content of frames is also printed out (may output non-printable chars, if it is repeated more than twice). If option \"-N\" is given, all the \"smarts\" are disabled - no normalization of fields happens, and (by default) no attempt to deduce the values of fields from non-ID3 information is done. This option is (currently) equivalent to having \"-C autoinfo=ParseData,ID3v2,ID3v1\" as the first directive, to having no Normalize::Text::Music_Fields.pm present on @INC path, and not calling autofill() method.","Process Name":"mp3info2","Link":"https:\/\/linux.die.net\/man\/1\/mp3info2"}},{"Process":{"Description":null,"Process Name":"mpack","Link":"https:\/\/linux.die.net\/man\/1\/mpack"}},{"Process":{"Description":"mpage reads plain text files or PostScript documents and prints them on a PostScript printer with the text reduced in size so that several pages appear on one sheet of paper. This is useful for viewing large printouts on a small amount of paper. It uses ISO 8859.1 to print 8-bit characters. The following options are recognized (note that arguments to options may be separated from the option by spaces, except for -B, -m, -M, -p and -P): Also when mpage encounters -- as option it will stop parsing arguments and the remaining arguments are interpreted as filenames. -1 Print 1 normal page per sheet (included for symmetry). -2 Print 2 normal pages per sheet. -4 Print 4 normal pages per sheet (default). -8 Print 8 normal pages per sheet. -a Toggle layout of the pages on the sheet so that successively numbered pages run down the sheet, as opposed to left to right. (default updown) . -A This option is deprecated, see -b. Prepare output for A4 sized paper. For default see 'mpage -x'. -b papertype Prepare output for selected paper type. Papersize can be A3 for European A3, A4 for European A4, Letter for US Letter or Legal for Legal sized paper. For default see 'mpage -x'. To see the list of currently available types, just give the 'mpage -bl' or 'mpage -b?' command (Note: mpage exits after finding such option use.) -B[ <num>[ lrtb]*] Setup a box around a particular part of your page. Specify text box margins and line thickness. The default is 0 columns (lines) for both left and right (top and bottom) margins and 0 line thickness. Specifying -B solely toggles printing of the box. l, r, t or b set the left, right, top or bottom margin respectively to <num> columns (lines). Not specifying any of the sides, will set the line thickness when <num> is given. For example -B 1 sets the line thickness to 1. Sides with negative margins will not print. -c Toggle concatenation off pages from different files on single sheets (default off). -C[ encodingfile] Specify the character encoding file. The file should be in the mpage library directory ( \/usr\/share\/mpage). Mpage has an internal default encoding based on Latin-1 or IBM codepage 850. Depending on compile time option this encoding definition is on or not. Not specifying an encodingfile will toggle the usage of the internal encoding. -d a| p Force input to be taken as ascii (a) or postscript (p) text. This way you can print your postscript code as text, or print postscript code that mpage does not recognise. When using -dp, make sure that the the postscript code contains %Page page separators or else things will probably look odd. -D dateformat Set the date format as in strftime(3) to be used in date\/time representations (e.g. in headers). (Note: to be useful you probably need the -H option.) -e Print 2 normal pages per sheet in duplex mode. Every first and fourth page or on one side and every second and third on the other side. This is more or less a combination of the -O and -E option but then in one pass. -E Print 2 normal pages per sheet. However, this option will print every second and third page of every set of four pages. This option will ignore -a and -l. See also the -O option. Using these options double sided prints can be created without a duplex printer. -f Toggles folding lines longer than page width (default off) . -F fontname Specify font. ( default Courier). Check your printer for supported fonts. Note: this has almost nothing to do with the fonts used for your X-windows\/KDE\/Gnome environment. -h header This is used only when the -p or -H switch is used and is passed as the \" -h header\" option to pr( 1) or as the header for -H. -H Create header line for each logical page separated from page text by a horizontal line. Unless -h is given, the header consist of last file modification time, filename and page number, all in bold and slightly larger font. This option only applies to non-postscript files. -I indent Indent text by indent characters. -j first[ -last][ %interval] Print just the selected sheets, specified by a number, starting at 1. Here last defaults to the end of data, interval to 1. Several -j options can be given (upto MAXJARGS, default 100) to create a complex selection of pages. Thus -j 1-10 selects the first 10 sheets, while -j 1%2 prints just the odd-numbered sheets and -j 2%2 prints just the even ones. You can do double-sided printing, in two passes, as follows. If you use 3-hole punched paper, put it in the printer such that the holes will appear at the top of the page -- on the right as you pull out the printer tray, in our Laser writer II NTX. Print the odd-numbered sheets with mpage ... -j 1%2 ... Note the number of pages it reports. (Only half this many will really be printed). When printing finishes, if mpage reported an odd number of pages, remove the last one from the stack, since there will be no even-numbered sheet to match it. Then arrange the stack of paper for printing on the other side. (If it's punched, the holes will now be on the left.) On our II NTX, the paper comes out blank-side up; replace it in the tray still blank-side up but rotated 180 degrees. For other printers, you figure it out. Now print the even-numbered sheets in reverse order with mpage ... -r -j 2%2 ... hoping no one else reaches the printer before you do. -J startpageno Set the start value of the sheet page count to startpageno instead of 1. -k When mpage finds a %%TRailer or %%PSTrailer in the postscript input file it normally assumes this is the end of the postscript file and stops reading the input file. But when the PS file includes EPS files, %%Trailers might be anywhere. Using this option ignores the %%TRailer and %%PSTRailer lines. -l Toggle printing landscape or portrait mode. Landscape pages are 55 lines long by 132 characters wide by default. Portrait pages are 66 lines long by 80 characters wide by default. (default portrait.) -L lines Adjust the page reduction parameters so that lines lines will fit in the space of one page. This overrides the default values normally supplied. (See -l.) If used in conjunction with -p then this value is passed to the pr(1) as well. As a side effect this changes the font size as well (as will the -W option.) So while there is an option to change font family, there is no explicit option to change font size! -m[ <num>[ lrtb]*] Specify sheet margin. The default margin is 20 points. Only specifying -m sets left margin to 40 points. l, r, t or b set left, right, top or bottom margin respectively to <num> points. Not specifying any of the sides will set all sides when <num> is given. <num> defaults to 40 points. For example -m 10 sets all margins to 10 points. -m l50tb sets left margin to default 40 and top and bottom margin to 50 points. -m 50l25bt30r set bottom and top margin to 25, left margin to 50 and right margin to 30 points. Margins can have negative numbers. -M[ <num>[ lrtb]*] Specify logical page margins. For syntax, see -m option. Defaults are 4 for -M solely, and 8 for <num>. Margins can be negative. This way large white borders in your (postscript) documents can be reduced. -o Toggle printing of outlines around each reduced page (default on). -O Print 2 normal pages per sheet. However, this option will print every first and fourth page of every set of four pages. This option will ignore -a and -l. See also the -E option. Using these options double sided prints can be created without a duplex printer. -p[ prprog] Pipe input through prprog command (including specified options) before printing (assumes the input is a text file). When no command is specified, it defaults to pr(1). -P[ printer] Specify the printer to which the PostScript output will be sent (e.g.lpr -P printer). Using -P with no printer specified will send the PostScript to the default printer queue (e.g. lpr). Using -P- will return output to stdout, useful in combination with MPAGE environment variable. Without -P output will be send to standard output. -r Reverse printing. The last sheet is printed first. The way of arranging reduced pages on the sheets doesn't change. -R Switch to left to right mode, starting first page on left bottom corner. This might be useful for landscape postscript files. (Note: using -l after -R undoes -R, and switches to normal landscape mode. -s tabstop Set tabstop width ( default 8 characters). Should by >= 2. -S Accept non-square page reduction. By default, pages are shrunk equally in X and Y, even if this wastes some space on the sheet. With -S, reduced pages are larger but slightly distorted. (only used when printing postscript files.) -t Toggle printing on both sides of the paper. This will toggle duplex mode of the printer. Use this option only if your printer is capable of printing in duplex mode. (default off). -T Toggle tumble of every second pages when printing in duplex mode. Use this option only if your printer is capable of printing in duplex mode and together with -t. -u Toggle checking for UTF-8 input (not relevant for postscript input). -U This option is deprecated, see -b. Prepare output for US Letter sized paper. For default see 'mpage -x'. -v Toggle printing a count of the number of sheets produced for printing (default off.) -V Print version information and exit. -W width Adjust the page reduction parameters so that a line with width characters long will fit in the space of one page. This overrides the default values normally supplied. (See -l.) If used in conjunction with -p then this value is passed to the s pr(1) program as well. See also the -L option on font sizes. -x Force usage display, which also shows current defaults. -X [header] Print header on the left and the page number on the right of each physical page (sheet). If no header is given, the default is the current filename (note influence of -c), the filename of the first file on the page is used. -z printcommand Specify command to use to send output to. Default is lpr (1) for BSD style spooler, lp (1) for SYSV style spooler. You can specify command line options, but note -Z. For example -zlp for system V Unix. -Z printprog_queuename_arg Specify what option to use for the \" -z printcommand\" to specify a printqueue. For example -zlp -Z-d for system V Unix. Default is -P for BSD style spooler, -d for SYSV style spooler.","Process Name":"mpage","Link":"https:\/\/linux.die.net\/man\/1\/mpage"}},{"Process":{"Description":null,"Process Name":"mpartition","Link":"https:\/\/linux.die.net\/man\/1\/mpartition"}},{"Process":{"Description":"mpc is a client for MPD, the Music Player Daemon. mpc connects to a MPD and controls it according to commands and arguments passed to it. If no command is given, the current status is printed (same as 'mpc status').","Process Name":"mpc","Link":"https:\/\/linux.die.net\/man\/1\/mpc"}},{"Process":{"Description":null,"Process Name":"mpd","Link":"https:\/\/linux.die.net\/man\/1\/mpd"}},{"Process":{"Description":null,"Process Name":"mpdscribble","Link":"https:\/\/linux.die.net\/man\/1\/mpdscribble"}},{"Process":{"Description":null,"Process Name":"mpeg2dec","Link":"https:\/\/linux.die.net\/man\/1\/mpeg2dec"}},{"Process":{"Description":null,"Process Name":"mpeg2desc","Link":"https:\/\/linux.die.net\/man\/1\/mpeg2desc"}},{"Process":{"Description":"mpeg2enc is heavily enhanced derivative of the MPEG Software Simulation Group's MPEG-2 reference encoder. It accepts streams in a simple planar YUV format \"YUV4MPEG\" produced by the lav2yuv and related filters (e.g. yuvscaler(1)) from the mjpegtools(1) package. An output plug-in to the mpeg2dec(1) MPEG decoder is available to permit its use in transcoding applications. The encoder currently fully supports the generation of elementary MPEG-1, progressive and interlaced frame MPEG-2 streams. Field encoded MPEG-2 is also possible but is not currently maintained or supported. For most purposes this elementary stream output will need to be multiplexed with one or more audio streams into a program\/systems stream using the mplex(1) tool. Note that although this manual page aims to explain how mpeg2enc can be used effectively it is not intended as an introduction to MPEG-1\/2 video which is a fairly complex topic in its own right. The MPEG video format is a somewhat baroque standard with many many options, not all of which necessarily easy to explain or even particular useful in the context of a software encoder. Much useful practical information for novices can be found in the mjpeg-HOWTO document that should have been installed with mjpegtools(1) package. Further information and useful supporting software can be found on the mjpegtools web-site: http:\/\/mjpeg.sourceforge.net","Process Name":"mpeg2enc","Link":"https:\/\/linux.die.net\/man\/1\/mpeg2enc"}},{"Process":{"Description":null,"Process Name":"mpg123","Link":"https:\/\/linux.die.net\/man\/1\/mpg123"}},{"Process":{"Description":"mpg321 is a free command-line mp3 player, which uses the mad audio decoding library. mpg321 is written to be a drop-in replacement for the non-free mpg123 player. Some functions remain unimplemented, but mpg321 should function as a basic drop-in replacement for mpg123 front-ends such as gqmpeg, and those programs which use mpg123 to decode mp3 files (like gtoaster, and other CD-recording software). mpg321 differs from mpg123 in several ways. First and foremost, it is fully Free, under the GNU General Public License. Secondly, it allows run-time switching of output devices (via the -o switch). (mpg321 also allows configuring a default output device at compile-time, but run-time switching is always allowed).","Process Name":"mpg321","Link":"https:\/\/linux.die.net\/man\/1\/mpg321"}},{"Process":{"Description":null,"Process Name":"mpgcat","Link":"https:\/\/linux.die.net\/man\/1\/mpgcat"}},{"Process":{"Description":"mpgtx can split and join MPEG files in various ways. Three file types are currently handled (more to come): MPEG 1 Video files, MPEG 1\/2 Audio files (mp1, mp2, and mp3), MPEG 1 System files (audio and video files), MPEG 2 Program files (Experimental), MPEG 2 Transport files (demultiplex and info modes only). mpgtx is a GOP (Group of Pictures) based editor. This means that mpgtx cuts MPEG files on a Group Of Picture basis, not on a frame-by-frame basis. A typical GOP duration is about 0.5 sec (approx. 15 frames), limiting the maximum accuracy of mpgtx.","Process Name":"mpgdemux","Link":"https:\/\/linux.die.net\/man\/1\/mpgdemux"}},{"Process":{"Description":null,"Process Name":"mpginfo","Link":"https:\/\/linux.die.net\/man\/1\/mpginfo"}},{"Process":{"Description":"mpgtx can split and join MPEG files in various ways. Three file types are currently handled (more to come): MPEG 1 Video files, MPEG 1\/2 Audio files (mp1, mp2, and mp3), MPEG 1 System files (audio and video files), MPEG 2 Program files (Experimental), MPEG 2 Transport files (demultiplex and info modes only). mpgtx is a GOP (Group of Pictures) based editor. This means that mpgtx cuts MPEG files on a Group Of Picture basis, not on a frame-by-frame basis. A typical GOP duration is about 0.5 sec (approx. 15 frames), limiting the maximum accuracy of mpgtx.","Process Name":"mpgjoin","Link":"https:\/\/linux.die.net\/man\/1\/mpgjoin"}},{"Process":{"Description":null,"Process Name":"mpgsplit","Link":"https:\/\/linux.die.net\/man\/1\/mpgsplit"}},{"Process":{"Description":"mpgtx can split and join MPEG files in various ways. Three file types are currently handled (more to come): MPEG 1 Video files, MPEG 1\/2 Audio files (mp1, mp2, and mp3), MPEG 1 System files (audio and video files), MPEG 2 Program files (Experimental), MPEG 2 Transport files (demultiplex and info modes only). mpgtx is a GOP (Group of Pictures) based editor. This means that mpgtx cuts MPEG files on a Group Of Picture basis, not on a frame-by-frame basis. A typical GOP duration is about 0.5 sec (approx. 15 frames), limiting the maximum accuracy of mpgtx.","Process Name":"mpgtx","Link":"https:\/\/linux.die.net\/man\/1\/mpgtx"}},{"Process":{"Description":null,"Process Name":"mpi","Link":"https:\/\/linux.die.net\/man\/1\/mpi"}},{"Process":{"Description":"The mpi-selector command is a simplistic tool to select one of multiple MPI implementations. mpi-selector allows system administrators to set a site-wide default MPI implementation while also allowing users to set their own default MPI implementation (thereby overriding the system-wide default). Note that both the site-wide and per-user defaults are independent from each other; a system administrator may choose not to have a site-wide default while a user may choose to have a personal default -- and vice versa. The system is effected by having system-wide shell startup files that looks first at the user's MPI preferences. If found, the MPI implementation indicated by the user's preferences is setup in the current environment. If not found, look for a site-wide default. If found, the MPI implementation indicated in by the site-wide default is setup in the current environment. If not found, exit silently. End Users \/ System Administrators The mpi-selector command provides four main actions: * List which MPI implementations are available * Set a default (either on a per-user or site-wide basis) * Unset a default (either on a per-user or site-wide basis) * Query what the current default is A common scenario is that a system administrator sets a site-wide default for a supported MPI implementation that most users will use. Power users then change their per-user defaults to use a different MPI implementation. Another common scenario is for power users to frequently use mpi-selector to swap back and forth between multiple different MPI implementations. NOTE: The mpi-selector command only changes the defaults for new shells. Specifically, after you invoke the mpi-selector command to change the default MPI implementation, this change does not take effect until you start a new shell. This is intentional. See the \" KNOWN LIMITATIONS \" section, below. MPI Implementations MPI implementations register themselves with mpi-selector when they are installed and unregister themselves when they are uninstalled. Each MPI installation provides two files that setup the environment for itself: * mpivars.sh: File sourceable by Bourne-like shells (sh, bash, etc.) * mpivars.csh: File sourceable by C-like shells (csh, tcsh, etc.) These files are expected to be in a single directory and \"registered\" with mpi-selector using the --register and --source-dir options. mpi-selector will copy these files to its own internal store; it is safe to remove the originals after the mpi-selector registration completes successfully. The <name> argument to --register must be simplistic -- it cannot contain any shell special characters (not even if they are escaped), nor can it contain spaces. The intent is to provide simple names that users can type without escaping or quoting. Names not conforming to these rules will be rejected and the registration will fail. When an MPI implementation is uninstalled, it should unregister with mpi-selector via the --unregister option.","Process Name":"mpi-selector","Link":"https:\/\/linux.die.net\/man\/1\/mpi-selector"}},{"Process":{"Description":null,"Process Name":"mpi-selector-menu","Link":"https:\/\/linux.die.net\/man\/1\/mpi-selector-menu"}},{"Process":{"Description":"Conceptually, the role of these commands is quite simple: transparently add relevant compiler and linker flags to the user's command line that are necessary to compile \/ link Open MPI programs, and then invoke the underlying compiler to actually perform the command. As such, these commands are frequently referred to as \"wrapper\" compilers because they do not actually compile or link applications themselves; they only add in command line flags and invoke the back-end compiler. Background Open MPI is comprised of three software layers: OPAL (Open Portable Access Layer), ORTE (Open Run-Time Environment), and OMPI (Open MPI). There are wrapper compilers for each layer; each layer's wrapper only links in the libraries relevant for that layer. Specifically, each layer provides the following wrapper compilers: OPAL opalcc and opalc++ ORTE ortecc and ortec++ OMPI mpicc, mpic++, mpicxx, mpiCC (only on systems with case-senstive file systems), mpif77, and mpif90. Note that mpic++, mpicxx, and mpiCC all invoke the same underlying C++ compiler with the same options. All are provided as compatibility with other MPI implementations. The Fortran wrapper compilers for MPI (mpif77 and mpif90) will be inoperative and will return an error on use if Fortran 77 \/ Fortran 90 support was not built into the MPI layer. Overview mpic++ is a convenience wrappers for the underlying C++ compiler. Translation of an Open MPI program requires the linkage of the Open MPI-specific libraries which may not reside in one of the standard search directories of ld(1). It also often requires the inclusion of header files what may also not be found in a standard location. mpic++ passes its arguments to the underlying C++ compiler along with the -I, -L and -l options required by Open MPI programs. The Open MPI Team strongly encourages using the wrapper compilers instead of attempting to link to the Open MPI libraries manually. This allows the specific implementation of Open MPI to change without forcing changes to linker directives in users' Makefiles. Indeed, the specific set of flags and libraries used by the wrapper compilers depends on how Open MPI was configured and built; the values can change between different installations of the same version of Open MPI. Indeed, since the wrappers are simply thin shells on top of an underlying compiler, there are very, very few compelling reasons not to use mpic++. When it is not possible to use the wrappers directly, the -showme:compile and -showme:link options should be used to determine what flags the wrappers would have used. For example: shell$ cc -c file1.c 'mpicc -showme:compile' shell$ cc -c file2.c 'mpicc -showme:compile' shell$ cc file1.o file2.o 'mpicc -showme:link' -o my_mpi_program","Process Name":"mpic++","Link":"https:\/\/linux.die.net\/man\/1\/mpic++"}},{"Process":{"Description":null,"Process Name":"mpicc","Link":"https:\/\/linux.die.net\/man\/1\/mpicc"}},{"Process":{"Description":"Mined is a text editor with Interactive features \u2022 Intuitive user interface \u2022 Logical and consistent concept of navigating and editing text (without ancient line-end handling limitations or insert\/append confusion) \u2022 Supports various control styles: \u2022 Editing with command control, function key control, or menu control \u2022 Navigation by cursor keys, control keys, mouse or scrollbar \u2022 Concise and comprehensive menus (driven by keyboard or mouse) \u2022 \"HOP\" key paradigm doubles the number of navigation functions that can be most easily reached and remembered by intuitively amplifying or expanding the associated function \u2022 →NEW→ Interactive file chooser and →NEW→ interactive file switcher \u2022 Proper handling of window size changes in any state of interaction Versatile character encoding support \u2022 Extensive Unicode support, including double-width and combining characters, script highlighting, various methods of character input support (mapped keyboard input methods, mnemonic and numeric input), supporting CJK, Vietnamese, Hebrew, Arabic, and other scripts \u2022 →NEW→ Character information updated to Unicode 6.1 \u2022 Extensive accented character input support, including multiple accent prefix keys \u2022 Support for Greek (monotonic and polytonic) \u2022 Support for Cyrillic accented characters \u2022 Support of bidirectional terminals \u2022 Support of Arabic ligature joining on all terminals \u2022 East Asian character set support: handling of major CJK encodings (including GB18030 and full EUC-JP with combining characters) \u2022 Support for a large number of 8 bit encodings (with combining characters for Vietnamese, Thai, Arabic, Hebrew) \u2022 Support of CJK input methods by enhanced keyboard mapping including multiple choice mappings (handled by a pick list menu); characters in the pick list being sorted by relevance of Unicode ranges \u2022 Han character information with description and pronunciation \u2022 Auto-detection of text character encoding, edits files with mixed character encoding sections (e.g. mailboxes), transparent handling and auto-detection of UTF-16 encoded files \u2022 Auto-detection of UTF-8 \/ CJK \/ 8 bit terminal mode and detailed features (like different Unicode width and combining data versions) \u2022 Comprehensive and flexible (though standard-conformant) set of mechanisms to specify both text and terminal encodings with useful precedences \u2022 Flexible combination of any text encoding with any terminal encoding \u2022 Encoding support tested with: xterm, mlterm, rxvt, cxterm, kterm, hanterm, KDE konsole, gnome-terminal, Linux console, cygwin console, mintty, PuTTY Text editing features \u2022 Many text editing features, e.g. paragraph wrapping, auto-indentation and back-tab, smart quotes (with quotation marks style selection and auto-detection) and smart dashes \u2022 Search and replacement patterns can have multiple lines \u2022 Cross-session paste buffer (copy\/paste between multiple - even subsequent or remote - invocations of mined) \u2022 Optional Unicode paste buffer mode with implicit conversion \u2022 Marker stack for quick return to previous text positions \u2022 Multiple paste buffers (emacs-style) \u2022 Optional rectangular copy\/paste area \u2022 Interactive selection highlighting (with mouse or keyboard selection), standard dual-mode Del key behaviour \u2022 Program editing features, HTML support and syntax highlighting, identifier and function definition search, also across files; structure input support \u2022 Text and program layout features; auto-indentation and undent function (back-tab), numbered item justification \u2022 Systematic text and file handling safety, avoiding loss of data \u2022 Visible indications of special text contents (TAB characters, different line-end types, character codes that cannot be displayed in the current mode) \u2022 Full binary transparent editing with visible indications (illegal UTF-8 or CJK, mixed line end types, NUL characters, ...) \u2022 Print function that works in all text encodings \u2022 Optional password hiding \u2022 Optional emacs command mode Small-footprint operation, portability and interworking \u2022 Plain text mode (terminal) operation \u2022 Optimized use of terminal features for a wide range of terminals, including large terminal support (2015x2015) of recent xterm and mintty \u2022 Instant start-up \u2022 Runs on many platforms (including legacy systems): Linux, →NEW→ Android, Unix (SunOS, BSD, Mac OS X, QNX, GNU Hurd, HP-UX, IBM AIX, SCO UnixWare, Ultrix, Tru64), DOS (djgpp), Windows (cygwin, Interix), →NEW→ OpenVMS, Haiku This manual contains the main topics \u2022 Command line options \u2022 Editing text with mined, an overview \u2022 Keypad layout \u2022 The HOP function \u2022 Mouse control and Menus \u2022 Paste buffers \u2022 Visual selection and →NEW→ Keypad modes \u2022 Rectangular copy\/paste \u2022 Text position marker stack \u2022 Paragraph justification \u2022 Auto indentation and Structure input support \u2022 Search and replace multiple lines \u2022 Overview: input support features \u2022 Handling files with mined \u2022 Tags file support \u2022 Data safety and security, →NEW→ Backup and recovery files and File locking \u2022 Line end modes and binary-transparent editing \u2022 File info: Memory of file position and editing style parameters \u2022 →NEW→ File chooser and File switcher \u2022 Version control integration \u2022 Printing \u2022 Working with mined \u2022 Quick Options (Mode indication) flags \u2022 Structured editing support \u2022 Password hiding \u2022 Visible indication of line contents Language support \u2022 Character handling support \u2022 Combining characters \u2022 Character information display \u2022 Character conversion features \u2022 Smart quotes \u2022 Character input support \u2022 Accented and mnemonic input support \u2022 Combining character input \u2022 Special character input shortcuts \u2022 Character input mnemonics \u2022 Keyboard Mapping and Input Methods \u2022 Character encoding support \u2022 Auto-detected character encodings \u2022 CJK and mapped 8 bit encoding support \u2022 Combining characters \u2022 Unicode support \u2022 Character input support \u2022 Encoding conversion support \u2022 Bidirectional terminal support \u2022 Joining characters \u2022 CJK support \u2022 CJK input method support \u2022 Han character information display \u2022 Terminal encoding support Mined Command reference (command and key function assignments) \u2022 Generic command modifiers (esp. HOP key) \u2022 Cursor and screen motion \u2022 Entering text \u2022 Input support commands \u2022 Modifying text \u2022 Text block and buffer operations \u2022 Search \u2022 File operations \u2022 Menu \u2022 Miscellaneous \u2022 MSDOS keyboard functions \u2022 Emacs mode \u2022 Windows keyboard mode \u2022 WordStar mode \u2022 Configuration of user preferences \u2022 Environment interworking and configuration hints \u2022 Mined runtime support library \u2022 PC versions \u2022 VMS version \u2022 Android version \u2022 Terminal environment \u2022 Locale configuration \u2022 PC terminals \u2022 Terminal setup and configuration \u2022 Terminal interworking problems \u2022 Keyboard Mapping \/ Input Method pre-selection \u2022 Smart Quotes style configuration \u2022 Han info configuration \u2022 Common paste buffer configuration \u2022 Keypad configuration \u2022 Printing configuration \u2022 Mined configuration \u2022 Environment variables \u2022 Author and Acknowledgements Interactive help is available with F1.","Process Name":"mpico","Link":"https:\/\/linux.die.net\/man\/1\/mpico"}},{"Process":{"Description":"Conceptually, the role of these commands is quite simple: transparently add relevant compiler and linker flags to the user's command line that are necessary to compile \/ link Open MPI programs, and then invoke the underlying compiler to actually perform the command. As such, these commands are frequently referred to as \"wrapper\" compilers because they do not actually compile or link applications themselves; they only add in command line flags and invoke the back-end compiler. Background Open MPI is comprised of three software layers: OPAL (Open Portable Access Layer), ORTE (Open Run-Time Environment), and OMPI (Open MPI). There are wrapper compilers for each layer; each layer's wrapper only links in the libraries relevant for that layer. Specifically, each layer provides the following wrapper compilers: OPAL opalcc and opalc++ ORTE ortecc and ortec++ OMPI mpicc, mpic++, mpicxx, mpiCC (only on systems with case-senstive file systems), mpif77, and mpif90. Note that mpic++, mpicxx, and mpiCC all invoke the same underlying C++ compiler with the same options. All are provided as compatibility with other MPI implementations. The Fortran wrapper compilers for MPI (mpif77 and mpif90) will be inoperative and will return an error on use if Fortran 77 \/ Fortran 90 support was not built into the MPI layer. Overview mpicxx is a convenience wrappers for the underlying C++ compiler. Translation of an Open MPI program requires the linkage of the Open MPI-specific libraries which may not reside in one of the standard search directories of ld(1). It also often requires the inclusion of header files what may also not be found in a standard location. mpicxx passes its arguments to the underlying C++ compiler along with the -I, -L and -l options required by Open MPI programs. The Open MPI Team strongly encourages using the wrapper compilers instead of attempting to link to the Open MPI libraries manually. This allows the specific implementation of Open MPI to change without forcing changes to linker directives in users' Makefiles. Indeed, the specific set of flags and libraries used by the wrapper compilers depends on how Open MPI was configured and built; the values can change between different installations of the same version of Open MPI. Indeed, since the wrappers are simply thin shells on top of an underlying compiler, there are very, very few compelling reasons not to use mpicxx. When it is not possible to use the wrappers directly, the -showme:compile and -showme:link options should be used to determine what flags the wrappers would have used. For example: shell$ cc -c file1.c 'mpicc -showme:compile' shell$ cc -c file2.c 'mpicc -showme:compile' shell$ cc file1.o file2.o 'mpicc -showme:link' -o my_mpi_program","Process Name":"mpicxx","Link":"https:\/\/linux.die.net\/man\/1\/mpicxx"}},{"Process":{"Description":null,"Process Name":"mpiexec","Link":"https:\/\/linux.die.net\/man\/1\/mpiexec"}},{"Process":{"Description":"This command can be used to compile and link MPI programs written in Fortran 77. It provides the options and any special libraries that are needed to compile and link MPI programs. It is important to use this command (or a Makefile processed with mpireconfig ) particularly when linking programs, as it provides the necessary libraries. It can also simplify the use of the MPE profiling libraries, through the use of the -mpilog , -mpitrace , and -mpianim commands.","Process Name":"mpif77","Link":"https:\/\/linux.die.net\/man\/1\/mpif77"}},{"Process":{"Description":null,"Process Name":"mpif90","Link":"https:\/\/linux.die.net\/man\/1\/mpif90"}},{"Process":{"Description":"The mpiman command gives access to the MPI manual pages in both UNIX man and Web HTML format. By default, mpiman uses xman, the X Window System manual browser to read the man pages. By providing a command-line argument to mpiman , you can choose a different browser. The Web HTML format provides hot links between related routines and with the MPI standard.","Process Name":"mpiman","Link":"https:\/\/linux.die.net\/man\/1\/mpiman"}},{"Process":{"Description":null,"Process Name":"mpimsg","Link":"https:\/\/linux.die.net\/man\/1\/mpimsg"}},{"Process":{"Description":"The mpireconfig command takes a template file and creates a file that may be given to the make command by replacing variable with values appropriate for a particular MPICH configuration.","Process Name":"mpireconfig","Link":"https:\/\/linux.die.net\/man\/1\/mpireconfig"}},{"Process":{"Description":null,"Process Name":"mpirun","Link":"https:\/\/linux.die.net\/man\/1\/mpirun"}},{"Process":{"Description":"The mpitask command displays information on processes which are using MPI. One line is printed for each reported MPI process. With no processes or nodes explicitly specified on the command line, all MPI processes on all nodes are reported. % mpitask TASK (G\/L) FUNCTION PEER|ROOT TAG COMM COUNT DATATYPE 0\/0 trivial Ssend 1\/1 123 WORLD 64 INT 1\/1 trivial Recv 0\/0 456 WORLD 64 INT For each process mpitask normally prints the following information: TASK an identification of the process - If the process is currently communicating, a '\/' followed by the process's rank within the current communicator is also displayed. The executable name, if available, is also displayed. See \"MPI Process Identification\". FUNCTION an abbreviated form of the function name if the process is blocked inside an MPI function - Otherwise one of the following execution states is printed: <running> free to run on the underlying OS <paused> blocked on lam_kpause(2) <stopped> stopped by the LAM signal, LAM_SIGARREST - See doom(1). <blocked> blocked in a LAM function - In general this should be a transitory state. Further information on a LAM process's state can be obtained with state(1). PEER|ROOT the source or destination of a point-to-point communication or the root process of certain collective communications, followed by a '\/' and the process's rank within the current communicator - TAG the message tag, if any, which was specified as a parameter to the current MPI function COMM the communicator ID, if any, which was specified as a parameter to the current MPI function - Communicators used in collective calls are displayed with a * suffix. Further information on the communicator may be obtained with the -c option. COUNT the element count, if any, which was specified as a parameter to the current MPI function DATATYPE the element datatype, if any, which was specified as a parameter to the current MPI function - For intrinsic datatypes, a shortened version of the datatype name is displayed. For derived datatypes, a datatype label is displayed. Further information on the datatype may be obtained with the -d option. MPI Process Identification By default, MPI processes are identified by their rank in MPI_COMM_WORLD. We refer to this rank more concisely as the \"global\" rank (G). The rank within the currently employed communicator is referred to as the \"local\" rank (L). Since processes may be dynamically spawned (see MPIL_Spawn(2)) and since multiple concurrent MPI applications are allowed, it is possible for multiple MPI_COMM_WORLD communicators to coexist. In these situations, the global rank is no longer globally unique and the identification is ambiguous. Thus, LAM provides an alternate way of identifying MPI processes, the GPS (Global Positioning System). A process's GPS consists of the nodeid the process is running on and the process's LAM index on that node. It is displayed in mpitask as the pair n<node>,i<index>. If the -gps option is given then the GPS is substituted for the global rank (G). Communicators If the -c option is given then information is no longer displayed in the horizontal format described above. Instead for each selected process currently using a communicator, the information from the TASK column, described above, is given followed by an expanded description of the communicator. This description includes the size of the communicator group(s) and the global identifiers of all members of the group(s). Datatypes If the -d option is given then information is no longer displayed in the horizontal format described above. Instead for each selected process currently using a communicator, the information from the TASK column, described above, is given followed by the datatype's type map.","Process Name":"mpitask","Link":"https:\/\/linux.die.net\/man\/1\/mpitask"}},{"Process":{"Description":null,"Process Name":"mplayer","Link":"https:\/\/linux.die.net\/man\/1\/mplayer"}},{"Process":{"Description":"Mplex is a general-purpose audio\/video multiplexer for MPEG-1\/MPEG-2. It accepts one or more MPEG-1\/2 video stream, MPEG layer I\/II\/III, DTS, AC3 and LPCM audio streams and multiplexes them into a combined program\/system stream according to the constraints specified. Many different types of output structure are supported along with presets for standard VCD and SVCD streams. These latter can be burned to CD using tools such as vcdimager(1) and played in stand-alone players. It is also capable of automatically splitting the output stream into chunks of a specified size either independently or at sequence end\/start points in the input video stream.","Process Name":"mplex","Link":"https:\/\/linux.die.net\/man\/1\/mplex"}},{"Process":{"Description":null,"Process Name":"mpost","Link":"https:\/\/linux.die.net\/man\/1\/mpost"}},{"Process":{"Description":"The mpstat command writes to standard output activities for each available processor, processor 0 being the first one. Global average activities among all processors are also reported. The mpstat command can be used both on SMP and UP machines, but in the latter, only global average activities will be printed. If no activity has been selected, then the default report is the CPU utilization report. The interval parameter specifies the amount of time in seconds between each report. A value of 0 (or no parameters at all) indicates that processors statistics are to be reported for the time since system startup (boot). The count parameter can be specified in conjunction with the interval parameter if this one is not set to zero. The value of count determines the number of reports generated at interval seconds apart. If the interval parameter is specified without the count parameter, the mpstat command generates reports continuously.","Process Name":"mpstat","Link":"https:\/\/linux.die.net\/man\/1\/mpstat"}},{"Process":{"Description":null,"Process Name":"mpto","Link":"https:\/\/linux.die.net\/man\/1\/mpto"}},{"Process":{"Description":"mptopdf can convert MetaPost-generated EPS files to PDF, or it can process a MetaPost source file directly (see mpost(1)) and convert the generated EPS files to PDF.","Process Name":"mptopdf","Link":"https:\/\/linux.die.net\/man\/1\/mptopdf"}},{"Process":{"Description":"mr is a Multiple Repository management tool. It can checkout, update, or perform other actions on a set of repositories as if they were one combined repository. It supports any combination of subversion, git, cvs, mercurial, bzr, darcs and fossil repositories, and support for other revision control systems can easily be added. mr cds into and operates on all registered repositories at or below your working directory. Or, if you are in a subdirectory of a repository that contains no other registered repositories, it will stay in that directory, and work on only that repository, mr is configured by .mrconfig files, which list the repositories. It starts by reading the .mrconfig file in your home directory, and this can in turn chain load .mrconfig files from repositories. It also automatically looks for a .mrconfig file in the current directory, or in one of its parent directories. These predefined commands should be fairly familiar to users of any revision control system: checkout (or co) Checks out any repositories that are not already checked out. update Updates each repository from its configured remote repository. If a repository isn't checked out yet, it will first check it out. status Displays a status report for each repository, showing what uncommitted changes are present in the repository. commit (or ci) Commits changes to each repository. (By default, changes are pushed to the remote repository too, when using distributed systems like git. If you don't like this default, you can change it in your .mrconfig, or use record instead.) The optional -m parameter allows specifying a commit message. record Records changes to the local repository, but does not push them to the remote repository. Only supported for distributed revision control systems. The optional -m parameter allows specifying a commit message. push Pushes committed local changes to the remote repository. A no-op for centralized revision control systems. diff Show a diff of uncommitted changes. log Show the commit log. run command [param ...] Runs the specified command in each repository. These commands are also available: bootstrap url [directory] Causes mr to download the url, and use it as a .mrconfig file to checkout the repositories listed in it, into the specified directory. The directory will be created if it does not exist. If no directory is specified, the current directory will be used. If the .mrconfig file includes a repository named \".\", that is checked out into the top of the specified directory. list (or ls) List the repositories that mr will act on. register Register an existing repository in a mrconfig file. By default, the repository in the current directory is registered, or you can specify a directory to register. The mrconfig file that is modified is chosen by either the -c option, or by looking for the closest known one at or in a parent of the current directory. config Adds, modifies, removes, or prints a value from a mrconfig file. The next parameter is the name of the section the value is in. To add or modify values, use one or more instances of \"parameter=value\". Use \"parameter=\" to remove a parameter. Use just \"parameter\" to get the value of a parameter. For example, to add (or edit) a repository in src\/foo: mr config src\/foo checkout=\"svn co svn:\/\/example.com\/foo\/trunk foo\" To show the command that mr uses to update the repository in src\/foo: mr config src\/foo update To see the built-in library of shell functions contained in mr: mr config DEFAULT lib The mrconfig file that is used is chosen by either the -c option, or by looking for the closest known one at or in a parent of the current directory. offline Advises mr that it is in offline mode. Any commands that fail in offline mode will be remembered, and retried when mr is told it's online. online Advices mr that it is in online mode again. Commands that failed while in offline mode will be re-run. remember Remember a command, to be run later when mr re-enters online mode. This implicitly puts mr into offline mode. The command can be any regular mr command. This is useful when you know that a command will fail due to being offline, and so don't want to run it right now at all, but just remember to run it when you go back online. help Displays this help. Actions can be abbreviated to any unambiguous substring, so \"mr st\" is equivalent to \"mr status\", and \"mr up\" is equivalent to \"mr update\" Additional parameters can be passed to most commands, and are passed on unchanged to the underlying revision control system. This is mostly useful if the repositories mr will act on all use the same revision control system.","Process Name":"mr","Link":"https:\/\/linux.die.net\/man\/1\/mr"}},{"Process":{"Description":null,"Process Name":"mrancid","Link":"https:\/\/linux.die.net\/man\/1\/mrancid"}},{"Process":{"Description":"The mrd command is used to remove an MS-DOS subdirectory. Its syntax is: mrd [-v] msdosdirectory [ msdosdirectories... ] Mrd removes a directory from an MS-DOS filesystem. An error occurs if the directory does not exist or is not empty.","Process Name":"mrd","Link":"https:\/\/linux.die.net\/man\/1\/mrd"}},{"Process":{"Description":null,"Process Name":"mren","Link":"https:\/\/linux.die.net\/man\/1\/mren"}},{"Process":{"Description":null,"Process Name":"mrf","Link":"https:\/\/linux.die.net\/man\/1\/mrf"}},{"Process":{"Description":"This program is part of Netpbm(1). mrftopbm converts an MRF image to PBM format. mrftopbm takes the MRF image from the file named by the input.mrf argument, or Standard Input if you don't specify input.mrf. The output goes to Standard Output. For more information about mrf, see theMRF specification (1).","Process Name":"mrftopbm","Link":"https:\/\/linux.die.net\/man\/1\/mrftopbm"}},{"Process":{"Description":null,"Process Name":"mrtg","Link":"https:\/\/linux.die.net\/man\/1\/mrtg"}},{"Process":{"Description":"If you have written an extension to mrtg or created a bug fix, please consider contributing it to the project. As I get quite a number of contributions every week, here are a few guidelines which explain how to contribute so that I can use the contribution without too much additional work. Translations MRTG messages have been translated to a number of languages but there are still many which have not been covered yet. If you want to add yours, go into the mrtg-2.16.2\/translate directory and follow the instructions given in the README file. Patches When you have created your modification or extension to mrtg and want to submit it to me, please crate a patch for the files which you have modified. Do not send entire files unless they are new. To create a patch, get hold of a copy of GNU diff (Many Unix systems will have this installed already. In the NT world you might want to get http:\/\/sources.redhat.com\/cygwin\/ to get all the nice GNU tools available.) and type diff --unified --ignore-space-change old-file new-file > simple.patch or if you have modified several files do diff --recursive --unified --ignore-space-change old-dir\/ new-dir\/ >long.patch Documentation All documentation of mrtg is done with the perl POD system. If you want to learn about it, type perldoc perlpod and read the instructions. If you have bugfixes or additions to the existing documents, make sure you modify the POD files and not the html or txt versions. I take documentation very seriously. Whenever you create a new feature for mrtg which you want to get included in the official release, your patch must also contain modifications for the relevant pod file in the doc tree or for the documentation sections of cfgmaker and indexmaker.","Process Name":"mrtg-contrib","Link":"https:\/\/linux.die.net\/man\/1\/mrtg-contrib"}},{"Process":{"Description":null,"Process Name":"mrtg-faq","Link":"https:\/\/linux.die.net\/man\/1\/mrtg-faq"}},{"Process":{"Description":"","Process Name":"mrtg-forum","Link":"https:\/\/linux.die.net\/man\/1\/mrtg-forum"}},{"Process":{"Description":null,"Process Name":"mrtg-ipv6","Link":"https:\/\/linux.die.net\/man\/1\/mrtg-ipv6"}},{"Process":{"Description":"","Process Name":"mrtg-logfile","Link":"https:\/\/linux.die.net\/man\/1\/mrtg-logfile"}},{"Process":{"Description":null,"Process Name":"mrtg-mibhelp","Link":"https:\/\/linux.die.net\/man\/1\/mrtg-mibhelp"}},{"Process":{"Description":null,"Process Name":"mrtg-nt-guide","Link":"https:\/\/linux.die.net\/man\/1\/mrtg-nt-guide"}},{"Process":{"Description":"","Process Name":"mrtg-nw-guide","Link":"https:\/\/linux.die.net\/man\/1\/mrtg-nw-guide"}},{"Process":{"Description":"","Process Name":"mrtg-reference","Link":"https:\/\/linux.die.net\/man\/1\/mrtg-reference"}},{"Process":{"Description":null,"Process Name":"mrtg-rrd","Link":"https:\/\/linux.die.net\/man\/1\/mrtg-rrd"}},{"Process":{"Description":"Squid 2.3 knows SNMP and you can therefore use mrtg to monitor it quite easily. I have made some modifications to mrtg which simplify this. My work is based on earlier modification made by: matija.grabnar@arnes.si and kostas@nlanr.net.","Process Name":"mrtg-squid","Link":"https:\/\/linux.die.net\/man\/1\/mrtg-squid"}},{"Process":{"Description":null,"Process Name":"mrtg-unix-guide","Link":"https:\/\/linux.die.net\/man\/1\/mrtg-unix-guide"}},{"Process":{"Description":null,"Process Name":"mrtg-webserver","Link":"https:\/\/linux.die.net\/man\/1\/mrtg-webserver"}},{"Process":{"Description":"mrtg2pcp is intended to read an MRTG log file as created by mrtg(1) and translate this into a Performance Co-Pilot ( PCP ) archive with the basename outfile. The hostname, devname, and timezone arguments specify information about the system for which the statistics were gathered. The resultant PCP achive may be used with all the PCP client tools to graph subsets of the data using pmchart(1), perform data reduction and reporting, filter with the PCP inference engine pmie(1), etc. A series of physical files will be created with the prefix outfile. These are outfile.0 (the performance data), outfile.meta (the metadata that describes the performance data) and outfile.index (a temporal index to improve efficiency of replay operations for the archive). If any of these files exists already, then mrtg2pcp will not overwrite them and will exit with an error message of the form __pmLogNewFile: \"blah.0\" already exists, not over-written mrtg2pcp is a Perl script that uses the PCP::LogImport Perl wrapper around the PCP libpcp_import library, and as such could be used as an example to develop new tools to import other types of performance data and create PCP archives.","Process Name":"mrtg2pcp","Link":"https:\/\/linux.die.net\/man\/1\/mrtg2pcp"}},{"Process":{"Description":null,"Process Name":"mrtglib","Link":"https:\/\/linux.die.net\/man\/1\/mrtglib"}},{"Process":{"Description":"clogin is an expect(1) script to automate the process of logging into a Cisco router, catalyst switch, Extreme switch, Juniper ERX\/E-series, Procket Networks, or Redback router. There are complementary scripts for Alteon, Avocent (Cyclades), Bay Networks (nortel), ADC-kentrox EZ-T3 mux, Foundry, HP Procurve Switches and Cisco AGMs, Hitachi Routers, Juniper Networks, MRV optical switch, Netscreen firewalls, Netscaler, Riverstone, Netopia, and Lucent TNT, named alogin, avologin, blogin, elogin, flogin, fnlogin, hlogin, htlogin, jlogin, mrvlogin, nlogin, nslogin, rivlogin, tlogin, and tntlogin, respectively. clogin reads the .cloginrc file for its configuration, then connects and logs into each of the routers specified on the command line in the order listed. Command-line options exist to override some of the directives found in the .cloginrc configuration file. The command-line options are as follows: -S Save the configuration on exit, if the device prompts at logout time. This only has affect when used with -s. -V Prints package name and version strings. -c Command to be run on each router list on the command-line. Multiple commands maybe listed by separating them with semi-colons (;). The argument should be quoted to avoid shell expansion. -d Enable expect debugging. -E Specifies a variable to pass through to scripts (-s). For example, the command-line option -Efoo=bar will produce a global variable by the name Efoo with the initial value \"bar\". -e Specify a password to be supplied when gaining enable privileges on the router(s). Also see the password directive of the .cloginrc file. -f Specifies an alternate configuration file. The default is $HOME\/.cloginrc. -p Specifies a password associated with the user specified by the -u option, user directive of the .cloginrc file, or the Unix username of the user. -s The filename of an expect(1) script which will be sourced after the login is successful and is expected to return control to clogin, with the connection to the router intact, when it is done. Note that clogin disables log_user of expect(1)when -s is used. Example script(s) can be found in share\/rancid\/*.exp. -t Alters the timeout interval; the period that clogin waits for an individual command to return a prompt or the login process to produce a prompt or failure. The argument is in seconds. -u Specifies the username used when prompted. The command-line option overrides any user directive found in .cloginrc. The default is the current Unix username. -v Specifies a vty password, that which is prompted for upon connection to the router. This overrides the vty password of the .cloginrc file's password directive. -w Specifies the username used if prompted when gaining enable privileges. The command-line option overrides any user or enauser directives found in .cloginrc. The default is the current Unix username. -x Similar to the -c option; -x specifies a file with commands to run on each of the routers. The commands must not expect additional input, such as 'copy rcp startup-config' does. For example: show version\nshow logging -y Specifies the encryption algorithm for use with the ssh(1) -c option. The default encryption type is often not supported. See the ssh(1) man page for details. The default is 3des.","Process Name":"mrvlogin","Link":"https:\/\/linux.die.net\/man\/1\/mrvlogin"}},{"Process":{"Description":null,"Process Name":"mrvrancid","Link":"https:\/\/linux.die.net\/man\/1\/mrvrancid"}},{"Process":{"Description":null,"Process Name":"mrxvt","Link":"https:\/\/linux.die.net\/man\/1\/mrxvt"}},{"Process":{"Description":"ms-sys is for writing Microsoft compatible boot records.","Process Name":"ms-sys","Link":"https:\/\/linux.die.net\/man\/1\/ms-sys"}},{"Process":{"Description":"ms_print takes an output file produced by the Valgrind tool Massif and prints the information in an easy-to-read form.","Process Name":"ms_print","Link":"https:\/\/linux.die.net\/man\/1\/ms_print"}},{"Process":{"Description":"Filters the messages of a translation catalog according to their attributes, and manipulates the attributes. Mandatory arguments to long options are mandatory for short options too. Input file location: INPUTFILE input PO file -D, --directory= DIRECTORY add DIRECTORY to list for input files search If no input file is given or if it is -, standard input is read. Output file location: -o, --output-file= FILE write output to specified file The results are written to standard output if no output file is specified or if it is -. Message selection: --translated keep translated, remove untranslated messages --untranslated keep untranslated, remove translated messages --no-fuzzy remove 'fuzzy' marked messages --only-fuzzy keep 'fuzzy' marked messages --no-obsolete remove obsolete #~ messages --only-obsolete keep obsolete #~ messages Attribute manipulation: --set-fuzzy set all messages 'fuzzy' --clear-fuzzy set all messages non-'fuzzy' --set-obsolete set all messages obsolete --clear-obsolete set all messages non-obsolete --clear-previous remove the \"previous msgid\" from all messages --only-file= FILE.po manipulate only entries listed in FILE.po --ignore-file= FILE.po manipulate only entries not listed in FILE.po --fuzzy synonym for --only-fuzzy --clear-fuzzy --obsolete synonym for --only-obsolete --clear-obsolete Input file syntax: -P, --properties-input input file is in Java .properties syntax --stringtable-input input file is in NeXTstep\/GNUstep .strings syntax Output details: -e, --no-escape do not use C escapes in output (default) -E, --escape use C escapes in output, no extended chars --force-po write PO file even if empty -i, --indent write the .po file using indented style --no-location do not write '#: filename:line' lines -n, --add-location generate '#: filename:line' lines (default) --strict write out strict Uniforum conforming .po file -p, --properties-output write out a Java .properties file --stringtable-output write out a NeXTstep\/GNUstep .strings file -w, --width= NUMBER set output page width --no-wrap do not break long message lines, longer than the output page width, into several lines -s, --sort-output generate sorted output -F, --sort-by-file sort output by file location Informative output: -h, --help display this help and exit -V, --version output version information and exit","Process Name":"msgattrib","Link":"https:\/\/linux.die.net\/man\/1\/msgattrib"}},{"Process":{"Description":null,"Process Name":"msgcat","Link":"https:\/\/linux.die.net\/man\/1\/msgcat"}},{"Process":{"Description":"Compare two Uniforum style .po files to check that both contain the same set of msgid strings. The def.po file is an existing PO file with the translations. The ref.pot file is the last created PO file, or a PO Template file (generally created by xgettext). This is useful for checking that you have translated each and every message in your program. Where an exact match cannot be found, fuzzy matching is used to produce better diagnostics. Mandatory arguments to long options are mandatory for short options too. Input file location: def.po translations ref.pot references to the sources -D, --directory= DIRECTORY add DIRECTORY to list for input files search Operation modifiers: -m, --multi-domain apply ref.pot to each of the domains in def.po --use-fuzzy consider fuzzy entries --use-untranslated consider untranslated entries Input file syntax: -P, --properties-input input files are in Java .properties syntax --stringtable-input input files are in NeXTstep\/GNUstep .strings syntax Informative output: -h, --help display this help and exit -V, --version output version information and exit","Process Name":"msgcmp","Link":"https:\/\/linux.die.net\/man\/1\/msgcmp"}},{"Process":{"Description":null,"Process Name":"msgcomm","Link":"https:\/\/linux.die.net\/man\/1\/msgcomm"}},{"Process":{"Description":"Converts a translation catalog to a different character encoding. Mandatory arguments to long options are mandatory for short options too. Input file location: INPUTFILE input PO file -D, --directory= DIRECTORY add DIRECTORY to list for input files search If no input file is given or if it is -, standard input is read. Output file location: -o, --output-file= FILE write output to specified file The results are written to standard output if no output file is specified or if it is -. Conversion target: -t, --to-code= NAME encoding for output The default encoding is the current locale's encoding. Input file syntax: -P, --properties-input input file is in Java .properties syntax --stringtable-input input file is in NeXTstep\/GNUstep .strings syntax Output details: -e, --no-escape do not use C escapes in output (default) -E, --escape use C escapes in output, no extended chars --force-po write PO file even if empty -i, --indent indented output style --no-location suppress '#: filename:line' lines --add-location preserve '#: filename:line' lines (default) --strict strict Uniforum output style -p, --properties-output write out a Java .properties file --stringtable-output write out a NeXTstep\/GNUstep .strings file -w, --width= NUMBER set output page width --no-wrap do not break long message lines, longer than the output page width, into several lines -s, --sort-output generate sorted output -F, --sort-by-file sort output by file location Informative output: -h, --help display this help and exit -V, --version output version information and exit","Process Name":"msgconv","Link":"https:\/\/linux.die.net\/man\/1\/msgconv"}},{"Process":{"Description":"Creates an English translation catalog. The input file is the last created English PO file, or a PO Template file (generally created by xgettext). Untranslated entries are assigned a translation that is identical to the msgid. Mandatory arguments to long options are mandatory for short options too. Input file location: INPUTFILE input PO or POT file -D, --directory= DIRECTORY add DIRECTORY to list for input files search If input file is -, standard input is read. Output file location: -o, --output-file= FILE write output to specified file The results are written to standard output if no output file is specified or if it is -. Input file syntax: -P, --properties-input input file is in Java .properties syntax --stringtable-input input file is in NeXTstep\/GNUstep .strings syntax Output details: -e, --no-escape do not use C escapes in output (default) -E, --escape use C escapes in output, no extended chars --force-po write PO file even if empty -i, --indent indented output style --no-location suppress '#: filename:line' lines --add-location preserve '#: filename:line' lines (default) --strict strict Uniforum output style -p, --properties-output write out a Java .properties file --stringtable-output write out a NeXTstep\/GNUstep .strings file -w, --width= NUMBER set output page width --no-wrap do not break long message lines, longer than the output page width, into several lines -s, --sort-output generate sorted output -F, --sort-by-file sort output by file location Informative output: -h, --help display this help and exit -V, --version output version information and exit","Process Name":"msgen","Link":"https:\/\/linux.die.net\/man\/1\/msgen"}},{"Process":{"Description":null,"Process Name":"msgexec","Link":"https:\/\/linux.die.net\/man\/1\/msgexec"}},{"Process":{"Description":"Applies a filter to all translations of a translation catalog. Mandatory arguments to long options are mandatory for short options too. Input file location: -i, --input= INPUTFILE input PO file -D, --directory= DIRECTORY add DIRECTORY to list for input files search If no input file is given or if it is -, standard input is read. Output file location: -o, --output-file= FILE write output to specified file The results are written to standard output if no output file is specified or if it is -. The FILTER can be any program that reads a translation from standard input and writes a modified translation to standard output. Useful FILTER-OPTIONs when the FILTER is 'sed': -e, --expression= SCRIPT add SCRIPT to the commands to be executed -f, --file= SCRIPTFILE add the contents of SCRIPTFILE to the commands to be executed -n, --quiet, --silent suppress automatic printing of pattern space Input file syntax: -P, --properties-input input file is in Java .properties syntax --stringtable-input input file is in NeXTstep\/GNUstep .strings syntax Output details: --no-escape do not use C escapes in output (default) -E, --escape use C escapes in output, no extended chars --force-po write PO file even if empty --indent indented output style --keep-header keep header entry unmodified, don't filter it --no-location suppress '#: filename:line' lines --add-location preserve '#: filename:line' lines (default) --strict strict Uniforum output style -p, --properties-output write out a Java .properties file --stringtable-output write out a NeXTstep\/GNUstep .strings file -w, --width= NUMBER set output page width --no-wrap do not break long message lines, longer than the output page width, into several lines -s, --sort-output generate sorted output -F, --sort-by-file sort output by file location Informative output: -h, --help display this help and exit -V, --version output version information and exit","Process Name":"msgfilter","Link":"https:\/\/linux.die.net\/man\/1\/msgfilter"}},{"Process":{"Description":null,"Process Name":"msgfmt","Link":"https:\/\/linux.die.net\/man\/1\/msgfmt"}},{"Process":{"Description":"Extracts all messages of a translation catalog that match a given pattern or belong to some given source files. Mandatory arguments to long options are mandatory for short options too. Input file location: INPUTFILE input PO file -D, --directory= DIRECTORY add DIRECTORY to list for input files search If no input file is given or if it is -, standard input is read. Output file location: -o, --output-file= FILE write output to specified file The results are written to standard output if no output file is specified or if it is -. Message selection: [-N SOURCEFILE]... [-M DOMAINNAME]... [-J MSGCTXT-PATTERN] [-K MSGID-PATTERN] [-T MSGSTR-PATTERN] [-C COMMENT-PATTERN] [-X EXTRACTED-COMMENT-PATTERN] A message is selected if it comes from one of the specified source files, or if it comes from one of the specified domains, or if -J is given and its context (msgctxt) matches MSGCTXT-PATTERN, or if -K is given and its key (msgid or msgid_plural) matches MSGID-PATTERN, or if -T is given and its translation (msgstr) matches MSGSTR-PATTERN, or if -C is given and the translator's comment matches COMMENT-PATTERN, or if -X is given and the extracted comment matches EXTRACTED-COMMENT-PATTERN. When more than one selection criterion is specified, the set of selected messages is the union of the selected messages of each criterion. MSGCTXT-PATTERN or MSGID-PATTERN or MSGSTR-PATTERN or COMMENT-PATTERN or EXTRACTED-COMMENT-PATTERN syntax: [-E | -F] [-e PATTERN | -f FILE]... PATTERNs are basic regular expressions by default, or extended regular expressions if -E is given, or fixed strings if -F is given. -N, --location= SOURCEFILE select messages extracted from SOURCEFILE -M, --domain= DOMAINNAME select messages belonging to domain DOMAINNAME -J, --msgctxt start of patterns for the msgctxt -K, --msgid start of patterns for the msgid -T, --msgstr start of patterns for the msgstr -C, --comment start of patterns for the translator's comment -X, --extracted-comment start of patterns for the extracted comment -E, --extended-regexp PATTERN is an extended regular expression -F, --fixed-strings PATTERN is a set of newline-separated strings -e, --regexp= PATTERN use PATTERN as a regular expression -f, --file= FILE obtain PATTERN from FILE -i, --ignore-case ignore case distinctions -v, --invert-match output only the messages that do not match any selection criterion Input file syntax: -P, --properties-input input file is in Java .properties syntax --stringtable-input input file is in NeXTstep\/GNUstep .strings syntax Output details: --no-escape do not use C escapes in output (default) --escape use C escapes in output, no extended chars --force-po write PO file even if empty --indent indented output style --no-location suppress '#: filename:line' lines --add-location preserve '#: filename:line' lines (default) --strict strict Uniforum output style -p, --properties-output write out a Java .properties file --stringtable-output write out a NeXTstep\/GNUstep .strings file -w, --width= NUMBER set output page width --no-wrap do not break long message lines, longer than the output page width, into several lines --sort-output generate sorted output --sort-by-file sort output by file location Informative output: -h, --help display this help and exit -V, --version output version information and exit","Process Name":"msggrep","Link":"https:\/\/linux.die.net\/man\/1\/msggrep"}},{"Process":{"Description":null,"Process Name":"msginit","Link":"https:\/\/linux.die.net\/man\/1\/msginit"}},{"Process":{"Description":"Merges two Uniforum style .po files together. The def.po file is an existing PO file with translations which will be taken over to the newly created file as long as they still match; comments will be preserved, but extracted comments and file positions will be discarded. The ref.pot file is the last created PO file with up-to-date source references but old translations, or a PO Template file (generally created by xgettext); any translations or comments in the file will be discarded, however dot comments and file positions will be preserved. Where an exact match cannot be found, fuzzy matching is used to produce better results. Mandatory arguments to long options are mandatory for short options too. Input file location: def.po translations referring to old sources ref.pot references to new sources -D, --directory= DIRECTORY add DIRECTORY to list for input files search -C, --compendium= FILE additional library of message translations, may be specified more than once Operation mode: -U, --update update def.po, do nothing if def.po already up to date Output file location: -o, --output-file= FILE write output to specified file The results are written to standard output if no output file is specified or if it is -. Output file location in update mode: The result is written back to def.po. --backup= CONTROL make a backup of def.po --suffix= SUFFIX override the usual backup suffix The version control method may be selected via the --backup option or through the VERSION_CONTROL environment variable. Here are the values: none, off never make backups (even if --backup is given) numbered, t make numbered backups existing, nil numbered if numbered backups exist, simple otherwise simple, never always make simple backups The backup suffix is '~', unless set with --suffix or the SIMPLE_BACKUP_SUFFIX environment variable. Operation modifiers: -m, --multi-domain apply ref.pot to each of the domains in def.po -N, --no-fuzzy-matching do not use fuzzy matching --previous keep previous msgids of translated messages Input file syntax: -P, --properties-input input files are in Java .properties syntax --stringtable-input input files are in NeXTstep\/GNUstep .strings syntax Output details: -e, --no-escape do not use C escapes in output (default) -E, --escape use C escapes in output, no extended chars --force-po write PO file even if empty -i, --indent indented output style --no-location suppress '#: filename:line' lines --add-location preserve '#: filename:line' lines (default) --strict strict Uniforum output style -p, --properties-output write out a Java .properties file --stringtable-output write out a NeXTstep\/GNUstep .strings file -w, --width= NUMBER set output page width --no-wrap do not break long message lines, longer than the output page width, into several lines -s, --sort-output generate sorted output -F, --sort-by-file sort output by file location Informative output: -h, --help display this help and exit -V, --version output version information and exit -v, --verbose increase verbosity level -q, --quiet, --silent suppress progress indicators","Process Name":"msgmerge","Link":"https:\/\/linux.die.net\/man\/1\/msgmerge"}},{"Process":{"Description":"Convert binary message catalog to Uniforum style .po file. Mandatory arguments to long options are mandatory for short options too. Operation mode: -j, --java Java mode: input is a Java ResourceBundle class --csharp C# mode: input is a .NET .dll file --csharp-resources C# resources mode: input is a .NET .resources file --tcl Tcl mode: input is a tcl\/msgcat .msg file Input file location: FILE ... input .mo files If no input file is given or if it is -, standard input is read. Input file location in Java mode: -r, --resource= RESOURCE resource name -l, --locale= LOCALE locale name, either language or language_COUNTRY The class name is determined by appending the locale name to the resource name, separated with an underscore. The class is located using the CLASSPATH. Input file location in C# mode: -r, --resource= RESOURCE resource name -l, --locale= LOCALE locale name, either language or language_COUNTRY -d DIRECTORY base directory for locale dependent .dll files The -l and -d options are mandatory. The .dll file is located in a subdirectory of the specified directory whose name depends on the locale. Input file location in Tcl mode: -l, --locale= LOCALE locale name, either language or language_COUNTRY -d DIRECTORY base directory of .msg message catalogs The -l and -d options are mandatory. The .msg file is located in the specified directory. Output file location: -o, --output-file= FILE write output to specified file The results are written to standard output if no output file is specified or if it is -. Output details: -e, --no-escape do not use C escapes in output (default) -E, --escape use C escapes in output, no extended chars --force-po write PO file even if empty -i, --indent write indented output style --strict write strict uniforum style -p, --properties-output write out a Java .properties file --stringtable-output write out a NeXTstep\/GNUstep .strings file -w, --width= NUMBER set output page width --no-wrap do not break long message lines, longer than the output page width, into several lines -s, --sort-output generate sorted output Informative output: -h, --help display this help and exit -V, --version output version information and exit -v, --verbose increase verbosity level","Process Name":"msgunfmt","Link":"https:\/\/linux.die.net\/man\/1\/msgunfmt"}},{"Process":{"Description":null,"Process Name":"msguniq","Link":"https:\/\/linux.die.net\/man\/1\/msguniq"}},{"Process":{"Description":null,"Process Name":"msguntypot","Link":"https:\/\/linux.die.net\/man\/1\/msguntypot"}},{"Process":{"Description":"The mshowfat command is used to display the FAT entries for a file. Syntax: $ mshowfat files","Process Name":"mshowfat","Link":"https:\/\/linux.die.net\/man\/1\/mshowfat"}},{"Process":{"Description":null,"Process Name":"msie_parse","Link":"https:\/\/linux.die.net\/man\/1\/msie_parse"}},{"Process":{"Description":"msiexec is the Wine MSI installer, which is command line compatible with its Microsoft Windows counterpart.","Process Name":"msiexec","Link":"https:\/\/linux.die.net\/man\/1\/msiexec"}},{"Process":{"Description":null,"Process Name":"msktutil","Link":"https:\/\/linux.die.net\/man\/1\/msktutil"}},{"Process":{"Description":null,"Process Name":"msort","Link":"https:\/\/linux.die.net\/man\/1\/msort"}},{"Process":{"Description":null,"Process Name":"msql2mysql","Link":"https:\/\/linux.die.net\/man\/1\/msql2mysql"}},{"Process":{"Description":null,"Process Name":"mstar","Link":"https:\/\/linux.die.net\/man\/1\/mstar"}},{"Process":{"Description":"This manual page documents the tape control program mt. mt performs the given operation, which must be one of the tape operations listed below, on a tape drive. The commands can also be listed by running the program with the -h option. The version of mt is printed with the -v or --version option. The path of the tape device on which to operate can be given with the -f or -t option. If neither of those options is given, and the environment variable TAPE is set, it is used. Otherwise, a default device defined in the file \/usr\/include\/sys\/mtio.h is used. Some operations optionally take an argument or repeat count, which can be given after the operation name and defaults to 1. The postfix k , M , or G can be used to give counts in units of 1024, 1024 * 1024, or 1024 * 1024 * 1024, respectively. The available operations are listed below. Unique abbreviations are accepted. Not all operations are available on all systems, or work on all types of tape drives. fsf Forward space count files. The tape is positioned on the first block of the next file. fsfm Forward space past count file marks, then backward space one file record. This leaves the tape positioned on the last block of the file that is count-1 files past the current file. bsf Backward space count files. The tape is positioned on the last block of the previous file. bsfm Backward space past count file marks, then forward space one file record. This leaves the tape positioned on the first block of the file that is count-1 files before the current file. asf The tape is positioned at the beginning of the count file. Positioning is done by first rewinding the tape and then spacing forward over count filemarks. fsr Forward space count records. bsr Backward space count records. fss (SCSI tapes) Forward space count setmarks. bss (SCSI tapes) Backward space count setmarks. eod, seod Space to end of valid data. Used on streamer tape drives to append data to the logical end of tape. rewind Rewind the tape. offline, rewoffl, eject Rewind the tape and, if applicable, unload the tape. retension Rewind the tape, then wind it to the end of the reel, then rewind it again. weof, eof Write count EOF marks at current position. wset (SCSI tapes) Write count setmarks at current position (only SCSI tape). erase Erase the tape. status Print status information about the tape unit. (If the density code is \"no translation\" in the status output, this does not affect working of the tape drive.) seek (SCSI tapes) Seek to the count block on the tape. This operation is available on some Tandberg and Wangtek streamers and some SCSI-2 tape drives. The block address should be obtained from a tell call earlier. tell (SCSI tapes) Tell the current block on tape. This operation is available on some Tandberg and Wangtek streamers and some SCSI-2 tape drives. setpartition (SCSI tapes) Switch to the partition determined by count. The default data partition of the tape is numbered zero. Switching partition is available only if enabled for the device, the device supports multiple partitions, and the tape is formatted with multiple partitions. partseek (SCSI tapes) The tape position is set to block count in the partition given by the argument after count. The default partition is zero. mkpartition (SCSI tapes) Format the tape with one (count is zero) or two partitions (count gives the size of the second partition in megabytes). The tape drive must be able to format partitioned tapes with initiator-specified partition size and partition support must be enabled for the drive. load (SCSI tapes) Send the load command to the tape drive. The drives usually load the tape when a new cartridge is inserted. The argument count can usually be omitted. Some HP changers load tape n if the count 10000 + n is given (a special funtion in the Linux st driver). lock (SCSI tapes) Lock the tape drive door. unlock (SCSI tapes) Unlock the tape drive door. setblk (SCSI tapes) Set the block size of the drive to count bytes per record. setdensity (SCSI tapes) Set the tape density code to count. The proper codes to use with each drive should be looked up from the drive documentation. densities (SCSI tapes) Write explanation of some common density codes to standard output. drvbuffer (SCSI tapes) Set the tape drive buffer code to number. The proper value for unbuffered operation is zero and \"normal\" buffered operation one. The meanings of other values can be found in the drive documentation or, in the case of a SCSI-2 drive, from the SCSI-2 standard. compression (SCSI tapes) The compression within the drive can be switched on or off using the MTCOMPRESSION ioctl. Note that this method is not supported by all drives implementing compression. For instance, the Exabyte 8 mm drives use density codes to select compression. stoptions (SCSI tapes) Set the driver options bits for the device to the defined values. Allowed only for the superuser. The bits can be set either by ORing the option bits from the file \/usr\/include\/linux\/mtio.h to count, or by using the following keywords (as many keywords can be used on the same line as necessary, unambiguous abbreviations allowed): buffer-writes buffered writes enabled async-writes asynchronous writes enabled read-ahead read-ahead for fixed block size debug debugging (if compiled into driver) two-fms write two filemarks when file closed fast-eod space directly to eod (and lose file number) no-wait don't wait until rewind, etc. complete auto-lock automatically lock\/unlock drive door def-writes the block size and density are for writes can-bsr drive can space backwards as well no-blklimits drive doesn't support read block limits can-partitions drive can handle partitioned tapes scsi2logical seek and tell use SCSI-2 logical block addresses instead of device dependent addresses sili Set the SILI bit is when reading in variable block mode. This may speed up reading blocks shorter than the read byte count. Set this option only if you know that the drive supports SILI and the HBA reliably returns transfer residual byte counts. Requires kernel version >= 2.6.26. sysv enable the System V semantics stsetoptions (SCSI tapes) Set selected driver options bits. The methods to specify the bits to set are given above in the description of stoptions. Allowed only for the superuser. stclearoptions (SCSI tapes) Clear selected driver option bits. The methods to specify the bits to clear are given above in description of stoptions. Allowed only for the superuser. stshowoptions (SCSI tapes) Print the currently enabled options for the device. Requires kernel version >= 2.6.26 and sysfs must be mounted at \/sys. stwrthreshold (SCSI tapes) The write threshold for the tape device is set to count kilobytes. The value must be smaller than or equal to the driver buffer size. Allowed only for the superuser. defblksize (SCSI tapes) Set the default block size of the device to count bytes. The value -1 disables the default block size. The block size set by setblk overrides the default until a new tape is inserted. Allowed only for the superuser. defdensity (SCSI tapes) Set the default density code. The value -1 disables the default density. The density set by setdensity overrides the default until a new tape is inserted. Allowed only for the superuser. defdrvbuffer (SCSI tapes) Set the default drive buffer code. The value -1 disables the default drive buffer code. The drive buffer code set by drvbuffer overrides the default until a new tape is inserted. Allowed only for the superuser. defcompression (SCSI tapes) Set the default compression state. The value -1 disables the default compression. The compression state set by compression overrides the default until a new tape is inserted. Allowed only for the superuser. sttimeout sets the normal timeout for the device. The value is given in seconds. Allowed only for the superuser. stlongtimeout sets the long timeout for the device. The value is given in seconds. Allowed only for the superuser. stsetcln set the cleaning request interpretation parameters. mt exits with a status of 0 if the operation succeeded, 1 if the operation or device name given was invalid, or 2 if the operation failed.","Process Name":"mt","Link":"https:\/\/linux.die.net\/man\/1\/mt"}},{"Process":{"Description":"mtbatch -v number set log level for stderr logging -b host defines the host of bearerbox (default: localhost) -p port the smsbox port to connect to (default: 13002) -s inidicatr to use SSL for bearerbox connection (default: no) -i smsbox-id defines the smsbox-id to be used for bearerbox connection (default: none) -f sender which sender address should be used -n service defines which service name should be logged (default: none) -a account defines which account name should be logged (default: none) -d seconds delay between message sending to bearerbox (default: 0) -r smsc-id use a specific route for the MT traffic","Process Name":"mtbatch","Link":"https:\/\/linux.die.net\/man\/1\/mtbatch"}},{"Process":{"Description":null,"Process Name":"mtn","Link":"https:\/\/linux.die.net\/man\/1\/mtn"}},{"Process":{"Description":"mtn-cleanup returns a workspace to its pristine state with the minimum of change; missing files are restored, changed files are reverted and new files are removed.","Process Name":"mtn-cleanup","Link":"https:\/\/linux.die.net\/man\/1\/mtn-cleanup"}},{"Process":{"Description":null,"Process Name":"mtnopt","Link":"https:\/\/linux.die.net\/man\/1\/mtnopt"}},{"Process":{"Description":null,"Process Name":"mtools","Link":"https:\/\/linux.die.net\/man\/1\/mtools"}},{"Process":{"Description":"The mtoolstest command is used to tests the mtools configuration files. To invoke it, just type mtoolstest without any arguments. Mtoolstest reads the mtools configuration files, and prints the cumulative configuration to stdout. The output can be used as a configuration file itself (although you might want to remove redundant clauses). You may use this program to convert old-style configuration files into new style configuration files.","Process Name":"mtoolstest","Link":"https:\/\/linux.die.net\/man\/1\/mtoolstest"}},{"Process":{"Description":"Shows the MySQL commands consuming the greatest time. By default, only non-sleeping threads are shown, the --idle option shows idle threads. While running several keys will affect the operation of mtop. Hitting h or ? will show the available options. Normally, run as a console program this will allow you to see errant or badly optimized queries as they will stay on the screen for a while. However, if you are hunting for short lived queries, running in the manualrefresh mode with a short refresh time will allow you to catch short lived queries as well. The following keys are active while mtop is running: q - quit\n? - help\n\nFiltering\/display\n\ns - change the number of seconds to delay between updates\nm - toggle manual refresh mode on\/off\nd - filter display with regular expression (user\/host\/db\/command\/state\/info)\nF - fold\/unfold column names in select statement display\nh - display process for only one host\nu - display process for only one user\ni - toggle all\/non-Sleeping process display\no - reverse the sort order\n\nControl\/Detail\n\nk - kill processes; send a kill to a list of ids\ne - explain a process; show query optimizer info\nz - zoom in on a process; show sql statement detail\nf - flush stats (reset show status variables)\nt - show mysqld stats (show status\/mysqladmin ext)\nT - show short\/important status\nv - show mysqld variables (show variables\/mysqladmin vars)\nr - show replication status for master\/slaves Main Screen The main query screen shows the following information as well as the currently active queries (explanations are from the MySQL online manual and references refer to the section in the manual where the explanation came from): n Threads: running, cached The n Threads represents how many threads the mysqld has allocated. One thread is allocated for each user connection. Additional threads are allocated for replication. Queries\/slow: Total queries \/ Total SLOW QUERIES The first number is the total number of queries sent to the server since the last 'flush status' or since server start. The second number is the number of queries that have taken more than long_query_time. See section 4.9.5 The Slow Query Log. Cache Hit: Cache hit ratio This is the percentage of times a key read is handled from the key buffer cache. See section 4.5.7.4 SHOW VARIABLES of the MySQL manual for more information. Opened tables: tables opened MySQL has a cache for open tables. If 'opened tables' is high, your cache may be too small. Look at the MySQL manual section: 5.4.7 How MySQL Opens and Closes Tables for further information. RRN: Handler_read_rnd_next Number of requests to read the next row in the datafile. This will be high if you are doing a lot of table scans. Generally this suggests that your tables are not properly indexed or that your queries are not written to take advantage of the indexes you have. (4.5.7.3) TLW: Table_locks_waited Number of times a table lock could not be acquired immediately and a wait was needed. If this is high, and you have performance problems, you should first optimise your queries, and then either split your table(s) or use replication. Available after 3.23.33. (4.5.7.3) SFJ: Select_full_join Number of joins without keys (If this is not 0, you should carefully check the indexes of your tables). (4.5.7.3) SMP: Sort_merge_passes Number of merges passes the sort algoritm have had to do. If this value is large you should consider increasing sort_buffer. (4.5.7.3) QPS: Questions per second The total number of sql commands handled by the MySQL server since startup or the last flush status command. Statistics\/Variables When viewing the stats screen (t), the screen will refresh until a key is pressed at which point you will return to the main screen. The bottom of the stats screen is denoted with a line containing ---. If you do not see that line, resize your screen until you do. The statistics screen has the following format: Stat:      total [avg per sec \/ instant per sec ] For example: Questions:     720,672 [30\/12] The short\/important status screen is a list of recommendations from the MySQL manual. The first number is the total since startup or the last 'flush status'. The second number is the number per second since startup or flush. The last is the number per second since the last screen refresh. The variables screen only shows the information once and returns to the main screen as the variables do not change after server startup. Replication The replication monitor screen looks for a master or slave server running on the currently monitored mysqld. If a master server is found, it then tries to connect to each slave connected to the master. Replication is shown for all masters and slaves found. Offsets from the master for each of the slaves is shown. Note: the offset may be less than zero because the slave position is checked after the master position. The offset shown is the number of queries in the binlog that the slave has to process before being caught up with the master.","Process Name":"mtop","Link":"https:\/\/linux.die.net\/man\/1\/mtop"}},{"Process":{"Description":null,"Process Name":"mtpaint","Link":"https:\/\/linux.die.net\/man\/1\/mtpaint"}},{"Process":{"Description":null,"Process Name":"mtt","Link":"https:\/\/linux.die.net\/man\/1\/mtt"}},{"Process":{"Description":"This program is part of Netpbm(1). mtvtoppm reads an input file from Mark VanDeWettering's MTV ray tracer and produces a PPM image as output. The PRT raytracer also produces this format.","Process Name":"mtvtoppm","Link":"https:\/\/linux.die.net\/man\/1\/mtvtoppm"}},{"Process":{"Description":"The mtx command controls single or multi-drive SCSI media changers such as tape changers, autoloaders, tape libraries, or optical media jukeboxes. It can also be used with media changers that use the 'ATTACHED' API, presuming that they properly report the MChanger bit as required by the SCSI T-10 SMC specification.","Process Name":"mtx","Link":"https:\/\/linux.die.net\/man\/1\/mtx"}},{"Process":{"Description":null,"Process Name":"mtype","Link":"https:\/\/linux.die.net\/man\/1\/mtype"}},{"Process":{"Description":"The program MultiTail lets you view one or multiple files like the original tail program. The difference is that it creates multiple windows on your console (with ncurses). It can also monitor wildcards: if another file matching the wildcard has a more recent modification date, it will automatically switch to that file. That way you can, for example, monitor a complete directory of files. Merging of 2 or even more logfiles is possible. It can also use colors while displaying the logfiles (through regular expressions), for faster recognition of what is important and what not. It can also filter lines (again with regular expressions). It has interactive menus for editing given regular expressions and deleting and adding windows. One can also have windows with the output of shell scripts and other software. When viewing the output of external software, MultiTail can mimic the functionality of tools like 'watch' and such. When new mail arrives for the current user, the statuslines will become green. To reset this \"mail has arrived\"-state, press ' ' (a space). For help at any time, press F1.","Process Name":"multitail","Link":"https:\/\/linux.die.net\/man\/1\/multitail"}},{"Process":{"Description":"Multixterm creates multiple xterms that can be driven together or separately. In its simplest form, multixterm is run with no arguments and commands are interactively entered in the first entry field. Press return (or click the \"new xterm\" button) to create a new xterm running that command. Keystrokes in the \"stdin window\" are redirected to all xterms started by multixterm. xterms may be driven separately simply by focusing on them. The stdin window must have the focus for keystrokes to be sent to the xterms. When it has the focus, the color changes to aquamarine. As characters are entered, the color changes to green for a second. This provides feedback since characters are not echoed in the stdin window. Typing in the stdin window while holding down the alt or meta keys sends an escape character before the typed characters. This provides support for programs such as emacs.","Process Name":"multixterm","Link":"https:\/\/linux.die.net\/man\/1\/multixterm"}},{"Process":{"Description":null,"Process Name":"munch","Link":"https:\/\/linux.die.net\/man\/1\/munch"}},{"Process":{"Description":"mundelete undeletes files with (possibly) relative data from MsDos\/Windows file systems","Process Name":"mundelete","Link":"https:\/\/linux.die.net\/man\/1\/mundelete"}},{"Process":{"Description":null,"Process Name":"munge","Link":"https:\/\/linux.die.net\/man\/1\/munge"}},{"Process":{"Description":"The munilist command reads photometry files and creates the table of magnitudes of selected stars in the dependence on a time. The table is written to a output file in text format. The format of the table depends on given parameters and on the number of selected stars. It is usually the last step of reduction process. The list of stars is given on command line, the stars are identified by index number according to their cross-reference identifiers.","Process Name":"munilist","Link":"https:\/\/linux.die.net\/man\/1\/munilist"}},{"Process":{"Description":null,"Process Name":"munimatch","Link":"https:\/\/linux.die.net\/man\/1\/munimatch"}},{"Process":{"Description":"munin-node is a daemon for reporting statistics on system performance. It doesn't produce these itself, but instead relies on a number of plugins which are responsible for gathering the data they require, and describing how this should be graphed. In fact, it does little more than fielding requests from the Munin master, running the appropriate plugins, and returning the output they produce.","Process Name":"munin-node","Link":"https:\/\/linux.die.net\/man\/1\/munin-node"}},{"Process":{"Description":null,"Process Name":"munin-node-configure","Link":"https:\/\/linux.die.net\/man\/1\/munin-node-configure"}},{"Process":{"Description":"munin-run is a script to run Munin plugins from the command-line. It's useful when debugging plugins, as they are run in the same conditions as they are under munin-node.","Process Name":"munin-run","Link":"https:\/\/linux.die.net\/man\/1\/munin-run"}},{"Process":{"Description":"munin-sched is a daemon for reporting statistics on system performance. It doesn't produce these itself, but instead relies on a number of plugins which are responsible for gathering the data they require, and describing how this should be graphed. In fact, it does little more than fielding requests from the Munin master, running the appropriate plugins, and returning the output they produce.","Process Name":"munin-sched","Link":"https:\/\/linux.die.net\/man\/1\/munin-sched"}},{"Process":{"Description":"This program displays Munin documentation, esp. plugin documentation. Note that not all plugins are documented yet. Most Munin commands (such as munin-run, and munindoc itself) is only documented through the usual Unix man command.","Process Name":"munindoc","Link":"https:\/\/linux.die.net\/man\/1\/munindoc"}},{"Process":{"Description":null,"Process Name":"muniphot","Link":"https:\/\/linux.die.net\/man\/1\/muniphot"}},{"Process":{"Description":"The Muniwin is a program for reduction of images carried out by a CCD camera, aimed at observation of variable stars. It provides a powerful and intuitive graphical user interface based on the excellent GTK+ package. The C-Munipack library is used for reduction and manipulation of CCD frames. The user interface should be familiar for Munidos users, but it takes full advantage of graphical environment and therefore the interface is more comfortable and enables user an improved control over reduction process in comparison with original interface of Munidos. Unlike the previous version 1.1, the Muniwin was completely rewritten to the C\/C++ language using a portable GTK package. Thus, it is compatible with most up-to-date operating systems - GNU\/Linux, Windows 2000 and later, Mac OS X and many others.","Process Name":"muniwin","Link":"https:\/\/linux.die.net\/man\/1\/muniwin"}},{"Process":{"Description":null,"Process Name":"munpack","Link":"https:\/\/linux.die.net\/man\/1\/munpack"}},{"Process":{"Description":"Mup is a program for producing printed music. There is an optional companion program called Mupmate that provides a more graphical user interface on top of Mup, but this manual page describes the command line interface. The Mup User's Guide should be consulted for details of the format of the input file. Options include: -c N Combine consecutive measures of all rests or spaces into multirests (multiple measures of rest printed as a single measure, with the number of measures of rest printed above the staff). Any time there are N or more measures in a row that consist entirely of rests or spaces, they will be replaced by a multirest. The combining of measures stops when there is a visible staff that contains notes, lyrics, or other musical symbols, when there are parameter changes on a visible staff or in score context, or when there is a bar line other than an ordinary or invisible bar. This option is most likely to be useful when printing a subset of staffs, where the particular staff(s) you are printing have long periods of rests. (See the -s option.) -C This option is only used in connection with the -E option. It specifies that comments are to be passed through rather than deleted. -d N Print debugging information. N is a bitmap. parse phase information high level parse phase tracing low level parse phase tracing reserved high level placement phase tracing low level placement phase tracing reserved contents of the main internal list high level print phase tracing low level print phase tracing N can be specified in decimal, octal (by using a leading zero), or hex (by using a leading 0x). This information is intended for debugging of Mup itself and thus is not likely to be of use to the average user. -D MACRO[=macro_def] Define the macro MACRO. The macro name must consist of upper case letters, digits, and underscores, beginning with an upper case letter. The macro_def is optional, and gives the text of the macro. If it contains any white space or other special characters, it must be quoted (if quoting is supported by your operating system or shell). -e errfile Place error messages into errfile instead of writing them to the standard error output stream. -E Rather than produce PostScript or MIDI output, just expand macros and includes, and write the result to the standard output stream. Comments in the input are deleted, unless the -C option is also specified. -f outfile Place the output into outfile instead of writing it to the standard output. -F This is like the -f option, except the name of the output file is derived from the name of the Mup input file. If the name of the Mup input file ends with a \".mup\" suffix, the generated PostScript output file will end with a \".ps\" suffix instead. If the name of the Mup input file ends with a \".MUP\" suffix, the PostScript file will end with a \".PS\" suffix. Otherwise, a \".ps\" suffix will be appended to the end of the Mup input file name. If multiple input files are listed, the last is used. If none are specified (input is read from standard input), the name \"stdin.ps\" will be used for the output file. -l Print the Mup license and exit. -m midifile Instead of generating PostScript output, generate standard MIDI (Musical Instrument Digital Interface) output, and put it in midifile. This option also causes the macro \"MIDI\" to become defined. -M This is like the -m option, except the name of the MIDI file is derived from the name of the Mup input file. If the name of the Mup input file ends with a \".mup\" suffix, the generated MIDI file will end with a \".mid\" suffix instead. If the name of the Mup input file ends with a \".MUP\" suffix, the MIDI file will end with a \".MID\" suffix. Otherwise, a \".mid\" suffix will be appended to the end of the Mup input file name. If multiple input files are listed, the last is used. If none are specified (input is read from standard input), the name \"stdin.mid\" will be used for the MIDI file. -o pagelist Print only the pages given in pagelist. The pagelist can be a comma-separated list of numbers or ranges, where a range is two numbers separated by a dash. For example, -o1,7-9,12-14 would print pages 1, 7, 8, 9, 12, 13, and 14. Pages will be printed in the order given. They need not be in order, and a page number may be included more than once. Alternately, the pagelist can be the special keyword \"odd\" or \"even\" which will cause all odd or even numbered pages to be printed. This may be useful if you have a printer that only makes single-sided copies, but you wish to print Mup output double-sided. You could print odd-numbered pages, then turn the paper over and feed the pages through again for the even-numbered pages. -p N Start numbering pages at N instead of at 1. If -o and -p are used together, the page numbers given in the -o pagelist must be the printed page numbers. For example, if you use -p10 and want to print just the second page, you would need to specify -o11. -s stafflist Only print the staffs that are included in stafflist. This can be a comma-separated list of staff numbers or ranges, such as \"1,5\" or \"1-3,7-8\" To further restrict to a single voice on a staff, add v N where N is the voice number (1, 2, or 3), after the staff, as in \"2v1,5v2\" You can't specify a list or range for voices; if you only want to make two out of three voices visible, you have to specify them separately, like \"1v2,1v3\". No spaces are allowed in the list. -v Print the Mup version number and exit. This manual page is for version 6.1. -x M,N Extract measures M through N of the song. This allows you to print or play a part of a song. The comma and second value are optional; if not specified, the default is to go to the end of the piece. Positive values specify the number of measures from the beginning of the piece, while negative values are relative to the end, with -1 referring to the last measure of the song. So -x1,-1 means the entire song, if the song doesn't have a pickup measure. If the song has a pickup measure, that is specified by 0. So for a song with a pickup, -x0,-1 would mean the entire song, and -x0,0 would mean just the pickup measure. As other examples, -x-1,-1 means just the final measure of the song, -x2 means starting after the first full measure, -x3,4 means only measures 3 and 4, and -x6,6 means just measure 6. The starting measure is not allowed to be inside an ending. A common use for this option might be to generate a MIDI file for just a few measures. For example, if you were trying to tweak tempo values for a ritard in the last 2 measures of a song, you could use -x-2 to listen to just those measures. The options, if any, can be followed by one or more files in Mup format. If no files are specified, standard input is read. If several files are listed, they are effectively concatenated together and treated as one big file. Since there are some things (such as header and footer) that are only allowed to occur once, if you have several independent pieces, mup should be called on each individually rather than trying to print them all with one command. If a specified file does not exist, and its name does not already end with .mup or .MUP, then Mup will append .mup to the specified name and attempt to open that. On most systems, the environment variable MUPPATH can be set to a list of paths in which to look for 'include' files. The components are separated by a colon on Unix or Linux systems, and by a semicolon on systems with DOS-like file naming conventions. For more debugging, in addition to the -d option, if the environment variable MUP_BB is set to \"bcfghnsu\" or any subset of those letters, the generated output will include \"bounding boxes\" for the things Mup internally calls bars (b), chords (c), feeds (f), grpsyls (g), header\/footer and top\/bottom (h), notes (n), staffs (s), and stuff (u). While this is intended for use in debugging Mup itself, it may also help you understand why Mup places things the way it does, since in general, Mup only allows bounding boxes to overlap according to specific rules. If viewed with a color PostScript viewer (not mupdisp), these boxes will be in color.","Process Name":"mup","Link":"https:\/\/linux.die.net\/man\/1\/mup"}},{"Process":{"Description":null,"Process Name":"mupdatetest","Link":"https:\/\/linux.die.net\/man\/1\/mupdatetest"}},{"Process":{"Description":"Mupdisp provides a way to view Mup output on your screen. The file is Mup input. Any other Mup options can be given, except -C, -E, -f, -F, -l, -m, -M, or -v, which don't produce print output. Mupdisp will run under MS-DOS or will run under UNIX with a TERM of AT386, linux, or xterm (under X windows). When running under X windows, several standard X options are available: -geometry XxY+M+N Sets the window size and\/or location on the screen. The actual window width will be determined by the width of the Mup output. The height will be adjusted if necessary to be between 400 and the actual height of the Mup output. The window placment specifications can be positive or negative. The actual placement may be adjusted by your window manager. -fg color or -foreground color Specifies the foreground color to use. -bg color or -background color Specifies the background color to use. These X options can also be set in your .Xdefaults file using resource names of mupdisp.geometry, mupdisp.foreground, and mupdisp.background. Command line arguments will override values in the .Xdefaults file. As an example, you could add these lines to your .Xdefaults file: mupdisp.foreground:   navy\nmupdisp.background:   gray\nmupdisp.geometry:     400x760+100-34 The Mupdisp program begins in partial page mode, which displays output at approximately actual size (depending on the size of your monitor). In this mode, it may be that not all of the page fits on the screen, so the scrolling commands can be used to move up and down to view different parts of the page. In full page mode, a small version of the entire page is displayed. This is useful for seeing overall page layout, but is generally too small to see much detail. This mode is now somewhat of a relic of the days when screens were typically much smaller than they are today, and is thus becoming less useful. If the environment variable MUPDISPMODE is set to some value, Mupdisp will start in full page rather than partial page mode. The commands are: num<Enter> Go to page number num. + or <space> or <control-E> or <control-F> move forward on the page by about 1\/8 of an inch (partial page mode only) - or <backspace> or <control-Y> or <control-B> move backward on the page by about 1\/8 of an inch (partial page mode only) b or <control-U> or <control-P> or <up-arrow-key> move backward on the page by about an inch (partial page mode only) f or <Enter> or <control-D> or <control-N> or <down-arrow-key> move forward on the page by about an inch (partial page mode only) h or ? display help screen m toggle between partial page and full page modes. n or <PageDown> go to next page p or <PageUp> go to previous page q or ZZ quit r Repaint the page (useful for exiting help page) When in X windows, the mouse can be used for scrolling. The left button scrolls downward like the f command, while the right button scrolls backwards like the b command. Mupdisp supports page sizes of letter (8.5 x 11.0 inches), note (7.5 x 10.0 inches), legal (8.5 x 14.0 inches), A4 (8.26 x 11.69 inches), A5 (5.85 x 8.26 inches), A6 (4.125 x 5.85 inches), flsa (8.5 x 13.0 inches), and halfletter (5.5 x 8.5 inches).","Process Name":"mupdisp","Link":"https:\/\/linux.die.net\/man\/1\/mupdisp"}},{"Process":{"Description":"You can create a Mup file using any ordinary text editor. On Windows, Notepad is a typical choice; on Linux, editors like vim and emacs are commonly used. But if you prefer to be able to edit, display, and play from a single integrated and more graphical interface, a helper program called \"mupmate\" is provided. Mupmate is currently supported on Windows, Apple Mac OS-X, and Linux. However, since the source code is available, and it is based on the cross-platform FLTK toolkit, it can probably be made to run on any system supported by FLTK fairly easily. If you prefer to use the Mup program directly rather than via mupmate, you can. The Mupmate program just helps lead you through some of the steps. Once you have installed Mup and Mupmate on Windows, double clicking a .mup file in Windows explorer will run Mupmate on that file. Or, you can run Mupmate by going to the Start menu, and choosing Programs, then Arkkra, and then Mupmate. If you would like an icon on the desktop, you can create one by right clicking the Mupmate choice in the Arkkra menu, choosing \"copy\", right clicking somewhere on the desktop, and choosing \"paste.\" On Linux, you can just type the mupmate command, optionally followed by the name of a Mup input file. Or you can add mupmate to your favorite window manager's menus. On Mac OS-X, you can double-click on the MupMate.app in Finder. You should also be able to double-click any file with a .mup suffix, which should then run Mupmate on that file. For setting paths in the Preferences, several \"magic\" variables are set automatically, if you have not already set them to something else. $APPL is set to the top of the application directory hierarchy. $RSRC is effectively set to $APPL\/MupMate.app\/Contents\/Resources. $HOME is set to your home directory. $SUPP is set to your applications support folder (which is typically $HOME\/Library\/Application Support). $DOCS is set to your document folder (which is typically $HOME\/Documents). Mupmate provides five top level menus: File, Edit, Run, Config, and Help. The File menu provides commands for opening new files and saving the file you are working on, as well as exit the program. The Edit menu provides the kinds of things you would expect in a editor: commands to find a pattern, or find and replace; to select text; to copy, cut, and paste; to go to a specific line; and to undo the previous operation, if you make a mistake or change you mind. The Run menu lets you set runtime options, and then run the Mup program on your input in various ways. You can either just generate a PostScript or MIDI file, or display the PostScript or play the MIDI. The Config menu lets you specify what application program you want to use to view PostScript files and which you want to use to play MIDI files, and well as specify locations for other Mup files. Mupmate will try to find reasonable default values, but you may want to check that they are what you want, and tweak them if they aren't. For paths, you can include environment variables to be expanded, by giving their name preceded by a dollar sign. A tilde by itself will be expanded to your home directory, whereas a tilde followed by the name of a user will be expanded to that user's home directory. The Help menu lets you browse the Mup User's Guide, view some startup hints, view the Mup license, or see the current version number of Mup and Mupmate.","Process Name":"mupmate","Link":"https:\/\/linux.die.net\/man\/1\/mupmate"}},{"Process":{"Description":null,"Process Name":"mupprnt","Link":"https:\/\/linux.die.net\/man\/1\/mupprnt"}},{"Process":{"Description":"Musca is a simple dynamic window manager for X, with features nicked from ratpoison and dwm. Musca operates as a tiling window manager by default. It uses \"manual tiling\", which means the user determines how the screen is divided into non-overlapping frames, with no restrictions on layout. Application windows always fill their assigned frame, with the exception of transient windows and popup dialog boxes which float above their parent application at the appropriate size. Once visible, applications do not change frames unless so instructed. Since not all applications suit tiling, a more traditional stacking window manager mode is also available, allowing windows to float at any screen location and overlap. There are no built in status bars, panels, tabs or window decorations to take up screen real estate. If the user wants any of these things, there are plenty of external applications available to do the job. Window decoration is limited to a slender border, which is coloured to indicate keyboard focus. Windows are placed in named \"groups\" which can be used in a similar fashion to virtual desktops. Groups can be added and removed on the fly, and each group has its own frame layout. The excellent \"dmenu\" utility is being used to execute commands and launch applications, and it can also act as a window and group switcher. Basic EWMH support allows use of common panels, pagers and the wmctrl utility. Windows and frames are navigated and focused on any mouse button click, including rolling the wheel, or alternatively driven entirely by the keyboard. Simple key combinations exist for window switching, group switching, frame control and screen switching. For more information about Musca visit http:\/\/aerosuidae.net\/musca.html","Process Name":"musca","Link":"https:\/\/linux.die.net\/man\/1\/musca"}},{"Process":{"Description":"mussh is a shell script that allows you to execute a command or script over ssh(1) on multiple hosts with one command. When possible mussh will use ssh-agent(1) and RSA\/DSA keys to minimize the need to enter your password more than once.","Process Name":"mussh","Link":"https:\/\/linux.die.net\/man\/1\/mussh"}},{"Process":{"Description":"Mustache is a logic-less templating system for HTML, config files, anything. The mustache command processes a Mustache template preceded by YAML frontmatter from standard input and prints one or more documents to standard output. YAML frontmatter beings with --- on a single line, followed by YAML, ending with another --- on a single line, e.g. ---names: [ {name: chris}, {name: mark}, {name: scott} ]--- If you are unfamiliar with YAML, it is a superset of JSON. Valid JSON should work fine. After the frontmatter should come any valid Mustache template. See mustache(5) for an overview of Mustache templates. For example: {{#names}} Hi {{name}}!{{\/names}} Now let's combine them. $ cat data.yml---names: [ {name: chris}, {name: mark}, {name: scott} ]---$ cat template.mustache{{#names}} Hi {{name}}!{{\/names}}$ cat data.yml template.mustache | mustacheHi chris!Hi mark!Hi scott! If you provide multiple YAML documents (as delimited by ---), your template will be rendered multiple times. Like a mail merge. For example: $ cat data.yml---name: chris---name: mark---name: scott---$ cat template.mustacheHi {{name}}!$ cat data.yml template.mustache | mustacheHi chris!Hi mark!Hi scott!","Process Name":"mustache","Link":"https:\/\/linux.die.net\/man\/1\/mustache"}},{"Process":{"Description":null,"Process Name":"mutagen-inspect","Link":"https:\/\/linux.die.net\/man\/1\/mutagen-inspect"}},{"Process":{"Description":"mutagen-pony scans any directories given and reports on the kinds of tags in the MP3s it finds in them. Ride the pony. It is primarily intended as a debugging tool for Mutagen.","Process Name":"mutagen-pony","Link":"https:\/\/linux.die.net\/man\/1\/mutagen-pony"}},{"Process":{"Description":null,"Process Name":"mutt","Link":"https:\/\/linux.die.net\/man\/1\/mutt"}},{"Process":{"Description":null,"Process Name":"mutt_ldap_query","Link":"https:\/\/linux.die.net\/man\/1\/mutt_ldap_query"}},{"Process":{"Description":"This manual page documents briefly the Muttprint utility. This manual page was written originally written for the Debian GNU\/Linux distribution because the original program did not have a manual page, but now I took over this man page in POD-format. Muttprint is a utility that formats the printing of Mutt and other mail clients like XFMail or PINE to be like the printing of Netscape Messenger or Kmail. It can print a little penguin on the first page and a headline on every page. Furthermore, it only prints the most important headers, but not the whole plethora of them. For detailed information about Muttprint look read the User's guide in PDF and HTML format at \/usr\/share\/doc\/packages\/muttprint\/. Anyway, you have to put the following line in your \/etc\/Muttrc or ~\/.muttrc: set print_command=\"muttprint\" If you want to customize the settings of Muttprint, just copy \/usr\/share\/doc\/packages\/muttprint\/sample-muttprintrc-en to \/etc\/Muttprintrc or ~\/.muttprintrc in reliance if you want change the settings for the whole system or one user. Muttprint defaults to English language settings if the environment variable LANG is not set. For example in a German environment you should set: export LANG=de_DE This can for instance be done in in your local ~\/.bashrc. For a more detailed information about localization of Muttprint read the User's guide.","Process Name":"muttprint","Link":"https:\/\/linux.die.net\/man\/1\/muttprint"}},{"Process":{"Description":"Rename SOURCE to DEST, or move SOURCE(s) to DIRECTORY. Mandatory arguments to long options are mandatory for short options too. --backup[= CONTROL] make a backup of each existing destination file -b like --backup but does not accept an argument -f, --force do not prompt before overwriting -i, --interactive prompt before overwrite -n, --no-clobber do not overwrite an existing file If you specify more than one of -i, -f, -n, only the final one takes effect. --strip-trailing-slashes remove any trailing slashes from each SOURCE argument -S, --suffix= SUFFIX override the usual backup suffix -t, --target-directory= DIRECTORY move all SOURCE arguments into DIRECTORY -T, --no-target-directory treat DEST as a normal file -u, --update move only when the SOURCE file is newer than the destination file or when the destination file is missing -v, --verbose explain what is being done --help display this help and exit --version output version information and exit The backup suffix is '~', unless set with --suffix or SIMPLE_BACKUP_SUFFIX. The version control method may be selected via the --backup option or through the VERSION_CONTROL environment variable. Here are the values: none, off never make backups (even if --backup is given) numbered, t make numbered backups existing, nil numbered if numbered backups exist, simple otherwise simple, never always make simple backups","Process Name":"mv","Link":"https:\/\/linux.die.net\/man\/1\/mv"}},{"Process":{"Description":"mvdic changes the name of the specified user dictionary from from-dic to to-dic. Dictionary directory file -- dics.dir -- is rewritten correspondingly to this. After the changing, the old dictionary name of the customize file must be deleted. The dictionary in use (i.e., the currently mounted dictionary) cannot be deleted.","Process Name":"mvdic","Link":"https:\/\/linux.die.net\/man\/1\/mvdic"}},{"Process":{"Description":null,"Process Name":"mwm","Link":"https:\/\/linux.die.net\/man\/1\/mwm"}},{"Process":{"Description":null,"Process Name":"my_print_defaults","Link":"https:\/\/linux.die.net\/man\/1\/my_print_defaults"}},{"Process":{"Description":"myisam_ftdump displays information about FULLTEXT indexes in MyISAM tables. It reads the MyISAM index file directly, so it must be run on the server host where the table is located. Before using myisam_ftdump, be sure to issue a FLUSH TABLES statement first if the server is running. myisam_ftdump scans and dumps the entire index, which is not particularly fast. On the other hand, the distribution of words changes infrequently, so it need not be run often. Invoke myisam_ftdump like this: shell> myisam_ftdump [options] tbl_name index_num\n The tbl_name argument should be the name of a MyISAM table. You can also specify a table by naming its index file (the file with the .MYI suffix). If you do not invoke myisam_ftdump in the directory where the table files are located, the table or index file name must be preceded by the path name to the table's database directory. Index numbers begin with 0. Example: Suppose that the test database contains a table named mytexttablel that has the following definition: CREATE TABLE mytexttable\n(\n  id   INT NOT NULL,\n  txt  TEXT NOT NULL,\n  PRIMARY KEY (id),\n  FULLTEXT (txt)\n) ENGINE=MyISAM; The index on id is index 0 and the FULLTEXT index on txt is index 1. If your working directory is the test database directory, invoke myisam_ftdump as follows: shell> myisam_ftdump mytexttable 1\n If the path name to the test database directory is \/usr\/local\/mysql\/data\/test, you can also specify the table name argument using that path name. This is useful if you do not invoke myisam_ftdump in the database directory: shell> myisam_ftdump \/usr\/local\/mysql\/data\/test\/mytexttable 1\n You can use myisam_ftdump to generate a list of index entries in order of frequency of occurrence like this: shell> myisam_ftdump -c mytexttable 1 | sort -r\n myisam_ftdump supports the following options: \u2022 --help, -h -? Display a help message and exit. \u2022 --count, -c Calculate per-word statistics (counts and global weights). \u2022 --dump, -d Dump the index, including data offsets and word weights. \u2022 --length, -l Report the length distribution. \u2022 --stats, -s Report global index statistics. This is the default operation if no other operation is specified. \u2022 --verbose, -v Verbose mode. Print more output about what the program does.","Process Name":"myisam_ftdump","Link":"https:\/\/linux.die.net\/man\/1\/myisam_ftdump"}},{"Process":{"Description":"The myisamchk utility gets information about your database tables or checks, repairs, or optimizes them. myisamchk works with MyISAM tables (tables that have .MYD and .MYI files for storing data and indexes). You can also use the CHECK TABLE and REPAIR TABLE statements to check and repair MyISAM tables. See Section 13.7.2.3, \"CHECK TABLE Syntax\", and Section 13.7.2.6, \"REPAIR TABLE Syntax\". The use of myisamchk with partitioned tables is not supported. Caution It is best to make a backup of a table before performing a table repair operation; under some circumstances the operation might cause data loss. Possible causes include but are not limited to file system errors. Invoke myisamchk like this: shell> myisamchk [options] tbl_name ...\n The options specify what you want myisamchk to do. They are described in the following sections. You can also get a list of options by invoking myisamchk --help. With no options, myisamchk simply checks your table as the default operation. To get more information or to tell myisamchk to take corrective action, specify options as described in the following discussion. tbl_name is the database table you want to check or repair. If you run myisamchk somewhere other than in the database directory, you must specify the path to the database directory, because myisamchk has no idea where the database is located. In fact, myisamchk does not actually care whether the files you are working on are located in a database directory. You can copy the files that correspond to a database table into some other location and perform recovery operations on them there. You can name several tables on the myisamchk command line if you wish. You can also specify a table by naming its index file (the file with the .MYI suffix). This enables you to specify all tables in a directory by using the pattern *.MYI. For example, if you are in a database directory, you can check all the MyISAM tables in that directory like this: shell> myisamchk *.MYI\n If you are not in the database directory, you can check all the tables there by specifying the path to the directory: shell> myisamchk \/path\/to\/database_dir\/*.MYI\n You can even check all tables in all databases by specifying a wildcard with the path to the MySQL data directory: shell> myisamchk \/path\/to\/datadir\/*\/*.MYI\n The recommended way to quickly check all MyISAM tables is: shell> myisamchk --silent --fast \/path\/to\/datadir\/*\/*.MYI\n If you want to check all MyISAM tables and repair any that are corrupted, you can use the following command: shell> myisamchk --silent --force --fast --update-state \\\n          --key_buffer_size=64M --sort_buffer_size=64M \\\n          --read_buffer_size=1M --write_buffer_size=1M \\\n          \/path\/to\/datadir\/*\/*.MYI\n This command assumes that you have more than 64MB free. For more information about memory allocation with myisamchk, see the section called \"MYISAMCHK MEMORY USAGE\". For additional information about using myisamchk, see Section 7.6, \"MyISAM Table Maintenance and Crash Recovery\". Important You must ensure that no other program is using the tables while you are running myisamchk. The most effective means of doing so is to shut down the MySQL server while running myisamchk, or to lock all tables that myisamchk is being used on. Otherwise, when you run myisamchk, it may display the following error message: warning: clients are using or haven't closed the table properly This means that you are trying to check a table that has been updated by another program (such as the mysqld server) that hasn't yet closed the file or that has died without closing the file properly, which can sometimes lead to the corruption of one or more MyISAM tables. If mysqld is running, you must force it to flush any table modifications that are still buffered in memory by using FLUSH TABLES. You should then ensure that no one is using the tables while you are running myisamchk However, the easiest way to avoid this problem is to use CHECK TABLE instead of myisamchk to check tables. See Section 13.7.2.3, \"CHECK TABLE Syntax\". myisamchk supports the following options, which can be specified on the command line or in the [myisamchk] group of an option file. myisamchk also supports the options for processing option files described at Section 4.2.3.4, \"Command-Line Options that Affect Option-File Handling\".","Process Name":"myisamchk","Link":"https:\/\/linux.die.net\/man\/1\/myisamchk"}},{"Process":{"Description":null,"Process Name":"myisamlog","Link":"https:\/\/linux.die.net\/man\/1\/myisamlog"}},{"Process":{"Description":null,"Process Name":"myisampack","Link":"https:\/\/linux.die.net\/man\/1\/myisampack"}},{"Process":{"Description":"The myproxy-change-pass-phrase command changes the passphrase under which a credential is protected in the MyProxy repository. The command first prompts for the current passphrase for the credential, then prompts twice for the new passphrase. Only the credential owner can change a credential's passphrase. The user must have a valid proxy credential as generated by grid-proxy-init or retrieved by myproxy-logon(1) when running this command.","Process Name":"myproxy-change-pass-phrase","Link":"https:\/\/linux.die.net\/man\/1\/myproxy-change-pass-phrase"}},{"Process":{"Description":null,"Process Name":"myproxy-destroy","Link":"https:\/\/linux.die.net\/man\/1\/myproxy-destroy"}},{"Process":{"Description":"The myproxy-logon command retrieves a proxy credential from the myproxy-server(8) that was previously stored using myproxy-init(1) or myproxy-store(1). It can also be used to retrieve short-lived end entity credentials from a myproxy-server(8) configured to act as a Certificate Authority. In the default mode, the command prompts for the MyProxy pass phrase associated with the credential to be retrieved and stores the retrieved credential in the location specified by the X509_USER_PROXY environment variable or \/tmp\/x509up_u<uid> if that environment variable is not set. The myproxy-logon command is also available under the name myproxy-get-delegation for backward compatibility.","Process Name":"myproxy-get-delegation","Link":"https:\/\/linux.die.net\/man\/1\/myproxy-get-delegation"}},{"Process":{"Description":"Retrieves a proxy certificate from a MyProxy Server.","Process Name":"myproxy-get.pl","Link":"https:\/\/linux.die.net\/man\/1\/myproxy-get.pl"}},{"Process":{"Description":"The myproxy-info command displays information about a user's credentials previously stored on a myproxy-server(8) using myproxy-init(1). The user must have a valid proxy credential as generated by grid-proxy-init or retrieved by myproxy-logon(1) when running this command. The myproxy-info command provides information only for credentials stored in the myproxy-server(8) credential repository using myproxy-init(1). In the case where the myproxy-server(8) is acting as a Certificate Authority, issuing end entity credentials via the myproxy-logon(1) command, the myproxy-info command will return \"no credentials found\".","Process Name":"myproxy-info","Link":"https:\/\/linux.die.net\/man\/1\/myproxy-info"}},{"Process":{"Description":null,"Process Name":"myproxy-init","Link":"https:\/\/linux.die.net\/man\/1\/myproxy-init"}},{"Process":{"Description":null,"Process Name":"myproxy-init.pl","Link":"https:\/\/linux.die.net\/man\/1\/myproxy-init.pl"}},{"Process":{"Description":"The myproxy-logon command retrieves a proxy credential from the myproxy-server(8) that was previously stored using myproxy-init(1) or myproxy-store(1). It can also be used to retrieve short-lived end entity credentials from a myproxy-server(8) configured to act as a Certificate Authority. In the default mode, the command prompts for the MyProxy pass phrase associated with the credential to be retrieved and stores the retrieved credential in the location specified by the X509_USER_PROXY environment variable or \/tmp\/x509up_u<uid> if that environment variable is not set. The myproxy-logon command is also available under the name myproxy-get-delegation for backward compatibility.","Process Name":"myproxy-logon","Link":"https:\/\/linux.die.net\/man\/1\/myproxy-logon"}},{"Process":{"Description":null,"Process Name":"myproxy-retrieve","Link":"https:\/\/linux.die.net\/man\/1\/myproxy-retrieve"}},{"Process":{"Description":"The myproxy-store command uploads a credential to a myproxy-server(8) for later retrieval. The user must have a valid proxy credential as generated by grid-proxy-init or retrieved by myproxy-logon(1) when running this command. Unlike myproxy-init(1), this command transfers the private key over the network (over a private channel). In the default mode, the command will take the credentials found in ~\/.globus\/usercert.pem and ~\/.globus\/userkey.pem and store them in the myproxy-server(8) repository. Proxy credentials with default lifetime of 12 hours can then be retrieved by myproxy-logon(1) using the credential passphrase. The default behavior can be overridden by options specified below. The hostname where the myproxy-server(8) is running must be specified by either defining the MYPROXY_SERVER environment variable or the -s option.","Process Name":"myproxy-store","Link":"https:\/\/linux.die.net\/man\/1\/myproxy-store"}},{"Process":{"Description":null,"Process Name":"myrescue","Link":"https:\/\/linux.die.net\/man\/1\/myrescue"}},{"Process":{"Description":"mysql is a simple SQL shell with input line editing capabilities. It supports interactive and noninteractive use. When used interactively, query results are presented in an ASCII-table format. When used noninteractively (for example, as a filter), the result is presented in tab-separated format. The output format can be changed using command options. If you have problems due to insufficient memory for large result sets, use the --quick option. This forces mysql to retrieve results from the server a row at a time rather than retrieving the entire result set and buffering it in memory before displaying it. This is done by returning the result set using the mysql_use_result() C API function in the client\/server library rather than mysql_store_result(). Using mysql is very easy. Invoke it from the prompt of your command interpreter as follows: shell> mysql db_name\n Or: shell> mysql --user=user_name --password=your_password db_name\n Then type an SQL statement, end it with \";\", \\g, or \\G and press Enter. As of MySQL 5.1.10, typing Control+C causes mysql to attempt to kill the current statement. If this cannot be done, or Control+C is typed again before the statement is killed, mysql exits. Previously, Control+C caused mysql to exit in all cases. You can execute SQL statements in a script file (batch file) like this: shell> mysql db_name < script.sql > output.tab\n On Unix, the mysql client writes a record of executed statements to a history file. See the section called \"MYSQL HISTORY FILE\".","Process Name":"mysql","Link":"https:\/\/linux.die.net\/man\/1\/mysql"}},{"Process":{"Description":null,"Process Name":"mysql.server","Link":"https:\/\/linux.die.net\/man\/1\/mysql.server"}},{"Process":{"Description":"The mysql_client_test program is used for testing aspects of the MySQL client API that cannot be tested using mysqltest and its test language. mysql_client_test_embedded is similar but used for testing the embedded server. Both programs are run as part of the test suite. The source code for the programs can be found in in tests\/mysql_client_test.c in a source distribution. The program serves as a good source of examples illustrating how to use various features of the client API. mysql_client_test is used in a test by the same name in the main tests suite of mysql-test-run.pl but may also be run directly. Unlike the other programs listed here, it does not read an external description of what tests to run. Instead, all tests are coded into the program, which is written to cover all aspects of the C language API. mysql_client_test supports the following options: \u2022 --help, -? Display a help message and exit. \u2022 --basedir= dir_name, -b dir_name The base directory for the tests. \u2022 --count= count, -t count The number of times to execute the tests. \u2022 --database= db_name, -D db_name The database to use. \u2022 --debug[= debug_options ], -#[ debug_options ] Write a debugging log if MySQL is built with debugging support. The default debug_options value is 'd:t:o,\/tmp\/mysql_client_test.trace'. \u2022 --getopt-ll-test= option, -g option Option to use for testing bugs in the getopt library. \u2022 --host= host_name, -h host_name Connect to the MySQL server on the given host. \u2022 --password[= password ], -p[ password ] The password to use when connecting to the server. If you use the short option form (-p), you cannot have a space between the option and the password. If you omit the password value following the --password or -p option on the command line, you are prompted for one. \u2022 --port= port_num, -P port_num The TCP\/IP port number to use for the connection. \u2022 --server-arg= arg, -A arg Argument to send to the embedded server. \u2022 --show-tests, -T Show all test names. \u2022 --silent, -s Be more silent. \u2022 --socket= path, -S path The socket file to use when connecting to localhost (which is the default host). \u2022 --testcase, -c The option is used when called from mysql-test-run.pl, so that mysql_client_test may optionally behave in a different way than if called manually, for example by skipping some tests. Currently, there is no difference in behavior but the option is included to make this possible. \u2022 --user= user_name, -u user_name The MySQL user name to use when connecting to the server. \u2022 -v dir_name, --vardir= dir_name The data directory for tests. The default is mysql-test\/var.","Process Name":"mysql_client_test","Link":"https:\/\/linux.die.net\/man\/1\/mysql_client_test"}},{"Process":{"Description":null,"Process Name":"mysql_config","Link":"https:\/\/linux.die.net\/man\/1\/mysql_config"}},{"Process":{"Description":"mysql_convert_table_format converts the tables in a database to use a particular storage engine (MyISAM by default). mysql_convert_table_format is written in Perl and requires that the DBI and DBD::mysql Perl modules be installed (see Section 2.15, \"Perl Installation Notes\"). Invoke mysql_convert_table_format like this: shell> mysql_convert_table_format [options]db_name\n The db_name argument indicates the database containing the tables to be converted. mysql_convert_table_format supports the options described in the following list. \u2022 --help Display a help message and exit. \u2022 --force Continue even if errors occur. \u2022 --host= host_name Connect to the MySQL server on the given host. \u2022 --password= password The password to use when connecting to the server. Note that the password value is not optional for this option, unlike for other MySQL programs. Specifying a password on the command line should be considered insecure. See Section 6.1.2.1, \"End-User Guidelines for Password Security\". You can use an option file to avoid giving the password on the command line. \u2022 --port= port_num The TCP\/IP port number to use for the connection. \u2022 --socket= path For connections to localhost, the Unix socket file to use. \u2022 --type= engine_name Specify the storage engine that the tables should be converted to use. The default is MyISAM if this option is not given. \u2022 --user= user_name The MySQL user name to use when connecting to the server. \u2022 --verbose Verbose mode. Print more information about what the program does. \u2022 --version Display version information and exit.","Process Name":"mysql_convert_table_format","Link":"https:\/\/linux.die.net\/man\/1\/mysql_convert_table_format"}},{"Process":{"Description":"mysql_explain_log reads its standard input for query log contents. It uses EXPLAIN to analyze SELECT statements found in the input. UPDATE statements are rewritten to SELECT statements and also analyzed with EXPLAIN. mysql_explain_log then displays a summary of its results. The results may assist you in determining which queries result in table scans and where it would be beneficial to add indexes to your tables. Invoke mysql_explain_log like this, where log_file contains all or part of a MySQL query log: shell> mysql_explain_log [options] < log_file\n mysql_explain_log understands the following options: \u2022 --help, -? Display a help message and exit. \u2022 --date= YYMMDD, -d YYMMDD Select entries from the log only for the given date. \u2022 --host= host_name, -h host_name Connect to the MySQL server on the given host. \u2022 --password= password, -p password The password to use when connecting to the server. Specifying a password on the command line should be considered insecure. See Section 5.6, \"Keeping Passwords Secure\". \u2022 --printerror=1, -e 1 Enable error output. \u2022 --socket= path, -S path For connections to localhost, the Unix socket file to use, or, on Windows, the name of the named pipe to use. \u2022 --user= user_name, -u user_name The MySQL user name to use when connecting to the server.","Process Name":"mysql_explain_log","Link":"https:\/\/linux.die.net\/man\/1\/mysql_explain_log"}},{"Process":{"Description":"mysql_find_rows reads files containing SQL statements and extracts statements that match a given regular expression or that contain USE db_name or SET statements. The utility was written for use with update log files (as used prior to MySQL 5.0) and as such expects statements to be terminated with semicolon (;) characters. It may be useful with other files that contain SQL statements as long as statements are terminated with semicolons. Invoke mysql_find_rows like this: shell> mysql_find_rows [options] [file_name ...]\n Each file_name argument should be the name of file containing SQL statements. If no file names are given, mysql_find_rows reads the standard input. Examples: mysql_find_rows --regexp=problem_table --rows=20 < update.log\nmysql_find_rows --regexp=problem_table  update-log.1 update-log.2 mysql_find_rows supports the following options: \u2022 --help, --Information Display a help message and exit. \u2022 --regexp= pattern Display queries that match the pattern. \u2022 --rows= N Quit after displaying N queries. \u2022 --skip-use-db Do not include USE db_name statements in the output. \u2022 --start_row= N Start output from this row.","Process Name":"mysql_find_rows","Link":"https:\/\/linux.die.net\/man\/1\/mysql_find_rows"}},{"Process":{"Description":"mysql_fix_extensions converts the extensions for MyISAM (or ISAM) table files to their canonical forms. It looks for files with extensions matching any lettercase variant of .frm, .myd, .myi, .isd, and .ism and renames them to have extensions of .frm, .MYD, .MYI, .ISD, and .ISM, respectively. This can be useful after transferring the files from a system with case-insensitive file names (such as Windows) to a system with case-sensitive file names. Invoke mysql_fix_extensions like this, where data_dir is the path name to the MySQL data directory. shell> mysql_fix_extensions data_dir","Process Name":"mysql_fix_extensions","Link":"https:\/\/linux.die.net\/man\/1\/mysql_fix_extensions"}},{"Process":{"Description":"Note In MySQL 5.1.7, mysql_fix_privilege_tables was superseded by mysql_upgrade, which should be used instead. See mysql_upgrade(1). Some releases of MySQL introduce changes to the structure of the system tables in the mysql database to add new privileges or support new features. When you update to a new version of MySQL, you should update your system tables as well to make sure that their structure is up to date. Otherwise, there might be capabilities that you cannot take advantage of. mysql_fix_privilege_tables is an older script that previously was used to upgrade the system tables in the mysql database after a MySQL upgrade. Before running mysql_fix_privilege_tables, make a backup of your mysql database. On Unix or Unix-like systems, update the system tables by running the mysql_fix_privilege_tables script: shell> mysql_fix_privilege_tables\n You must run this script while the server is running. It attempts to connect to the server running on the local host as root. If your root account requires a password, indicate the password on the command line like this: shell> mysql_fix_privilege_tables --password=root_password\n The mysql_fix_privilege_tables script performs any actions necessary to convert your system tables to the current format. You might see some Duplicate column name warnings as it runs; you can ignore them. After running the script, stop the server and restart it so that any changes made to the system tables take effect. On Windows systems, MySQL distributions include a mysql_fix_privilege_tables.sql SQL script that you can run using the mysql client. For example, if your MySQL installation is located at C:\\Program Files\\MySQL\\MySQL Server 5.1, the commands look like this: C:\\> cd \"C:\\Program Files\\MySQL\\MySQL Server 5.1\"\nC:\\> bin\\mysql -u root -p mysql\nmysql> SOURCE share\/mysql_fix_privilege_tables.sql\n Note Prior to version 5.1.17, the mysql_fix_privilege_tables.sql script is found in the scripts directory. The mysql command will prompt you for the root password; enter it when prompted. If your installation is located in some other directory, adjust the path names appropriately. As with the Unix procedure, you might see some Duplicate column name warnings as mysql processes the statements in the mysql_fix_privilege_tables.sql script; you can ignore them. After running the script, stop the server and restart it.","Process Name":"mysql_fix_privilege_tables","Link":"https:\/\/linux.die.net\/man\/1\/mysql_fix_privilege_tables"}},{"Process":{"Description":"mysql_install_db initializes the MySQL data directory and creates the system tables that it contains, if they do not exist. To invoke mysql_install_db, use the following syntax: shell> mysql_install_db [options]\n Because the MySQL server, mysqld, needs to access the data directory when it runs later, you should either run mysql_install_db from the same account that will be used for running mysqld or run it as root and use the --user option to indicate the user name that mysqld will run as. It might be necessary to specify other options such as --basedir or --datadir if mysql_install_db does not use the correct locations for the installation directory or data directory. For example: shell> bin\/mysql_install_db --user=mysql \\\n         --basedir=\/opt\/mysql\/mysql \\\n         --datadir=\/opt\/mysql\/mysql\/data\n mysql_install_db needs to invoke mysqld with the --bootstrap and --skip-grant-tables options. If MySQL was configured with the --disable-grant-options option, --bootstrap and --skip-grant-tables will be disabled (see Section 2.11.4, \"MySQL Source-Configuration Options\"). To handle this, set the MYSQLD_BOOTSTRAP environment variable to the full path name of a server that has all options enabled. mysql_install_db will use that server. Note If you have set a custom TMPDIR variable when performing the installation, and the specified directory is not accessible, the execution of mysql_install_db may fail. You should unset TMPDIR, or set TMPDIR to point to the system temporary directory (usually \/tmp). mysql_install_db supports the following options, which can be specified on the command line or in the [mysql_install_db] and (if they are common to mysqld) [mysqld] groups of an option file. Other options are passed to mysqld. For information about option files, see Section 4.2.3.3, \"Using Option Files\". mysql_install_db also supports the options for processing option files described at Section 4.2.3.4, \"Command-Line Options that Affect Option-File Handling\". \u2022 --basedir= path The path to the MySQL installation directory. \u2022 --force Cause mysql_install_db to run even if DNS does not work. In that case, grant table entries that normally use host names will use IP addresses. \u2022 --datadir= path, --ldata= path The path to the MySQL data directory. \u2022 --rpm For internal use. This option is used by RPM files during the MySQL installation process. \u2022 --skip-name-resolve Use IP addresses rather than host names when creating grant table entries. This option can be useful if your DNS does not work. \u2022 --srcdir= path For internal use. The directory under which mysql_install_db looks for support files such as the error message file and the file for populating the help tables. This option was added in MySQL 5.1.14. \u2022 --user= user_name The login user name to use for running mysqld. Files and directories created by mysqld will be owned by this user. You must be root to use this option. By default, mysqld runs using your current login name and files and directories that it creates will be owned by you. \u2022 --verbose Verbose mode. Print more information about what the program does. \u2022 --windows For internal use. This option is used for creating Windows distributions.","Process Name":"mysql_install_db","Link":"https:\/\/linux.die.net\/man\/1\/mysql_install_db"}},{"Process":{"Description":"This program enables you to improve the security of your MySQL installation in the following ways: \u2022 You can set a password for root accounts. \u2022 You can remove root accounts that are accessible from outside the local host. \u2022 You can remove anonymous-user accounts. \u2022 You can remove the test database (which by default can be accessed by all users, even anonymous users), and privileges that permit anyone to access databases with names that start with test_. mysql_secure_installation helps you implement security recommendations similar to those described at Section 2.12.2, \"Securing the Initial MySQL Accounts\". Invoke mysql_secure_installation without arguments: shell> mysql_secure_installation\n The script will prompt you to determine which actions to perform. mysql_secure_installation is not available on Windows.","Process Name":"mysql_secure_installation","Link":"https:\/\/linux.die.net\/man\/1\/mysql_secure_installation"}},{"Process":{"Description":"mysql_setpermission is a Perl script that was originally written and contributed by Luuk de Boer. It interactively sets permissions in the MySQL grant tables. mysql_setpermission is written in Perl and requires that the DBI and DBD::mysql Perl modules be installed (see Section 2.15, \"Perl Installation Notes\"). Invoke mysql_setpermission like this: shell> mysql_setpermission [options]\n options should be either --help to display the help message, or options that indicate how to connect to the MySQL server. The account used when you connect determines which permissions you have when attempting to modify existing permissions in the grant tables. mysql_setpermissions also reads options from the [client] and [perl] groups in the .my.cnf file in your home directory, if the file exists. mysql_setpermission supports the following options: \u2022 --help Display a help message and exit. \u2022 --host= host_name Connect to the MySQL server on the given host. \u2022 --password= password The password to use when connecting to the server. Note that the password value is not optional for this option, unlike for other MySQL programs. Specifying a password on the command line should be considered insecure. See Section 6.1.2.1, \"End-User Guidelines for Password Security\". You can use an option file to avoid giving the password on the command line. \u2022 --port= port_num The TCP\/IP port number to use for the connection. \u2022 --socket= path For connections to localhost, the Unix socket file to use. \u2022 --user= user_name The MySQL user name to use when connecting to the server.","Process Name":"mysql_setpermission","Link":"https:\/\/linux.die.net\/man\/1\/mysql_setpermission"}},{"Process":{"Description":"mysql_tableinfo creates tables and populates them with database metadata. It uses SHOW DATABASES, SHOW TABLES, SHOW TABLE STATUS, SHOW COLUMNS, and SHOW INDEX to obtain the metadata. In MySQL 5.0 and up, the INFORMATION_SCHEMA database contains the same kind of information in the SCHEMATA, TABLES, COLUMNS, and STATISTICS tables. See Chapter 19, INFORMATION_SCHEMA Tables. Invoke mysql_tableinfo like this: shell> mysql_tableinfo [options] db_name [db_like [tbl_like]]\n The db_name argument indicates which database mysql_tableinfo should use as the location for the metadata tables. The database will be created if it does not exist. The tables will be named db, tbl (or tbl_status), col, and idx. If the db_like or tbl_like arguments are given, they are used as patterns and metadata is generated only for databases or tables that match the patterns. These arguments default to % if not given. Examples: mysql_tableinfo info\nmysql_tableinfo info world\nmysql_tableinfo info mydb tmp% Each of the commands stores information into tables in the info database. The first stores information for all databases and tables. The second stores information for all tables in the world database. The third stores information for tables in the mydb database that have names matching the pattern tmp%. mysql_tableinfo supports the following options: \u2022 --help Display a help message and exit. \u2022 --clear Before populating each metadata table, drop it if it exists. \u2022 --clear-only Similar to --clear, but exits after dropping the metadata tables to be populated. \u2022 --col Generate column metadata into the col table. \u2022 --host= host_name, -h host_name Connect to the MySQL server on the given host. \u2022 --idx Generate index metadata into the idx table. \u2022 --password= password, -p password The password to use when connecting to the server. Note that the password value is not optional for this option, unlike for other MySQL programs. You can use an option file to avoid giving the password on the command line. Specifying a password on the command line should be considered insecure. See Section 5.6, \"Keeping Passwords Secure\". \u2022 --port= port_num, -P port_num The TCP\/IP port number to use for the connection. \u2022 --prefix= prefix_str Add prefix_str at the beginning of each metadata table name. \u2022 --quiet, -q Be silent except for errors. \u2022 --socket= path, -S path The Unix socket file to use for the connection. \u2022 --tbl-status Use SHOW TABLE STATUS instead of SHOW TABLES. This provides more complete information, but is slower. \u2022 --user= user_name, -u user_name The MySQL user name to use when connecting to the server.","Process Name":"mysql_tableinfo","Link":"https:\/\/linux.die.net\/man\/1\/mysql_tableinfo"}},{"Process":{"Description":"The mysql_tzinfo_to_sql program loads the time zone tables in the mysql database. It is used on systems that have a zoneinfo database (the set of files describing time zones). Examples of such systems are Linux, FreeBSD, Solaris, and Mac OS X. One likely location for these files is the \/usr\/share\/zoneinfo directory (\/usr\/share\/lib\/zoneinfo on Solaris). If your system does not have a zoneinfo database, you can use the downloadable package described in Section 10.6, \"MySQL Server Time Zone Support\". mysql_tzinfo_to_sql can be invoked several ways: shell> mysql_tzinfo_to_sql tz_dir\nshell> mysql_tzinfo_to_sql tz_file tz_name\nshell> mysql_tzinfo_to_sql --leap tz_file\n For the first invocation syntax, pass the zoneinfo directory path name to mysql_tzinfo_to_sql and send the output into the mysql program. For example: shell> mysql_tzinfo_to_sql \/usr\/share\/zoneinfo | mysql -u root mysql\n mysql_tzinfo_to_sql reads your system's time zone files and generates SQL statements from them. mysql processes those statements to load the time zone tables. The second syntax causes mysql_tzinfo_to_sql to load a single time zone file tz_file that corresponds to a time zone name tz_name: shell> mysql_tzinfo_to_sql tz_file tz_name | mysql -u root mysql\n If your time zone needs to account for leap seconds, invoke mysql_tzinfo_to_sql using the third syntax, which initializes the leap second information. tz_file is the name of your time zone file: shell> mysql_tzinfo_to_sql --leap tz_file | mysql -u root mysql\n After running mysql_tzinfo_to_sql, it is best to restart the server so that it does not continue to use any previously cached time zone data.","Process Name":"mysql_tzinfo_to_sql","Link":"https:\/\/linux.die.net\/man\/1\/mysql_tzinfo_to_sql"}},{"Process":{"Description":"mysql_upgrade examines all tables in all databases for incompatibilities with the current version of MySQL Server. mysql_upgrade also upgrades the system tables so that you can take advantage of new privileges or capabilities that might have been added. mysql_upgrade should be executed each time you upgrade MySQL. It supersedes the older mysql_fix_privilege_tables script, which should no longer be used. If mysql_upgrade finds that a table has a possible incompatibility, it performs a table check and, if problems are found, attempts a table repair. If the table cannot be repaired, see Section 2.13.4, \"Rebuilding or Repairing Tables or Indexes\" for manual table repair strategies. Note On Windows Server 2008, Vista, and newer, you must run mysql_upgrade with administrator privileges. You can do this by running a Command Prompt as Administrator and running the command. Failure to do so may result in the upgrade failing to execute correctly. Caution You should always back up your current MySQL installation before performing an upgrade. See Section 7.2, \"Database Backup Methods\". Some upgrade incompatibilities may require special handling before you upgrade your MySQL installation and run mysql_upgrade. See Section 2.13.1, \"Upgrading MySQL\", for instructions on determining whether any such incompatibilities apply to your installation and how to handle them. To use mysql_upgrade, make sure that the server is running, and then invoke it like this: shell> mysql_upgrade [options]\n After running mysql_upgrade, stop the server and restart it so that any changes made to the system tables take effect. mysql_upgrade executes the following commands to check and repair tables and to upgrade the system tables: mysqlcheck --all-databases --check-upgrade --auto-repair\nmysql < fix_priv_tables\nmysqlcheck --all-databases --check-upgrade --fix-db-names --fix-table-names Notes about the preceding commands: \u2022 Because mysql_upgrade invokes mysqlcheck with the --all-databases option, it processes all tables in all databases, which might take a long time to complete. Each table is locked and therefore unavailable to other sessions while it is being processed. Check and repair operations can be time-consuming, particularly for large tables. \u2022 For details about what checks the --check-upgrade option entails, see the description of the FOR UPGRADE option of the CHECK TABLE statement (see Section 13.7.2.3, \"CHECK TABLE Syntax\"). \u2022 fix_priv_tables represents a script generated internally by mysql_upgrade that contains SQL statements to upgrade the tables in the mysql database. \u2022 Prior to MySQL 5.1.31, mysql_upgrade does not run the second mysqlcheck command, which is necessary to re-encode database or table names that contain nonalphanumeric characters. (They still appear after the upgrade with the #mysql50# prefix described in Section 9.2.3, \"Mapping of Identifiers to File Names\".) If you have such database or table names, execute the second mysqlcheck command manually after executing mysql_upgrade. All checked and repaired tables are marked with the current MySQL version number. This ensures that next time you run mysql_upgrade with the same version of the server, it can tell whether there is any need to check or repair the table again. mysql_upgrade also saves the MySQL version number in a file named mysql_upgrade_info in the data directory. This is used to quickly check whether all tables have been checked for this release so that table-checking can be skipped. To ignore this file and perform the check regardless, use the --force option. If you install MySQL from RPM packages on Linux, you must install the server and client RPMs. mysql_upgrade is included in the server RPM but requires the client RPM because the latter includes mysqlcheck. (See Section 2.5.1, \"Installing MySQL from RPM Packages on Linux\".) In MySQL 5.1.7, mysql_upgrade was added as a shell script and worked only for Unix systems. As of MySQL 5.1.10, mysql_upgrade is an executable binary and is available on all systems. mysql_upgrade does not upgrade the contents of the help tables. For upgrade instructions, see Section 5.1.9, \"Server-Side Help\". mysql_upgrade supports the following options, which can be specified on the command line or in the [mysql_upgrade] and [client] groups of an option file. Other options are passed to mysqlcheck. For example, it might be necessary to specify the --password[=password] option. mysql_upgrade also supports the options for processing option files described at Section 4.2.3.4, \"Command-Line Options that Affect Option-File Handling\". \u2022 --help Display a short help message and exit. \u2022 --basedir= path The path to the MySQL installation directory. This option is accepted for backward compatibility but ignored. \u2022 --datadir= path The path to the data directory. This option is accepted for backward compatibility but ignored. \u2022 --debug-check Print some debugging information when the program exits. This option was added in MySQL 5.1.21. \u2022 --debug-info, -T Print debugging information and memory and CPU usage statistics when the program exits. This option was added in MySQL 5.1.21. \u2022 --force Ignore the mysql_upgrade_info file and force execution of mysqlcheck even if mysql_upgrade has already been executed for the current version of MySQL. \u2022 --tmpdir= path, -t path The path name of the directory to use for creating temporary files. This option was added in MySQL 5.1.25. \u2022 --user= user_name, -u user_name The MySQL user name to use when connecting to the server. The default user name is root. \u2022 --verbose Verbose mode. Print more information about what the program does. \u2022 --write-binlog Cause binary logging to be enabled while mysql_upgrade runs. This is the default behavior; to disable binary logging during the upgrade, use the inverse of this option (that is, start the program with --skip-write-binlog). This option was introduced in MySQL 5.1.40.","Process Name":"mysql_upgrade","Link":"https:\/\/linux.die.net\/man\/1\/mysql_upgrade"}},{"Process":{"Description":"mysql_waitpid signals a process to terminate and waits for the process to exit. It uses the kill() system call and Unix signals, so it runs on Unix and Unix-like systems. Invoke mysql_waitpid like this: shell> mysql_waitpid [options] pid wait_time\n mysql_waitpid sends signal 0 to the process identified by pid and waits up to wait_time seconds for the process to terminate. pid and wait_time must be positive integers. If process termination occurs within the wait time or the process does not exist, mysql_waitpid returns 0. Otherwise, it returns 1. If the kill() system call cannot handle signal 0, mysql_waitpid() uses signal 1 instead. mysql_waitpid supports the following options: \u2022 --help, -?, -I Display a help message and exit. \u2022 --verbose, -v Verbose mode. Display a warning if signal 0 could not be used and signal 1 is used instead. \u2022 --version, -V Display version information and exit.","Process Name":"mysql_waitpid","Link":"https:\/\/linux.die.net\/man\/1\/mysql_waitpid"}},{"Process":{"Description":"mysql_zap kills processes that match a pattern. It uses the ps command and Unix signals, so it runs on Unix and Unix-like systems. Invoke mysql_zap like this: shell> mysql_zap [-signal] [-?Ift] pattern\n A process matches if its output line from the ps command contains the pattern. By default, mysql_zap asks for confirmation for each process. Respond y to kill the process, or q to exit mysql_zap. For any other response, mysql_zap does not attempt to kill the process. If the -signal option is given, it specifies the name or number of the signal to send to each process. Otherwise, mysql_zap tries first with TERM (signal 15) and then with KILL (signal 9). mysql_zap supports the following additional options: \u2022 --help, -?, -I Display a help message and exit. \u2022 -f Force mode. mysql_zap attempts to kill each process without confirmation. \u2022 -t Test mode. Display information about each process but do not kill it.","Process Name":"mysql_zap","Link":"https:\/\/linux.die.net\/man\/1\/mysql_zap"}},{"Process":{"Description":"mysqlaccess is a diagnostic tool that Yves Carlier has provided for the MySQL distribution. It checks the access privileges for a host name, user name, and database combination. Note that mysqlaccess checks access using only the user, db, and host tables. It does not check table, column, or routine privileges specified in the tables_priv, columns_priv, or procs_priv tables. Invoke mysqlaccess like this: shell> mysqlaccess [host_name [user_name [db_name]]] [options]\n mysqlaccess supports the following options. \u2022 --help, -? Display a help message and exit. \u2022 --brief, -b Generate reports in single-line tabular format. \u2022 --commit Copy the new access privileges from the temporary tables to the original grant tables. The grant tables must be flushed for the new privileges to take effect. (For example, execute a mysqladmin reload command.) \u2022 --copy Reload the temporary grant tables from original ones. \u2022 --db= db_name, -d db_name Specify the database name. \u2022 --debug= N Specify the debug level. N can be an integer from 0 to 3. \u2022 --host= host_name, -h host_name The host name to use in the access privileges. \u2022 --howto Display some examples that show how to use mysqlaccess. \u2022 --old_server Assume that the server is an old MySQL server (before MySQL 3.21) that does not yet know how to handle full WHERE clauses. \u2022 --password[= password ], -p[ password ] The password to use when connecting to the server. If you omit the password value following the --password or -p option on the command line, mysqlaccess prompts for one. Specifying a password on the command line should be considered insecure. See Section 6.1.2.1, \"End-User Guidelines for Password Security\". \u2022 --plan Display suggestions and ideas for future releases. \u2022 --preview Show the privilege differences after making changes to the temporary grant tables. \u2022 --relnotes Display the release notes. \u2022 --rhost= host_name, -H host_name Connect to the MySQL server on the given host. \u2022 --rollback Undo the most recent changes to the temporary grant tables. \u2022 --spassword[= password ], -P[ password ] The password to use when connecting to the server as the superuser. If you omit the password value following the --spassword or -p option on the command line, mysqlaccess prompts for one. Specifying a password on the command line should be considered insecure. See Section 6.1.2.1, \"End-User Guidelines for Password Security\". \u2022 --superuser= user_name, -U user_name Specify the user name for connecting as the superuser. \u2022 --table, -t Generate reports in table format. \u2022 --user= user_name, -u user_name The user name to use in the access privileges. \u2022 --version, -v Display version information and exit. If your MySQL distribution is installed in some nonstandard location, you must change the location where mysqlaccess expects to find the mysql client. Edit the mysqlaccess script at approximately line 18. Search for a line that looks like this: $MYSQL     = '\/usr\/local\/bin\/mysql';    # path to mysql executable Change the path to reflect the location where mysql actually is stored on your system. If you do not do this, a Broken pipe error will occur when you run mysqlaccess.","Process Name":"mysqlaccess","Link":"https:\/\/linux.die.net\/man\/1\/mysqlaccess"}},{"Process":{"Description":"mysqladmin is a client for performing administrative operations. You can use it to check the server's configuration and current status, to create and drop databases, and more. Invoke mysqladmin like this: shell> mysqladmin [options] command [command-arg] [command [command-arg]] ...\n mysqladmin supports the following commands. Some of the commands take an argument following the command name. \u2022 create db_name Create a new database named db_name. \u2022 debug Tell the server to write debug information to the error log. Beginning with MySQL 5.1.12, this includes information about the Event Scheduler. See Section 19.4.5, \"Event Scheduler Status\". \u2022 drop db_name Delete the database named db_name and all its tables. \u2022 extended-status Display the server status variables and their values. \u2022 flush-hosts Flush all information in the host cache. \u2022 flush-logs Flush all logs. \u2022 flush-privileges Reload the grant tables (same as reload). \u2022 flush-status Clear status variables. \u2022 flush-tables Flush all tables. \u2022 flush-threads Flush the thread cache. \u2022 kill id, id,... Kill server threads. If multiple thread ID values are given, there must be no spaces in the list. \u2022 old-password new-password This is like the password command but stores the password using the old (pre-4.1) password-hashing format. (See Section 6.1.2.4, \"Password Hashing in MySQL\".) \u2022 password new-password Set a new password. This changes the password to new-password for the account that you use with mysqladmin for connecting to the server. Thus, the next time you invoke mysqladmin (or any other client program) using the same account, you will need to specify the new password. If the new-password value contains spaces or other characters that are special to your command interpreter, you need to enclose it within quotation marks. On Windows, be sure to use double quotation marks rather than single quotation marks; single quotation marks are not stripped from the password, but rather are interpreted as part of the password. For example: shell> mysqladmin password \"my new password\"\n Caution Do not use this command used if the server was started with the --skip-grant-tables option. No password change will be applied. This is true even if you precede the password command with flush-privileges on the same command line to re-enable the grant tables because the flush operation occurs after you connect. However, you can use mysqladmin flush-privileges to re-enable the grant table and then use a separate mysqladmin password command to change the password. \u2022 ping Check whether the server is available. The return status from mysqladmin is 0 if the server is running, 1 if it is not. This is 0 even in case of an error such as Access denied, because this means that the server is running but refused the connection, which is different from the server not running. \u2022 processlist Show a list of active server threads. This is like the output of the SHOW PROCESSLIST statement. If the --verbose option is given, the output is like that of SHOW FULL PROCESSLIST. (See Section 13.7.5.31, \"SHOW PROCESSLIST Syntax\".) \u2022 reload Reload the grant tables. \u2022 refresh Flush all tables and close and open log files. \u2022 shutdown Stop the server. \u2022 start-slave Start replication on a slave server. \u2022 status Display a short server status message. \u2022 stop-slave Stop replication on a slave server. \u2022 variables Display the server system variables and their values. \u2022 version Display version information from the server. All commands can be shortened to any unique prefix. For example: shell> mysqladmin proc stat\n+----+-------+-----------+----+---------+------+-------+------------------+\n| Id | User  | Host      | db | Command | Time | State | Info             |\n+----+-------+-----------+----+---------+------+-------+------------------+\n| 51 | monty | localhost |    | Query   | 0    |       | show processlist |\n+----+-------+-----------+----+---------+------+-------+------------------+\nUptime: 1473624  Threads: 1  Questions: 39487\nSlow queries: 0  Opens: 541  Flush tables: 1\nOpen tables: 19  Queries per second avg: 0.0268 The mysqladmin status command result displays the following values: \u2022 Uptime The number of seconds the MySQL server has been running. \u2022 Threads The number of active threads (clients). \u2022 Questions The number of questions (queries) from clients since the server was started. \u2022 Slow queries The number of queries that have taken more than long_query_time seconds. See Section 5.2.5, \"The Slow Query Log\". \u2022 Opens The number of tables the server has opened. \u2022 Flush tables The number of flush-*, refresh, and reload commands the server has executed. \u2022 Open tables The number of tables that currently are open. \u2022 Memory in use The amount of memory allocated directly by mysqld. This value is displayed only when MySQL has been compiled with --with-debug=full. \u2022 Maximum memory used The maximum amount of memory allocated directly by mysqld. This value is displayed only when MySQL has been compiled with --with-debug=full. If you execute mysqladmin shutdown when connecting to a local server using a Unix socket file, mysqladmin waits until the server's process ID file has been removed, to ensure that the server has stopped properly. mysqladmin supports the following options, which can be specified on the command line or in the [mysqladmin] and [client] groups of an option file. mysqladmin also supports the options for processing option files described at Section 4.2.3.4, \"Command-Line Options that Affect Option-File Handling\". \u2022 --help, -? Display a help message and exit. \u2022 --bind-address= ip_address On a computer having multiple network interfaces, this option can be used to select which interface is employed when connecting to the MySQL server. This option is supported only in the version of mysqladmin that is supplied with MySQL Cluster, beginning with MySQL Cluster NDB 6.3.4. It is not available in standard MySQL 5.1 releases. \u2022 --character-sets-dir= path The directory where character sets are installed. See Section 10.5, \"Character Set Configuration\". \u2022 --compress, -C Compress all information sent between the client and the server if both support compression. \u2022 --count= N, -c N The number of iterations to make for repeated command execution if the --sleep option is given. \u2022 --debug[= debug_options ], -# [ debug_options ] Write a debugging log. A typical debug_options string is 'd:t:o,file_name'. The default is 'd:t:o,\/tmp\/mysqladmin.trace'. \u2022 --debug-check Print some debugging information when the program exits. This option was added in MySQL 5.1.21. \u2022 --debug-info Print debugging information and memory and CPU usage statistics when the program exits. This option was added in MySQL 5.1.14. \u2022 --default-character-set= charset_name Use charset_name as the default character set. See Section 10.5, \"Character Set Configuration\". \u2022 --force, -f Do not ask for confirmation for the drop db_name command. With multiple commands, continue even if an error occurs. \u2022 --host= host_name, -h host_name Connect to the MySQL server on the given host. \u2022 --no-beep, -b Suppress the warning beep that is emitted by default for errors such as a failure to connect to the server. This option was added in MySQL 5.1.17. \u2022 --password[= password ], -p[ password ] The password to use when connecting to the server. If you use the short option form (-p), you cannot have a space between the option and the password. If you omit the password value following the --password or -p option on the command line, mysqladmin prompts for one. Specifying a password on the command line should be considered insecure. See Section 6.1.2.1, \"End-User Guidelines for Password Security\". You can use an option file to avoid giving the password on the command line. \u2022 --pipe, -W On Windows, connect to the server using a named pipe. This option applies only if the server supports named-pipe connections. \u2022 --port= port_num, -P port_num The TCP\/IP port number to use for the connection. \u2022 --protocol={TCP|SOCKET|PIPE|MEMORY} The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally would cause a protocol to be used other than the one you want. For details on the permissible values, see Section 4.2.2, \"Connecting to the MySQL Server\". \u2022 --relative, -r Show the difference between the current and previous values when used with the --sleep option. This option works only with the extended-status command. \u2022 --silent, -s Exit silently if a connection to the server cannot be established. \u2022 --sleep= delay, -i delay Execute commands repeatedly, sleeping for delay seconds in between. The --count option determines the number of iterations. If --count is not given, mysqladmin executes commands indefinitely until interrupted. \u2022 --socket= path, -S path For connections to localhost, the Unix socket file to use, or, on Windows, the name of the named pipe to use. \u2022 --ssl* Options that begin with --ssl specify whether to connect to the server using SSL and indicate where to find SSL keys and certificates. See Section 6.3.6.4, \"SSL Command Options\". \u2022 --user= user_name, -u user_name The MySQL user name to use when connecting to the server. \u2022 --verbose, -v Verbose mode. Print more information about what the program does. \u2022 --version, -V Display version information and exit. \u2022 --vertical, -E Print output vertically. This is similar to --relative, but prints output vertically. \u2022 --wait[= count ], -w[ count ] If the connection cannot be established, wait and retry instead of aborting. If a count value is given, it indicates the number of times to retry. The default is one time. You can also set the following variables by using -- var_name = value The --set-variable format is deprecated and is removed in MySQL 5.5. \u2022 connect_timeout The maximum number of seconds before connection timeout. The default value is 43200 (12 hours). \u2022 shutdown_timeout The maximum number of seconds to wait for server shutdown. The default value is 3600 (1 hour).","Process Name":"mysqladmin","Link":"https:\/\/linux.die.net\/man\/1\/mysqladmin"}},{"Process":{"Description":"The server's binary log consists of files containing \"events\" that describe modifications to database contents. The server writes these files in binary format. To display their contents in text format, use the mysqlbinlog utility. You can also use mysqlbinlog to display the contents of relay log files written by a slave server in a replication setup because relay logs have the same format as binary logs. The binary log and relay log are discussed further in Section 5.2.4, \"The Binary Log\", and Section 16.2.2, \"Replication Relay and Status Logs\". Invoke mysqlbinlog like this: shell> mysqlbinlog [options] log_file ...\n For example, to display the contents of the binary log file named binlog.000003, use this command: shell> mysqlbinlog binlog.0000003\n The output includes events contained in binlog.000003. For statement-based logging, event information includes the SQL statement, the ID of the server on which it was executed, the timestamp when the statement was executed, how much time it took, and so forth. For row-based logging, the event indicates a row change rather than an SQL statement. See Section 16.1.2, \"Replication Formats\", for information about logging modes. Events are preceded by header comments that provide additional information. For example: # at 141\n#100309  9:28:36 server id 123  end_log_pos 245\n  Query thread_id=3350  exec_time=11  error_code=0 In the first line, the number following at indicates the starting position of the event in the binary log file. The second line starts with a date and time indicating when the statement started on the server where the event originated. For replication, this timestamp is propagated to slave servers. server id is the server_id value of the server where the event originated. end_log_pos indicates where the next event starts (that is, it is the end position of the current event + 1). thread_id indicates which thread executed the event. exec_time is the time spent executing the event, on a master server. On a slave, it is the difference of the end execution time on the slave minus the beginning execution time on the master. The difference serves as an indicator of how much replication lags behind the master. error_code indicates the result from executing the event. Zero means that no error occurred. The output from mysqlbinlog can be re-executed (for example, by using it as input to mysql) to redo the statements in the log. This is useful for recovery operations after a server crash. For other usage examples, see the discussion later in this section and in Section 7.5, \"Point-in-Time (Incremental) Recovery Using the Binary Log\". Normally, you use mysqlbinlog to read binary log files directly and apply them to the local MySQL server. It is also possible to read binary logs from a remote server by using the --read-from-remote-server option. To read remote binary logs, the connection parameter options can be given to indicate how to connect to the server. These options are --host, --password, --port, --protocol, --socket, and --user; they are ignored except when you also use the --read-from-remote-server option. mysqlbinlog supports the following options, which can be specified on the command line or in the [mysqlbinlog] and [client] groups of an option file. mysqlbinlog also supports the options for processing option files described at Section 4.2.3.4, \"Command-Line Options that Affect Option-File Handling\". \u2022 --help, -? Display a help message and exit. \u2022 --base64-output[= value ] This option determines when events should be displayed encoded as base-64 strings using BINLOG statements. The option has these permissible values (not case sensitive): \u2022 AUTO (\"automatic\") or UNSPEC (\"unspecified\") displays BINLOG statements automatically when necessary (that is, for format description events and row events). If no --base64-output option is given, the effect is the same as --base64-output=AUTO. Note Automatic BINLOG display is the only safe behavior if you intend to use the output of mysqlbinlog to re-execute binary log file contents. The other option values are intended only for debugging or testing purposes because they may produce output that does not include all events in executable form. \u2022 ALWAYS displays BINLOG statements whenever possible. If the --base64-output option is given without a value, the effect is the same as --base64-output=ALWAYS. \u2022 NEVER causes BINLOG statements not to be displayed. mysqlbinlog exits with an error if a row event is found that must be displayed using BINLOG. \u2022 DECODE-ROWS specifies to mysqlbinlog that you intend for row events to be decoded and displayed as commented SQL statements by also specifying the --verbose option. Like NEVER, DECODE-ROWS suppresses display of BINLOG statements, but unlike NEVER, it does not exit with an error if a row event is found. The --base64-output option was introduced in MySQL 5.1.5, to be given as --base64-output or --skip-base64-output (with the sense of AUTO or NEVER). The option values described in the preceding list may be used as of MySQL 5.1.24, with the exception of UNSPEC and DECODE-ROWS, which are available as of MySQL 5.1.28. For examples that show the effect of --base64-output and --verbose on row event output, see the section called \"MYSQLBINLOG ROW EVENT DISPLAY\". \u2022 --bind-address=ip_address On a computer having multiple network interfaces, this option can be used to select which interface is employed when connecting to the MySQL server. This option is supported only in the version of mysqlbinlog that is supplied with MySQL Cluster, beginning with MySQL Cluster NDB 6.3.4. It is not available in standard MySQL 5.1 releases. \u2022 --character-sets-dir=path The directory where character sets are installed. See Section 10.5, \"Character Set Configuration\". \u2022 --database=db_name, -d db_name This option causes mysqlbinlog to output entries from the binary log (local log only) that occur while db_name is been selected as the default database by USE. The --database option for mysqlbinlog is similar to the --binlog-do-db option for mysqld, but can be used to specify only one database. If --database is given multiple times, only the last instance is used. The effects of this option depend on whether the statement-based or row-based logging format is in use, in the same way that the effects of --binlog-do-db depend on whether statement-based or row-based logging is in use. Statement-based logging. The --database option works as follows: \u2022 While db_name is the default database, statements are output whether they modify tables in db_name or a different database. \u2022 Unless db_name is selected as the default database, statements are not output, even if they modify tables in db_name. \u2022 There is an exception for CREATE DATABASE, ALTER DATABASE, and DROP DATABASE. The database being created, altered, or dropped is considered to be the default database when determining whether to output the statement. Suppose that the binary log was created by executing these statements using statement-based-logging: INSERT INTO test.t1 (i) VALUES(100);\nINSERT INTO db2.t2 (j)  VALUES(200);\nUSE test;\nINSERT INTO test.t1 (i) VALUES(101);\nINSERT INTO t1 (i)      VALUES(102);\nINSERT INTO db2.t2 (j)  VALUES(201);\nUSE db2;\nINSERT INTO test.t1 (i) VALUES(103);\nINSERT INTO db2.t2 (j)  VALUES(202);\nINSERT INTO t2 (j)      VALUES(203); mysqlbinlog --database=test does not output the first two INSERT statements because there is no default database. It outputs the three INSERT statements following USE test, but not the three INSERT statements following USE db2. mysqlbinlog --database=db2 does not output the first two INSERT statements because there is no default database. It does not output the three INSERT statements following USE test, but does output the three INSERT statements following USE db2. Row-based logging. mysqlbinlog outputs only entries that change tables belonging to db_name. The default database has no effect on this. Suppose that the binary log just described was created using row-based logging rather than statement-based logging. mysqlbinlog --database=test outputs only those entries that modify t1 in the test database, regardless of whether USE was issued or what the default database is. If a server is running with binlog_format set to MIXED and you want it to be possible to use mysqlbinlog with the --database option, you must ensure that tables that are modified are in the database selected by USE. (In particular, no cross-database updates should be used.) This option did not work correctly for mysqlbinlog with row-based logging prior to MySQL 5.1.37. (Bug #42941) Note Prior to MySQL Cluster NDB 7.0.28 and MySQL Cluster NDB 7.1.17, this option did not work correctly with MySQL Cluster tables unless, unless the binary log was generated using --log-bin-use-v1-row-events=0. (Bug #13067813) \u2022 --debug[=debug_options], -# [debug_options] Write a debugging log. A typical debug_options string is 'd:t:o,file_name'. The default is 'd:t:o,\/tmp\/mysqlbinlog.trace'. \u2022 --debug-check Print some debugging information when the program exits. This option was added in MySQL 5.1.21. \u2022 --debug-info Print debugging information and memory and CPU usage statistics when the program exits. This option was added in MySQL 5.1.21. \u2022 --disable-log-bin, -D Disable binary logging. This is useful for avoiding an endless loop if you use the --to-last-log option and are sending the output to the same MySQL server. This option also is useful when restoring after a crash to avoid duplication of the statements you have logged. This option requires that you have the SUPER privilege. It causes mysqlbinlog to include a SET sql_log_bin = 0 statement in its output to disable binary logging of the remaining output. The SET statement is ineffective unless you have the SUPER privilege. \u2022 --force-if-open, -F Read binary log files even if they are open or were not closed properly. This option was added in MySQL 5.1.15. \u2022 --force-read, -f With this option, if mysqlbinlog reads a binary log event that it does not recognize, it prints a warning, ignores the event, and continues. Without this option, mysqlbinlog stops if it reads such an event. \u2022 --hexdump, -H Display a hex dump of the log in comments, as described in the section called \"MYSQLBINLOG HEX DUMP FORMAT\". The hex output can be helpful for replication debugging. This option was added in MySQL 5.1.2. \u2022 --host=host_name, -h host_name Get the binary log from the MySQL server on the given host. \u2022 --local-load=path, -l path Prepare local temporary files for LOAD DATA INFILE in the specified directory. Important These temporary files are not automatically removed by mysqlbinlog or any other MySQL program. \u2022 --offset=N, -o N Skip the first N entries in the log. \u2022 --password[=password], -p[password] The password to use when connecting to the server. If you use the short option form (-p), you cannot have a space between the option and the password. If you omit the password value following the --password or -p option on the command line, mysqlbinlog prompts for one. Specifying a password on the command line should be considered insecure. See Section 6.1.2.1, \"End-User Guidelines for Password Security\". You can use an option file to avoid giving the password on the command line. \u2022 --port=port_num, -P port_num The TCP\/IP port number to use for connecting to a remote server. \u2022 --position=N Deprecated. Use --start-position instead. --position is removed in MySQL 5.5. \u2022 --protocol={TCP|SOCKET|PIPE|MEMORY} The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally would cause a protocol to be used other than the one you want. For details on the permissible values, see Section 4.2.2, \"Connecting to the MySQL Server\". \u2022 --read-from-remote-server, -R Read the binary log from a MySQL server rather than reading a local log file. Any connection parameter options are ignored unless this option is given as well. These options are --host, --password, --port, --protocol, --socket, and --user. This option requires that the remote server be running. It works only for binary log files on the remote server, not relay log files. \u2022 --result-file=name, -r name Direct output to the given file. \u2022 --server-id=id Display only those events created by the server having the given server ID. This option is available as of MySQL 5.1.4. \u2022 --server-id-bits=N Use only the first N bits of the server_id to identify the server. If the binary log was written by a mysqld with server-id-bits set to less than 32 and user data stored in the most significant bit, running mysqlbinlog with --server-id-bits set to 32 enables this data to be seen. This option was added in MySQL Cluster NDB 7.0.17 and MySQL Cluster NDB 7.1.6, and is supported only by the versions of mysqlbinlog supplied with these and later releases of MySQL Cluster. \u2022 --set-charset=charset_name Add a SET NAMES charset_name statement to the output to specify the character set to be used for processing log files. This option was added in MySQL 5.1.12. \u2022 --short-form, -s Display only the statements contained in the log, without any extra information or row-based events. This is for testing only, and should not be used in production systems. \u2022 --socket=path, -S path For connections to localhost, the Unix socket file to use, or, on Windows, the name of the named pipe to use. \u2022 --start-datetime=datetime Start reading the binary log at the first event having a timestamp equal to or later than the datetime argument. The datetime value is relative to the local time zone on the machine where you run mysqlbinlog. The value should be in a format accepted for the DATETIME or TIMESTAMP data types. For example: shell> mysqlbinlog --start-datetime=\"2005-12-25 11:25:56\" binlog.000003\n This option is useful for point-in-time recovery. See Section 7.3, \"Example Backup and Recovery Strategy\". \u2022 --start-position=N, -j N Start reading the binary log at the first event having a position equal to or greater than N. This option applies to the first log file named on the command line. This option is useful for point-in-time recovery. See Section 7.3, \"Example Backup and Recovery Strategy\". \u2022 --stop-datetime=datetime Stop reading the binary log at the first event having a timestamp equal to or later than the datetime argument. This option is useful for point-in-time recovery. See the description of the --start-datetime option for information about the datetime value. This option is useful for point-in-time recovery. See Section 7.3, \"Example Backup and Recovery Strategy\". \u2022 --stop-position=N Stop reading the binary log at the first event having a position equal to or greater than N. This option applies to the last log file named on the command line. This option is useful for point-in-time recovery. See Section 7.3, \"Example Backup and Recovery Strategy\". \u2022 --to-last-log, -t Do not stop at the end of the requested binary log from a MySQL server, but rather continue printing until the end of the last binary log. If you send the output to the same MySQL server, this may lead to an endless loop. This option requires --read-from-remote-server. \u2022 --user=user_name, -u user_name The MySQL user name to use when connecting to a remote server. \u2022 --verbose, -v Reconstruct row events and display them as commented SQL statements. If this option is given twice, the output includes comments to indicate column data types and some metadata. This option was added in MySQL 5.1.28. For examples that show the effect of --base64-output and --verbose on row event output, see the section called \"MYSQLBINLOG ROW EVENT DISPLAY\". \u2022 --version, -V Display version information and exit. You can also set the following variable by using -- var_name = value syntax: \u2022 open_files_limit Specify the number of open file descriptors to reserve. You can pipe the output of mysqlbinlog into the mysql client to execute the events contained in the binary log. This technique is used to recover from a crash when you have an old backup (see Section 7.5, \"Point-in-Time (Incremental) Recovery Using the Binary Log\"). For example: shell> mysqlbinlog binlog.000001 | mysql -u root -p\n Or: shell> mysqlbinlog binlog.[0-9]* | mysql -u root -p\n You can also redirect the output of mysqlbinlog to a text file instead, if you need to modify the statement log first (for example, to remove statements that you do not want to execute for some reason). After editing the file, execute the statements that it contains by using it as input to the mysql program: shell> mysqlbinlog binlog.000001 > tmpfile\nshell> ... edit tmpfile ...\nshell> mysql -u root -p < tmpfile\n When mysqlbinlog is invoked with the --start-position option, it displays only those events with an offset in the binary log greater than or equal to a given position (the given position must match the start of one event). It also has options to stop and start when it sees an event with a given date and time. This enables you to perform point-in-time recovery using the --stop-datetime option (to be able to say, for example, \"roll forward my databases to how they were today at 10:30 a.m.\"). If you have more than one binary log to execute on the MySQL server, the safe method is to process them all using a single connection to the server. Here is an example that demonstrates what may be unsafe: shell> mysqlbinlog binlog.000001 | mysql -u root -p # DANGER!!\nshell> mysqlbinlog binlog.000002 | mysql -u root -p # DANGER!!\n Processing binary logs this way using multiple connections to the server causes problems if the first log file contains a CREATE TEMPORARY TABLE statement and the second log contains a statement that uses the temporary table. When the first mysql process terminates, the server drops the temporary table. When the second mysql process attempts to use the table, the server reports \"unknown table.\" To avoid problems like this, use a single mysql process to execute the contents of all binary logs that you want to process. Here is one way to do so: shell> mysqlbinlog binlog.000001 binlog.000002 | mysql -u root -p\n Another approach is to write all the logs to a single file and then process the file: shell> mysqlbinlog binlog.000001 >  \/tmp\/statements.sql\nshell> mysqlbinlog binlog.000002 >> \/tmp\/statements.sql\nshell> mysql -u root -p -e \"source \/tmp\/statements.sql\"\n mysqlbinlog can produce output that reproduces a LOAD DATA INFILE operation without the original data file. mysqlbinlog copies the data to a temporary file and writes a LOAD DATA LOCAL INFILE statement that refers to the file. The default location of the directory where these files are written is system-specific. To specify a directory explicitly, use the --local-load option. Because mysqlbinlog converts LOAD DATA INFILE statements to LOAD DATA LOCAL INFILE statements (that is, it adds LOCAL), both the client and the server that you use to process the statements must be configured with the LOCAL capability enabled. See Section 6.1.6, \"Security Issues with LOAD DATA LOCAL\". Warning The temporary files created for LOAD DATA LOCAL statements are not automatically deleted because they are needed until you actually execute those statements. You should delete the temporary files yourself after you no longer need the statement log. The files can be found in the temporary file directory and have names like original_file_name-#-#.","Process Name":"mysqlbinlog","Link":"https:\/\/linux.die.net\/man\/1\/mysqlbinlog"}},{"Process":{"Description":"This program enables you to generate a bug report and send it to Oracle Corporation. It is a shell script and runs on Unix. The normal way to report bugs is to visit http:\/\/bugs.mysql.com\/, which is the address for our bugs database. This database is public and can be browsed and searched by anyone. If you log in to the system, you can enter new reports. If you have no Web access, you can generate a bug report by using the mysqlbug script. mysqlbug helps you generate a report by determining much of the following information automatically, but if something important is missing, please include it with your message. mysqlbug can be found in the scripts directory (source distribution) and in the bin directory under your MySQL installation directory (binary distribution). Invoke mysqlbug without arguments: shell> mysqlbug\n The script will place you in an editor with a copy of the report to be sent. Edit the lines near the beginning that indicate the nature of the problem. Then write the file to save your changes, quit the editor, and mysqlbug will send the report by email.","Process Name":"mysqlbug","Link":"https:\/\/linux.die.net\/man\/1\/mysqlbug"}},{"Process":{"Description":"The mysqlcheck client performs table maintenance: It checks, repairs, optimizes, or analyzes tables. Each table is locked and therefore unavailable to other sessions while it is being processed, although for check operations, the table is locked with a READ lock only (see Section 13.3.5, \"LOCK TABLES and UNLOCK TABLES Syntax\", for more information about READ and WRITE locks). Table maintenance operations can be time-consuming, particularly for large tables. If you use the --databases or --all-databases option to process all tables in one or more databases, an invocation of mysqlcheck might take a long time. (This is also true for mysql_upgrade because that program invokes mysqlcheck to check all tables and repair them if necessary.) mysqlcheck is similar in function to myisamchk, but works differently. The main operational difference is that mysqlcheck must be used when the mysqld server is running, whereas myisamchk should be used when it is not. The benefit of using mysqlcheck is that you do not have to stop the server to perform table maintenance. mysqlcheck uses the SQL statements CHECK TABLE, REPAIR TABLE, ANALYZE TABLE, and OPTIMIZE TABLE in a convenient way for the user. It determines which statements to use for the operation you want to perform, and then sends the statements to the server to be executed. For details about which storage engines each statement works with, see the descriptions for those statements in Section 13.7.2, \"Table Maintenance Statements\". The MyISAM storage engine supports all four maintenance operations, so mysqlcheck can be used to perform any of them on MyISAM tables. Other storage engines do not necessarily support all operations. In such cases, an error message is displayed. For example, if test.t is a MEMORY table, an attempt to check it produces this result: shell> mysqlcheck test t\ntest.t\nnote     : The storage engine for the table doesn't support check If mysqlcheck is unable to repair a table, see Section 2.13.4, \"Rebuilding or Repairing Tables or Indexes\" for manual table repair strategies. This will be the case, for example, for InnoDB tables, which can be checked with CHECK TABLE, but not repaired with REPAIR TABLE. The use of mysqlcheck with partitioned tables is not supported before MySQL 5.1.27. Caution It is best to make a backup of a table before performing a table repair operation; under some circumstances the operation might cause data loss. Possible causes include but are not limited to file system errors. There are three general ways to invoke mysqlcheck: shell> mysqlcheck [options] db_name [tbl_name ...]\nshell> mysqlcheck [options] --databases db_name ...\nshell> mysqlcheck [options] --all-databases\n If you do not name any tables following db_name or if you use the --databases or --all-databases option, entire databases are checked. mysqlcheck has a special feature compared to other client programs. The default behavior of checking tables (--check) can be changed by renaming the binary. If you want to have a tool that repairs tables by default, you should just make a copy of mysqlcheck named mysqlrepair, or make a symbolic link to mysqlcheck named mysqlrepair. If you invoke mysqlrepair, it repairs tables. The names shown in the following table can be used to change mysqlcheck default behavior. mysqlcheck supports the following options, which can be specified on the command line or in the [mysqlcheck] and [client] groups of an option file. mysqlcheck also supports the options for processing option files described at Section 4.2.3.4, \"Command-Line Options that Affect Option-File Handling\". \u2022 --help, -? Display a help message and exit. \u2022 --all-databases, -A Check all tables in all databases. This is the same as using the --databases option and naming all the databases on the command line. \u2022 --all-in-1, -1 Instead of issuing a statement for each table, execute a single statement for each database that names all the tables from that database to be processed. \u2022 --analyze, -a Analyze the tables. \u2022 --auto-repair If a checked table is corrupted, automatically fix it. Any necessary repairs are done after all tables have been checked. \u2022 --bind-address= ip_address On a computer having multiple network interfaces, this option can be used to select which interface is employed when connecting to the MySQL server. This option is supported only in the version of mysqlcheck that is supplied with MySQL Cluster, beginning with MySQL Cluster NDB 6.3.4. It is not available in standard MySQL 5.1 releases. \u2022 --character-sets-dir= path The directory where character sets are installed. See Section 10.5, \"Character Set Configuration\". \u2022 --check, -c Check the tables for errors. This is the default operation. \u2022 --check-only-changed, -C Check only tables that have changed since the last check or that have not been closed properly. \u2022 --check-upgrade, -g Invoke CHECK TABLE with the FOR UPGRADE option to check tables for incompatibilities with the current version of the server. This option automatically enables the --fix-db-names and --fix-table-names options. --check-upgrade was added in MySQL 5.1.7. \u2022 --compress Compress all information sent between the client and the server if both support compression. \u2022 --databases, -B Process all tables in the named databases. Normally, mysqlcheck treats the first name argument on the command line as a database name and following names as table names. With this option, it treats all name arguments as database names. \u2022 --debug[= debug_options ], -# [ debug_options ] Write a debugging log. A typical debug_options string is 'd:t:o,file_name'. The default is 'd:t:o'. \u2022 --debug-check Print some debugging information when the program exits. This option was added in MySQL 5.1.21. \u2022 --debug-info Print debugging information and memory and CPU usage statistics when the program exits. This option was added in MySQL 5.1.14. \u2022 --default-character-set= charset_name Use charset_name as the default character set. See Section 10.5, \"Character Set Configuration\". \u2022 --extended, -e If you are using this option to check tables, it ensures that they are 100% consistent but takes a long time. If you are using this option to repair tables, it runs an extended repair that may not only take a long time to execute, but may produce a lot of garbage rows also! \u2022 --fast, -F Check only tables that have not been closed properly. \u2022 --fix-db-names Convert database names to 5.1 format. Only database names that contain special characters are affected. This option was added in MySQL 5.1.7. \u2022 --fix-table-names Convert table names to 5.1 format. Only table names that contain special characters are affected. This option was added in MySQL 5.1.7. As of MySQL 5.1.23, this option also applies to views. \u2022 --force, -f Continue even if an SQL error occurs. \u2022 --host= host_name, -h host_name Connect to the MySQL server on the given host. \u2022 --medium-check, -m Do a check that is faster than an --extended operation. This finds only 99.99% of all errors, which should be good enough in most cases. \u2022 --optimize, -o Optimize the tables. \u2022 --password[= password ], -p[ password ] The password to use when connecting to the server. If you use the short option form (-p), you cannot have a space between the option and the password. If you omit the password value following the --password or -p option on the command line, mysqlcheck prompts for one. Specifying a password on the command line should be considered insecure. See Section 6.1.2.1, \"End-User Guidelines for Password Security\". You can use an option file to avoid giving the password on the command line. \u2022 --pipe, -W On Windows, connect to the server using a named pipe. This option applies only if the server supports named-pipe connections. \u2022 --port= port_num, -P port_num The TCP\/IP port number to use for the connection. \u2022 --protocol={TCP|SOCKET|PIPE|MEMORY} The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally would cause a protocol to be used other than the one you want. For details on the permissible values, see Section 4.2.2, \"Connecting to the MySQL Server\". \u2022 --quick, -q If you are using this option to check tables, it prevents the check from scanning the rows to check for incorrect links. This is the fastest check method. If you are using this option to repair tables, it tries to repair only the index tree. This is the fastest repair method. \u2022 --repair, -r Perform a repair that can fix almost anything except unique keys that are not unique. \u2022 --silent, -s Silent mode. Print only error messages. \u2022 --socket= path, -S path For connections to localhost, the Unix socket file to use, or, on Windows, the name of the named pipe to use. \u2022 --ssl* Options that begin with --ssl specify whether to connect to the server using SSL and indicate where to find SSL keys and certificates. See Section 6.3.6.4, \"SSL Command Options\". \u2022 --tables Override the --databases or -B option. All name arguments following the option are regarded as table names. \u2022 --use-frm For repair operations on MyISAM tables, get the table structure from the .frm file so that the table can be repaired even if the .MYI header is corrupted. \u2022 --user= user_name, -u user_name The MySQL user name to use when connecting to the server. \u2022 --verbose, -v Verbose mode. Print information about the various stages of program operation. \u2022 --version, -V Display version information and exit. \u2022 --write-binlog This option is enabled by default, so that ANALYZE TABLE, OPTIMIZE TABLE, and REPAIR TABLE statements generated by mysqlcheck are written to the binary log. Use --skip-write-binlog to cause NO_WRITE_TO_BINLOG to be added to the statements so that they are not logged. Use the --skip-write-binlog when these statements should not be sent to replication slaves or run when using the binary logs for recovery from backup. This option was added in MySQL 5.1.18.","Process Name":"mysqlcheck","Link":"https:\/\/linux.die.net\/man\/1\/mysqlcheck"}},{"Process":{"Description":"mysqld is the MySQL server. The following discussion covers these MySQL server configuration topics: \u2022 Startup options that the server supports \u2022 Server system variables \u2022 Server status variables \u2022 How to set the server SQL mode \u2022 The server shutdown process","Process Name":"mysqld","Link":"https:\/\/linux.die.net\/man\/1\/mysqld"}},{"Process":{"Description":"mysqld_multi is designed to manage several mysqld processes that listen for connections on different Unix socket files and TCP\/IP ports. It can start or stop servers, or report their current status. The MySQL Instance Manager is an alternative means of managing multiple servers (see mysqlmanager(8)). mysqld_multi searches for groups named [mysqldN] in my.cnf (or in the file named by the --config-file option). N can be any positive integer. This number is referred to in the following discussion as the option group number, or GNR. Group numbers distinguish option groups from one another and are used as arguments to mysqld_multi to specify which servers you want to start, stop, or obtain a status report for. Options listed in these groups are the same that you would use in the [mysqld] group used for starting mysqld. (See, for example, Section 2.12.1.2, \"Starting and Stopping MySQL Automatically\".) However, when using multiple servers, it is necessary that each one use its own value for options such as the Unix socket file and TCP\/IP port number. For more information on which options must be unique per server in a multiple-server environment, see Section 5.3, \"Running Multiple MySQL Instances on One Machine\". To invoke mysqld_multi, use the following syntax: shell> mysqld_multi [options] {start|stop|report} [GNR[,GNR] ...]\n start, stop, and report indicate which operation to perform. You can perform the designated operation for a single server or multiple servers, depending on the GNR list that follows the option name. If there is no list, mysqld_multi performs the operation for all servers in the option file. Each GNR value represents an option group number or range of group numbers. The value should be the number at the end of the group name in the option file. For example, the GNR for a group named [mysqld17] is 17. To specify a range of numbers, separate the first and last numbers by a dash. The GNR value 10-13 represents groups [mysqld10] through [mysqld13]. Multiple groups or group ranges can be specified on the command line, separated by commas. There must be no whitespace characters (spaces or tabs) in the GNR list; anything after a whitespace character is ignored. This command starts a single server using option group [mysqld17]: shell> mysqld_multi start 17\n This command stops several servers, using option groups [mysqld8] and [mysqld10] through [mysqld13]: shell> mysqld_multi stop 8,10-13\n For an example of how you might set up an option file, use this command: shell> mysqld_multi --example\n As of MySQL 5.1.18, mysqld_multi searches for option files as follows: \u2022 With --no-defaults, no option files are read. \u2022 With --defaults-file= file_name, only the named file is read. \u2022 Otherwise, option files in the standard list of locations are read, including any file named by the --defaults-extra-file= file_name option, if one is given. (If the option is given multiple times, the last value is used.) Before MySQL 5.1.18, the preceding options are not recognized. Files in the standard locations are read, and any file named by the --config-file= file_name option, if one is given. A file named by --config-file is read only for [mysqld N] option groups, not the [mysqld_multi] group. Option files read are searched for [mysqld_multi] and [mysqldN] option groups. The [mysqld_multi] group can be used for options to mysqld_multi itself. [mysqldN] groups can be used for options passed to specific mysqld instances. As of MySQL 5.1.35, the [mysqld] or [mysqld_safe] groups can be used for common options read by all instances of mysqld or mysqld_safe. You can specify a --defaults-file=file_name option to use a different configuration file for that instance, in which case the [mysqld] or [mysqld_safe] groups from that file will be used for that instance. Before MySQL 5.1.35, some versions of mysqld_multi pass the --no-defaults options to instances, so these techniques are inapplicable. mysqld_multi supports the following options. \u2022 --help Display a help message and exit. \u2022 --config-file= file_name As of MySQL 5.1.18, this option is deprecated. If given, it is treated the same way as --defaults-extra-file, described earlier. --config-file is removed in MySQL 5.5. Before MySQL 5.1.18, this option specifies the name of an extra option file. It affects where mysqld_multi looks for [mysqldN] option groups. Without this option, all options are read from the usual my.cnf file. The option does not affect where mysqld_multi reads its own options, which are always taken from the [mysqld_multi] group in the usual my.cnf file. \u2022 --example Display a sample option file. \u2022 --log= file_name Specify the name of the log file. If the file exists, log output is appended to it. \u2022 --mysqladmin= prog_name The mysqladmin binary to be used to stop servers. \u2022 --mysqld= prog_name The mysqld binary to be used. Note that you can specify mysqld_safe as the value for this option also. If you use mysqld_safe to start the server, you can include the mysqld or ledir options in the corresponding [mysqldN] option group. These options indicate the name of the server that mysqld_safe should start and the path name of the directory where the server is located. (See the descriptions for these options in mysqld_safe(1).) Example: [mysqld38]\nmysqld = mysqld-debug\nledir  = \/opt\/local\/mysql\/libexec \u2022 --no-log Print log information to stdout rather than to the log file. By default, output goes to the log file. \u2022 --password= password The password of the MySQL account to use when invoking mysqladmin. Note that the password value is not optional for this option, unlike for other MySQL programs. \u2022 --silent Silent mode; disable warnings. \u2022 --tcp-ip Connect to each MySQL server through the TCP\/IP port instead of the Unix socket file. (If a socket file is missing, the server might still be running, but accessible only through the TCP\/IP port.) By default, connections are made using the Unix socket file. This option affects stop and report operations. \u2022 --user= user_name The user name of the MySQL account to use when invoking mysqladmin. \u2022 --verbose Be more verbose. \u2022 --version Display version information and exit. Some notes about mysqld_multi: \u2022 Most important: Before using mysqld_multi be sure that you understand the meanings of the options that are passed to the mysqld servers and why you would want to have separate mysqld processes. Beware of the dangers of using multiple mysqld servers with the same data directory. Use separate data directories, unless you know what you are doing. Starting multiple servers with the same data directory does not give you extra performance in a threaded system. See Section 5.3, \"Running Multiple MySQL Instances on One Machine\". \u2022 Important Make sure that the data directory for each server is fully accessible to the Unix account that the specific mysqld process is started as. Do not use the Unix root account for this, unless you know what you are doing. See Section 6.1.5, \"How to Run MySQL as a Normal User\". \u2022 Make sure that the MySQL account used for stopping the mysqld servers (with the mysqladmin program) has the same user name and password for each server. Also, make sure that the account has the SHUTDOWN privilege. If the servers that you want to manage have different user names or passwords for the administrative accounts, you might want to create an account on each server that has the same user name and password. For example, you might set up a common multi_admin account by executing the following commands for each server: shell> mysql -u root -S \/tmp\/mysql.sock -p\nEnter password:\nmysql> GRANT SHUTDOWN ON *.*\n    -> TO 'multi_admin'@'localhost'  IDENTIFIED BY 'multipass';\n See Section 6.2, \"The MySQL Access Privilege System\". You have to do this for each mysqld server. Change the connection parameters appropriately when connecting to each one. Note that the host name part of the account name must permit you to connect as multi_admin from the host where you want to run mysqld_multi. \u2022 The Unix socket file and the TCP\/IP port number must be different for every mysqld. (Alternatively, if the host has multiple network addresses, you can use --bind-address to cause different servers to listen to different interfaces.) \u2022 The --pid-file option is very important if you are using mysqld_safe to start mysqld (for example, --mysqld=mysqld_safe) Every mysqld should have its own process ID file. The advantage of using mysqld_safe instead of mysqld is that mysqld_safe monitors its mysqld process and restarts it if the process terminates due to a signal sent using kill -9 or for other reasons, such as a segmentation fault. Please note that the mysqld_safe script might require that you start it from a certain place. This means that you might have to change location to a certain directory before running mysqld_multi. If you have problems starting, please see the mysqld_safe script. Check especially the lines: ----------------------------------------------------------------\nMY_PWD='pwd'\n# Check if we are starting this relative (for the binary release)\nif test -d $MY_PWD\/data\/mysql -a \\\n   -f .\/share\/mysql\/english\/errmsg.sys -a \\\n   -x .\/bin\/mysqld\n----------------------------------------------------------------\n The test performed by these lines should be successful, or you might encounter problems. See mysqld_safe(1). \u2022 You might want to use the --user option for mysqld, but to do this you need to run the mysqld_multi script as the Unix superuser (root). Having the option in the option file doesn't matter; you just get a warning if you are not the superuser and the mysqld processes are started under your own Unix account. The following example shows how you might set up an option file for use with mysqld_multi. The order in which the mysqld programs are started or stopped depends on the order in which they appear in the option file. Group numbers need not form an unbroken sequence. The first and fifth [mysqld N] groups were intentionally omitted from the example to illustrate that you can have \"gaps\" in the option file. This gives you more flexibility. # This file should probably be in your home dir (~\/.my.cnf)\n# or \/etc\/my.cnf\n# Version 2.1 by Jani Tolonen\n[mysqld_multi]\nmysqld     = \/usr\/local\/bin\/mysqld_safe\nmysqladmin = \/usr\/local\/bin\/mysqladmin\nuser       = multi_admin\npassword   = multipass\n[mysqld2]\nsocket     = \/tmp\/mysql.sock2\nport       = 3307\npid-file   = \/usr\/local\/mysql\/var2\/hostname.pid2\ndatadir    = \/usr\/local\/mysql\/var2\nlanguage   = \/usr\/local\/share\/mysql\/english\nuser       = john\n[mysqld3]\nsocket     = \/tmp\/mysql.sock3\nport       = 3308\npid-file   = \/usr\/local\/mysql\/var3\/hostname.pid3\ndatadir    = \/usr\/local\/mysql\/var3\nlanguage   = \/usr\/local\/share\/mysql\/swedish\nuser       = monty\n[mysqld4]\nsocket     = \/tmp\/mysql.sock4\nport       = 3309\npid-file   = \/usr\/local\/mysql\/var4\/hostname.pid4\ndatadir    = \/usr\/local\/mysql\/var4\nlanguage   = \/usr\/local\/share\/mysql\/estonia\nuser       = tonu\n[mysqld6]\nsocket     = \/tmp\/mysql.sock6\nport       = 3311\npid-file   = \/usr\/local\/mysql\/var6\/hostname.pid6\ndatadir    = \/usr\/local\/mysql\/var6\nlanguage   = \/usr\/local\/share\/mysql\/japanese\nuser       = jani See Section 4.2.3.3, \"Using Option Files\".","Process Name":"mysqld_multi","Link":"https:\/\/linux.die.net\/man\/1\/mysqld_multi"}},{"Process":{"Description":"mysqld_safe is the recommended way to start a mysqld server on Unix and NetWare. mysqld_safe adds some safety features such as restarting the server when an error occurs and logging runtime information to an error log file. Descriptions of error logging and NetWare-specific behaviors are given later in this section. Note In MySQL 5.1.20 (only), the default error logging behavior with mysqld_safe is to write errors to syslog on systems that support the logger program. This differs from the default behavior of writing an error log file for other versions. In 5.1.20, logging to syslog may fail to operate correctly in some cases; if so, use --skip-syslog to use the default log file or --log-error=file_name to specify a log file name explicitly. mysqld_safe tries to start an executable named mysqld. To override the default behavior and specify explicitly the name of the server you want to run, specify a --mysqld or --mysqld-version option to mysqld_safe. You can also use --ledir to indicate the directory where mysqld_safe should look for the server. Many of the options to mysqld_safe are the same as the options to mysqld. See Section 5.1.3, \"Server Command Options\". Options unknown to mysqld_safe are passed to mysqld if they are specified on the command line, but ignored if they are specified in the [mysqld_safe] group of an option file. See Section 4.2.3.3, \"Using Option Files\". mysqld_safe reads all options from the [mysqld], [server], and [mysqld_safe] sections in option files. For example, if you specify a [mysqld] section like this, mysqld_safe will find and use the --log-error option: [mysqld]\nlog-error=error.log For backward compatibility, mysqld_safe also reads [safe_mysqld] sections, although you should rename such sections to [mysqld_safe] in MySQL 5.1 installations. mysqld_safe supports the options in the following list. It also reads option files and supports the options for processing them described at Section 4.2.3.4, \"Command-Line Options that Affect Option-File Handling\". \u2022 --help Display a help message and exit. \u2022 --autoclose (NetWare only) On NetWare, mysqld_safe provides a screen presence. When you unload (shut down) the mysqld_safe NLM, the screen does not by default go away. Instead, it prompts for user input: *<NLM has terminated; Press any key to close the screen>* If you want NetWare to close the screen automatically instead, use the --autoclose option to mysqld_safe. \u2022 --basedir= path The path to the MySQL installation directory. \u2022 --core-file-size= size The size of the core file that mysqld should be able to create. The option value is passed to ulimit -c. \u2022 --datadir= path The path to the data directory. \u2022 --defaults-extra-file= path The name of an option file to be read in addition to the usual option files. This must be the first option on the command line if it is used. If the file does not exist or is otherwise inaccessible, the server will exit with an error. \u2022 --defaults-file= file_name The name of an option file to be read instead of the usual option files. This must be the first option on the command line if it is used. \u2022 --ledir= path If mysqld_safe cannot find the server, use this option to indicate the path name to the directory where the server is located. \u2022 --log-error= file_name Write the error log to the given file. See Section 5.2.2, \"The Error Log\". \u2022 --mysqld= prog_name The name of the server program (in the ledir directory) that you want to start. This option is needed if you use the MySQL binary distribution but have the data directory outside of the binary distribution. If mysqld_safe cannot find the server, use the --ledir option to indicate the path name to the directory where the server is located. \u2022 --mysqld-version= suffix This option is similar to the --mysqld option, but you specify only the suffix for the server program name. The basename is assumed to be mysqld. For example, if you use --mysqld-version=debug, mysqld_safe starts the mysqld-debug program in the ledir directory. If the argument to --mysqld-version is empty, mysqld_safe uses mysqld in the ledir directory. \u2022 --nice= priority Use the nice program to set the server's scheduling priority to the given value. \u2022 --no-defaults Do not read any option files. This must be the first option on the command line if it is used. \u2022 --open-files-limit= count The number of files that mysqld should be able to open. The option value is passed to ulimit -n. Note that you need to start mysqld_safe as root for this to work properly! \u2022 --pid-file= file_name The path name of the process ID file. \u2022 --port= port_num The port number that the server should use when listening for TCP\/IP connections. The port number must be 1024 or higher unless the server is started by the root system user. \u2022 --skip-kill-mysqld Do not try to kill stray mysqld processes at startup. This option works only on Linux. \u2022 --socket= path The Unix socket file that the server should use when listening for local connections. \u2022 --syslog, --skip-syslog --syslog causes error messages to be sent to syslog on systems that support the logger program. --skip-syslog suppresses the use of syslog; messages are written to an error log file. These options were added in MySQL 5.1.20. When syslog is used, the daemon.err syslog priority\/facility is used for all log messages. \u2022 --syslog-tag= tag For logging to syslog, messages from mysqld_safe and mysqld are written with a tag of mysqld_safe and mysqld, respectively. To specify a suffix for the tag, use --syslog-tag=tag, which modifies the tags to be mysqld_safe-tag and mysqld-tag. This option was added in MySQL 5.1.21. \u2022 --timezone= timezone Set the TZ time zone environment variable to the given option value. Consult your operating system documentation for legal time zone specification formats. \u2022 --user={ user_name | user_id } Run the mysqld server as the user having the name user_name or the numeric user ID user_id. (\"User\" in this context refers to a system login account, not a MySQL user listed in the grant tables.) If you execute mysqld_safe with the --defaults-file or --defaults-extra-file option to name an option file, the option must be the first one given on the command line or the option file will not be used. For example, this command will not use the named option file: mysql> mysqld_safe --port=port_num --defaults-file=file_name\n Instead, use the following command: mysql> mysqld_safe --defaults-file=file_name --port=port_num\n The mysqld_safe script is written so that it normally can start a server that was installed from either a source or a binary distribution of MySQL, even though these types of distributions typically install the server in slightly different locations. (See Section 2.1.5, \"Installation Layouts\".) mysqld_safe expects one of the following conditions to be true: \u2022 The server and databases can be found relative to the working directory (the directory from which mysqld_safe is invoked). For binary distributions, mysqld_safe looks under its working directory for bin and data directories. For source distributions, it looks for libexec and var directories. This condition should be met if you execute mysqld_safe from your MySQL installation directory (for example, \/usr\/local\/mysql for a binary distribution). \u2022 If the server and databases cannot be found relative to the working directory, mysqld_safe attempts to locate them by absolute path names. Typical locations are \/usr\/local\/libexec and \/usr\/local\/var. The actual locations are determined from the values configured into the distribution at the time it was built. They should be correct if MySQL is installed in the location specified at configuration time. Because mysqld_safe tries to find the server and databases relative to its own working directory, you can install a binary distribution of MySQL anywhere, as long as you run mysqld_safe from the MySQL installation directory: shell> cd mysql_installation_directory\nshell> bin\/mysqld_safe &\n If mysqld_safe fails, even when invoked from the MySQL installation directory, you can specify the --ledir and --datadir options to indicate the directories in which the server and databases are located on your system. When you use mysqld_safe to start mysqld, mysqld_safe arranges for error (and notice) messages from itself and from mysqld to go to the same destination. As of MySQL 5.1.20, there are several mysqld_safe options for controlling the destination of these messages: \u2022 --syslog: Write error messages to syslog on systems that support the logger program. \u2022 --skip-syslog: Do not write error messages to syslog. Messages are written to the default error log file ( host_name.err in the data directory), or to a named file if the --log-error option is given. \u2022 --log-error= file_name: Write error messages to the named error file. If none of these options is given, the default is --skip-syslog. Note In MySQL 5.1.20 only, the default is --syslog. This differs from logging behavior for other versions of MySQL, for which the default is to write messages to the default error log file. If --syslog and --log-error are both given, a warning is issued and --log-error takes precedence. When mysqld_safe writes a message, notices go to the logging destination (syslog or the error log file) and stdout. Errors go to the logging destination and stderr. Before MySQL 5.1.20, error logging is controlled only with the --log-error option. If it is given, messages go to the named error file. Otherwise, messages go to the default error file. Normally, you should not edit the mysqld_safe script. Instead, configure mysqld_safe by using command-line options or options in the [mysqld_safe] section of a my.cnf option file. In rare cases, it might be necessary to edit mysqld_safe to get it to start the server properly. However, if you do this, your modified version of mysqld_safe might be overwritten if you upgrade MySQL in the future, so you should make a copy of your edited version that you can reinstall. On NetWare, mysqld_safe is a NetWare Loadable Module (NLM) that is ported from the original Unix shell script. It starts the server as follows: 1. Runs a number of system and option checks. 2. Runs a check on MyISAM tables. 3. Provides a screen presence for the MySQL server. 4. Starts mysqld, monitors it, and restarts it if it terminates in error. 5. Sends error messages from mysqld to the host_name.err file in the data directory. 6. Sends mysqld_safe screen output to the host_name.safe file in the data directory.","Process Name":"mysqld_safe","Link":"https:\/\/linux.die.net\/man\/1\/mysqld_safe"}},{"Process":{"Description":"mysqldbcompare - compare databases for consistency","Process Name":"mysqldbcompare","Link":"https:\/\/linux.die.net\/man\/1\/mysqldbcompare"}},{"Process":{"Description":"mysqldbcopy - copy databases from one server to another","Process Name":"mysqldbcopy","Link":"https:\/\/linux.die.net\/man\/1\/mysqldbcopy"}},{"Process":{"Description":"mysqldbexport - export metadata and data from databases","Process Name":"mysqldbexport","Link":"https:\/\/linux.die.net\/man\/1\/mysqldbexport"}},{"Process":{"Description":"mysqldbimport - import metadata and data from files","Process Name":"mysqldbimport","Link":"https:\/\/linux.die.net\/man\/1\/mysqldbimport"}},{"Process":{"Description":"mysqldiff - compare object definitions among objects where the difference is how db1.obj1 differs from db2.obj2","Process Name":"mysqldiff","Link":"https:\/\/linux.die.net\/man\/1\/mysqldiff"}},{"Process":{"Description":"mysqldiskusage - show disk usage for databases","Process Name":"mysqldiskusage","Link":"https:\/\/linux.die.net\/man\/1\/mysqldiskusage"}},{"Process":{"Description":"The mysqldump client is a backup program originally written by Igor Romanenko. It can be used to dump a database or a collection of databases for backup or transfer to another SQL server (not necessarily a MySQL server). The dump typically contains SQL statements to create the table, populate it, or both. However, mysqldump can also be used to generate files in CSV, other delimited text, or XML format. mysqldump requires at least the SELECT privilege for dumped tables, SHOW VIEW for dumped views, and LOCK TABLES if the --single-transaction option is not used. Certain options might require other privileges as noted in the option descriptions. If you are doing a backup on the server and your tables all are MyISAM tables, consider using the mysqlhotcopy instead because it can accomplish faster backups and faster restores. See mysqlhotcopy(1). There are three general ways to invoke mysqldump: shell> mysqldump [options] db_name [tbl_name ...]\nshell> mysqldump [options] --databases db_name ...\nshell> mysqldump [options] --all-databases\n If you do not name any tables following db_name or if you use the --databases or --all-databases option, entire databases are dumped. mysqldump does not dump the INFORMATION_SCHEMA database by default. As of MySQL 5.1.38, mysqldump dumps INFORMATION_SCHEMA if you name it explicitly on the command line, although you must also use the --skip-lock-tables option. Before 5.1.38, mysqldump silently ignores INFORMATION_SCHEMA even if you name it explicitly on the command line. Before MySQL 5.1.64, mysqldump does not dump the general_log or slow_query_log tables for dumps of the mysql database. As of 5.1.64, the dump includes statements to recreate those tables so that they are not missing after reloading the dump file. Log table contents are not dumped. In MySQL Cluster NDB 7.1.7 and later, the ndbinfo information database is ignored and not dumped by mysqldump. To see a list of the options your version of mysqldump supports, execute mysqldump --help. Some mysqldump options are shorthand for groups of other options: \u2022 Use of --opt is the same as specifying --add-drop-table, --add-locks, --create-options, --disable-keys, --extended-insert, --lock-tables, --quick, and --set-charset. All of the options that --opt stands for also are on by default because --opt is on by default. \u2022 Use of --compact is the same as specifying --skip-add-drop-table, --skip-add-locks, --skip-comments, --skip-disable-keys, and --skip-set-charset options. To reverse the effect of a group option, uses its --skip- xxx form ( --skip-opt or --skip-compact). It is also possible to select only part of the effect of a group option by following it with options that enable or disable specific features. Here are some examples: \u2022 To select the effect of --opt except for some features, use the --skip option for each feature. To disable extended inserts and memory buffering, use --opt --skip-extended-insert --skip-quick. (Actually, --skip-extended-insert --skip-quick is sufficient because --opt is on by default.) \u2022 To reverse --opt for all features except index disabling and table locking, use --skip-opt --disable-keys --lock-tables. When you selectively enable or disable the effect of a group option, order is important because options are processed first to last. For example, --disable-keys --lock-tables --skip-opt would not have the intended effect; it is the same as --skip-opt by itself. mysqldump can retrieve and dump table contents row by row, or it can retrieve the entire content from a table and buffer it in memory before dumping it. Buffering in memory can be a problem if you are dumping large tables. To dump tables row by row, use the --quick option (or --opt, which enables --quick). The --opt option (and hence --quick) is enabled by default, so to enable memory buffering, use --skip-quick. If you are using a recent version of mysqldump to generate a dump to be reloaded into a very old MySQL server, you should not use the --opt or --extended-insert option. Use --skip-opt instead. Note mysqldump from MySQL 5.1.21 cannot be used to create dumps from MySQL server 5.1.20 and older. This issue is fixed in MySQL 5.1.22. (Bug #30123) mysqldump supports the following options, which can be specified on the command line or in the [mysqldump] and [client] groups of an option file. mysqldump also supports the options for processing option files described at Section 4.2.3.4, \"Command-Line Options that Affect Option-File Handling\". \u2022 --help, -? Display a help message and exit. \u2022 --add-drop-database Add a DROP DATABASE statement before each CREATE DATABASE statement. This option is typically used in conjunction with the --all-databases or --databases option because no CREATE DATABASE statements are written unless one of those options is specified. \u2022 --add-drop-table Add a DROP TABLE statement before each CREATE TABLE statement. \u2022 --add-drop-trigger Add a DROP TRIGGER statement before each CREATE TRIGGER statement. Note This option is supported only by mysqldump as supplied with MySQL Cluster NDB 6.3.38, MySQL Cluster NDB 7.0.19, MySQL Cluster NDB 7.1.8, and later MySQL Cluster releases. It is not available when using MySQL 5.1. \u2022 --add-locks Surround each table dump with LOCK TABLES and UNLOCK TABLES statements. This results in faster inserts when the dump file is reloaded. See Section 8.3.2.1, \"Speed of INSERT Statements\". \u2022 --all-databases, -A Dump all tables in all databases. This is the same as using the --databases option and naming all the databases on the command line. \u2022 --all-tablespaces, -Y Adds to a table dump all SQL statements needed to create any tablespaces used by an NDBCLUSTER table. This information is not otherwise included in the output from mysqldump. This option is currently relevant only to MySQL Cluster tables. This option was added in MySQL 5.1.6. \u2022 --allow-keywords Permit creation of column names that are keywords. This works by prefixing each column name with the table name. \u2022 --bind-address=ip_address On a computer having multiple network interfaces, this option can be used to select which interface is employed when connecting to the MySQL server. This option is supported only in the version of mysqldump that is supplied with MySQL Cluster, beginning with MySQL Cluster NDB 6.3.4. It is not available in standard MySQL 5.1 releases. \u2022 --character-sets-dir=path The directory where character sets are installed. See Section 10.5, \"Character Set Configuration\". \u2022 --comments, -i Write additional information in the dump file such as program version, server version, and host. This option is enabled by default. To suppress this additional information, use --skip-comments. \u2022 --compact Produce more compact output. This option enables the --skip-add-drop-table, --skip-add-locks, --skip-comments, --skip-disable-keys, and --skip-set-charset options. Note Prior to MySQL 5.1.21, this option did not create valid SQL if the database dump contained views. The recreation of views requires the creation and removal of temporary tables and this option suppressed the removal of those temporary tables. As a workaround, use --compact with the --add-drop-table option and then manually adjust the dump file. \u2022 --compatible=name Produce output that is more compatible with other database systems or with older MySQL servers. The value of name can be ansi, mysql323, mysql40, postgresql, oracle, mssql, db2, maxdb, no_key_options, no_table_options, or no_field_options. To use several values, separate them by commas. These values have the same meaning as the corresponding options for setting the server SQL mode. See Section 5.1.7, \"Server SQL Modes\". This option does not guarantee compatibility with other servers. It only enables those SQL mode values that are currently available for making dump output more compatible. For example, --compatible=oracle does not map data types to Oracle types or use Oracle comment syntax. This option requires a server version of 4.1.0 or higher. With older servers, it does nothing. \u2022 --complete-insert, -c Use complete INSERT statements that include column names. \u2022 --compress, -C Compress all information sent between the client and the server if both support compression. \u2022 --create-options Include all MySQL-specific table options in the CREATE TABLE statements. \u2022 --databases, -B Dump several databases. Normally, mysqldump treats the first name argument on the command line as a database name and following names as table names. With this option, it treats all name arguments as database names. CREATE DATABASE and USE statements are included in the output before each new database. \u2022 --debug[=debug_options], -# [debug_options] Write a debugging log. A typical debug_options string is 'd:t:o,file_name'. The default value is 'd:t:o,\/tmp\/mysqldump.trace'. \u2022 --debug-check Print some debugging information when the program exits. This option was added in MySQL 5.1.21. \u2022 --debug-info Print debugging information and memory and CPU usage statistics when the program exits. This option was added in MySQL 5.1.14. \u2022 --default-character-set=charset_name Use charset_name as the default character set. See Section 10.5, \"Character Set Configuration\". If no character set is specified, mysqldump uses utf8, and earlier versions use latin1. Prior to MySQL 5.1.38, this option has no effect for output data files produced by using the --tab option. See the description for that option. \u2022 --delayed-insert Write INSERT DELAYED statements rather than INSERT statements. \u2022 --delete-master-logs On a master replication server, delete the binary logs by sending a PURGE BINARY LOGS statement to the server after performing the dump operation. This option automatically enables --master-data. \u2022 --disable-keys, -K For each table, surround the INSERT statements with \/*!40000 ALTER TABLE tbl_name DISABLE KEYS *\/; and \/*!40000 ALTER TABLE tbl_name ENABLE KEYS *\/; statements. This makes loading the dump file faster because the indexes are created after all rows are inserted. This option is effective only for nonunique indexes of MyISAM tables. It has no effect for other tables. \u2022 --dump-date If the --comments option is given, mysqldump produces a comment at the end of the dump of the following form: --  Dump completed on DATE\n However, the date causes dump files taken at different times to appear to be different, even if the data are otherwise identical. --dump-date and --skip-dump-date control whether the date is added to the comment. The default is --dump-date (include the date in the comment). --skip-dump-date suppresses date printing. This option was added in MySQL 5.1.23. \u2022 --events, -E Include Event Scheduler events for the dumped databases in the output. This option was added in MySQL 5.1.8. \u2022 --extended-insert, -e Use multiple-row INSERT syntax that include several VALUES lists. This results in a smaller dump file and speeds up inserts when the file is reloaded. \u2022 --fields-terminated-by=..., --fields-enclosed-by=..., --fields-optionally-enclosed-by=..., --fields-escaped-by=... These options are used with the --tab option and have the same meaning as the corresponding FIELDS clauses for LOAD DATA INFILE. See Section 13.2.6, \"LOAD DATA INFILE Syntax\". \u2022 --first-slave Deprecated. Use --lock-all-tables instead. --first-slave is removed in MySQL 5.5. \u2022 --flush-logs, -F Flush the MySQL server log files before starting the dump. This option requires the RELOAD privilege. If you use this option in combination with the --all-databases option, the logs are flushed for each database dumped. The exception is when using --lock-all-tables or --master-data: In this case, the logs are flushed only once, corresponding to the moment that all tables are locked. If you want your dump and the log flush to happen at exactly the same moment, you should use --flush-logs together with either --lock-all-tables or --master-data. \u2022 --flush-privileges Send a FLUSH PRIVILEGES statement to the server after dumping the mysql database. This option should be used any time the dump contains the mysql database and any other database that depends on the data in the mysql database for proper restoration. This option was added in MySQL 5.1.12. \u2022 --force, -f Continue even if an SQL error occurs during a table dump. One use for this option is to cause mysqldump to continue executing even when it encounters a view that has become invalid because the definition refers to a table that has been dropped. Without --force, mysqldump exits with an error message. With --force, mysqldump prints the error message, but it also writes an SQL comment containing the view definition to the dump output and continues executing. \u2022 --host=host_name, -h host_name Dump data from the MySQL server on the given host. The default host is localhost. \u2022 --hex-blob Dump binary columns using hexadecimal notation (for example, 'abc' becomes 0x616263). The affected data types are BINARY, VARBINARY, the BLOB types, and BIT. \u2022 --ignore-table=db_name.tbl_name Do not dump the given table, which must be specified using both the database and table names. To ignore multiple tables, use this option multiple times. This option also can be used to ignore views. \u2022 --insert-ignore Write INSERT IGNORE statements rather than INSERT statements. \u2022 --lines-terminated-by=... This option is used with the --tab option and has the same meaning as the corresponding LINES clause for LOAD DATA INFILE. See Section 13.2.6, \"LOAD DATA INFILE Syntax\". \u2022 --lock-all-tables, -x Lock all tables across all databases. This is achieved by acquiring a global read lock for the duration of the whole dump. This option automatically turns off --single-transaction and --lock-tables. \u2022 --lock-tables, -l For each dumped database, lock all tables to be dumped before dumping them. The tables are locked with READ LOCAL to permit concurrent inserts in the case of MyISAM tables. For transactional tables such as InnoDB, --single-transaction is a much better option than --lock-tables because it does not need to lock the tables at all. Because --lock-tables locks tables for each database separately, this option does not guarantee that the tables in the dump file are logically consistent between databases. Tables in different databases may be dumped in completely different states. \u2022 --log-error=file_name Log warnings and errors by appending them to the named file. The default is to do no logging. This option was added in MySQL 5.1.18. \u2022 --master-data[=value] Use this option to dump a master replication server to produce a dump file that can be used to set up another server as a slave of the master. It causes the dump output to include a CHANGE MASTER TO statement that indicates the binary log coordinates (file name and position) of the dumped server. These are the master server coordinates from which the slave should start replicating after you load the dump file into the slave. If the option value is 2, the CHANGE MASTER TO statement is written as an SQL comment, and thus is informative only; it has no effect when the dump file is reloaded. If the option value is 1, the statement is not written as a comment and takes effect when the dump file is reloaded. If no option value is specified, the default value is 1. This option requires the RELOAD privilege and the binary log must be enabled. The --master-data option automatically turns off --lock-tables. It also turns on --lock-all-tables, unless --single-transaction also is specified, in which case, a global read lock is acquired only for a short time at the beginning of the dump (see the description for --single-transaction). In all cases, any action on logs happens at the exact moment of the dump. It is also possible to set up a slave by dumping an existing slave of the master. To do this, use the following procedure on the existing slave: 1. Stop the slave's SQL thread and get its current status: mysql> STOP SLAVE SQL_THREAD;\nmysql> SHOW SLAVE STATUS;\n 2. From the output of the SHOW SLAVE STATUS statement, the binary log coordinates of the master server from which the new slave should start replicating are the values of the Relay_Master_Log_File and Exec_Master_Log_Pos fields. Denote those values as file_name and file_pos. 3. Dump the slave server: shell> mysqldump --master-data=2 --all-databases > dumpfile\n Using --master-data=2 works only if binary logging has been enabled on the slave. Otherwise, mysqldump fails with the error Binlogging on server not active. In this case you must handle any locking issues in another manner, using one or more of --add-locks, --lock-tables, --lock-all-tables, or --single-transaction, as required by your application and environment. 4. Restart the slave: mysql> START SLAVE;\n 5. On the new slave, load the dump file: shell> mysql < dumpfile\n 6. On the new slave, set the replication coordinates to those of the master server obtained earlier: mysql> CHANGE MASTER TO\n    -> MASTER_LOG_FILE = ' file_name', MASTER_LOG_POS = file_pos;\n The CHANGE MASTER TO statement might also need other parameters, such as MASTER_HOST to point the slave to the correct master server host. Add any such parameters as necessary. \u2022 --no-autocommit Enclose the INSERT statements for each dumped table within SET autocommit = 0 and COMMIT statements. \u2022 --no-create-db, -n This option suppresses the CREATE DATABASE statements that are otherwise included in the output if the --databases or --all-databases option is given. \u2022 --no-create-info, -t Do not write CREATE TABLE statements that re-create each dumped table. Note This option does not not exclude statements creating log file groups or tablespaces from mysqldump output; in MySQL 5.1.14 and later, you can use the --no-tablespaces option for this purpose. \u2022 --no-data, -d Do not write any table row information (that is, do not dump table contents). This is useful if you want to dump only the CREATE TABLE statement for the table (for example, to create an empty copy of the table by loading the dump file). \u2022 --no-set-names, -N This has the same effect as --skip-set-charset. \u2022 --no-tablespaces, -y This option suppresses all CREATE LOGFILE GROUP and CREATE TABLESPACE statements in the output of mysqldump. This option was added in MySQL 5.1.14. \u2022 --opt This option is shorthand. It is the same as specifying --add-drop-table --add-locks --create-options --disable-keys --extended-insert --lock-tables --quick --set-charset. It should give you a fast dump operation and produce a dump file that can be reloaded into a MySQL server quickly. The --opt option is enabled by default. Use --skip-opt to disable it. See the discussion at the beginning of this section for information about selectively enabling or disabling a subset of the options affected by --opt. \u2022 --order-by-primary Dump each table's rows sorted by its primary key, or by its first unique index, if such an index exists. This is useful when dumping a MyISAM table to be loaded into an InnoDB table, but will make the dump operation take considerably longer. \u2022 --password[=password], -p[password] The password to use when connecting to the server. If you use the short option form (-p), you cannot have a space between the option and the password. If you omit the password value following the --password or -p option on the command line, mysqldump prompts for one. Specifying a password on the command line should be considered insecure. See Section 6.1.2.1, \"End-User Guidelines for Password Security\". You can use an option file to avoid giving the password on the command line. \u2022 --pipe, -W On Windows, connect to the server using a named pipe. This option applies only if the server supports named-pipe connections. \u2022 --port=port_num, -P port_num The TCP\/IP port number to use for the connection. \u2022 --protocol={TCP|SOCKET|PIPE|MEMORY} The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally would cause a protocol to be used other than the one you want. For details on the permissible values, see Section 4.2.2, \"Connecting to the MySQL Server\". \u2022 --quick, -q This option is useful for dumping large tables. It forces mysqldump to retrieve rows for a table from the server a row at a time rather than retrieving the entire row set and buffering it in memory before writing it out. \u2022 --quote-names, -Q Quote identifiers (such as database, table, and column names) within \"'\" characters. If the ANSI_QUOTES SQL mode is enabled, identifiers are quoted within \"\"\" characters. This option is enabled by default. It can be disabled with --skip-quote-names, but this option should be given after any option such as --compatible that may enable --quote-names. \u2022 --replace Write REPLACE statements rather than INSERT statements. This option was added in MySQL 5.1.3. \u2022 --result-file=file_name, -r file_name Direct output to a given file. This option should be used on Windows to prevent newline \"\\n\" characters from being converted to \"\\r\\n\" carriage return\/newline sequences. The result file is created and its previous contents overwritten, even if an error occurs while generating the dump. \u2022 --routines, -R Included stored routines (procedures and functions) for the dumped databases in the output. Use of this option requires the SELECT privilege for the mysql.proc table. The output generated by using --routines contains CREATE PROCEDURE and CREATE FUNCTION statements to re-create the routines. However, these statements do not include attributes such as the routine creation and modification timestamps. This means that when the routines are reloaded, they will be created with the timestamps equal to the reload time. If you require routines to be re-created with their original timestamp attributes, do not use --routines. Instead, dump and reload the contents of the mysql.proc table directly, using a MySQL account that has appropriate privileges for the mysql database. This option was added in MySQL 5.1.2. Before that, stored routines are not dumped. Routine DEFINER values are not dumped until MySQL 5.1.8. This means that before 5.1.8, when routines are reloaded, they will be created with the definer set to the reloading user. If you require routines to be re-created with their original definer, dump and load the contents of the mysql.proc table directly as described earlier. Prior to MySQL 5.1.62, this option had no effect when used together with the --xml option. (Bug #11760384, Bug #52792) \u2022 --set-charset Add SET NAMES default_character_set to the output. This option is enabled by default. To suppress the SET NAMES statement, use --skip-set-charset. \u2022 --single-transaction This option sends a START TRANSACTION SQL statement to the server before dumping data. It is useful only with transactional tables such as InnoDB, because then it dumps the consistent state of the database at the time when BEGIN was issued without blocking any applications. When using this option, you should keep in mind that only InnoDB tables are dumped in a consistent state. For example, any MyISAM or MEMORY tables dumped while using this option may still change state. While a --single-transaction dump is in process, to ensure a valid dump file (correct table contents and binary log coordinates), no other connection should use the following statements: ALTER TABLE, CREATE TABLE, DROP TABLE, RENAME TABLE, TRUNCATE TABLE. A consistent read is not isolated from those statements, so use of them on a table to be dumped can cause the SELECT that is performed by mysqldump to retrieve the table contents to obtain incorrect contents or fail. The --single-transaction option and the --lock-tables option are mutually exclusive because LOCK TABLES causes any pending transactions to be committed implicitly. This option is not supported for MySQL Cluster tables; the results cannot be guaranteed to be consistent due to the fact that the NDBCLUSTER storage engine supports only the READ_COMMITTED transaction isolation level. You should always use NDB backup and restore instead. To dump large tables, you should combine the --single-transaction option with --quick. \u2022 --skip-comments See the description for the --comments option. \u2022 --skip-opt See the description for the --opt option. \u2022 --socket=path, -S path For connections to localhost, the Unix socket file to use, or, on Windows, the name of the named pipe to use. \u2022 --ssl* Options that begin with --ssl specify whether to connect to the server using SSL and indicate where to find SSL keys and certificates. See Section 6.3.6.4, \"SSL Command Options\". \u2022 --tab=path, -T path Produce tab-separated text-format data files. For each dumped table, mysqldump creates a tbl_name.sql file that contains the CREATE TABLE statement that creates the table, and the server writes a tbl_name.txt file that contains its data. The option value is the directory in which to write the files. Note This option should be used only when mysqldump is run on the same machine as the mysqld server. You must have the FILE privilege, and the server must have permission to write files in the directory that you specify. By default, the .txt data files are formatted using tab characters between column values and a newline at the end of each line. The format can be specified explicitly using the --fields- xxx and --lines-terminated-by options. As of MySQL 5.1.38, column values are converted to the character set specified by the --default-character-set option. Prior to 5.1.38 or if no such option is present, values are dumped using the binary character set. In effect, there is no character set conversion. If a table contains columns in several character sets, the output data file will as well and you may not be able to reload the file correctly. \u2022 --tables Override the --databases or -B option. mysqldump regards all name arguments following the option as table names. \u2022 --triggers Include triggers for each dumped table in the output. This option is enabled by default; disable it with --skip-triggers. \u2022 --tz-utc This option enables TIMESTAMP columns to be dumped and reloaded between servers in different time zones. mysqldump sets its connection time zone to UTC and adds SET TIME_ZONE='+00:00' to the dump file. Without this option, TIMESTAMP columns are dumped and reloaded in the time zones local to the source and destination servers, which can cause the values to change if the servers are in different time zones. --tz-utc also protects against changes due to daylight saving time. --tz-utc is enabled by default. To disable it, use --skip-tz-utc. This option was added in MySQL 5.1.2. \u2022 --user=user_name, -u user_name The MySQL user name to use when connecting to the server. \u2022 --verbose, -v Verbose mode. Print more information about what the program does. \u2022 --version, -V Display version information and exit. \u2022 --where=' where_condition' , -w ' where_condition' Dump only rows selected by the given WHERE condition. Quotes around the condition are mandatory if it contains spaces or other characters that are special to your command interpreter. Examples: --where=\"user='jimf'\"\n-w\"userid>1\"\n-w\"userid<1\"\n \u2022 --xml, -X Write dump output as well-formed XML. NULL, 'NULL', and Empty Values: For a column named column_name, the NULL value, an empty string, and the string value 'NULL' are distinguished from one another in the output generated by this option as follows. Beginning with MySQL 5.1.12, the output from the mysql client when run using the --xml option also follows the preceding rules. (See the section called \"MYSQL OPTIONS\".) Beginning with MySQL 5.1.18, XML output from mysqldump includes the XML namespace, as shown here: shell> mysqldump --xml -u root world City\n<?xml version=\"1.0\"?>\n<mysqldump xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\">\n<database name=\"world\">\n<table_structure name=\"City\">\n<field Field=\"ID\" Type=\"int(11)\" Null=\"NO\" Key=\"PRI\" Extra=\"auto_increment\" \/>\n<field Field=\"Name\" Type=\"char(35)\" Null=\"NO\" Key=\"\" Default=\"\" Extra=\"\" \/>\n<field Field=\"CountryCode\" Type=\"char(3)\" Null=\"NO\" Key=\"\" Default=\"\" Extra=\"\" \/>\n<field Field=\"District\" Type=\"char(20)\" Null=\"NO\" Key=\"\" Default=\"\" Extra=\"\" \/>\n<field Field=\"Population\" Type=\"int(11)\" Null=\"NO\" Key=\"\" Default=\"0\" Extra=\"\" \/>\n<key Table=\"City\" Non_unique=\"0\" Key_name=\"PRIMARY\" Seq_in_index=\"1\" Column_name=\"ID\"\nCollation=\"A\" Cardinality=\"4079\" Null=\"\" Index_type=\"BTREE\" Comment=\"\" \/>\n<options Name=\"City\" Engine=\"MyISAM\" Version=\"10\" Row_format=\"Fixed\" Rows=\"4079\"\nAvg_row_length=\"67\" Data_length=\"273293\" Max_data_length=\"18858823439613951\"\nIndex_length=\"43008\" Data_free=\"0\" Auto_increment=\"4080\"\nCreate_time=\"2007-03-31 01:47:01\" Update_time=\"2007-03-31 01:47:02\"\nCollation=\"latin1_swedish_ci\" Create_options=\"\" Comment=\"\" \/>\n<\/table_structure>\n<table_data name=\"City\">\n<row>\n<field name=\"ID\">1<\/field>\n<field name=\"Name\">Kabul<\/field>\n<field name=\"CountryCode\">AFG<\/field>\n<field name=\"District\">Kabol<\/field>\n<field name=\"Population\">1780000<\/field>\n<\/row>\n...\n<row>\n<field name=\"ID\">4079<\/field>\n<field name=\"Name\">Rafah<\/field>\n<field name=\"CountryCode\">PSE<\/field>\n<field name=\"District\">Rafah<\/field>\n<field name=\"Population\">92020<\/field>\n<\/row>\n<\/table_data>\n<\/database>\n<\/mysqldump>\n Prior to MySQL 5.1.62, this option prevented the --routines option from working correctly-that is, no stored routines, triggers, or events could be dumped in XML format. (Bug #11760384, Bug #52792) You can also set the following variables by using --var_name=value syntax: \u2022 max_allowed_packet The maximum size of the buffer for client\/server communication. The maximum is 1GB. \u2022 net_buffer_length The initial size of the buffer for client\/server communication. When creating multiple-row INSERT statements (as with the --extended-insert or --opt option), mysqldump creates rows up to net_buffer_length length. If you increase this variable, you should also ensure that the net_buffer_length variable in the MySQL server is at least this large. A common use of mysqldump is for making a backup of an entire database: shell> mysqldump db_name > backup-file.sql\n You can load the dump file back into the server like this: shell> mysql db_name < backup-file.sql\n Or like this: shell> mysql -e \"source \/path-to-backup\/backup-file.sql\" db_name\n mysqldump is also very useful for populating databases by copying data from one MySQL server to another: shell> mysqldump --opt db_name | mysql --host=remote_host -C db_name\n It is possible to dump several databases with one command: shell> mysqldump --databases db_name1 [db_name2 ...] > my_databases.sql\n To dump all databases, use the --all-databases option: shell> mysqldump --all-databases > all_databases.sql\n For InnoDB tables, mysqldump provides a way of making an online backup: shell> mysqldump --all-databases --single-transaction > all_databases.sql\n This backup acquires a global read lock on all tables (using FLUSH TABLES WITH READ LOCK) at the beginning of the dump. As soon as this lock has been acquired, the binary log coordinates are read and the lock is released. If long updating statements are running when the FLUSH statement is issued, the MySQL server may get stalled until those statements finish. After that, the dump becomes lock free and does not disturb reads and writes on the tables. If the update statements that the MySQL server receives are short (in terms of execution time), the initial lock period should not be noticeable, even with many updates. For point-in-time recovery (also known as \"roll-forward,\" when you need to restore an old backup and replay the changes that happened since that backup), it is often useful to rotate the binary log (see Section 5.2.4, \"The Binary Log\") or at least know the binary log coordinates to which the dump corresponds: shell> mysqldump --all-databases --master-data=2 > all_databases.sql\n Or: shell> mysqldump --all-databases --flush-logs --master-data=2\n              > all_databases.sql\n The --master-data and --single-transaction options can be used simultaneously, which provides a convenient way to make an online backup suitable for use prior to point-in-time recovery if tables are stored using the InnoDB storage engine. For more information on making backups, see Section 7.2, \"Database Backup Methods\", and Section 7.3, \"Example Backup and Recovery Strategy\". If you encounter problems backing up views, please read the section that covers restrictions on views which describes a workaround for backing up views when this fails due to insufficient privileges. See Section E.4, \"Restrictions on Views\".","Process Name":"mysqldump","Link":"https:\/\/linux.die.net\/man\/1\/mysqldump"}},{"Process":{"Description":"The MySQL slow query log contains information about queries that take a long time to execute (see Section 5.2.5, \"The Slow Query Log\"). mysqldumpslow parses MySQL slow query log files and prints a summary of their contents. Normally, mysqldumpslow groups queries that are similar except for the particular values of number and string data values. It \"abstracts\" these values to N and 'S' when displaying summary output. The -a and -n options can be used to modify value abstracting behavior. Invoke mysqldumpslow like this: shell> mysqldumpslow [options] [log_file ...]\n mysqldumpslow supports the following options. \u2022 --help Display a help message and exit. \u2022 -a Do not abstract all numbers to N and strings to 'S'. \u2022 --debug, -d Run in debug mode. \u2022 -g pattern Consider only queries that match the (grep-style) pattern. \u2022 -h host_name Host name of MySQL server for *-slow.log file name. The value can contain a wildcard. The default is * (match all). \u2022 -i name Name of server instance (if using mysql.server startup script). \u2022 -l Do not subtract lock time from total time. \u2022 -n N Abstract numbers with at least N digits within names. \u2022 -r Reverse the sort order. \u2022 -s sort_type How to sort the output. The value of sort_type should be chosen from the following list: \u2022 t, at: Sort by query time or average query time \u2022 l, al: Sort by lock time or average lock time \u2022 r, ar: Sort by rows sent or average rows sent \u2022 c: Sort by count By default, mysqldumpslow sorts by average query time (equivalent to -s at). \u2022 -t N Display only the first N queries in the output. \u2022 --verbose, -v Verbose mode. Print more information about what the program does. Example of usage: shell> mysqldumpslow\nReading mysql slow query log from \/usr\/local\/mysql\/data\/mysqld51-apple-slow.log\nCount: 1  Time=4.32s (4s)  Lock=0.00s (0s)  Rows=0.0 (0), root[root]@localhost\n insert into t2 select * from t1\nCount: 3  Time=2.53s (7s)  Lock=0.00s (0s)  Rows=0.0 (0), root[root]@localhost\n insert into t2 select * from t1 limit N\nCount: 3  Time=2.13s (6s)  Lock=0.00s (0s)  Rows=0.0 (0), root[root]@localhost\n insert into t1 select * from t1","Process Name":"mysqldumpslow","Link":"https:\/\/linux.die.net\/man\/1\/mysqldumpslow"}},{"Process":{"Description":"mysqlfailover - automatic replication health monitoring and failover","Process Name":"mysqlfailover","Link":"https:\/\/linux.die.net\/man\/1\/mysqlfailover"}},{"Process":{"Description":"mysqlhotcopy is a Perl script that was originally written and contributed by Tim Bunce. It uses FLUSH TABLES, LOCK TABLES, and cp or scp to make a database backup. It is a fast way to make a backup of the database or single tables, but it can be run only on the same machine where the database directories are located. mysqlhotcopy works only for backing up MyISAM and ARCHIVE tables. It runs on Unix and NetWare. To use mysqlhotcopy, you must have read access to the files for the tables that you are backing up, the SELECT privilege for those tables, the RELOAD privilege (to be able to execute FLUSH TABLES), and the LOCK TABLES privilege (to be able to lock the tables). shell> mysqlhotcopy db_name [\/path\/to\/new_directory]\n shell> mysqlhotcopy db_name_1 ... db_name_n \/path\/to\/new_directory\n Back up tables in the given database that match a regular expression: shell> mysqlhotcopy db_name.\/regex\/\n The regular expression for the table name can be negated by prefixing it with a tilde (\"~\"): shell> mysqlhotcopy db_name.\/~regex\/\n mysqlhotcopy supports the following options, which can be specified on the command line or in the [mysqlhotcopy] and [client] groups of an option file. For information about option files, see Section 4.2.3.3, \"Using Option Files\". \u2022 --help, -? Display a help message and exit. \u2022 --addtodest Do not rename target directory (if it exists); merely add files to it. \u2022 --allowold Do not abort if a target exists; rename it by adding an _old suffix. \u2022 --checkpoint= db_name . tbl_name Insert checkpoint entries into the specified database db_name and table tbl_name. \u2022 --chroot= path Base directory of the chroot jail in which mysqld operates. The path value should match that of the --chroot option given to mysqld. \u2022 --debug Enable debug output. \u2022 --dryrun, -n Report actions without performing them. \u2022 --flushlog Flush logs after all tables are locked. \u2022 --host= host_name, -h host_name The host name of the local host to use for making a TCP\/IP connection to the local server. By default, the connection is made to localhost using a Unix socket file. \u2022 --keepold Do not delete previous (renamed) target when done. \u2022 --method= command The method for copying files (cp or scp). The default is cp. \u2022 --noindices Do not include full index files for MyISAM tables in the backup. This makes the backup smaller and faster. The indexes for reloaded tables can be reconstructed later with myisamchk -rq. \u2022 --password= password, -p password The password to use when connecting to the server. The password value is not optional for this option, unlike for other MySQL programs. Specifying a password on the command line should be considered insecure. See Section 6.1.2.1, \"End-User Guidelines for Password Security\". You can use an option file to avoid giving the password on the command line. \u2022 --port= port_num, -P port_num The TCP\/IP port number to use when connecting to the local server. \u2022 --quiet, -q Be silent except for errors. \u2022 --record_log_pos= db_name . tbl_name Record master and slave status in the specified database db_name and table tbl_name. \u2022 --regexp= expr Copy all databases with names that match the given regular expression. \u2022 --resetmaster Reset the binary log after locking all the tables. \u2022 --resetslave Reset the master.info file after locking all the tables. \u2022 --socket= path, -S path The Unix socket file to use for connections to localhost. \u2022 --suffix= str The suffix to use for names of copied databases. \u2022 --tmpdir= path The temporary directory. The default is \/tmp. \u2022 --user= user_name, -u user_name The MySQL user name to use when connecting to the server. Use perldoc for additional mysqlhotcopy documentation, including information about the structure of the tables needed for the --checkpoint and --record_log_pos options: shell> perldoc mysqlhotcopy","Process Name":"mysqlhotcopy","Link":"https:\/\/linux.die.net\/man\/1\/mysqlhotcopy"}},{"Process":{"Description":"The mysqlimport client provides a command-line interface to the LOAD DATA INFILE SQL statement. Most options to mysqlimport correspond directly to clauses of LOAD DATA INFILE syntax. See Section 13.2.6, \"LOAD DATA INFILE Syntax\". Invoke mysqlimport like this: shell> mysqlimport [options] db_name textfile1 [textfile2 ...]\n For each text file named on the command line, mysqlimport strips any extension from the file name and uses the result to determine the name of the table into which to import the file's contents. For example, files named patient.txt, patient.text, and patient all would be imported into a table named patient. For additional information about mysqldump, see Section 7.4, \"Using mysqldump for Backups\". mysqlimport supports the following options, which can be specified on the command line or in the [mysqlimport] and [client] groups of an option file. mysqlimport also supports the options for processing option files described at Section 4.2.3.4, \"Command-Line Options that Affect Option-File Handling\". \u2022 --help, -? Display a help message and exit. \u2022 --bind-address= ip_address On a computer having multiple network interfaces, this option can be used to select which interface is employed when connecting to the MySQL server. This option is supported only in the version of mysqlimport that is supplied with MySQL Cluster, beginning with MySQL Cluster NDB 6.3.4. It is not available in standard MySQL 5.1 releases. \u2022 --character-sets-dir= path The directory where character sets are installed. See Section 10.5, \"Character Set Configuration\". \u2022 --columns= column_list, -c column_list This option takes a comma-separated list of column names as its value. The order of the column names indicates how to match data file columns with table columns. \u2022 --compress, -C Compress all information sent between the client and the server if both support compression. \u2022 --debug[= debug_options ], -# [ debug_options ] Write a debugging log. A typical debug_options string is 'd:t:o,file_name'. The default is 'd:t:o'. \u2022 --debug-check Print some debugging information when the program exits. This option was added in MySQL 5.1.21. \u2022 --debug-info Print debugging information and memory and CPU usage statistics when the program exits. This option was added in MySQL 5.1.14. \u2022 --default-character-set= charset_name Use charset_name as the default character set. See Section 10.5, \"Character Set Configuration\". \u2022 --delete, -D Empty the table before importing the text file. \u2022 --fields-terminated-by=..., --fields-enclosed-by=..., --fields-optionally-enclosed-by=..., --fields-escaped-by=... These options have the same meaning as the corresponding clauses for LOAD DATA INFILE. See Section 13.2.6, \"LOAD DATA INFILE Syntax\". \u2022 --force, -f Ignore errors. For example, if a table for a text file does not exist, continue processing any remaining files. Without --force, mysqlimport exits if a table does not exist. \u2022 --host= host_name, -h host_name Import data to the MySQL server on the given host. The default host is localhost. \u2022 --ignore, -i See the description for the --replace option. \u2022 --ignore-lines= N Ignore the first N lines of the data file. \u2022 --lines-terminated-by=... This option has the same meaning as the corresponding clause for LOAD DATA INFILE. For example, to import Windows files that have lines terminated with carriage return\/linefeed pairs, use --lines-terminated-by=\"\\r\\n\". (You might have to double the backslashes, depending on the escaping conventions of your command interpreter.) See Section 13.2.6, \"LOAD DATA INFILE Syntax\". \u2022 --local, -L Read input files locally from the client host. \u2022 --lock-tables, -l Lock all tables for writing before processing any text files. This ensures that all tables are synchronized on the server. \u2022 --low-priority Use LOW_PRIORITY when loading the table. This affects only storage engines that use only table-level locking (such as MyISAM, MEMORY, and MERGE). \u2022 --password[= password ], -p[ password ] The password to use when connecting to the server. If you use the short option form (-p), you cannot have a space between the option and the password. If you omit the password value following the --password or -p option on the command line, mysqlimport prompts for one. Specifying a password on the command line should be considered insecure. See Section 6.1.2.1, \"End-User Guidelines for Password Security\". You can use an option file to avoid giving the password on the command line. \u2022 --pipe, -W On Windows, connect to the server using a named pipe. This option applies only if the server supports named-pipe connections. \u2022 --port= port_num, -P port_num The TCP\/IP port number to use for the connection. \u2022 --protocol={TCP|SOCKET|PIPE|MEMORY} The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally would cause a protocol to be used other than the one you want. For details on the permissible values, see Section 4.2.2, \"Connecting to the MySQL Server\". \u2022 --replace, -r The --replace and --ignore options control handling of input rows that duplicate existing rows on unique key values. If you specify --replace, new rows replace existing rows that have the same unique key value. If you specify --ignore, input rows that duplicate an existing row on a unique key value are skipped. If you do not specify either option, an error occurs when a duplicate key value is found, and the rest of the text file is ignored. \u2022 --silent, -s Silent mode. Produce output only when errors occur. \u2022 --socket= path, -S path For connections to localhost, the Unix socket file to use, or, on Windows, the name of the named pipe to use. \u2022 --ssl* Options that begin with --ssl specify whether to connect to the server using SSL and indicate where to find SSL keys and certificates. See Section 6.3.6.4, \"SSL Command Options\". \u2022 --user= user_name, -u user_name The MySQL user name to use when connecting to the server. \u2022 --use-threads= N Load files in parallel using N threads. This option was added in MySQL 5.1.7. \u2022 --verbose, -v Verbose mode. Print more information about what the program does. \u2022 --version, -V Display version information and exit. Here is a sample session that demonstrates use of mysqlimport: shell> mysql -e 'CREATE TABLE imptest(id INT, n VARCHAR(30))' test\nshell> ed\na\n100     Max Sydow\n101     Count Dracula\n.\nw imptest.txt\n32\nq\nshell> od -c imptest.txt\n0000000   1   0   0  \\t   M   a   x       S   y   d   o   w  \\n   1   0\n0000020   1  \\t   C   o   u   n   t       D   r   a   c   u   l   a  \\n\n0000040\nshell> mysqlimport --local test imptest.txt\ntest.imptest: Records: 2  Deleted: 0  Skipped: 0  Warnings: 0\nshell> mysql -e 'SELECT * FROM imptest' test\n+------+---------------+\n| id   | n             |\n+------+---------------+\n|  100 | Max Sydow     |\n|  101 | Count Dracula |\n+------+---------------+","Process Name":"mysqlimport","Link":"https:\/\/linux.die.net\/man\/1\/mysqlimport"}},{"Process":{"Description":"mysqlindexcheck - check for duplicate or redundant indexes","Process Name":"mysqlindexcheck","Link":"https:\/\/linux.die.net\/man\/1\/mysqlindexcheck"}},{"Process":{"Description":"Certain executables distributed with the MySQL database management system do not have specific man pages.","Process Name":"mysqlman","Link":"https:\/\/linux.die.net\/man\/1\/mysqlman"}},{"Process":{"Description":"mysqlmetagrep - search metadata","Process Name":"mysqlmetagrep","Link":"https:\/\/linux.die.net\/man\/1\/mysqlmetagrep"}},{"Process":{"Description":"mysqlprocgrep - search process information","Process Name":"mysqlprocgrep","Link":"https:\/\/linux.die.net\/man\/1\/mysqlprocgrep"}},{"Process":{"Description":"mysqlreplicate - establish replication with a master","Process Name":"mysqlreplicate","Link":"https:\/\/linux.die.net\/man\/1\/mysqlreplicate"}},{"Process":{"Description":"mysqlrpladmin - administration utility for MySQL replication","Process Name":"mysqlrpladmin","Link":"https:\/\/linux.die.net\/man\/1\/mysqlrpladmin"}},{"Process":{"Description":"mysqlrplcheck - check replication","Process Name":"mysqlrplcheck","Link":"https:\/\/linux.die.net\/man\/1\/mysqlrplcheck"}},{"Process":{"Description":"mysqlrplshow - show slaves attached to a master","Process Name":"mysqlrplshow","Link":"https:\/\/linux.die.net\/man\/1\/mysqlrplshow"}},{"Process":{"Description":"mysqlserverclone - start another instance of a running server","Process Name":"mysqlserverclone","Link":"https:\/\/linux.die.net\/man\/1\/mysqlserverclone"}},{"Process":{"Description":"mysqlserverinfo - show server information","Process Name":"mysqlserverinfo","Link":"https:\/\/linux.die.net\/man\/1\/mysqlserverinfo"}},{"Process":{"Description":"The mysqlshow client can be used to quickly see which databases exist, their tables, or a table's columns or indexes. mysqlshow provides a command-line interface to several SQL SHOW statements. See Section 13.7.5, \"SHOW Syntax\". The same information can be obtained by using those statements directly. For example, you can issue them from the mysql client program. Invoke mysqlshow like this: shell> mysqlshow [options] [db_name [tbl_name [col_name]]]\n \u2022 If no database is given, a list of database names is shown. \u2022 If no table is given, all matching tables in the database are shown. \u2022 If no column is given, all matching columns and column types in the table are shown. The output displays only the names of those databases, tables, or columns for which you have some privileges. If the last argument contains shell or SQL wildcard characters (\"*\", \"?\", \"%\", or \"_\"), only those names that are matched by the wildcard are shown. If a database name contains any underscores, those should be escaped with a backslash (some Unix shells require two) to get a list of the proper tables or columns. \"*\" and \"?\" characters are converted into SQL \"%\" and \"_\" wildcard characters. This might cause some confusion when you try to display the columns for a table with a \"_\" in the name, because in this case, mysqlshow shows you only the table names that match the pattern. This is easily fixed by adding an extra \"%\" last on the command line as a separate argument. mysqlshow supports the following options, which can be specified on the command line or in the [mysqlshow] and [client] groups of an option file. mysqlshow also supports the options for processing option files described at Section 4.2.3.4, \"Command-Line Options that Affect Option-File Handling\". \u2022 --help, -? Display a help message and exit. \u2022 --bind-address= ip_address On a computer having multiple network interfaces, this option can be used to select which interface is employed when connecting to the MySQL server. This option is supported only in the version of mysqlshow that is supplied with MySQL Cluster, beginning with MySQL Cluster NDB 6.3.4. It is not available in standard MySQL 5.1 releases. \u2022 --character-sets-dir= path The directory where character sets are installed. See Section 10.5, \"Character Set Configuration\". \u2022 --compress, -C Compress all information sent between the client and the server if both support compression. \u2022 --count Show the number of rows per table. This can be slow for non-MyISAM tables. \u2022 --debug[= debug_options ], -# [ debug_options ] Write a debugging log. A typical debug_options string is 'd:t:o,file_name'. The default is 'd:t:o'. \u2022 --debug-check Print some debugging information when the program exits. This option was added in MySQL 5.1.21. \u2022 --debug-info Print debugging information and memory and CPU usage statistics when the program exits. This option was added in MySQL 5.1.14. \u2022 --default-character-set= charset_name Use charset_name as the default character set. See Section 10.5, \"Character Set Configuration\". \u2022 --host= host_name, -h host_name Connect to the MySQL server on the given host. \u2022 --keys, -k Show table indexes. \u2022 --password[= password ], -p[ password ] The password to use when connecting to the server. If you use the short option form (-p), you cannot have a space between the option and the password. If you omit the password value following the --password or -p option on the command line, mysqlshow prompts for one. Specifying a password on the command line should be considered insecure. See Section 6.1.2.1, \"End-User Guidelines for Password Security\". You can use an option file to avoid giving the password on the command line. \u2022 --pipe, -W On Windows, connect to the server using a named pipe. This option applies only if the server supports named-pipe connections. \u2022 --port= port_num, -P port_num The TCP\/IP port number to use for the connection. \u2022 --protocol={TCP|SOCKET|PIPE|MEMORY} The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally would cause a protocol to be used other than the one you want. For details on the permissible values, see Section 4.2.2, \"Connecting to the MySQL Server\". \u2022 --show-table-type, -t Show a column indicating the table type, as in SHOW FULL TABLES. The type is BASE TABLE or VIEW. \u2022 --socket= path, -S path For connections to localhost, the Unix socket file to use, or, on Windows, the name of the named pipe to use. \u2022 --ssl* Options that begin with --ssl specify whether to connect to the server using SSL and indicate where to find SSL keys and certificates. See Section 6.3.6.4, \"SSL Command Options\". \u2022 --status, -i Display extra information about each table. \u2022 --user= user_name, -u user_name The MySQL user name to use when connecting to the server. \u2022 --verbose, -v Verbose mode. Print more information about what the program does. This option can be used multiple times to increase the amount of information. \u2022 --version, -V Display version information and exit.","Process Name":"mysqlshow","Link":"https:\/\/linux.die.net\/man\/1\/mysqlshow"}},{"Process":{"Description":"mysqlslap is a diagnostic program designed to emulate client load for a MySQL server and to report the timing of each stage. It works as if multiple clients are accessing the server. mysqlslap is available as of MySQL 5.1.4. Invoke mysqlslap like this: shell> mysqlslap [options]\n Some options such as --create or --query enable you to specify a string containing an SQL statement or a file containing statements. If you specify a file, by default it must contain one statement per line. (That is, the implicit statement delimiter is the newline character.) Use the --delimiter option to specify a different delimiter, which enables you to specify statements that span multiple lines or place multiple statements on a single line. You cannot include comments in a file; mysqlslap does not understand them. mysqlslap runs in three stages: 1. Create schema, table, and optionally any stored programs or data to use for the test. This stage uses a single client connection. 2. Run the load test. This stage can use many client connections. 3. Clean up (disconnect, drop table if specified). This stage uses a single client connection. Examples: Supply your own create and query SQL statements, with 50 clients querying and 200 selects for each (enter the command on a single line): mysqlslap --delimiter=\";\"\n  --create=\"CREATE TABLE a (b int);INSERT INTO a VALUES (23)\"\n  --query=\"SELECT * FROM a\" --concurrency=50 --iterations=200 Let mysqlslap build the query SQL statement with a table of two INT columns and three VARCHAR columns. Use five clients querying 20 times each. Do not create the table or insert the data (that is, use the previous test's schema and data): mysqlslap --concurrency=5 --iterations=20\n  --number-int-cols=2 --number-char-cols=3\n  --auto-generate-sql Tell the program to load the create, insert, and query SQL statements from the specified files, where the create.sql file has multiple table creation statements delimited by ';' and multiple insert statements delimited by ';'. The --query file will have multiple queries delimited by ';'. Run all the load statements, then run all the queries in the query file with five clients (five times each): mysqlslap --concurrency=5\n  --iterations=5 --query=query.sql --create=create.sql\n  --delimiter=\";\" mysqlslap supports the following options, which can be specified on the command line or in the [mysqlslap] and [client] groups of an option file. mysqlslap also supports the options for processing option files described at Section 4.2.3.4, \"Command-Line Options that Affect Option-File Handling\". \u2022 --help, -? Display a help message and exit. \u2022 --auto-generate-sql, -a Generate SQL statements automatically when they are not supplied in files or using command options. \u2022 --auto-generate-sql-add-autoincrement Add an AUTO_INCREMENT column to automatically generated tables. This option was added in MySQL 5.1.18. \u2022 --auto-generate-sql-execute-number= N Specify how many queries to generate automatically. This option was added in MySQL 5.1.18. \u2022 --auto-generate-sql-guid-primary Add a GUID-based primary key to automatically generated tables. This option was added in MySQL 5.1.18. \u2022 --auto-generate-sql-load-type= type Specify the test load type. The permissible values are read (scan tables), write (insert into tables), key (read primary keys), update (update primary keys), or mixed (half inserts, half scanning selects). The default is mixed. This option was added in MySQL 5.1.16. \u2022 --auto-generate-sql-secondary-indexes= N Specify how many secondary indexes to add to automatically generated tables. By default, none are added. This option was added in MySQL 5.1.18. \u2022 --auto-generate-sql-unique-query-number= N How many different queries to generate for automatic tests. For example, if you run a key test that performs 1000 selects, you can use this option with a value of 1000 to run 1000 unique queries, or with a value of 50 to perform 50 different selects. The default is 10. This option was added in MySQL 5.1.18. \u2022 --auto-generate-sql-unique-write-number= N How many different queries to generate for --auto-generate-sql-write-number. The default is 10. This option was added in MySQL 5.1.18. \u2022 --auto-generate-sql-write-number= N How many row inserts to perform on each thread. The default is 100. This option was added in MySQL 5.1.16. \u2022 --commit= N How many statements to execute before committing. The default is 0 (no commits are done). This option was added in MySQL 5.1.21. \u2022 --compress, -C Compress all information sent between the client and the server if both support compression. \u2022 --concurrency= N, -c N The number of clients to simulate when issuing the SELECT statement. \u2022 --create= value The file or string containing the statement to use for creating the table. \u2022 --create-and-drop-schema= value The schema in which to run the tests. mysqlslap drops the schema at the end of the test run. This option was added in MySQL 5.1.57. \u2022 --create-schema= value The schema in which to run the tests. This option was added in MySQL 5.1.5. Note If the --auto-generate-sql option is also given, mysqlslap drops the schema at the end of the test run. To avoid this, use the --create-and-drop-schema option instead. \u2022 --csv[=file_name] Generate output in comma-separated values format. The output goes to the named file, or to the standard output if no file is given. This option was added in MySQL 5.1.5. \u2022 --debug[=debug_options], -# [debug_options] Write a debugging log. A typical debug_options string is 'd:t:o,file_name'. The default is 'd:t:o,\/tmp\/mysqlslap.trace'. \u2022 --debug-check Print some debugging information when the program exits. This option was added in MySQL 5.1.21. \u2022 --debug-info, -T Print debugging information and memory and CPU usage statistics when the program exits. This option was added in MySQL 5.1.21. \u2022 --delimiter=str, -F str The delimiter to use in SQL statements supplied in files or using command options. \u2022 --detach=N Detach (close and reopen) each connection after each N statements. The default is 0 (connections are not detached). This option was added in MySQL 5.1.21. \u2022 --engine=engine_name, -e engine_name The storage engine to use for creating tables. \u2022 --host=host_name, -h host_name Connect to the MySQL server on the given host. \u2022 --iterations=N, -i N The number of times to run the tests. \u2022 --lock-directory=path The directory to use for storing locks. This option was added in MySQL 5.1.5 and removed in 5.1.18. \u2022 --number-char-cols=N, -x N The number of VARCHAR columns to use if --auto-generate-sql is specified. \u2022 --number-int-cols=N, -y N The number of INT columns to use if --auto-generate-sql is specified. \u2022 --number-of-queries=N Limit each client to approximately this many queries. Query counting takes into account the statement delimiter. For example, if you invoke mysqlslap as follows, the ; delimiter is recognized so that each instance of the query string counts as two queries. As a result, 5 rows (not 10) are inserted. shell> mysqlslap --delimiter=\";\" --number-of-queries=10\n         --query=\"use test;insert into t values(null)\"\n This option was added in MySQL 5.1.5. \u2022 --only-print Do not connect to databases. mysqlslap only prints what it would have done. This option was added in MySQL 5.1.5. \u2022 --password[=password], -p[password] The password to use when connecting to the server. If you use the short option form (-p), you cannot have a space between the option and the password. If you omit the password value following the --password or -p option on the command line, mysqlslap prompts for one. Specifying a password on the command line should be considered insecure. See Section 6.1.2.1, \"End-User Guidelines for Password Security\". You can use an option file to avoid giving the password on the command line. \u2022 --pipe, -W On Windows, connect to the server using a named pipe. This option applies only if the server supports named-pipe connections. \u2022 --port=port_num, -P port_num The TCP\/IP port number to use for the connection. \u2022 --post-query=value The file or string containing the statement to execute after the tests have completed. This execution is not counted for timing purposes. This option was added in MySQL 5.1.18. \u2022 --shared-memory-base-name=name On Windows, the shared-memory name to use, for connections made using shared memory to a local server. This option applies only if the server supports shared-memory connections. \u2022 --post-system=str The string to execute using system() after the tests have completed. This execution is not counted for timing purposes. This option was added in MySQL 5.1.21. \u2022 --pre-query=value The file or string containing the statement to execute before running the tests. This execution is not counted for timing purposes. This option was added in MySQL 5.1.18. \u2022 --pre-system=str The string to execute using system() before running the tests. This execution is not counted for timing purposes. This option was added in MySQL 5.1.21. \u2022 --preserve-schema Preserve the schema from the mysqlslap run. The --auto-generate-sql and --create options disable this option. This option was added in MySQL 5.1.5 and removed in MySQL 5.1.23. \u2022 --protocol={TCP|SOCKET|PIPE|MEMORY} The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally would cause a protocol to be used other than the one you want. For details on the permissible values, see Section 4.2.2, \"Connecting to the MySQL Server\". \u2022 --query=value, -q value The file or string containing the SELECT statement to use for retrieving data. \u2022 --silent, -s Silent mode. No output. \u2022 --slave Follow master locks for other mysqlslap clients. Use this option if you are trying to synchronize around one master server with --lock-directory plus NFS. This option was added in MySQL 5.1.5 and removed in 5.1.18. \u2022 --socket=path, -S path For connections to localhost, the Unix socket file to use, or, on Windows, the name of the named pipe to use. \u2022 --ssl* Options that begin with --ssl specify whether to connect to the server using SSL and indicate where to find SSL keys and certificates. See Section 6.3.6.4, \"SSL Command Options\". \u2022 --use-threads On Unix, the default is to use fork() calls and this option causes pthread calls to be used instead. (On Windows, the default is to use pthread calls and the option has no effect.) This option was added in MySQL 5.1.6 and removed in 5.1.18. \u2022 --user=user_name, -u user_name The MySQL user name to use when connecting to the server. \u2022 --verbose, -v Verbose mode. Print more information about what the program does. This option can be used multiple times to increase the amount of information. \u2022 --version, -V Display version information and exit.","Process Name":"mysqlslap","Link":"https:\/\/linux.die.net\/man\/1\/mysqlslap"}},{"Process":{"Description":"The mysqltest program runs a test case against a MySQL server and optionally compares the output with a result file. This program reads input written in a special test language. Typically, you invoke mysqltest using mysql-test-run.pl rather than invoking it directly. mysqltest_embedded is similar but is built with support for the libmysqld embedded server. Features of mysqltest: \u2022 Can send SQL statements to MySQL servers for execution \u2022 Can execute external shell commands \u2022 Can test whether the result from an SQL statement or shell command is as expected \u2022 Can connect to one or more standalone mysqld servers and switch between connections \u2022 Can connect to an embedded server (libmysqld), if MySQL is compiled with support for libmysqld. (In this case, the executable is named mysqltest_embedded rather than mysqltest.) By default, mysqltest reads the test case on the standard input. To run mysqltest this way, you normally invoke it like this: shell> mysqltest [options] [db_name] < test_file\n You can also name the test case file with a --test-file= file_name option. The exit value from mysqltest is 0 for success, 1 for failure, and 62 if it skips the test case (for example, if after checking some preconditions it decides not to run the test). mysqltest supports the following options: \u2022 --help, -? Display a help message and exit. \u2022 --basedir= dir_name, -b dir_name The base directory for tests. \u2022 --character-sets-dir= path The directory where character sets are installed. \u2022 --compress, -C Compress all information sent between the client and the server if both support compression. \u2022 --cursor-protocol Use cursors for prepared statements. \u2022 --database= db_name, -D db_name The default database to use. \u2022 --debug[= debug_options ], -#[ debug_options ] Write a debugging log if MySQL is built with debugging support. The default debug_options value is 'd:t:S:i:O,\/tmp\/mysqltest.trace'. \u2022 --debug-check Print some debugging information when the program exits. \u2022 --debug-info Print debugging information and memory and CPU usage statistics when the program exits. \u2022 --host= host_name, -h host_name Connect to the MySQL server on the given host. \u2022 --include= file_name, -i file_name Include the contents of the given file before processing the contents of the test file. The included file should have the same format as other mysqltest test files. This option has the same effect as putting a --source file_name command as the first line of the test file. \u2022 --logdir= dir_name The directory to use for log files. \u2022 --mark-progress Write the line number and elapsed time to test_file.progress. \u2022 --max-connect-retries= num The maximum number of connection attempts when connecting to server. \u2022 --max-connections= num The maximum number of simultaneous server connections per client (that is, per test). If not set, the maximum is 128. Minimum allowed limit is 8, maximum is 5120. This option is available from MySQL 5.1.45. \u2022 --no-defaults Do not read default options from any option files. If used, this must be the first option. \u2022 --plugin-dir= path The directory in which to look for plugins. It may be necessary to specify this option if the default_auth argument is used for the connect() command to specify an authentication plugin but mysqltest does not find it. This option was added in MySQL 5.5.7. \u2022 --password[= password ], -p[ password ] The password to use when connecting to the server. If you use the short option form (-p), you cannot have a space between the option and the password. If you omit the password value following the --password or -p option on the command line, you are prompted for one. \u2022 --port= port_num, -P port_num The TCP\/IP port number to use for the connection. \u2022 --protocol={TCP|SOCKET|PIPE|MEMORY} Choose the protocol for communication with the server. SOCKET is default. The --protocol option is available from MySQL 5.1.51. It is ignored if running with the embedded server. \u2022 --ps-protocol Use the prepared-statement protocol for communication. \u2022 --quiet Suppress all normal output. This is a synonym for --silent. \u2022 --record, -r Record the output that results from running the test file into the file named by the --result-file option, if that option is given. It is an error to use this option without also using --result-file. \u2022 --result-file= file_name, -R file_name This option specifies the file for test case expected results. --result-file, together with --record, determines how mysqltest treats the test actual and expected results for a test case: \u2022 If the test produces no results, mysqltest exits with an error message to that effect, unless --result-file is given and the named file is an empty file. \u2022 Otherwise, if --result-file is not given, mysqltest sends test results to the standard output. \u2022 With --result-file but not --record, mysqltest reads the expected results from the given file and compares them with the actual results. If the results do not match, mysqltest writes a .reject file in the same directory as the result file, outputs a diff of the two files, and exits with an error. \u2022 With both --result-file and --record, mysqltest updates the given file by writing the actual test results to it. \u2022 --server-arg= value, -A value Pass the argument as an argument to the embedded server. For example, --server-arg=--tmpdir=\/tmp or --server-arg=--core. Up to 64 arguments can be given. \u2022 --server-file= file_name, -F file_name Read arguments for the embedded server from the given file. The file should contain one argument per line. \u2022 --server-public-key-path=file_name The path name to a file containing the server RSA public key. The file must be in PEM format. The public key is used for RSA encryption of the client password for connections to the server made using accounts that authenticate with the sha256_password plugin. This option is ignored for client accounts that do not authenticate with that plugin. It is also ignored if password encryption is not needed, as is the case when the client connects to the server using an SSL connection. The server sends the public key to the client as needed, so it is not necessary to use this option for RSA password encryption to occur. It is more efficient to do so because then the server need not send the key. For additional discussion regarding use of the sha256_password plugin, including how to get the RSA public key, see The SHA-256 Authentication Plugin [1] . This option is available only if MySQL was built using OpenSSL. It was added in MySQL 5.6.6 under the name --server-public-key and renamed in 5.6.7 to --server-public-key-path. \u2022 --silent, -s Suppress all normal output. \u2022 --skip-safemalloc Do not use memory allocation checking. \u2022 --sleep=num, -T num Cause all sleep commands in the test case file to sleep num seconds. This option does not affect real_sleep commands. As of MySQL 5.0.23, an option value of 0 can be used, which effectively disables sleep commands in the test case. \u2022 --socket=path, -S path The socket file to use when connecting to localhost (which is the default host). \u2022 --sp-protocol Execute DML statements within a stored procedure. For every DML statement, mysqltest creates and invokes a stored procedure that executes the statement rather than executing the statement directly. \u2022 --tail-lines=nn Specify how many lines of the result to include in the output if the test fails because an SQL statement fails. The default is 0, meaning no lines of result printed. \u2022 --test-file=file_name, -x file_name Read test input from this file. The default is to read from the standard input. \u2022 --timer-file=file_name, -m file_name If given, the number of millisecond spent running the test will be written to this file. This is used by mysql-test-run.pl for its reporting. \u2022 --tmpdir=dir_name, -t dir_name The temporary directory where socket files are created. \u2022 --user=user_name, -u user_name The MySQL user name to use when connecting to the server. \u2022 --verbose, -v Verbose mode. Print out more information about what the program does. \u2022 --version, -V Display version information and exit. \u2022 --view-protocol Every SELECT statement is wrapped inside a view. This option was added in MySQL 5.0.19.","Process Name":"mysqltest","Link":"https:\/\/linux.die.net\/man\/1\/mysqltest"}},{"Process":{"Description":"mysqluserclone - clone a MySQL user account to one or more new users","Process Name":"mysqluserclone","Link":"https:\/\/linux.die.net\/man\/1\/mysqluserclone"}},{"Process":{"Description":"Help is always welcome in improving this software. Feel free to contact the author (see \" AUTHOR \" below) with bug reports, fixes, suggestions, and comments. Additionally \" BUGS \" will provide a list of things this software is not able to do yet. Having said that, here are the details on how it works and what you can do with it. The Basics mytop was inspired by the system monitoring tool top. I routinely use top on Linux, FreeBSD, and Solaris. You are likely to notice features from each of them here. mytop will connect to a MySQL server and periodically run the SHOW PROCESSLIST and SHOW GLOBAL STATUS commands and attempt to summarize the information from them in a useful format. The Display The mytop display screen is really broken into two parts. The top 4 lines (header) contain summary information about your MySQL server. For example, you might see something like: MySQL on localhost (4.0.13-log) up 1+11:13:00 [23:29:11] Queries: 19.3M qps: 160 Slow: 1.0 Se\/In\/Up\/De(%): 00\/80\/03\/17 qps now: 219 Slow qps: 0.0 Threads: 1 ( 1\/ 16) 00\/74\/00\/25 Key Efficiency: 99.3% Bps in\/out: 30.5k\/162.8 Now in\/out: 32.7k\/ 3.3k The first line identifies the hostname of the server (localhost) and the version of MySQL it is running. The right had side shows the uptime of the MySQL server process in days+hours:minutes:seconds format (much like FreeBSD's top) as well as the current time. The second line displays the total number of queries the server has processed, the average number of queries per second, the number of slow queries, and the percentage of Select, Insert, Update, and Delete queries. The third real-time values. First is the number of queries per second, then the number of slow queries, followed by query precentages (like on the previous line). And the fourth line displays key buffer efficiency (how often keys are read from the buffer rather than disk) and the number of bytes that MySQL has sent and received, both over all and in the last cycle. You can toggle the header by hitting h when running mytop. The second part of the display lists as many threads as can fit on screen. By default they are sorted according to their idle time (least idle first). The display looks like: Id     User       Host      Dbase   Time      Cmd Query or State\n--     ----       ----      -----   ----      --- --------------\n61  jzawodn  localhost      music      0    Query show processlist As you can see, the thread id, username, host from which the user is connecting, database to which the user is connected, number of seconds of idle time, the command the thread is executing, and the query info are all displayed. Often times the query info is what you are really interested in, so it is good to run mytop in an xterm that is wider than the normal 80 columns if possible. The thread display color-codes the threads if you have installed color support. The current color scheme only works well in a window with a dark (like black) background. The colors are selected according to the \"Command\" column of the display: Query   -  Yellow\nSleep   -  White\nConnect -  Green Those are purely arbitrary and will be customizable in a future release. If they annoy you just start mytop with the -nocolor flag or adjust your config file appropriately. Arguments mytop handles long and short command-line arguments. Not all options have both long and short formats, however. The long arguments can start with one or two dashes '-' or '--'. They are shown here with just one. -u or -user username Username to use when logging in to the MySQL server. Default: ''root''. -p or -pass or -password password Password to use when logging in to the MySQL server. Default: none. -h or -host hostname[:port] Hostname of the MySQL server. The hostname may be followed by an option port number. Note that the port is specified separate from the host when using a config file. Default: ''localhost''. -port or -P port If you're running MySQL on a non-standard port, use this to specify the port number. Default: 3306. -s or -delay seconds How long between display refreshes. Default: 5 -d or -db or -database database Use if you'd like mytop to connect to a specific database by default. Default: ''test''. -b or -batch or -batchmode In batch mode, mytop runs only once, does not clear the screen, and places no limit on the number of lines it will print. This is suitable for running periodically (perhaps from cron) to capture the information into a file for later viewing. You might use batch mode in a CGI script to occasionally display your MySQL server status on the web. Default: unset. -S or -socket \/path\/to\/socket If you're running mytop on the same host as MySQL, you may wish to have it use the MySQL socket directly rather than a standard TCP\/IP connection. If you do,just specify one. Note that specifying a socket will make mytop ignore any host and\/or port that you might have specified. If the socket does not exist (or the file specified is not a socket), this option will be ignored and mytop will use the hostname and port number instead. Default: none. -header or -noheader Sepcify if you want the header to display or not. You can toggle this with the h key while mytop is running. Default: header. -color or -nocolor Specify if you want a color display. This has no effect if you don't have color support available. Default: If you have color support, mytop will try color unless you tell it not to. -i or -idle or -noidle Specify if you want idle (sleeping) threads to appear in the list. If sleeping threads are omitted, the default sorting order is reversed so that the longest running queries appear at the top of the list. Default: idle. -prompt or -noprompt Specify if you want to be prompted to type in your database password. This provides a little bit more security since it not only prevents the password from viewable in a process list, but also doesn't require the password to be stored in plain text in your ~\/.mytop config file. You will only be prompted if a password has not been specified in your config file or through another command line option. Default: noprompt. -resolve If you have skip-resolve set on MySQL (to keep it from doing a reverse DNS lookup on each inbound connection), mytop can replace IP addresses with hostnames but toggling this option. Default: noresolve Command-line arguments will always take precedence over config file options. That happens because the config file is read BEFORE the command-line arguments are applied. Config File Instead of always using bulky command-line parameters, you can also use a config file in your home directory ( \"~\/.mytop\"). If present, mytop will read it automatically. It is read before any of your command-line arguments are processed, so your command-line arguments will override directives in the config file. Here is a sample config file \"~\/.mytop\" which implements the defaults described above. user=root\npass=\nhost=localhost\ndb=test\ndelay=5\nport=3306\nsocket=\nbatchmode=0\nheader=1\ncolor=1\nidle=1 Using a config file will help to ensure that your database password isn't visible to users on the command-line. Just make sure that the permissions on \"~\/.mytop\" are such that others cannot read it (unless you want them to, of course). You may have white space on either side of the \"=\" in lines of the config file. Shortcut Keys The following keys perform various actions while mytop is running. Those which have not been implemented are listed as such. They are included to give the user idea of what is coming. ? Display help. c Show \"command counters\" based on the Com_* values in SHOW GLOBAL STATUS . This is a new feature. Feedback welcome. d Show only threads connected to a particular database. f Given a thread id, display the entire query that thread was (and still may be) running. F Disable all filtering (host, user, and db). h Only show queries from a particular host. H Toggle the header display. You can also specify either \"header=0\" or \"header=1\" in your config file to set the default behavior. i Toggle the display of idle (sleeping) threads. If sleeping threads are filtered, the default sorting order is reversed so that the longest running queries appear at the top of the list. I Switch to InnoDB Status mode. The output of \" SHOW INNODB STATUS \" will be displayed every cycle. In a future version, this may actually summarize that data rather than producing raw output. k Kill a thread. m Toggle modes. Currently this switches from 'top' mode to 'qps' (Queries Per Second Mode). In this mode, mytop will write out one integer per second. The number written reflects the number of queries executed by the server in the previous one second interval. More modes may be added in the future. o Reverse the default sort order. p Pause display. q Quit mytop r Reset the server's status counters via a FLUSH STATUS command. s Change the sleep time (number of seconds between display refreshes). u Show only threads owned by a giver user. The s key has a command-line counterpart: -s. The h key has two command-line counterparts: -header and -noheader.","Process Name":"mytop","Link":"https:\/\/linux.die.net\/man\/1\/mytop"}},{"Process":{"Description":"The mzip command is used to issue ZIP disk specific commands on Linux, Solaris or HPUX. Its syntax is: mzip [-epqrwx] Mzip allows the following command line options: e Ejects the disk. f Force eject even if the disk is mounted (must be given in addition to -e). r Write protect the disk. w Remove write protection. p Password write protect. x Password protect u Temporarily unprotect the disk until it is ejected. The disk becomes writable, and reverts back to its old state when ejected. q Queries the status To remove the password, set it to one of the passwordless modes -r or -w: mzip will then ask you for the password, and unlock the disk. If you have forgotten the password, you can get rid of it by low-level formatting the disk (using your SCSI adaptor's BIOS setup). The ZipTools disk shipped with the drive is also password protected. On Dos or on a Mac, this password is automatically removed once the ZipTools have been installed. From various articles posted to Usenet, I learned that the password for the tools disk is APlaceForYourStuff. Mzip knows about this password, and tries it first, before prompting you for a password. Thus mzip -w z: unlocks the tools disk. The tools disk is formatted in a special way so as to be usable both in a PC and in a Mac. On a PC, the Mac filesystem appears as a hidden file named 'partishn.mac'. You may erase it to reclaim the 50 Megs of space taken up by the Mac filesystem.","Process Name":"mzip","Link":"https:\/\/linux.die.net\/man\/1\/mzip"}}]