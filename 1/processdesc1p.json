[{"Process":{"Description":"p0f uses a fingerprinting technique based on analyzing the structure of a TCP\/IP packet to determine the operating system and other configuration properties of a remote host. The process is completely passive and does not generate any suspicious network traffic. The other host has to either: - connect to your network - either spontaneously or in an induced manner, for example when trying to establish a ftp data stream, returning a bounced mail, performing auth lookup, using IRC DCC, external html mail image reference and so on, - or be contacted by some entity on your network using some standard means (such as a web browsing); it can either accept or refuse the connection. The method can see thru packet firewalls and does not have the restrictions of an active fingerprinting. The main uses of passive OS fingerprinting are attacker profiling (IDS and honeypots), visitor profiling (content optimization), customer\/user profiling (policy enforcement), pen-testing, etc.","Process Name":"p0f","Link":"https:\/\/linux.die.net\/man\/1\/p0f"}},{"Process":{"Description":"P2BIN is a tool to convert the contents of one or several code files generated by AS into binary files. A binary file is a 1:1 memory image of the processor's memory and is especially suited for EPROM programmers and emulators. Arguments to P2BIN may be either command line parameters or file name specifications. Any argument that starts with the charactes +, - or \/ is regarded as a comand line parameter (which may take an additional command line argument); any other argument is regarded as a file name. Generally, P2BIN needs at least two file names: An input code file and the name of the binary output file. If multiple file names are given, P2BIN will always take the last name as the output file's name. If an input file name does not have an extension, the extension '.p' is added automatically. Similarly, the extension '.bin' is added automatically to the target file's name. A special case occurs when only one file name is given: P2BIN will then take its name as the source (possibly extended with '.p'), and the same name as target (with '.bin' as additional or replaced extension).","Process Name":"p2bin","Link":"https:\/\/linux.die.net\/man\/1\/p2bin"}},{"Process":{"Description":"P2HEX is a tool to convert the contents of one or several code files generated by AS into HEX files. A HEX file is a common method of representing binary data in a way that is human-readable and transferrable over non-transparent data lines. Generally spoken, each byte of code or data is represented by two characters that show the byte in its hexadecimal notation. A HEX file also contains additional information like addresses and checksums that ease processing of the data. Unfortunately, there is no generally accepted standard format for HEX files. Instead, every processor manufacturer developed his own format and some of them have become \"industry standards\". P2HEX supports all formats that seem to have gained acceptance, with some variations that are commonplace. Arguments to P2HEX may be either command line parameters or file name specifications. Any argument that starts with the charactes +, - or \/ is regarded as a comand line parameter (which may take an additional command line argument); any other argument is regarded as a file name. Generally, P2HEX needs at least two file names: An input code file and the name of the HEX output file. If multiple file names are given, P2HEX will always take the last name as the output file's name. If an input file name does not have an extension, the extension '.p' is added automatically. Similarly, the extension '.hex' is added automatically to the target file's name. A special case occurs when only one file name is given: P2HEX will then take its name as the source (possibly extended with '.p'), and the same name as target (with '.hex' as additional or replaced extension). By default, P2HEX will choose a HEX format that is the most common for the processor family a source file contains code for; this however means that if the source file(s) contain(s) code for different processor families, the HEX file might become an undesirable mixture of formats; use the -F command-line parameter to force a certain format then.","Process Name":"p2hex","Link":"https:\/\/linux.die.net\/man\/1\/p2hex"}},{"Process":{"Description":"pabrowse lists all PulseAudio sound servers on the local network that are being announced with Zeroconf\/Avahi. This program takes no command line arguments.","Process Name":"pabrowse","Link":"https:\/\/linux.die.net\/man\/1\/pabrowse"}},{"Process":{"Description":"pacat is a simple tool for playing back or capturing raw or encoded audio files on a PulseAudio sound server.","Process Name":"pacat","Link":"https:\/\/linux.die.net\/man\/1\/pacat"}},{"Process":{"Description":"The pack200 tool is a Java application that transforms a JAR file into a compressed pack200 file using the Java gzip compressor. The pack200 files are highly compressed files that can be directly deployed, saving bandwidth and reducing download time. The pack200 tool uses several options to fine-tune and set the compression engine. Typical usage: % pack200 myarchive.pack.gz myarchive.jar In this example, myarchive.pack.gz is produced using the default pack200 settings.","Process Name":"pack200-java-1.6.0-openjdk","Link":"https:\/\/linux.die.net\/man\/1\/pack200-java-1.6.0-openjdk"}},{"Process":{"Description":"The pack200 tool is a Java application that transforms a JAR file into a compressed pack200 file using the Java gzip compressor. The pack200 files are highly compressed files that can be directly deployed, saving bandwidth and reducing download time. The pack200 tool uses several options to fine-tune and set the compression engine. Typical usage: % pack200 myarchive.pack.gz myarchive.jar In this example, myarchive.pack.gz is produced using the default pack200 settings.","Process Name":"pack200-java-1.7.0-openjdk","Link":"https:\/\/linux.die.net\/man\/1\/pack200-java-1.7.0-openjdk"}},{"Process":{"Description":"The myisampack utility compresses MyISAM tables. myisampack works by compressing each column in the table separately. Usually, myisampack packs the data file 40% to 70%. When the table is used later, the server reads into memory the information needed to decompress columns. This results in much better performance when accessing individual rows, because you only have to uncompress exactly one row. MySQL uses mmap() when possible to perform memory mapping on compressed tables. If mmap() does not work, MySQL falls back to normal read\/write file operations. Please note the following: \u2022 If the mysqld server was invoked with external locking disabled, it is not a good idea to invoke myisampack if the table might be updated by the server during the packing process. It is safest to compress tables with the server stopped. \u2022 After packing a table, it becomes read only. This is generally intended (such as when accessing packed tables on a CD). Invoke myisampack like this: shell> myisampack [options] file_name ...\n Each file name argument should be the name of an index (.MYI) file. If you are not in the database directory, you should specify the path name to the file. It is permissible to omit the .MYI extension. After you compress a table with myisampack, you should use myisamchk -rq to rebuild its indexes. myisamchk(1). myisampack supports the following options. It also reads option files and supports the options for processing them described at Section 4.2.3.4, \"Command-Line Options that Affect Option-File Handling\". \u2022 --help, -? Display a help message and exit. \u2022 --backup, -b Make a backup of each table's data file using the name tbl_name.OLD. \u2022 --character-sets-dir= path The directory where character sets are installed. See Section 10.5, \"Character Set Configuration\". \u2022 --debug[= debug_options ], -# [ debug_options ] Write a debugging log. A typical debug_options string is 'd:t:o,file_name'. The default is 'd:t:o'. \u2022 --force, -f Produce a packed table even if it becomes larger than the original or if the intermediate file from an earlier invocation of myisampack exists. (myisampack creates an intermediate file named tbl_name.TMD in the database directory while it compresses the table. If you kill myisampack, the .TMD file might not be deleted.) Normally, myisampack exits with an error if it finds that tbl_name.TMD exists. With --force, myisampack packs the table anyway. \u2022 --join= big_tbl_name, -j big_tbl_name Join all tables named on the command line into a single packed table big_tbl_name. All tables that are to be combined must have identical structure (same column names and types, same indexes, and so forth). big_tbl_name must not exist prior to the join operation. All source tables named on the command line to be merged into big_tbl_name must exist. The source tables are read for the join operation but not modified. The join operation does not create a .frm file for big_tbl_name, so after the join operation finishes, copy the .frm file from one of the source tables and name it big_tbl_name.frm. \u2022 --silent, -s Silent mode. Write output only when errors occur. \u2022 --test, -t Do not actually pack the table, just test packing it. \u2022 --tmpdir= path, -T path Use the named directory as the location where myisampack creates temporary files. \u2022 --verbose, -v Verbose mode. Write information about the progress of the packing operation and its result. \u2022 --version, -V Display version information and exit. \u2022 --wait, -w Wait and retry if the table is in use. If the mysqld server was invoked with external locking disabled, it is not a good idea to invoke myisampack if the table might be updated by the server during the packing process. The following sequence of commands illustrates a typical table compression session: shell> ls -l station.*\n-rw-rw-r--   1 monty    my         994128 Apr 17 19:00 station.MYD\n-rw-rw-r--   1 monty    my          53248 Apr 17 19:00 station.MYI\n-rw-rw-r--   1 monty    my           5767 Apr 17 19:00 station.frm\nshell> myisamchk -dvv station\nMyISAM file:     station\nIsam-version:  2\nCreation time: 1996-03-13 10:08:58\nRecover time:  1997-02-02  3:06:43\nData records:              1192  Deleted blocks:              0\nDatafile parts:            1192  Deleted data:                0\nDatafile pointer (bytes):     2  Keyfile pointer (bytes):     2\nMax datafile length:   54657023  Max keyfile length:   33554431\nRecordlength:               834\nRecord format: Fixed length\ntable description:\nKey Start Len Index   Type                 Root  Blocksize    Rec\/key\n1   2     4   unique  unsigned long        1024       1024          1\n2   32    30  multip. text                10240       1024          1\nField Start Length Type\n1     1     1\n2     2     4\n3     6     4\n4     10    1\n5     11    20\n6     31    1\n7     32    30\n8     62    35\n9     97    35\n10    132   35\n11    167   4\n12    171   16\n13    187   35\n14    222   4\n15    226   16\n16    242   20\n17    262   20\n18    282   20\n19    302   30\n20    332   4\n21    336   4\n22    340   1\n23    341   8\n24    349   8\n25    357   8\n26    365   2\n27    367   2\n28    369   4\n29    373   4\n30    377   1\n31    378   2\n32    380   8\n33    388   4\n34    392   4\n35    396   4\n36    400   4\n37    404   1\n38    405   4\n39    409   4\n40    413   4\n41    417   4\n42    421   4\n43    425   4\n44    429   20\n45    449   30\n46    479   1\n47    480   1\n48    481   79\n49    560   79\n50    639   79\n51    718   79\n52    797   8\n53    805   1\n54    806   1\n55    807   20\n56    827   4\n57    831   4\nshell> myisampack station.MYI\nCompressing station.MYI: (1192 records)\n- Calculating statistics\nnormal:     20  empty-space:   16  empty-zero:     12  empty-fill:  11\npre-space:   0  end-space:     12  table-lookups:   5  zero:         7\nOriginal trees:  57  After join: 17\n- Compressing file\n87.14%\nRemember to run myisamchk -rq on compressed tables\nshell> ls -l station.*\n-rw-rw-r--   1 monty    my         127874 Apr 17 19:00 station.MYD\n-rw-rw-r--   1 monty    my          55296 Apr 17 19:04 station.MYI\n-rw-rw-r--   1 monty    my           5767 Apr 17 19:00 station.frm\nshell> myisamchk -dvv station\nMyISAM file:     station\nIsam-version:  2\nCreation time: 1996-03-13 10:08:58\nRecover time:  1997-04-17 19:04:26\nData records:               1192  Deleted blocks:              0\nDatafile parts:             1192  Deleted data:                0\nDatafile pointer (bytes):      3  Keyfile pointer (bytes):     1\nMax datafile length:    16777215  Max keyfile length:     131071\nRecordlength:                834\nRecord format: Compressed\ntable description:\nKey Start Len Index   Type                 Root  Blocksize    Rec\/key\n1   2     4   unique  unsigned long       10240       1024          1\n2   32    30  multip. text                54272       1024          1\nField Start Length Type                         Huff tree  Bits\n1     1     1      constant                             1     0\n2     2     4      zerofill(1)                          2     9\n3     6     4      no zeros, zerofill(1)                2     9\n4     10    1                                           3     9\n5     11    20     table-lookup                         4     0\n6     31    1                                           3     9\n7     32    30     no endspace, not_always              5     9\n8     62    35     no endspace, not_always, no empty    6     9\n9     97    35     no empty                             7     9\n10    132   35     no endspace, not_always, no empty    6     9\n11    167   4      zerofill(1)                          2     9\n12    171   16     no endspace, not_always, no empty    5     9\n13    187   35     no endspace, not_always, no empty    6     9\n14    222   4      zerofill(1)                          2     9\n15    226   16     no endspace, not_always, no empty    5     9\n16    242   20     no endspace, not_always              8     9\n17    262   20     no endspace, no empty                8     9\n18    282   20     no endspace, no empty                5     9\n19    302   30     no endspace, no empty                6     9\n20    332   4      always zero                          2     9\n21    336   4      always zero                          2     9\n22    340   1                                           3     9\n23    341   8      table-lookup                         9     0\n24    349   8      table-lookup                        10     0\n25    357   8      always zero                          2     9\n26    365   2                                           2     9\n27    367   2      no zeros, zerofill(1)                2     9\n28    369   4      no zeros, zerofill(1)                2     9\n29    373   4      table-lookup                        11     0\n30    377   1                                           3     9\n31    378   2      no zeros, zerofill(1)                2     9\n32    380   8      no zeros                             2     9\n33    388   4      always zero                          2     9\n34    392   4      table-lookup                        12     0\n35    396   4      no zeros, zerofill(1)               13     9\n36    400   4      no zeros, zerofill(1)                2     9\n37    404   1                                           2     9\n38    405   4      no zeros                             2     9\n39    409   4      always zero                          2     9\n40    413   4      no zeros                             2     9\n41    417   4      always zero                          2     9\n42    421   4      no zeros                             2     9\n43    425   4      always zero                          2     9\n44    429   20     no empty                             3     9\n45    449   30     no empty                             3     9\n46    479   1                                          14     4\n47    480   1                                          14     4\n48    481   79     no endspace, no empty               15     9\n49    560   79     no empty                             2     9\n50    639   79     no empty                             2     9\n51    718   79     no endspace                         16     9\n52    797   8      no empty                             2     9\n53    805   1                                          17     1\n54    806   1                                           3     9\n55    807   20     no empty                             3     9\n56    827   4      no zeros, zerofill(2)                2     9\n57    831   4      no zeros, zerofill(1)                2     9 myisampack displays the following kinds of information: \u2022 normal The number of columns for which no extra packing is used. \u2022 empty-space The number of columns containing values that are only spaces. These occupy one bit. \u2022 empty-zero The number of columns containing values that are only binary zeros. These occupy one bit. \u2022 empty-fill The number of integer columns that do not occupy the full byte range of their type. These are changed to a smaller type. For example, a BIGINT column (eight bytes) can be stored as a TINYINT column (one byte) if all its values are in the range from -128 to 127. \u2022 pre-space The number of decimal columns that are stored with leading spaces. In this case, each value contains a count for the number of leading spaces. \u2022 end-space The number of columns that have a lot of trailing spaces. In this case, each value contains a count for the number of trailing spaces. \u2022 table-lookup The column had only a small number of different values, which were converted to an ENUM before Huffman compression. \u2022 zero The number of columns for which all values are zero. \u2022 Original trees The initial number of Huffman trees. \u2022 After join The number of distinct Huffman trees left after joining trees to save some header space. After a table has been compressed, the Field lines displayed by myisamchk -dvv include additional information about each column: \u2022 Type The data type. The value may contain any of the following descriptors: \u2022 constant All rows have the same value. \u2022 no endspace Do not store endspace. \u2022 no endspace, not_always Do not store endspace and do not do endspace compression for all values. \u2022 no endspace, no empty Do not store endspace. Do not store empty values. \u2022 table-lookup The column was converted to an ENUM. \u2022 zerofill( N) The most significant N bytes in the value are always 0 and are not stored. \u2022 no zeros Do not store zeros. \u2022 always zero Zero values are stored using one bit. \u2022 Huff tree The number of the Huffman tree associated with the column. \u2022 Bits The number of bits used in the Huffman tree. After you run myisampack, you must run myisamchk to re-create any indexes. At this time, you can also sort the index blocks and create statistics needed for the MySQL optimizer to work more efficiently: shell> myisamchk -rq --sort-index --analyze tbl_name.MYI\n After you have installed the packed table into the MySQL database directory, you should execute mysqladmin flush-tables to force mysqld to start using the new table. To unpack a packed table, use the --unpack option to myisamchk.","Process Name":"pack_isam","Link":"https:\/\/linux.die.net\/man\/1\/pack_isam"}},{"Process":{"Description":null,"Process Name":"package-cleanup","Link":"https:\/\/linux.die.net\/man\/1\/package-cleanup"}},{"Process":{"Description":"Search through all the global variables in all packagse for any circular reference. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"packages.pl","Link":"https:\/\/linux.die.net\/man\/1\/packages.pl"}},{"Process":{"Description":"When called with no options in the root directory of the sources for a program, packer will ask for information neccessary to build a package. This information will be saved in the packer directory in the working directory. The user can call packer again with no options to make changes. Once packer has been run in this manner at least once, packer can be called with options.","Process Name":"packer","Link":"https:\/\/linux.die.net\/man\/1\/packer"}},{"Process":{"Description":null,"Process Name":"packetforge-ng","Link":"https:\/\/linux.die.net\/man\/1\/packetforge-ng"}},{"Process":{"Description":"Simulates a game of Pac-Man on a randomly-created level.","Process Name":"pacman","Link":"https:\/\/linux.die.net\/man\/1\/pacman"}},{"Process":{"Description":"This tool can be used to introspect or reconfigure a running PulseAudio sound server during runtime. It connects to the sound server and offers a simple live shell that can be used to enter the commands also understood in the default.pa configuration scripts. This program takes no command line options.","Process Name":"pacmd","Link":"https:\/\/linux.die.net\/man\/1\/pacmd"}},{"Process":{"Description":"pactl can be used to issue control commands to the PulseAudio sound server. pactl only exposes a subset of the available operations. For the full set use the pacmd(1).","Process Name":"pactl","Link":"https:\/\/linux.die.net\/man\/1\/pactl"}},{"Process":{"Description":"padsp starts the specified program and redirects its access to OSS compatible audio devices ( \/dev\/dsp and auxiliary devices) to a PulseAudio sound server. padsp uses the $LD_PRELOAD environment variable that is interpreted by ld.so(8) and thus does not work for SUID binaries and statically built executables. Equivalent to using padsp is starting an application with $LD_PRELOAD set to libpulsedsp.so","Process Name":"padsp","Link":"https:\/\/linux.die.net\/man\/1\/padsp"}},{"Process":{"Description":null,"Process Name":"pagesize","Link":"https:\/\/linux.die.net\/man\/1\/pagesize"}},{"Process":{"Description":"Starts a new subprocess that is detached from any Kerberos ticket cache and AFS tokens. Without command a new shell is started.","Process Name":"pagsh","Link":"https:\/\/linux.die.net\/man\/1\/pagsh"}},{"Process":{"Description":"pahole shows data structure layouts encoded in debugging information formats, DWARF and CTF being supported. This is useful for, among other things: optimizing important data structures by reducing its size, figuring out what is the field sitting at an offset from the start of a data structure, investigating ABI changes and more generally understanding a new codebase you have to work with. The files must have associated debugging information. This information may be inside the file itself, in ELF sections, or in another file. One way to have this information is to specify the -g option to the compiler when building it. When this is done the information will be stored in an ELF section. For the DWARF debugging information format this, adds, among others, the .debug_info ELF section. For CTF it is found in just one ELF section, .SUNW_ctf. The debuginfo packages available in most Linux distributions are also supported by pahole, where the debugging information is available in a separate file. By default, pahole shows the layout of all named structs in the files specified.","Process Name":"pahole","Link":"https:\/\/linux.die.net\/man\/1\/pahole"}},{"Process":{"Description":null,"Process Name":"pal2rgb","Link":"https:\/\/linux.die.net\/man\/1\/pal2rgb"}},{"Process":{"Description":"This program is part of Netpbm(1). palmtopnm reads a Palm Bitmap as input, from Standard Input or palmfile and produces a PPM image as output. Alternatively (when you specify -transparent), palmtopnm writes the value of the transparent color in the Palm Bitmap to Standard Output. Palmtopnm can convert Palm Bitmaps with the following features. This does not mean that it doesn't handle other features. These are just the ones we found worth mentioning. \u2022 Version 0 \u2022 Version 1 \u2022 Version 2 \u2022 Version 3 (new in Netpbm 10.27 (March 2005)) \u2022 Scanline compression \u2022 RLE compression \u2022 Packbits compression (new in Netpbm 10.27 (March 2005))","Process Name":"palmtopnm","Link":"https:\/\/linux.die.net\/man\/1\/palmtopnm"}},{"Process":{"Description":"pam-panel-icon should be automatically started when starting an X11 desktop environment. For example, in GNOME gnome-session should be configured to start pam-panel-icon. In a properly configured system it should never be necessary to start pam-panel-icon manually. pam-panel-icon uses pam_timestamp_check(8) to watch the pam_timestamp timestamp status. If the pam_timestamp authorization is active, allowing an unprivileted user to temporarily authenticate as the root user without providing a password, an icon in the notification area of the panel is displayed. The icon allows dropping the authorization immediately.","Process Name":"pam-panel-icon","Link":"https:\/\/linux.die.net\/man\/1\/pam-panel-icon"}},{"Process":{"Description":"Performs maintenance on the databases used by the pam_abl (auto blacklist) module. CONFIG is the name of the pam_abl config file (\/etc\/security\/pam_abl.conf). The config file is read to discover the names of the pam_abl databases and the rules that control purging of old data from them.","Process Name":"pam_abl","Link":"https:\/\/linux.die.net\/man\/1\/pam_abl"}},{"Process":{"Description":"This program is part of Netpbm(1). pamaddnoise adds the specified noise type to a Netpbm image. pamaddnoise treats a PPM image as 3 independent planes, not as a plane of colors in a color space.","Process Name":"pamaddnoise","Link":"https:\/\/linux.die.net\/man\/1\/pamaddnoise"}},{"Process":{"Description":"This program is part of Netpbm(1). pamarith reads two PBM, PGM, PPM, or PAM images as input. It performs the specified binary arithmetic operation on their sample values and produces an output of a format which is the more general of the two input formats. The two input images must be of the same width and height. The arithmetic is performed on each pair of identically located tuples to generate the identically located tuple of the output. For the purpose of the calculation, it assumes any PBM, PGM, or PPM input image is the equivalent PAM image of tuple type BLACKANDWHITE, GRAYSCALE, or RGB, respectively, and if it produces a PBM, PGM, or PPM output, produces the equivalent of the PAM image which is the result of the calculation. The first pamfile argument identifies the 'left' argument image; the second pamfile argument identifies the 'right' one. If the output is PAM, the tuple type is the same as the tuple type of the left input image. pamarith performs the arithmetic on each pair of identically located tuples in the two input images. The arithmetic operation is in all cases fundamentally a function from two integers to an integer. The operation is performed on two tuples as follows. The two input images must have the same depth, or one of them must have depth one. pamarith fails if one of these is not the case. If they have the same depth, pamarith simply carries out the arithmetic one sample at a time. I.e. if at a particular position the left input image contains the tuple (s1,s2,...,sN) and the right input image contains the tuple (t1,t2,...tN), and the function is f, then the output image contains the tuple (f(s1,t1),f(s2,t2),...,f(sN,tN)). If one of the images has depth 1, the arithmetic is performed between the one sample in that image and each of the samples in the other. I.e. if at a particular position the left input image contains the tuple (s) and the right input image contains the tuple (t1,t2,...tN), and the function is f, then the output image contains the tuple (f(s,t1),f(s,t2),...,f(s,tN)). Maxval The meanings of the samples with respect to the maxval varies according to the function you select. In PAM images in general, the most usual meaning of a sample (the one that applies when a PAM image represents a visual image), is that it represents a fraction of some maximum. The maxval of the image corresponds to some maximum value (in the case of a visual image, it corresponds to 'full intensity.'), and a sample value divided by the maxval gives the fraction. For pamarith, this interpretation applies to the regular arithmetic functions: -add, -subtract, -multiply, -divide, -difference, -minimum, -maximum, -mean, and -compare. For those, you should think of the arguments and result as numbers in the range [0,1). For example, if the maxval of the left argument image is 100 and the maxval of the right argument image is 200 and the maxval of the output image is 200, and the left sample value in an -add calculation is 50 and the right sample is 60, the actual calculation is 50\/100 + 60\/200 = 160\/200, and the output sample value is 160. For these functions, pamarith makes the output image's maxval the maximum of the two input maxvals, except with -compare, where pamarith uses an output maxval of 2. (Before Netpbm 10.14 (February 2003), there was no exception for -compare; in 10.14, the exception was just that the maxval was at least 2, and sometime between 10.18 and 10.26 (January 2005), it changed to being exactly 2). If the result of a calculation falls outside the range [0, 1), pamarith clips it -- i.e. considers it to be zero or 1-. In many cases, where both your input maxvals are the same, you can just think of the operation as taking place between the sample values directly, with no consideration of the maxval except for the clipping. E.g. an -add of sample value 5 to sample value 8 yields sample value 13. But with -multiply, this doesn't work. Say your two input images have maxval 255, which means the output image also has maxval 255. Consider a location in the image where the input sample values are 5 and 10. You might think the multiplicative product of those would yield 50 in the output. But pamarith carries out the arithmetic on the fractions 5\/255 and 10\/255. It multiplies those together and then rescales to the output maxval, giving a sample value in the output PAM of 50\/255 rounded to the nearest integer: 0. With the bit string operations, the maxval has a whole different meaning. The operations in question are: -and, -or, -nand, -nor, -xor, and -shiftleft, -shiftright. With these, each sample value in one or both input images, and in the output image, represents a bit string, not a number. The maxval tells how wide the bit string is. The maxval must be a full binary count (a power of two minus one, such as 0xff) and the number of ones in it is the width of the bit string. For the dyadic bit string operations (that's everything but the shift functions), the maxvals of the input images must be the same and pamarith makes the maxval of the output image the same. For the bit shift operations, the output maxval is the same as the left input maxval. The right input image (which contains the shift counts) can have any maxval and the maxval is irrelevant to the interpretation of the samples. The sample value is the actual shift count. But it's still required that no sample value exceed the maxval. The Operations Most of the operations are obvious from the option name. The following paragraphs cover those that aren't. -subtract subtracts a value in the right input image from a value in the left input image. -difference calculates the absolute value of the difference. -multiply does an ordinary arithmetic multiplication, but tends to produce nonobvious results because of the way pamarith interprets sample values. See Maxval . -divide divides a value in the left input image by the value in the left input image. But like -multiply, it tends to produce nonobvious results. Note that pamarith clipping behavior makes this of little use when the left argument (dividend) is greater than the right argument (divisor) -- the result in that case is always the maxval. If the divisor is 0, the result is the maxval. This option was new in Netpbm 10.30 (October 2005). -compare produces the value 0 when the value in the left input image is less than the value in the right input image, 1 when the values are equal, and 2 when the left is greater than the right. If the maxvals of the input images are not identical, pamarith may claim two values are not equal when in fact they are, due to the precision with which it does the arithmetic. However, it will never say A is greater than B if A is less than B. -compare was new in Netpbm 10.13 (December 2002). -and, -nand, -or, -nor, and -xor consider the input and output images to contain bit strings; they compute bitwise logic operations. Note that if the maxval is 1, you can also look at these as logic operations on boolean input values. See section Maxval for the special meaning of maxval with respect to bit string operations such as these. -shiftleft and -shiftright consider the left input image and output image to contain bit strings. They compute a bit shift operation, with bits falling off the left or right end and zeroes shifting in, as opposed to bits off one end to the other. The right input image sample value is the number of bit positions to shift. Note that the maxval (see Maxval ) determines the width of the frame within which you are shifting. Notes If you want to apply a unary function, e.g. \"halve\", to a single image, use pamfunc.","Process Name":"pamarith","Link":"https:\/\/linux.die.net\/man\/1\/pamarith"}},{"Process":{"Description":"This program is part of Netpbm(1). pambackground reads a PNM or PAM image as input. It generates as output a PAM image that identifies the background area of the image (a mask). To identify the background, pambackground assumes the image is a foreground image, smaller than the total image size, placed over a single-color background. It assumes that foreground image is solid -- it does not have holes through which the background can be seen. So in specific, pambackground first identifies the background color, then finds all contiguous pixels of that color in regions touching any edge of the image. Think of it as starting at each of the four edges and moving inward as far as possible until it hits pixels of another color (the foreground image). pambackground identifies the background color as follows: If any 3 corners of the image are the same color, that's the background color. If not, but 2 corners are the same color, the background color is the color of a pair of identically colored corners in this priority order: top, right, left, bottom. If no two corners have the same color, the background color is the color of the upper left corner. In a typical photograph, the area that you would consider the background is many shades of a color, so to pambackground it is multiple colors and pambackground will not meaningfully identify the background of your image. To use pambackground in this case, you might use ppmchange to change all similar colors to a single one first. For example, if the photograph is a building against a blue sky, where nothing remotely sky-blue appears in the building, you could use ppmchange to change all pixels within 20% of 'SkyBlue' to SkyBlue, then run pambackground on it. In Release 10.37, pambackground does not really do what is promised above. It can't see places where the background appears in the middle of a row (think of the sky between two buildings). From Release 10.38 forward, it snakes through whatever passages it has to to find all the background. The PAM that pambackground creates has a single plane, with a maxval of 1. The sample value 1 means background; 0 means foreground. There is no tuple type. Some older programs (but none that are part of Netpbm) don't know what a PAM is and expect a mask to be in the form of a PGM or PBM image. To convert pambackground's output to PBM, use pamtopnm -assume. To convert to PGM, use pgmtopgm. netpbmfile is the file specification of the input file, or - to indicate Standard Input. The default is Standard Input. A common use for a background mask is with pamcomp. You could replace the entire background (or foreground) of your image with something else. Another common use is to make an image with the background transparent (in some image format that has a concept of transparency; not Netpbm formats) so that image can be overlaid onto another image later. Netpbm's converters to image formats that have transparency (e.g. PNG) let you use the mask that pambackground generates to identify the transparent areas for the output. To simply make a mask of all the areas of a specified color, use ppmcolormask. If you have a unique background color (one that doesn't occur in the foreground) and know what it is, this can create a background mask in cases that pambackground cannot: where there are see-through holes in the foreground image.","Process Name":"pambackground","Link":"https:\/\/linux.die.net\/man\/1\/pambackground"}},{"Process":{"Description":"This program is part of Netpbm(1). pambayer reads a Bayer pattern in a 1-deep Netpbm image and produces a color image in PAM RGB format as output. A Bayer pattern is what you get from the optical sensor in some digital cameras. Such a camera doesn't have a red, green, and blue sensor in the exact same place for an individual pixel. Instead, it has red, green, and blue sensors laid out in a two dimensional array. The pattern in which they are laid out is the Bayer pattern. The input to pambayer is one sample value for each of those sensors, so some samples are red, some are green, and some are blue. pambayer turns that into a regular visual image with one pixel per sensor. For the two components of each pixel that are missing in the corresponding Bayer input, pambayer averages the sample values from the adjacent pixels that do have that component. But you can have pambayer fill in black instead (see the -noninterpolate option), which gives you a simpler representation of what the camera saw, on which you might do further processing. Such an image still looks right, though considerably dimmer, if you stand far enough away and let your eyes do the interpolation. The input image is a pseudo-PNM image (pseudo- because while the structure is the same, the sample values have different meanings) or PAM image of arbitrary tuple type. pambayer looks at only the first plane of the input. The output image is a PAM image of tuple type 'RGB', i.e. a standard color image. You can convert this to PPM with pamtopnm(1). If you're interested in just one of the primary colors, use pamchannel on the output of pambayer to extract it.","Process Name":"pambayer","Link":"https:\/\/linux.die.net\/man\/1\/pambayer"}},{"Process":{"Description":"This program is part of Netpbm(1). pamchannel reads a PAM or PNM image as input and produces a PAM image as output, consisting of the indicated channels (planes) of the input. The output is the same dimensions as the input, except that the depth is the number of channum arguments you supply. The tuple type is a null string unless you specify the -tupletype option. This program works on multi-image streams, producing a corresponding output stream. But before Netpbm 10.32 (February 2006), it ignored every image after the first. pamstack does the opposite of pamchannel: It takes multiple PAM or PNM images as input and stacks their planes (channels) on top of one another to yield a single PAM.","Process Name":"pamchannel","Link":"https:\/\/linux.die.net\/man\/1\/pamchannel"}},{"Process":{"Description":"This program is part of Netpbm(1). pamcomp reads two images and produces a composite image with one of the images overlayed on top of the other, possible translucently. The images need not be the same size. The input and outputs are Netpbm format image files. In its simplest use, pamcomp simply places the image in the file overlay_file on top of the image in the file underlying_file, blocking out the part of underlying_file beneath it. If you add the -alpha option, then pamcomp uses the image in file alpha-pgmfile as an alpha mask, which means it determines the level of transparency of each point in the overlay image. The alpha mask must have the same dimensions as the overlay image. In places where the alpha mask defines the overlay image to be opaque, the composite output contains only the contents of the overlay image; the underlying image is totally blocked out. In places where the alpha mask defines the overlay image to be transparent, the composite output contains none of the overlay image; the underlying image shows through completely. In places where the alpha mask shows a value in between opaque and transparent (translucence), the composite image contains a mixture of the overlay image and the underlying image and the level of translucence determines how much of each. The alpha mask is a PGM file in which a white pixel represents opaqueness and a black pixel transparency. Anything in between is translucent. (Like any Netpbm program, pamcomp will see a PBM file as if it is PGM). If the overlay image is a PAM image of tuple type RGB_ALPHA or GRAYSCALE_ALPHA, then the overlay image contains transparency information itself and pamcomp uses it the same way as the alpha mask described above. If you supply both an overlay image that has transparency information and an alpha mask, pamcomp multiplies the two opacities to get the opacity of the overlay pixel. Before Netpbm 10.25 (October 2004), pamcomp did not recognize the transparency information in a PAM image -- it just ignored it. So people had to make appropriate alpha masks in order to have a non-opaque overlay. Some Netpbm programs that convert from image formats such as PNG that contain transparency information are not able to create RGB_ALPHA or GRAYSCALE_ALPHA PAM output, so you have to use the old method -- extract the transparency information from the original into a separate alpha mask and use that as input to pamcomp. The output image is always of the same dimensions as the underlying image. pamcomp uses only parts of the overlay image that fit within the underlying image. To specify where on the underlying image to place the overlay image, use the -align, -valign, -xoff, and -yoff options. Without these options, the default horizontal position is flush left and the default vertical position is flush top. The overlay image, in the position you specify, need not fit entirely within the underlying image. pamcomp uses only the parts of the overlay image that appear above the underlying image. It is possible to specify positioning such that none of the overlay image is over the underlying image -- i.e. the overlay is out of frame. If you do that, pamcomp issues a warning. The overlay and underlying images may be of different formats (e.g. overlaying a PBM text image over a full color PPM image) and have different maxvals. The output image has the more general of the two input formats and a maxval that is the least common multiple the two maxvals (or the maximum maxval allowable by the format, if the LCM is more than that).","Process Name":"pamcomp","Link":"https:\/\/linux.die.net\/man\/1\/pamcomp"}},{"Process":{"Description":"This program is part of Netpbm(1). pamcut reads a PAM, PBM, PGM, or PPM image as input and extracts the specified rectangle, and produces the same kind of image as output. There are two ways to specify the rectangle to cut: arguments and options. Options are easier to remember and read, more expressive, and allow you to use defaults. Arguments were the only way available before July 2000. If you use both options and arguments, the two specifications get mixed in an unspecified way. In any case, remember that you are specifying the rectangle to keep, not the bits to discard. Otherwise, you'll be tempted to believe that -right=9 means to delete the 9 rightmost columns. (It really means keep the stuff up to Column 9 and delete the rest). To use options, just code any mixture of the -left, -right, -top, -bottom, -width, and -height options. What you don't specify defaults. Those defaults are in favor of minimal cutting and in favor of cutting the right and bottom edges off. It is an error to overspecify, i.e. to specify all three of -left, -right, and -width or -top, -bottom, and -height. To use arguments, specify all four of the left, top, width, and height arguments. left and top have the same effect as specifying them as the argument of a -left or -top option, respectively. width and height have the same effect as specifying them as the argument of a -width or -height option, respectively, where they are positive. Where they are not positive, they have the same effect as specifying one less than the value as the argument to a -right or -bottom option, respectively. (E.g. width = 0 makes the cut go all the way to the right edge). Before July 2000, negative numbers were not allowed for width and height. Input is from Standard Input if you don't specify the input file pnmfile. Output is to Standard Output. pamcut works on a multi-image stream. It cuts each image in the stream independently and produces a multi-image stream output. Before Netpbm 10.32 (March 2006), it ignored all but the first image in the stream. If you are splitting a single image into multiple same-size images, pamdice is faster and easier than running pamcut multiple times. pamcomp is also useful for cutting and padding an image to a certain size. You create a background image of the desired frame dimensions and overlay the subject image on it.","Process Name":"pamcut","Link":"https:\/\/linux.die.net\/man\/1\/pamcut"}},{"Process":{"Description":"This program is part of Netpbm(1). pamdeinterlace removes all the even-numbered or odd-numbered rows from the input PNM or PAM image. Specify which with the -takeeven and -takeodd options. This can be useful if the image is a video capture from an interlaced video source. In that case, each row shows the subject 1\/60 second before or after the two rows that surround it. If the subject is moving, this can detract from the quality of the image. Because the resulting image is half the height of the input image, you will then want to use pamstretch or pamscale to restore it to its normal height: pamdeinterlace myimage.ppm | pamstretch -yscale=2 >newimage.ppm Another, usually better, way to deinterlace an image is with pammixinterlace.","Process Name":"pamdeinterlace","Link":"https:\/\/linux.die.net\/man\/1\/pamdeinterlace"}},{"Process":{"Description":"This program is part of Netpbm(1). pamdepth reads a Netpbm image as input, scales all the pixel values, and writes out the image with the new maxval. Scaling the colors down to a smaller maxval will result in some loss of information. This program works on multi-image streams. Be careful of off-by-one errors when choosing the new maxval. For instance, if you want the color values to be five bits wide, use a maxval of 31, not 32. One important use of pamdepth is to convert a new format 2-byte-per-sample PNM file to the older 1-byte-per-sample format. Before April 2000, essentially all raw (binary) format PNM files had a maxval less than 256 and one byte per sample, and many programs may rely on that. If you specify a newmaxval less than 256, the resulting file should be readable by any program that worked with PNM files before April 2000.","Process Name":"pamdepth","Link":"https:\/\/linux.die.net\/man\/1\/pamdepth"}},{"Process":{"Description":"This program is part of Netpbm(1). pamdice reads a PAM, PBM, PGM, or PPM image as input and splits it horizontally and\/or vertically into equal size pieces and writes them into separate files as the same kind of image. You can optionally make the pieces overlap. See the -outstem option for information on naming of the output files. The -width and -height options determine the size of the output pieces. pamundice can rejoin the images. For finer control, you can also use pnmcat. One use for this is to make pieces that take less computer resources than the whole image to process. For example, you might have an image so large that an image editor can't read it all into memory or processes it very slowly. With pamdice, you can split it into smaller pieces, edit one at a time, and then reassemble them. Another use for this is to print a large image in small printer-sized pieces that you can glue together. ppmglobe does a similar thing; it lets you glue the pieces together into a sphere. If you want to cut pieces from an image individually, not in a regular grid, use pamcut.","Process Name":"pamdice","Link":"https:\/\/linux.die.net\/man\/1\/pamdice"}},{"Process":{"Description":"This program is part of Netpbm(1). pamditherbw dithers a grayscale image. Dithering means turning each shade of gray into a pattern of black and white pixels that, from a distance, look the same as the gray. The input should be a PGM image or a PAM image of tuple type GRAYSCALE. However, pamditherbw doesn't check, so if you feed it e.g. a PPM image, it will produce arbitrary results (actually, it just takes the first channel of whatever you give it and treats it as if it represented gray levels). The output is a PAM with tuple type BLACKANDWHITE. You can turn this into a PBM (if you need to use it with an older program doesn't understand PAM) with pamtopnm. To do the opposite of dithering, you can usually just scale the image down and then back up again with pamscale, possibly smoothing or blurring the result with pnmsmooth or pnmconvol. Or use the special case program pbmtopgm. To dither a color image (to reduce the number of pixel colors), use ppmdither. Another way to convert a grayscale image to a black and white image is thresholding. Thresholding is simply replacing each grayscale pixel with a black or white pixel depending on whether its brightness is above or below a threshold. That threshold might vary. Simple thresholding is a degenerate case of dithering, so pamditherbw does very simple thresholding with its -threshold option. But pamthreshold does more sophisticated thresholding.","Process Name":"pamditherbw","Link":"https:\/\/linux.die.net\/man\/1\/pamditherbw"}},{"Process":{"Description":"This program is part of Netpbm(1). pamedge reads a Netpbm image (PNM or PAM) and produces an image that outlines the edges. The output image is of the same type as the input, except that the maxval of the output is at least 255 and if the input is PBM, the output is PGM. You can pipe the result through pamditherbw -threshold and play with the threshold value to get a PBM (bilevel image) of the edges. The edge detection technique used is to take the Pythagorean sum of two Sobel gradient operators at 90 degrees to each other. For more details see 'Digital Image Processing' by Gonzalez and Wintz, chapter 7. The maxval of the output is the same as the maxval of the input, except at least 255. The effect is better with larger maxvals, so you may want to increase the maxval of the input by running it through pamdepth first.","Process Name":"pamedge","Link":"https:\/\/linux.die.net\/man\/1\/pamedge"}},{"Process":{"Description":"This program is part of Netpbm(1). All Netpbm formats that have samples in pure binary format with multiple bytes are defined to have them in big endian (most significant byte first) order. However, there exist variations on these formats, primarily developed before official multibyte Netpbm formats existed, that are identical to Netpbm formats in every respect except that samples are in little endian (least signficant byte first) order. pamendian reverses the byte order of the sample to convert between the two formats. If the input is true PAM, PGM, or PPM, the output is the little endian variation on that format, and vice versa. The X Window System viewer xv expects the little endian variation of PGM and PPM. Programs that come with the Independent Jpeg Group's JPEG library are known to use the little endian variation of PGM and PPM. The reason some programs use this variant is that at one time during Netpbm's darkage(1),there was a version of Netpbm around that used it. But it was never formally specified. This program takes input only on Standard Input. Its output is always on Standard Output. You should never have to use this program with images generated by programs in the Netpbm package or programs that use the Netpbm libraries. If you do, that probably means something needs to be fixed in those programs. The Netpbm converter for any graphics format that represents numbers in little endian form should properly reverse the bytes to create correct Netpbm output. If you create a Netpbm image from a generic stream of samples, using rawtopgm or rawtoppm, use options on those programs to declare the endianness of your input, thus creating correct endianness in your PGM or PPM output.","Process Name":"pamendian","Link":"https:\/\/linux.die.net\/man\/1\/pamendian"}},{"Process":{"Description":"This program is part of Netpbm(1). pamenlarge reads a Netpbm image as input, replicates its pixels N times, and produces a Netpbm image as output. The output is the same type of image as the input. If you enlarge by a factor of 3 or more, you should probably add a pnmsmooth step; otherwise, you can see the original pixels in the resulting image. pamenlarge can enlarge only by integer factors. The slower but more general pamscale can enlarge or reduce by arbitrary factors. pamscale allows you to enlarge by resampling, which gives you smoother enlargements. But it is much slower. pamstretch is another enlarging program that enlarges by integer factors. It does a simple kind of resampling that gives you a smoothed enlargement with less computational cost. pbmreduce can reduce by integer factors, but only for PBM images.","Process Name":"pamenlarge","Link":"https:\/\/linux.die.net\/man\/1\/pamenlarge"}},{"Process":{"Description":"This program is part of Netpbm(1). pamfile reads one or more Netpbm files as input and writes out short descriptions of the image type, size, etc. This is partly for use in shell scripts, so the format is not particularly pretty. By default, pamfile reads only the header of the input file. If that file is a pipe, that might cause problems for the process that is feeding the pipe. In that case, see the -allimages option.","Process Name":"pamfile","Link":"https:\/\/linux.die.net\/man\/1\/pamfile"}},{"Process":{"Description":"This program is part of Netpbm(1). pamfixtrunc reads as much as it can of a Netpbm image that may be truncated (i.e. the file may not contain the last part of the image) and writes out a valid Netpbm image that is just missing the bottom rows of the original (pre-truncation) image. The header of a Netpbm image implies how large the image must be (how many bytes the file must contain). If the file is actually smaller than that, a Netpbm program that tries to read the image fails, with an error message telling you that it couldn't read the whole file. The data in the file is arranged in row order, from top to bottom, and the most common reason for the file being smaller than its header says it should be is because the bottommost rows are simply missing. So pamfixtrunc assumes that is the case and generates a new image with just the rows that are readable. (technically, that means the output's header indicates a smaller number of rows and omits any partial last row). The most common way for a Netpbm file to be small is that something interrupted the program that generated it before it was finished writing the file. For example, the program ran out of its own input or encountered a bug or ran out of space in which to write the output. Another problem pamfixtrunc deals with is where the file isn't actually too small, but due to a system error, a byte in the middle of it cannot be read (think of a disk storage failure). pamfixtrunc reads the input sequentially until it can't read any further, for any reason. So it treats such an image as a truncated one, ignoring all data after the unreadable byte. But be aware that an image file is sometimes too small because of a bug in the program that generated it, and in that case it is not simply a matter of the bottom of the image missing, so pamfixtrunc simply creates a valid Netpbm image containing a garbage picture. pamfixtrunc looks at only on the first image in a multi-image stream. If you want to test an image file to see if it is corrupted by being too small, use pamfile --allimages . It fails with an error message if the file is too small. If you want to cut the bottom off a valid Netpbm image, use pamcut.","Process Name":"pamfixtrunc","Link":"https:\/\/linux.die.net\/man\/1\/pamfixtrunc"}},{"Process":{"Description":"This program is part of Netpbm(1). pamflip flips a PAM or PNM image top for bottom or left for right, or transposes it horizontal for vertical, or rotates it 1, 2, or 3 quarter turns. To rotate at other angles, use pnmrotate. It is much slower, though. The input image is pamfile, or Standard Input if pamfile is not specified. To flip\/rotate a JFIF (JPEG) image losslessly, use jpegtran. jpegtran is part of the Independent Jpeg Group's compression library package, not part of Netpbm. The normal Netpbm way to flip a JFIF file would be to convert it to PNM, use pamflip, and convert back to JFIF. But since JPEG compression is lossy, the resulting image would have less quality than the original. jpegtran, on the other hand, can do this particular transformation directly on the compressed data without loss.","Process Name":"pamflip","Link":"https:\/\/linux.die.net\/man\/1\/pamflip"}},{"Process":{"Description":"This program is part of Netpbm(1). pamfunc reads a Netpbm image as input and produces a Netpbm image as output, with the same format, maxval, and dimensions as the input. pamfunc applies a simple transfer function to each sample in the input to generate the corresponding sample in the output. The options determine what function. pamarith is the same thing for binary functions -- it takes two images as input and applies a specified simple arithmetic function (e.g. addition) on pairs of samples from the two to produce the single output image.","Process Name":"pamfunc","Link":"https:\/\/linux.die.net\/man\/1\/pamfunc"}},{"Process":{"Description":"This program is part of Netpbm(1). pamgauss generates a one-plane PAM image whose samples are a gaussian function of their distance from the center of the image. I.e. the sample value is highest in the center and goes down, in a bell curve shape, as you move away from the center. The values are scaled so that the volume under the surface of the two-dimensional Gaussian function is the maxval of the image. You can use this image as a convolution kernel with pnmconvol to blur an image. (This technique is known as Gaussian blurring). width and height are the dimensions of the image that pamgauss generates. Mathematically speaking, they are the domain of the two dimensional gaussian function. The sum of all the samples is equal to the image's maxval (within rounding error). This is true even if you clip the Gaussian function by making the image too small. If you want to be sure you get a whole Gaussian function, make sure that you choose a sigma and image dimensions so that if you made it any larger, the sample values at the edges would be zero. The output image is PAM. To make it usable with pnmconvol, specify -tupletype=GRAYSCALE so pnmconvol can use it as if it were PGM. You must use the -nooffset option on pnmconvol because zero means zero in the PAM that pamgauss generates.","Process Name":"pamgauss","Link":"https:\/\/linux.die.net\/man\/1\/pamgauss"}},{"Process":{"Description":"This program is part of Netpbm(1). pamgradient creates an image of the specified dimensions width by height which contains a smooth, two-dimensional gradient between the specified colors of the four corners (from top left to bottom right). Specify the colors as described for the argument of the ppm_parsecolor() library routine . If all four colors are gray values, pamgradient creates a grayscale image (PAM tuple type GRAYSCALE). Otherwise, it creates a color image (PAM tuple type RGB).","Process Name":"pamgradient","Link":"https:\/\/linux.die.net\/man\/1\/pamgradient"}},{"Process":{"Description":"This program is part of Netpbm(1). pamlookup takes a two dimensional array of indices and a lookup table as input. For each position in the index array, it looks up the index in the lookup table and places the result of the lookup in the output image. The output thus has the same width and height as the index image, and tuple types determined by the lookup table. An index is either a whole number or an ordered pair of whole numbers. If the index image has a depth of one, each index in it is a whole number: the value of the one sample. If the index image has a depth greater than one, each index in it is an ordered pair of the first and second samples in the relevant tuple. The lookup table is a PAM or PNM image. If the index image contains whole number indices, the lookup image is a single row and the index is a column number. The lookup result is the value of the tuple or pixel at the indicated column in the one row in the lookup table. If the index image contains ordered pair indices, the first element of the ordered pair is a row number and the second element of the ordered pair is a column number. The lookup result is the value of the tuple or pixel at the indicated row and column in the lookup table. For example: Consider an index image consisting of a 3x2x1 PAM as follows: and a lookup table consisting of a 3x1 PPM image as follows: The lookup table above says Index 0 corresponds to the color red, Index 1 corresponds to yellow, and Index 2 corresponds to beige. The output of pamlookup is the following PPM image: Now let's look at an example of the more complex case where the indices are ordered pairs of whole numbers instead of whole numbers. Our index image will be this 3x2x2 PAM image: Our lookup table for the example will be this two dimensional PPM: This lookup table says Index (0,0) corresponds to the color red, Index (0,1) corresponds to yellow, Index (1,0) corresponds to green, and Index (1,1) corresponds to black. The output of pamlookup is the following PPM image: If an index specifies a row or column that exceeds the dimensions of the lookup table image, pamlookup uses the value from the top left corner of the lookup image, or the value you specify with the -missingcolor option. The indexfile argument identifies the file containing the index PAM or PNM image. - means Standard Input. The mandatory -lookupfile option identifies the file containing the lookup table image. Again, - means Standard Input. It won't work if both the index image file and lookup table file are Standard Input. The output image goes to Standard Output. You can use ppmmake and pnmcat to create a lookup table file. If you want to use two separate 1-plane images as indices (so that your output reflects the combination of both inputs), use pamstack to combine the two into one two-plane image (and use a 2-dimensional lookup table image).","Process Name":"pamlookup","Link":"https:\/\/linux.die.net\/man\/1\/pamlookup"}},{"Process":{"Description":"This program is part of Netpbm(1). pammasksharpen reads a Netpbm image as input and produces a sharpened version of it, in the same format, as output. It does this via an unsharp mask, which you supply as another Netpbm image. An unsharp mask is generally a blurred version of the original image. The sharpening computation is this: Calculate the 'edgeness' of a sample in the input image as the signed difference between the sample value and the corresponding sample in the unsharp mask. This tells how different the pixel is from its neighbors. Add a multiple of the edgeness to the original sample to get the corresponding output sample. Clip as necessary. This causes pixels that are brighter than their neighbors to get even brighter, while pixels that are dimmer than their neighbors get even dimmer. This makes edges -- places where pixel values change quickly in space -- stand out more. The unsharp mask must be the same dimensions and have the same maxval as the input image. The Unsharp Mask You usually create the unsharp mask as a gaussian blur of the original image, which you can do using pamgauss and pnmconvol as in the example above. The convolution kernel you use with pnmconvol is normally a square with side length an odd number of pixels. When you create an unsharp mask like this, you will have to choose the side length of the convolution kernel. That length implements the parameter of unsharp mask sharpening usually known as 'radius.' In particular, a radius of R pixels corresponds to a convolution kernel 2R+1 pixels on a side. Radius is a very important parameter; you can ruin an image with a radius too large. You can safely use the highest radius with an inanimate object, while a human face demands the least. Landscapes fall in between. But it really depends on the size of the details. Fine detail needs a smaller radius, or else you may obliterate tiny detail of the same size as the Radius width. A large image often has larger detail (more pixels involved), so can use a larger radius. Radius and sharpness (see -sharpness option) interact: reducing one allows you to increase the other.","Process Name":"pammasksharpen","Link":"https:\/\/linux.die.net\/man\/1\/pammasksharpen"}},{"Process":{"Description":"This program is part of Netpbm(1). pammixinterlace is meant to operate on an image which is the interlacing of two images, where raster rows 0, 2, 4, etc. are from one image and rows 1, 3, 5, etc. are from another. (See below for why you might expect to encounter such an image). pammixinterlace makes each row of the output a mixture of the corresponding row of the input and its two neighbors. It uses half of the main row and a quarter each of the two neighbor rows. This can be useful if the image is a video capture from an interlaced video source. In that case, each row shows the subject 1\/60 second before or after the two rows that surround it. If the subject is moving, this can detract from the quality of the image. In video data streams, you often find each frame contains only half the rows of the image -- the odd half or the even half. The displayer of the stream displays the rows in their proper positions on a CRT as they come in. When you display the rows in this order, the CRT has less flicker because a particular area of the screen gets refreshed twice as often. In the process of capturing such a stream, computers often generate the interlaced image of the type that pammixinterlace works with. But this interlaced image, when displayed on a CRT, does not look the same as if a displayer were rendering the stream directly on a CRT as it arrived, because of the timing of when the various pixels get drawn and subsequently fade. That's why you need something like pammixinterlace. You may prefer the effect of simply extracting one of two images. You can do that with pamdeinterlace.","Process Name":"pammixinterlace","Link":"https:\/\/linux.die.net\/man\/1\/pammixinterlace"}},{"Process":{"Description":"This program is part of Netpbm(1). pamoil reads a Netpbm image as input and does an 'oil transfer', and writes the same type of Netpbm image as output. The oil transfer is described in 'Beyond Photography' by Holzmann, chapter 4, photo 7. It's a sort of localized smearing. The smearing works like this: First, assume a grayscale image. For each pixel in the image, pamoil looks at a square neighborhood around it. pamoil determines what is the most common pixel intensity in the neighborhood, and puts a pixel of that intensity into the output in the same position as the input pixel. For color images, or any arbitrary multi-channel image, pamoil computes each channel (e.g. red, green, and blue) separately the same way as the grayscale case above. At the edges of the image, where the regular neighborhood would run off the edge of the image, pamoil uses a clipped neighborhood.","Process Name":"pamoil","Link":"https:\/\/linux.die.net\/man\/1\/pamoil"}},{"Process":{"Description":"This program is part of Netpbm(1). pamperspective reads a Netpbm image as input and produces a Netpbm image of the same format as output. pamperspective interprets the input image as a perspective projection of another image which is in a plane oblique to that of the input image. For example, a photograph of a painting, taken at an angle. The arguments upper_left_x ... lower_right_y specify a quadrilateral in the photograph that pamperspective assumes corresponds to a parallelogram in the painting. The output image consists of this parallelogram, sheared to a rectangle. In this way pamperspective undoes the effect of a raytracer or scanline renderer. Note that if the input image is a projection of a solid scene, rather than a plane, the result is like a different camera angle on that scene, to the extent that the scene is shallow from the other angle. The input is from infile, or from Standard Input, if infile is not specified. The output is to Standard Output.","Process Name":"pamperspective","Link":"https:\/\/linux.die.net\/man\/1\/pamperspective"}},{"Process":{"Description":"This program is part of Netpbm(1). pampick reads a PNM or PAM image stream as input. It picks certain images from the stream and copies them to a new image stream on Standard Output. You identify the images to pick by sequence number within the stream. Each image_sequence_number is a decimal sequence number, with zero meaning the first image. The arguments must be in increasing order, without duplicates. The results are undefined if they are not. (There are a number of enhancements that might be made in future releases that would make whatever pampick does today when you break this rule change). pampick outputs the images in the same order as they appear in the input. If you specify no sequence numbers, pampick outputs nothing. If you specify a sequence number that is beyond what is in the input, pampick fails with an error message to that effect. pampick always reads the entire input stream. (This is helpful when the input stream is a pipe and whatever is feeding the pipe would be upset if it filled up or broke). To see how many images, and what kind, are in a stream, use pamfile. To extract all the images in a stream into separate named files, use pamsplit.","Process Name":"pampick","Link":"https:\/\/linux.die.net\/man\/1\/pampick"}},{"Process":{"Description":"This program is part of Netpbm(1). pampop9 tiles your starting image xtiles by ytiles times. Each of these tiles is taken from a slightly different offset within the source, as determined by the xdelta and ydelta arguments. The top line of tiles in the output is taken from the top of the source image, the second starts with the ydelta row of the source image, the next with the 2*ydelta row, and so on. Similarly, the first column of tiles in the output is taken from the left of the source image, the next starts with the xdelta column, the next with the 2*xdelta column, and so on.","Process Name":"pampop9","Link":"https:\/\/linux.die.net\/man\/1\/pampop9"}},{"Process":{"Description":"This program is part of Netpbm(1). pamrgbatopng reads a PAM image with the RGB_ALPHA tuple type (a color visual image with transparency) and produces an equivalent PNG image as output. The input image if from the file named by the pamfile argument, or Standard Input if you don't specify pamfile. The output goes to Standard Output. The maxval of the input image must be 255. You can use pamdepth to change the maxval of an image to 255 if necessary. pnmtopng(1)isamuchmorepowerful program for generating PNG images from Netpbm images, but it cannot take PAM images with transparency as input. To supply transparency information, you must supply it in a separate PGM image. That makes it considerably less convenient to use. (But note that pnmtopng takes PAM images, even with RGB_ALPHA tuple type just fine -- it just ignores the alpha plane). Netpbm's strategic direction is to add to pnmtopng all the capabilities of pamrgbatopng and retire pamrtbatopng. But there's no telling when that will happen.","Process Name":"pamrgbatopng","Link":"https:\/\/linux.die.net\/man\/1\/pamrgbatopng"}},{"Process":{"Description":"This program is part of Netpbm(1). pamscale scales a Netpbm image by a specified factor, or scales individually horizontally and vertically by specified factors. You can either enlarge (scale factor > 1) or reduce (scale factor < 1). The Scale Factors The options -width, -height, -xsize, -ysize, -xscale, -yscale, -xyfit, -xyfill, -reduce, and -pixels control the amount of scaling. For backward compatibility, there is also -xysize and the scale_factor argument, but you shouldn't use those. -width and -height specify the width and height in pixels you want the resulting image to be. See below for rules when you specify one and not the other. -xsize and -ysize are synonyms for -width and -height, respectively. -xscale and -yscale tell the factor by which you want the width and height of the image to change from source to result (e.g. -xscale 2 means you want to double the width; -xscale .5 means you want to halve it). See below for rules when you specify one and not the other. When you specify an absolute size or scale factor for both dimensions, pamscale scales each dimension independently without consideration of the aspect ratio. If you specify one dimension as a pixel size and don't specify the other dimension, pamscale scales the unspecified dimension to preserve the aspect ratio. If you specify one dimension as a scale factor and don't specify the other dimension, pamscale leaves the unspecified dimension unchanged from the input. If you specify the scale_factor parameter instead of dimension options, that is the scale factor for both dimensions. It is equivalent to -xscale=scale_factor -yscale=scale_factor. Specifying the -reduce reduction_factor option is equivalent to specifying the scale_factor parameter, where scale_factor is the reciprocal of reduction_factor. -xyfit specifies a bounding box. pamscale scales the input image to the largest size that fits within the box, while preserving its aspect ratio. -xysize is a synonym for this. Before Netpbm 10.20 (January 2004), -xyfit did not exist, but -xysize did. -xyfill is similar, but pamscale scales the input image to the smallest size that completely fills the box, while preserving its aspect ratio. This option has existed since Netpbm 10.20 (January 2004). -pixels specifies a maximum total number of output pixels. pamscale scales the image down to that number of pixels. If the input image is already no more than that many pixels, pamscale just copies it as output; pamscale does not scale up with -pixels. If you enlarge by a factor of 3 or more, you should probably add a pnmsmooth step; otherwise, you can see the original pixels in the resulting image. Usage Notes A useful application of pamscale is to blur an image. Scale it down (without -nomix) to discard some information, then scale it back up using pamstretch. Or scale it back up with pamscale and create a 'pixelized' image, which is sort of a computer-age version of blurring. Transparency pamscale understands transparency and properly mixes pixels considering the pixels' transparency. Proper mixing does not mean just mixing the transparency value and the color component values separately. In a PAM image, a pixel which is not opaque represents a color that contains light of the foreground color indicated explicitly in the PAM and light of a background color to be named later. But the numerical scale of a color component sample in a PAM is as if the pixel is opaque. So a pixel that is supposed to contain half-strength red light for the foreground plus some light from the background has a red color sample that says full red and a transparency sample that says 50% opaque. In order to mix pixels, you have to first convert the color sample values to numbers that represent amount of light directly (i.e. multiply by the opaqueness) and after mixing, convert back (divide by the opaqueness). Input And Output Image Types pamscale produces output of the same type (and tuple type if the type is PAM) as the input, except if the input is PBM. In that case, the output is PGM with maxval 255. The purpose of this is to allow meaningful pixel mixing. Note that there is no equivalent exception when the input is PAM. If the PAM input tuple type is BLACKANDWHITE, the PAM output tuple type is also BLACKANDWHITE, and you get no meaningful pixel mixing. If you want PBM output with PBM input, use pamditherbw to convert pamscale's output to PBM. Also consider pbmreduce. pamscale's function is essentially undefined for PAM input images that are not of tuple type RGB, GRAYSCALE, BLACKANDWHITE, or the _ALPHA variations of those. (By standard Netpbm backward compatibility, this includes PBM, PGM, and PPM images). You might think it would have an obvious effect on other tuple types, but remember that the aforementioned tuple types have gamma-adjusted sample values, and pamscale uses that fact in its calculations. And it treats a transparency plane different from any other plane. pamscale does not simply reject unrecognized tuple types because there's a possibility that just by coincidence you can get useful function out of it with some other tuple type and the right combination of options (consider -linear in particular). Methods Of Scaling There are numerous ways to scale an image. pamscale implements a bunch of them; you select among them with invocation options. Pixel Mixing Pamscale's default method is pixel mixing. To understand this, imagine the source image as composed of square tiles. Each tile is a pixel and has uniform color. The tiles are all the same size. Now take a transparent sheet the size of the target image, marked with a square grid of tiles the same size. Stretch or compress the source image to the size of the sheet and lay the sheet over the source. Each cell in the overlay grid stands for a pixel of the target image. For example, if you are scaling a 100x200 image up by 1.5, the source image is 100 x 200 tiles, and the transparent sheet is marked off in 150 x 300 cells. Each cell covers parts of multiple tiles. To make the target image, just color in each cell with the color which is the average of the colors the cell covers -- weighted by the amount of that color it covers. A cell in our example might cover 4\/9 of a blue tile, 2\/9 of a red tile, 2\/9 of a green tile, and 1\/9 of a white tile. So the target pixel would be somewhat unsaturated blue. When you are scaling up or down by an integer, the results are simple. When scaling up, pixels get duplicated. When scaling down, pixels get thrown away. In either case, the colors in the target image are a subset of those in the source image. When the scale factor is weirder than that, the target image can have colors that didn't exist in the original. For example, a red pixel next to a white pixel in the source might become a red pixel, a pink pixel, and a white pixel in the target. This method tends to replicate what the human eye does as it moves closer to or further away from an image. It also tends to replicate what the human eye sees, when far enough away to make the pixelization disappear, if an image is not made of pixels and simply stretches or shrinks. Discrete Sampling Discrete sampling is basically the same thing as pixel mixing except that, in the model described above, instead of averaging the colors of the tiles the cell covers, you pick the one color that covers the most area. The result you see is that when you enlarge an image, pixels get duplicated and when you reduce an image, some pixels get discarded. The advantage of this is that you end up with an image made from the same color palette as the original. Sometimes that's important. The disadvantage is that it distorts the picture. If you scale up by 1.5 horizontally, for example, the even numbered input pixels are doubled in the output and the odd numbered ones are copied singly. If you have a bunch of one pixel wide lines in the source, you may find that some of them stretch to 2 pixels, others remain 1 pixel when you enlarge. When you reduce, you may find that some of the lines disappear completely. You select discrete sampling with pamscale's -nomix option. Actually, -nomix doesn't do exactly what I described above. It does the scaling in two passes - first horizontal, then vertical. This can produce slightly different results. There is one common case in which one often finds it burdensome to have pamscale make up colors that weren't there originally: Where one is working with an image format such as GIF that has a limited number of possible colors per image. If you take a GIF with 256 colors, convert it to PPM, scale by .625, and convert back to GIF, you will probably find that the reduced image has way more than 256 colors, and therefore cannot be converted to GIF. One way to solve this problem is to do the reduction with discrete sampling instead of pixel mixing. Probably a better way is to do the pixel mixing, but then color quantize the result with pnmquant before converting to GIF. When the scale factor is an integer (which means you're scaling up), discrete sampling and pixel mixing are identical -- output pixels are always just N copies of the input pixels. In this case, though, consider using pamstretch instead of pamscale to get the added pixels interpolated instead of just copied and thereby get a smoother enlargement. pamscale's discrete sampling is faster than pixel mixing, but pamenlarge is faster still. pamenlarge works only on integer enlargements. discrete sampling (-nomix) was new in Netpbm 9.24 (January 2002). Resampling Resampling assumes that the source image is a discrete sampling of some original continuous image. That is, it assumes there is some non-pixelized original image and each pixel of the source image is simply the color of that image at a particular point. Those points, naturally, are the intersections of a square grid. The idea of resampling is just to compute that original image, then sample it at a different frequency (a grid of a different scale). The problem, of course, is that sampling necessarily throws away the information you need to rebuild the original image. So we have to make a bunch of assumptions about the makeup of the original image. You tell pamscale to use the resampling method by specifying the -filter option. The value of this option is the name of a function, from the set listed below. To explain resampling, we are going to talk about a simple one dimensional scaling -- scaling a single row of grayscale pixels horizontally. If you can understand that, you can easily understand how to do a whole image: Scale each of the rows of the image, then scale each of the resulting columns. And scale each of the color component planes separately. As a first step in resampling, pamscale converts the source image, which is a set of discrete pixel values, into a continuous step function. A step function is a function whose graph is a staircase-y thing. Now, we convolve the step function with a proper scaling of the filter function that you identified with -filter. If you don't know what the mathematical concept of convolution (convolving) is, you are officially lost. You cannot understand this explanation. The result of this convolution is the imaginary original continuous image we've been talking about. Finally, we make target pixels by picking values from that function. To understand what is going on, we use Fourier analysis: The idea is that the only difference between our step function and the original continuous function (remember that we constructed the step function from the source image, which is itself a sampling of the original continuous function) is that the step function has a bunch of high frequency Fourier components added. If we could chop out all the higher frequency components of the step function, and know that they're all higher than any frequency in the original function, we'd have the original function back. The resampling method assumes that the original function was sampled at a high enough frequency to form a perfect sampling. A perfect sampling is one from which you can recover exactly the original continuous function. The Nyquist theorem says that as long as your sample rate is at least twice the highest frequency in your original function, the sampling is perfect. So we assume that the image is a sampling of something whose highest frequency is half the sample rate (pixel resolution) or less. Given that, our filtering does in fact recover the original continuous image from the samples (pixels). To chop out all the components above a certain frequency, we just multiply the Fourier transform of the step function by a rectangle function. We could find the Fourier transform of the step function, multiply it by a rectangle function, and then Fourier transform the result back, but there's an easier way. Mathematicians tell us that multiplying in the frequency domain is equivalent to convolving in the time domain. That means multiplying the Fourier transform of F by a rectangle function R is the same as convolving F with the Fourier transform of R. It's a lot better to take the Fourier transform of R, and build it into pamscale than to have pamscale take the Fourier transform of the input image dynamically. That leaves only one question: What is the Fourier transform of a rectangle function? Answer: sinc. Recall from math that sinc is defined as sinc(x) = sin(PI*x)\/PI*x. Hence, when you specify -filter=sinc, you are effectively passing the step function of the source image through a low pass frequency filter and recovering a good approximation of the original continuous image. Refiltering There's another twist: If you simply sample the reconstructed original continuous image at the new sample rate, and that new sample rate isn't at least twice the highest frequency in the original continuous image, you won't get a perfect sampling. In fact, you'll get something with ugly aliasing in it. Note that this can't be a problem when you're scaling up (increasing the sample rate), because the fact that the old sample rate was above the Nyquist level means so is the new one. But when scaling down, it's a problem. Obviously, you have to give up image quality when scaling down, but aliasing is not the best way to do it. It's better just to remove high frequency components from the original continuous image before sampling, and then get a perfect sampling of that. Therefore, pamscale filters out frequencies above half the new sample rate before picking the new samples. Approximations Unfortunately, pamscale doesn't do the convolution precisely. Instead of evaluating the filter function at every point, it samples it -- assumes that it doesn't change any more often than the step function does. pamscale could actually do the true integration fairly easily. Since the filter functions are built into the program, the integrals of them could be too. Maybe someday it will. There is one more complication with the Fourier analysis. sinc has nonzero values on out to infinity and minus infinity. That makes it hard to compute a convolution with it. So instead, there are filter functions that approximate sinc but are nonzero only within a manageable range. To get those, you multiply the sinc function by a window function, which you select with the -window option. The same holds for other filter functions that go on forever like sinc. By default, for a filter that needs a window function, the window function is the Blackman function. Filter Functions Besides Sinc The math described above works only with sinc as the filter function. pamscale offers many other filter functions, though. Some of these approximate sinc and are faster to compute. For most of them, I have no idea of the mathematical explanation for them, but people do find they give pleasing results. They may not be based on resampling at all, but just exploit the convolution that is coincidentally part of a resampling calculation. For some filter functions, you can tell just by looking at the convolution how they vary the resampling process from the perfect one based on sinc: The impulse filter assumes that the original continuous image is in fact a step function -- the very one we computed as the first step in the resampling. This is mathematically equivalent to the discrete sampling method. The box (rectangle) filter assumes the original image is a piecewise linear function. Its graph just looks like straight lines connecting the pixel values. This is mathematically equivalent to the pixel mixing method (but mixing brightness, not light intensity, so like pamscale -linear) when scaling down, and interpolation (ala pamstretch) when scaling up. Gamma pamscale assumes the underlying continuous function is a function of brightness (as opposed to light intensity), and therefore does all this math using the gamma-adjusted numbers found in a PNM or PAM image. The -linear option is not available with resampling (it causes pamscale to fail), because it wouldn't be useful enough to justify the implementation effort. Resampling (-filter) was new in Netpbm 10.20 (January 2004). The filter functions Here is a list of the function names you can specify for the -filter option. For most of them, you're on your own to figure out just what the function is and what kind of scaling it does. These are common functions from mathematics. point The graph of this is a single point at X=0, Y=1. box The graph of this is a rectangle sitting on the X axis and centered on the Y axis with height 1 and base 1. triangle The graph of this is an isosceles triangle sitting on the X axis and centered on the Y axis with height 1 and base 2. quadratic cubic catrom mitchell gauss sinc bessel hanning hamming blackman kaiser normal hermite lanczos Not documented Linear vs Gamma-adjusted The pixel mixing scaling method described above involves intensities of pixels (more precisely, it involves individual intensities of primary color components of pixels). But the PNM and PNM-equivalent PAM image formats represent intensities with gamma-adjusted numbers that are not linearly proportional to intensity. So pamscale, by default, performs a calculation on each sample read from its input and each sample written to its output to convert between these gamma-adjusted numbers and internal intensity-proportional numbers. Sometimes you are not working with true PNM or PAM images, but rather a variation in which the sample values are in fact directly proportional to intensity. If so, use the -linear option to tell pamscale this. pamscale then will skip the conversions. The conversion takes time. In one experiment, it increased by a factor of 10 the time required to reduce an image. And the difference between intensity-proportional values and gamma-adjusted values may be small enough that you would barely see a difference in the result if you just pretended that the gamma-adjusted values were in fact intensity-proportional. So just to save time, at the expense of some image quality, you can specify -linear even when you have true PPM input and expect true PPM output. For the first 13 years of Netpbm's life, until Netpbm 10.20 (January 2004), pamscale's predecessor pnmscale always treated the PPM samples as intensity-proportional even though they were not, and drew few complaints. So using -linear as a lie is a reasonable thing to do if speed is important to you. But if speed is important, you also should consider the -nomix option and pnmscalefixed. Another technique to consider is to convert your PNM image to the linear variation with pnmgamma, run pamscale on it and other transformations that like linear PNM, and then convert it back to true PNM with pnmgamma -ungamma. pnmgamma is often faster than pamscale in doing the conversion. With -nomix, -linear has no effect. That's because pamscale does not concern itself with the meaning of the sample values in this method; pamscale just copies numbers from its input to its output. Precision pamscale uses floating point arithmetic internally. There is a speed cost associated with this. For some images, you can get the acceptable results (in fact, sometimes identical results) faster with pnmscalefixed, which uses fixed point arithmetic. pnmscalefixed may, however, distort your image a little. See the pnmscalefixed user manual for a complete discussion of the difference.","Process Name":"pamscale","Link":"https:\/\/linux.die.net\/man\/1\/pamscale"}},{"Process":{"Description":"This program is part of Netpbm(1). pamseq generates a PAM image of a specified depth and specified maxval that consists of a single row. The row consists of one tuple of every possible value, in order. For a depth of one, the order is simple: From 0 to maxval, going from left to right. For higher depths, the highest numbered plane goes from 0 to maxval (going left to right) while all the other planes have value 0. Then the sequence repeats except with the next highest plane set to a value of 1, then 2, etc.","Process Name":"pamseq","Link":"https:\/\/linux.die.net\/man\/1\/pamseq"}},{"Process":{"Description":"This program is part of Netpbm(1). pamsharpmap reads a Netpbm image (PNM or PAM) and produces an image that shows how sharp it is at each location. Sharpness is a measure of how suddenly (in space) colors change in the image. pamsharpmap computes the sharpness of each component color (R, G, B) separately and produces a pixel whose intensity of each component color is directly proportional to the sharpness of that component color at the same location in the input image. Thus, at a point where the image is very sharp in its red and green components, but dull in its blue component, you will see a yellow pixel in the output. pamsharpmap computes sharpness at a point simply as the average difference in intensity between the pixel at that point and the 8 pixels surrounding it. At the edges of the image, where there are not 8 pixels surrounding a pixel, pamsharpmap assumes the image is extended with a black border. pamsharpmap assumes that the image is a PNM or PNM equivalent PAM. If it isn't, the results are not necessarily meaningful. The output image is the same dimensions, depth, and tuple type as the input, and has maxval 255.","Process Name":"pamsharpmap","Link":"https:\/\/linux.die.net\/man\/1\/pamsharpmap"}},{"Process":{"Description":"This program is part of Netpbm(1). pamsharpness reads a Netpbm image (PNM or PAM) and prints a number that tells how sharp it is. Sharpness is a measure of how suddenly (in space) colors change in the image. pamsharpness computes the sharpness of the image as the average difference in intensity between each pixel and its 8 surrounding pixels, in each of the color components (R, G, B). pamsharpness does not include the edges of the image, where there are not 8 pixels surrounding a pixel, in its computation. pamsharpness assumes that the image is a PNM or PNM equivalent PAM. If it isn't, the results are not necessarily meaningful.","Process Name":"pamsharpness","Link":"https:\/\/linux.die.net\/man\/1\/pamsharpness"}},{"Process":{"Description":"This program is part of Netpbm(1). pamsistoaglyph reads a Netpbm image as input and produces a Netpbm image as output. pamsistoaglyph takes a single-image stereogram (SIS) such as those produced by <a href= \"http:\/\/netpbm.sourceforge.net\/doc\/pamstereogram.html\">pamstereogram<\/a> and converts it to a red\/cyan anaglyphic image such as those produced by ppm3d(1). Many people have trouble tricking their eyes into focusing beyond the image in front of them and are therefore unable to perceive the 3-D shape hidden within a single-image stereogram. Anaglyphic stereograms are easier to perceive in 3-D but require a pair of red\/cyan glasses such as those often used to watch 3-D movies. The goal of pamsistoaglyph is to help people who have trouble viewing single-image stereograms see the intriguing 3-D effect. pamsistoaglyph can convert single-image random-dot stereograms (SIRDS), wallpaper stereograms, and even dual-image stereograms to anaglyphic images.","Process Name":"pamsistoaglyph","Link":"https:\/\/linux.die.net\/man\/1\/pamsistoaglyph"}},{"Process":{"Description":"This program is part of Netpbm(1). pamslice extracts one line of tuples (pixels) out of a Netpbm image and prints their values in a table. A line means a row or column. It shows you a one-dimensional cross section of a two-dimensional image. (With the -plane option, it can be thought of as a one-dimensional cross-section of a three-dimensional image). The table has one line per tuple, consisting of blank-separated ASCII decimal numbers. The first number is the column number if you specified a row slice or the row number if you specified a column slice. The rest of the numbers are the sample values in plane number order. For a PBM or PGM input, there is only one plane. For a PPM input, Plane 0 is red, Plane 1 is green, and Plane 2 is blue. See the specifications of the image formats for details on exactly what these numbers mean. If you want to see all the pixels in a PPM, PGM, or PBM image in ASCII decimal, pnmtoplainpnm is a good way to do that.","Process Name":"pamslice","Link":"https:\/\/linux.die.net\/man\/1\/pamslice"}},{"Process":{"Description":"This program is part of Netpbm(1). pamsplit reads a PNM or PAM stream as input. It copies each image in the input into a separate file, in the same format. netpbmfile is the file specification of the input file, or - to indicate Standard Input. The default is Standard Input. output_file_pattern tells how to name the output files. It is the file specification of the output file, except that the first occurence of '%d' in it is replaced by the image sequence number in unpadded ASCII decimal, with the sequence starting at 0. If there is no '%d' in the pattern, pamsplit fails. The default output file pattern is 'image%d'. The -padname option specifies to how many characters you want the image sequence number in the output file name padded with zeroes. pamsplit adds leading zeroes to the image sequence number to get up to at least that number of characters. This is just the number of characters in the sequence number part of the name. For example, pamsplit - outputfile%d.ppm -padname=3 would yield output filenames outputfile000.ppm, outputfile001.ppm, etc. The default is no padding (equivalent to -padname=0. The -padname option was new in Netpbm 10.23 (July 2004). Before that, there was never any padding. Note that to do the reverse operation (combining multiple single-image Netpbm files into a multi-image one), there is no special Netpbm program. Just use cat. If you just want to find out basic information about the images in a stream, you can use pamfile on the stream. To extract images from a stream and generate a single stream containing them, use pampick.","Process Name":"pamsplit","Link":"https:\/\/linux.die.net\/man\/1\/pamsplit"}},{"Process":{"Description":"This program is part of Netpbm(1). pamstack reads multiple PAM or PNM images as input and produces a PAM image as output, consisting of all the planes (channels) of the inputs, stacked in the order specified. For any one (but not more) of the input files, you may specify '-' to mean Standard Input. If you specify no arguments at all, the input is one file: Standard Input. The output is the same dimensions as the inputs, except that the depth is the sum of the depths of the inputs. It has the same maxval. pamstack fails if the inputs are not all the same width, height, and maxval. The tuple type is a null string unless you specify the -tupletype option. pamstack works with multi-image streams. It stacks the 1st image in all the streams into one output image (the first one in the output stream), then stacks the 2nd image in all the streams into the 2nd image in the output stream, and so on, until one of the streams runs dry. It's like a matrix operation. Before Netpbm 10.32 (February 2006), pamstack ignored all but the first image in each input stream. pamchannel does the opposite of pamstack: It extracts individual planes from a single PAM. Use pamtopnm(1)toconvertasuitablePAM image to a more traditional PNM (PBM, PGM, or PPM) image. (But there's no need to do that if you're going to feed it to a modern Netpbm program -- they all take suitable PAM input directly). One example of using pamstack is that some Netpbm programs accept as input a PAM that represents graphic image with transparency information. Taking a color image for example, this would be a PAM with tuple type \"RGB_ALPHA\". In Netpbm, such images were traditionally represented as two images - a PPM for the color and a PGM for the transparency. To convert a PPM\/PGM pair into PAM(RGB_ALPHA) input that newer programs require, do something like this: $ pamstack -tupletype=RGB_ALPHA myimage.ppm myalpha.pgm | \\\n      pamtouil >myimage.uil","Process Name":"pamstack","Link":"https:\/\/linux.die.net\/man\/1\/pamstack"}},{"Process":{"Description":"This program is part of Netpbm(1). pamstereogram inputs a height map (a map of the distances from your eye of the points in a scene) and outputs a single-image stereogram (SIS). A SIS is a 2-D image specially designed to appear three dimensional when viewed with relaxed, slightly unfocused eyes. What's exciting about single-image stereograms is that they don't require special glasses to view, although it does require a bit of practice to train your eyes to unfocus properly. The pamstereogram program provides a wealth of control over how the stereogram is generated, including the following: \u2022 black and white, grayscale, or color output \u2022 single-image random-dot stereograms (SIRDS) or single-image stereograms (SIS) using a tiled image \u2022 images targeting a given device resolution and eye separation \u2022 optional guide boxes to assist in focusing \u2022 the ability to trade off depth levels for easier viewing \u2022 choice of wall-eyed or cross-eyed stereograms The output is a PAM image on standard output. Options control the exact format of the PAM. If you want a PNM (PBM, PGM, or PPM) image, use pamtopnm on the output. There is no need to convert if you will use the image as input to a current Netpbm program, but many other programs don't know what a PAM is. To make a red\/green type of stereogram (that you view with 3-D glasses) instead, see ppm3d.","Process Name":"pamstereogram","Link":"https:\/\/linux.die.net\/man\/1\/pamstereogram"}},{"Process":{"Description":"This program is part of Netpbm(1). pamstretch scales up pictures by integer values, either vertically, horizontally, or both. pamstretch differs from pamscale and pamenlarge in that when it inserts the additional rows and columns, instead of making the new row or column a copy of its neighbor, pamstretch makes the new row or column an interpolation between its neighbors. In some images, this produces better looking output. To scale up to non-integer pixel sizes, e.g. 2.5, try pamstretch-gen(1)instead. Options let you select alternative methods of dealing with the right\/bottom edges of the picture. Since the interpolation is done between the top-left corners of the scaled-up pixels, it's not obvious what to do with the right\/bottom edges. The default behaviour is to scale those up without interpolation (more precisely, the right edge is only interpolated vertically, and the bottom edge is only interpolated horizontally), but there are two other possibilities, selected by the blackedge and dropedge options.","Process Name":"pamstretch","Link":"https:\/\/linux.die.net\/man\/1\/pamstretch"}},{"Process":{"Description":"This program is part of Netpbm(1). pamstretch-gen is a program which uses pamstretch(1), pnmfile(1),and pamscale(1)tosmoothlyscaleupaPNMfile by any ratio; it's like a more general version of pamstretch (hence the name). But other than the 'any ratio' bit, it's much the same as pamstretch. :-)","Process Name":"pamstretch-gen","Link":"https:\/\/linux.die.net\/man\/1\/pamstretch-gen"}},{"Process":{"Description":"This program is part of Netpbm(1). pamsumm reads a Netpbm image (PNM or PAM) and performs a summary function over all the samples in all the rows, columns, and planes and prints the result to Standard Output. pamsumm performs the operation on the actual sample values, not on the light intensities represented by them in the case that the image is a PGM or PPM image or PAM equivalent. If you want to do arithmetic on light intensities of such a visual image, you can use pnmgamma to convert it to one with samples proportional to light intensity, and then use pamsumm on the result. If you want to summarize by column (e.g. add up the columns separately), use pamsummcol. If you want to summarize by row, use a combination of pamsummcol and pamflip. If you want to summarize a particular plane, use pamchannel to extract it and then pamsumm.","Process Name":"pamsumm","Link":"https:\/\/linux.die.net\/man\/1\/pamsumm"}},{"Process":{"Description":"This program is part of Netpbm(1). pamsummcol reads a Netpbm image (PNM or PAM) and performs a summary function over all the rows in each column (sum, mean, etc.). It produces an image of the same kind that the same width and depth as the input, and one row high. Its sample values are the result of the summary. pamsummcol performs the summary operation on each plane independently. pamsummcol performs the operation on the actual sample values, not on the light intensities represented by them in the case that the image is a PGM or PPM image. If you want to summarize by row instead of by column, run the input through pamflip first (and if you want the output to be a single column instead of a single row, use pamflip again). If you want to summarize over the entire image (getting a one-tuple output image), use pamsumm to get a summary row, pamflip to turn that into a column, the pamsumm again to summarize the column. If you want to summarize the individual samples in an entire image, instead of by tuple, use pamsumm. pamsummcol performs the operation on the actual sample values, not on the light intensities represented by them in the case that the image is a PGM or PPM image or PAM equivalent. You can use pnmgamma to convert such an image to one with samples proportional to light intensity, and then use pamsummcol on the result. You can achieve the same thing as pamsummcol -mean with pamscale. Just scale vertically to a single row, without scaling horizontally at all. Use the pixel mixing method.","Process Name":"pamsummcol","Link":"https:\/\/linux.die.net\/man\/1\/pamsummcol"}},{"Process":{"Description":"Test pluggable authentication module (PAM) facility. service is the PAM service name. user is the name of the user account to operate with the PAM facility. The following operations are supported. authenticate Authenticate user. A conversation may subsequently take place to prompt user input to retrieve necessary authentication information. acct_mgmt Perform account management on user. A conversation may subsequently take place to prompt user input for necessary authentication information. open_session Open a new session for user. close_session Close the current session for user. chauthtok Change the authentication token currently assigned to user. Conversation may subsequently take place to prompt user input for necessary authentication information. Note that some operations may eventually need additional privileges to fulfill the request depending on the service configuration. Any operation may also be followed by the option flags that are provided between the pair of parenthesis. Flags are all named and combinable or inversible with bitwise operators; \"|\" (OR), \"&\" (AND), \"^\" (XOR) and \"~\" (NOT) are accepted. authenticate(PAM_SILENT | PAM_DISALLOW_NULL_AUTHTOK) The list of allowed options is shown below: - PAM_SILENT - PAM_DISALLOW_NULL_AUTHTOK - PAM_ESTABLISH_CRED - PAM_REINITIALIZE_CRED - PAM_REFRESH_CRED - PAM_CHANGE_EXPIRED_AUTHTOK Additional authentication information such as the name of the remote user, the remote host and the tty can be supplied via -I (--item) option. The following types of information are supported: - service - user - prompt - tty - ruser - rhost","Process Name":"pamtester","Link":"https:\/\/linux.die.net\/man\/1\/pamtester"}},{"Process":{"Description":"This program is part of Netpbm(1). pamthreshold thresholds a grayscale image. Thresholding means dividing the image into background and foreground by comparing every pixel to a thresholding value. The input should be a PGM image or a PAM image of tuple type GRAYSCALE or GRAYSCALE_ALPHA. However, pamthreshold doesn't check; it just thresholds the first channel as if it were grayscale samples and if there is a second channel, processes it as if it is an alpha (transparency) channel. So if you feed it e.g. a PPM image, it will work but produce probably useless results. The output is a PAM with tuple type BLACKANDWHITE or BLACKANDWHITE_ALPHA, depending on whether the input has an alpha channel. You can turn this into a PBM (if you need to use it with an older program that doesn't understand PAM, or you can't afford the 8X amount of space that PAM uses for the image) with pamtopnm. The output is to Standard Output. When the input has an alpha channel, pamthreshold includes an alpha channel in the output. Since the output has maxval 1, the alpha channel can indicate only fully transparent or fully opaque. pamthreshold make it fully transparent where the input is more than half transparent and fully opaque where it isn't. The alpha function was new in Netpbm 10.43 (June 2008). Before that, pamthreshold ignores any alpha channel in the input. Another way to convert a grayscale image to black and white is to dither. Dithering is using clustered black and white pixels such that if you step back and look at the picture, you see varying levels of gray. pamditherbw does dithering.","Process Name":"pamthreshold","Link":"https:\/\/linux.die.net\/man\/1\/pamthreshold"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtilt tries to find the correct angle for untilting (de-skewing) a scanned text document. The output is a single floating-point number (the angle in degrees) for use as the argument to pnmrotate. 'Document skew' is the name given to what happens when you feed a page into an image scanner at an angle: the resulting image is tilted. pamtilt aims to correct that. pamtilt makes three iterations at successively finer increments, testing prospective rotation angles to find the best one. pamtilt works best for straightening images with strong horizontal lines and does poorly with arbitrary photos. If pamtilt has no confidence in its results, it prints the special value 00.00; you can check for this or just pass it as a legal argument to pnmrotate. pamtilt operates on the first plane of the input image, which is either PNM or PAM, and ignores any other planes. Ordinarily, the input is PGM or GRAYSCALE PAM, so there is only one plane. pamtilt works on bilevel (PBM, BLACKANDWHITE PAM) images as well as grayscale, but you will minimize artifacts if you scan and rotate in grayscale before you apply a threshold to make a bilevel image.","Process Name":"pamtilt","Link":"https:\/\/linux.die.net\/man\/1\/pamtilt"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtodjvurle reads a Netpbm image (PNM or PAM equivalent of PNM) as input and produces DjVu Color RLE format as output.","Process Name":"pamtodjvurle","Link":"https:\/\/linux.die.net\/man\/1\/pamtodjvurle"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtofits reads a PNM or PAM image as input and produces a FITS (Flexible Image Transport System) file as output. The resolution of the output file is either 8 bits\/pixel, or 16 bits\/pixel, depending on the value of maxval in the input file. If the input file is a PBM or PGM image, the output file consists of a single plane image (NAXIS = 2). If instead the input file is a PPM image, the output file will consist of a three-plane image (NAXIS = 3, NAXIS3 = 3).","Process Name":"pamtofits","Link":"https:\/\/linux.die.net\/man\/1\/pamtofits"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtogif reads a Netpbm image as input and produces a GIF file as output. This program creates only individual GIF images. To combine multiple GIF images into an animated GIF, use gifsicle (not part of the Netpbm package). pamtogif creates either an original GIF87 format GIF file or the newer GIF89 format. It creates GIF89 when you request features that were new with GIF89, to wit the -transparent or -comment options. Otherwise, it creates GIF87. Really old GIF readers conceivably could not recognize GIF89. The GIF format is not capable of representing an image with more than 256 colors in it (it contains a color map with a maximum size of 256). If the image you want to convert has more colors than that (ppmhist can tell you), you can use pnmquant to reduce it to 256. If your input image is a PAM with transparency information, ppmtogif uses one entry in the GIF colormap specifically for the transparent pixels, so you can have at most 255 opaque colors. In contrast, if you use the -transparent option, one of the colors from the input becomes transparent, so the limit is still 256. pamtogif was new in Netpbm 10.37 (December 2006). In older Netpbm, use ppmtogif.","Process Name":"pamtogif","Link":"https:\/\/linux.die.net\/man\/1\/pamtogif"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtohdiff takes a PAM (or PNM) image as input and produced a horizontal difference image version of it as output. A horizontal difference image is one where the samples in each row indicate the difference between the sample value in the corresponding sample of the input image and the sample directly above it (in the previous row) in the input image. The horizontal difference image has the property that if a row of the original image is identical to the row above it over a long extent, the corresponding row in the horizontal difference image will contain all zeroes. That makes it compress better than the original image. Because the horizontal difference samples can be positive or negative, but PAM samples are unsigned integers, the samples in the horizontal difference image PAM are defined to be the difference modulus the range of the input (maxval + 1). This doesn't lose any information, as it might seem, because: of the two differences that could result in the same pamtohdiff output value (e.g. if maxval is 99, +20 and -80 would both result in \"20\" in the output), only one is possible in context and the other would result, when reconstructing the original image, in a value less than 0 or greater than maxval. Before the modulus operation, the values pamtohdiff computes are also biased by half the maxval. This is to make the results easier to inspect visually. Because of the bias, you can display the pamtohdiff output as if it were a PNM image. As long as none of your differences are more than half the maxval, large negative differences show up as dark spots, smaller negative differences are lighter, zero differences are medium intensity, and positive differences are light. If you want this to work even for images that have differences that exceed half the maxval, just use ppmdim 50 on the original image. To avoid losing information, though, do a pamdepth to double the maxval first. Note that because of the transfer function just described, a difference of zero, which is most common, is represented by a PAM sample value in the output of one half the maxval. The output PAM has a tuple type of \"hdiff\". You can use hdifftopam to recover the original image from a horizontal difference image PAM.","Process Name":"pamtohdiff","Link":"https:\/\/linux.die.net\/man\/1\/pamtohdiff"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtohtmltbl converts a visual image to an HTML table with one cell per pixel. The cell is empty, but its background color is that of the pixel. file is a PBM, PGM, PPM, or PAM file. If PAM, it must be a standard visual image of tuple type RGB, GRAYSCALE, or BLACKANDWHITE, or something equivalent with extra higher numbered channels, but pamtohtmltbl doesn't check the tuple type; it just assumes. Note that the more normal way to include a visual image in an HTML document is with a <IMG> tag. Not all web browsers render tables as pamtohtmltbl expects, and therefore show a grossly distorted image. Internet Explorer 7 on Windows and Opera 9.02 on Windows have been seen to work; Firefox 2.0.0.16 on the same Windows system has been seen not to.","Process Name":"pamtohtmltbl","Link":"https:\/\/linux.die.net\/man\/1\/pamtohtmltbl"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtojpeg2k converts the named PBM, PGM, PPM, or PAM file, or Standard Input if no file is named, to a JPEG-2000 code stream (JPC) file on Standard Output. The JPEG-2000 specification specifies two different formats: JP2 and JPEG-2000 code stream (JPC). JP2 represents a visual image quite specifically, whereas JPC is a more or less arbitrary array of codes. pamtojpeg2k can't produce a JP2, but the JPC image that pamtojpeg2k produces is very similar to a JP2 if the input is a PBM, PGM, or PPM image or equivalent PAM image. One difference is that that RGB intensity values in a JP2 are SRGB values, while pamtojpeg2k produces ITU-R Recommedation BT.709 values. Those are very similar, but not identical. Another difference is that a JP2 can contain extra information about an image that JPC cannot. When the input is a PAM image other than a PBM, PGM, or PPM equivalent, the JPC raster produced contains whatever the PAM raster does. It can have any number of planes with any meanings; the planes are in the same order in the JPC output as in the PAM input. A JPC image has a \"precision,\" which is the number of bits used for each code (in Netpbm lingo, \"sample\"). Actually, it has a separate precision for each component. pamtojpeg2k uses for the precision of every component the least number of bits that can represent the maxval of the input image. A JPC image does not have an independent concept of maxval; the maxval of a JPC sample is the maximum value that the number of bits specified by the precision can represent in pure binary code. E.g. if the precision is 4, the maxval is 15. pamtojpeg2k does of course scale the sample values from the input maxval to the output maxval. Example: The input maxval is 99. This means JPC precision is 7 bits and the JPC maxval is 127. A sample value of 33 in the input becomes a sample value of 43 in the output. pamtojpeg2k generates the JPC output with the Jasper JPEG-2000 library . See documentation of the library for details on what pamtojpeg2k produces. Note that the Jasper library contains facilities for reading PNM images, but pamtojpeg2k does not use those. It uses the Netpbm library instead. Note that the makers of the Jasper library write it \"JasPer,\" but Netpbm documentation follows standard American English typography rules, which don't allow that kind of capitalization. Use jpeg2ktopam to convert in the other direction. The program jasper, which is packaged with the Jasper JPEG-2000 library, also converts between JPEG-2000 and PNM formats. Because it's packaged with the library, it may exploit it better, especially recently added features. However, since it does not use the Netpbm library to read and write the Netpbm formats, it doesn't do as good a job on that side.","Process Name":"pamtojpeg2k","Link":"https:\/\/linux.die.net\/man\/1\/pamtojpeg2k"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtompfont reads a Netpbm image (PNM or PAM) and converts it to an Mplayer bitmap font raster file. This is the original font format used by Mplayer (for subtitles, on-screen messages, etc.), before it had the ability to use Freetype to access standard fonts. The format was apparently an image format before Mplayer adopted it for fonts, but I have no idea where it came from or where else it might be used. An Mplayer bitmap font consists of a font descriptor file and raster files. The font descriptor file identifies the raster files by file name. A raster file contains a single rectangular raster image which contains an arrangement of a bunch of glyphs. Each glyph is a rectangular image and the font descriptor indicates where in the image the glyph for each codepoint is. Every glyph in the font has the same height, so the font descriptor just indicates the file position in the raster file of the to left corner of the glyph, and the width of the glyph in pixels.","Process Name":"pamtompfont","Link":"https:\/\/linux.die.net\/man\/1\/pamtompfont"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtooctaveimg reads a Netpbm image as input and produces a GNU Octave image file as output. An Octave image file (called 'Octave's image format' in Octave documentation) is a particular kind of Octave data file. It describes two matrices: \u2022 the image itself as a list of indexes into a colormap, and \u2022 the corresponding colormap as a list of {red, green, blue} triplets. An Octave data file is an ASCII text file that you use to import data to Octave. See the Image Processing chapter of the GNU Octave manual for details. pamtooctaveimg writes the output Octave image to Standard Output.","Process Name":"pamtooctaveimg","Link":"https:\/\/linux.die.net\/man\/1\/pamtooctaveimg"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtopam simply copies a PAM image from Standard Input to Standard Output. This may seem an unnecessary duplication of cat, but remember that a PAM program can read a PBM, PGM, or PPM image as if it were PAM. So pamtopam can read either a PBM, PGM, PPM, or PAM image and produce a PAM image as output. Even that is of limited usefulness because of the fact that almost any program to which you would feed the resulting PAM image could also just take the original image directly. However, sometimes you really want a true PAM image. You can do a more general job of translating PAM\/PNM to PAM with pamchannel.","Process Name":"pamtopam","Link":"https:\/\/linux.die.net\/man\/1\/pamtopam"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtopfm reads a Netpbm image (PNM or PAM) and converts it to a PFM (Portable Float Map) image. The PFM (Portable Float Map) image format is a lot like PPM, but uses floating point numbers with no maxval to achieve a High Dynamic Range (HDR) format. That means it doesn't have a concept of absolute color and it can represent generic light intensity information rather than just visual information like PPM does. For example, two pixels that are so close in intensity that the human eye cannot tell them apart are not visually distinct, so a visual image format such as PPM would have no reason to use different sample values for them. But an HDR format would. There are details of the PFM format in the PFM Format Description (1). USC's HDRShop program and a program called Lefty use it. pamtopfm creates a color PFM image if its input is RGB (PPM) and a non-color PFM otherwise. Use pfmtopam(1)toconvertaPFM image to Netpbm format.","Process Name":"pamtopfm","Link":"https:\/\/linux.die.net\/man\/1\/pamtopfm"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtopnm reads a PAM image as input and produces an equivalent PBM, PGM, or PPM (i.e. PNM) image, whichever is most appropriate, as output. pamtopnm assumes the PAM image represents the information required for a PBM, PGM, or PPM image if its tuple type is 'BLACKANDWHITE', 'GRAYSCALE', or 'RGB' and its depth and maxval are appropriate. If this is not the case, pamtopnm fails. However, you can override the tuple type requirement with the -assume option. As with any Netpbm program that reads PAM images, pamtopnm also reads PNM images as if they were PAM. In that case, pamtopnm's functions reduces to simply copying the input to the output. But this can be useful in a program that doesn't know whether its input is PAM or PNM but needs to feed it to a program that only recognizes PNM.","Process Name":"pamtopnm","Link":"https:\/\/linux.die.net\/man\/1\/pamtopnm"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtosvg reads a PNM image as input and produce an SVG (Scalable Vector Graphics) image as output. Thus, it traces curves in the input image and creates a set of splines that represent the image. SVG is a vector image format, which means it describes curves that compose an image. By contrast, PNM is a raster format, which means it describes dots that compose an image. The main practical difference between the two types is that you can scale vector images better. A vector image also takes a lot less data to describe an image if the image is composed of simple curves. That means it is really an understatement to say that pamtosvg is an image format converter. It's really an image tracer. Its main job is to trace a raster image and find the lines in it. It then represents its findings in SVG format. pamtosvg does the same kind of thing that StreamLine, CorelTrace, and Autotrace do. It is in fact derived from Autotrace. SVG is a gigantic format, capable of amazing things. pamtosvg exploits only a morsel of it. The SVG image produced by pamtosvg consists of a single <svg> element, which has a 'width' attribute and a 'height' attribute. The value of that element is composed of <path> elements. That's it. In the SVG output, distances are unitless, with one unit corresponding to one pixel of the input. So that pamtosvg will find simple curves in the image, you may want to remove speckles from it with pbmclean and consolidate multiple shades into single colors with pnmquant first. For more information on SVG, see the Worldwide Web Consortium's SVG web page .","Process Name":"pamtosvg","Link":"https:\/\/linux.die.net\/man\/1\/pamtosvg"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtotga reads a PBM, PGM, PPM, or PAM image as input and produces a TrueVision Targa file as output. The PAM image may be either a BLACKANDWHITE, GRAYSCALE, RGB, or RGB_ALPHA image. To create a TGA image with transparency (i.e. with an alpha mask), use RGB_ALPHA PAM input. Some Netpbm programs that generate images with alpha masks generate them in that format. For another way to create the proper input stream, see pamstack(1). It is unclear that anything except pamtotga knows about TGAs with transparency. The history behind this feature of pamtotga is not clear. The format pamtotga produces is simply the same as an ordinary RGB TGA image except with a 4th plane added for transparency. The PixelSize field of the TGA header specifies 32 bits instead of 24 and the raster has an extra byte added to each pixel, at the tail end. The value of that byte has the same meaning as in a PAM image with maxval 255.","Process Name":"pamtotga","Link":"https:\/\/linux.die.net\/man\/1\/pamtotga"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtotiff reads a PNM or PAM image as input and produces a TIFF file as output. Actually, it handles multi-image Netpbm streams, producing multi-image TIFF streams (i.e. a TIFF stream with multiple 'directories'). But before Netpbm 10.27 (March 2005), it ignored all but the first Netpbm image in the input stream. The Output File The output goes to Standard Output. pamtotiff approaches this output file differently from Unix and Netpbm convention. This is entirely due to pamtotiff's use of the TIFF library to do all TIFF output. \u2022 The output file must be seekable. pamtotiff does not write it sequentially. Therefore, you can't use a pipe; you can't pipe the output of pamtotiff to some other program. But any regular file should work. \u2022 If the output file descriptor is readable, you must either specify -append so as to add to the existing file, or make sure the file is empty. Otherwise, pamtotiff will fail with an unhelpful message telling you that a TIFF library function failed to open the TIFF output stream. \u2022 If you are converting multiple images (your input stream contains multiple images), the output file must be both readable and writable. If you're using a Unix command shell to run pamtotiff, you use facilities of your shell to set up Standard Output. In Bash, for example, you would set up a write-only Standard Output to the file \/tmp\/myimage.tiff like this: $ pamtotiff myimage.pnm >\/tmp\/myimage.tiff In Bash, you would set up a read\/write Standard Output to the file \/tmp\/myimage.tiff like this: $ pamtotiff myimage.pnm 1<>\/tmp\/myimage.tiff TIFF Capability pamtotiff uses the Libtiff.org TIFF library (or whatever equivalent you provide) to generate the TIFF output. Details of the format it produces are therefore controlled by that library.","Process Name":"pamtotiff","Link":"https:\/\/linux.die.net\/man\/1\/pamtotiff"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtouil reads a PNM or PAM image as input and produces a Motif UIL icon file as output. If the input is PAM, it may be either a regular grayscale or color image or grayscale+alpha or color+alpha. Where the alpha channel is present, pamtouil renders pixels that are more than half transparent as transparent in the output. In the UIL's colormap, pamtouil uses the color names from the RGB database -- the same one ppmmake(1) uses. Where a color in the input does not exactly match one of the colors named in the RGB database, pamtouil uses the closest color named in the RGB database.","Process Name":"pamtouil","Link":"https:\/\/linux.die.net\/man\/1\/pamtouil"}},{"Process":{"Description":"This program is part of Netpbm(1). pamtoxvmini reads a Netpbm image (PAM or PNM) and produces an XV 'thumbnail' picture (a miniature picture normally generated by the 'VisualSchnauzer' browser) as output.","Process Name":"pamtoxvmini","Link":"https:\/\/linux.die.net\/man\/1\/pamtoxvmini"}},{"Process":{"Description":"This program is part of Netpbm(1). pamundice reads a bunch of PAM, PBM, PGM, or PPM images as input and combines them as a grid of tiles into a single output image of the same kind on Standard Output. You can optionally make the pieces overlap. See the input_filename_pattern argument for information on naming of the input files. The input images must all have the same format (PAM, PPM, etc.) and maxval and for PAM must have the same depth and tuple type. All the images in a rank (horizontal row of tiles) must have the same height. All the images in a file (vertical column of tiles) must have the same width. But it is not required that every rank have the same height or every file have the same width. pamdice is the inverse of pamundice. You can use pamundice to reassemble an image sliced up by pamdice. You can use pamdice to recreate the tiles of an image created by pamundice, but to do this the original ranks must all have been the same height except for the bottom one and the original files must all have been the same width except the right one. One use for this is to make pieces that take less computer resources than the whole image to process. For example, you might have an image so large that an image editor can't read it all into memory or processes it very slowly. You can split it into smaller pieces with pamdice, edit one at a time, and then reassemble them with pamundice. An alternative to join images in a single direction (i.e. a single rank or a single file) is pnmcat. pnmcat gives you more flexibility than pamundice in identifying the input images: you can supply them on Standard Input or as a list of arbitrarily named files. To join piecewise photographs, use pnmstitch instead of pamundice, because it figures out where the pieces overlap, even if they don't overlap exactly vertically or horizontally. To create an image of the same tile repeated in a grid, that's pnmtile. pnmindex does a similar thing to pamundice: it combines a bunch of small images in a grid into a big one. But its purpose is to produce a an index image of the input images. So it leaves space between them and has labels for them, for example.","Process Name":"pamundice","Link":"https:\/\/linux.die.net\/man\/1\/pamundice"}},{"Process":{"Description":"This program is part of Netpbm(1). pamx displays a Netpbm image in an X Window System window. It is like a very simple version of the classic X image viewer xloadimage. If you don't specify the input file netpbm_file, the input is from Standard Input. The input image can be any Netpbm image format. If the input is a multi-image stream, pamx ignores all but the first image. pamx is not the best choice for general purpose viewing of images, because it is a traditional simple Netpbm building block. It is a good thing to build into other programs and can be useful for debugging more complex systems, but you can get much more powerful viewers that can display Netpbm images. For example, xloadimage, xli, xzgv, and any web browser. The initial window is at most 90% of the size of the display unless the window manager does not correctly handle window size requests or if you've used the -fullscreen option. You may move the image around in the window by dragging with the first mouse button. The cursor will indicate which directions you may drag, if any. You may exit the window by typing 'q' or control-C when the keyboard focus is on the window. ppmsvgalib is a similar program that displays an image on a Linux system without the need for the X Window System.","Process Name":"pamx","Link":"https:\/\/linux.die.net\/man\/1\/pamx"}},{"Process":{"Description":"The pand PAN daemon allows your computer to connect to ethernet networks using Bluetooth.","Process Name":"pand","Link":"https:\/\/linux.die.net\/man\/1\/pand"}},{"Process":{"Description":"Pandoc is a Haskell library for converting from one markup format to another, and a command-line tool that uses this library. It can read markdown and (subsets of) Textile, reStructuredText, HTML, LaTeX, and DocBook XML; and it can write plain text, markdown, reStructuredText, XHTML, HTML 5, LaTeX (including beamer slide shows), ConTeXt, RTF, DocBook XML, OpenDocument XML, ODT, Word docx, GNU Texinfo, MediaWiki markup, EPUB, Textile, groff man pages, Emacs Org-Mode, AsciiDoc, and Slidy, Slideous, DZSlides, or S5 HTML slide shows. It can also produce PDF output on systems where LaTeX is installed. Pandoc's enhanced version of markdown includes syntax for footnotes, tables, flexible ordered lists, definition lists, delimited code blocks, superscript, subscript, strikeout, title blocks, automatic tables of contents, embedded LaTeX math, citations, and markdown inside HTML block elements. (These enhancements, described below under Pandoc's markdown, can be disabled using the --strict option.) In contrast to most existing tools for converting markdown to HTML, which use regex substitutions, Pandoc has a modular design: it consists of a set of readers, which parse text in a given format and produce a native representation of the document, and a set of writers, which convert this native representation into a target format. Thus, adding an input or output format requires only adding a reader or writer. Using pandoc If no input-file is specified, input is read from stdin. Otherwise, the input-files are concatenated (with a blank line between each) and used as input. Output goes to stdout by default (though output to stdout is disabled for the odt, docx, and epub output formats). For output to a file, use the -o option: pandoc -o output.html input.txt Instead of a file, an absolute URI may be given. In this case pandoc will fetch the content using HTTP: pandoc -f html -t markdown http:\/\/www.fsf.org If multiple input files are given, pandoc will concatenate them all (with blank lines between them) before parsing. The format of the input and output can be specified explicitly using command-line options. The input format can be specified using the -r\/--read or -f\/--from options, the output format using the -w\/--write or -t\/--to options. Thus, to convert hello.txt from markdown to LaTeX, you could type: pandoc -f markdown -t latex hello.txt To convert hello.html from html to markdown: pandoc -f html -t markdown hello.html Supported output formats are listed below under the -t\/--to option. Supported input formats are listed below under the -f\/--from option. Note that the rst, textile, latex, and html readers are not complete; there are some constructs that they do not parse. If the input or output format is not specified explicitly, pandoc will attempt to guess it from the extensions of the input and output filenames. Thus, for example, pandoc -o hello.tex hello.txt will convert hello.txt from markdown to LaTeX. If no output file is specified (so that output goes to stdout), or if the output file's extension is unknown, the output format will default to HTML. If no input file is specified (so that input comes from stdin), or if the input files' extensions are unknown, the input format will be assumed to be markdown unless explicitly specified. Pandoc uses the UTF-8 character encoding for both input and output. If your local character encoding is not UTF-8, you should pipe input and output through iconv: iconv -t utf-8 input.txt | pandoc | iconv -f utf-8 Creating a PDF Earlier versions of pandoc came with a program, markdown2pdf, that used pandoc and pdflatex to produce a PDF. This is no longer needed, since pandoc can now produce pdf output itself. To produce a PDF, simply specify an output file with a .pdf extension. Pandoc will create a latex file and use pdflatex (or another engine, see --latex-engine) to convert it to PDF: pandoc test.txt -o test.pdf Production of a PDF requires that a LaTeX engine be installed (see --latex-engine, below), and assumes that the following LaTeX packages are available: amssymb, amsmath, ifxetex, ifluatex, listings (if the --listings option is used), fancyvrb, enumerate, ctable, url, graphicx, hyperref, ulem, babel (if the lang variable is set), fontspec (if xelatex or lualatex is used as the LaTeX engine), xltxtra and xunicode (if xelatex is used). hsmarkdown A user who wants a drop-in replacement for Markdown.pl may create a symbolic link to the pandoc executable called hsmarkdown. When invoked under the name hsmarkdown, pandoc will behave as if the --strict flag had been selected, and no command-line options will be recognized. However, this approach does not work under Cygwin, due to problems with its simulation of symbolic links.","Process Name":"pandoc","Link":"https:\/\/linux.die.net\/man\/1\/pandoc"}},{"Process":{"Description":"panelctl is a command line tool to send control commands via an IEEE1394 link to an AV\/C Panel such as the Motorola Digital Consumer Terminal (DCT) series. Or for the non-techies: panelctl lets you remote control your digital cable box via a Firewire cable.","Process Name":"panelctl","Link":"https:\/\/linux.die.net\/man\/1\/panelctl"}},{"Process":{"Description":"pango-querymodules collects information about loadable modules for Pango and writes it to stdout. If called without arguments, it looks for modules in the Pango module path. If called with arguments, it looks for the specified modules. The arguments may be absolute or relative paths.","Process Name":"pango-querymodules","Link":"https:\/\/linux.die.net\/man\/1\/pango-querymodules"}},{"Process":{"Description":"Usage: pango-view [OPTION...] - FILE Help Options: -h, --help Show help options --help-all Show all help options --help-cairo Options understood by the cairo backend Cairo backend options: --annotate= 1 or 2 Annotate the output Application Options: --no-auto-dir No layout direction according to contents --backend= cairo\/xft\/ft2\/x Pango backend to use for rendering (default: cairo) --background= red\/#rrggbb\/#rrggbbaa\/transparent Set the background color -q, --no-display Do not display (just write to file or whatever) --dpi= number Set the resolution --align= left\/center\/right Text alignment --ellipsize= start\/middle\/end Ellipsization mode --font= description Set the font description --foreground= red\/#rrggbb\/#rrggbbaa Set the text color --gravity= south\/east\/north\/west\/auto Base gravity: glyph rotation --gravity-hint= natural\/strong\/line Gravity hint --header Display the options in the output --height=+points\/-numlines Height in points (positive) or number of lines (negative) for ellipsizing --hinting= none\/auto\/full Hinting style --indent= points Width in points to indent paragraphs --justify Align paragraph lines to be justified --language= en_US\/etc Language to use for font selection --margin= CSS-style numbers in pixels Set the margin on the output in pixels --markup Interpret text as Pango markup -o, --output= file Save rendered image to output file --pangorc= file pangorc file to use (default is .\/pangorc) --pixels Use pixel units instead of points (sets dpi to 72) --rtl Set base direction to right-to-left --rotate= degrees Angle at which to rotate results -n, --runs= integer Run Pango layout engine this many times --single-par Enable single-paragraph mode -t, --text= string Text to display (instead of a file) --version Show version numbers --waterfall Create a waterfall display -w, --width= points Width in points to which to wrap lines or ellipsize --wrap= word\/char\/word-char Text wrapping mode (needs a width to be set) Pango module interface version: 1.6.0 Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"pango-view","Link":"https:\/\/linux.die.net\/man\/1\/pango-view"}},{"Process":{"Description":"paperconf prints informations about a given paper. The informations that can be obtaineed are the name of the paper, its size and its width or height. When called without arguments, paperconf prints the name of the system- or user-specified paper, obtained by looking in order at the PAPERSIZE environment variable, at the contents of the file specified by the PAPERCONF environment variable, at the contents of the file \/etc\/papersize , consulting the values controlled by the LC_PAPER locale setting, or by using letter as a fall-back value if none of the other alternatives are successful. By default, width and height of the paper are printed in PostScript points.","Process Name":"paperconf","Link":"https:\/\/linux.die.net\/man\/1\/paperconf"}},{"Process":{"Description":"papi_avail is a PAPI utility program that reports information about the current PAPI installation and supported preset events. Using the -e option, it will also display information about specific native events.","Process Name":"papi_avail","Link":"https:\/\/linux.die.net\/man\/1\/papi_avail"}},{"Process":{"Description":"papi_clockres is a PAPI utility program that measures and reports the latency and resolution of the four PAPI timer functions: PAPI_get_real_cyc(), PAPI_get_virt_cyc(), PAPI_get_real_usec() and PAPI_get_virt_usec().","Process Name":"papi_clockres","Link":"https:\/\/linux.die.net\/man\/1\/papi_clockres"}},{"Process":{"Description":"papi_command_line is a PAPI utility program that adds named events from the command line to a PAPI EventSet and does some work with that EventSet. This serves as a handy way to see if events can be counted together, and if they give reasonable results for known work.","Process Name":"papi_command_line","Link":"https:\/\/linux.die.net\/man\/1\/papi_command_line"}},{"Process":{"Description":"papi_cost is a PAPI utility program that computes the min \/ max \/ mean \/ std. deviation of execution times for PAPI start\/stop pairs and for PAPI reads. This information provides the basic operating cost to a user's program for collecting hardware counter data. Command line options control display capabilities.","Process Name":"papi_cost","Link":"https:\/\/linux.die.net\/man\/1\/papi_cost"}},{"Process":{"Description":"papi_decode is a PAPI utility program that converts the PAPI presets for the existing library into a comma separated value format that can then be viewed or modified in spreadsheet applications or text editors, and can be supplied to papi_encode_events(3) as a way of adding or modifying event definitions for specialized applications. The format for the csv output consists of a line of field names, followed by a blank line, followed by one line of comma separated values for each event contained in the preset table. A portion of this output (for Pentium 4) is shown below: name,derived,postfix,short_descr,long_descr,note,[native,...]\nPAPI_L1_ICM,NOT_DERIVED,,\"L1I cache misses\",\"Level 1 instruction cache\nmisses\",,BPU_fetch_request_TCMISS\nPAPI_L2_TCM,NOT_DERIVED,,\"L2 cache misses\",\"Level 2 cache misses\",,BSQ_cache_reference_RD_2ndL_MISS_WR_2ndL_MISS\nPAPI_TLB_DM,NOT_DERIVED,,\"Data TLB misses\",\"Data translation lookaside\nbuffer misses\",,page_walk_type_DTMISS","Process Name":"papi_decode","Link":"https:\/\/linux.die.net\/man\/1\/papi_decode"}},{"Process":{"Description":"papi_event_chooser is a PAPI utility program that reports information about the current PAPI installation and supported preset events.","Process Name":"papi_event_chooser","Link":"https:\/\/linux.die.net\/man\/1\/papi_event_chooser"}},{"Process":{"Description":"papi_mem_info is a PAPI utility program that reports information about the cache memory architecture of the current processor, including number, types, sizes and associativities of instruction and data caches and Translation Lookaside Buffers.","Process Name":"papi_mem_info","Link":"https:\/\/linux.die.net\/man\/1\/papi_mem_info"}},{"Process":{"Description":"papi_native_avail is a PAPI utility program that reports information about the native events available on the current platform. A native event is an event specific to a specific hardware platform. On many platforms, a specific native event may have a number of optional settings. In such cases, the native event and the valid settings are presented, rather than every possible combination of those settings. For each native event, a name, a description, and specific bit patterns are provided.","Process Name":"papi_native_avail","Link":"https:\/\/linux.die.net\/man\/1\/papi_native_avail"}},{"Process":{"Description":"paplay is a simple tool for playing back audio files on a PulseAudio sound server. It understands all audio file formats supported by libsndfile.","Process Name":"paplay","Link":"https:\/\/linux.die.net\/man\/1\/paplay"}},{"Process":{"Description":"paps reads a UTF-8 encoded file and generates a PostScript language rendering of the file. The rendering is done by creating outline curves through the pango ft2 backend.","Process Name":"paps","Link":"https:\/\/linux.die.net\/man\/1\/paps"}},{"Process":{"Description":"par takes a list of files to run a command on. The first line of each file begins with a colon (:) or a pound-sign (#). If a colon, the remainder of the line is a command to run for each of the subsequent lines. If a pound-sign, then each subsequent line is a (self-contained) command, unless the -c option was specified, in which case it operates as if the argument to -c had followed a colon on the first line. In each of the cases where the lines of the file following the first are not commands (i.e.: colon or -c), instances of open-close braces ({}) in the command will be replaced by these values. For example, a inputfile whose contents is: : echo {} a b c run with par like so: %par -q inputfile will produce the following output (order will vary): b a c The command-line options are as follows: -c Command to be run on each of the arguments following the command-line options, where the first line of the input file(s) begins with a pound-sign (#). -d Print debugging information on standard error (stderr). -f No file or STDIN, just run a quantity of the command specified with -c. -i Run commands interactively through (multiple) xterm(1) processes. -l Prefix of logfile name, as in prefix.N where N is the par process number ([0..]). Default: par.log.<time>.[0..] -n Number of simultaneous processes. Default: 3 -q Quiet mode. Do not log anything. -q is mutually exclusive with the -x and -l options and the option appearing last will take precedence. -x View par logs in real-time via an xterm(1).","Process Name":"par","Link":"https:\/\/linux.die.net\/man\/1\/par"}},{"Process":{"Description":"parallel runs the specified command, passing it a single one of the specified arguments. This is repeated for each argument. Jobs may be run in parallel. The default is to run one job per CPU. If no command is specified before the --, the commands after it are instead run in parallel.","Process Name":"parallel","Link":"https:\/\/linux.die.net\/man\/1\/parallel"}},{"Process":{"Description":"Parcellite is a lightweight GTK+ clipboard manager. This is a stripped down, basic-features-only clipboard manager with a small memory footprint for those who like simplicity. Parcellite features a clipboard CLI. Unrecognized options and the contents of your standard input get copied to your clipboard. See CLI EXAMPLES. OPTIONS -?, --help Show help options -d, --daemon Run as daemon. Use this mode if you just want Parcellite to keep your clipboard and primary contents safe -n, --no-icon Do not use status icon -o, --output Print clipboard contents","Process Name":"parcellite","Link":"https:\/\/linux.die.net\/man\/1\/parcellite"}},{"Process":{"Description":"Invokes the PARI-GP calculator, loading the file1, file2, ... (written in the GP language) on startup. gp is an advanced programmable calculator, which computes symbolically as long as possible, numerically where needed, and contains a wealth of number-theoretic functions (elliptic curves, class field theory...). It can be programmed with the GP scripting language. Its basic data types are numbers integers, real numbers, exact rational numbers, algebraic numbers, p-adic numbers, modular integers (integers modulo n), complex numbers, polynomials, rational functions, and power series, integral binary quadratic forms, matrices, vectors, and lists, character strings, and recursive combinations of these.","Process Name":"pari","Link":"https:\/\/linux.die.net\/man\/1\/pari"}},{"Process":{"Description":"","Process Name":"parrot","Link":"https:\/\/linux.die.net\/man\/1\/parrot"}},{"Process":{"Description":"","Process Name":"parrot-nqp","Link":"https:\/\/linux.die.net\/man\/1\/parrot-nqp"}},{"Process":{"Description":"Create src\/parrot_config.c with relevant runtime for the config process. The data in the generated configuration file is a serialised hash which can be passed to the parrot VM by calling Parrot_set_config_hash and will in turn be used to provide the config environment for subsequently created Interpreters. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"parrot_config","Link":"https:\/\/linux.die.net\/man\/1\/parrot_config"}},{"Process":{"Description":"","Process Name":"parse.pl","Link":"https:\/\/linux.die.net\/man\/1\/parse.pl"}},{"Process":{"Description":"Dia is a diagram creation program for Linux, Unix and Windows released under the GPL license. parsediasql is a Command-line interface to Parse::Dia::SQL Parse::Dia::SQL converts Dia class diagrams into SQL .","Process Name":"parsediasql","Link":"https:\/\/linux.die.net\/man\/1\/parsediasql"}},{"Process":{"Description":"partimage backs up disk partitions into image files and restores them.","Process Name":"partimage","Link":"https:\/\/linux.die.net\/man\/1\/partimage"}},{"Process":{"Description":"pass is a very simple password store that keeps passwords inside gpg2(1) encrypted files inside a simple directory tree residing at ~\/.password-store. The pass utility provides a series of commands for manipulating the password store, allowing the user to add, remove, edit, synchronize, generate, and manipulate passwords. If no COMMAND is specified, COMMAND defaults to either show or ls, depending on the type of specifier in ARGS. Otherwise COMMAND must be one of the valid commands listed below. Several of the commands below rely on or provide additional functionality if the password store directory is also a git repository. If the password store directory is a git repository, all password store modification commands will cause a corresponding git commit. See the EXTENDED GIT EXAMPLE section for a detailed description using init and git(1). The init command must be run before other commands in order to initialize the password store with the correct gpg key id. Passwords are encrypting using the gpg key set with init. There is a corresponding bash completion script for use with tab completing password names in bash(1).","Process Name":"pass","Link":"https:\/\/linux.die.net\/man\/1\/pass"}},{"Process":{"Description":"passenger-config shows the current configuration settings for Phusion Passenger. You need to select one of the following options.","Process Name":"passenger-config","Link":"https:\/\/linux.die.net\/man\/1\/passenger-config"}},{"Process":{"Description":"Stress test the given (Phusion Passenger-powered) website by - crawling it with multiple concurrently running crawlers. - gracefully restarting Apache at random times - restarting the target (Phusion Passenger-powered) application at random times","Process Name":"passenger-stress-test","Link":"https:\/\/linux.die.net\/man\/1\/passenger-stress-test"}},{"Process":{"Description":"","Process Name":"passmass","Link":"https:\/\/linux.die.net\/man\/1\/passmass"}},{"Process":{"Description":"The passwd utility is used to update user's authentication token(s). This task is achieved through calls to the Linux-PAM and Libuser API. Essentially, it initializes itself as a \"passwd\" service with Linux-PAM and utilizes configured password modules to authenticate and then update a user's password. A simple entry in the global Linux-PAM configuration file for this service would be: # # passwd service entry that does strength checking of # a proposed password before updating it. # passwd password requisite pam_cracklib.so retry=3 passwd password required pam_unix.so use_authtok # Note, other module types are not required for this application to function correctly.","Process Name":"passwd","Link":"https:\/\/linux.die.net\/man\/1\/passwd"}},{"Process":{"Description":"passwdGen is a utility useful to system administrators and end-users who, for security reasons, wish to generate random passwords based on their criteria","Process Name":"passwdgen","Link":"https:\/\/linux.die.net\/man\/1\/passwdgen"}},{"Process":{"Description":"Write lines consisting of the sequentially corresponding lines from each FILE, separated by TABs, to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. -d, --delimiters= LIST reuse characters from LIST instead of TABs -s, --serial paste one file at a time instead of in parallel --help display this help and exit --version output version information and exit","Process Name":"paste","Link":"https:\/\/linux.die.net\/man\/1\/paste"}},{"Process":{"Description":"pasuspender is a tool that can be used to tell a local PulseAudio sound server to temporarily suspend access to the audio devices, to allow other applications access them directly. pasuspender will suspend access to the audio devices, fork a child process, and when the child process terminates, resume access again. Make sure to include -- in your pasuspender command line before passing the subprocess command line (as shown above). Otherwise pasuspender itself might end up interpreting the command line switches and options you intended to pass to the subprocess.","Process Name":"pasuspender","Link":"https:\/\/linux.die.net\/man\/1\/pasuspender"}},{"Process":{"Description":"pat2ppm is a program that converts an image file from PAT to PPM format. infile is a PAT file; the resulting .ppm file is written to stdout.","Process Name":"pat2ppm","Link":"https:\/\/linux.die.net\/man\/1\/pat2ppm"}},{"Process":{"Description":"pat2spi is a translator from ALLIANCE pattern format (\".pat\") to spice PWL format (\".spi\"). An optional slope parameter can be used to specify the slope value in pico second.","Process Name":"pat2spi","Link":"https:\/\/linux.die.net\/man\/1\/pat2spi"}},{"Process":{"Description":"patch takes a patch file patchfile containing a difference listing produced by the diff program and applies those differences to one or more original files, producing patched versions. Normally the patched versions are put in place of the originals. Backups can be made; see the -b or --backup option. The names of the files to be patched are usually taken from the patch file, but if there's just one file to be patched it can be specified on the command line as originalfile. Upon startup, patch attempts to determine the type of the diff listing, unless overruled by a -c (--context), -e (--ed), -n (--normal), or -u (--unified) option. Context diffs (old-style, new-style, and unified) and normal diffs are applied by the patch program itself, while ed diffs are simply fed to the ed(1) editor via a pipe. patch tries to skip any leading garbage, apply the diff, and then skip any trailing garbage. Thus you could feed an article or message containing a diff listing to patch, and it should work. If the entire diff is indented by a consistent amount, or if a context diff contains lines ending in CRLF or is encapsulated one or more times by prepending \"- \" to lines starting with \"-\" as specified by Internet RFC 934, this is taken into account. After removing indenting or encapsulation, lines beginning with # are ignored, as they are considered to be comments. With context diffs, and to a lesser extent with normal diffs, patch can detect when the line numbers mentioned in the patch are incorrect, and attempts to find the correct place to apply each hunk of the patch. As a first guess, it takes the line number mentioned for the hunk, plus or minus any offset used in applying the previous hunk. If that is not the correct place, patch scans both forwards and backwards for a set of lines matching the context given in the hunk. First patch looks for a place where all lines of the context match. If no such place is found, and it's a context diff, and the maximum fuzz factor is set to 1 or more, then another scan takes place ignoring the first and last line of context. If that fails, and the maximum fuzz factor is set to 2 or more, the first two and last two lines of context are ignored, and another scan is made. (The default maximum fuzz factor is 2.) Hunks with less prefix context than suffix context (after applying fuzz) must apply at the start of the file if their first line number is 1. Hunks with more prefix context than suffix context (after applying fuzz) must apply at the end of the file. If patch cannot find a place to install that hunk of the patch, it puts the hunk out to a reject file, which normally is the name of the output file plus a .rej suffix, or # if .rej would generate a file name that is too long (if even appending the single character # makes the file name too long, then # replaces the file name's last character). The rejected hunk comes out in unified or context diff format. If the input was a normal diff, many of the contexts are simply null. The line numbers on the hunks in the reject file may be different than in the patch file: they reflect the approximate location patch thinks the failed hunks belong in the new file rather than the old one. As each hunk is completed, you are told if the hunk failed, and if so which line (in the new file) patch thought the hunk should go on. If the hunk is installed at a different line from the line number specified in the diff, you are told the offset. A single large offset may indicate that a hunk was installed in the wrong place. You are also told if a fuzz factor was used to make the match, in which case you should also be slightly suspicious. If the --verbose option is given, you are also told about hunks that match exactly. If no original file origfile is specified on the command line, patch tries to figure out from the leading garbage what the name of the file to edit is, using the following rules. First, patch takes an ordered list of candidate file names as follows: \u2022 If the header is that of a context diff, patch takes the old and new file names in the header. A name is ignored if it does not have enough slashes to satisfy the -pnum or --strip=num option. The name \/dev\/null is also ignored. \u2022 If there is an Index: line in the leading garbage and if either the old and new names are both absent or if patch is conforming to POSIX , patch takes the name in the Index: line. \u2022 For the purpose of the following rules, the candidate file names are considered to be in the order (old, new, index), regardless of the order that they appear in the header. Then patch selects a file name from the candidate list as follows: \u2022 If some of the named files exist, patch selects the first name if conforming to POSIX , and the best name otherwise. \u2022 If patch is not ignoring RCS , ClearCase, Perforce, and SCCS (see the -g num or --get=num option), and no named files exist but an RCS , ClearCase, Perforce, or SCCS master is found, patch selects the first named file with an RCS , ClearCase, Perforce, or SCCS master. \u2022 If no named files exist, no RCS , ClearCase, Perforce, or SCCS master was found, some names are given, patch is not conforming to POSIX , and the patch appears to create a file, patch selects the best name requiring the creation of the fewest directories. \u2022 If no file name results from the above heuristics, you are asked for the name of the file to patch, and patch selects that name. To determine the best of a nonempty list of file names, patch first takes all the names with the fewest path name components; of those, it then takes all the names with the shortest basename; of those, it then takes all the shortest names; finally, it takes the first remaining name. Additionally, if the leading garbage contains a Prereq: line, patch takes the first word from the prerequisites line (normally a version number) and checks the original file to see if that word can be found. If not, patch asks for confirmation before proceeding. The upshot of all this is that you should be able to say, while in a news interface, something like the following: | patch -d \/usr\/src\/local\/blurfl and patch a file in the blurfl directory directly from the article containing the patch. If the patch file contains more than one patch, patch tries to apply each of them as if they came from separate patch files. This means, among other things, that it is assumed that the name of the file to patch must be determined for each diff listing, and that the garbage before each diff listing contains interesting things such as file names and revision level, as mentioned previously.","Process Name":"patch","Link":"https:\/\/linux.die.net\/man\/1\/patch"}},{"Process":{"Description":"","Process Name":"patchperl","Link":"https:\/\/linux.die.net\/man\/1\/patchperl"}},{"Process":{"Description":"patextract is a program that extracts a part of a PNG image file and output that part in PAT format. infile.png is an RGB or RGBA PNG file; the resulting part of the image is written in PAT format to stdout. The file can be used with visgrep(1) to scrape screen content.","Process Name":"patextract","Link":"https:\/\/linux.die.net\/man\/1\/patextract"}},{"Process":{"Description":"This manual page is not meant to be exhaustive. The complete documentation for this version of TeX can be found in the info file or manual Web2C: A TeX implementation. The patgen program reads the dictionary_file containing a list of hyphenated words and the pattern_file containing previously-generated patterns (if any) for a particular language, and produces the patout_file with (previously- plus newly-generated) hyphenation patterns for that language. The translate_file defines language specific values for the parameters left_hyphen_min and right_hyphen_min used by TeX's hyphenation algorithm and the external representation of the lower and upper case version(s) of all `letters' of that language. Further details of the pattern generation process such as hyphenation levels and pattern lengths are requested interactively from the user's terminal. Optionally patgen creates a new dictionary file pattmp.n showing the good and bad hyphens found by the generated patterns, where n is the highest hypenation level. The patterns generated by patgen can be read by initex for use in hyphenating words. For a (very) long example of patgen's output, see $TEXMFMAIN\/tex\/generic\/hyphen\/hyphen.tex, which contains the patterns TeX uses for English. At some sites, patterns for several other languages may be available, and the local tex programs may have them preloaded; consult your Local Guide or your system administrator for details. All filenames must be complete; no adding of default extensions or path searching is done.","Process Name":"patgen","Link":"https:\/\/linux.die.net\/man\/1\/patgen"}},{"Process":{"Description":"Diagnose invalid or unportable file names. -p check for most POSIX systems -P check for empty names and leading \"-\" --portability check for all POSIX systems (equivalent to -p -P) --help display this help and exit --version output version information and exit","Process Name":"pathchk","Link":"https:\/\/linux.die.net\/man\/1\/pathchk"}},{"Process":{"Description":"PathFinder features file mime-type bindings, customizable file- and directory icons, directory bookmarking, drag and drop (compatible with KDE and GNOME), and wildcard matching to reduce the number of visible files. It is probably the fastest file manager you've ever seen.","Process Name":"pathfinder","Link":"https:\/\/linux.die.net\/man\/1\/pathfinder"}},{"Process":{"Description":"PAW is an interactive utility for visualizing experimental data on a computer graphics display. It may be run in batch mode if desired for very large and time consuming data analyses; typically, however, the user will decide on an analysis procedure interactively before running a batch job. PAW combines a handful of CERN High Energy Physics Library systems that may also be used individually in software that processes and displays data. The purpose of PAW is to provide many common analysis and display procedures that would be duplicated needlessly by individual programmers, to supply a flexible way to invoke these common procedures, and yet also to allow user customization where necessary. Paw++ is a Motif-based version of PAW. OPTIONS When paw starts, the macro pawlogon.kumac in the current directory is executed. If this macro doesn't exist the system tries to execute the macro .pawlogon.kumac in the home directory. -n The macro pawlogon is not executed. -b macro_name The macro specified is executed in batch mode and paw exits when the macro ends. -w workstation_type PAW starts immediately without prompting for the workstation type. If workstation_type = 0, paw starts without graphics. When the X11 version of paw is used, a list of 10 valid workstation types is provided in the file higz_windows.dat. By default this file is in the current directory. If it is not, the one in the home directory is used. If it is not in the home directory, one is automatically created in the current directory. Each line in this file describes the position and the size of the window. To access one of the described windows it is enough to give the line number in reply to the prompt \"Workstation type\"","Process Name":"paw","Link":"https:\/\/linux.die.net\/man\/1\/paw"}},{"Process":{"Description":"PAW is an interactive utility for visualizing experimental data on a computer graphics display. It may be run in batch mode if desired for very large and time consuming data analyses; typically, however, the user will decide on an analysis procedure interactively before running a batch job. PAW combines a handful of CERN High Energy Physics Library systems that may also be used individually in software that processes and displays data. The purpose of PAW is to provide many common analysis and display procedures that would be duplicated needlessly by individual programmers, to supply a flexible way to invoke these common procedures, and yet also to allow user customization where necessary. Paw++ is a Motif-based version of PAW. OPTIONS When paw starts, the macro pawlogon.kumac in the current directory is executed. If this macro doesn't exist the system tries to execute the macro .pawlogon.kumac in the home directory. -n The macro pawlogon is not executed. -b macro_name The macro specified is executed in batch mode and paw exits when the macro ends. -w workstation_type PAW starts immediately without prompting for the workstation type. If workstation_type = 0, paw starts without graphics. When the X11 version of paw is used, a list of 10 valid workstation types is provided in the file higz_windows.dat. By default this file is in the current directory. If it is not, the one in the home directory is used. If it is not in the home directory, one is automatically created in the current directory. Each line in this file describes the position and the size of the window. To access one of the described windows it is enough to give the line number in reply to the prompt \"Workstation type\"","Process Name":"paw++","Link":"https:\/\/linux.die.net\/man\/1\/paw++"}},{"Process":{"Description":"pawd is used to print the current working directory, adjusted to reflect proper paths that can be reused to go through the automounter for the shortest possible path. In particular, the path printed back does not include any of Amd's local mount points. Using them is unsafe, because Amd may unmount managed file systems from the mount points, and thus including them in paths may not always find the files within. Without any arguments, pawd will print the automounter adjusted current working directory. With any number of arguments, it will print the adjusted path of each one of the arguments.","Process Name":"pawd","Link":"https:\/\/linux.die.net\/man\/1\/pawd"}},{"Process":{"Description":"PAW is an interactive utility for visualizing experimental data on a computer graphics display. It may be run in batch mode if desired for very large and time consuming data analyses; typically, however, the user will decide on an analysis procedure interactively before running a batch job. PAW combines a handful of CERN High Energy Physics Library systems that may also be used individually in software that processes and displays data. The purpose of PAW is to provide many common analysis and display procedures that would be duplicated needlessly by individual programmers, to supply a flexible way to invoke these common procedures, and yet also to allow user customization where necessary. Paw++ is a Motif-based version of PAW. OPTIONS When paw starts, the macro pawlogon.kumac in the current directory is executed. If this macro doesn't exist the system tries to execute the macro .pawlogon.kumac in the home directory. -n The macro pawlogon is not executed. -b macro_name The macro specified is executed in batch mode and paw exits when the macro ends. -w workstation_type PAW starts immediately without prompting for the workstation type. If workstation_type = 0, paw starts without graphics. When the X11 version of paw is used, a list of 10 valid workstation types is provided in the file higz_windows.dat. By default this file is in the current directory. If it is not, the one in the home directory is used. If it is not in the home directory, one is automatically created in the current directory. Each line in this file describes the position and the size of the window. To access one of the described windows it is enough to give the line number in reply to the prompt \"Workstation type\"","Process Name":"pawx11","Link":"https:\/\/linux.die.net\/man\/1\/pawx11"}},{"Process":{"Description":"pax will read, write, and list the members of an archive file, and will copy directory hierarchies. pax operation is independent of the specific archive format, and supports a wide variety of different archive formats. A list of supported archive formats can be found under the description of the -x option. The presence of the -r and the -w options specifies which of the following functional modes pax will operate under: list, read, write, and copy. <none> List. pax will write to standard output a table of contents of the members of the archive file read from standard input, whose pathnames match the specified patterns. The table of contents contains one filename per line and is written using single line buffering. -r' Read. pax extracts the members of the archive file read from the standard input, with pathnames matching the specified patterns. The archive format and blocking is automatically determined on input. When an extracted file is a directory, the entire file hierarchy rooted at that directory is extracted. All extracted files are created relative to the current file hierarchy. The setting of ownership, access and modification times, and file mode of the extracted files are discussed in more detail under the -p option. -w' Write. pax writes an archive containing the file operands to standard output using the specified archive format. When no file operands are specified, a list of files to copy with one per line is read from standard input. When a file operand is also a directory, the entire file hierarchy rooted at that directory will be included. -r -w Copy. pax copies the file operands to the destination directory. When no file operands are specified, a list of files to copy with one per line is read from the standard input. When a file operand is also a directory the entire file hierarchy rooted at that directory will be included. The effect of the copy is as if the copied files were written to an archive file and then subsequently extracted, except that there may be hard links between the original and the copied files (see the -l option below). Warning: The destination directory must not be one of the file operands or a member of a file hierarchy rooted at one of the file operands. The result of a copy under these conditions is unpredictable. While processing a damaged archive during a read or list operation, pax will attempt to recover from media defects and will search through the archive to locate and process the largest number of archive members possible (see the -E option for more details on error handling). The directory operand specifies a destination directory pathname. If the directory operand does not exist, or it is not writable by the user, or it is not of type directory, pax will exit with a non-zero exit status. The pattern operand is used to select one or more pathnames of archive members. Archive members are selected using the pattern matching notation described by fnmatch(3). When the pattern operand is not supplied, all members of the archive will be selected. When a pattern matches a directory, the entire file hierarchy rooted at that directory will be selected. When a pattern operand does not select at least one archive member, pax will write these pattern operands in a diagnostic message to standard error and then exit with a non-zero exit status. The file operand specifies the pathname of a file to be copied or archived. When a file operand does not select at least one archive member, pax will write these file operand pathnames in a diagnostic message to standard error and then exit with a non-zero exit status. The options are as follows: -r' Read an archive file from standard input and extract the specified files. If any intermediate directories are needed in order to extract an archive member, these directories will be created as if mkdir(2) was called with the bitwise inclusive OR of S_IRWXU, S_IRWXG, and S_IRWXO as the mode argument. When the selected archive format supports the specification of linked files and these files cannot be linked while the archive is being extracted, pax will write a diagnostic message to standard error and exit with a non-zero exit status at the completion of operation. -w' Write files to the standard output in the specified archive format. When no file operands are specified, standard input is read for a list of pathnames with one per line without any leading or trailing <blanks>. -a' Append files to the end of an archive that was previously written. If an archive format is not specified with a -x option, the format currently being used in the archive will be selected. Any attempt to append to an archive in a format different from the format already used in the archive will cause pax to exit immediately with a non-zero exit status. The blocking size used in the archive volume where writing starts will continue to be used for the remainder of that archive volume. Warning: Many storage devices are not able to support the operations necessary to perform an append operation. Any attempt to append to an archive stored on such a device may damage the archive or have other unpredictable results. Tape drives in particular are more likely to not support an append operation. An archive stored in a regular file system file or on a disk device will usually support an append operation. -0' Use the NUL ('\\0') character as a pathname terminator, instead of newline ('\\n'). This applies only to the pathnames read from standard input in the write and copy modes, and to the pathnames written to standard output in list mode. This option is expected to be used in concert with the -print0 function in find(1) or the -0 flag in xargs(1). -b blocksize When writing an archive, block the output at a positive decimal integer number of bytes per write to the archive file. The blocksize must be a multiple of 512 bytes with a maximum of 64512 bytes. Archives larger than 32256 bytes violate the POSIX standard and will not be portable to all systems. A blocksize can end with 'k' or 'b' to specify multiplication by 1024 (1K) or 512, respectively. A pair of blocksizes can be separated by 'x' to indicate a product. A specific archive device may impose additional restrictions on the size of blocking it will support. When blocking is not specified, the default blocksize is dependent on the specific archive format being used (see the -x option). -c' Match all file or archive members except those specified by the pattern and file operands. -d' Cause files of type directory being copied or archived, or archive members of type directory being extracted, to match only the directory file or archive member and not the file hierarchy rooted at the directory. -f archive Specify archive as the pathname of the input or output archive, overriding the default standard input (for list and read) or standard output (for write). A single archive may span multiple files and different archive devices. When required, pax will prompt for the pathname of the file or device of the next volume in the archive. -i' Interactively rename files or archive members. For each archive member matching a pattern operand or each file matching a file operand, pax will prompt to \/dev\/tty giving the name of the file, its file mode, and its modification time. pax will then read a line from \/dev\/tty. If this line is blank, the file or archive member is skipped. If this line consists of a single period, the file or archive member is processed with no modification to its name. Otherwise, its name is replaced with the contents of the line. pax will immediately exit with a non-zero exit status if EOF is encountered when reading a response or if \/dev\/tty cannot be opened for reading and writing. -k' Do not overwrite existing files. -l' (The lowercase letter ''ell.'') Link files. In the copy mode (-r -w), hard links are made between the source and destination file hierarchies whenever possible. -n' Select the first archive member that matches each pattern operand. No more than one archive member is matched for each pattern. When members of type directory are matched, the file hierarchy rooted at that directory is also matched (unless -d is also specified). -o options Information to modify the algorithm for extracting or writing archive files which is specific to the archive format specified by -x. In general, options take the form: name=value. -p string Specify one or more file characteristic options (privileges). The string option-argument is a string specifying file characteristics to be retained or discarded on extraction. The string consists of the specification characters a, e, m, o, and p. Multiple characteristics can be concatenated within the same string and multiple -p options can be specified. The meaning of the specification characters are as follows: a Do not preserve file access times. By default, file access times are preserved whenever possible. e 'Preserve everything', the user ID, group ID, file mode bits, file access time, and file modification time. This is intended to be used by root, someone with all the appropriate privileges, in order to preserve all aspects of the files as they are recorded in the archive. The e flag is the sum of the o and p flags. m Do not preserve file modification times. By default, file modification times are preserved whenever possible. o Preserve the user ID and group ID. p 'Preserve' the file mode bits. This is intended to be used by a user with regular privileges who wants to preserve all aspects of the file other than the ownership. The file times are preserved by default, but two other flags are offered to disable this and use the time of extraction instead. In the preceding list, 'preserve' indicates that an attribute stored in the archive is given to the extracted file, subject to the permissions of the invoking process. Otherwise the attribute of the extracted file is determined as part of the normal file creation action. If neither the e nor the o specification character is specified, or the user ID and group ID are not preserved for any reason, pax will not set the S_ISUID (setuid) and S_ISGID (setgid) bits of the file mode. If the preservation of any of these items fails for any reason, pax will write a diagnostic message to standard error. Failure to preserve these items will affect the final exit status, but will not cause the extracted file to be deleted. If the file characteristic letters in any of the string option-arguments are duplicated or conflict with each other, the one(s) given last will take precedence. For example, if -p eme is specified, file modification times are still preserved. -s replstr Modify the file or archive member names specified by the pattern or file operands according to the substitution expression replstr, using the syntax of the ed(1) utility regular expressions. The format of these regular expressions are: \/old\/new\/[gp] As in ed(1), old is a basic regular expression and new can contain an ampersand ('&'), '\\n' (where n is a digit) back-references, or subexpression matching. The old string may also contain newline characters. Any non-null character can be used as a delimiter ( '\/' is shown here). Multiple -s expressions can be specified. The expressions are applied in the order they are specified on the command line, terminating with the first successful substitution. The optional trailing g continues to apply the substitution expression to the pathname substring which starts with the first character following the end of the last successful substitution. The first unsuccessful substitution stops the operation of the g option. The optional trailing p will cause the final result of a successful substitution to be written to standard error in the following format: <original pathname> >> <new pathname> File or archive member names that substitute to the empty string are not selected and will be skipped. -t' Reset the access times of any file or directory read or accessed by pax to be the same as they were before being read or accessed by pax. -u' Ignore files that are older (having a less recent file modification time) than a pre-existing file or archive member with the same name. During read, an archive member with the same name as a file in the file system will be extracted if the archive member is newer than the file. During write, a file system member with the same name as an archive member will be written to the archive if it is newer than the archive member. During copy, the file in the destination hierarchy is replaced by the file in the source hierarchy or by a link to the file in the source hierarchy if the file in the source hierarchy is newer. -v' During a list operation, produce a verbose table of contents using the format of the ls(1) utility with the -l option. For pathnames representing a hard link to a previous member of the archive, the output has the format: <ls -l listing> == <link name> For pathnames representing a symbolic link, the output has the format: <ls -l listing> => <link name> Where <ls -l listing> is the output format specified by the ls(1) utility when used with the -l option. Otherwise for all the other operational modes ( read, write, and copy), pathnames are written and flushed to standard error without a trailing newline as soon as processing begins on that file or archive member. The trailing newline is not buffered and is written only after the file has been read or written. -x format Specify the output archive format, with the default format being ustar. pax currently supports the following formats: cpio' The extended cpio interchange format specified in the IEEE Std 1003.2 (''POSIX.2'') standard. The default blocksize for this format is 5120 bytes. Inode and device information about a file (used for detecting file hard links by this format) which may be truncated by this format is detected by pax and is repaired. bcpio' The old binary cpio format. The default blocksize for this format is 5120 bytes. This format is not very portable and should not be used when other formats are available. Inode and device information about a file (used for detecting file hard links by this format) which may be truncated by this format is detected by pax and is repaired. sv4cpio The System V release 4 cpio. The default blocksize for this format is 5120 bytes. Inode and device information about a file (used for detecting file hard links by this format) which may be truncated by this format is detected by pax and is repaired. sv4crc The System V release 4 cpio with file crc checksums. The default blocksize for this format is 5120 bytes. Inode and device information about a file (used for detecting file hard links by this format) which may be truncated by this format is detected by pax and is repaired. tar' The old BSD tar format as found in BSD4.3. The default blocksize for this format is 10240 bytes. Pathnames stored by this format must be 100 characters or less in length (including the trailing character, which means that filenames can have a maximum length of 99 characters). Only regular files, hard links, soft links, and directories will be archived (other file system types are not supported). For backwards compatibility with even older tar formats, a -o option can be used when writing an archive to omit the storage of directories. This option takes the form: -o write_opt=nodir ustar' The extended tar interchange format specified in the IEEE Std 1003.2 (''POSIX.2'') standard. The default blocksize for this format is 10240 bytes. Filenames stored by this format must be 100 characters or less in length (including the trailing character, which means that filenames can have a maximum length of 99 characters). Pathnames (directorynames + filenames) stored by this format must be 250 characters or less in length. pax will detect and report any file that it is unable to store or extract as the result of any specific archive format restrictions. The individual archive formats may impose additional restrictions on use. Typical archive format restrictions include (but are not limited to): file pathname length, file size, link pathname length, and the type of the file. -z' Use gzip(1) to compress (decompress) the archive while writing (reading). Incompatible with -a. -B bytes Limit the number of bytes written to a single archive volume to bytes. The bytes limit can end with 'm', 'k', or 'b' to specify multiplication by 1048576 (1M), 1024 (1K) or 512, respectively. A pair of bytes limits can be separated by 'x' to indicate a product. Warning: Only use this option when writing an archive to a device which supports an end of file read condition based on last (or largest) write offset (such as a regular file or a tape drive). The use of this option with a floppy or hard disk is not recommended. -D' This option is the same as the -u option, except that the file inode change time is checked instead of the file modification time. The file inode change time can be used to select files whose inode information (e.g., UID, GID, etc.) is newer than a copy of the file in the destination directory. -E limit Limit the number of consecutive read faults while trying to read a flawed archive to limit. With a positive limit, pax will attempt to recover from an archive read error and will continue processing starting with the next file stored in the archive. A limit of 0 will cause pax to stop operation after the first read error is detected on an archive volume. A limit of NONE will cause pax to attempt to recover from read errors forever. The default limit is a small positive number of retries. Warning: Using this option with NONE should be used with extreme caution as pax may get stuck in an infinite loop on a very badly flawed archive. -G group Select a file based on its group name, or when starting with a #, a numeric gid. A '\\' can be used to escape the #. Multiple -G options may be supplied and checking stops with the first match. -H' Follow only command-line symbolic links while performing a physical file system traversal. -L' Follow all symbolic links to perform a logical file system traversal. -O' Force the archive to be one volume. If a volume ends prematurely, pax will not prompt for a new volume. This option can be useful for automated tasks where error recovery cannot be performed by a human. -P' Do not follow symbolic links, perform a physical file system traversal. This is the default mode. -T [from_date][,to_date][\/[c][m]] Allow files to be selected based on a file modification or inode change time falling within a specified time range of from_date to to_date (the dates are inclusive). If only a from_date is supplied, all files with a modification or inode change time equal to or younger are selected. If only a to_date is supplied, all files with a modification or inode change time equal to or older will be selected. When the from_date is equal to the to_date, only files with a modification or inode change time of exactly that time will be selected. When pax is in the write or copy mode, the optional trailing field [c][m] can be used to determine which file time (inode change, file modification or both) are used in the comparison. If neither is specified, the default is to use file modification time only. The m specifies the comparison of file modification time (the time when the file was last written). The c specifies the comparison of inode change time (the time when the file inode was last changed; e.g., a change of owner, group, mode, etc). When c and m are both specified, then the modification and inode change times are both compared. The inode change time comparison is useful in selecting files whose attributes were recently changed or selecting files which were recently created and had their modification time reset to an older time (as what happens when a file is extracted from an archive and the modification time is preserved). Time comparisons using both file times is useful when pax is used to create a time based incremental archive (only files that were changed during a specified time range will be archived). A time range is made up of six different fields and each field must contain two digits. The format is: [[[[[cc]yy]mm]dd]HH]MM[.SS] Where cc is the first two digits of the year (the century), yy is the last two digits of the year, the first mm is the month (from 01 to 12), dd is the day of the month (from 01 to 31), HH is the hour of the day (from 00 to 23), MM is the minute (from 00 to 59), and SS is the seconds (from 00 to 59). The minute field MM is required, while the other fields are optional and must be added in the following order: HH, dd, mm, yy, cc. The SS field may be added independently of the other fields. Time ranges are relative to the current time, so -T 1234\/cm would select all files with a modification or inode change time of 12:34 PM today or later. Multiple -T time range can be supplied and checking stops with the first match. -U user Select a file based on its user name, or when starting with a #, a numeric UID. A '\\' can be used to escape the #. Multiple -U options may be supplied and checking stops with the first match. -X' When traversing the file hierarchy specified by a pathname, do not descend into directories that have a different device ID. See the st_dev field as described in stat(2) for more information about device IDs. -Y' This option is the same as the -D option, except that the inode change time is checked using the pathname created after all the file name modifications have completed. -Z' This option is the same as the -u option, except that the modification time is checked using the pathname created after all the file name modifications have completed. The options that operate on the names of files or archive members ( -c, -i, -n, -s, -u, -v, -D, -G, -T, -U, -Y, and -Z) interact as follows. When extracting files during a read operation, archive members are 'selected', based only on the user specified pattern operands as modified by the -c, -n, -u, -D, -G, -T, -U options. Then any -s and -i options will modify in that order, the names of these selected files. Then the -Y and -Z options will be applied based on the final pathname. Finally, the -v option will write the names resulting from these modifications. When archiving files during a write operation, or copying files during a copy operation, archive members are 'selected', based only on the user specified pathnames as modified by the -n, -u, -D, -G, -T, and -U options (the -D option only applies during a copy operation). Then any -s and -i options will modify in that order, the names of these selected files. Then during a copy operation the -Y and the -Z options will be applied based on the final pathname. Finally, the -v option will write the names resulting from these modifications. When one or both of the -u or -D options are specified along with the -n option, a file is not considered selected unless it is newer than the file to which it is compared.","Process Name":"pax","Link":"https:\/\/linux.die.net\/man\/1\/pax"}},{"Process":{"Description":"The pax11publish utility can be used to dump or manipulate the PulseAudio server credentials that can be stored as properties on the X11 root window. Please note that the loadable module module-x11-publish exports the same information directly from the PulseAudio sound server, and should in most cases be used in preference over this tool. Use the following command to dump the raw PulseAudio-specific data that is stored in your X11 root window: xprop -root | grep ^PULSE_","Process Name":"pax11publish","Link":"https:\/\/linux.die.net\/man\/1\/pax11publish"}},{"Process":{"Description":"pb helps you build various packages directly from your project sources. Those sources could be handled by a CMS (Configuration Management System) such as Subversion, CVS , Git, Mercurial... or being a simple reference to a compressed tar file. It's based on a set of configuration files, a set of provided macros to help you keeping build files as generic as possible. For example, a single .spec file should be required to generate for all rpm based distributions, even if you could also have multiple .spec files if required.","Process Name":"pb","Link":"https:\/\/linux.die.net\/man\/1\/pb"}},{"Process":{"Description":"This uses the \"Parrot_disassemble()\" function from src\/embed.c, which in turn uses the \"PDB_disassemble()\" function from src\/debug.c. Without non-option arguments it reads the pbc from STDIN . Functions \"static void help(void)\" Print out the user help info. \"int main(int argc, const char *argv[])\" The run-loop. Starts up an interpreter, loads the bytecode from the command-line and disassembles it. \"static void show_last_error_and_exit(Parrot_PMC interp)\" Prints out the \"interp\"'s last error and exits.","Process Name":"pbc_disassemble","Link":"https:\/\/linux.die.net\/man\/1\/pbc_disassemble"}},{"Process":{"Description":"Compile bytecode to executable. SYNOPSIS pbc_to_exe my.pbc\n=> my.exe\n\npbc_to_exe my.pbc --install\n=> installable_my.exe Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"pbc_to_exe","Link":"https:\/\/linux.die.net\/man\/1\/pbc_to_exe"}},{"Process":{"Description":"pb helps you build various packages directly from your project sources. pbdistrocheck is a command from the pb project providing the same type of services as lsb_release, but extended.","Process Name":"pbdistrocheck","Link":"https:\/\/linux.die.net\/man\/1\/pbdistrocheck"}},{"Process":{"Description":"BIND is a tool to combine code files generated by the AS cross assembler to a single file or to extract records out of a code file. pbind is the Unix\/C implementation of BIND. BIND is not a linker; AS does not generate linkable code! Arguments to BIND can be either file name specifications or command line parameters; any argument starting with a plus(+), minus(-) or slash(\/) is recognized as a parameter; anything else is regarded as a file name. BIND always regards the last name as the target file's name specification; all other files are regarded as source files. A target name and no source will yield an empty target file, whereas no file name at all will result in an error message. File names that do not have an extension will be expanded with '.p', the standard extension for code files. The way BIND operates is to process source files in the order they are given in the command line, reading record by record, and to write records that fit into the given filtering criteria to the target file. After all source files have been processed, BIND will write a new creator entry to the target file.","Process Name":"pbind","Link":"https:\/\/linux.die.net\/man\/1\/pbind"}},{"Process":{"Description":"Reads a portable bitmap as input, converting it into a G3 fax file on stdout. That file is suitable for faxing it with sendfax(8) or queueing it for faxing with faxspool(1) (provided that it gets a ''.g3'' suffix). faxspool(1) uses pbm2g3(1) internally to convert various bitmap formats into fax g3 format.","Process Name":"pbm2g3","Link":"https:\/\/linux.die.net\/man\/1\/pbm2g3"}},{"Process":{"Description":"Reads portable bitmap (PBM) format as input. Outputs a stream suitable for processing by Hewlett-Packard's range of Printing Performance Architecture (PPA) printers. pnm2ppa supports the HP 710c, 712c, 720c, 722c, 820c, and 1000c series printers. (Portable bitmap (PBM) format output can be produced from PostScript(tm) input by the GhostScript driver \"pbmraw\".)","Process Name":"pbm2ppa","Link":"https:\/\/linux.die.net\/man\/1\/pbm2ppa"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmclean cleans up a PBM image of random specks. It reads a PBM image as input and outputs a PBM that is the same as the input except with isolated pixels inverted. An isolated pixel is one that has very few neighboring pixels of the same color. The -minneighbors option gives the number of same-color neighbors are required. The default is 1 pixel -- only completely isolated pixels are flipped. (A -minneighbors value greater than 8 generates a completely inverted image (but use pnminvert to do that) -- or a completely white or completely black image with the -black or -white option). pbmclean considers the area beyond the edges of the image to be white. (This matters when you consider pixels right on the edge of the image). You can use pbmclean to clean up 'snow' on bitmap images.","Process Name":"pbmclean","Link":"https:\/\/linux.die.net\/man\/1\/pbmclean"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmlife reads a PBM image as input, applies the rules of Life to it for one generation, and produces a PBM image as output. A white pixel in the image is interpreted as a live beastie, and a black pixel as an empty space.","Process Name":"pbmlife","Link":"https:\/\/linux.die.net\/man\/1\/pbmlife"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmmake produces a PBM image of the specified width and height, either all black, all white, or a dithered gray. The default is white.","Process Name":"pbmmake","Link":"https:\/\/linux.die.net\/man\/1\/pbmmake"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmmask reads a PBM image as input and Generates a corresponding mask of the foreground areas as another PBM image. The color to be interpreted as 'background' is determined automatically. Regardless of which color is background, the mask will be white where the background is and black where the figure is. This lets you do a masked paste like this, for objects with a black background: pbmmask obj > objmask\npnmpaste < dest -and objmask <x> <y> | pnmpaste -or obj <x> <y> For objects with a white background, you can either invert them or add a step: pbmmask obj > objmask\npnminvert objmask | pnmpaste -and obj 0 0 > blackback\npnmpaste < dest -and objmask <x> <y> | pnmpaste -or blackback <x> <y> Note that this three-step version works for objects with black backgrounds too, if you don't care about the wasted time. You can also use masks with grayscale and color images, using the pnmarith tool. For instance: ppmtopgm obj.ppm | pamditherbw -threshold | pbmmask > objmask.pbm\npnmarith -multiply dest.ppm objmask.pbm > t1.ppm\npnminvert objmask.pbm | pnmarith -multiply obj.ppm - > t2.ppm\npnmarith -add t1.ppm t2.ppm An interesting variation on this is to pipe the mask through pnmsmooth before using it. This makes the boundary between the two images less sharp.","Process Name":"pbmmask","Link":"https:\/\/linux.die.net\/man\/1\/pbmmask"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmminkowski computes the 3 Minkowski integrals of a PBM image. It is similar to pgmminkowski(1). Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"pbmminkowski","Link":"https:\/\/linux.die.net\/man\/1\/pbmminkowski"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmpage generates a one page test pattern to print on a sheet of paper, for use in calibrating a printer. The test pattern in is PBM format. pbmpage produces an image intended for 600 dots per inch printer resolution. If you are printing on an HP PPA printer, you can convert the output of this program to a stream that you can feed to the printer with pbmtoppa. Bear in mind that when you print the test pattern, you are testing not only the printer, but any converter or driver software along the printing path. Any one of these components may adjust margins, crop the image, erase edges, and such. If, due to addition of margins, the printer refuses to print the image because it is too big, use pamcut to cut the right and bottom edges off the test pattern until it is small enough to print. test_pattern is the number of the test pattern to generate, as follows. The default is 1. 1 A black on white grid ruled in numbers of pixels. A black one pixel box is at the very edges of the paper. Before Netpbm 10.18 (August 2003), the perimeter box was not there. 2 A vertical line segment, one pixel wide, extending 1\/2' up from the exact center of the page. 3 Two diagonal line segments, one starting at the upper left corner of the page, the other starting from the lower left corner of the page. Both extend 1\/2' toward the center of the page at 45 degrees.","Process Name":"pbmpage","Link":"https:\/\/linux.die.net\/man\/1\/pbmpage"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmpscale reads a PBM image as input, and outputs a PBM image enlarged N times. pbmpscale does this enlargement by pixel replication, with some additional smoothing of corners and edges.","Process Name":"pbmpscale","Link":"https:\/\/linux.die.net\/man\/1\/pbmpscale"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmreduce reads a PBM image as input and reduces it by a factor of N, producing a PBM image as output. pbmreduce duplicates a lot of the functionality of pamditherbw; you could do something like pamscale | pamditherbw, but pbmreduce is a lot faster. You can use pbmreduce to 're-halftone' an image. Let's say you have a scanner that only produces black&white, not grayscale, and it does a terrible job of halftoning (most b&w scanners fit this description). One way to fix the halftoning is to scan at the highest possible resolution, say 300 dpi, and then reduce by a factor of three or so using pbmreduce. You can even correct the brightness of an image, by using the -value option.","Process Name":"pbmreduce","Link":"https:\/\/linux.die.net\/man\/1\/pbmreduce"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtext takes the specified text, either a single line from the command line or multiple lines from standard input, and renders it into a PBM graphical image. In the image, each line of input is a line of output. Formatting characters such as newline have no effect on the formatting; like any unprintable character, they turn into spaces. The image is just wide enough for the longest line of text, plus margins, and just high enough to contain the lines of text, plus margins. The left and right margins are twice the width of the widest character in the font; the top and bottom margins are the height of the tallest character in the font. But if the text is only one line, all the margins are half of this. You can use the -nomargins option to eliminate the margins. pbmtextps does the same thing as pbmtext, but uses Ghostscript to generate the characters, which means you can use Postscript fonts. But it also means you have to have Ghostscript installed and it isn't as fast. Also, pbmtextps generates only one line of text, whereas pbmtext can create multiple lines. pbmtext is meant for small quantities of simple text. If you're working with a document, you would be better off using a document formatting program to 'print' to a Postscript file, then feeding that Postscript to pstopnm.","Process Name":"pbmtext","Link":"https:\/\/linux.die.net\/man\/1\/pbmtext"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtextps takes a single line of text from the command line and renders it into a PBM image. The image is of a single line of text; newline characters in the input have no effect. The image is cropped at the top and the right. It is not cropped at the left or bottom so that the text begins at the same position relative to the origin. You can use pnmcrop to crop it all the way. See pbmtext for a more sophisticated generator of text, but using less common font formats. pbmtext can generate multiple lines of text. The -plain common option has no effect before Netpbm 10.42 (March 2008). The output is always raw PBM.","Process Name":"pbmtextps","Link":"https:\/\/linux.die.net\/man\/1\/pbmtextps"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmto10x reads a PBM image as input and produces a file of Gemini 10X printer graphics as output. The 10x's printer codes are alleged to be similar to the Epson codes. Note that there is no 10xtopbm tool - this transformation is one way.","Process Name":"pbmto10x","Link":"https:\/\/linux.die.net\/man\/1\/pbmto10x"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmto4425 displays PBM format images on an AT&T 4425 ASCII terminal using that terminal's mosaic graphics character set. The program should also work with other VT100-like terminals with mosaic graphics character sets such as the C. Itoh CIT-101, but it has not yet been tested on terminals other than the 4425. Pbmto4425 puts the terminal into 132 column mode to achieve the maximum resolution of the terminal. In this mode the terminal has a resolution of 264 columns by 69 rows. The pixels have an aspect ratio of 1:2.6, therefore an image should be processed before being displayed in a manner such as this: % pamscale -xscale 2.6 pamfile \\\n    | pamscale -xysize 264 69 \\\n    | ppmtopgm \\\n    | pamditherbw \\\n    | pbmto4425","Process Name":"pbmto4425","Link":"https:\/\/linux.die.net\/man\/1\/pbmto4425"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtoascii reads a PBM image as input and produces a somewhat crude ASCII graphic image as output. To convert back, use asciitopgm(1).","Process Name":"pbmtoascii","Link":"https:\/\/linux.die.net\/man\/1\/pbmtoascii"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtoatk reads a PBM image as input and produces a Andrew Toolkit raster object as output.","Process Name":"pbmtoatk","Link":"https:\/\/linux.die.net\/man\/1\/pbmtoatk"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtobbnbg reads a portable bitmap as input and produces BBN BitGraph terminal Display Pixel Data (DPD) sequence as output. The rasterop can be specified on the command line. If this is omitted, 3 (replace) will be used. A position in (x,y) coordinates can also be specified. If both are given, the rasterop comes first. The portable bitmap is always taken from the standard input. Note that there is no bgtopbm tool.","Process Name":"pbmtobbnbg","Link":"https:\/\/linux.die.net\/man\/1\/pbmtobbnbg"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtocis reads a PBM image as input and produces a CompuServe RLE image as output.","Process Name":"pbmtocis","Link":"https:\/\/linux.die.net\/man\/1\/pbmtocis"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtocmuwm reads a portable bitmap as input and produces a CMU window manager bitmap as output.","Process Name":"pbmtocmuwm","Link":"https:\/\/linux.die.net\/man\/1\/pbmtocmuwm"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtodjvurle reads a PBM image as input and produces DjVu Bitonal RLE format as output.","Process Name":"pbmtodjvurle","Link":"https:\/\/linux.die.net\/man\/1\/pbmtodjvurle"}},{"Process":{"Description":"This program is part of Netpbm(1). Reads a PBM image as input. Produces an encapsulated Postscript style bitmap as output. The output is not a stand alone postscript file, it is only a preview bitmap, which can be included in an encapsulated PostScript file. pbmtoepsi assumes the PBM input describes a whole output page, with one pixel on the page corresponding to one PBM pixel. It detects white borders in the image and generates Postscript output that contains a Bounding Box statement to describe the location of the principal image (the image excluding the white borders) on the page and thus does not include the borders in the raster part of the Postscript output. There is no epsitopbm tool - this transformation is one way.","Process Name":"pbmtoepsi","Link":"https:\/\/linux.die.net\/man\/1\/pbmtoepsi"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtoepson reads a PBM image as input and produces a stream of Epson printer graphics as output. The input is from the file identified by the pbmfile argument or, if you don't specify pbmfile, from Standard Input. Output is to Standard Output. The output is for traditional (ca 1991) Epson 9-wire dot matrix (sometimes called ESC\/P 9-wire) printers or newer ESC\/P printers. For a more modern Epson ESC\/P2 type printer, try pbmtoescp2. Before Netpbm 10.23 (July 2004), pbmtoepson could not produce ESC\/P streams -- only ESC\/P 9-wire. The Epson printer protocols are described in Epson's protocol specification. Note that there is no epsontopbm tool - this transformation is one way.","Process Name":"pbmtoepson","Link":"https:\/\/linux.die.net\/man\/1\/pbmtoepson"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtoescp2 reads a PBM image as input. It produces an ESC\/P2 raster graphic printer control stream as output. This program creates an output that is printable on Epson printers that understand the ESC\/P2 printer control language (e.g. the Stylus models). For older Epson 9-pin dot matrix printers, which use the ESC\/P protocol, see pbmtoepson.","Process Name":"pbmtoescp2","Link":"https:\/\/linux.die.net\/man\/1\/pbmtoescp2"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtog3 reads a PBM image as input and produces a Group 3 MH fax file as output. You can also generate a TIFF file that uses the same encoding inside, with pamtotiff. There is no program in Netpbm that generates other fax formats, such as MR and MMR, but pamtotiff can generate TIFF files that use those encodings.","Process Name":"pbmtog3","Link":"https:\/\/linux.die.net\/man\/1\/pbmtog3"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtogem reads a PBM image as input and produces a compressed GEM .img file as output.","Process Name":"pbmtogem","Link":"https:\/\/linux.die.net\/man\/1\/pbmtogem"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtogo reads a PBM image as input and produces 2D compressed GraphOn graphics as output. Be sure to set up your GraphOn with the following modes: 8 bits \/ no parity; obeys no XON\/XOFF; NULs are accepted. These are all on the Comm menu. Also, remember to turn off tty post processing. Note that there is no gotopbm tool.","Process Name":"pbmtogo","Link":"https:\/\/linux.die.net\/man\/1\/pbmtogo"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtoibm23xx reads one or more PBM files as input and writes an IBM 23XX printer command stream to generate all the images in all the files to Standard Output. If you don't specify any file names, pbmtoibm23xx reads from Standard Input.","Process Name":"pbmtoibm23xx","Link":"https:\/\/linux.die.net\/man\/1\/pbmtoibm23xx"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtoicon reads a PBM image as input and produces a Sun icon as output.","Process Name":"pbmtoicon","Link":"https:\/\/linux.die.net\/man\/1\/pbmtoicon"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtolj reads a PBM image as input and produces HP LaserJet data as output. You can send this data to a LaserJet or DeskJet printer (at least some of them). Each pixel in the input PBM image becomes one dot in the printed output. Therefore, you must make sure the width and height of the input are appropriate for the print resolution you choose and the print area you want. E.g. if you print at 300 dpi and want the image to print as 8 inches by 10, you must supply a PBM that is 2400 pixels wide by 3000 pixels high. You can adjust the size of the input with pamscale, pamstretch, pbmreduce, or pamenlarge. The input may be a multi-image PBM stream. Each input image becomes a page of output. But before Netpbm 10.28 (June 2005), images after the first one are ignored. Note that there is no ljtopbm tool.","Process Name":"pbmtolj","Link":"https:\/\/linux.die.net\/man\/1\/pbmtolj"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtoln03 reads a PBM image as input and produces a DEC LN03+ Sixel output file.","Process Name":"pbmtoln03","Link":"https:\/\/linux.die.net\/man\/1\/pbmtoln03"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtolps reads a PBM image as input and outputs PostScript. The output Postscript uses lines instead of the image operator to generate a (device dependent) picture which will be imaged much faster. The Postscript path length is constrained to be less that 1000 points so that no limits are overrun on the Apple Laserwriter and (presumably) no other printers.","Process Name":"pbmtolps","Link":"https:\/\/linux.die.net\/man\/1\/pbmtolps"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtomacp reads a PBM image as input and produces a MacPaint file as output. If you do not specify pbmfile, pbmtomacp uses Standard Input. The generated file is only the data fork of a picture. You will need a program such as mcvert to generate a Macbinary or a BinHex file that contains the necessary information to identify the file as a PNTG file to MacOS.","Process Name":"pbmtomacp","Link":"https:\/\/linux.die.net\/man\/1\/pbmtomacp"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtomatrixorbital reads a PBM image as input and produces as output an image that can be uploaded to a Matrix Orbital LCD display. You can upload the image to the LCD via the serial port to which it is connected with the program mo-upload.pl, which you can get from the package pbmtomatrixorbital. Yes, the package is the same name as this Netpbm program, and it contains its own pbmtomatrixorbital program which is slightly different from this one because it is not part of the Netpbm package.","Process Name":"pbmtomatrixorbital","Link":"https:\/\/linux.die.net\/man\/1\/pbmtomatrixorbital"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtomda reads a PBM image as input and produces a MicroDesign 2 area file (.MDA) as output. If you do not specify pbmfile, pbmtomda uses Standard Input.","Process Name":"pbmtomda","Link":"https:\/\/linux.die.net\/man\/1\/pbmtomda"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtomgr reads a PBM image as input and produces a MGR bitmap as output. MGR(1)is a window manager that is a smaller alternative to the X Windows System.","Process Name":"pbmtomgr","Link":"https:\/\/linux.die.net\/man\/1\/pbmtomgr"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtomrf converts a PBM image to MRF format. For more information about mrf, see theMRF specification (1). pbmtomrf takes the PBM image from the file named by the input.pbm argument, or Standard Input if you don't specify input.pbm. The output goes to Standard Output. The compression of the edges of pictures with width and\/or height not an exact multiple of 64 is not optimal in all cases.","Process Name":"pbmtomrf","Link":"https:\/\/linux.die.net\/man\/1\/pbmtomrf"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtonokia reads a PBM image as input and produces a Nokia Smart Messaging (hexcode, .ngg, .nol, .npm) file as output.","Process Name":"pbmtonokia","Link":"https:\/\/linux.die.net\/man\/1\/pbmtonokia"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtopgm reads a PBM image as input. It outputs a PGM image in which each pixel's gray level is the average of the surrounding black and white input pixels. The surrounding area is a rectangle of width by height pixels. In other words, this is a convolution. pbmtopgm is similar to a special case of pnmconvol. You may need a pnmsmooth step after pbmtopgm. pbmtopgm has the effect of anti-aliasing bitmaps which contain distinct line features. pbmtopgm works best with odd sample width and heights. You don't need pbmtopgm just to use a PGM program on a PBM image. Any PGM program (assuming it uses the Netpbm libraries to read the PGM input) takes PBM input as if it were PGM, with only the mininum and maximum gray levels. So unless your convolution rectangle is bigger than one pixel, you're not gaining anything with a pbmtopgm step. The opposite transformation (which would turn a PGM into a PBM) is dithering. See pamditherbw.","Process Name":"pbmtopgm","Link":"https:\/\/linux.die.net\/man\/1\/pbmtopgm"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtopi3 reads a PBM image as input and produces an Atari Degas .pi3 file as output.","Process Name":"pbmtopi3","Link":"https:\/\/linux.die.net\/man\/1\/pbmtopi3"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtopk reads PBM images as input and produces a packed (PK) font file and a TFM (TeX font metric) file as output. The resolution parameter indicates the resolution of the font, in dots per inch. If the filename '-' is used for any of the filenames, pbmtopk uses Standard Input or Standard Output.","Process Name":"pbmtopk","Link":"https:\/\/linux.die.net\/man\/1\/pbmtopk"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtoplot reads a PBM image as input and produces a Unix plot file as output. Note that there is no plottopbm tool - this transformation is one-way.","Process Name":"pbmtoplot","Link":"https:\/\/linux.die.net\/man\/1\/pbmtoplot"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtoppa converts page images in PBM format to Hewlett Packard's PPA (Printer Performance Architecture) format, which is the data stream format expected by some HP 'Windows-only' printers including the HP Deskjet 820C series, the HP DeskJet 720 series, and the HP DeskJet 1000 series. pbm_file is the file specification of the input file or - for Standard Input. The default is Standard Input. The input file contains one or more PBM images, with each one being a single page. Each image must have the exact dimensions of a page (at 600 pixels per inch in both directions). Significantly, this is the format that Ghostscript produces. ppa_file is the file specification of the output file or - for Standard Output. The default is Standard Output. To print Postscript on an HP PPA printer, just use Ghostscript with the pbmraw (or pbm) device driver. You can generate a test page for use with this program with pbmpage. You can also set up a printer filter so you can submit PBM input directly to your print queue. See the documentation for your print spooler for information on how to do that, or look in hp820install.doc for an example lpd print filter for Postscript and text files. Sometimes, pbmtoppa generates a file which the printer will not print (because pbmtoppa's input is unprintable). When this happens, all three lights blink to signal the error. This is usually because there is material outside of the printer's printable area. To make the file print, increase the margins via pbmtoppa options or a configuration file. See the section on calibration below. About PPA The PPA printer language is a far lower level language than most. When you use a PPA printer, most of the processing that a conventional printer does is done instead on the computer end of the wire. In particular, pbmtoppa has to do 'swath cutting,' and 'sweep formatting,' which other printers do themselves. There is very little intelligence inside a PPA printer; pbmtoppa generates direct controls for the printer's hardware. The design goal of PPA was to reduce the cost of a printer by exploiting computing resources already present in the computer that requests the printing. CPU power, ROM, and RAM requirements inside the printer are all reduced compared to a conventional printer. PPA was new in 1997. It was preceded by Hewlett Packard's PCL (Printer Control Language) language. HP manufactured PPA printers for only a few years, and no one else ever did.","Process Name":"pbmtoppa","Link":"https:\/\/linux.die.net\/man\/1\/pbmtoppa"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtopsg3 converts the PBM images in the input PBM file to pages in a Postscript file encoded with G3 fax compression. If you don't specify filespec, the input is from Standard Input. Remember that you can create a multi-image PBM file simply by concatenating single-image PBM files, so if each page is in a different file, you might do: cat faxpage* | pbmtopsg3 >fax.ps","Process Name":"pbmtopsg3","Link":"https:\/\/linux.die.net\/man\/1\/pbmtopsg3"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtoptx reads a PBM image as input and produces a file of Printronix printer graphics as output. Note that there is no ptxtopbm tool - this transformation is one way.","Process Name":"pbmtoptx","Link":"https:\/\/linux.die.net\/man\/1\/pbmtoptx"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtowbmp reads a PBM image as input and produces a wbmp file as output.","Process Name":"pbmtowbmp","Link":"https:\/\/linux.die.net\/man\/1\/pbmtowbmp"}},{"Process":{"Description":"pbmtox10bm was replaced in Netpbm 10.37 (December 2006) by pbmtoxbm(1). pbmtoxbm with the -x10 option is backward compatible with pbmtox10bm. pbmtoxbm also can generate X11 bitmaps. You should not make any new use of pbmtox10bm and if you modify an existing use, you should upgrade to pbmtoxbm.","Process Name":"pbmtox10bm","Link":"https:\/\/linux.die.net\/man\/1\/pbmtox10bm"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtoxbm reads a PBM image as input and produces an X10 or X11 bitmap as output.","Process Name":"pbmtoxbm","Link":"https:\/\/linux.die.net\/man\/1\/pbmtoxbm"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtoybm reads a PBM image as input and produces as output a file acceptable to the face and xbm programs by Bennet Yee (bsy+@cs.cmu.edu).","Process Name":"pbmtoybm","Link":"https:\/\/linux.die.net\/man\/1\/pbmtoybm"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmtozinc reads a PBM image as input and produces a bitmap in the format used by the Zinc Interface Library (ZIL) Version 1.0 as output.","Process Name":"pbmtozinc","Link":"https:\/\/linux.die.net\/man\/1\/pbmtozinc"}},{"Process":{"Description":"This program is part of Netpbm(1). pbmupc generates an image of a Universal Product Code symbol. The three arguments are: a one digit product type, a five digit manufacturer code, and a five digit product code. For example, '0 72890 00011' is the code for Heineken. As presently configured, pbmupc produces an image 230 bits wide and 175 bits high. The size can be altered by changing the defines at the beginning of the program, or by running the output through pamenlarge or pamscale.","Process Name":"pbmupc","Link":"https:\/\/linux.die.net\/man\/1\/pbmupc"}},{"Process":{"Description":"PBS stands for Portable Batch System. It is a networked subsystem for submitting, monitoring, and controlling a work load of batch jobs on one or more systems. More information about PBS is available in the PBS Users Guide. Batch means that the job will be scheduled for execution at a time chosen by the subsystem according to a defined policy and the availability of resources. For a normal batch job, the standard output and standard error of the job will be returned to files available to the user when the job is complete. This differs from an interactive session where commands are executed when entered via the terminal and output is returned directly to the terminal. PBS also supports an interactive batch mode where the input and output is connected to the user's terminal, but the scheduling of the job is still under control of the batch system. A job is typically a shell script and a set of attributes which provide resource and control information about the job. A job does not have to be submitted on the system where it will run, tt can be submitted on any system with the PBS commands and access to the execution system, see qsub(1B). Output will be returned to the system from which the job was submitted unless directed otherwise. Attributes offer control over when a job is eligible to be run, what happens to the output when it is completed and how the user is notified when it completes. The attributes of the job may be specified on the command line or in the job script when the job is submitted. For information about job attributes, see qsub(1B) and pbs_job_attributes(7B). One important attribute is the resource list. The list specifies the amount and type of resources needed by the job in order to execute. The list also implies a hard upper limit on usage of those resources. When the limit is reached, the job is terminated. The types of resources available to a job vary with the system architecture. For a list of resources supported on the default system, see pbs_resources(7B). There are man pages for other systems types as well, see pbs_resources_aix4(7B), pbs_resources_fujitsu(7B), pbs_resources_irix5(7B), pbs_resources_solaris5(7B), pbs_resources_sp2(7B), pbs_resources_sunos4(7B), or pbs_resources_unicos8(7B). Once a job has been submitted, it may be monitored by use of the qstat(1B) command. Two forms of output are available with the qstat command. The default form is the short display. Information about a job is limited to a single line. Complete information about the job or jobs is available through qstat with the -f option. Information will be given about all jobs in the system, all jobs in specified queues, or only specified jobs. When displaying status of jobs, you will see in which queue the job resides. In PBS a queue is just a collection point for jobs, it does not imply any execution ordering. That ordering is determined by a scheduling policy implemented by the system administration. Other commands of interest which have man pages of their own are: qalter Alter a job's attributes. qdel Delete a job. qhold Place a hold on a job to keep it from being scheduled for running. qmove Move a job to a different queue or server. qmsg Append a message to the output of an executing job. qrerun Terminate an executing job and return it to a queue. qrls Remove a hold from a job. qselect Obtain a list of jobs that met certain criteria. qsig Send a signal to an executing job.","Process Name":"pbs","Link":"https:\/\/linux.die.net\/man\/1\/pbs"}},{"Process":{"Description":"Executes (spawns) a normal Unix program on one or more nodes under control of the Portable Batch System, PBS. Pbsdsh uses the Task Manager API, see tm_spawn(3), to distribute the program on the allocated nodes. When run without the -c or the -n option, pbsdsh will spawn the program on all nodes allocated to the PBS job. The spawns take place concurrently - all execute at (about) the same time. Users will find the PBS_TASKNUM , PBS_NODENUM , and the PBS_VNODENUM environmental variables useful. They contain the TM task id, the node identifier, and the cpu (virtual node) identifier.","Process Name":"pbsdsh","Link":"https:\/\/linux.die.net\/man\/1\/pbsdsh"}},{"Process":{"Description":"Draws a full-terminal display of your nodes and jobs. The default grid shows each node's 1st CPU as a single character. The specific character denotes the state of the node or identifies the job running on that CPU . The job listing shows the job name, queue name, state, etc. and, on the far left, the character used to identify nodes in the upper grid. Pressing a number key will toggle the display of that CPU on all of the nodes. This program runs best if the \"perl-PBS\" module is installed. While there are currently no loss of features if it isn't installed, it will run much faster with it. If you are unsure if PBS is installed, run this program, hit \"h\", and look for the Backend information at the top right.","Process Name":"pbstop","Link":"https:\/\/linux.die.net\/man\/1\/pbstop"}},{"Process":{"Description":"pbzip2 is a parallel implementation of the bzip2 block-sorting file compressor that uses pthreads and achieves near-linear speedup on SMP machines. The output of this version is fully compatible with bzip2 v1.0.2 or newer (ie: anything compressed with pbzip2 can be decompressed with bzip2). pbzip2 should work on any system that has a pthreads compatible C++ compiler (such as gcc). It has been tested on: Linux, Windows (cygwin), Solaris, Tru64\/OSF1, HP-UX, and Irix. The default settings for pbzip2 will work well in most cases. The only switch you will likely need to use is -d to decompress files and -p to set the # of processors for pbzip2 to use if autodetect is not supported on your system, or you want to use a specific # of CPUs.","Process Name":"pbzip2","Link":"https:\/\/linux.die.net\/man\/1\/pbzip2"}},{"Process":{"Description":"This program is part of Netpbm(1). pc1toppm reads an Atari Degas .pc1 file as input and produces a PPM image as output. The .pc1 format is a compressed (run length encoded) variation on .pi1.","Process Name":"pc1toppm","Link":"https:\/\/linux.die.net\/man\/1\/pc1toppm"}},{"Process":{"Description":"When run with the --cflags option, pcap-config writes to the standard output the -I compiler flags required to include libpcap's header files. When run with the --libs option, pcap-config writes to the standard output the -L and -l linker flags required to link with libpcap, including -l flags for libraries required by libpcap. When run with the --additional-libs option, pcap-config writes to the standard output the -L and -l flags for libraries required by libpcap, but not the -lpcap flag to link with libpcap itself. By default, it writes flags appropriate for compiling with a dynamically-linked version of libpcap; the --static flag causes it to write flags appropriate for compiling with a statically-linked version of libpcap.","Process Name":"pcap-config","Link":"https:\/\/linux.die.net\/man\/1\/pcap-config"}},{"Process":{"Description":"pcapinfo prints detailed information about the network devices and Pcap library available on the current host. Here is an example: Host information\n----------------\n  Hostname      : fangorn.maddingue.net\n  Aliases       : fangorn.local fangorn\n  Pcap version  : libpcap version 0.8.3\n\nDevices information\n-------------------\nDevice eth0 (default)\n  Description       : No description available\n  Link type         : Ethernet, no autonegotiation, 10baseT-HD, link ok\n  Hardware address  : 00:0c:6e:0a:c3:ca\n  Network address   : 10.0.1.51\n  Network mask      : 255.255.255.0\n  Flags             : up running broadcast multicast\n\nDevice eth1\n  Description       : No description available\n  Link type         : Ethernet, no autonegotiation, 10baseT-HD, link ok\n  Hardware address  : 00:26:54:0a:d8:4d\n  Network address   : 192.168.1.51\n  Network mask      : 255.255.255.0\n  Flags             : up running broadcast multicast The device marked as \"(default)\" is the one returned when calling \"Net::Pcap::lookupdev()\" Some information like the link type can only be gathered with administrative privileges.","Process Name":"pcapinfo","Link":"https:\/\/linux.die.net\/man\/1\/pcapinfo"}},{"Process":{"Description":"The pcb program is a tool for the layout of printed circuit boards. The complete manual for pcb is provided in a GNU texinfo format as well as HTML and PDF. The texinfo version of the manual is typically viewed with the info program or alternatively with emacs or a graphical info viewer such as tkinfo. The PDF and HTML documentation is typically installed as \/usr\/local\/share\/pcb\/pcb.html and \/usr\/local\/share\/pcb\/pcb.pdf. The prefix \"\/usr\/local\" may vary at your site. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"pcb","Link":"https:\/\/linux.die.net\/man\/1\/pcb"}},{"Process":{"Description":"The cc utility provides a front-end to the ''portable C compiler''. Multiple files may be given on the command line. Unrecognized options are all sent directly to ld(1). Filenames that end with .c are passed via cpp(1)  ccom(1)  as(1)  ld(1). Filenames that end with .i are passed via ccom(1)  as(1)  ld(1). Filenames that end with .s are passed via as(1)  ld(1). Filenames that end with .S are passed via cpp(1)  as(1)  ld(1). Filenames that end with .o are passed directly to ld(1). The options are as follows:        -Bprefix Define alternate prefix path for cpp(1), ccom(1), as(1), or ld(1) executables. -C' Passed to the cpp(1) preprocessor to not discard comments. -c' Stop after generating object code with as(1). Do not link. The resulting object output is saved as a filename with a ''.o'' suffix unless -o option is used. Note: cannot be combined with -o if multiple files are given. -D macro[ =value] Passed to the cpp(1) preprocessor to define macro with an optional value. -E' Stop after preprocessing with cpp(1). Do not compile, assemble, or link. Output is sent to standard output unless the -o option is used. -ffreestanding Assume a freestanding environment. -fPIC Generate PIC code. -fpic Tells C compiler to generate PIC code and tells assembler that PIC code has been generated. -g' Send -g flag to ccom(1) to create debug output. Debug information output can be disabled with -g0. -I path Passed to the cpp(1) preprocessor to add header search directory to override system defaults. -include file Tells the cpp(1) preprocessor to include the file during preprocessing. -isystem path Defines path as a system header directory for the cpp(1) preprocessor. -k' Generate PIC code. See -fpic option. -L' TODO -M' Pass -M flag to cpp(1) to generate dependencies for make(1). -moption Target-dependent options. Multiple -m options can be given, the following are supported: ARM' -mlittle-endian -mbig-endian -mfpe=fpa -mfpe=vpf -msoft-float -march=armv1 -march=armv2 -march=armv2a -march=armv3 -march=armv4 -march=armv4t -march=armv4tej -march=armv5 -march=armv6 -march=armv6t2 -march=armv6kz -march=armv6k -march=armv7 HPPA' i386' MIPS' -mlittle-endian -mbig-endian -mhard-float -msoft-float PDP-10 PowerPC Sparc64 VAX' -nodefaultlibs Do not link with the system default libraries (libc, etc.) -nostartfiles Do not link with the system startup files (crt0.c, etc.) -nostdinc Do not use the system include paths (\/usr\/include, etc.) -nostdlib Do not link with the system default libraries or startup files. -O[ level] Enable compiler optimizations. Currently, for levels higher than zero, this defines __OPTIMIZE__ in the cpp(1) preprocessor, and passes -xdeljumps, -xtemps and -xinline to ccom(1). If no level is given the optimization level is increased, or optimizations can be disabled using -O0. -o outfile Save result to outfile. -P' TODO -pg' Enable profiling on the generated executable. -pthread Defines the _PTHREADS preprocessor identifier for cpp(1), and adds -lpthread to the ld(1) linker arguments. -S' Stop after compilation by ccom(1). Do not assemble and do not link. The resulting assembler-language output is saved as a filename with a ''.s'' suffix unless the -o option is used. Note: cannot be combined with -o if multiple files are given. -shared Create a shared object of the result. Tells the linker not to generate an executable. -static Do not use dynamic linkage. By default, it will link using the dynamic linker options and\/or shared objects for the platform. -t' Passed to cpp(1) to suppress some default macro definitions and enable use of traditional C preprocessor syntax. -U macro Passes to the cpp(1) preprocessor to remove the initial macro definition. -v' Outputs the version of cc and shows what commands will be run with their command line arguments. -Wa,options Comma separated list of options for the assembler. -Wc,options Comma separated list of options for the compiler. -Wl,options Comma separated list of options for the linker. -Wp,options Comma separated list of options for the preprocessor. -X' Don't remove temporary files on exit. -x language GCC compatibility option; specify the language in use rather than interpreting the filename extension. Currently known language values are c, c++ and assembler-with-cpp. Any unknown -x options are passed to ccom(1). Predefined Macros A few macros are predefined by cc when sent to cpp(1). __PCC__ Set to the major version of pcc(1). These macros can be used to select code based on pcc(1) compatibility. See the -v option. __PCC_MINOR__ Set to the minor version. __PCC_MINORMINOR__ Set to the minor-minor version - the number after the minor version. _PTHREADS Defined when -pthread switch is used. Also system- and\/or machine-dependent macros may also be predefined; for example: __NetBSD__, __ELF__, and __i386__.","Process Name":"pcc","Link":"https:\/\/linux.die.net\/man\/1\/pcc"}},{"Process":{"Description":"The cpp utility is a macro preprocessor used by the pcc(1) compiler. It is mainly used to include header files, expand macro definitions, discard comments, and perform conditional compilation. cpp is written to comply with the ISO\/IEC 9899:1999 (''ISO C99'') specification. The infile input file is optional. If not provided or the file name is \"-\" (dash), cpp reads its initial file from standard input. The outfile output file is also optional, with output written to standard output if not provided. The options are as follows:       -C'        Do not discard comments. -D macro[ = value] Create a macro definition before processing any input, as if a #define macro value directive had appeared in the source. If value is not set on the command-line, then a value of 1 is used. -d flags Modify output according to flags, which can be a list of character flags. The following flags are currently supported:","Process Name":"pcc-cpp","Link":"https:\/\/linux.die.net\/man\/1\/pcc-cpp"}},{"Process":{"Description":"pcdindex has been renamed to pcdovtoppm(1). Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"pcdindex","Link":"https:\/\/linux.die.net\/man\/1\/pcdindex"}},{"Process":{"Description":"This program is part of Netpbm(1). This program generates an index image in PPM format for a photo CD, based on the photo CD overview file. You can achieve a similar result with hpcdtoppm -Overview followed by pnmindex -black on the generated PPM images.","Process Name":"pcdovtoppm","Link":"https:\/\/linux.die.net\/man\/1\/pcdovtoppm"}},{"Process":{"Description":"Pcitweak is a utility that can be used to examine or change registers in the PCI configuration space. On most platforms pcitweak can only be run by the root user.","Process Name":"pcitweak","Link":"https:\/\/linux.die.net\/man\/1\/pcitweak"}},{"Process":{"Description":"The pcp command summarizes the status of a Performance Co-Pilot (PCP) installation. The report includes: the OS version, a summary of the hardware inventory, the local timezone, details of valid PCP licenses, the PCP software version, the state of the pmcd(1) process and associated Performance Metrics Domain Agents (PMDAs), as well as information about any PCP archive loggers (pmlogger(1)) and PCP inference engines (pmie(1)) that are running. For more general information about PCP, refer to pcpintro(1). With no arguments, pcp reports on the local host, however the following options are accepted: -a archive Report the PCP configuration as described in the PCP archive log archive. -h host Report the PCP configuration on host rather than the localhost. -n pmnsfile Load an alternative Performance Metrics Name Space ( pmns(4)) from the file pmnsfile. -p Display pmie performance information - counts of rules evaluating to true, false, or indeterminate, as well as the expected rate of rule calculation, for each pmie process running on the default host. Refer to the individual metric help text for full details on these values. All of the displayed values are performance metric values and further information for each can be obtained using the command: $ pminfo -dtT metric\n\n The complete set of metrics required by pcp to produce its output is contained in $PCP_VAR_DIR\/config\/pmlogger\/config.pcp. When displaying running pmlogger instances, as a space-saving measure pcp will display a relative path to the archive being created if that archive is located below a pcplog subdirectory, otherwise the full pathname is displayed (the PCP log rotation and periodic pmlogger checking facilities support the creation of archives below $PCP_LOG_DIR\/pmlogger\/<hostname>). A similar convention is used for trimming the amount of information displayed for running pmie instances, where configuration files below $PCP_VAR_DIR\/config will be displayed in truncated form.","Process Name":"pcp","Link":"https:\/\/linux.die.net\/man\/1\/pcp"}},{"Process":{"Description":"","Process Name":"pcpintro","Link":"https:\/\/linux.die.net\/man\/1\/pcpintro"}},{"Process":{"Description":"pcre-config returns the configuration of the installed PCRE libraries and the options required to compile a program to use them.","Process Name":"pcre-config","Link":"https:\/\/linux.die.net\/man\/1\/pcre-config"}},{"Process":{"Description":"pcregrep searches files for character patterns, in the same way as other grep commands do, but it uses the PCRE regular expression library to support patterns that are compatible with the regular expressions of Perl 5. See pcrepattern(3) for a full description of syntax and semantics of the regular expressions that PCRE supports. Patterns, whether supplied on the command line or in a separate file, are given without delimiters. For example: pcregrep Thursday \/etc\/motd If you attempt to use delimiters (for example, by surrounding a pattern with slashes, as is common in Perl scripts), they are interpreted as part of the pattern. Quotes can of course be used to delimit patterns on the command line because they are interpreted by the shell, and indeed they are required if a pattern contains white space or shell metacharacters. The first argument that follows any option settings is treated as the single pattern to be matched when neither -e nor -f is present. Conversely, when one or both of these options are used to specify patterns, all arguments are treated as path names. At least one of -e, -f, or an argument pattern must be provided. If no files are specified, pcregrep reads the standard input. The standard input can also be referenced by a name consisting of a single hyphen. For example: pcregrep some-pattern \/file1 - \/file3 By default, each line that matches a pattern is copied to the standard output, and if there is more than one file, the file name is output at the start of each line, followed by a colon. However, there are options that can change how pcregrep behaves. In particular, the -M option makes it possible to search for patterns that span line boundaries. What defines a line boundary is controlled by the -N (--newline) option. Patterns are limited to 8K or BUFSIZ characters, whichever is the greater. BUFSIZ is defined in <stdio.h>. When there is more than one pattern (specified by the use of -e and\/or -f), each pattern is applied to each line in the order in which they are defined, except that all the -e patterns are tried before the -f patterns. As soon as one pattern matches (or fails to match when -v is used), no further patterns are considered. When --only-matching, --file-offsets, or --line-offsets is used, the output is the part of the line that matched (either shown literally, or as an offset). In this case, scanning resumes immediately following the match, so that further matches on the same line can be found. If there are multiple patterns, they are all tried on the remainder of the line. However, patterns that follow the one that matched are not tried on the earlier part of the line. If the LC_ALL or LC_CTYPE environment variable is set, pcregrep uses the value to set a locale when calling the PCRE library. The --locale option can be used to override this.","Process Name":"pcregrep","Link":"https:\/\/linux.die.net\/man\/1\/pcregrep"}},{"Process":{"Description":"If pcretest is given two filename arguments, it reads from the first and writes to the second. If it is given only one filename argument, it reads from that file and writes to stdout. Otherwise, it reads from stdin and writes to stdout, and prompts for each line of input, using \"re>\" to prompt for regular expressions, and \"data>\" to prompt for data lines. When pcretest is built, a configuration option can specify that it should be linked with the libreadline library. When this is done, if the input is from a terminal, it is read using the readline() function. This provides line-editing and history facilities. The output from the -help option states whether or not readline() will be used. The program handles any number of sets of input on a single input file. Each set starts with a regular expression, and continues with any number of data lines to be matched against the pattern. Each data line is matched separately and independently. If you want to do multi-line matches, you have to use the \\n escape sequence (or \\r or \\r\\n, etc., depending on the newline setting) in a single line of input to encode the newline sequences. There is no limit on the length of data lines; the input buffer is automatically extended if it is too small. An empty line signals the end of the data lines, at which point a new regular expression is read. The regular expressions are given enclosed in any non-alphanumeric delimiters other than backslash, for example: \/(a|bc)x+yz\/ White space before the initial delimiter is ignored. A regular expression may be continued over several input lines, in which case the newline characters are included within it. It is possible to include the delimiter within the pattern by escaping it, for example \/abc\\\/def\/ If you do so, the escape and the delimiter form part of the pattern, but since delimiters are always non-alphanumeric, this does not affect its interpretation. If the terminating delimiter is immediately followed by a backslash, for example, \/abc\/\\ then a backslash is added to the end of the pattern. This is done to provide a way of testing the error condition that arises if a pattern finishes with a backslash, because \/abc\\\/ is interpreted as the first line of a pattern that starts with \"abc\/\", causing pcretest to read the next line as a continuation of the regular expression.","Process Name":"pcretest","Link":"https:\/\/linux.die.net\/man\/1\/pcretest"}},{"Process":{"Description":"This utility will convert a pseudocolor band on the input file into an output RGB file of the desired format. -of format : Format to generated (defaults to GeoTIFF). -b band : Band to convert to RGB, defaults to 1. source_file : The input file. dest_file : The output RGB file that will be created. NOTE: pct2rgb.py is a Python script, and will only work if GDAL was built with Python support. The new '-expand rgb|rgba' option of gdal_translate obsoletes that utility.","Process Name":"pct2rgb","Link":"https:\/\/linux.die.net\/man\/1\/pct2rgb"}},{"Process":{"Description":"This program is part of Netpbm(1). pcxtoppm reads a PCX file as input and produces a PPM image as output. pcxtoppm recognizes the following PCX types: \u2022 Colormapped files with 2-16 colors. 'Packed pixel' format (1, 2 or 4 bits\/pixel, 1 plane) or bitplane format (1 bit\/pixel, 1-4 planes). The program uses a predefined standard palette if the image does not provide one. 'Does not provide one' means the palette in the PCX header is completely black. \u2022 Colormapped files with 256 colors. 8 bits\/pixel, 1 plane, colormap at the end of the file. \u2022 24bit truecolor files. 24bit RGB: 8 bits\/pixel, 3 planes. \u2022 32bit truecolor files. 24bit RGB + 8bit intensity: 8 bits\/pixel, 4 planes.","Process Name":"pcxtoppm","Link":"https:\/\/linux.die.net\/man\/1\/pcxtoppm"}},{"Process":{"Description":"\"pdbdump\" reads a PalmOS .pdb file, parses it, and prints its contents. This includes both a hex dump of the raw data of each piece, and a human-readable list of the various values, insofar as possible. The aim of \"pdbdump\" is to allow one to verify whether a particular file is a well-formed PalmOS database file and if not, where the error lies. If the database is of a known type, \"pdbdump\" parses the AppInfo block and records. Otherwise, it simply prints out a hex dump of their contents. \"pdbdump\" includes, by default, support for most of the built-in applications. Other helper modules may be loaded with the \"-M\" option.","Process Name":"pdbdump","Link":"https:\/\/linux.die.net\/man\/1\/pdbdump"}},{"Process":{"Description":"This manual page is only an abstract; for the complete documentation of syslog-ng and pdbtool, see The syslog-ng Administrator Guide [1] . The syslog-ng application can match the contents of the log messages to a database of predefined message patterns (also called patterndb). By comparing the messages to the known patterns, syslog-ng is able to identify the exact type of the messages, tag the messages, and sort them into message classes. The message classes can be used to classify the type of the event described in the log message. The functionality of the pattern database is similar to that of the logcheck project, but the syslog-ng approach is faster, scales better, and is much easier to maintain compared to the regular expressions of logcheck. The pdbtool application is a utility that can be used to: \u2022 test message patterns; \u2022 convert an older pattern database to the latest database format; \u2022 merge pattern databases into a single file; \u2022 dump the RADIX tree built from the pattern database (or a part of it) to explore how the pattern matching works.","Process Name":"pdbtool","Link":"https:\/\/linux.die.net\/man\/1\/pdbtool"}},{"Process":{"Description":"pdcp is a variant of the rcp(1) command. Unlike rcp(1), which copies files to a single remote host, pdcp can copy files to multiple remote hosts in parallel. However, pdcp does not recognize files in the format ''rname@rhost:path,'' therefore all source files must be on the local host machine. Destination nodes must be listed on the pdcp command line using a suitable target nodelist option (See the OPTIONS section below). Each destination node listed must have pdcp installed for the copy to succeed. When pdcp receives SIGINT (ctrl-C), it lists the status of current threads. A second SIGINT within one second terminates the program. Pending threads may be canceled by issuing ctrl-Z within one second of ctrl-C. Pending threads are those that have not yet been initiated, or are still in the process of connecting to the remote host. Like pdsh(1), the functionality of pdcp may be supplemented by dynamically loadable modules. In pdcp, the modules may provide a new connect protocol (replacing the standard rsh(1) protocol), filtering options (e.g. excluding hosts that are down), and\/or host selection options (e.g. -a selects all nodes from a local config file). By default, pdcp requires at least one \"rcmd\" module to be loaded (to provide the channel for remote copy).","Process Name":"pdcp","Link":"https:\/\/linux.die.net\/man\/1\/pdcp"}},{"Process":{"Description":"pdf180 rotates the pages of files in the Adobe Portable Document Format (PDF) through 180 degrees. If no source PDF file ('SRC') is specified, input is from \/dev\/stdin. If 'PAGESPEC' is omitted, all pages are processed. Source files are processed sequentially into a single output unless the '--batch' option is used, in which case they are processed separately. pdf180 operates on one or more PDF files, and (either with the '--batch' option or with '--outfile DIR' where 'DIR' is a directory) the resulting files have the suffix '-rotated180' applied to their names by default. To change the suffix, use the '--suffix' option, for example pdf180 --suffix 'upturned' --batch myfile1.pdf myfile2.pdf will result in files named 'myfile1-upturned.pdf' and 'myfile2-upturned.pdf'. pdf180 is a simple wrapper for pdfjam, which is a front end to many of the capabilities of the pdfpages package for pdflatex. A working installation of pdflatex with the pdfpages package is required. pdf180 is part of the \"PDFjam\" package of tools, whose homepage is at http:\/\/go.warwick.ac.uk\/pdfjam.","Process Name":"pdf180","Link":"https:\/\/linux.die.net\/man\/1\/pdf180"}},{"Process":{"Description":"pdf270 rotates the pages of files in the Adobe Portable Document Format (PDF) through 90 degrees (clockwise). If no source PDF file ('SRC') is specified, input is from \/dev\/stdin. If 'PAGESPEC' is omitted, all pages are processed. Source files are processed sequentially into a single output unless the '--batch' option is used, in which case they are processed separately. pdf270 operates on one or more PDF files, and (either with the '--batch' option or with '--outfile DIR' where 'DIR' is a directory) the resulting files have the suffix 'rotated270' applied to their names by default. To change the suffix, use the '--suffix' option, for example pdf270 --suffix '-turned' --batch myfile1.pdf myfile2.pdf will result in files named 'myfile1-turned.pdf' and 'myfile2-turned.pdf'. pdf270 is a simple wrapper for pdfjam, which is a front end to many of the capabilities of the pdfpages package for pdflatex. A working installation of pdflatex with the pdfpages package is required. pdf270 is part of the \"PDFjam\" package of tools, whose homepage is at http:\/\/go.warwick.ac.uk\/pdfjam.","Process Name":"pdf270","Link":"https:\/\/linux.die.net\/man\/1\/pdf270"}},{"Process":{"Description":"pdf2dsc uses gs(1) to read an Adobe Portable Document Format (PDF) document \"input.pdf\" and create a PostScript(tm) document \"output.dsc\" that conforms to Adobe's Document Structuring Conventions (DSC) requirements. This new document simply tells Ghostscript to read the PDF file and to display pages one at a time. The generated document can then be viewed with any PostScript viewer based on Ghostscript, like ghostview(1) on Unix or GSview on Windows, with which the user can browse through the pages of the PDF document in any order. If no output file is named on the command line, the name of the output file is that of the input file with any extension removed, followed by the extension \".dsc\".","Process Name":"pdf2dsc","Link":"https:\/\/linux.die.net\/man\/1\/pdf2dsc"}},{"Process":{"Description":"pdf2ps uses gs(1) to convert the Adobe Portable Document Format (PDF) file \"input.pdf\" to PostScript(tm) in \"output.ps\". Normally the output is allowed to use PostScript Level 2 (but not PostScript LanguageLevel 3) constructs; the -dLanguageLevel=1 option restricts the output to Level 1, while -dLanguageLevel=3 allows using LanguageLevel 3 in the output.","Process Name":"pdf2ps","Link":"https:\/\/linux.die.net\/man\/1\/pdf2ps"}},{"Process":{"Description":"Converts a PDF file to a SWF file.","Process Name":"pdf2swf","Link":"https:\/\/linux.die.net\/man\/1\/pdf2swf"}},{"Process":{"Description":"pdf90 rotates the pages of files in the Adobe Portable Document Format (PDF) through 90 degrees (anti-clockwise). If no source PDF file ('SRC') is specified, input is from \/dev\/stdin. If 'PAGESPEC' is omitted, all pages are processed. Source files are processed sequentially into a single output unless the '--batch' option is used, in which case they are processed separately. pdf90 operates on one or more PDF files, and (either with the '--batch' option or with '--outfile DIR' where 'DIR' is a directory) the resulting files have the suffix 'rotated90' applied to their names by default. To change the suffix, use the '--suffix' option, for example pdf90 --suffix '-turned' --batch myfile1.pdf myfile2.pdf will result in files named 'myfile1-turned.pdf' and 'myfile2-turned.pdf'. pdf90 is a simple wrapper for pdfjam, which is a front end to many of the capabilities of the pdfpages package for pdflatex. A working installation of pdflatex with the pdfpages package is required. pdf90 is part of the \"PDFjam\" package of tools, whose homepage is at http:\/\/go.warwick.ac.uk\/pdfjam.","Process Name":"pdf90","Link":"https:\/\/linux.die.net\/man\/1\/pdf90"}},{"Process":{"Description":"pdfbook makes 2-up versions of PDF files, with the pages ordered as signatures. The default signature size is 4: to change this, use the option '--signature N', where N is a multiple of 4 (alternatively use '--signature* N' for right-edge binding). The default is to make pages suitable for long-edge binding. For short-edge binding, use '--short-edge' as the first argument; this will only work if the LaTeX package 'everyshi' is installed. The default output page orientation is landscape. To change this, use the '--no-landscape' option. By default, the option '--booklet true' is used (see the pdfpages manual for details). To turn this off, just specify '--booklet false'. If no source PDF file ('SRC') is specified, input is from \/dev\/stdin. If 'PAGESPEC' is omitted, all pages are processed. Source files are processed sequentially into a single output unless the '--batch' option is used, in which case they are processed separately. pdfbook is a simple wrapper for pdfjam, which provides a front end to many of the capabilities of the pdfpages package for pdflatex. A working installation of pdflatex, with the pdfpages package, is required. pdfbook operates on one or more PDF files, and (either with the '--batch' option or with '--outfile DIR' where 'DIR' is a directory) the resulting files have the suffix '-book' applied to their names by default. To change the suffix, use the '--suffix' option, for example pdfbook --suffix 'sig4' --batch myfile1.pdf myfile2.pdf will result in files named 'myfile1-sig4.pdf' and 'myfile2-sig4.pdf'. pdfbook is part of the \"PDFjam\" package of tools, whose homepage is at http:\/\/www.warwick.ac.uk\/go\/pdfjam.","Process Name":"pdfbook","Link":"https:\/\/linux.die.net\/man\/1\/pdfbook"}},{"Process":{"Description":"This program changes the MediaBox entry in a PDF file. It runs as a filter, reading a PDF file from standard input and writing a cropped PDF file to standard output. If one cuts a PostScript file using epsffit and converts it to PDF using ps2pdf the resulting PDF is not yet cropped to the bounding box established by epsffit. The pdfcmb program does this final cropping step on PDFs generated using epsffit\/ps2pdf. Note: See the RESTRICTIONS section.","Process Name":"pdfcmb","Link":"https:\/\/linux.die.net\/man\/1\/pdfcmb"}},{"Process":{"Description":"You can specify any number of filenames as parameters on commandline. One window will be opened for each file specified. If no file is specified on commandline, editor will be loaded initially empty. Name of files can be mixed with options (parameter that begin with a dash). Invalid option on commandline will cause editor to abort with error message. Names of options are case sensitive. Options which require a parameter can be specified in \"short form\", like -d1 or \"long form\", like -d 1 , both of these mean option -d with parameter 1 Use -script , -eval and -run options to run any script besides the init script. These parameters are run\/evaluated in the order they are specified on commandline and may be specified multiple times. If these parameters are specified in GUI mode, they are used in each window opened on program start, in commandline mode (console mode) they are used after commandline init script. After these scripts finish execution, the editor terminates.","Process Name":"pdfedit","Link":"https:\/\/linux.die.net\/man\/1\/pdfedit"}},{"Process":{"Description":"Run the pdfeTeX typesetter on file, usually creating file.pdf. If the file argument has no extension, \".tex\" will be appended to it. Instead of a filename, a set of pdfeTeX commands can be given, the first of which must start with a backslash. With a &format argument pdfeTeX uses a different set of precompiled commands, contained in format.fmt; it is usually better to use the -fmt format option instead. pdfeTeX is a version of e-TeX that can create PDF files as well as DVI files. In DVI mode, pdfeTeX can be used as a complete replacement of the e-TeX engine. The typical use of pdfeTeX is with a pregenerated formats for which PDF output has been enabled. The pdfetex command uses the equivalent of the plain e-TeX format, and the pdfelatex command uses the equivalent of the e-LaTeX format. To generate formats, use the -ini switch. The pdfeinitex and pdfevirtex commands are pdfeTeX's analogues to the einitex and evirtex commands. In this installation, they are symbolic links to the pdfetex executable. These symbolic links may not exist at all. In PDF mode, pdfeTeX can natively handle the PDF, JPG, JBIG2, and PNG graphics formats. pdfeTeX cannot include PostScript or Encapsulated PostScript (EPS) graphics files; first convert them to PDF using epstopdf(1). pdfeTeX's handling of its command-line arguments is similar to that of of the other TeX programs in the web2c implementation.","Process Name":"pdfetex","Link":"https:\/\/linux.die.net\/man\/1\/pdfetex"}},{"Process":{"Description":"pdfflip reflects (left-right) the pages of files in the Adobe Portable Document Format (PDF). If no source PDF file ('SRC') is specified, input is from \/dev\/stdin. If 'PAGESPEC' is omitted, all pages are processed. Source files are processed sequentially into a single output unless the '--batch' option is used, in which case they are processed separately. pdfflip operates on one or more PDF files, and (either with the '--batch' option or with '--outfile DIR' where 'DIR' is a directory) the resulting files have the suffix '-flipped' applied to their names by default. To change the suffix, use the '--suffix' option, for example pdfflip --suffix 'reflected' --batch myfile1.pdf myfile2.pdf will result in files named 'myfile1-reflected.pdf' and 'myfile2-reflected.pdf'. pdfflip is a simple wrapper for pdfjam, which is a front end to many of the capabilities of the pdfpages package for pdflatex. A working installation of pdflatex with the pdfpages package is required. pdfflip is part of the \"PDFjam\" package of tools, whose homepage is at http:\/\/go.warwick.ac.uk\/pdfjam.","Process Name":"pdfflip","Link":"https:\/\/linux.die.net\/man\/1\/pdfflip"}},{"Process":{"Description":"Pdffonts lists the fonts used in a Portable Document Format (PDF) file along with various information for each font. The following information is listed for each font: name the font name, exactly as given in the PDF file (potentially including a subset prefix) type the font type -- see below for details emb \"yes\" if the font is embedded in the PDF file sub \"yes\" if the font is a subset uni \"yes\" if there is an explicit \"ToUnicode\" map in the PDF file (the absence of a ToUnicode map doesn't necessarily mean that the text can't be converted to Unicode) object ID the font dictionary object ID (number and generation) PDF files can contain the following types of fonts: Type 1 Type 1C -- aka Compact Font Format (CFF) Type 3 TrueType CID Type 0 -- 16-bit font with no specified type CID Type 0C -- 16-bit PostScript CFF font CID TrueType -- 16-bit TrueType font","Process Name":"pdffonts","Link":"https:\/\/linux.die.net\/man\/1\/pdffonts"}},{"Process":{"Description":"Pdfimages saves images from a Portable Document Format (PDF) file as Portable Pixmap (PPM), Portable Bitmap (PBM), or JPEG files. Pdfimages reads the PDF file PDF-file, scans one or more pages, and writes one PPM, PBM, or JPEG file for each image, image-root-nnn.xxx, where nnn is the image number and xxx is the image type (.ppm, .pbm, .jpg).","Process Name":"pdfimages","Link":"https:\/\/linux.die.net\/man\/1\/pdfimages"}},{"Process":{"Description":"Pdfinfo prints the contents of the 'Info' dictionary (plus some other useful information) from a Portable Document Format (PDF) file. The 'Info' dictionary contains the following values: title subject keywords author creator producer creation date modification date In addition, the following information is printed: tagged (yes\/no) page count encrypted flag (yes\/no) print and copy permissions (if encrypted) page size file size linearized (yes\/no) PDF version metadata (only if requested)","Process Name":"pdfinfo","Link":"https:\/\/linux.die.net\/man\/1\/pdfinfo"}},{"Process":{"Description":"Run the pdfTeX typesetter on file, usually creating file.pdf. If the file argument has no extension, \".tex\" will be appended to it. Instead of a filename, a set of pdfTeX commands can be given, the first of which must start with a backslash. With a &format argument pdfTeX uses a different set of precompiled commands, contained in format.fmt; it is usually better to use the -fmt format option instead. pdfTeX is a version of TeX, with the e-TeX extensions, that can create PDF files as well as DVI files. In DVI mode, pdfTeX can be used as a complete replacement for the TeX engine. The typical use of pdfTeX is with a pregenerated formats for which PDF output has been enabled. The pdftex command uses the equivalent of the plain TeX format, and the pdflatex command uses the equivalent of the LaTeX format. To generate formats, use the -ini switch. The pdfinitex and pdfvirtex commands are pdfTeX's analogues to the initex and virtex commands. In this installation, if the links exist, they are symbolic links to the pdftex executable. In PDF mode, pdfTeX can natively handle the PDF, JPG, JBIG2, and PNG graphics formats. pdfTeX cannot include PostScript or Encapsulated PostScript (EPS) graphics files; first convert them to PDF using epstopdf(1). pdfTeX's handling of its command-line arguments is similar to that of of the other TeX programs in the web2c implementation.","Process Name":"pdfinitex","Link":"https:\/\/linux.die.net\/man\/1\/pdfinitex"}},{"Process":{"Description":"This manual page was derived from the manual page for LaTeX and is not meant to be exhaustive. The complete documentation for this version of TeX can be found in the info file or manual Web2C: A TeX implementation. JadeTeX is a TeX macro package, not a modification to the TeX source program, so all the capabilities described in tex(1) are present. pdfjadetex is the PDFTeX version of the jadeTeX format.","Process Name":"pdfjadetex","Link":"https:\/\/linux.die.net\/man\/1\/pdfjadetex"}},{"Process":{"Description":"pdfjam provides a front end to most capabilities of the \"pdfpages\" package (by Andreas Matthias) of pdflatex. Detailed information can be found via \"pdfjam --help\", and also in the web page mentioned below . A working installation of pdflatex, with the pdfpages package, is required. The pdfjam script is distributed as (the main) part of the PDFjam package. The homepage of PDFjam is at http:\/\/go.warwick.ac.uk\/pdfjam .","Process Name":"pdfjam","Link":"https:\/\/linux.die.net\/man\/1\/pdfjam"}},{"Process":{"Description":"pdfjam-pocketmod converts 8 pages of a PDF file into a single 8-up page, with pages ordered and oriented for folding into pocket-sized booklet ( as described at http:\/\/repocketmod.com\/ ). SRC must be a regular PDF file (not \/dev\/stdin). If PAGESPEC is omitted, the first 8 pages are processed. OPTION is any option to pdfjam(1) other than --batch. pdfjam-pocketmod is a simple wrapper for pdfjam, which provides a front end to some of the capabilities of the pdfpages package for pdflatex. A working installation of pdflatex, with the pdfpages package, is required. pdfjam-pocketmod is part of the \"PDFjam\" package of tools, whose homepage is at http:\/\/go.warwick.ac.uk\/pdfjam .","Process Name":"pdfjam-pocketmod","Link":"https:\/\/linux.die.net\/man\/1\/pdfjam-pocketmod"}},{"Process":{"Description":"pdfjam-slides3up converts PDF files whose pages are presentation slides (with 4:3 aspect ratio) into 3-up versions suitable for making a handout with space for handwritten side notes (for example). By default, the 3-up pages do not themselves have page numbers. To put page numbers on the output pages, use either '--pagenumbering true' or, for example, '--pagenumbering 3.4cm' to place the page numbers a bit lower on the page than the default position. The value of 'SWITCH' must be either 'true', 'false' or a dimension that can be used by LateX. (To be precise, it's the value of the 'footskip' dimension in LaTeX; by default, pdfjam-slides3up sets that as 3.1cm, which works pretty well in conjunction with both '--paper a4paper' and '--paper letterpaper'.) If no source PDF file ('SRC') is specified, input is from \/dev\/stdin. If 'PAGESPEC' is omitted, all pages are processed. Source files are processed sequentially into a single output unless the '--batch' option is used, in which case they are processed separately. pdfjam-slides3up is a simple wrapper for pdfjam, which provides a front end to many of the capabilities of the pdfpages package for pdflatex. A working installation of pdflatex, with the pdfpages package, is required. pdfjam-slides3up operates on one or more PDF files, and (either with the '--batch' option or with '--outfile DIR' where 'DIR' is a directory) the resulting files have the suffix '-3up' applied to their names by default. To change the suffix, use the '--suffix' option, for example pdfjam-slides3up --suffix '1x3' --batch myslides1.pdf myslides2.pdf will result in files named 'myslides1-1x3.pdf' and 'myslides2-1x3.pdf'. By default a narrow line frame is printed around every slide. This can be turned off if required by using the option '--frame false'. pdfjam-slides3up is part of the \"PDFjam\" package of tools, whose homepage is at http:\/\/www.warwick.ac.uk\/go\/pdfjam .","Process Name":"pdfjam-slides3up","Link":"https:\/\/linux.die.net\/man\/1\/pdfjam-slides3up"}},{"Process":{"Description":"pdfjam-slides6up converts PDF files whose pages are presentation slides (with 4:3 aspect ratio) into 6-up versions suitable for making a handout (for example). By default, the 6-up pages do not themselves have page numbers. To put page numbers on the output pages, use either '--pagenumbering true' or, for example, '--pagenumbering 3.0cm' to place the page numbers a bit lower on the page than the default position. The value of 'SWITCH' must be either 'true', 'false' or a dimension that can be used by LateX. (To be precise, it's the value of the 'footskip' dimension in LaTeX; by default, pdfjam-slides6up sets that as 2.7cm, which works pretty well in conjunction with both '--paper a4paper' and '--paper letterpaper'.) If no source PDF file ('SRC') is specified, input is from \/dev\/stdin. If 'PAGESPEC' is omitted, all pages are processed. Source files are processed sequentially into a single output unless the '--batch' option is used, in which case they are processed separately. pdfjam-slides6up is a simple wrapper for pdfjam, which provides a front end to many of the capabilities of the pdfpages package for pdflatex. A working installation of pdflatex, with the pdfpages package, is required. pdfjam-slides6up operates on one or more PDF files, and (either with the '--batch' option or with '--outfile DIR' where 'DIR' is a directory) the resulting files have the suffix '-6up' applied to their names by default. To change the suffix, use the '--suffix' option, for example pdfjam-slides6up --suffix '2x3' --batch myslides1.pdf myslides2.pdf will result in files named 'myslides1-2x3.pdf' and 'myslides2-2x3.pdf'. By default a narrow line frame is printed around every slide. This can be turned off if required by using the option '--frame false'. pdfjam-slides6up is part of the \"PDFjam\" package of tools, whose homepage is at http:\/\/www.warwick.ac.uk\/go\/pdfjam .","Process Name":"pdfjam-slides6up","Link":"https:\/\/linux.die.net\/man\/1\/pdfjam-slides6up"}},{"Process":{"Description":"pdfjoin concatenates the pages of multiple Portable Document Format (PDF) files together into a single file.. If no source PDF file ('SRC') is specified, input (but just one file -- not very useful here! is from \/dev\/stdin. If 'PAGESPEC' is omitted, all pages are processed. Source files are processed sequentially into a single output. The '--batch' option of pdfjam(1) cannot be used. pdfjoin is a simple wrapper for pdfjam, which provides a front end to many of the capabilities of the pdfpages package for pdflatex. A working installation of pdflatex, with the pdfpages package, is required. pdfjoin is part of the \"PDFjam\" package of tools, whose homepage is at http:\/\/go.warwick.ac.uk\/pdfjam .","Process Name":"pdfjoin","Link":"https:\/\/linux.die.net\/man\/1\/pdfjoin"}},{"Process":{"Description":"Run the pdfTeX typesetter on file, usually creating file.pdf. If the file argument has no extension, \".tex\" will be appended to it. Instead of a filename, a set of pdfTeX commands can be given, the first of which must start with a backslash. With a &format argument pdfTeX uses a different set of precompiled commands, contained in format.fmt; it is usually better to use the -fmt format option instead. pdfTeX is a version of TeX, with the e-TeX extensions, that can create PDF files as well as DVI files. In DVI mode, pdfTeX can be used as a complete replacement for the TeX engine. The typical use of pdfTeX is with a pregenerated formats for which PDF output has been enabled. The pdftex command uses the equivalent of the plain TeX format, and the pdflatex command uses the equivalent of the LaTeX format. To generate formats, use the -ini switch. The pdfinitex and pdfvirtex commands are pdfTeX's analogues to the initex and virtex commands. In this installation, if the links exist, they are symbolic links to the pdftex executable. In PDF mode, pdfTeX can natively handle the PDF, JPG, JBIG2, and PNG graphics formats. pdfTeX cannot include PostScript or Encapsulated PostScript (EPS) graphics files; first convert them to PDF using epstopdf(1). pdfTeX's handling of its command-line arguments is similar to that of of the other TeX programs in the web2c implementation.","Process Name":"pdflatex","Link":"https:\/\/linux.die.net\/man\/1\/pdflatex"}},{"Process":{"Description":"pdfnup converts files in the Adobe Portable Document Format (PDF) to \"n-up\" PDF files, that is, with multiple input pages per output page, for more economical printing etc. The default processing is to 2-up landscape output with no frame around pages, equivalent to using the options '--nup 2x1 --landscape true --frame false'. If no source PDF file ('SRC') is specified, input is from \/dev\/stdin. If 'PAGESPEC' is omitted, all pages are processed. Source files are processed sequentially into a single output unless the '--batch' option is used, in which case they are processed separately. pdfnup operates on one or more PDF files, and (either with the '--batch' option or with '--outfile DIR' where 'DIR' is a directory) the resulting files have the suffix '-nup' applied to their names by default. To change the suffix, use the '--suffix' option, for example pdfnup --nup 2x2 --suffix '2x2' --batch myfile1.pdf myfile2.pdf will result in files named 'myfile1-2x2.pdf' and 'myfile2-2x2.pdf'. pdfnup is a simple wrapper for pdfjam, which provides a front end to many of the capabilities of the pdfpages package for pdflatex. A working installation of pdflatex, with the pdfpages and geometry packages, is required. pdfnup is part of the \"PDFjam\" package of tools, whose homepage is at http:\/\/www.warwick.ac.uk\/go\/pdfjam .","Process Name":"pdfnup","Link":"https:\/\/linux.die.net\/man\/1\/pdfnup"}},{"Process":{"Description":"pdfopt uses gs(1) to convert the Adobe Portable Document Format (PDF) file \"input.pdf\" to a so-called optimized form in \"output.pdf\". Optimization puts the elements of the file into a more linear order and adds \"hint\" pointers, allowing Adobe's Acrobat(TM) products to display individual pages of the file more quickly when accessing the file through a network. Note: input.pdf and output.pdf must not be the same. If they are, the file will probably be destroyed. pdfopt currently does not check for this.","Process Name":"pdfopt","Link":"https:\/\/linux.die.net\/man\/1\/pdfopt"}},{"Process":{"Description":"pdfpun converts a file in the Adobe Portable Document Format (PDF) to a \"n-up\" PDF file, that is, with multiple input pages per output page, for more economical printing etc. The pages are ordered right-to-left in the output. The default processing is to 2-up landscape output with no frame around pages, equivalent to using the options '--nup 2x1 --landscape --frame false'. SRC must be a PDF file; '\/dev\/stdin' can be used for PDF input via a pipeline. If PAGESPEC is omitted, all pages are processed (equivalent to '-' as PAGESPEC) OPTION is any option of pdfjam(1) other than --batch. pdfpun is a simple wrapper for pdfjam, which provides a front end to many of the capabilities of the pdfpages package for pdflatex. A working installation of pdflatex, with the pdfpages package, is required. pdfpun is part of the \"PDFjam\" package of tools, whose homepage is at http:\/\/www.warwick.ac.uk\/go\/pdfjam.","Process Name":"pdfpun","Link":"https:\/\/linux.die.net\/man\/1\/pdfpun"}},{"Process":{"Description":"PDF-Shuffler is a small python-gtk application, which helps the user to merge or split pdf documents and rearrange their pages using an interactive and intuitive graphical interface. In the current version, page rotation and cropping is also supported. PDF-Shuffler is a frontend for python-pyPdf.","Process Name":"pdfshuffler","Link":"https:\/\/linux.die.net\/man\/1\/pdfshuffler"}},{"Process":{"Description":"Run the pdfTeX typesetter on file, usually creating file.pdf. If the file argument has no extension, \".tex\" will be appended to it. Instead of a filename, a set of pdfTeX commands can be given, the first of which must start with a backslash. With a &format argument pdfTeX uses a different set of precompiled commands, contained in format.fmt; it is usually better to use the -fmt format option instead. pdfTeX is a version of TeX, with the e-TeX extensions, that can create PDF files as well as DVI files. In DVI mode, pdfTeX can be used as a complete replacement for the TeX engine. The typical use of pdfTeX is with a pregenerated formats for which PDF output has been enabled. The pdftex command uses the equivalent of the plain TeX format, and the pdflatex command uses the equivalent of the LaTeX format. To generate formats, use the -ini switch. The pdfinitex and pdfvirtex commands are pdfTeX's analogues to the initex and virtex commands. In this installation, if the links exist, they are symbolic links to the pdftex executable. In PDF mode, pdfTeX can natively handle the PDF, JPG, JBIG2, and PNG graphics formats. pdfTeX cannot include PostScript or Encapsulated PostScript (EPS) graphics files; first convert them to PDF using epstopdf(1). pdfTeX's handling of its command-line arguments is similar to that of of the other TeX programs in the web2c implementation.","Process Name":"pdftex","Link":"https:\/\/linux.die.net\/man\/1\/pdftex"}},{"Process":{"Description":"Run each Texinfo or (La)TeX FILE through TeX in turn until all cross-references are resolved, building all indices. The directory containing each FILE is searched for included files. The suffix of FILE is used to determine its language ((La)TeX or Texinfo). To process (e)plain TeX files, set the environment variable LATEX=tex. In order to make texi2dvi a drop-in replacement of TeX\/LaTeX in AUC-TeX, the FILE may also be composed of the following simple TeX commands. '\\input{FILE}' the actual file to compile '\\nonstopmode' same as --batch Makeinfo is used to perform Texinfo macro expansion before running TeX when needed. General options: -b, --batch no interaction -D, --debug turn on shell debugging (set -x) -h, --help display this help and exit successfully -o, --output= OFILE leave output in OFILE (implies --clean); only one input FILE may be specified in this case -q, --quiet no output unless errors (implies --batch) -s, --silent same as --quiet -v, --version display version information and exit successfully -V, --verbose report on what is done TeX tuning: -@ use @input instead of \\input for preloaded Texinfo --dvi output a DVI file [default] --dvipdf output a PDF file via DVI (using dvipdf) -e, -E, --expand force macro expansion using makeinfo -I DIR search DIR for Texinfo files -l, --language= LANG specify LANG for FILE, either latex or texinfo --no-line-error do not pass --file-line-error to TeX -p, --pdf use pdftex or pdflatex for processing -r, --recode call recode before TeX to translate input --recode-from= ENC recode from ENC to the @documentencoding --src-specials pass --src-specials to TeX -t, --command= CMD insert CMD in copy of input file or --texinfo= CMD multiple values accumulate --translate-file= FILE use given charset translation file for TeX Build modes: --build= MODE specify the treatment of auxiliary files [local] --tidy same as --build= tidy -c, --clean same as --build= clean --build-dir= DIR specify where the tidy compilation is performed; implies --tidy; defaults to TEXI2DVI_BUILD_DIRECTORY [.] --mostly-clean remove the auxiliary files and directories but not the output The MODE specifies where the TeX compilation takes place, and, as a consequence, how auxiliary files are treated. The build mode can also be set using the environment variable TEXI2DVI_BUILD_MODE. Valid MODEs are: 'local' compile in the current directory, leaving all the auxiliary files around. This is the traditional TeX use. 'tidy' compile in a local *.t2d directory, where the auxiliary files are left. Output files are copied back to the original file. 'clean' same as 'tidy', but remove the auxiliary directory afterwards. Every compilation therefore requires the full cycle. Using the 'tidy' mode brings several advantages: - the current directory is not cluttered with plethora of temporary files. - clutter can be even reduced using --build-dir= dir: all the *.t2d directories are stored there. - clutter can be reduced to zero using, e.g., --build-dir=\/tmp\/$USER.t2d or --build-dir=$HOME\/.t2d. - the output file is updated after every succesful TeX run, for sake of concurrent visualization of the output. In a 'local' build the viewer stops during the whole TeX run. - if the compilation fails, the previous state of the output file is preserved. - PDF and DVI compilation are kept in separate subdirectories preventing any possibility of auxiliary file incompatibility. On the other hand, because 'tidy' compilation takes place in another directory, occasionally TeX won't be able to find some files (e.g., when using \\graphicspath): in that case use -I to specify the additional directories to consider. The values of the BIBTEX, LATEX (or PDFLATEX), MAKEINDEX, MAKEINFO, TEX (or PDFTEX), TEXINDEX, and THUMBPDF environment variables are used to run those commands, if they are set. Any CMD strings are added after @setfilename for Texinfo input, in the first line for LaTeX input.","Process Name":"pdftexi2dvi","Link":"https:\/\/linux.die.net\/man\/1\/pdftexi2dvi"}},{"Process":{"Description":"If PDF is electronic paper, then pdftk is an electronic staple-remover, hole-punch, binder, secret-decoder-ring, and X-Ray-glasses. Pdftk is a simple tool for doing everyday things with PDF documents. Use it to: * Merge PDF Documents or Collate PDF Page Scans * Split PDF Pages into a New Document * Rotate PDF Documents or Pages * Decrypt Input as Necessary (Password Required) * Encrypt Output as Desired * Fill PDF Forms with X\/FDF Data and\/or Flatten Forms * Generate FDF Data Stencils from PDF Forms * Apply a Background Watermark or a Foreground Stamp * Report PDF Metrics such as Metadata and Bookmarks * Update PDF Metadata * Attach Files to PDF Pages or the PDF Document * Unpack PDF Attachments * Burst a PDF Document into Single Pages * Uncompress and Re-Compress Page Streams * Repair Corrupted PDF (Where Possible)","Process Name":"pdftk","Link":"https:\/\/linux.die.net\/man\/1\/pdftk"}},{"Process":{"Description":"This manual page documents briefly the pdftohtml command. This manual page was written for the Debian GNU\/Linux distribution because the original program does not have a manual page. pdftohtml is a program that converts pdf documents into html. It generates its output in the current working directory.","Process Name":"pdftohtml","Link":"https:\/\/linux.die.net\/man\/1\/pdftohtml"}},{"Process":{"Description":"pdftools analyzes PDF files and changes image colors. It is used by the ConTeXt programs. The image-processing features are not documented here (since I don't understand what they do).","Process Name":"pdftools","Link":"https:\/\/linux.die.net\/man\/1\/pdftools"}},{"Process":{"Description":"Pdftoppm converts Portable Document Format (PDF) files to color image files in Portable Pixmap (PPM) format, grayscale image files in Portable Graymap (PGM) format, or monochrome image files in Portable Bitmap (PBM) format. Pdftoppm reads the PDF file, PDF-file, and writes one PPM file for each page, PPM-root-nnnnnn.ppm, where nnnnnn is the page number.","Process Name":"pdftoppm","Link":"https:\/\/linux.die.net\/man\/1\/pdftoppm"}},{"Process":{"Description":"Pdftops converts Portable Document Format (PDF) files to PostScript so they can be printed. Pdftops reads the PDF file, PDF-file, and writes a PostScript file, PS-file. If PS-file is not specified, pdftops converts file.pdf to file.ps (or file.eps with the -eps option). If PS-file is '-', the PostScript is sent to stdout.","Process Name":"pdftops","Link":"https:\/\/linux.die.net\/man\/1\/pdftops"}},{"Process":{"Description":"If only PDF-file is given as argument, pdftosrc extracts the embedded source file from the first found stream object with \/Type \/SourceFile within the PDF-file and writes it to a file with the name \/SourceName as defined in that PDF stream object (see application example below). If both PDF-file and stream-object-number are given as arguments, and stream-object-number is positive, pdftosrc extracts and uncompresses the PDF stream of the object given by its stream-object-number from the PDF-file and writes it to a file named PDF-file.stream-object-number with the ending .pdf or .PDF stripped from the original PDF-file name. A special case is related to XRef object streams that are part of the PDF standard from PDF-1.5 onward: If stream-object-number equals -1, then pdftosrc decompresses the XRef stream from the PDF file and writes it in human-readable PDF cross-reference table format to a file named PDF-file.xref (these XRef streams can not be extracted just by giving their object number). In any case an existing file with the output file name will be overwritten.","Process Name":"pdftosrc","Link":"https:\/\/linux.die.net\/man\/1\/pdftosrc"}},{"Process":{"Description":"Pdftotext converts Portable Document Format (PDF) files to plain text. Pdftotext reads the PDF file, PDF-file, and writes a text file, text-file. If text-file is not specified, pdftotext converts file.pdf to file.txt. If text-file is '-', the text is sent to stdout.","Process Name":"pdftotext","Link":"https:\/\/linux.die.net\/man\/1\/pdftotext"}},{"Process":{"Description":"Run the pdfTeX typesetter on file, usually creating file.pdf. If the file argument has no extension, \".tex\" will be appended to it. Instead of a filename, a set of pdfTeX commands can be given, the first of which must start with a backslash. With a &format argument pdfTeX uses a different set of precompiled commands, contained in format.fmt; it is usually better to use the -fmt format option instead. pdfTeX is a version of TeX, with the e-TeX extensions, that can create PDF files as well as DVI files. In DVI mode, pdfTeX can be used as a complete replacement for the TeX engine. The typical use of pdfTeX is with a pregenerated formats for which PDF output has been enabled. The pdftex command uses the equivalent of the plain TeX format, and the pdflatex command uses the equivalent of the LaTeX format. To generate formats, use the -ini switch. The pdfinitex and pdfvirtex commands are pdfTeX's analogues to the initex and virtex commands. In this installation, if the links exist, they are symbolic links to the pdftex executable. In PDF mode, pdfTeX can natively handle the PDF, JPG, JBIG2, and PNG graphics formats. pdfTeX cannot include PostScript or Encapsulated PostScript (EPS) graphics files; first convert them to PDF using epstopdf(1). pdfTeX's handling of its command-line arguments is similar to that of of the other TeX programs in the web2c implementation.","Process Name":"pdfvirtex","Link":"https:\/\/linux.die.net\/man\/1\/pdfvirtex"}},{"Process":{"Description":"This manual page documents briefly the xmltex, and pdfxmltex commands. This manual page was written for the Debian GNU\/Linux distribution because the original program does not have a manual page. Instead, it has documentation in HTML and PS format in the \/usr\/share\/doc\/xmltex directory. xmltex and pdfxmltex is a TeX XML parser able to transform XML documents into .dvi files. xmltex knows nothing about your XML files. It needs to load some special macros files, usually with the .xmt extension. A configuration file, either named xmltex.cfg or [rs]jobname.cfg, is parsed. An especially useful configuration command is [rs]xmltraceoff which disables XML elements tracing. xmltex already knows about many XML schemata, such as TEI, TEI.2, MathML, SEC, HTML and XSL-FO, the support for the latest being provided by the passivetex package.","Process Name":"pdfxmltex","Link":"https:\/\/linux.die.net\/man\/1\/pdfxmltex"}},{"Process":{"Description":"Run the pdfxTeX typesetter on file, usually creating file.pdf. If the file argument has no extension, \".tex\" will be appended to it. Instead of a filename, a set of pdfxTeX commands can be given, the first of which must start with a backslash. With a &format argument pdfxTeX uses a different set of precompiled commands, contained in format.fmt; it is usually better to use the -fmt format option instead. pdfxTeX is a version of e-TeX that can create PDF files as well as DVI files. In DVI mode, pdfxTeX can be used as a complete replacement of the e-TeX engine. The typical use of pdfxTeX is with a pregenerated formats for which PDF output has been enabled. The pdfxtex command uses the equivalent of the plain e-TeX format, and the pdfxlatex command uses the equivalent of the e-LaTeX format. To generate formats, use the -ini switch. The pdfxinitex and pdfxvirtex commands are pdfxTeX's analogues to the einitex and evirtex commands. In this installation, they are symbolic links to the pdfxtex executable. These symbolic links may not exist at all. In PDF mode, pdfxTeX can natively handle the PDF, JPG, and PNG graphics formats. pdfxTeX's handling of its command-line arguments is similar to that of of the other TeX programs in the web2c implementation.","Process Name":"pdfxtex","Link":"https:\/\/linux.die.net\/man\/1\/pdfxtex"}},{"Process":{"Description":"Pretty print the differences between FILE1 and FILE2.","Process Name":"pdiff","Link":"https:\/\/linux.die.net\/man\/1\/pdiff"}},{"Process":{"Description":"ksh is a command interpreter that is intended for both interactive and shell script use. Its command language is a superset of the sh(1) shell language. Shell Startup The following options can be specified only on the command line: -c command-string the shell executes the command(s) contained in command-string -i interactive mode - see below -l login shell - see below interactive mode - see below -s the shell reads commands from standard input; all non-option arguments are positional parameters -r restricted mode - see below In addition to the above, the options described in the set built-in command can also be used on the command line. If neither the -c nor the -s options are specified, the first non-option argument specifies the name of a file the shell reads commands from; if there are no non-option arguments, the shell reads commands from standard input. The name of the shell (i.e., the contents of the $0) parameter is determined as follows: if the -c option is used and there is a non-option argument, it is used as the name; if commands are being read from a file, the file is used as the name; otherwise the name the shell was called with (i.e., argv[0]) is used. A shell is interactive if the -i option is used or if both standard input and standard error are attached to a tty. An interactive shell has job control enabled (if available), ignores the INT, QUIT and TERM signals, and prints prompts before reading input (see PS1 and PS2 parameters). For non-interactive shells, the trackall option is on by default (see set command below). A shell is restricted if the -r option is used or if either the basename of the name the shell is invoked with or the SHELL parameter match the pattern *r*sh (e.g., rsh, rksh, rpdksh, etc.). The following restrictions come into effect after the shell processes any profile and $ENV files: \u2022 the cd command is disabled \u2022 the SHELL, ENV and PATH parameters can't be changed \u2022 command names can't be specified with absolute or relative paths \u2022 the -p option of the command built-in can't be used \u2022 redirections that create files can't be used (i.e., >, >|, >>, <>) A shell is privileged if the -p option is used or if the real user-id or group-id does not match the effective user-id or group-id (see getuid(2), getgid(2)). A privileged shell does not process $HOME\/.profile nor the ENV parameter (see below), instead the file \/etc\/suid_profile is processed. Clearing the privileged option causes the shell to set its effective user-id (group-id) to its real user-id (group-id). If the basename of the name the shell is called with (i.e., argv[0]) starts with - or if the -l option is used, the shell is assumed to be a login shell and the shell reads and executes the contents of \/etc\/profile and $HOME\/.profile if they exist and are readable. If the ENV parameter is set when the shell starts (or, in the case of login shells, after any profiles are processed), its value is subjected to parameter, command, arithmetic and tilde substitution and the resulting file (if any) is read and executed. If ENV parameter is not set (and not null) and pdksh was compiled with the DEFAULT_ENV macro defined, the file named in that macro is included (after the above mentioned substitutions have been performed). The exit status of the shell is 127 if the command file specified on the command line could not be opened, or non-zero if a fatal syntax error occurred during the execution of a script. In the absence of fatal errors, the exit status is that of the last command executed, or zero, if no command is executed. Command Syntax The shell begins parsing its input by breaking it into words. Words, which are sequences of characters, are delimited by unquoted white-space characters (space, tab and newline) or meta-characters ( <, >, |, ;, &, ( and )). Aside from delimiting words, spaces and tabs are ignored, while newlines usually delimit commands. The meta-characters are used in building the following tokens: <, <&, <<, >, >&, >>, etc. are used to specify redirections (see Input\/Output Redirection below); | is used to create pipelines; |& is used to create co-processes (see Co-Processes below); ; is used to separate commands; & is used to create asynchronous pipelines; && and || are used to specify conditional execution; ;; is used in case statements; (( .. )) are used in arithmetic expressions; and lastly, ( .. ) are used to create subshells. White-space and meta-characters can be quoted individually using backslash (\\), or in groups using double (\") or single (') quotes. Note that the following characters are also treated specially by the shell and must be quoted if they are to represent themselves: \\, \", ', #, $, ', ~, {, }, *, ? and [. The first three of these are the above mentioned quoting characters (see Quoting below); #, if used at the beginning of a word, introduces a comment - everything after the # up to the nearest newline is ignored; $ is used to introduce parameter, command and arithmetic substitutions (see Substitution below); ' introduces an old-style command substitution (see Substitution below); ~ begins a directory expansion (see Tilde Expansion below); { and } delimit csh(1) style alternations (see Brace Expansion below); and, finally, *, ? and [ are used in file name generation (see File Name Patterns below). As words and tokens are parsed, the shell builds commands, of which there are two basic types: simple-commands, typically programs that are executed, and compound-commands, such as for and if statements, grouping constructs and function definitions. A simple-command consists of some combination of parameter assignments (see Parameters below), input\/output redirections (see Input\/Output Redirections below), and command words; the only restriction is that parameter assignments come before any command words. The command words, if any, define the command that is to be executed and its arguments. The command may be a shell built-in command, a function or an external command, i.e., a separate executable file that is located using the PATH parameter (see Command Execution below). Note that all command constructs have an exit status: for external commands, this is related to the status returned by wait(2) (if the command could not be found, the exit status is 127, if it could not be executed, the exit status is 126); the exit status of other command constructs (built-in commands, functions, compound-commands, pipelines, lists, etc.) are all well defined and are described where the construct is described. The exit status of a command consisting only of parameter assignments is that of the last command substitution performed during the parameter assignment or zero if there were no command substitutions. Commands can be chained together using the | token to form pipelines, in which the standard output of each command but the last is piped (see pipe(2)) to the standard input of the following command. The exit status of a pipeline is that of its last command. A pipeline may be prefixed by the ! reserved word which causes the exit status of the pipeline to be logically complemented: if the original status was 0 the complemented status will be 1, and if the original status was not 0, then the complemented status will be 0. Lists of commands can be created by separating pipelines by any of the following tokens: &&, ||, &, |& and ;. The first two are for conditional execution: cmd1 && cmd2 executes cmd2 only if the exit status of cmd1 is zero; || is the opposite - cmd2 is executed only if the exit status of cmd1 is non-zero. && and || have equal precedence which is higher than that of &, |& and ;, which also have equal precedence. The & token causes the preceding command to be executed asynchronously, that is, the shell starts the command, but does not wait for it to complete (the shell does keep track of the status of asynchronous commands - see Job Control below). When an asynchronous command is started when job control is disabled (i.e., in most scripts), the command is started with signals INT and QUIT ignored and with input redirected from \/dev\/null (however, redirections specified in the asynchronous command have precedence). The |& operator starts a co-process which is special kind of asynchronous process (see Co-Processes below). Note that a command must follow the && and || operators, while a command need not follow &, |& and ;. The exit status of a list is that of the last command executed, with the exception of asynchronous lists, for which the exit status is 0. Compound commands are created using the following reserved words - these words are only recognized if they are unquoted and if they are used as the first word of a command (i.e., they can't be preceded by parameter assignments or redirections): Note: Some shells (but not this one) execute control structure commands in a subshell when one or more of their file descriptors are redirected, so any environment changes inside them may fail. To be portable, the exec statement should be used instead to redirect file descriptors before the control structure. In the following compound command descriptions, command lists (denoted as list) that are followed by reserved words must end with a semi-colon, a newline or a (syntactically correct) reserved word. For example, { echo foo; echo bar; } { echo foo; echo bar<newline>} { { echo foo; echo bar; } } are all valid, but { echo foo; echo bar } is not. ( list ) Execute list in a subshell. There is no implicit way to pass environment changes from a subshell back to its parent. { list } Compound construct; list is executed, but not in a subshell. Note that { and } are reserved words, not meta-characters. case word in [ [ (] pattern [ | pattern] ... ) list ;; ] ... esac The case statement attempts to match word against the specified patterns; the list associated with the first successfully matched pattern is executed. Patterns used in case statements are the same as those used for file name patterns except that the restrictions regarding . and \/ are dropped. Note that any unquoted space before and after a pattern is stripped; any space with a pattern must be quoted. Both the word and the patterns are subject to parameter, command, and arithmetic substitution as well as tilde substitution. For historical reasons, open and close braces may be used instead of in and esac ( e.g., case $foo { *) echo bar; }). The exit status of a case statement is that of the executed list; if no list is executed, the exit status is zero. for name [ in word ... term ] do list done where term is either a newline or a ;. For each word in the specified word list, the parameter name is set to the word and list is executed. If in is not used to specify a word list, the positional parameters ( \"$1\", \"$2\", etc.) are used instead. For historical reasons, open and close braces may be used instead of do and done ( e.g., for i; { echo $i; }). The exit status of a for statement is the last exit status of list; if list is never executed, the exit status is zero. if list then list [ elif list then list] ... [ else list] fi If the exit status of the first list is zero, the second list is executed; otherwise the list following the elif, if any, is executed with similar consequences. If all the lists following the if and elifs fail ( i.e., exit with non-zero status), the list following the else is executed. The exit status of an if statement is that of non-conditional list that is executed; if no non-conditional list is executed, the exit status is zero. select name [ in word ... term ] do list done where term is either a newline or a ;. The select statement provides an automatic method of presenting the user with a menu and selecting from it. An enumerated list of the specified words is printed on standard error, followed by a prompt ( PS3, normally ' #? '). A number corresponding to one of the enumerated words is then read from standard input, name is set to the selected word (or is unset if the selection is not valid), REPLY is set to what was read (leading\/trailing space is stripped), and list is executed. If a blank line ( i.e., zero or more IFS characters) is entered, the menu is re-printed without executing list. When list completes, the enumerated list is printed if REPLY is null, the prompt is printed and so on. This process is continues until an end-of-file is read, an interrupt is received or a break statement is executed inside the loop. If in word ... is omitted, the positional parameters are used ( i.e., \"$1\", \"$2\", etc.). For historical reasons, open and close braces may be used instead of do and done ( e.g., select i; { echo $i; }). The exit status of a select statement is zero if a break statement is used to exit the loop, non-zero otherwise. until list do list done This works like while, except that the body is executed only while the exit status of the first list is non-zero. while list do list done A while is a prechecked loop. Its body is executed as often as the exit status of the first list is zero. The exit status of a while statement is the last exit status of the list in the body of the loop; if the body is not executed, the exit status is zero. function name { list } Defines the function name. See Functions below. Note that redirections specified after a function definition are performed whenever the function is executed, not when the function definition is executed. name () command Mostly the same as function. See Functions below. time [ -p ] [ pipeline ] The time reserved word is described in the Command Execution section. (( expression )) The arithmetic expression expression is evaluated; equivalent to let \" expression \". See Arithmetic Expressions and the let command below. [[ expression ]] Similar to the test and [ ... ] commands (described later), with the following exceptions: \u2022 Field splitting and file name generation are not performed on arguments. \u2022 The -a (and) and -o (or) operators are replaced with && and ||, respectively. \u2022 Operators (e.g., -f, =, !, etc.) must be unquoted. \u2022 The second operand of != and = expressions are patterns (e.g., the comparison in [[ foobar = f*r ]] succeeds). \u2022 There are two additional binary operators: < and > which return true if their first string operand is less than, or greater than, their second string operand, respectively. \u2022 The single argument form of test, which tests if the argument has non-zero length, is not valid - explicit operators must be always be used, e.g., instead of [ str ] use [[ -n str ]] \u2022 Parameter, command and arithmetic substitutions are performed as expressions are evaluated and lazy expression evaluation is used for the && and || operators. This means that in the statement [[ -r foo && $(< foo) = b*r ]] the $(< foo) is evaluated if and only if the file foo exists and is readable. Quoting Quoting is used to prevent the shell from treating characters or words specially. There are three methods of quoting: First, \\ quotes the following character, unless it is at the end of a line, in which case both the \\ and the newline are stripped. Second, a single quote ( ') quotes everything up to the next single quote (this may span lines). Third, a double quote ( \") quotes all characters, except $, ' and \\, up to the next unquoted double quote. $ and ' inside double quotes have their usual meaning ( i.e., parameter, command or arithmetic substitution) except no field splitting is carried out on the results of double-quoted substitutions. If a \\ inside a double-quoted string is followed by \\, $, ' or \", it is replaced by the second character; if it is followed by a newline, both the \\ and the newline are stripped; otherwise, both the \\ and the character following are unchanged. Note: see POSIX Mode below for a special rule regarding sequences of the form \"...'...\\\"...'..\". Aliases There are two types of aliases: normal command aliases and tracked aliases. Command aliases are normally used as a short hand for a long or often used command. The shell expands command aliases ( i.e., substitutes the alias name for its value) when it reads the first word of a command. An expanded alias is re-processed to check for more aliases. If a command alias ends in a space or tab, the following word is also checked for alias expansion. The alias expansion process stops when a word that is not an alias is found, when a quoted word is found or when an alias word that is currently being expanded is found. The following command aliases are defined automatically by the shell: autoload='typeset -fu' functions='typeset -f' hash='alias -t' history='fc -l' integer='typeset -i' local='typeset' login='exec login' newgrp='exec newgrp' nohup='nohup ' r='fc -e -' stop='kill -STOP' suspend='kill -STOP $$' type='whence -v' Tracked aliases allow the shell to remember where it found a particular command. The first time the shell does a path search for a command that is marked as a tracked alias, it saves the full path of the command. The next time the command is executed, the shell checks the saved path to see that it is still valid, and if so, avoids repeating the path search. Tracked aliases can be listed and created using alias -t. Note that changing the PATH parameter clears the saved paths for all tracked aliases. If the trackall option is set ( i.e., set -o trackall or set -h), the shell tracks all commands. This option is set automatically for non-interactive shells. For interactive shells, only the following commands are automatically tracked: cat, cc, chmod, cp, date, ed, emacs, grep, ls, mail, make, mv, pr, rm, sed, sh, vi and who. Substitution The first step the shell takes in executing a simple-command is to perform substitutions on the words of the command. There are three kinds of substitution: parameter, command and arithmetic. Parameter substitutions, which are described in detail in the next section, take the form $name or ${... }; command substitutions take the form $( command ) or ' command '; and arithmetic substitutions take the form $(( expression )). If a substitution appears outside of double quotes, the results of the substitution are generally subject to word or field splitting according to the current value of the IFS parameter. The IFS parameter specifies a list of characters which are used to break a string up into several words; any characters from the set space, tab and newline that appear in the IFS characters are called IFS white space. Sequences of one or more IFS white space characters, in combination with zero or one non-IFS white space characters delimit a field. As a special case, leading and trailing IFS white space is stripped (i.e., no leading or trailing empty field is created by it); leading or trailing non-IFS white space does create an empty field. Example: if IFS is set to '<space>:', the sequence of characters '<space>A<space>:<space><space>B::D' contains four fields: 'A', 'B', '' and 'D'. Note that if the IFS parameter is set to the null string, no field splitting is done; if the parameter is unset, the default value of space, tab and newline is used. The results of substitution are, unless otherwise specified, also subject to brace expansion and file name expansion (see the relevant sections below). A command substitution is replaced by the output generated by the specified command, which is run in a subshell. For $(command) substitutions, normal quoting rules are used when command is parsed, however, for the 'command' form, a \\ followed by any of $, ' or \\ is stripped (a \\ followed by any other character is unchanged). As a special case in command substitutions, a command of the form < file is interpreted to mean substitute the contents of file ($(< foo) has the same effect as $(cat foo), but it is carried out more efficiently because no process is started). NOTE: $(command) expressions are currently parsed by finding the matching parenthesis, regardless of quoting. This will hopefully be fixed soon. Arithmetic substitutions are replaced by the value of the specified expression. For example, the command echo $((2+3*4)) prints 14. See Arithmetic Expressions for a description of an expression. Parameters Parameters are shell variables; they can be assigned values and their values can be accessed using a parameter substitution. A parameter name is either one of the special single punctuation or digit character parameters described below, or a letter followed by zero or more letters or digits ('_' counts as a letter). The later form can be treated as arrays by appending an array index of the form: [ expr ] where expr is an arithmetic expression. Array indicies are currently limited to the range 0 through 1023, inclusive. Parameter substitutions take the form $ name, ${ name } or ${ name [ expr ]}, where name is a parameter name. If substitution is performed on a parameter (or an array parameter element) that is not set, a null string is substituted unless the nounset option ( set -o nounset or set -u) is set, in which case an error occurs. Parameters can be assigned values in a number of ways. First, the shell implicitly sets some parameters like #, PWD, etc.; this is the only way the special single character parameters are set. Second, parameters are imported from the shell's environment at startup. Third, parameters can be assigned values on the command line, for example, 'FOO=bar' sets the parameter FOO to bar; multiple parameter assignments can be given on a single command line and they can be followed by a simple-command, in which case the assignments are in effect only for the duration of the command (such assignments are also exported, see below for implications of this). Note that both the parameter name and the = must be unquoted for the shell to recognize a parameter assignment. The fourth way of setting a parameter is with the export, readonly and typeset commands; see their descriptions in the Command Execution section. Fifth, for and select loops set parameters as well as the getopts, read and set -A commands. Lastly, parameters can be assigned values using assignment operators inside arithmetic expressions (see Arithmetic Expressions below) or using the ${name=value} form of parameter substitution (see below). Parameters with the export attribute (set using the export or typeset -x commands, or by parameter assignments followed by simple commands) are put in the environment (see environ(5)) of commands run by the shell as name=value pairs. The order in which parameters appear in the environment of a command is unspecified. When the shell starts up, it extracts parameters and their values from its environment and automatically sets the export attribute for those parameters. Modifiers can be applied to the ${name} form of parameter substitution: ${ name :- word } if name is set and not null, it is substituted, otherwise word is substituted. ${ name :+ word } if name is set and not null, word is substituted, otherwise nothing is substituted. ${ name := word } if name is set and not null, it is substituted, otherwise it is assigned word and the resulting value of name is substituted. ${ name :? word } if name is set and not null, it is substituted, otherwise word is printed on standard error (preceded by name:) and an error occurs (normally causing termination of a shell script, function or .-script). If word is omitted the string 'parameter null or not set' is used instead. In the above modifiers, the : can be omitted, in which case the conditions only depend on name being set (as opposed to set and not null). If word is needed, parameter, command, arithmetic and tilde substitution are performed on it; if word is not needed, it is not evaluated. The following forms of parameter substitution can also be used: ${# name } The number of positional parameters if name is *, @ or is not specified, or the length of the string value of parameter name. ${# name [*]}, ${# name [@]} The number of elements in the array name. ${ name # pattern }, ${ name ## pattern } If pattern matches the beginning of the value of parameter name, the matched text is deleted from the result of substitution. A single # results in the shortest match, two #'s results in the longest match. ${ name % pattern }, ${ name %% pattern } Like ${.. #.. } substitution, but it deletes from the end of the value. The following special parameters are implicitly set by the shell and cannot be set directly using assignments: ! Process id of the last background process started. If no background processes have been started, the parameter is not set. # The number of positional parameters (i.e., $1, $2, etc.). $ The process ID of the shell, or the PID of the original shell if it is a subshell. - The concatenation of the current single letter options (see set command below for list of options). ? The exit status of the last non-asynchronous command executed. If the last command was killed by a signal, $? is set to 128 plus the signal number. 0 The name the shell was invoked with (i.e., argv[0]), or the command-name if it was invoked with the -c option and the command-name was supplied, or the file argument, if it was supplied. If the posix option is not set, $0 is the name of the current function or script. 1 ... 9 The first nine positional parameters that were supplied to the shell, function or .-script. Further positional parameters may be accessed using ${ number }. * All positional parameters (except parameter 0), i.e., $1 $2 $3.... If used outside of double quotes, parameters are separate words (which are subjected to word splitting); if used within double quotes, parameters are separated by the first character of the IFS parameter (or the empty string if IFS is null). @ Same as $*, unless it is used inside double quotes, in which case a separate word is generated for each positional parameter - if there are no positional parameters, no word is generated (\"$@\" can be used to access arguments, verbatim, without loosing null arguments or splitting arguments with spaces). The following parameters are set and\/or used by the shell: _ (underscore) When an external command is executed by the shell, this parameter is set in the environment of the new process to the path of the executed command. In interactive use, this parameter is also set in the parent shell to the last word of the previous command. When MAILPATH messages are evaluated, this parameter contains the name of the file that changed (see MAILPATH parameter below). CDPATH Search path for the cd built-in command. Works the same way as PATH for those directories not beginning with \/ in cd commands. Note that if CDPATH is set and does not contain . nor an empty path, the current directory is not searched. COLUMNS Set to the number of columns on the terminal or window. Currently set to the cols value as reported by stty(1) if that value is non-zero. This parameter is used by the interactive line editing modes, and by select, set -o and kill -l commands to format information in columns. EDITOR If the VISUAL parameter is not set, this parameter controls the command line editing mode for interactive shells. See VISUAL parameter below for how this works. ENV If this parameter is found to be set after any profile files are executed, the expanded value is used as a shell start-up file. It typically contains function and alias definitions. ERRNO Integer value of the shell's errno variable - indicates the reason the last system call failed. Not implemented yet. EXECSHELL If set, this parameter is assumed to contain the shell that is to be used to execute commands that execve(2) fails to execute and which do not start with a ' #! shell' sequence. FCEDIT The editor used by the fc command (see below). FPATH Like PATH, but used when an undefined function is executed to locate the file defining the function. It is also searched when a command can't be found using PATH. See Functions below for more information. HISTFILE The name of the file used to store history. When assigned to, history is loaded from the specified file. Also, several invocations of the shell running on the same machine will share history if their HISTFILE parameters all point at the same file. NOTE: if HISTFILE isn't set, no history file is used. This is different from the original Korn shell, which uses $HOME\/.sh_history; in future, pdksh may also use a default history file. HISTSIZE The number of commands normally stored for history, default 128. HOME The default directory for the cd command and the value substituted for an unqualified ~ (see Tilde Expansion below). IFS Internal field separator, used during substitution and by the read command, to split values into distinct arguments; normally set to space, tab and newline. See Substitution above for details. Note: this parameter is not imported from the environment when the shell is started. KSH_VERSION The version of shell and the date the version was created (readonly). See also the version commands in Emacs Editing Mode and Vi Editing Mode sections, below. LINENO The line number of the function or shell script that is currently being executed. LINES Set to the number of lines on the terminal or window. Not implemented yet. MAIL If set, the user will be informed of the arrival of mail in the named file. This parameter is ignored if the MAILPATH parameter is set. MAILCHECK How often, in seconds, the shell will check for mail in the file(s) specified by MAIL or MAILPATH. If 0, the shell checks before each prompt. The default is 600 (10 minutes). MAILPATH A list of files to be checked for mail. The list is colon separated, and each file may be followed by a ? and a message to be printed if new mail has arrived. Command, parameter and arithmetic substitution is performed on the message, and, during substitution, the parameter $_ contains the name of the file. The default message is you have mail in $_. OLDPWD The previous working directory. Unset if cd has not successfully changed directories since the shell started, or if the shell doesn't know where it is. OPTARG When using getopts, it contains the argument for a parsed option, if it requires one. OPTIND The index of the last argument processed when using getopts. Assigning 1 to this parameter causes getopts to process arguments from the beginning the next time it is invoked. PATH A colon separated list of directories that are searched when looking for commands and .'d files. An empty string resulting from a leading or trailing colon, or two adjacent colons is treated as a '.', the current directory. POSIXLY_CORRECT If set, this parameter causes the posix option to be enabled. See POSIX Mode below. PPID The process ID of the shell's parent (readonly). PS1 PS1 is the primary prompt for interactive shells. Parameter, command and arithmetic substitutions are performed, and ! is replaced with the current command number (see fc command below). A literal ! can be put in the prompt by placing !! in PS1. Note that since the command line editors try to figure out how long the prompt is (so they know how far it is to edge of the screen), escape codes in the prompt tend to mess things up. You can tell the shell not to count certain sequences (such as escape codes) by prefixing your prompt with a non-printing character (such as control-A) followed by a carriage return and then delimiting the escape codes with this non-printing character. If you don't have any non-printing characters, you're out of luck... BTW, don't blame me for this hack; it's in the original ksh. Default is '$ ' for non-root users, '# ' for root.. PS2 Secondary prompt string, by default '> ', used when more input is needed to complete a command. PS3 Prompt used by select statement when reading a menu selection. Default is '#? '. PS4 Used to prefix commands that are printed during execution tracing (see set -x command below). Parameter, command and arithmetic substitutions are performed before it is printed. Default is '+ '. PWD The current working directory. Maybe unset or null if shell doesn't know where it is. RANDOM A simple random number generator. Every time RANDOM is referenced, it is assigned the next number in a random number series. The point in the series can be set by assigning a number to RANDOM (see rand(3)). REPLY Default parameter for the read command if no names are given. Also used in select loops to store the value that is read from standard input. SECONDS The number of seconds since the shell started or, if the parameter has been assigned an integer value, the number of seconds since the assignment plus the value that was assigned. TMOUT If set to a positive integer in an interactive shell, it specifies the maximum number of seconds the shell will wait for input after printing the primary prompt (PS1). If the time is exceeded, the shell exits. TMPDIR The directory shell temporary files are created in. If this parameter is not set, or does not contain the absolute path of a writable directory, temporary files are created in \/tmp. VISUAL If set, this parameter controls the command line editing mode for interactive shells. If the last component of the path specified in this parameter contains the string vi, emacs or gmacs, the vi, emacs or gmacs (Gosling emacs) editing mode is enabled, respectively. Tilde Expansion Tilde expansion, which is done in parallel with parameter substitution, is done on words starting with an unquoted ~. The characters following the tilde, up to the first \/, if any, are assumed to be a login name. If the login name is empty, + or -, the value of the HOME, PWD, or OLDPWD parameter is substituted, respectively. Otherwise, the password file is searched for the login name, and the tilde expression is substituted with the user's home directory. If the login name is not found in the password file or if any quoting or parameter substitution occurs in the login name, no substitution is performed. In parameter assignments (those preceding a simple-command or those occurring in the arguments of alias, export, readonly, and typeset), tilde expansion is done after any unquoted colon (:), and login names are also delimited by colons. The home directory of previously expanded login names are cached and re-used. The alias -d command may be used to list, change and add to this cache (e.g., 'alias -d fac=\/usr\/local\/facilities; cd ~fac\/bin'). Brace Expansion (alternation) Brace expressions, which take the form prefix { str1 ,... , strN } suffix are expanded to N words, each of which is the concatenation of prefix, stri and suffix ( e.g., 'a{c,b{X,Y},d}e' expands to four word: ace, abXe, abYe, and ade). As noted in the example, brace expressions can be nested and the resulting words are not sorted. Brace expressions must contain an unquoted comma ( ,) for expansion to occur ( i.e., {} and {foo} are not expanded). Brace expansion is carried out after parameter substitution and before file name generation. File Name Patterns A file name pattern is a word containing one or more unquoted ? or * characters or [.. ] sequences. Once brace expansion has been performed, the shell replaces file name patterns with the sorted names of all the files that match the pattern (if no files match, the word is left unchanged). The pattern elements have the following meaning: ? matches any single character. * matches any sequence of characters. [..] matches any of the characters inside the brackets. Ranges of characters can be specified by separating two characters by a -, e.g., [a0-9] matches the letter a or any digit. In order to represent itself, a - must either be quoted or the first or last character in the character list. Similarly, a ] must be quoted or the first character in the list if it is represent itself instead of the end of the list. Also, a ! appearing at the start of the list has special meaning (see below), so to represent itself it must be quoted or appear later in the list. [!..] like [..], except it matches any character not inside the brackets. *( pattern | ... | pattern ) matches any string of characters that matches zero or more occurances of the specified patterns. Example: the pattern *(foo|bar) matches the strings '', 'foo', 'bar', 'foobarfoo', etc.. +( pattern | ... | pattern ) matches any string of characters that matches one or more occurances of the specified patterns. Example: the pattern +(foo|bar) matches the strings 'foo', 'bar', 'foobarfoo', etc.. ?( pattern | ... | pattern ) matches the empty string or a string that matches one of the specified patterns. Example: the pattern ?(foo|bar) only matches the strings '', 'foo' and 'bar'. @( pattern | ... | pattern ) matches a string that matches one of the specified patterns. Example: the pattern @(foo|bar) only matches the strings 'foo' and 'bar'. !( pattern | ... | pattern ) matches any string that does not match one of the specified patterns. Examples: the pattern !(foo|bar) matches all strings except 'foo' and 'bar'; the pattern !(*) matches no strings; the pattern !(?)* matches all strings (think about it). Note that pdksh currently never matches . and .., but the original ksh, Bourne sh and bash do, so this may have to change (too bad). Note that none of the above pattern elements match either a period (.) at the start of a file name or a slash (\/), even if they are explicitly used in a [..] sequence; also, the names . and .. are never matched, even by the pattern .*. If the markdirs option is set, any directories that result from file name generation are marked with a trailing \/. The POSIX character classes (i.e., [:class-name:] inside a [..] expression) are not yet implemented. Input\/Output Redirection When a command is executed, its standard input, standard output and standard error (file descriptors 0, 1 and 2, respectively) are normally inherited from the shell. Three exceptions to this are commands in pipelines, for which standard input and\/or standard output are those set up by the pipeline, asynchronous commands created when job control is disabled, for which standard input is initially set to be from \/dev\/null, and commands for which any of the following redirections have been specified: > file standard output is redirected to file. If file does not exist, it is created; if it does exist, is a regular file and the noclobber option is set, an error occurs, otherwise the file is truncated. Note that this means the command cmd < foo > foo will open foo for reading and then truncate it when it opens it for writing, before cmd gets a chance to actually read foo. >| file same as >, except the file is truncated, even if the noclobber option is set. >> file same as >, except the file an existing file is appended to instead of being truncated. Also, the file is opened in append mode, so writes always go to the end of the file (see open(2)). < file standard input is redirected from file, which is opened for reading. <> file same as <, except the file is opened for reading and writing. << marker after reading the command line containing this kind of redirection (called a here document), the shell copies lines from the command source into a temporary file until a line matching marker is read. When the command is executed, standard input is redirected from the temporary file. If marker contains no quoted characters, the contents of the temporary file are processed as if enclosed in double quotes each time the command is executed, so parameter, command and arithmetic substitutions are performed, along with backslash ( \\) escapes for $, ', \\ and \\newline. If multiple here documents are used on the same command line, they are saved in order. <<- marker same as <<, except leading tabs are stripped from lines in the here document. <& fd standard input is duplicated from file descriptor fd. fd can be a single digit, indicating the number of an existing file descriptor, the letter p, indicating the file descriptor associated with the output of the current co-process, or the character -, indicating standard input is to be closed. >& fd same as <&, except the operation is done on standard output. In any of the above redirections, the file descriptor that is redirected ( i.e., standard input or standard output) can be explicitly given by preceding the redirection with a single digit. Parameter, command and arithmetic substitutions, tilde substitutions and (if the shell is interactive) file name generation are all performed on the file, marker and fd arguments of redirections. Note however, that the results of any file name generation are only used if a single file is matched; if multiple files match, the word with the unexpanded file name generation characters is used. Note that in restricted shells, redirections which can create files cannot be used. For simple-commands, redirections may appear anywhere in the command, for compound-commands (if statements, etc.), any redirections must appear at the end. Redirections are processed after pipelines are created and in the order they are given, so cat \/foo\/bar 2>&1 > \/dev\/null | cat -n will print an error with a line number prepended to it. Arithmetic Expressions Integer arithmetic expressions can be used with the let command, inside $((.. )) expressions, inside array references ( e.g., name [ expr ]), as numeric arguments to the test command, and as the value of an assignment to an integer parameter. Expression may contain alpha-numeric parameter identifiers, array references, and integer constants and may be combined with the following C operators (listed and grouped in increasing order of precedence). Unary operators: + - ! ~ ++ -- Binary operators: , = *= \/= %= += -= <<= >>= &= ^= |= || && | ^ & == != < <= >= > << >> + - * \/ % Ternary operator: ?: (precedence is immediately higher than assignment) Grouping operators: ( ) Integer constants may be specified with arbitrary bases using the notation base # number, where base is a decimal integer specifying the base, and number is a number in the specified base. The operators are evaluated as follows: unary + result is the argument (included for completeness). unary - negation. ! logical not; the result is 1 if argument is zero, 0 if not. ~ arithmetic (bit-wise) not. ++ increment; must be applied to a parameter (not a literal or other expression) - the parameter is incremented by 1. When used as a prefix operator, the result is the incremented value of the parameter, when used as a postfix operator, the result is the original value of the parameter. ++ similar to ++, except the paramter is decremented by 1. , separates two arithmetic expressions; the left hand side is evaluated first, then the right. The result is value of the expression on the right hand side. = assignment; variable on the left is set to the value on the right. *= \/= %= += -= <<= >>= &= ^= |= assignment operators; <var> <op>= <expr> is the same as <var> = <var> <op> ( <expr> ). || logical or; the result is 1 if either argument is non-zero, 0 if not. The right argument is evaluated only if the left argument is zero. && logical and; the result is 1 if both arguments are non-zero, 0 if not. The right argument is evaluated only if the left argument is non-zero. | arithmetic (bit-wise) or. ^ arithmetic (bit-wise) exclusive-or. & arithmetic (bit-wise) and. == equal; the result is 1 if both arguments are equal, 0 if not. != not equal; the result is 0 if both arguments are equal, 1 if not. < less than; the result is 1 if the left argument is less than the right, 0 if not. <= >= > less than or equal, greater than or equal, greater than. See <. << >> shift left (right); the result is the left argument with its bits shifted left (right) by the amount given in the right argument. + - * \/ addition, subtraction, multiplication, and division. % remainder; the result is the remainder of the division of the left argument by the right. The sign of the result is unspecified if either argument is negative. <arg1> ? <arg2> : <arg3> if <arg1> is non-zero, the result is <arg2>, otherwise <arg3>. Co-Processes A co-process, which is a pipeline created with the |& operator, is an asynchronous process that the shell can both write to (using print -p) and read from (using read -p). The input and output of the co-process can also be manipulated using >&p and <&p redirections, respectively. Once a co-process has been started, another can't be started until the co-process exits, or until the co-process input has been redirected using an exec n >&p redirection. If a co-process's input is redirected in this way, the next co-process to be started will share the output with the first co-process, unless the output of the initial co-process has been redirected using an exec n <&p redirection. Some notes concerning co-processes: \u2022 the only way to close the co-process input (so the co-process reads an end-of-file) is to redirect the input to a numbered file descriptor and then close that file descriptor ( e.g., exec 3>&p;exec 3>&-). \u2022 in order for co-processes to share a common output, the shell must keep the write portion of the output pipe open. This means that end of file will not be detected until all co-processes sharing the co-process output have exited (when they all exit, the shell closes its copy of the pipe). This can be avoided by redirecting the output to a numbered file descriptor (as this also causes the shell to close its copy). Note that this behaviour is slightly different from the original Korn shell which closes its copy of the write portion of the co-processs output when the most recently started co-process (instead of when all sharing co-processes) exits. \u2022 print -p will ignore SIGPIPE signals during writes if the signal is not being trapped or ignored; the same is not true if the co-process input has been duplicated to another file descriptor and print -un is used. Functions Functions are defined using either Korn shell function name syntax or the Bourne\/POSIX shell name () syntax (see below for the difference between the two forms). Functions are like .-scripts in that they are executed in the current environment, however, unlike .-scripts, shell arguments ( i.e., positional parameters, $1, etc.) are never visible inside them. When the shell is determining the location of a command, functions are searched after special built-in commands, and before regular and non-regular built-ins, and before the PATH is searched. An existing function may be deleted using unset -f function-name. A list of functions can be obtained using typeset +f and the function definitions can be listed using typeset -f. autoload (which is an alias for typeset -fu) may be used to create undefined functions; when an undefined function is executed, the shell searches the path specified in the FPATH parameter for a file with the same name as the function, which, if found is read and executed. If after executing the file, the named function is found to be defined, the function is executed, otherwise, the normal command search is continued (i.e., the shell searches the regular built-in command table and PATH). Note that if a command is not found using PATH, an attempt is made to autoload a function using FPATH (this is an undocumented feature of the original Korn shell). Functions can have two attributes, trace and export, which can be set with typeset -ft and typeset -fx, respectively. When a traced function is executed, the shell's xtrace option is turned on for the functions duration, otherwise the xtrace option is turned off. The export attribute of functions is currently not used. In the original Korn shell, exported functions are visible to shell scripts that are executed. Since functions are executed in the current shell environment, parameter assignments made inside functions are visible after the function completes. If this is not the desired effect, the typeset command can be used inside a function to create a local parameter. Note that special parameters (e.g., $$, $!) can't be scoped in this way. The exit status of a function is that of the last command executed in the function. A function can be made to finish immediately using the return command; this may also be used to explicitly specify the exit status. Functions defined with the function reserved word are treated differently in the following ways from functions defined with the () notation: \u2022 the $0 parameter is set to the name of the function (Bourne-style functions leave $0 untouched). \u2022 parameter assignments preceeding function calls are not kept in the shell environment (executing Bourne-style functions will keep assignments). \u2022 OPTIND is saved\/reset and restored on entry and exit from the function so getopts can be used properly both inside and outside the function (Bourne-style functions leave OPTIND untouched, so using getopts inside a function interferes with using getopts outside the function). In the future, the following differences will also be added: \u2022 A separate trap\/signal environment will be used during the execution of functions. This will mean that traps set inside a function will not affect the shell's traps and signals that are not ignored in the shell (but may be trapped) will have their default effect in a function. \u2022 The EXIT trap, if set in a function, will be executed after the function returns. POSIX Mode The shell is intended to be POSIX compliant, however, in some cases, POSIX behaviour is contrary either to the original Korn shell behaviour or to user convenience. How the shell behaves in these cases is determined by the state of the posix option ( set -o posix) - if it is on, the POSIX behaviour is followed, otherwise it is not. The posix option is set automatically when the shell starts up if the environment contains the POSIXLY_CORRECT parameter. (The shell can also be compiled so that it is in POSIX mode by default, however this is usually not desirable). The following is a list of things that are affected by the state of the posix option: \u2022 \\\" inside double quoted '.. ' command substitutions: in posix mode, the \\\" is interpreted when the command is interpreted; in non-posix mode, the backslash is stripped before the command substitution is interpreted. For example, echo \"'echo \\\"hi\\\"'\" produces '\"hi\"' in posix mode, 'hi' in non-posix mode. To avoid problems, use the $(...) form of command substitution. \u2022 kill -l output: in posix mode, signal names are listed one a single line; in non-posix mode, signal numbers, names and descriptions are printed in columns. In future, a new option (-v perhaps) will be added to distinguish the two behaviours. \u2022 fg exit status: in posix mode, the exit status is 0 if no errors occur; in non-posix mode, the exit status is that of the last foregrounded job. \u2022 eval exit status: if eval gets to see an empty command (e.g., eval \"'false'\"), its exit status in posix mode will be 0. In non-posix mode, it will be the exit status of the last command substitution that was done in the processing of the arguments to eval (or 0 if there were no command substitutions). \u2022 getopts: in posix mode, options must start with a -; in non-posix mode, options can start with either - or +. \u2022 brace expansion (also known as alternation): in posix mode, brace expansion is disabled; in non-posix mode, brace expansion enabled. Note that set -o posix (or setting the POSIXLY_CORRECT parameter) automatically turns the braceexpand option off, however it can be explicitly turned on later. \u2022 set -: in posix mode, this does not clear the verbose or xtrace options; in non-posix mode, it does. \u2022 set exit status: in posix mode, the exit status of set is 0 if there are no errors; in non-posix mode, the exit status is that of any command substitutions performed in generating the set command. For example, 'set -- 'false'; echo $?' prints 0 in posix mode, 1 in non-posix mode. This construct is used in most shell scripts that use the old getopt(1) command. \u2022 argument expansion of alias, export, readonly, and typeset commands: in posix mode, normal argument expansion done; in non-posix mode, field splitting, file globing, brace expansion and (normal) tilde expansion are turned off, and assignment tilde expansion is turned on. \u2022 signal specification: in posix mode, signals can be specified as digits only if signal numbers match POSIX values (i.e., HUP=1, INT=2, QUIT=3, ABRT=6, KILL=9, ALRM=14, and TERM=15); in non-posix mode, signals can be always digits. \u2022 alias expansion: in posix mode, alias expansion is only carried out when reading command words; in non-posix mode, alias expansion is carried out on any word following an alias that ended in a space. For example, the following for loop alias a='for ' i='j' a i in 1 2; do echo i=$i j=$j; done uses parameter i in posix mode, j in non-posix mode. \u2022 test: in posix mode, the expression \" -t\" (preceded by some number of \" !\" arguments) is always true as it is a non-zero length string; in non-posix mode, it tests if file descriptor 1 is a tty ( i.e., the fd argument to the -t test may be left out and defaults to 1). Command Execution After evaluation of command line arguments, redirections and parameter assignments, the type of command is determined: a special built-in, a function, a regular built-in or the name of a file to execute found using the PATH parameter. The checks are made in the above order. Special built-in commands differ from other commands in that the PATH parameter is not used to find them, an error during their execution can cause a non-interactive shell to exit and parameter assignments that are specified before the command are kept after the command completes. Just to confuse things, if the posix option is turned off (see set command below) some special commands are very special in that no field splitting, file globing, brace expansion nor tilde expansion is preformed on arguments that look like assignments. Regular built-in commands are different only in that the PATH parameter is not used to find them. The original ksh and POSIX differ somewhat in which commands are considered special or regular: POSIX special commands Additional ksh special commands Very special commands (non-posix mode) POSIX regular commands Additional ksh regular commands In the future, the additional ksh special and regular commands may be treated differently from the POSIX special and regular commands. Once the type of the command has been determined, any command line parameter assignments are performed and exported for the duration of the command. The following describes the special and regular built-in commands: . file [ arg1 ...] Execute the commands in file in the current environment. The file is searched for in the directories of PATH. If arguments are given, the positional parameters may be used to access them while file is being executed. If no arguments are given, the positional parameters are those of the environment the command is used in. : [ ... ] The null command. Exit status is set to zero. alias [ -d | t [ -r] ] [ px] [ ] [ name1[ = value1] ...] Without arguments, alias lists all aliases. For any name without a value, the existing alias is listed. Any name with a value defines an alias (see Aliases above). When listing aliases, one of two formats is used: normally, aliases are listed as name=value, where value is quoted; if options were preceded with + or a lone + is given on the command line, only name is printed. In addition, if the -p option is used, each alias is prefixed with the string \"alias \". The -x option sets (+x clears) the export attribute of an alias, or, if no names are given, lists the aliases with the export attribute (exporting an alias has no affect). The -t option indicates that tracked aliases are to be listed\/set (values specified on the command line are ignored for tracked aliases). The -r option indicates that all tracked aliases are to be reset. The -d causes directory aliases, which are used in tilde expansion, to be listed or set (see Tilde Expansion above). bg [ job ...] Resume the specified stopped job(s) in the background. If no jobs are specified, %+ is assumed. This command is only available on systems which support job control. See Job Control below for more information. bind [ -m] [ key[ = editing-command] ...] Set or view the current emacs command editing key bindings\/macros. See Emacs Editing Mode below for a complete description. break [ level] break exits the levelth inner most for, select, until, or while loop. level defaults to 1. builtin command [ arg1 ...] Execute the built-in command command. cd [ -LP] [ dir] Set the working directory to dir. If the parameter CDPATH is set, it lists directories to search in for dir. dir. An empty entry in the CDPATH entry means the current directory. If a non-empty directory from CDPATH is used, the resulting full path is printed to standard output. If dir is missing, the home directory $HOME is used. If dir is -, the previous working directory is used (see OLDPWD parameter). If -L option (logical path) is used or if the physical option (see set command below) isn't set, references to .. in dir are relative to the path used get to the directory. If -P option (physical path) is used or if the physical option is set, .. is relative to the filesystem directory tree. The PWD and OLDPWD parameters are updated to reflect the current and old wording directory, respectively. cd [ -LP] old new The string new is substituted for old in the current directory, and the shell attempts to change to the new directory. command [ -pvV] cmd [ arg1 ...] If neither the -v nor -V options are given, cmd is executed exactly as if the command had not been specified, with two exceptions: first, cmd cannot be a shell function, and second, special built-in commands lose their specialness ( i.e., redirection and utility errors do not cause the shell to exit, and command assignments are not permanent). If the -p option is given, a default search path is used instead of the current value of PATH (the actual value of the default path is system dependent: on POSIXish systems, it is the value returned by getconf CS_PATH ). If the -v option is given, instead of executing cmd, information about what would be executed is given (and the same is done for arg1 ...): for special and regular built-in commands and functions, their names are simply printed, for aliases, a command that defines them is printed, and for commands found by searching the PATH parameter, the full path of the command is printed. If no command is be found, (i.e., the path search fails), nothing is printed and command exits with a non-zero status. The -V option is like the -v option, except it is more verbose. continue [ levels] continue jumps to the beginning of the levelth inner most for, select, until, or while loop. level defaults to 1. echo [ -neE] [ arg ...] Prints its arguments (separated by spaces) followed by a newline, to standard out. The newline is suppressed if any of the arguments contain the backslash sequence \\c. See print command below for a list of other backslash sequences that are recognized. The options are provided for compatibility with BSD shell scripts: -n suppresses the trailing newline, -e enables backslash interpretation (a no-op, since this is normally done), and -E which suppresses backslash interpretation. eval command ... The arguments are concatenated (with spaces between them) to form a single string which the shell then parses and executes in the current environment. exec [ command [ arg ...]] The command is executed without forking, replacing the shell process. If no arguments are given, any IO redirection is permanent and the shell is not replaced. Any file descriptors greater than 2 which are opened or dup(2)-ed in this way are not made available to other executed commands (i.e., commands that are not built-in to the shell). Note that the Bourne shell differs here: it does pass these file descriptors on. exit [ status] The shell exits with the specified exit status. If status is not specified, the exit status is the current value of the ? parameter. export [ -p] [ parameter[ = value]] ... Sets the export attribute of the named parameters. Exported parameters are passed in the environment to executed commands. If values are specified, the named parameters also assigned. If no parameters are specified, the names of all parameters with the export attribute are printed one per line, unless the -p option is used, in which case export commands defining all exported parameters, including their values, are printed. false A command that exits with a non-zero status. fc [ -e editor | -l [ -n]] [ -r] [ first [ last]] first and last select commands from the history. Commands can be selected by history number, or a string specifying the most recent command starting with that string. The -l option lists the command on stdout, and -n inhibits the default command numbers. The -r option reverses the order of the list. Without -l, the selected commands are edited by the editor specified with the -e option, or if no -e is specified, the editor specified by the FCEDIT parameter (if this parameter is not set, \/bin\/ed is used), and then executed by the shell. fc [ -e - | -s] [ -g] [ old = new] [ prefix] Re-execute the selected command (the previous command by default) after performing the optional substitution of old with new. If -g is specified, all occurrences of old are replaced with new. This command is usually accessed with the predefined alias r='fc -e -'. fg [ job ...] Resume the specified job(s) in the foreground. If no jobs are specified, %+ is assumed. This command is only available on systems which support job control. See Job Control below for more information. getopts optstring name [ arg ...] getopts is used by shell procedures to parse the specified arguments (or positional parameters, if no arguments are given) and to check for legal options. optstring contains the option letters that getopts is to recognize. If a letter is followed by a colon, the option is expected to have an argument. Options that do not take arguments may be grouped in a single argument. If an option takes an argument and the option character is not the last character of the argument it is found in, the remainder of the argument is taken to be the option's argument, otherwise, the next argument is the option's argument. Each time getopts is invoked, it places the next option in the shell parameter name and the index of the next argument to be processed in the shell parameter OPTIND. If the option was introduced with a +, the option placed in name is prefixed with a +. When an option requires an argument, getopts places it in the shell parameter OPTARG. When an illegal option or a missing option argument is encountered a question mark or a colon is placed in name (indicating an illegal option or missing argument, respectively) and OPTARG is set to the option character that caused the problem. An error message is also printed to standard error if optstring does not begin with a colon. When the end of the options is encountered, getopts exits with a non-zero exit status. Options end at the first (non-option argument) argument that does not start with a -, or when a -- argument is encountered. Option parsing can be reset by setting OPTIND to 1 (this is done automatically whenever the shell or a shell procedure is invoked). Warning: Changing the value of the shell parameter OPTIND to a value other than 1, or parsing different sets of arguments without resetting OPTIND may lead to unexpected results. hash [ -r] [ name ...] Without arguments, any hashed executable command pathnames are listed. The -r option causes all hashed commands to be removed from the hash table. Each name is searched as if it where a command name and added to the hash table if it is an executable command. jobs [ -lpn] [ job ...] Display information about the specified jobs; if no jobs are specified, all jobs are displayed. The -n option causes information to be displayed only for jobs that have changed state since the last notification. If the -l option is used, the process-id of each process in a job is also listed. The -p option causes only the process group of each job to be printed. See Job Control below for the format of job and the displayed job. kill [ -s signame | -signum | -signame ] { job | pid | - pgrp } ... Send the specified signal to the specified jobs, process ids, or process groups. If no signal is specified, the signal TERM is sent. If a job is specified, the signal is sent to the job's process group. See Job Control below for the format of job. kill -l [ exit-status ...] Print the name of the signal that killed a process which exited with the specified exit-statuses. If no arguments are specified, a list of all the signals, their numbers and a short description of them are printed. let [ expression ...] Each expression is evaluated, see Arithmetic Expressions above. If all expressions are successfully evaluated, the exit status is 0 (1) if the last expression evaluated to non-zero (zero). If an error occurs during the parsing or evaluation of an expression, the exit status is greater than 1. Since expressions may need to be quoted, (( expr )) is syntactic sugar for let \" expr \". print [ -nprsu n | -R [ -en]] [ argument ...] Print prints its arguments on the standard output, separated by spaces, and terminated with a newline. The -n option suppresses the newline. By default, certain C escapes are translated. These include \\b, \\f, \\n, \\r, \\t, \\v, and \\0### (# is an octal digit, of which there may be 0 to 3). \\c is equivalent to using the -n option. \\ expansion may be inhibited with the -r option. The -s option prints to the history file instead of standard output, the -u option prints to file descriptor n ( n defaults to 1 if omitted), and the -p option prints to the co-process (see Co-Processes above). The -R option is used to emulate, to some degree, the BSD echo command, which does not process \\ sequences unless the -e option is given. As above, the -n option suppresses the trailing newline. pwd [ -LP] Print the present working directory. If -L option is used or if the physical option (see set command below) isn't set, the logical path is printed ( i.e., the path used to cd to the current directory). If -P option (physical path) is used or if the physical option is set, the path determined from the filesystem (by following .. directories to the root directory) is printed. read [ -prsu n] [ parameter ...] Reads a line of input from standard input, separate the line into fields using the IFS parameter (see Substitution above), and assign each field to the specified parameters. If there are more parameters than fields, the extra parameters are set to null, or alternatively, if there are more fields than parameters, the last parameter is assigned the remaining fields (inclusive of any separating spaces). If no parameters are specified, the REPLY parameter is used. If the input line ends in a backslash and the -r option was not used, the backslash and newline are stripped and more input is read. If no input is read, read exits with a non-zero status. The first parameter may have a question mark and a string appended to it, in which case the string is used as a prompt (printed to standard error before any input is read) if the input is a tty (e.g., read nfoo?'number of foos: '). The -un and -p options cause input to be read from file descriptor n or the current co-process (see Co-Processes above for comments on this), respectively. If the -s option is used, input is saved to the history file. readonly [ -p] [ parameter[ = value]] ... Sets the readonly attribute of the named parameters. If values are given, parameters are set to them before setting the attribute. Once a parameter is made readonly, it cannot be unset and its value cannot be changed. If no parameters are specified, the names of all parameters with the readonly attribute are printed one per line, unless the -p option is used, in which case readonly commands defining all readonly parameters, including their values, are printed. return [ status] Returns from a function or . script, with exit status status. If no status is given, the exit status of the last executed command is used. If used outside of a function or . script, it has the same effect as exit. Note that pdksh treats both profile and $ENV files as . scripts, while the original Korn shell only treats profiles as . scripts. set [ abCefhkmnpsuvxX] [ o [ option]] [ A name] [ --] [ arg ...] The set command can be used to set ( -) or clear ( +) shell options, set the positional parameters, or set an array parameter. Options can be changed using the o option syntax, where option is the long name of an option, or using the  letter syntax, where letter is the option's single letter name (not all options have a single letter name). The following table lists both option letters (if they exist) and long names along with a description of what the option does. These options can also be used upon invocation of the shell. The current set of options (with single letter names) can be found in the parameter -. set -o with no option name will list all the options and whether each is on or off; set +o will print the long names of all options that are currently on. Remaining arguments, if any, are positional parameters and are assigned, in order, to the positional parameters (i.e., 1, 2, etc.). If options are ended with -- and there are no remaining arguments, all positional parameters are cleared. If no options or arguments are given, then the values of all names are printed. For unknown historical reasons, a lone - option is treated specially: it clears both the -x and -v options. shift [ number] The positional parameters number+1, number+2 etc. are renamed to 1, 2, etc. number defaults to 1. test expression [ expression ] test evaluates the expression and returns zero status if true, and 1 status if false and greater than 1 if there was an error. It is normally used as the condition command of if and while statements. The following basic expressions are available: The above basic expressions, in which unary operators have precedence over binary operators, may be combined with the following operators (listed in increasing order of precedence): On operating systems not supporting \/dev\/fd\/ n devices (where n is a file descriptor number), the test command will attempt to fake it for all tests that operate on files (except the -e test). I.e., [ -w \/dev\/fd\/2 ] tests if file descriptor 2 is writable. Note that some special rules are applied (courtesy of POSIX) if the number of arguments to test or [ ... ] is less than five: if leading ! arguments can be stripped such that only one argument remains then a string length test is performed (again, even if the argument is a unary operator); if leading ! arguments can be stripped such that three arguments remain and the second argument is a binary operator, then the binary operation is performed (even if first argument is a unary operator, including an unstripped !). Note: A common mistake is to use if [ $foo = bar ] which fails if parameter foo is null or unset, if it has embedded spaces (i.e., IFS characters), or if it is a unary operator like ! or -n. Use tests like if [ \"X$foo\" = Xbar ] instead. time [ -p] [ pipeline ] If a pipeline is given, the times used to execute the pipeline are reported. If no pipeline is given, then the user and system time used by the shell itself, and all the commands it has run since it was started, are reported. The times reported are the real time (elapsed time from start to finish), the user cpu time (time spent running in user mode) and the system cpu time (time spent running in kernel mode). Times are reported to standard error; the format of the output is: 0.00s real     0.00s user     0.00s system unless the -p option is given (only possible if pipeline is a simple command), in which case the output is slightly longer: real   0.00\nuser   0.00\nsys    0.00 (the number of digits after the decimal may vary from system to system). Note that simple redirections of standard error do not effect the output of the time command: time sleep 1 2> afile { time sleep 1; } 2> afile times for the first command do not go to afile, but those of the second command do. times Print the accumulated user and system times used by the shell and by processes which have exited that the shell started. trap [ handler signal ...] Sets trap handler that is to be executed when any of the specified signals are received. Handler is either a null string, indicating the signals are to be ignored, a minus ( -), indicating that the default action is to be taken for the signals (see signal(2 or 3)), or a string containing shell commands to be evaluated and executed at the first opportunity ( i.e., when the current command completes, or before printing the next PS1 prompt) after receipt of one of the signals. Signal is the name of a signal ( e.g., PIPE or ALRM) or the number of the signal (see kill -l command above). There are two special signals: EXIT (also known as 0), which is executed when the shell is about to exit, and ERR which is executed after an error occurs (an error is something that would cause the shell to exit if the -e or errexit option were set - see set command above). EXIT handlers are executed in the environment of the last executed command. Note that for non-interactive shells, the trap handler cannot be changed for signals that were ignored when the shell started. With no arguments, trap lists, as a series of trap commands, the current state of the traps that have been set since the shell started. Note that the output of trap can not be usefully piped to another process (an artifact of the fact that traps are cleared when subprocesses are created). The original Korn shell's DEBUG trap and the handling of ERR and EXIT traps in functions are not yet implemented. true A command that exits with a zero value. typeset [[Ulprtux] [ -L[ n]] [ -R[ n]] [ -Z[ n]] [ -i[ n]] | -f [ -tux]] [ name[ = value] ...] Display or set parameter attributes. With no name arguments, parameter attributes are displayed: if no options arg used, the current attributes of all parameters are printed as typeset commands; if an option is given (or - with no option letter) all parameters and their values with the specified attributes are printed; if options are introduced with +, parameter values are not printed. If name arguments are given, the attributes of the named parameters are set (-) or cleared (+). Values for parameters may optionally be specified. If typeset is used inside a function, any newly created parameters are local to the function. When -f is used, typeset operates on the attributes of functions. As with parameters, if no names are given, functions are listed with their values (i.e., definitions) unless options are introduced with +, in which case only the function names are reported. ulimit [ -acdfHlmnpsStvw] [ value] Display or set process limits. If no options are used, the file size limit (-f) is assumed. value, if specified, may be either be an arithmetic expression or the word unlimited. The limits affect the shell and any processes created by the shell after a limit is imposed. Note that some systems may not allow limits to be increased once they are set. Also note that the types of limits available are system dependent - some systems have only the -f limit. -a Displays all limits; unless -H is used, soft limits are displayed. -H Set the hard limit only (default is to set both hard and soft limits). -S Set the soft limit only (default is to set both hard and soft limits). -c Impose a size limit of n blocks on the size of core dumps. -d Impose a size limit of n kbytes on the size of the data area. -f Impose a size limit of n blocks on files written by the shell and its child processes (files of any size may be read). -l Impose a limit of n kbytes on the amount of locked (wired) physical memory. -m Impose a limit of n kbytes on the amount of physical memory used. -n Impose a limit of n file descriptors that can be open at once. -p Impose a limit of n processes that can be run by the user at any one time. -s Impose a size limit of n kbytes on the size of the stack area. -t Impose a time limit of n cpu seconds to be used by each process. -v Impose a limit of n kbytes on the amount of virtual memory used; on some systems this is the maximum allowable virtual address (in bytes, not kbytes). -w Impose a limit of n kbytes on the amount of swap space used. As far as ulimit is concerned, a block is 512 bytes. umask [ -S] [ mask] Display or set the file permission creation mask, or umask (see umask(2)). If the -S option is used, the mask displayed or set is symbolic, otherwise it is an octal number. Symbolic masks are like those used by chmod(1): [ugoa]{{=+-}{rwx}*}+[,...] in which the first group of characters is the who part, the second group is the op part, and the last group is the perm part. The who part specifies which part of the umask is to be modified. The letters mean: u the user permissions g the group permissions o the other permissions (non-user, non-group) a all permissions (user, group and other) The op part indicates how the who permissions are to be modified: = set + added to - removed from The perm part specifies which permissions are to be set, added or removed: r read permission w write permission x execute permission When symbolic masks are used, they describe what permissions may be made available (as opposed to octal masks in which a set bit means the corresponding bit is to be cleared). Example: 'ug=rwx,o=' sets the mask so files will not be readable, writable or executable by 'others', and is equivalent (on most systems) to the octal mask '07'. unalias [ -adt] [ name1 ...] The aliases for the given names are removed. If the -a option is used, all aliases are removed. If the -t or -d options are used, the indicated operations are carried out on tracked or directory aliases, respectively. unset [ -fv] parameter ... Unset the named parameters ( -v, the default) or functions ( -f). The exit status is non-zero if any of the parameters were already unset, zero otherwise. wait [ job] Wait for the specified job(s) to finish. The exit status of wait is that of the last specified job: if the last job is killed by a signal, the exit status is 128 + the number of the signal (see kill -l exit-status above); if the last specified job can't be found (because it never existed, or had already finished), the exit status of wait is 127. See Job Control below for the format of job. Wait will return if a signal for which a trap has been set is received, or if a HUP, INT or QUIT signal is received. If no jobs are specified, wait waits for all currently running jobs (if any) to finish and exits with a zero status. If job monitoring is enabled, the completion status of jobs is printed (this is not the case when jobs are explicitly specified). whence [ -pv] [name ...] For each name, the type of command is listed (reserved word, built-in, alias, function, tracked alias or executable). If the -p option is used, a path search done even if name is a reserved word, alias, etc. Without the -v option, whence is similar to command -v except that whence will find reserved words and won't print aliases as alias commands; with the -v option, whence is the same as command -V. Note that for whence, the -p option does not affect the search path used, as it does for command. If the type of one or more of the names could not be determined, the exit status is non-zero. Job Control Job control refers to the shell's ability to monitor and control jobs, which are processes or groups of processes created for commands or pipelines. At a minimum, the shell keeps track of the status of the background ( i.e., asynchronous) jobs that currently exist; this information can be displayed using the jobs command. If job control is fully enabled (using set -m or set -o monitor), as it is for interactive shells, the processes of a job are placed in their own process group, foreground jobs can be stopped by typing the suspend character from the terminal (normally ^Z), jobs can be restarted in either the foreground or background, using the fg and bg commands, respectively, and the state of the terminal is saved or restored when a foreground job is stopped or restarted, respectively. Note that only commands that create processes (e.g., asynchronous commands, subshell commands, and non-built-in, non-function commands) can be stopped; commands like read cannot be. When a job is created, it is assigned a job-number. For interactive shells, this number is printed inside [..], followed by the process-ids of the processes in the job when an asynchronous command is run. A job may be referred to in bg, fg, jobs, kill and wait commands either by the process id of the last process in the command pipeline (as stored in the $! parameter) or by prefixing the job-number with a percent sign (%). Other percent sequences can also be used to refer to jobs: When a job changes state ( e.g., a background job finishes or foreground job is stopped), the shell prints the following status information: [ number ] flag status command where number is the job-number of the job. flag is + or - if the job is the %+ or %- job, respectively, or space if it is neither. status indicates the current state of the job and can be Running the job has neither stopped or exited (note that running does not necessarily mean consuming CPU time - the process could be blocked waiting for some event). Done [ ( number )] the job exited. number is the exit status of the job, which is omitted if the status is zero. Stopped [ ( signal )] the job was stopped by the indicated signal (if no signal is given, the job was stopped by SIGTSTP). signal-description [ (core dumped)] the job was killed by a signal (e.g., Memory fault, Hangup, etc. - use kill -l for a list of signal descriptions). The (core dumped) message indicates the process created a core file. command is the command that created the process. If there are multiple processes in the job, then each process will have a line showing its command and possibly its status, if it is different from the status of the previous process. When an attempt is made to exit the shell while there are jobs in the stopped state, the shell warns the user that there are stopped jobs and does not exit. If another attempt is immediately made to exit the shell, the stopped jobs are sent a HUP signal and the shell exits. Similarly, if the nohup option is not set and there are running jobs when an attempt is made to exit a login shell, the shell warns the user and does not exit. If another attempt is immediately made to exit the shell, the running jobs are sent a HUP signal and the shell exits. Interactive Input Line Editing The shell supports three modes of reading command lines from a tty in an interactive session. Which is used is controlled by the emacs, gmacs and vi set options (at most one of these can be set at once). If none of these options is enabled, the shell simply reads lines using the normal tty driver. If the emacs or gmacs option is set, the shell allows emacs like editing of the command; similarly, if the vi option is set, the shell allows vi like editing of the command. These modes are described in detail in the following sections. In these editing modes, if a line is longer that the screen width (see COLUMNS parameter), a >, + or < character is displayed in the last column indicating that there are more characters after, before and after, or before the current position, respectively. The line is scrolled horizontally as necessary. Emacs Editing Mode When the emacs option is set, interactive input line editing is enabled. Warning: This mode is slightly different from the emacs mode in the original Korn shell and the 8th bit is stripped in emacs mode. In this mode various editing commands (typically bound to one or more control characters) cause immediate actions without waiting for a new-line. Several editing commands are bound to particular control characters when the shell is invoked; these bindings can be changed using the following commands: bind The current bindings are listed. bind string =[ editing-command] The specified editing command is bound to the given string, which should consist of a control character (which may be written using caret notation ^ X), optionally preceded by one of the two prefix characters. Future input of the string will cause the editing command to be immediately invoked. Note that although only two prefix characters (usually ESC and ^X) are supported, some multi-character sequences can be supported. The following binds the arrow keys on an ANSI terminal, or xterm (these are in the default bindings). Of course some escape sequences won't work out quite this nicely: bind '^[['=prefix-2 bind '^XA'=up-history bind '^XB'=down-history bind '^XC'=forward-char bind '^XD'=backward-char bind -l Lists the names of the functions to which keys may be bound. bind -m string =[ substitute] The specified input string will afterwards be immediately replaced by the given substitute string, which may contain editing commands. The following is a list of editing commands available. Each description starts with the name of the command, a n, if the command can be prefixed with a count, and any keys the command is bound to by default (written using caret notation, e.g., ASCII ESC character is written as ^[). A count prefix for a command is entered using the sequence ^[ n, where n is a sequence of 1 or more digits; unless otherwise specified, if a count is omitted, it defaults to 1. Note that editing command names are used only with the bind command. Furthermore, many editing commands are useful only on terminals with a visible cursor. The default bindings were chosen to resemble corresponding EMACS key bindings. The users tty characters ( e.g., ERASE) are bound to reasonable substitutes and override the default bindings. abort ^G Useful as a response to a request for a search-history pattern in order to abort the search. auto-insert n Simply causes the character to appear as literal input. Most ordinary characters are bound to this. backward-char n ^B Moves the cursor backward n characters. backward-word n ^[B Moves the cursor backward to the beginning of a word; words consist of alphanumerics, underscore (_) and dollar ($). beginning-of-history ^[< Moves to the beginning of the history. beginning-of-line ^A Moves the cursor to the beginning of the edited input line. capitalize-word n ^[c, ^[C Uppercase the first character in the next n words, leaving the cursor past the end of the last word. If the current line does not begin with a comment character, one is added at the beginning of the line and the line is entered (as if return had been pressed), otherwise the existing comment characters are removed and the cursor is placed at the beginning of the line. complete ^[^[ Automatically completes as much as is unique of the command name or the file name containing the cursor. If the entire remaining command or file name is unique a space is printed after its completion, unless it is a directory name in which case \/ is appended. If there is no command or file name with the current partial word as its prefix, a bell character is output (usually causing a audio beep). complete-command ^X^[ Automatically completes as much as is unique of the command name having the partial word up to the cursor as its prefix, as in the complete command described above. complete-file ^[^X Automatically completes as much as is unique of the file name having the partial word up to the cursor as its prefix, as in the complete command described above. complete-list ^[= List the possible completions for the current word. delete-char-backward n ERASE, ^?, ^H Deletes n characters before the cursor. delete-char-forward n Deletes n characters after the cursor. delete-word-backward n ^[ERASE, ^[^?, ^[^H, ^[h Deletes n words before the cursor. delete-word-forward n ^[d Deletes characters after the cursor up to the end of n words. down-history n ^N Scrolls the history buffer forward n lines (later). Each input line originally starts just after the last entry in the history buffer, so down-history is not useful until either search-history or up-history has been performed. downcase-word n ^[L, ^[l Lowercases the next n words. end-of-history ^[> Moves to the end of the history. end-of-line ^E Moves the cursor to the end of the input line. eot ^_ Acts as an end-of-file; this is useful because edit-mode input disables normal terminal input canonicalization. eot-or-delete n ^D Acts as eot if alone on a line; otherwise acts as delete-char-forward. error Error (ring the bell). exchange-point-and-mark ^X^X Places the cursor where the mark is, and sets the mark to where the cursor was. expand-file ^[* Appends a * to the current word and replaces the word with the result of performing file globbing on the word. If no files match the pattern, the bell is rung. forward-char n ^F Moves the cursor forward n characters. forward-word n ^[f Moves the cursor forward to the end of the nth word. goto-history n ^[g Goes to history number n. kill-line KILL Deletes the entire input line. kill-region ^W Deletes the input between the cursor and the mark. kill-to-eol n ^K Deletes the input from the cursor to the end of the line if n is not specified, otherwise deletes characters between the cursor and column n. list ^[? Prints a sorted, columnated list of command names or file names (if any) that can complete the partial word containing the cursor. Directory names have \/ appended to them. list-command ^X? Prints a sorted, columnated list of command names (if any) that can complete the partial word containing the cursor. list-file ^X^Y Prints a sorted, columnated list of file names (if any) that can complete the partial word containing the cursor. File type indicators are appended as described under list above. newline ^J, ^M Causes the current input line to be processed by the shell. The current cursor position may be anywhere on the line. newline-and-next ^O Causes the current input line to be processed by the shell, and the next line from history becomes the current line. This is only useful after an up-history or search-history. no-op QUIT This does nothing. prefix-1 ^[ Introduces a 2-character command sequence. prefix-2 ^X prefix-2 ^[[ Introduces a 2-character command sequence. prev-hist-word n ^[., ^[_ The last ( nth) word of the previous command is inserted at the cursor. quote ^^ The following character is taken literally rather than as an editing command. redraw ^L Reprints the prompt string and the current input line. search-character-backward n ^[^] Search backward in the current line for the nth occurance of the next character typed. search-character-forward n ^] Search forward in the current line for the nth occurance of the next character typed. search-history ^R Enter incremental search mode. The internal history list is searched backwards for commands matching the input. An initial ^ in the search string anchors the search. The abort key will leave search mode. Other commands will be executed after leaving search mode. Successive search-history commands continue searching backward to the next previous occurrence of the pattern. The history buffer retains only a finite number of lines; the oldest are discarded as necessary. set-mark-command ^[<space> Set the mark at the cursor position. stuff On systems supporting it, pushes the bound character back onto the terminal input where it may receive special processing by the terminal handler. This is useful for the BRL ^T mini-systat feature, for example. stuff-reset Acts like stuff, then aborts input the same as an interrupt. transpose-chars ^T If at the end of line, or if the gmacs option is set, this exchanges the two previous characters; otherwise, it exchanges the previous and current characters and moves the cursor one character to the right. up-history n ^P Scrolls the history buffer backward n lines (earlier). upcase-word n ^[U, ^[u Uppercases the next n words. version ^V Display the version of ksh. The current edit buffer is restored as soon as any key is pressed (the key is then processed, unless it is a space). yank ^Y Inserts the most recently killed text string at the current cursor position. yank-pop ^[y Immediately after a yank, replaces the inserted text string with the next previous killed text string. Vi Editing Mode The vi command line editor in ksh has basically the same commands as the vi editor (see vi(1)), with the following exceptions: \u2022 you start out in insert mode, \u2022 there are file name and command completion commands (=, \\, *, ^X, ^E, ^F and, optionally, <tab>), \u2022 the _ command is different (in ksh it is the last argument command, in vi it goes to the start of the current line), \u2022 the \/ and G commands move in the opposite direction as the j command \u2022 and commands which don't make sense in a single line editor are not available (e.g., screen movement commands, ex : commands, etc.). Note that the ^X stands for control-X; also <esc>, <space> and <tab> are used for escape, space and tab, respectively (no kidding). Like vi, there are two modes: insert mode and command mode. In insert mode, most characters are simply put in the buffer at the current cursor position as they are typed, however, some characters are treated specially. In particular, the following characters are taken from current tty settings (see stty(1)) and have their usual meaning (normal values are in parentheses): kill (^U), erase (^?), werase (^W), eof (^D), intr (^C) and quit (^\\). In addition to the above, the following characters are also treated specially in insert mode: In command mode, each character is interpreted as a command. Characters that don't correspond to commands, are illegal combinations of commands or are commands that can't be carried out all cause beeps. In the following command descriptions, a n indicates the command may be prefixed by a number ( e.g., 10l moves right 10 characters); if no number prefix is used, n is assumed to be 1 unless otherwise specified. The term 'current position' refers to the position between the cursor and the character preceding the cursor. A 'word' is a sequence of letters, digits and underscore characters or a sequence of non-letter, non-digit, non-underscore, non-white-space characters ( e.g., ab2*&^ contains two words) and a 'big-word' is a sequence of non-white-space characters. Special ksh vi commands The following commands are not in, or are different from, the normal vi file editor: n _ insert a space followed by the nth big-word from the last command in the history at the current position and enter insert mode; if n is not specified, the last word is inserted. # insert the comment character (#) at the start of the current line and return the line to the shell (equivalent to I#^J). ng like G, except if n is not specified, it goes to the most recent remembered line. nv edit line n using the vi editor; if n is not specified, the current line is edited. The actual command executed is 'fc -e ${VISUAL:-${EDITOR:-vi}} n'. * and ^X command or file name expansion is applied to the current big-word (with an appended *, if the word contains no file globing characters) - the big-word is replaced with the resulting words. If the current big-word is the first on the line (or follows one of the following characters: ;, |, &, (, )) and does not contain a slash (\/) then command expansion is done, otherwise file name expansion is done. Command expansion will match the big-word against all aliases, functions and built-in commands as well as any executable files found by searching the directories in the PATH parameter. File name expansion matches the big-word against the files in the current directory. After expansion, the cursor is placed just past the last word and the editor is in insert mode. n \\, n ^F, n <tab> and n <esc> command\/file name completion: replace the current big-word with the longest unique match obtained after performing command\/file name expansion. <tab> is only recognized if the vi-tabcomplete option is set, while <esc> is only recognized if the vi-esccomplete option is set (see set -o). If n is specified, the nth possible completion is selected (as reported by the command\/file name enumeration command). = and ^E command\/file name enumeration: list all the commands or files that match the current big-word. ^V display the version of pdksh; it is displayed until another key is pressed (this key is ignored). @c macro expansion: execute the commands found in the alias _c. Intra-line movement commands n h and n ^H move left n characters. n l and n <space> move right n characters. 0 move to column 0. ^ move to the first non white-space character. n| move to column n. $ move to the last character. nb move back n words. nB move back n big-words. ne move forward to the end the word, n times. nE move forward to the end the big-word, n times. nw move forward n words. nW move forward n big-words. % find match: the editor looks forward for the nearest parenthesis, bracket or brace and then moves the to the matching parenthesis, bracket or brace. nfc move forward to the nth occurrence of the character c. nFc move backward to the nth occurrence of the character c. ntc move forward to just before the nth occurrence of the character c. nTc move backward to just before the nth occurrence of the character c. n; repeats the last f, F, t or T command. n, repeats the last f, F, t or T command, but moves in the opposite direction. Inter-line movement commands n j and n + and n ^N move to the nth next line in the history. n k and n - and n ^P move to the nth previous line in the history. n G move to line n in the history; if n is not specified, the number first remembered line is used. ng like G, except if n is not specified, it goes to the most recent remembered line. n \/ string search backward through the history for the nth line containing string; if string starts with ^, the remainder of the string must appear at the start of the history line for it to match. n ? string same as \/, except it searches forward through the history. n n search for the nth occurrence of the last search string; the direction of the search is the same as the last search. nN search for the nth occurrence of the last search string; the direction of the search is the opposite of the last search. Edit commands n a append text n times: goes into insert mode just after the current position. The append is only replicated if command mode is re-entered (i.e., <esc> is used). nA same as a, except it appends at the end of the line. ni insert text n times: goes into insert mode at the current position. The insertion is only replicated if command mode is re-entered (i.e., <esc> is used). nI same as i, except the insertion is done just before the first non-blank character. ns substitute the next n characters (i.e., delete the characters and go into insert mode). S substitute whole line: all characters from the first non-blank character to the end of line are deleted and insert mode is entered. n c move-cmd change from the current position to the position resulting from n move-cmds (i.e., delete the indicated region and go into insert mode); if move-cmd is c, the line starting from the first non-blank character is changed. C change from the current position to the end of the line (i.e., delete to the end of the line and go into insert mode). nx delete the next n characters. nX delete the previous n characters. D delete to the end of the line. n d move-cmd delete from the current position to the position resulting from n move-cmds; move-cmd is a movement command (see above) or d, in which case the current line is deleted. n r c replace the next n characters with the character c. nR replace: enter insert mode but overwrite existing characters instead of inserting before existing characters. The replacement is repeated n times. n~ change the case of the next n characters. n y move-cmd yank from the current position to the position resulting from n move-cmds into the yank buffer; if move-cmd is y, the whole line is yanked. Y yank from the current position to the end of the line. np paste the contents of the yank buffer just after the current position, n times. nP same as p, except the buffer is pasted at the current position. Miscellaneous vi commands ^J and ^M the current line is read, parsed and executed by the shell. ^L and ^R redraw the current line. n . redo the last edit command n times. u undo the last edit command. U undo all changes that have been made to the current line. intr and quit the interrupt and quit terminal characters cause the current line to be deleted and a new prompt to be printed.","Process Name":"pdksh","Link":"https:\/\/linux.die.net\/man\/1\/pdksh"}},{"Process":{"Description":"Perl Data Language ( PDL ) is a perl extension that is designed for scientific and bulk numeric data processing and display. It extends perl's syntax and includes fully vectorized, multidimensional array handling, plus several paths for device-independent graphics output. \"pdl\" is an interactive command shell that is supplied with PDL ; for more information, see perldl(1). Because PDL is a modular extension to perl, it is accessible to ordinary perl scripts: to write a command-line PDL script you just say \"use PDL ;\" at the top of an ordinary perl script. There is also a specialized interactive shell (perldl(1)) that allows you to issue PDL commands interactively and that includes a path-based subroutine autoloader similar to those found in MatLab and IDL (which are trademarks of MathWorks and Kodak, respectively). The perldl shell allows you to quickly manipulate and \"play with\" your data. (You can also invoke it with the shorter command \"pdl\"). The \"PDL\" module is a complete Object-Oriented extension to Perl (although you don't have to know what an object is to use it) which allows large N-dimensional data sets, such as large images, spectra, time series, etc to be stored efficiently and manipulated en masse. For example with the PDL module we can write the perl code \"$a=$b+$c\", where $b and $c are large datasets (e.g. 2048x2048 images), and get the result in only a fraction of a second. PDL variables (or piddles as they have come to be known) support a wide range of fundamental data types - arrays can be bytes, short integers (signed or unsigned), long integers, floats or double precision floats. And because of the Object-Oriented nature of PDL new customised datatypes can be derived from them. Perl is an extremely good and versatile scripting language, well suited to beginners, and allows rapid prototyping. The PDL extensions to the language use Perl's object-oriented capabilities to seamlessly add high-speed scientific capabilities that are themselves written in perl, C and\/or FORTRAN as appropriate -- so your code's \"hot spots\" run at native compiled-language speed, while you work in the higher level perl language (which itself runs faster than many other JIT-compiled or interpreted languages). External modules that have been incorporated into PDL include the complete Gnu Scientific Library; CFITSIO for FITS file handling; FFTW ; the Slatec matrix-handling package; and the PGPLOT , PLPLOT , Karma, and OpenGL graphics libraries. Ancillary packages written in PDL itself include image handling, curve fitting, matrix manipulation, coordinate transformation, nonlinear data resampling, graphics I\/O, and extensive file I\/O utilities. Because PDL programs are \"just\" perl with additional modules loaded, the entire CPAN archive is also available to your PDL scripts.","Process Name":"pdl","Link":"https:\/\/linux.die.net\/man\/1\/pdl"}},{"Process":{"Description":"The \"pdl2\" program, also known as the Perldl2 shell, is a second generation version of the original \"perldl\" interactive PDL shell. It attempts to be backward compatible in usage while providing improved features, better support for Perl syntax, and an more easily extended framework based on the Devel::REPL shell. If you have Devel::REPL version 1.003011 or later, then \"pdl2\" will start with full functionality. If Devel::REPL is not installed or found then \"pdl2\" will print a warning and run the legacy \"perldl\" shell command instead. By default, command lines beginning with the default prompt of either \"pdl2\" or \"perldl\" (one of 'pdl> ', ' PDL > ', or 'perldl> ') will have the prefix string and surrounding whitespace stripped. This allows for easy cut-and-paste from sample PDL shell sessions or other examples into another PDL shell session.","Process Name":"pdl2","Link":"https:\/\/linux.die.net\/man\/1\/pdl2"}},{"Process":{"Description":"The aim of pdldoc is to provide the same functionality as the \"apropos\", \"help\", \"sig\", \"badinfo\", and \"usage\" commands available in the perldl shell. Think of it as the PDL equivalent of \"perldoc -f\".","Process Name":"pdldoc","Link":"https:\/\/linux.die.net\/man\/1\/pdldoc"}},{"Process":{"Description":"pdns_recursor(1) is a high performance, simple and secure recursing nameserver. It currently powers over two million internet connections. The recursor is configured via a configuration file, but each item in that file can be overridden on the command line. This manpage lists the core set of features needed to get the PowerDNS recursor working, for full and up to date details head to http:\/\/doc.powerdns.com\/built-in-recursor.html","Process Name":"pdns_recursor","Link":"https:\/\/linux.die.net\/man\/1\/pdns_recursor"}},{"Process":{"Description":"pdsh is a variant of the rsh(1) command. Unlike rsh(1), which runs commands on a single remote host, pdsh can run multiple remote commands in parallel. pdsh uses a \"sliding window\" (or fanout) of threads to conserve resources on the initiating host while allowing some connections to time out. When pdsh receives SIGINT (ctrl-C), it lists the status of current threads. A second SIGINT within one second terminates the program. Pending threads may be canceled by issuing ctrl-Z within one second of ctrl-C. Pending threads are those that have not yet been initiated, or are still in the process of connecting to the remote host. If a remote command is not specified on the command line, pdsh runs interactively, prompting for commands and executing them when terminated with a carriage return. In interactive mode, target nodes that time out on the first command are not contacted for subsequent commands, and commands prefixed with an exclamation point will be executed on the local system. The core functionality of pdsh may be supplemented by dynamically loadable modules. The modules may provide a new connection protocol (replacing the standard rcmd(3) protocol used by rsh(1)), filtering options (e.g. removing hosts that are \"down\" from the target list), and\/or host selection options (e.g., -a selects all hosts from a configuration file.). By default, pdsh must have at least one \"rcmd\" module loaded. See the RCMD MODULES section for more information.","Process Name":"pdsh","Link":"https:\/\/linux.die.net\/man\/1\/pdsh"}},{"Process":{"Description":"THIS MAN PAGE IS OBSOLETE! See the Texinfo documentation instead. You can read it either in Emacs or with the standalone info program which comes with the GNU texinfo distribution as prep.ai.mit.edu:pub\/gnu\/texinfo*.tar.gz. The program dvips takes a DVI file file[.dvi] produced by TeX (or by some other processor such as GFtoDVI) and converts it to PostScript, normally sending the result directly to the (laser)printer. The DVI file may be specified without the .dvi extension. Fonts used may either be resident in the printer or defined as bitmaps in PK files, or a 'virtual' combination of both. If the mktexpk program is installed, dvips will automatically invoke METAFONT to generate fonts that don't already exist. For more information, see the Texinfo manual dvips.texi, which should be installed somewhere on your system, hopefully accessible through the standard Info tree.","Process Name":"pdvips","Link":"https:\/\/linux.die.net\/man\/1\/pdvips"}},{"Process":{"Description":"The pedal program displays pretty geometric pictures.","Process Name":"pedal","Link":"https:\/\/linux.die.net\/man\/1\/pedal"}},{"Process":{"Description":"pee is like tee but for pipes. Each command is run and fed a copy of the standard input. The output of all commands is sent to stdout. Note that while this is similar to tee, a copy of the input is not sent to stdout, like tee does.","Process Name":"pee","Link":"https:\/\/linux.die.net\/man\/1\/pee"}},{"Process":{"Description":"peekfd attaches to a running process and intercepts all reads and writes to file descriptors. You can specify the desired file descriptor numbers or dump all of them.","Process Name":"peekfd","Link":"https:\/\/linux.die.net\/man\/1\/peekfd"}},{"Process":{"Description":"Pekwm is a tabbed window manager which focuses on being highly configurable. Pekwm has a rich feature set including: * Autoproperties, set properties and group windows automatically based on type or title. * Keychains, multi-level keybindings. * XRandR and Xinerama support. For more information about the pekwm project and for full documentation, visit http:\/\/www.pekwm.org.","Process Name":"pekwm","Link":"https:\/\/linux.die.net\/man\/1\/pekwm"}},{"Process":{"Description":"Pen is a load balancer for tcp based protocols such as http or smtp. It allows several servers to appear as one to the outside and automatically detects servers that are down and distributes clients among the available servers. This gives high availability and scalable performance. The load balancing algorithm keeps track of clients and will try to send them back to the server they visited the last time. The client table has a number of slots (default 2048, settable through command-line arguments). When the table is full, the least recently used one will be thrown out to make room for the new one. This is superior to a simple round-robin algorithm, which sends a client that connects repeatedly to different servers. Doing so breaks applications that maintain state between connections in the server, including most modern web applications. When pen detects that a server is unavailable, it scans for another starting with the server after the most recently used one. That way we get load balancing and \"fair\" failover for free. Correctly configured, pen can ensure that a server farm is always available, even when individual servers are brought down for maintenance or reconfiguration. The final single point of failure, pen itself, can be eliminated by running pen on several servers, using vrrp to decide which is active. Sending pen a USR1 signal will make it print some useful statistics on stderr, even if debugging is disabled. If pen is running in the background (i.e. without the -f option), syslog is used rather than stderr. If the -w option is used, the statistics is saved in HTML format in the given file. Sending pen a HUP signal will make it close and reopen the logfile, if logging is enabled, and reload the configuration file. Rotate the log like this (assuming pen.log is the name of the logfile): mv pen.log pen.log.1 kill -HUP 'cat <pidfile>' where <pidfile> is the file containing pen's process id, as written by the -p option. Sending pen a TERM signal will make it exit cleanly, closing the log file and all open sockets.","Process Name":"pen","Link":"https:\/\/linux.die.net\/man\/1\/pen"}},{"Process":{"Description":"Penctl connects to the optional control socket on a pen load balancer. It reads commands from the command line, performs minimal syntax checking and sends them to pen. Replies, if any, are printed on stdout. The program can also be used through the cgi script penctl.cgi, which allows pen to be controlled from any web browser.","Process Name":"penctl","Link":"https:\/\/linux.die.net\/man\/1\/penctl"}},{"Process":{"Description":"Penetrate simulates the arcade classic with the cities and the stuff shooting down from the sky and stuff. The computer plays against itself, desperately defending the forces of good against those thingies raining down. Bonus cities are awarded at ever-increasing intervals. Every five levels appears a bonus round. The computer player gets progressively more intelligent as the game progresses. Better aim, more economical with ammo, and better target selection. Points are in the bottom right, and high score is in the bottom left. Start with -smart to have the computer player skip the learning process.","Process Name":"penetrate","Link":"https:\/\/linux.die.net\/man\/1\/penetrate"}},{"Process":{"Description":"Penlog reads webserver log entries from stdin and sends them using UDP to penlogd. It is intended for Apache's \"reliable piped logs\". To use penlog from Apache, add a command like this to the web server's httpd.conf: CustomLog \"|\/usr\/local\/bin\/penlog somehost 10000\" common The optional third argument is used if the server has several addresses. Penlogd uses the source address to identify the server, and it must be identical to the address configured in the command line to Pen.","Process Name":"penlog","Link":"https:\/\/linux.die.net\/man\/1\/penlog"}},{"Process":{"Description":"Penlogd receives log entries from Pen and from each of the web servers. It consolidates the entries by replacing the source addresses in each entry with the \"real\" client address and writes the result to stdout or to the file given on the command line. This completely removes the need for postprocessing with mergelogs, since the logs are already merged. Pen must be instructed to send its log to penlogd. See HOWTO and pen man page for details. Sending penlogd a HUP signal will make it close and reopen the logfile, unless it is logging to stdout. Rotate the log like this: mv access_log access_log.1 kill -HUP 'cat <pidfile>' where <pidfile> is the file containing pen's process id. Sending penlogd a TERM signal will make it close the log file and exit cleanly.","Process Name":"penlogd","Link":"https:\/\/linux.die.net\/man\/1\/penlogd"}},{"Process":{"Description":"The penrose program draws quasiperiodic tilings. See Onoda, Steinhardt, DiVincenzo and Socolar in Phys. Rev. Lett. 60, #25, 1988 or Strandburg in Computers in Physics, Sep\/Oct 1991. This implementation uses the simpler version of the growth algorithm, i.e., if there are no forced vertices, a randomly chosen tile is added to a randomly chosen vertex (no preference for those 108 degree angles). There are two essential differences to the algorithm presented in the literature: First, we do not allow the tiling to enclose an untiled area. Whenever this is in danger of happening, we just do not add the tile, hoping for a better random choice the next time. Second, when choosing a vertex randomly, we will take one that lies withing the viewport if available. If this seems to cause enclosures in the forced rule case, we will allow invisible vertices to be chosen. Tiling is restarted whenever one of the following happens: there are no incomplete vertices within the viewport or the tiling has extended a window's length beyond the edge of the window horizontally or vertically or forced rule choice has failed 100 times due to areas about to become enclosed. Although quasiperiodic tilings are produced, the tiles themselves are not penrose tiles (darts and kites). In contrast to penrose tiles, these tiles can be arranged to form a periodic tiling.","Process Name":"penrose","Link":"https:\/\/linux.die.net\/man\/1\/penrose"}},{"Process":{"Description":"Performance counters for Linux are a new kernel-based subsystem that provide a framework for all things performance analysis. It covers hardware level (CPU\/PMU, Performance Monitoring Unit) features and software features (software counters, tracepoints) as well.","Process Name":"perf","Link":"https:\/\/linux.die.net\/man\/1\/perf"}},{"Process":{"Description":"This command reads the input file and displays an annotated version of the code. If the object file has debug symbols then the source code will be displayed alongside assembly code. If there is no debug info in the object, then annotated assembly is displayed.","Process Name":"perf-annotate","Link":"https:\/\/linux.die.net\/man\/1\/perf-annotate"}},{"Process":{"Description":"This command runs runs perf-buildid-list --with-hits, and collects the files with the buildids found so that analisys of perf.data contents can be possible on another machine.","Process Name":"perf-archive","Link":"https:\/\/linux.die.net\/man\/1\/perf-archive"}},{"Process":{"Description":"This perf bench command is a general framework for benchmark suites.","Process Name":"perf-bench","Link":"https:\/\/linux.die.net\/man\/1\/perf-bench"}},{"Process":{"Description":"This command manages the build-id cache. It can add and remove files to\/from the cache. In the future it should as well purge older entries, set upper limits for the space used by the cache, etc.","Process Name":"perf-buildid-cache","Link":"https:\/\/linux.die.net\/man\/1\/perf-buildid-cache"}},{"Process":{"Description":"This command displays the buildids found in a perf.data file, so that other tools can be used to fetch packages with matching symbol tables for use by perf report. It can also be used to show the build id of the running kernel or in an ELF file using -i\/--input.","Process Name":"perf-buildid-list","Link":"https:\/\/linux.die.net\/man\/1\/perf-buildid-list"}},{"Process":{"Description":"This command displays the performance difference amongst two perf.data files captured via perf record. If no parameters are passed it will assume perf.data.old and perf.data.","Process Name":"perf-diff","Link":"https:\/\/linux.die.net\/man\/1\/perf-diff"}},{"Process":{"Description":"This command displays the names of events sampled in a perf.data file.","Process Name":"perf-evlist","Link":"https:\/\/linux.die.net\/man\/1\/perf-evlist"}},{"Process":{"Description":"With no options and no COMMAND given, the synopsis of the perf command and a list of the most commonly used perf commands are printed on the standard output. If the option --all or -a is given, then all available commands are printed on the standard output. If a perf command is named, a manual page for that command is brought up. The man program is used by default for this purpose, but this can be overridden by other options or configuration variables. Note that perf --help ... is identical to perf help ... because the former is internally converted into the latter.","Process Name":"perf-help","Link":"https:\/\/linux.die.net\/man\/1\/perf-help"}},{"Process":{"Description":"perf-inject reads a perf-record event stream and repipes it to stdout. At any point the processing code can inject other events into the event stream - in this case build-ids (-b option) are read and injected as needed into the event stream. Build-ids are just the first user of perf-inject - potentially anything that needs userspace processing to augment the events stream with additional information could make use of this facility.","Process Name":"perf-inject","Link":"https:\/\/linux.die.net\/man\/1\/perf-inject"}},{"Process":{"Description":"There are two variants of perf kmem: 'perf kmem record <command>' to record the kmem events\nof an arbitrary workload. 'perf kmem stat' to report kernel memory statistics.","Process Name":"perf-kmem","Link":"https:\/\/linux.die.net\/man\/1\/perf-kmem"}},{"Process":{"Description":"There are a couple of variants of perf kvm: 'perf kvm [options] top <command>' to generates and displays\na performance counter profile of guest os in realtime\nof an arbitrary workload. 'perf kvm record <command>' to record the performance counter profile\nof an arbitrary workload and save it into a perf data file. If both\n--host and --guest are input, the perf data file name is perf.data.kvm.\nIf there is  no --host but --guest, the file name is perf.data.guest.\nIf there is no --guest but --host, the file name is perf.data.host. 'perf kvm report' to display the performance counter profile information\nrecorded via perf kvm record. 'perf kvm diff' to displays the performance difference amongst two perf.data\nfiles captured via perf record. 'perf kvm buildid-list' to  display the buildids found in a perf data file,\nso that other tools can be used to fetch packages with matching symbol tables\nfor use by perf report.","Process Name":"perf-kvm","Link":"https:\/\/linux.die.net\/man\/1\/perf-kvm"}},{"Process":{"Description":"This command displays the symbolic event types which can be selected in the various perf commands with the -e option.","Process Name":"perf-list","Link":"https:\/\/linux.die.net\/man\/1\/perf-list"}},{"Process":{"Description":"You can analyze various lock behaviours and statistics with this perf lock command. 'perf lock record <command>' records lock events\nbetween start and end <command>. And this command\nproduces the file \"perf.data\" which contains tracing\nresults of lock events. 'perf lock report' reports statistical data. 'perf lock script' shows raw lock events. 'perf lock info' shows metadata like threads or addresses\nof lock instances.","Process Name":"perf-lock","Link":"https:\/\/linux.die.net\/man\/1\/perf-lock"}},{"Process":{"Description":"This command defines dynamic tracepoint events, by symbol and registers without debuginfo, or by C expressions (C line numbers, C function names, and C local variables) with debuginfo.","Process Name":"perf-probe","Link":"https:\/\/linux.die.net\/man\/1\/perf-probe"}},{"Process":{"Description":"This command runs a command and gathers a performance counter profile from it, into perf.data - without displaying anything. This file can then be inspected later on, using perf report.","Process Name":"perf-record","Link":"https:\/\/linux.die.net\/man\/1\/perf-record"}},{"Process":{"Description":"This command displays the performance counter profile information recorded via perf record.","Process Name":"perf-report","Link":"https:\/\/linux.die.net\/man\/1\/perf-report"}},{"Process":{"Description":"There are five variants of perf sched: 'perf sched record <command>' to record the scheduling events\nof an arbitrary workload. 'perf sched latency' to report the per task scheduling latencies\nand other scheduling properties of the workload. 'perf sched script' to see a detailed trace of the workload that\n was recorded (aliased to 'perf script' for now). 'perf sched replay' to simulate the workload that was recorded\nvia perf sched record. (this is done by starting up mockup threads\nthat mimic the workload based on the events in the trace. These\nthreads can then replay the timings (CPU runtime and sleep patterns)\nof the workload as it occurred when it was recorded - and can repeat\nit a number of times, measuring its performance.) 'perf sched map' to print a textual context-switching outline of\nworkload captured via perf sched record.  Columns stand for\nindividual CPUs, and the two-letter shortcuts stand for tasks that\nare running on a CPU. A '*' denotes the CPU that had the event, and\na dot signals an idle CPU.","Process Name":"perf-sched","Link":"https:\/\/linux.die.net\/man\/1\/perf-sched"}},{"Process":{"Description":"This command reads the input file and displays the trace recorded. There are several variants of perf script: 'perf script' to see a detailed trace of the workload that was\nrecorded. You can also run a set of pre-canned scripts that aggregate and\nsummarize the raw trace data in various ways (the list of scripts is\navailable via 'perf script -l').  The following variants allow you to\nrecord and run those scripts: 'perf script record <script> <command>' to record the events required\nfor 'perf script report'.  <script> is the name displayed in the\noutput of 'perf script --list' i.e. the actual script name minus any\nlanguage extension.  If <command> is not specified, the events are\nrecorded using the -a (system-wide) 'perf record' option. 'perf script report <script> [args]' to run and display the results\nof <script>.  <script> is the name displayed in the output of 'perf\ntrace --list' i.e. the actual script name minus any language\nextension.  The perf.data output from a previous run of 'perf script\nrecord <script>' is used and should be present for this command to\nsucceed.  [args] refers to the (mainly optional) args expected by\nthe script. 'perf script <script> <required-script-args> <command>' to both\nrecord the events required for <script> and to run the <script>\nusing 'live-mode' i.e. without writing anything to disk.  <script>\nis the name displayed in the output of 'perf script --list' i.e. the\nactual script name minus any language extension.  If <command> is\nnot specified, the events are recorded using the -a (system-wide)\n'perf record' option.  If <script> has any required args, they\nshould be specified before <command>.  This mode doesn't allow for\noptional script args to be specified; if optional script args are\ndesired, they can be specified using separate 'perf script record'\nand 'perf script report' commands, with the stdout of the record step\npiped to the stdin of the report script, using the '-o -' and '-i -'\noptions of the corresponding commands. 'perf script <top-script>' to both record the events required for\n<top-script> and to run the <top-script> using 'live-mode'\ni.e. without writing anything to disk.  <top-script> is the name\ndisplayed in the output of 'perf script --list' i.e. the actual\nscript name minus any language extension; a <top-script> is defined\nas any script name ending with the string 'top'. [<record-options>] can be passed to the record steps of 'perf script\nrecord' and 'live-mode' variants; this isn't possible however for\n<top-script> 'live-mode' or 'perf script report' variants. See the 'SEE ALSO' section for links to language-specific\ninformation on how to write and run your own trace scripts.","Process Name":"perf-script","Link":"https:\/\/linux.die.net\/man\/1\/perf-script"}},{"Process":{"Description":"This perf script option is used to process perf script data using perf's built-in Perl interpreter. It reads and processes the input file and displays the results of the trace analysis implemented in the given Perl script, if any.","Process Name":"perf-script-perl","Link":"https:\/\/linux.die.net\/man\/1\/perf-script-perl"}},{"Process":{"Description":"This perf script option is used to process perf script data using perf's built-in Python interpreter. It reads and processes the input file and displays the results of the trace analysis implemented in the given Python script, if any.","Process Name":"perf-script-python","Link":"https:\/\/linux.die.net\/man\/1\/perf-script-python"}},{"Process":{"Description":"This command runs a command and gathers performance counter statistics from it.","Process Name":"perf-stat","Link":"https:\/\/linux.die.net\/man\/1\/perf-stat"}},{"Process":{"Description":"This command does assorted sanity tests, initially through linked routines but also will look for a directory with more tests in the form of scripts. To get a list of available tests use perf test list, specifying a test name fragment will show all tests that have it. To run just specific tests, inform test name fragments or the numbers obtained from perf test list.","Process Name":"perf-test","Link":"https:\/\/linux.die.net\/man\/1\/perf-test"}},{"Process":{"Description":"There are two variants of perf timechart: 'perf timechart record <command>' to record the system level events\nof an arbitrary workload. 'perf timechart' to turn a trace into a Scalable Vector Graphics file,\nthat can be viewed with popular SVG viewers such as 'Inkscape'.","Process Name":"perf-timechart","Link":"https:\/\/linux.die.net\/man\/1\/perf-timechart"}},{"Process":{"Description":"This command generates and displays a performance counter profile in real time.","Process Name":"perf-top","Link":"https:\/\/linux.die.net\/man\/1\/perf-top"}},{"Process":{"Description":"With the perftest command we can test an ARC1 service performance","Process Name":"perftest","Link":"https:\/\/linux.die.net\/man\/1\/perftest"}},{"Process":{"Description":"Perl is a language optimized for scanning arbitrary text files, extracting information from those text files, and printing reports based on that information. It's also a good language for many system management tasks. The language is intended to be practical (easy to use, efficient, complete) rather than beautiful (tiny, elegant, minimal). Perl combines (in the author's opinion, anyway) some of the best features of C, sed, awk, and sh, so people familiar with those languages should have little difficulty with it. (Language historians will also note some vestiges of csh, Pascal, and even BASIC-PLUS.) Expression syntax corresponds closely to C expression syntax. Unlike most Unix utilities, Perl does not arbitrarily limit the size of your data--if you've got the memory, Perl can slurp in your whole file as a single string. Recursion is of unlimited depth. And the tables used by hashes (sometimes called \"associative arrays\") grow as necessary to prevent degraded performance. Perl can use sophisticated pattern matching techniques to scan large amounts of data quickly. Although optimized for scanning text, Perl can also deal with binary data, and can make dbm files look like hashes. Setuid Perl scripts are safer than C programs through a dataflow tracing mechanism that prevents many stupid security holes. If you have a problem that would ordinarily use sed or awk or sh, but it exceeds their capabilities or must run a little faster, and you don't want to write the silly thing in C, then Perl may be for you. There are also translators to turn your sed and awk scripts into Perl scripts. But wait, there's more... Begun in 1993 (see perlhist), Perl version 5 is nearly a complete rewrite that provides the following additional benefits: \u2022 modularity and reusability using innumerable modules Described in perlmod, perlmodlib, and perlmodinstall. \u2022 embeddable and extensible Described in perlembed, perlxstut, perlxs, perlcall, perlguts, and xsubpp. \u2022 roll-your-own magic variables (including multiple simultaneous DBM implementations) Described in perltie and AnyDBM_File. \u2022 subroutines can now be overridden, autoloaded, and prototyped Described in perlsub. \u2022 arbitrarily nested data structures and anonymous functions Described in perlreftut, perlref, perldsc, and perllol. \u2022 object-oriented programming Described in perlobj, perlboot, perltoot, perltooc, and perlbot. \u2022 support for light-weight processes (threads) Described in perlthrtut and threads. \u2022 support for Unicode, internationalization, and localization Described in perluniintro, perllocale and Locale::Maketext. \u2022 lexical scoping Described in perlsub. \u2022 regular expression enhancements Described in perlre, with additional examples in perlop. \u2022 enhanced debugger and interactive Perl environment, with integrated editor support Described in perldebtut, perldebug and perldebguts. \u2022 POSIX 1003.1 compliant library Described in POSIX . Okay, that's definitely enough hype.","Process Name":"perl","Link":"https:\/\/linux.die.net\/man\/1\/perl"}},{"Process":{"Description":"This script calculates conventional name for each Perl source file specified on a command line, based on its location relative to standard Perl library paths; alternatively, a list of files is obtained from standard input, one file per line. *.pm, *.pl, and *.ph files are processed (*.pm files also suffer version extraction). The output of perl.prov is suitable for automatic dependency tracking (e.g. for RPM packaging). For example, \/usr\/lib\/perl5\/i386-linux\/DB_File.pm provides \"perl(DB_File.pm) = 1.810\" (as of perl-5.8.6). perl.prov is a counterpart of perl.req.","Process Name":"perl.prov","Link":"https:\/\/linux.die.net\/man\/1\/perl.prov"}},{"Process":{"Description":"","Process Name":"perl.prov.files","Link":"https:\/\/linux.die.net\/man\/1\/perl.prov.files"}},{"Process":{"Description":"perl.req calculates prerequisites for each Perl source file specified on a command line; alternatively, a list of files is obtained from standard input, one file per line. \"use\", \"require\" and \"do\" statements are processed. The output of perl.req is suitable for automatic dependency tracking (e.g. for RPM packaging). For example, \/usr\/lib\/perl5\/File\/Temp.pm requires, in particular, \"perl(Fcntl.pm) >= 1.030\" (as of perl-5.8.6). perl.req is basically a wrapper for B::PerlReq Perl compiler backend.","Process Name":"perl.req","Link":"https:\/\/linux.die.net\/man\/1\/perl.req"}},{"Process":{"Description":"This document describes differences between the 5.003 release (as documented in Programming Perl, second edition--the Camel Book) and this one.","Process Name":"perl5004delta","Link":"https:\/\/linux.die.net\/man\/1\/perl5004delta"}},{"Process":{"Description":"This document describes differences between the 5.004 release and this one.","Process Name":"perl5005delta","Link":"https:\/\/linux.die.net\/man\/1\/perl5005delta"}},{"Process":{"Description":"This document describes the differences between the 5.8.8 release and the 5.10.0 release. Many of the bug fixes in 5.10.0 were already seen in the 5.8.X maintenance releases; they are not duplicated here and are documented in the set of man pages named perl58[1-8]?delta.","Process Name":"perl5100delta","Link":"https:\/\/linux.die.net\/man\/1\/perl5100delta"}},{"Process":{"Description":"This document describes differences between the 5.10.0 release and the 5.10.1 release. If you are upgrading from an earlier release such as 5.8.8, first read the perl5100delta, which describes differences between 5.8.8 and 5.10.0","Process Name":"perl5101delta","Link":"https:\/\/linux.die.net\/man\/1\/perl5101delta"}},{"Process":{"Description":"This document describes differences between the 5.005 release and the 5.6.1 release.","Process Name":"perl561delta","Link":"https:\/\/linux.die.net\/man\/1\/perl561delta"}},{"Process":{"Description":"This document describes differences between the 5.005 release and the 5.6.0 release.","Process Name":"perl56delta","Link":"https:\/\/linux.die.net\/man\/1\/perl56delta"}},{"Process":{"Description":"This document describes differences between the 5.6.0 release and the 5.7.0 release.","Process Name":"perl570delta","Link":"https:\/\/linux.die.net\/man\/1\/perl570delta"}},{"Process":{"Description":"This document describes differences between the 5.7.0 release and the 5.7.1 release. (To view the differences between the 5.6.0 release and the 5.7.0 release, see perl570delta.)","Process Name":"perl571delta","Link":"https:\/\/linux.die.net\/man\/1\/perl571delta"}},{"Process":{"Description":"This document describes differences between the 5.7.1 release and the 5.7.2 release. (To view the differences between the 5.6.0 release and the 5.7.0 release, see perl570delta. To view the differences between the 5.7.0 release and the 5.7.1 release, see perl571delta.)","Process Name":"perl572delta","Link":"https:\/\/linux.die.net\/man\/1\/perl572delta"}},{"Process":{"Description":"This document describes differences between the 5.7.2 release and the 5.7.3 release. (To view the differences between the 5.6.0 release and the 5.7.0 release, see perl570delta. To view the differences between the 5.7.0 release and the 5.7.1 release, see perl571delta. To view the differences between the 5.7.1 release and the 5.7.2 release, see perl572delta.)","Process Name":"perl573delta","Link":"https:\/\/linux.die.net\/man\/1\/perl573delta"}},{"Process":{"Description":"This document describes differences between the 5.8.0 release and the 5.8.1 release. If you are upgrading from an earlier release such as 5.6.1, first read the perl58delta, which describes differences between 5.6.0 and 5.8.0. In case you are wondering about 5.6.1, it was bug-fix-wise rather identical to the development release 5.7.1. Confused? This timeline hopefully helps a bit: it lists the new major releases, their maintenance releases, and the development releases. New     Maintenance  Development\n\n5.6.0                             2000-Mar-22\n                     5.7.0        2000-Sep-02\n        5.6.1                     2001-Apr-08\n                     5.7.1        2001-Apr-09\n                     5.7.2        2001-Jul-13\n                     5.7.3        2002-Mar-05\n5.8.0                             2002-Jul-18\n        5.8.1                     2003-Sep-25","Process Name":"perl581delta","Link":"https:\/\/linux.die.net\/man\/1\/perl581delta"}},{"Process":{"Description":"This document describes differences between the 5.8.1 release and the 5.8.2 release. If you are upgrading from an earlier release such as 5.6.1, first read the perl58delta, which describes differences between 5.6.0 and 5.8.0, and the perl581delta, which describes differences between 5.8.0 and 5.8.1.","Process Name":"perl582delta","Link":"https:\/\/linux.die.net\/man\/1\/perl582delta"}},{"Process":{"Description":"This document describes differences between the 5.8.2 release and the 5.8.3 release. If you are upgrading from an earlier release such as 5.6.1, first read the perl58delta, which describes differences between 5.6.0 and 5.8.0, and the perl581delta and perl582delta, which describe differences between 5.8.0, 5.8.1 and 5.8.2","Process Name":"perl583delta","Link":"https:\/\/linux.die.net\/man\/1\/perl583delta"}},{"Process":{"Description":"This document describes differences between the 5.8.3 release and the 5.8.4 release.","Process Name":"perl584delta","Link":"https:\/\/linux.die.net\/man\/1\/perl584delta"}},{"Process":{"Description":"This document describes differences between the 5.8.4 release and the 5.8.5 release.","Process Name":"perl585delta","Link":"https:\/\/linux.die.net\/man\/1\/perl585delta"}},{"Process":{"Description":"This document describes differences between the 5.8.5 release and the 5.8.6 release.","Process Name":"perl586delta","Link":"https:\/\/linux.die.net\/man\/1\/perl586delta"}},{"Process":{"Description":"This document describes differences between the 5.8.6 release and the 5.8.7 release.","Process Name":"perl587delta","Link":"https:\/\/linux.die.net\/man\/1\/perl587delta"}},{"Process":{"Description":"This document describes differences between the 5.8.7 release and the 5.8.8 release.","Process Name":"perl588delta","Link":"https:\/\/linux.die.net\/man\/1\/perl588delta"}},{"Process":{"Description":"This document describes differences between the 5.8.8 release and the 5.8.9 release.","Process Name":"perl589delta","Link":"https:\/\/linux.die.net\/man\/1\/perl589delta"}},{"Process":{"Description":"This document describes differences between the 5.6.0 release and the 5.8.0 release. Many of the bug fixes in 5.8.0 were already seen in the 5.6.1 maintenance release since the two releases were kept closely coordinated (while 5.8.0 was still called 5.7.something). Changes that were integrated into the 5.6.1 release are marked \"[561]\". Many of these changes have been further developed since 5.6.1 was released, those are marked \"[561+]\". You can see the list of changes in the 5.6.1 release (both from the 5.005_03 release and the 5.6.0 release) by reading perl561delta.","Process Name":"perl58delta","Link":"https:\/\/linux.die.net\/man\/1\/perl58delta"}},{"Process":{"Description":"This document describes differences between the 5.8.0 release and the 5.9.0 release.","Process Name":"perl590delta","Link":"https:\/\/linux.die.net\/man\/1\/perl590delta"}},{"Process":{"Description":"This document describes differences between the 5.9.0 and the 5.9.1 development releases. See perl590delta for the differences between 5.8.0 and 5.9.0.","Process Name":"perl591delta","Link":"https:\/\/linux.die.net\/man\/1\/perl591delta"}},{"Process":{"Description":"This document describes differences between the 5.9.1 and the 5.9.2 development releases. See perl590delta and perl591delta for the differences between 5.8.0 and 5.9.1.","Process Name":"perl592delta","Link":"https:\/\/linux.die.net\/man\/1\/perl592delta"}},{"Process":{"Description":"This document describes differences between the 5.9.2 and the 5.9.3 development releases. See perl590delta, perl591delta and perl592delta for the differences between 5.8.0 and 5.9.2.","Process Name":"perl593delta","Link":"https:\/\/linux.die.net\/man\/1\/perl593delta"}},{"Process":{"Description":"This document describes differences between the 5.9.3 and the 5.9.4 development releases. See perl590delta, perl591delta, perl592delta and perl593delta for the differences between 5.8.0 and 5.9.3.","Process Name":"perl594delta","Link":"https:\/\/linux.die.net\/man\/1\/perl594delta"}},{"Process":{"Description":"This document describes differences between the 5.9.4 and the 5.9.5 development releases. See perl590delta, perl591delta, perl592delta, perl593delta and perl594delta for the differences between 5.8.0 and 5.9.4.","Process Name":"perl595delta","Link":"https:\/\/linux.die.net\/man\/1\/perl595delta"}},{"Process":{"Description":"With no arguments, enters a REPL . With a \"[programfile]\" or the \"-e\" option, compiles the given program and by default also executes the compiled code. -c                   check syntax only (runs BEGIN and CHECK blocks)\n-e program           one line of program\n-h, --help           display this help text\n-n                   run program once for each line of input\n-p                   same as -n, but also print $_ at the end of lines\n--target=[stage]     specify compilation stage to emit\n-t, --trace=[flags]  enable trace flags, see 'parrot --help-debug'\n--encoding=[mode]    specify string encoding mode\n-o, --output=[name]  specify name of output file\n-v, --version        display version information\n--stagestats         display time spent in the compilation stages\n--ll-backtrace       display a low level backtrace on errors Note that only boolean single-letter options may be bundled Supported stages for --target are: parse past post pir evalpmc where parse = a representation of the parse tree\npast  = an intermediate format representing the parrot abstract syntax tree\npost  = an intermediate format representing the parrot opcode syntax tree\npir   = the parrot intermediate representation","Process Name":"perl6","Link":"https:\/\/linux.die.net\/man\/1\/perl6"}},{"Process":{"Description":"This document describes various features of IBM 's Unix operating system ( AIX ) that will affect how Perl version 5 (hereafter just Perl) is compiled and\/or runs. Compiling Perl 5 on AIX For information on compilers on older versions of AIX , see \"Compiling Perl 5 on older AIX versions up to 4.3.3\". When compiling Perl, you must use an ANSI C compiler. AIX does not ship an ANSI compliant C-compiler with AIX by default, but binary builds of gcc for AIX are widely available. Supported Compilers Currently all versions of IBM 's \"xlc\", \"xlc_r\", \"cc\", \"cc_r\" or \"vac\" ANSI\/C compiler will work for building Perl if that compiler works on your system. If you plan to link Perl to any module that requires thread-support, like DBD::Oracle, it is better to use the _r version of the compiler. This will not build a threaded Perl, but a thread-enabled Perl. See also \"Threaded Perl\" later on. As of writing (2009-08) only the IBM XL C for AIX or XL C\/C ++ for AIX compiler is supported by IBM on AIX 5L\/6.1. The following compiler versions are supported by IBM: XL C and XL C\/C ++ V7, V8, V9, V10 The XL C for AIX is integrated in the XL C\/C ++ for AIX compiler. If you choose XL C\/C ++ V9 you need APAR IZ35785 installed otherwise the integrated SDBM_File do not compile correctly due to an optimization bug. You can circumvent this problem by adding -qipa to the optimization flags (-Doptimize='-O -qipa'). The PTF for APAR IZ35785 which solves this problem is available from IBM (April 2009 PTF for XL C\/C ++ Enterprise Edition for AIX , V9.0). Perl can be compiled with either IBM 's ANSI C compiler or with gcc. The former is recommended, as not only it can compile Perl with no difficulty, but also can take advantage of features listed later that require the use of IBM compiler-specific command-line flags. If you decide to use gcc, make sure your installation is recent and complete, and be sure to read the Perl INSTALL file for more gcc-specific details. Please report any hoops you had to jump through to the development team. Incompatibility with AIX Toolbox lib gdbm If the AIX Toolbox version of lib gdbm 1.8.x is installed on the system then Perl will not work. This library contains a defect version of the dbm_store() function. The lib gdbm will be automatically removed from the wanted libraries. Perl 5.10 was successfully compiled and tested on: AIX Level                 | Compiler Level          | w th | w\/o th\n--------------------------+-------------------------+------+-------\n5.1 TL9 32 bit            | XL C\/C++ V7             | OK   | OK\n5.1 TL9 32 bit            | gcc 3.2.2               | OK   | OK\n5.1 TL9 64 bit            | XL C\/C++ V7             | OK   | OK\n5.2 TL10 32 bit           | XL C\/C++ V8             | OK   | OK\n5.2 TL8 64 bit            | VA C\/C++ V6             | OK   | OK\n5.2 TL10 64 bit           | XL C\/C++ V8             | OK   | OK\n5.3 TL7 32 bit            | XL C\/C++ V9 + IZ35785   | OK   | OK\n5.3 TL7 32 bit            | gcc 4.2.4               | OK   | OK\n5.3 TL7 64 bit            | XL C\/C++ V9 + IZ35785   | OK   | OK\n6.1 TL1 32 bit            | XL C\/C++ V10            | OK   | OK\n6.1 TL1 64 bit + IZ39077  | XL C\/C++ V10            | OK   | OK\n\nw th   = with thread\nw\/o th = without thread\nOK     = tested Successfully tested means that all \"make test\" runs finish with an result of 100% OK . All tests were conducted with -Duseshrplib set. Building Dynamic Extensions on AIX Starting from Perl 5.7.2 (and consequently 5.8.x \/ 5.10.x) and AIX 4.3 or newer Perl uses the AIX native dynamic loading interface in the so called runtime linking mode instead of the emulated interface that was used in Perl releases 5.6.1 and earlier or, for AIX releases 4.2 and earlier. This change does break backward compatibility with compiled modules from earlier Perl releases. The change was made to make Perl more compliant with other applications like Apache\/mod_perl which are using the AIX native interface. This change also enables the use of C ++ code with static constructors and destructors in Perl extensions, which was not possible using the emulated interface. It is highly recommended to use the new interface. Using Large Files with Perl Should yield no problems. Threaded Perl Should yield no problems with AIX 5.1 \/ 5.2 \/ 5.3 and 6.1. IBM uses the AIX system Perl (V5.6.0 on AIX 5.1 and V5.8.2 on AIX 5.2 \/ 5.3 and 6.1) for some AIX system scripts. If you switch the links in \/usr\/bin from the AIX system Perl (\/usr\/opt\/perl5) to the newly build Perl then you get the same features as with the IBM AIX system Perl if the threaded options are used. The threaded Perl build works also on AIX 5.1 but the IBM Perl build (Perl v5.6.0) is not threaded on AIX 5.1. 64-bit Perl If your AIX system is installed with 64-bit support, you can expect 64-bit configurations to work. If you want to use 64-bit Perl on AIX 6.1 you need a APAR for a libc.a bug which affects (n)dbm_XXX functions. The APAR number for this problem is IZ39077 . If you need more memory (larger data segment) for your Perl programs you can set: \/etc\/security\/limits\ndefault:                    (or your user)\n    data = -1               (default is 262144 * 512 byte) With the default setting the size is limited to 128MB. The -1 removes this limit. If the \"make test\" fails please change your \/etc\/security\/limits as stated above. Recommended Options AIX 5.1\/5.2\/5.3 and 6.1 (threaded\/32-bit) With the following options you get a threaded Perl version which passes all make tests in threaded 32-bit mode, which is the default configuration for the Perl builds that AIX ships with. rm config.sh\n.\/Configure \\\n-d \\\n-Dcc=cc_r \\\n-Duseshrplib \\\n-Dusethreads \\\n-Dprefix=\/usr\/opt\/perl5_32 The -Dprefix option will install Perl in a directory parallel to the IBM AIX system Perl installation. Recommended Options AIX 5.1\/5.2\/5.3 and 6.1 (32-bit) With the following options you get a Perl version which passes all make tests in 32-bit mode. rm config.sh\n.\/Configure \\\n-d \\\n-Dcc=cc_r \\\n-Duseshrplib \\\n-Dprefix=\/usr\/opt\/perl5_32 The -Dprefix option will install Perl in a directory parallel to the IBM AIX system Perl installation. Recommended Options AIX 5.1\/5.2\/5.3 and 6.1 (threaded\/64-bit) With the following options you get a threaded Perl version which passes all make tests in 64-bit mode. export OBJECT_MODE=64 \/ setenv OBJECT_MODE 64 (depending on your shell)\n\nrm config.sh\n.\/Configure \\\n-d \\\n-Dcc=cc_r \\\n-Duseshrplib \\\n-Dusethreads \\\n-Duse64bitall \\\n-Dprefix=\/usr\/opt\/perl5_64 Recommended Options AIX 5.1\/5.2\/5.3 and 6.1(64-bit) With the following options you get a Perl version which passes all make tests in 64-bit mode. export OBJECT_MODE=64 \/ setenv OBJECT_MODE 64 (depending on your shell)\n\nrm config.sh\n.\/Configure \\\n-d \\\n-Dcc=cc_r \\\n-Duseshrplib \\\n-Duse64bitall \\\n-Dprefix=\/usr\/opt\/perl5_64 The -Dprefix option will install Perl in a directory parallel to the IBM AIX system Perl installation. If you choose gcc to compile 64-bit Perl then you need to add the following option: -Dcc='gcc -maix64' Compiling Perl 5 on older AIX versions up to 4.3.3 Due to the fact that AIX 4.3.3 reached end-of-service in December 31, 2003 this information is provided as is. The Perl versions prior to Perl 5.8.9 could be compiled on AIX up to 4.3.3 with the following settings (your mileage may vary): When compiling Perl, you must use an ANSI C compiler. AIX does not ship an ANSI compliant C-compiler with AIX by default, but binary builds of gcc for AIX are widely available. At the moment of writing, AIX supports two different native C compilers, for which you have to pay: xlC and vac. If you decide to use either of these two (which is quite a lot easier than using gcc), be sure to upgrade to the latest available patch level. Currently: xlC.C     3.1.4.10 or 3.6.6.0 or 4.0.2.2 or 5.0.2.9 or 6.0.0.3\nvac.C     4.4.0.3  or 5.0.2.6 or 6.0.0.1 note that xlC has the OS version in the name as of version 4.0.2.0, so you will find xlC.C for AIX-5 .0 as package xlC.aix50.rte   5.0.2.0 or 6.0.0.3 subversions are not the same \"latest\" on all OS versions. For example, the latest xlC-5 on aix41 is 5.0.2.9, while on aix43, it is 5.0.2.7. Perl can be compiled with either IBM 's ANSI C compiler or with gcc. The former is recommended, as not only can it compile Perl with no difficulty, but also can take advantage of features listed later that require the use of IBM compiler-specific command-line flags. The IBM 's compiler patch levels 5.0.0.0 and 5.0.1.0 have compiler optimization bugs that affect compiling perl.c and regcomp.c, respectively. If Perl's configuration detects those compiler patch levels, optimization is turned off for the said source code files. Upgrading to at least 5.0.2.0 is recommended. If you decide to use gcc, make sure your installation is recent and complete, and be sure to read the Perl INSTALL file for more gcc-specific details. Please report any hoops you had to jump through to the development team. OS level Before installing the patches to the IBM C-compiler you need to know the level of patching for the Operating System. IBM 's command 'oslevel' will show the base, but is not always complete (in this example oslevel shows 4.3.NULL, whereas the system might run most of 4.3.THREE): # oslevel\n4.3.0.0\n# lslpp -l | grep 'bos.rte '\nbos.rte           4.3.3.75  COMMITTED  Base Operating System Runtime\nbos.rte            4.3.2.0  COMMITTED  Base Operating System Runtime\n# The same might happen to AIX 5.1 or other OS levels. As a side note, Perl cannot be built without bos.adt.syscalls and bos.adt.libm installed # lslpp -l | egrep \"syscalls|libm\"\nbos.adt.libm      5.1.0.25  COMMITTED  Base Application Development\nbos.adt.syscalls  5.1.0.36  COMMITTED  System Calls Application\n# Building Dynamic Extensions on AIX AIX supports dynamically loadable objects as well as shared libraries. Shared libraries by convention end with the suffix .a, which is a bit misleading, as an archive can contain static as well as dynamic members. For Perl dynamically loaded objects we use the .so suffix also used on many other platforms. Note that starting from Perl 5.7.2 (and consequently 5.8.0) and AIX 4.3 or newer Perl uses the AIX native dynamic loading interface in the so called runtime linking mode instead of the emulated interface that was used in Perl releases 5.6.1 and earlier or, for AIX releases 4.2 and earlier. This change does break backward compatibility with compiled modules from earlier Perl releases. The change was made to make Perl more compliant with other applications like Apache\/mod_perl which are using the AIX native interface. This change also enables the use of C ++ code with static constructors and destructors in Perl extensions, which was not possible using the emulated interface. The IBM ANSI C Compiler All defaults for Configure can be used. If you've chosen to use vac 4, be sure to run 4.4.0.3. Older versions will turn up nasty later on. For vac 5 be sure to run at least 5.0.1.0, but vac 5.0.2.6 or up is highly recommended. Note that since IBM has removed vac 5.0.2.1 through 5.0.2.5 from the software depot, these versions should be considered obsolete. Here's a brief lead of how to upgrade the compiler to the latest level. Of course this is subject to changes. You can only upgrade versions from ftp-available updates if the first three digit groups are the same (in where you can skip intermediate unlike the patches in the developer snapshots of Perl), or to one version up where the \"base\" is available. In other words, the AIX compiler patches are cumulative. vac.C.4.4.0.1 => vac.C.4.4.0.3  is OK     (vac.C.4.4.0.2 not needed)\nxlC.C.3.1.3.3 => xlC.C.3.1.4.10 is NOT OK (xlC.C.3.1.4.0 is not available)\n\n# ftp ftp.software.ibm.com\nConnected to service.boulder.ibm.com.\n: welcome message ...\nName (ftp.software.ibm.com:merijn): anonymous\n331 Guest login ok, send your complete e-mail address as password.\nPassword:\n... accepted login stuff\nftp> cd \/aix\/fixes\/v4\/\nftp> dir other other.ll\noutput to local-file: other.ll? y\n200 PORT command successful.\n150 Opening ASCII mode data connection for \/bin\/ls.\n226 Transfer complete.\nftp> dir xlc xlc.ll\noutput to local-file: xlc.ll? y\n200 PORT command successful.\n150 Opening ASCII mode data connection for \/bin\/ls.\n226 Transfer complete.\nftp> bye\n... goodbye messages\n# ls -l *.ll\n-rw-rw-rw-   1 merijn   system    1169432 Nov  2 17:29 other.ll\n-rw-rw-rw-   1 merijn   system      29170 Nov  2 17:29 xlc.ll On AIX 4.2 using xlC, we continue: # lslpp -l | fgrep 'xlC.C '\n  xlC.C                     3.1.4.9  COMMITTED  C for AIX Compiler\n  xlC.C                     3.1.4.0  COMMITTED  C for AIX Compiler\n# grep 'xlC.C.3.1.4.*.bff' xlc.ll\n-rw-r--r--   1 45776101 1        6286336 Jul 22 1996  xlC.C.3.1.4.1.bff\n-rw-rw-r--   1 45776101 1        6173696 Aug 24 1998  xlC.C.3.1.4.10.bff\n-rw-r--r--   1 45776101 1        6319104 Aug 14 1996  xlC.C.3.1.4.2.bff\n-rw-r--r--   1 45776101 1        6316032 Oct 21 1996  xlC.C.3.1.4.3.bff\n-rw-r--r--   1 45776101 1        6315008 Dec 20 1996  xlC.C.3.1.4.4.bff\n-rw-rw-r--   1 45776101 1        6178816 Mar 28 1997  xlC.C.3.1.4.5.bff\n-rw-rw-r--   1 45776101 1        6188032 May 22 1997  xlC.C.3.1.4.6.bff\n-rw-rw-r--   1 45776101 1        6191104 Sep  5 1997  xlC.C.3.1.4.7.bff\n-rw-rw-r--   1 45776101 1        6185984 Jan 13 1998  xlC.C.3.1.4.8.bff\n-rw-rw-r--   1 45776101 1        6169600 May 27 1998  xlC.C.3.1.4.9.bff\n# wget ftp:\/\/ftp.software.ibm.com\/aix\/fixes\/v4\/xlc\/xlC.C.3.1.4.10.bff\n# On AIX 4.3 using vac, we continue: # lslpp -l | grep 'vac.C '\n vac.C                      5.0.2.2  COMMITTED  C for AIX Compiler\n vac.C                      5.0.2.0  COMMITTED  C for AIX Compiler\n# grep 'vac.C.5.0.2.*.bff' other.ll\n-rw-rw-r--   1 45776101 1        13592576 Apr 16 2001  vac.C.5.0.2.0.bff\n-rw-rw-r--   1 45776101 1        14133248 Apr  9 2002  vac.C.5.0.2.3.bff\n-rw-rw-r--   1 45776101 1        14173184 May 20 2002  vac.C.5.0.2.4.bff\n-rw-rw-r--   1 45776101 1        14192640 Nov 22 2002  vac.C.5.0.2.6.bff\n# wget ftp:\/\/ftp.software.ibm.com\/aix\/fixes\/v4\/other\/vac.C.5.0.2.6.bff\n# Likewise on all other OS levels. Then execute the following command, and fill in its choices # smit install_update\n -> Install and Update from LATEST Available Software\n * INPUT device \/ directory for software [ vac.C.5.0.2.6.bff    ]\n [ OK ]\n [ OK ] Follow the messages ... and you're done. If you like a more web-like approach, a good start point can be http:\/\/www14.software.ibm.com\/webapp\/download\/downloadaz.jsp and click \"C for AIX \", and follow the instructions. The usenm option If linking miniperl cc -o miniperl ... miniperlmain.o opmini.o perl.o ... -lm -lc ... causes error like this ld: 0711-317 ERROR: Undefined symbol: .aintl\nld: 0711-317 ERROR: Undefined symbol: .copysignl\nld: 0711-317 ERROR: Undefined symbol: .syscall\nld: 0711-317 ERROR: Undefined symbol: .eaccess\nld: 0711-317 ERROR: Undefined symbol: .setresuid\nld: 0711-317 ERROR: Undefined symbol: .setresgid\nld: 0711-317 ERROR: Undefined symbol: .setproctitle\nld: 0711-345 Use the -bloadmap or -bnoquiet option to obtain more information. you could retry with make realclean\nrm config.sh\n.\/Configure -Dusenm ... which makes Configure to use the \"nm\" tool when scanning for library symbols, which usually is not done in AIX . Related to this, you probably should not use the \"-r\" option of Configure in AIX , because that affects of how the \"nm\" tool is used. Using GNU 's gcc for building Perl Using gcc-3.x (tested with 3.0.4, 3.1, and 3.2) now works out of the box, as do recent gcc-2.9 builds available directly from IBM as part of their Linux compatibility packages, available here: http:\/\/www.ibm.com\/servers\/aix\/products\/aixos\/linux\/ Using Large Files with Perl Should yield no problems. Threaded Perl Threads seem to work OK , though at the moment not all tests pass when threads are used in combination with 64-bit configurations. You may get a warning when doing a threaded build: \"pp_sys.c\", line 4640.39: 1506-280 (W) Function argument assignment between types \"unsigned char*\" and \"const void*\" is not allowed. The exact line number may vary, but if the warning (W) comes from a line line this hent = PerlSock_gethostbyaddr(addr, (Netdb_hlen_t) addrlen, addrtype); in the \"pp_ghostent\" function, you may ignore it safely. The warning is caused by the reentrant variant of gethostbyaddr() having a slightly different prototype than its non-reentrant variant, but the difference is not really significant here. 64-bit Perl If your AIX is installed with 64-bit support, you can expect 64-bit configurations to work. In combination with threads some tests might still fail. AIX 4.2 and extensions using C ++ with statics In AIX 4.2 Perl extensions that use C ++ functions that use statics may have problems in that the statics are not getting initialized. In newer AIX releases this has been solved by linking Perl with the libC_r library, but unfortunately in AIX 4.2 the said library has an obscure bug where the various functions related to time (such as time() and gettimeofday()) return broken values, and therefore in AIX 4.2 Perl is not linked against the libC_r.","Process Name":"perlaix","Link":"https:\/\/linux.die.net\/man\/1\/perlaix"}},{"Process":{"Description":"Prerequisites for Compiling Perl on AmigaOS Unix emulation for AmigaOS: ixemul.library You need the Unix emulation for AmigaOS, whose most important part is ixemul.library. For a minimum setup, get the latest versions of the following packages from the Aminet archives ( http:\/\/www.aminet.net\/~aminet\/ ): ixemul-bin\nixemul-env-bin\npdksh-bin Note also that this is a minimum setup; you might want to add other packages of ADE (the Amiga Developers Environment). Version of Amiga OS You need at the very least AmigaOS version 2.0. Recommended is version 3.1. Starting Perl programs under AmigaOS Start your Perl program foo with arguments \"arg1 arg2 arg3\" the same way as on any other platform, by perl foo arg1 arg2 arg3 If you want to specify perl options \"-my_opts\" to the perl itself (as opposed to your program), use perl -my_opts foo arg1 arg2 arg3 Alternately, you can try to get a replacement for the system's Execute command that honors the #!\/usr\/bin\/perl syntax in scripts and set the s-Bit of your scripts. Then you can invoke your scripts like under UNIX with foo arg1 arg2 arg3 (Note that having *nixish full path to perl \/usr\/bin\/perl is not necessary, perl would be enough, but having full path would make it easier to use your script under *nix.) Shortcomings of Perl under AmigaOS Perl under AmigaOS lacks some features of perl under UNIX because of deficiencies in the UNIX-emulation, most notably: \u2022 fork() \u2022 some features of the UNIX filesystem regarding link count and file dates \u2022 inplace operation (the -i switch) without backup file \u2022 umask() works, but the correct permissions are only set when the file is finally close()d","Process Name":"perlamiga","Link":"https:\/\/linux.die.net\/man\/1\/perlamiga"}},{"Process":{"Description":"This file contains the documentation of the perl public API generated by embed.pl, specifically a listing of functions, macros, flags, and variables that may be used by extension writers. The interfaces of any functions that are not listed here are subject to change without notice. For this reason, blindly using functions listed in proto.h is to be avoided when writing extensions. Note that all Perl API global variables must be referenced with the \"PL_\" prefix. Some macros are provided for compatibility with the older, unadorned names, but this support may be disabled in a future release. Perl was originally written to handle US-ASCII only (that is characters whose ordinal numbers are in the range 0 - 127). And documentation and comments may still use the term ASCII , when sometimes in fact the entire range from 0 - 255 is meant. Note that Perl can be compiled and run under EBCDIC (See perlebcdic) or ASCII . Most of the documentation (and even comments in the code) ignore the EBCDIC possibility. For almost all purposes the differences are transparent. As an example, under EBCDIC , instead of UTF-8 , UTF-EBCDIC is used to encode Unicode strings, and so whenever this documentation refers to \"utf8\" (and variants of that name, including in function names), it also (essentially transparently) means \"UTF-EBCDIC\". But the ordinals of characters differ between ASCII , EBCDIC , and the UTF- encodings, and a string encoded in UTF-EBCDIC may occupy more bytes than in UTF-8 . Also, on some EBCDIC machines, functions that are documented as operating on US-ASCII (or Basic Latin in Unicode terminology) may in fact operate on all 256 characters in the EBCDIC range, not just the subset corresponding to US-ASCII. The listing below is alphabetical, case insensitive.","Process Name":"perlapi","Link":"https:\/\/linux.die.net\/man\/1\/perlapi"}},{"Process":{"Description":"Perl's source code, and extensions that want maximum portability, should use the above functions instead of those defined in ANSI C's stdio.h. The perl headers (in particular \"perlio.h\") will \"#define\" them to the I\/O mechanism selected at Configure time. The functions are modeled on those in stdio.h, but parameter order has been \"tidied up a little\". \"PerlIO *\" takes the place of FILE *. Like FILE * it should be treated as opaque (it is probably safe to assume it is a pointer to something). There are currently three implementations: 1. USE_STDIO All above are #define'd to stdio functions or are trivial wrapper functions which call stdio. In this case only PerlIO * is a FILE *. This has been the default implementation since the abstraction was introduced in perl5.003_02. 2. USE_SFIO A \"legacy\" implementation in terms of the \"sfio\" library. Used for some specialist applications on Unix machines (\"sfio\" is not widely ported away from Unix). Most of above are #define'd to the sfio functions. PerlIO * is in this case Sfio_t *. 3. USE_PERLIO Introduced just after perl5.7.0, this is a re-implementation of the above abstraction which allows perl more control over how IO is done as it decouples IO from the way the operating system and C library choose to do things. For USE_PERLIO PerlIO * has an extra layer of indirection - it is a pointer-to-a-pointer. This allows the PerlIO * to remain with a known value while swapping the implementation around underneath at run time. In this case all the above are true (but very simple) functions which call the underlying implementation. This is the only implementation for which \"PerlIO_apply_layers()\" does anything \"interesting\". The USE_PERLIO implementation is described in perliol. Because \"perlio.h\" is a thin layer (for efficiency) the semantics of these functions are somewhat dependent on the underlying implementation. Where these variations are understood they are noted below. Unless otherwise noted, functions return 0 on success, or a negative value (usually \"EOF\" which is usually -1) and set \"errno\" on error. PerlIO_stdin(), PerlIO_stdout(), PerlIO_stderr() Use these rather than \"stdin\", \"stdout\", \"stderr\". They are written to look like \"function calls\" rather than variables because this makes it easier to make them function calls if platform cannot export data to loaded modules, or if (say) different \"threads\" might have different values. PerlIO_open(path, mode), PerlIO_fdopen(fd,mode) These correspond to fopen()\/ fdopen() and the arguments are the same. Return \"NULL\" and set \"errno\" if there is an error. There may be an implementation limit on the number of open handles, which may be lower than the limit on the number of open files - \"errno\" may not be set when \"NULL\" is returned if this limit is exceeded. PerlIO_reopen(path,mode,f) While this currently exists in all three implementations perl itself does not use it. As perl does not use it, it is not well tested. Perl prefers to \"dup\" the new low-level descriptor to the descriptor used by the existing PerlIO. This may become the behaviour of this function in the future. PerlIO_printf(f,fmt,...), PerlIO_vprintf(f,fmt,a) These are fprintf()\/ vfprintf() equivalents. PerlIO_stdoutf(fmt,...) This is printf() equivalent. printf is #defined to this function, so it is (currently) legal to use \"printf(fmt,...)\" in perl sources. PerlIO_read(f,buf,count), PerlIO_write(f,buf,count) These correspond functionally to fread() and fwrite() but the arguments and return values are different. The PerlIO_read() and PerlIO_write() signatures have been modeled on the more sane low level read() and write() functions instead: The \"file\" argument is passed first, there is only one \"count\", and the return value can distinguish between error and \"EOF\". Returns a byte count if successful (which may be zero or positive), returns negative value and sets \"errno\" on error. Depending on implementation \"errno\" may be \"EINTR\" if operation was interrupted by a signal. PerlIO_close(f) Depending on implementation \"errno\" may be \"EINTR\" if operation was interrupted by a signal. PerlIO_puts(f,s), PerlIO_putc(f,c) These correspond to fputs() and fputc(). Note that arguments have been revised to have \"file\" first. PerlIO_ungetc(f,c) This corresponds to ungetc(). Note that arguments have been revised to have \"file\" first. Arranges that next read operation will return the byte c. Despite the implied \"character\" in the name only values in the range 0..0xFF are defined. Returns the byte c on success or -1 ( \"EOF\") on error. The number of bytes that can be \"pushed back\" may vary, only 1 character is certain, and then only if it is the last character that was read from the handle. PerlIO_getc(f) This corresponds to getc(). Despite the c in the name only byte range 0..0xFF is supported. Returns the character read or -1 ( \"EOF\") on error. PerlIO_eof(f) This corresponds to feof(). Returns a true\/false indication of whether the handle is at end of file. For terminal devices this may or may not be \"sticky\" depending on the implementation. The flag is cleared by PerlIO_seek(), or PerlIO_rewind(). PerlIO_error(f) This corresponds to ferror(). Returns a true\/false indication of whether there has been an IO error on the handle. PerlIO_fileno(f) This corresponds to fileno(), note that on some platforms, the meaning of \"fileno\" may not match Unix. Returns -1 if the handle has no open descriptor associated with it. PerlIO_clearerr(f) This corresponds to clearerr(), i.e., clears 'error' and (usually) 'eof' flags for the \"stream\". Does not return a value. PerlIO_flush(f) This corresponds to fflush(). Sends any buffered write data to the underlying file. If called with \"NULL\" this may flush all open streams (or core dump with some USE_STDIO implementations). Calling on a handle open for read only, or on which last operation was a read of some kind may lead to undefined behaviour on some USE_STDIO implementations. The USE_PERLIO (layers) implementation tries to behave better: it flushes all open streams when passed \"NULL\", and attempts to retain data on read streams either in the buffer or by seeking the handle to the current logical position. PerlIO_seek(f,offset,whence) This corresponds to fseek(). Sends buffered write data to the underlying file, or discards any buffered read data, then positions the file descriptor as specified by offset and whence (sic). This is the correct thing to do when switching between read and write on the same handle (see issues with PerlIO_flush() above). Offset is of type \"Off_t\" which is a perl Configure value which may not be same as stdio's \"off_t\". PerlIO_tell(f) This corresponds to ftell(). Returns the current file position, or (Off_t) -1 on error. May just return value system \"knows\" without making a system call or checking the underlying file descriptor (so use on shared file descriptors is not safe without a PerlIO_seek()). Return value is of type \"Off_t\" which is a perl Configure value which may not be same as stdio's \"off_t\". PerlIO_getpos(f,p), PerlIO_setpos(f,p) These correspond (loosely) to fgetpos() and fsetpos(). Rather than stdio's Fpos_t they expect a \"Perl Scalar Value\" to be passed. What is stored there should be considered opaque. The layout of the data may vary from handle to handle. When not using stdio or if platform does not have the stdio calls then they are implemented in terms of PerlIO_tell() and PerlIO_seek(). PerlIO_rewind(f) This corresponds to rewind(). It is usually defined as being PerlIO_seek(f,(Off_t)0L, SEEK_SET);\nPerlIO_clearerr(f); PerlIO_tmpfile() This corresponds to tmpfile(), i.e., returns an anonymous PerlIO or NULL on error. The system will attempt to automatically delete the file when closed. On Unix the file is usually \"unlink\"-ed just after it is created so it does not matter how it gets closed. On other systems the file may only be deleted if closed via PerlIO_close() and\/or the program exits via \"exit\". Depending on the implementation there may be \"race conditions\" which allow other processes access to the file, though in general it will be safer in this regard than ad. hoc. schemes. PerlIO_setlinebuf(f) This corresponds to setlinebuf(). Does not return a value. What constitutes a \"line\" is implementation dependent but usually means that writing \"\\n\" flushes the buffer. What happens with things like \"this\\nthat\" is uncertain. (Perl core uses it only when \"dumping\"; it has nothing to do with $| auto-flush.) Co-existence with stdio There is outline support for co-existence of PerlIO with stdio. Obviously if PerlIO is implemented in terms of stdio there is no problem. However in other cases then mechanisms must exist to create a FILE * which can be passed to library code which is going to use stdio calls. The first step is to add this line: #define PERLIO_NOT_STDIO 0 before including any perl header files. (This will probably become the default at some point). That prevents \"perlio.h\" from attempting to #define stdio functions onto PerlIO functions. XS code is probably better using \"typemap\" if it expects FILE * arguments. The standard typemap will be adjusted to comprehend any changes in this area. PerlIO_importFILE(f,mode) Used to get a PerlIO * from a FILE *. The mode argument should be a string as would be passed to fopen\/PerlIO_open. If it is NULL then - for legacy support - the code will (depending upon the platform and the implementation) either attempt to empirically determine the mode in which f is open, or use \"r+\" to indicate a read\/write stream. Once called the FILE * should ONLY be closed by calling \"PerlIO_close()\" on the returned PerlIO *. The PerlIO is set to textmode. Use PerlIO_binmode if this is not the desired mode. This is not the reverse of PerlIO_exportFILE(). PerlIO_exportFILE(f,mode) Given a PerlIO * create a 'native' FILE * suitable for passing to code expecting to be compiled and linked with ANSI C stdio.h. The mode argument should be a string as would be passed to fopen\/PerlIO_open. If it is NULL then - for legacy support - the FILE * is opened in same mode as the PerlIO *. The fact that such a FILE * has been 'exported' is recorded, (normally by pushing a new :stdio \"layer\" onto the PerlIO *), which may affect future PerlIO operations on the original PerlIO *. You should not call \"fclose()\" on the file unless you call \"PerlIO_releaseFILE()\" to disassociate it from the PerlIO *. (Do not use PerlIO_importFILE() for doing the disassociation.) Calling this function repeatedly will create a FILE * on each call (and will push an :stdio layer each time as well). PerlIO_releaseFILE(p,f) Calling PerlIO_releaseFILE informs PerlIO that all use of FILE * is complete. It is removed from the list of 'exported' FILE *s, and the associated PerlIO * should revert to its original behaviour. Use this to disassociate a file from a PerlIO * that was associated using PerlIO_exportFILE(). PerlIO_findFILE(f) Returns a native FILE * used by a stdio layer. If there is none, it will create one with PerlIO_exportFILE. In either case the FILE * should be considered as belonging to PerlIO subsystem and should only be closed by calling \"PerlIO_close()\". \"Fast gets\" Functions In addition to standard-like API defined so far above there is an \"implementation\" interface which allows perl to get at internals of PerlIO. The following calls correspond to the various FILE_xxx macros determined by Configure - or their equivalent in other implementations. This section is really of interest to only those concerned with detailed perl-core behaviour, implementing a PerlIO mapping or writing code which can make use of the \"read ahead\" that has been done by the IO system in the same way perl does. Note that any code that uses these interfaces must be prepared to do things the traditional way if a handle does not support them. PerlIO_fast_gets(f) Returns true if implementation has all the interfaces required to allow perl's \"sv_gets\" to \"bypass\" normal IO mechanism. This can vary from handle to handle. PerlIO_fast_gets(f) = PerlIO_has_cntptr(f) && \\\n                      PerlIO_canset_cnt(f) && \\\n                      `Can set pointer into buffer' PerlIO_has_cntptr(f) Implementation can return pointer to current position in the \"buffer\" and a count of bytes available in the buffer. Do not use this - use PerlIO_fast_gets. PerlIO_get_cnt(f) Return count of readable bytes in the buffer. Zero or negative return means no more bytes available. PerlIO_get_ptr(f) Return pointer to next readable byte in buffer, accessing via the pointer (dereferencing) is only safe if PerlIO_get_cnt() has returned a positive value. Only positive offsets up to value returned by PerlIO_get_cnt() are allowed. PerlIO_set_ptrcnt(f,p,c) Set pointer into buffer, and a count of bytes still in the buffer. Should be used only to set pointer to within range implied by previous calls to \"PerlIO_get_ptr\" and \"PerlIO_get_cnt\". The two values must be consistent with each other (implementation may only use one or the other or may require both). PerlIO_canset_cnt(f) Implementation can adjust its idea of number of bytes in the buffer. Do not use this - use PerlIO_fast_gets. PerlIO_set_cnt(f,c) Obscure - set count of bytes in the buffer. Deprecated. Only usable if PerlIO_canset_cnt() returns true. Currently used in only doio.c to force count less than -1 to -1. Perhaps should be PerlIO_set_empty or similar. This call may actually do nothing if \"count\" is deduced from pointer and a \"limit\". Do not use this - use PerlIO_set_ptrcnt(). PerlIO_has_base(f) Returns true if implementation has a buffer, and can return pointer to whole buffer and its size. Used by perl for -T \/ -B tests. Other uses would be very obscure... PerlIO_get_base(f) Return start of buffer. Access only positive offsets in the buffer up to the value returned by PerlIO_get_bufsiz(). PerlIO_get_bufsiz(f) Return the total number of bytes in the buffer, this is neither the number that can be read, nor the amount of memory allocated to the buffer. Rather it is what the operating system and\/or implementation happened to \"read()\" (or whatever) last time IO was requested. Other Functions PerlIO_apply_layers(f,mode,layers) The new interface to the USE_PERLIO implementation. The layers \":crlf\" and \":raw\" are only ones allowed for other implementations and those are silently ignored. (As of perl5.8 \":raw\" is deprecated.) Use PerlIO_binmode() below for the portable case. PerlIO_binmode(f,ptype,imode,layers) The hook used by perl's \"binmode\" operator. ptype is perl's character for the kind of IO: '<' read '>' write '+' read\/write imode is \"O_BINARY\" or \"O_TEXT\". layers is a string of layers to apply, only \":crlf\" makes sense in the non USE_PERLIO case. (As of perl5.8 \":raw\" is deprecated in favour of passing NULL .) Portable cases are:     PerlIO_binmode(f,ptype,O_BINARY,NULL);\nand\n    PerlIO_binmode(f,ptype,O_TEXT,\":crlf\"); On Unix these calls probably have no effect whatsoever. Elsewhere they alter \"\\n\" to CR ,LF translation and possibly cause a special text \"end of file\" indicator to be written or honoured on read. The effect of making the call after doing any IO to the handle depends on the implementation. (It may be ignored, affect any data which is already buffered as well, or only apply to subsequent data.) PerlIO_debug(fmt,...) PerlIO_debug is a printf()-like function which can be used for debugging. No return value. Its main use is inside PerlIO where using real printf, warn() etc. would recursively call PerlIO and be a problem. PerlIO_debug writes to the file named by $ENV{' PERLIO_DEBUG '} typical use might be Bourne shells (sh, ksh, bash, zsh, ash, ...):\n PERLIO_DEBUG=\/dev\/tty .\/perl somescript some args\n\nCsh\/Tcsh:\n setenv PERLIO_DEBUG \/dev\/tty\n .\/perl somescript some args\n\nIf you have the \"env\" utility:\n env PERLIO_DEBUG=\/dev\/tty .\/perl somescript some args\n\nWin32:\n set PERLIO_DEBUG=CON\n perl somescript some args If $ENV{' PERLIO_DEBUG '} is not set PerlIO_debug() is a no-op. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"perlapio","Link":"https:\/\/linux.die.net\/man\/1\/perlapio"}},{"Process":{"Description":"The following tests are known to fail as of Perl 5.005_03: comp\/decl..........FAILED at test 0 op\/write...........FAILED at test 0 lib\/filefind.......FAILED at test 2 lib\/io_udp.........FAILED at test 2 lib\/findbin........stat(\/ressel\/ABT\/USER\/vta\/jk\/proj.local\/perl\/perl5.005_03-MAINT_TRIAL_5\/t\/lib\/): No such file or directory at ..\/lib\/FindBin.pm line 162 stat(\/ressel\/ABT\/USER\/vta\/jk\/proj.local\/perl\/perl5.005_03-MAINT_TRIAL_5\/t\/lib\/): No such file or directory at ..\/lib\/FindBin.pm line 163 FAILED at test 1","Process Name":"perlapollo","Link":"https:\/\/linux.die.net\/man\/1\/perlapollo"}},{"Process":{"Description":"This is \"The Artistic License\". It's here so that modules, programs, etc., that want to declare this as their distribution license, can link to it. It is also one of the two licenses Perl allows itself to be redistributed and\/or modified; for the other one, the GNU General Public License, see the perlgpl.","Process Name":"perlartistic","Link":"https:\/\/linux.die.net\/man\/1\/perlartistic"}},{"Process":{"Description":"This file contains instructions how to build Perl under BeOS and lists known problems.","Process Name":"perlbeos","Link":"https:\/\/linux.die.net\/man\/1\/perlbeos"}},{"Process":{"Description":"The Camel Book, officially known as Programming Perl, Third Edition, by Larry Wall et al, is the definitive reference work covering nearly all of Perl. You can order it and other Perl books from O'Reilly & Associates, 1-800-998-9938. Local\/overseas is +1 707 829 0515. If you can locate an O'Reilly order form, you can also fax to +1 707 829 0104. If you're web-connected, you can even mosey on over to <http:\/\/www.oreilly.com\/> for an online order form. Other Perl books from various publishers and authors can be found listed in perlfaq2 or on the web at <http:\/\/books.perl.org\/>. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"perlbook","Link":"https:\/\/linux.die.net\/man\/1\/perlbook"}},{"Process":{"Description":"If you're not familiar with objects from other languages, some of the other Perl object documentation may be a little daunting, such as perlobj, a basic reference in using objects, and perltoot, which introduces readers to the peculiarities of Perl's object system in a tutorial way. So, let's take a different approach, presuming no prior object experience. It helps if you know about subroutines (perlsub), references (perlref et. seq.), and packages (perlmod), so become familiar with those first if you haven't already. If we could talk to the animals... Let's let the animals talk for a moment: sub Cow::speak {\n  print \"a Cow goes moooo!\\n\";\n}\nsub Horse::speak {\n  print \"a Horse goes neigh!\\n\";\n}\nsub Sheep::speak {\n  print \"a Sheep goes baaaah!\\n\";\n}\n\nCow::speak;\nHorse::speak;\nSheep::speak; This results in: a Cow goes moooo!\na Horse goes neigh!\na Sheep goes baaaah! Nothing spectacular here. Simple subroutines, albeit from separate packages, and called using the full package name. So let's create an entire pasture: # Cow::speak, Horse::speak, Sheep::speak as before\n@pasture = qw(Cow Cow Horse Sheep Sheep);\nforeach $animal (@pasture) {\n  &{$animal.\"::speak\"};\n} This results in: a Cow goes moooo!\na Cow goes moooo!\na Horse goes neigh!\na Sheep goes baaaah!\na Sheep goes baaaah! Wow. That symbolic coderef de-referencing there is pretty nasty. We're counting on \"no strict refs\" mode, certainly not recommended for larger programs. And why was that necessary? Because the name of the package seems to be inseparable from the name of the subroutine we want to invoke within that package. Or is it? Introducing the method invocation arrow For now, let's say that \"Class->method\" invokes subroutine \"method\" in package \"Class\". (Here, \"Class\" is used in its \"category\" meaning, not its \"scholastic\" meaning.) That's not completely accurate, but we'll do this one step at a time. Now let's use it like so: # Cow::speak, Horse::speak, Sheep::speak as before\nCow->speak;\nHorse->speak;\nSheep->speak; And once again, this results in: a Cow goes moooo!\na Horse goes neigh!\na Sheep goes baaaah! That's not fun yet. Same number of characters, all constant, no variables. But yet, the parts are separable now. Watch: $a = \"Cow\";\n$a->speak; # invokes Cow->speak Ahh! Now that the package name has been parted from the subroutine name, we can use a variable package name. And this time, we've got something that works even when \"use strict refs\" is enabled. Invoking a barnyard Let's take that new arrow invocation and put it back in the barnyard example: sub Cow::speak {\n  print \"a Cow goes moooo!\\n\";\n}\nsub Horse::speak {\n  print \"a Horse goes neigh!\\n\";\n}\nsub Sheep::speak {\n  print \"a Sheep goes baaaah!\\n\";\n}\n\n@pasture = qw(Cow Cow Horse Sheep Sheep);\nforeach $animal (@pasture) {\n  $animal->speak;\n} There! Now we have the animals all talking, and safely at that, without the use of symbolic coderefs. But look at all that common code. Each of the \"speak\" routines has a similar structure: a \"print\" operator and a string that contains common text, except for two of the words. It'd be nice if we could factor out the commonality, in case we decide later to change it all to \"says\" instead of \"goes\". And we actually have a way of doing that without much fuss, but we have to hear a bit more about what the method invocation arrow is actually doing for us. The extra parameter of method invocation The invocation of: Class->method(@args) attempts to invoke subroutine \"Class::method\" as: Class::method(\"Class\", @args); (If the subroutine can't be found, \"inheritance\" kicks in, but we'll get to that later.) This means that we get the class name as the first parameter (the only parameter, if no arguments are given). So we can rewrite the \"Sheep\" speaking subroutine as: sub Sheep::speak {\n  my $class = shift;\n  print \"a $class goes baaaah!\\n\";\n} And the other two animals come out similarly: sub Cow::speak {\n  my $class = shift;\n  print \"a $class goes moooo!\\n\";\n}\nsub Horse::speak {\n  my $class = shift;\n  print \"a $class goes neigh!\\n\";\n} In each case, $class will get the value appropriate for that subroutine. But once again, we have a lot of similar structure. Can we factor that out even further? Yes, by calling another method in the same class. Calling a second method to simplify things Let's call out from \"speak\" to a helper method called \"sound\". This method provides the constant text for the sound itself. { package Cow;\n  sub sound { \"moooo\" }\n  sub speak {\n    my $class = shift;\n    print \"a $class goes \", $class->sound, \"!\\n\";\n  }\n} Now, when we call \"Cow->speak\", we get a $class of \"Cow\" in \"speak\". This in turn selects the \"Cow->sound\" method, which returns \"moooo\". But how different would this be for the \"Horse\"? { package Horse;\n  sub sound { \"neigh\" }\n  sub speak {\n    my $class = shift;\n    print \"a $class goes \", $class->sound, \"!\\n\";\n  }\n} Only the name of the package and the specific sound change. So can we somehow share the definition for \"speak\" between the Cow and the Horse? Yes, with inheritance! Inheriting the windpipes We'll define a common subroutine package called \"Animal\", with the definition for \"speak\": { package Animal;\n  sub speak {\n  my $class = shift;\n  print \"a $class goes \", $class->sound, \"!\\n\";\n  }\n} Then, for each animal, we say it \"inherits\" from \"Animal\", along with the animal-specific sound: { package Cow;\n  @ISA = qw(Animal);\n  sub sound { \"moooo\" }\n} Note the added @ISA array (pronounced \"is a\"). We'll get to that in a minute. But what happens when we invoke \"Cow->speak\" now? First, Perl constructs the argument list. In this case, it's just \"Cow\". Then Perl looks for \"Cow::speak\". But that's not there, so Perl checks for the inheritance array @Cow::ISA. It's there, and contains the single name \"Animal\". Perl next checks for \"speak\" inside \"Animal\" instead, as in \"Animal::speak\". And that's found, so Perl invokes that subroutine with the already frozen argument list. Inside the \"Animal::speak\" subroutine, $class becomes \"Cow\" (the first argument). So when we get to the step of invoking \"$class->sound\", it'll be looking for \"Cow->sound\", which gets it on the first try without looking at @ISA. Success! A few notes about @ISA This magical @ISA variable has declared that \"Cow\" \"is a\" \"Animal\". Note that it's an array, not a simple single value, because on rare occasions, it makes sense to have more than one parent class searched for the missing methods. If \"Animal\" also had an @ISA, then we'd check there too. The search is recursive, depth-first, left-to-right in each @ISA by default (see mro for alternatives). Typically, each @ISA has only one element (multiple elements means multiple inheritance and multiple headaches), so we get a nice tree of inheritance. When we turn on \"use strict\", we'll get complaints on @ISA, since it's not a variable containing an explicit package name, nor is it a lexical (\"my\") variable. We can't make it a lexical variable though (it has to belong to the package to be found by the inheritance mechanism), so there's a couple of straightforward ways to handle that. The easiest is to just spell the package name out: @Cow::ISA = qw(Animal); Or declare it as package global variable: package Cow;\nour @ISA = qw(Animal); Or allow it as an implicitly named package variable: package Cow;\nuse vars qw(@ISA);\n@ISA = qw(Animal); If the \"Animal\" class comes from another (object-oriented) module, then just employ \"use base\" to specify that \"Animal\" should serve as the basis for the \"Cow\" class: package Cow;\nuse base qw(Animal); Now that's pretty darn simple! Overriding the methods Let's add a mouse, which can barely be heard: # Animal package from before\n{ package Mouse;\n  @ISA = qw(Animal);\n  sub sound { \"squeak\" }\n  sub speak {\n    my $class = shift;\n    print \"a $class goes \", $class->sound, \"!\\n\";\n    print \"[but you can barely hear it!]\\n\";\n  }\n}\n\nMouse->speak; which results in: a Mouse goes squeak!\n[but you can barely hear it!] Here, \"Mouse\" has its own speaking routine, so \"Mouse->speak\" doesn't immediately invoke \"Animal->speak\". This is known as \"overriding\". In fact, we don't even need to say that a \"Mouse\" is an \"Animal\" at all, because all of the methods needed for \"speak\" are completely defined for \"Mouse\"; this is known as \"duck typing\": \"If it walks like a duck and quacks like a duck, I would call it a duck\" (James Whitcomb). However, it would probably be beneficial to allow a closer examination to conclude that a \"Mouse\" is indeed an \"Animal\", so it is actually better to define \"Mouse\" with \"Animal\" as its base (that is, it is better to \"derive \"Mouse\" from \"Animal\"\"). Moreover, this duplication of code could become a maintenance headache (though code-reuse is not actually a good reason for inheritance; good design practices dictate that a derived class should be usable wherever its base class is usable, which might not be the outcome if code-reuse is the sole criterion for inheritance. Just remember that a \"Mouse\" should always act like an \"Animal\"). So, let's make \"Mouse\" an \"Animal\"! The obvious solution is to invoke \"Animal::speak\" directly: # Animal package from before\n{ package Mouse;\n  @ISA = qw(Animal);\n  sub sound { \"squeak\" }\n  sub speak {\n    my $class = shift;\n    Animal::speak($class);\n    print \"[but you can barely hear it!]\\n\";\n  }\n} Note that we're using \"Animal::speak\". If we were to invoke \"Animal->speak\" instead, the first parameter to \"Animal::speak\" would automatically be \"Animal\" rather than \"Mouse\", so that the call to \"$class->sound\" in \"Animal::speak\" would become \"Animal->sound\" rather than \"Mouse->sound\". Also, without the method arrow \"->\", it becomes necessary to specify the first parameter to \"Animal::speak\" ourselves, which is why $class is explicitly passed: \"Animal::speak($class)\". However, invoking \"Animal::speak\" directly is a mess: Firstly, it assumes that the \"speak\" method is a member of the \"Animal\" class; what if \"Animal\" actually inherits \"speak\" from its own base? Because we are no longer using \"->\" to access \"speak\", the special method look up mechanism wouldn't be used, so \"speak\" wouldn't even be found! The second problem is more subtle: \"Animal\" is now hardwired into the subroutine selection. Let's assume that \"Animal::speak\" does exist. What happens when, at a later time, someone expands the class hierarchy by having \"Mouse\" inherit from \"Mus\" instead of \"Animal\". Unless the invocation of \"Animal::speak\" is also changed to an invocation of \"Mus::speak\", centuries worth of taxonomical classification could be obliterated! What we have here is a fragile or leaky abstraction; it is the beginning of a maintenance nightmare. What we need is the ability to search for the right method wih as few assumptions as possible. Starting the search from a different place A better solution is to tell Perl where in the inheritance chain to begin searching for \"speak\". This can be achieved with a modified version of the method arrow \"->\": ClassName->FirstPlaceToLook::method So, the improved \"Mouse\" class is: # same Animal as before\n{ package Mouse;\n  # same @ISA, &sound as before\n  sub speak {\n    my $class = shift;\n    $class->Animal::speak;\n    print \"[but you can barely hear it!]\\n\";\n  }\n} Using this syntax, we start with \"Animal\" to find \"speak\", and then use all of \"Animal\"'s inheritance chain if it is not found immediately. As usual, the first parameter to \"speak\" would be $class, so we no longer need to pass $class explicitly to \"speak\". But what about the second problem? We're still hardwiring \"Animal\" into the method lookup. The SUPER way of doing things If \"Animal\" is replaced with the special placeholder \"SUPER\" in that invocation, then the contents of \"Mouse\"'s @ISA are used for the search, beginning with $ISA[0]. So, all of the problems can be fixed as follows: # same Animal as before\n{ package Mouse;\n  # same @ISA, &sound as before\n  sub speak {\n    my $class = shift;\n    $class->SUPER::speak;\n    print \"[but you can barely hear it!]\\n\";\n  }\n} In general, \"SUPER::speak\" means look in the current package's @ISA for a class that implements \"speak\", and invoke the first one found. The placeholder is called \"SUPER\", because many other languages refer to base classes as \" superclasses\", and Perl likes to be eclectic. Note that a call such as $class->SUPER::method; does not look in the @ISA of $class unless $class happens to be the current package. Let's review... So far, we've seen the method arrow syntax: Class->method(@args); or the equivalent: $a = \"Class\";\n$a->method(@args); which constructs an argument list of: (\"Class\", @args) and attempts to invoke: Class::method(\"Class\", @args); However, if \"Class::method\" is not found, then @Class::ISA is examined (recursively) to locate a class (a package) that does indeed contain \"method\", and that subroutine is invoked instead. Using this simple syntax, we have class methods, (multiple) inheritance, overriding, and extending. Using just what we've seen so far, we've been able to factor out common code (though that's never a good reason for inheritance!), and provide a nice way to reuse implementations with variations. Now, what about data? A horse is a horse, of course of course -- or is it? Let's start with the code for the \"Animal\" class and the \"Horse\" class: { package Animal;\n  sub speak {\n    my $class = shift;\n    print \"a $class goes \", $class->sound, \"!\\n\";\n  }\n}\n{ package Horse;\n  @ISA = qw(Animal);\n  sub sound { \"neigh\" }\n} This lets us invoke \"Horse->speak\" to ripple upward to \"Animal::speak\", calling back to \"Horse::sound\" to get the specific sound, and the output of: a Horse goes neigh! But all of our Horse objects would have to be absolutely identical. If we add a subroutine, all horses automatically share it. That's great for making horses the same, but how do we capture the distinctions of an individual horse? For example, suppose we want to give our first horse a name. There's got to be a way to keep its name separate from the other horses. That is to say, we want particular instances of \"Horse\" to have different names. In Perl, any reference can be an \"instance\", so let's start with the simplest reference that can hold a horse's name: a scalar reference. my $name = \"Mr. Ed\";\nmy $horse = \\$name; So, now $horse is a reference to what will be the instance-specific data (the name). The final step is to turn this reference into a real instance of a \"Horse\" by using the special operator \"bless\": bless $horse, Horse; This operator stores information about the package named \"Horse\" into the thing pointed at by the reference. At this point, we say $horse is an instance of \"Horse\". That is, it's a specific horse. The reference is otherwise unchanged, and can still be used with traditional dereferencing operators. Invoking an instance method The method arrow can be used on instances, as well as classes (the names of packages). So, let's get the sound that $horse makes: my $noise = $horse->sound(\"some\", \"unnecessary\", \"args\"); To invoke \"sound\", Perl first notes that $horse is a blessed reference (and thus an instance). It then constructs an argument list, as per usual. Now for the fun part: Perl takes the class in which the instance was blessed, in this case \"Horse\", and uses that class to locate the subroutine. In this case, \"Horse::sound\" is found directly (without using inheritance). In the end, it is as though our initial line were written as follows: my $noise = Horse::sound($horse, \"some\", \"unnecessary\", \"args\"); Note that the first parameter here is still the instance, not the name of the class as before. We'll get \"neigh\" as the return value, and that'll end up as the $noise variable above. If Horse::sound had not been found, we'd be wandering up the @Horse::ISA array, trying to find the method in one of the superclasses. The only difference between a class method and an instance method is whether the first parameter is an instance (a blessed reference) or a class name (a string). Accessing the instance data Because we get the instance as the first parameter, we can now access the instance-specific data. In this case, let's add a way to get at the name: { package Horse;\n  @ISA = qw(Animal);\n  sub sound { \"neigh\" }\n  sub name {\n    my $self = shift;\n    $$self;\n  }\n} Inside \"Horse::name\", the @_ array contains: ($horse, \"some\", \"unnecessary\", \"args\") so the \"shift\" stores $horse into $self. Then, $self gets de-referenced with $$self as normal, yielding \"Mr. Ed\". It's traditional to \"shift\" the first parameter into a variable named $self for instance methods and into a variable named $class for class methods. Then, the following line: print $horse->name, \" says \", $horse->sound, \"\\n\"; outputs: Mr. Ed says neigh. How to build a horse Of course, if we constructed all of our horses by hand, we'd most likely make mistakes from time to time. We're also violating one of the properties of object-oriented programming, in that the \"inside guts\" of a Horse are visible. That's good if you're a veterinarian, but not if you just like to own horses. So, let's have the Horse class handle the details inside a class method: { package Horse;\n  @ISA = qw(Animal);\n  sub sound { \"neigh\" }\n  sub name {\n    my $self = shift;     # instance method, so use $self\n    $$self;\n  }\n  sub named {\n    my $class = shift;    # class method, so use $class\n    my $name = shift;\n    bless \\$name, $class;\n  }\n} Now with the new \"named\" method, we can build a horse as follows: my $horse = Horse->named(\"Mr. Ed\"); Notice we're back to a class method, so the two arguments to \"Horse::named\" are \"Horse\" and \"Mr. Ed\". The \"bless\" operator not only blesses \"\\$name\", it also returns that reference. This \"Horse::named\" method is called a \"constructor\". We've called the constructor \"named\" here, so that it quickly denotes the constructor's argument as the name for this particular \"Horse\". You can use different constructors with different names for different ways of \"giving birth\" to the object (like maybe recording its pedigree or date of birth). However, you'll find that most people coming to Perl from more limited languages use a single constructor named \"new\", with various ways of interpreting the arguments to \"new\". Either style is fine, as long as you document your particular way of giving birth to an object. (And you were going to do that, right?) Inheriting the constructor But was there anything specific to \"Horse\" in that method? No. Therefore, it's also the same recipe for building anything else that inherited from \"Animal\", so let's put \"name\" and \"named\" there: { package Animal;\n  sub speak {\n    my $class = shift;\n    print \"a $class goes \", $class->sound, \"!\\n\";\n  }\n  sub name {\n    my $self = shift;\n    $$self;\n  }\n  sub named {\n    my $class = shift;\n    my $name = shift;\n    bless \\$name, $class;\n  }\n}\n{ package Horse;\n  @ISA = qw(Animal);\n  sub sound { \"neigh\" }\n} Ahh, but what happens if we invoke \"speak\" on an instance? my $horse = Horse->named(\"Mr. Ed\");\n$horse->speak; We get a debugging value: a Horse=SCALAR(0xaca42ac) goes neigh! Why? Because the \"Animal::speak\" routine is expecting a classname as its first parameter, not an instance. When the instance is passed in, we'll end up using a blessed scalar reference as a string, and that shows up as we saw it just now. Making a method work with either classes or instances All we need is for a method to detect if it is being called on a class or called on an instance. The most straightforward way is with the \"ref\" operator. This returns a string (the classname) when used on a blessed reference, and an empty string when used on a string (like a classname). Let's modify the \"name\" method first to notice the change: sub name {\n  my $either = shift;\n  ref $either ? $$either : \"Any $either\";\n} Here, the \"?:\" operator comes in handy to select either the dereference or a derived string. Now we can use this with either an instance or a class. Note that I've changed the first parameter holder to $either to show that this is intended: my $horse = Horse->named(\"Mr. Ed\");\nprint Horse->name, \"\\n\"; # prints \"Any Horse\\n\"\nprint $horse->name, \"\\n\"; # prints \"Mr Ed.\\n\" and now we'll fix \"speak\" to use this: sub speak {\n  my $either = shift;\n  print $either->name, \" goes \", $either->sound, \"\\n\";\n} And since \"sound\" already worked with either a class or an instance, we're done! Adding parameters to a method Let's train our animals to eat: { package Animal;\n  sub named {\n    my $class = shift;\n    my $name = shift;\n    bless \\$name, $class;\n  }\n  sub name {\n    my $either = shift;\n    ref $either ? $$either : \"Any $either\";\n  }\n  sub speak {\n    my $either = shift;\n    print $either->name, \" goes \", $either->sound, \"\\n\";\n  }\n  sub eat {\n    my $either = shift;\n    my $food = shift;\n    print $either->name, \" eats $food.\\n\";\n  }\n}\n{ package Horse;\n  @ISA = qw(Animal);\n  sub sound { \"neigh\" }\n}\n{ package Sheep;\n  @ISA = qw(Animal);\n  sub sound { \"baaaah\" }\n} And now try it out: my $horse = Horse->named(\"Mr. Ed\");\n$horse->eat(\"hay\");\nSheep->eat(\"grass\"); which prints: Mr. Ed eats hay.\nAny Sheep eats grass. An instance method with parameters gets invoked with the instance, and then the list of parameters. So that first invocation is like: Animal::eat($horse, \"hay\"); More interesting instances What if an instance needs more data? Most interesting instances are made of many items, each of which can in turn be a reference or even another object. The easiest way to store these is often in a hash. The keys of the hash serve as the names of parts of the object (often called \"instance variables\" or \"member variables\"), and the corresponding values are, well, the values. But how do we turn the horse into a hash? Recall that an object was any blessed reference. We can just as easily make it a blessed hash reference as a blessed scalar reference, as long as everything that looks at the reference is changed accordingly. Let's make a sheep that has a name and a color: my $bad = bless { Name => \"Evil\", Color => \"black\" }, Sheep; so \"$bad->{Name}\" has \"Evil\", and \"$bad->{Color}\" has \"black\". But we want to make \"$bad->name\" access the name, and that's now messed up because it's expecting a scalar reference. Not to worry, because that's pretty easy to fix up. One solution is to override \"Animal::name\" and \"Animal::named\" by defining them anew in \"Sheep\", but then any methods added later to \"Animal\" might still mess up, and we'd have to override all of those too. Therefore, it's never a good idea to define the data layout in a way that's different from the data layout of the base classes. In fact, it's a good idea to use blessed hash references in all cases. Also, this is why it's important to have constructors do the low-level work. So, let's redefine \"Animal\": ## in Animal\nsub name {\n  my $either = shift;\n  ref $either ? $either->{Name} : \"Any $either\";\n}\nsub named {\n  my $class = shift;\n  my $name = shift;\n  my $self = { Name => $name };\n  bless $self, $class;\n} Of course, we still need to override \"named\" in order to handle constructing a \"Sheep\" with a certain color: ## in Sheep\nsub named {\n  my ($class, $name) = @_;\n  my $self = $class->SUPER::named(@_);\n  $$self{Color} = $class->default_color;\n  $self\n} (Note that @_ contains the parameters to \"named\".) What's this \"default_color\"? Well, if \"named\" has only the name, we still need to set a color, so we'll have a class-specific default color. For a sheep, we might define it as white: ## in Sheep\nsub default_color { \"white\" } Now: my $sheep = Sheep->named(\"Bad\");\nprint $sheep->{Color}, \"\\n\"; outputs: white Now, there's nothing particularly specific to \"Sheep\" when it comes to color, so let's remove \"Sheep::named\" and implement \"Animal::named\" to handle color instead: ## in Animal\nsub named {\n  my ($class, $name) = @_;\n  my $self = { Name => $name, Color => $class->default_color };\n  bless $self, $class;\n} And then to keep from having to define \"default_color\" for each additional class, we'll define a method that serves as the \"default default\" directly in \"Animal\": ## in Animal\nsub default_color { \"brown\" } Of course, because \"name\" and \"named\" were the only methods that referenced the \"structure\" of the object, the rest of the methods can remain the same, so \"speak\" still works as before. A horse of a different color But having all our horses be brown would be boring. So let's add a method or two to get and set the color. ## in Animal\nsub color {\n  $_[0]->{Color}\n}\nsub set_color {\n  $_[0]->{Color} = $_[1];\n} Note the alternate way of accessing the arguments: $_[0] is used in-place, rather than with a \"shift\". (This saves us a bit of time for something that may be invoked frequently.) And now we can fix that color for Mr. Ed: my $horse = Horse->named(\"Mr. Ed\");\n$horse->set_color(\"black-and-white\");\nprint $horse->name, \" is colored \", $horse->color, \"\\n\"; which results in: Mr. Ed is colored black-and-white Summary So, now we have class methods, constructors, instance methods, instance data, and even accessors. But that's still just the beginning of what Perl has to offer. We haven't even begun to talk about accessors that double as getters and setters, destructors, indirect object notation, overloading, \"isa\" and \"can\" tests, the \"UNIVERSAL\" class, and so on. That's for the rest of the Perl documentation to cover. Hopefully, this gets you started, though.","Process Name":"perlboot","Link":"https:\/\/linux.die.net\/man\/1\/perlboot"}},{"Process":{"Description":"The following collection of tricks and hints is intended to whet curious appetites about such things as the use of instance variables and the mechanics of object and class relationships. The reader is encouraged to consult relevant textbooks for discussion of Object Oriented definitions and methodology. This is not intended as a tutorial for object-oriented programming or as a comprehensive guide to Perl's object oriented features, nor should it be construed as a style guide. If you're looking for tutorials, be sure to read perlboot, perltoot, and perltooc. The Perl motto still holds: There's more than one way to do it.","Process Name":"perlbot","Link":"https:\/\/linux.die.net\/man\/1\/perlbot"}},{"Process":{"Description":"","Process Name":"perlbrew","Link":"https:\/\/linux.die.net\/man\/1\/perlbrew"}},{"Process":{"Description":"This is a ported perl for the POSIX subsystem in BS2000 VERSION OSD V3.1A or later. It may work on other versions, but we started porting and testing it with 3.1A and are currently using Version V4.0A. You may need the following GNU programs in order to install perl: gzip on BS2000 We used version 1.2.4, which could be installed out of the box with one failure during 'make check'. bison on BS2000 The yacc coming with BS2000 POSIX didn't work for us. So we had to use bison. We had to make a few changes to perl in order to use the pure (reentrant) parser of bison. We used version 1.25, but we had to add a few changes due to EBCDIC . See below for more details concerning yacc. Unpacking Perl Distribution on BS2000 To extract an ASCII tar archive on BS2000 POSIX you need an ASCII filesystem (we used the mountpoint \/usr\/local\/ascii for this). Now you extract the archive in the ASCII filesystem without I\/O-conversion: cd \/usr\/local\/ascii export IO_CONVERSION=NO gunzip < \/usr\/local\/src\/perl.tar.gz | pax -r You may ignore the error message for the first element of the archive (this doesn't look like a tar archive \/ skipping to next file...), it's only the directory which will be created automatically anyway. After extracting the archive you copy the whole directory tree to your EBCDIC filesystem. This time you use I\/O-conversion: cd \/usr\/local\/src IO_CONVERSION=YES cp -r \/usr\/local\/ascii\/perl5.005_02 .\/ Compiling Perl on BS2000 There is a \"hints\" file for BS2000 called hints.posix-bc (because posix-bc is the OS name given by 'uname') that specifies the correct values for most things. The major problem is (of course) the EBCDIC character set. We have german EBCDIC version. Because of our problems with the native yacc we used GNU bison to generate a pure (=reentrant) parser for perly.y. So our yacc is really the following script: -----8<-----\/usr\/local\/bin\/yacc-----8<----- #! \/usr\/bin\/sh # Bison as a reentrant yacc: # save parameters: params=\"\" while [[ $# -gt 1 ]]; do params=\"$params $1\" shift done # add flag %pure_parser: tmpfile=\/tmp\/bison.$$.y echo %pure_parser > $tmpfile cat $1 >> $tmpfile # call bison: echo \"\/usr\/local\/bin\/bison --yacc $params $1\\t\\t\\t(Pure Parser)\" \/usr\/local\/bin\/bison --yacc $params $tmpfile # cleanup: rm -f $tmpfile -----8<----------8<----- We still use the normal yacc for a2p.y though!!! We made a softlink called byacc to distinguish between the two versions: ln -s \/usr\/bin\/yacc \/usr\/local\/bin\/byacc We build perl using GNU make. We tried the native make once and it worked too. Testing Perl on BS2000 We still got a few errors during \"make test\". Some of them are the result of using bison. Bison prints parser error instead of syntax error, so we may ignore them. The following list shows our errors, your results may differ: op\/numconvert.......FAILED tests 1409-1440 op\/regexp...........FAILED tests 483, 496 op\/regexp_noamp.....FAILED tests 483, 496 pragma\/overload.....FAILED tests 152-153, 170-171 pragma\/warnings.....FAILED tests 14, 82, 129, 155, 192, 205, 207 lib\/bigfloat........FAILED tests 351-352, 355 lib\/bigfltpm........FAILED tests 354-355, 358 lib\/complex.........FAILED tests 267, 487 lib\/dumper..........FAILED tests 43, 45 Failed 11\/231 test scripts, 95.24% okay. 57\/10595 subtests failed, 99.46% okay. Installing Perl on BS2000 We have no nroff on BS2000 POSIX (yet), so we ignored any errors while installing the documentation. Using Perl in the Posix-Shell of BS2000 BS2000 POSIX doesn't support the shebang notation ( \"#!\/usr\/local\/bin\/perl\"), so you have to use the following lines instead: : # use perl eval 'exec \/usr\/local\/bin\/perl -S $0 ${1+\"$@\"}' if $running_under_some_shell; Using Perl in \"native\" BS2000 We don't have much experience with this yet, but try the following: Copy your Perl executable to a BS2000 LLM using bs2cp: \"bs2cp \/usr\/local\/bin\/perl 'bs2:perl(perl,l)'\" Now you can start it with the following ( SDF ) command: \"\/START-PROG FROM-FILE=*MODULE(PERL,PERL),PROG-MODE=*ANY,RUN-MODE=*ADV\" First you get the BS2000 commandline prompt ('*'). Here you may enter your parameters, e.g. \"-e 'print \"Hello World!\\\\n\";'\" (note the double backslash!) or \"-w\" and the name of your Perl script. Filenames starting with \"\/\" are searched in the Posix filesystem, others are searched in the BS2000 filesystem. You may even use wildcards if you put a \"%\" in front of your filename (e.g. \"-w checkfiles.pl %*.c\"). Read your C\/C ++ manual for additional possibilities of the commandline prompt (look for PARAMETER-PROMPTING). Floating point anomalies on BS2000 There appears to be a bug in the floating point implementation on BS2000 POSIX systems such that calling int() on the product of a number and a small magnitude number is not the same as calling int() on the quotient of that number and a large magnitude number. For example, in the following Perl code: my $x = 100000.0;\nmy $y = int($x * 1e-5) * 1e5; # '0'\nmy $z = int($x \/ 1e+5) * 1e5;  # '100000'\nprint \"\\$y is $y and \\$z is $z\\n\"; # $y is 0 and $z is 100000 Although one would expect the quantities $y and $z to be the same and equal to 100000 they will differ and instead will be 0 and 100000 respectively. Using PerlIO and different encodings on ASCII and EBCDIC partitions Since version 5.8 Perl uses the new PerlIO on BS2000 . This enables you using different encodings per IO channel. For example you may use use Encode;\nopen($f, \">:encoding(ascii)\", \"test.ascii\");\nprint $f \"Hello World!\\n\";\nopen($f, \">:encoding(posix-bc)\", \"test.ebcdic\");\nprint $f \"Hello World!\\n\";\nopen($f, \">:encoding(latin1)\", \"test.latin1\");\nprint $f \"Hello World!\\n\";\nopen($f, \">:encoding(utf8)\", \"test.utf8\");\nprint $f \"Hello World!\\n\"; to get two files containing \"Hello World!\\n\" in ASCII , EBCDIC , ISO Latin-1 (in this example identical to ASCII ) respective UTF-EBCDIC (in this example identical to normal EBCDIC ). See the documentation of Encode::PerlIO for details. As the PerlIO layer uses raw IO internally, all this totally ignores the type of your filesystem ( ASCII or EBCDIC ) and the IO_CONVERSION environment variable. If you want to get the old behavior, that the BS2000 IO functions determine conversion depending on the filesystem PerlIO still is your friend. You use IO_CONVERSION as usual and tell Perl, that it should use the native IO layer: export IO_CONVERSION=YES\nexport PERLIO=stdio Now your IO would be ASCII on ASCII partitions and EBCDIC on EBCDIC partitions. See the documentation of PerlIO (without \"Encode::\"!) for further posibilities.","Process Name":"perlbs2000","Link":"https:\/\/linux.die.net\/man\/1\/perlbs2000"}},{"Process":{"Description":"This program is designed to help you generate and send bug reports (and thank-you notes) about perl5 and the modules which ship with it. In most cases, you can just run it interactively from a command line without any special arguments and follow the prompts. If you have found a bug with a non-standard port (one that was not part of the standard distribution), a binary distribution, or a non-core module (such as Tk, DBI , etc), then please see the documentation that came with that distribution to determine the correct place to report bugs. If you are unable to send your report using perlbug (most likely because your system doesn't have a way to send mail that perlbug recognizes), you may be able to use this tool to compose your report and save it to a file which you can then send to perlbug@perl.org using your regular mail client. In extreme cases, perlbug may not work well enough on your system to guide you through composing a bug report. In those cases, you may be able to use perlbug -d to get system configuration information to include in a manually composed bug report to perlbug@perl.org. When reporting a bug, please run through this checklist: What version of Perl you are running? Type \"perl -v\" at the command line to find out. Are you running the latest released version of perl? Look at http:\/\/www.perl.org\/ to find out. If you are not using the latest released version, please try to replicate your bug on the latest stable release. Note that reports about bugs in old versions of Perl, especially those which indicate you haven't also tested the current stable release of Perl, are likely to receive less attention from the volunteers who build and maintain Perl than reports about bugs in the current release. This tool isn't apropriate for reporting bugs in any version prior to Perl 5.0. Are you sure what you have is a bug? A significant number of the bug reports we get turn out to be documented features in Perl. Make sure the issue you've run into isn't intentional by glancing through the documentation that comes with the Perl distribution. Given the sheer volume of Perl documentation, this isn't a trivial undertaking, but if you can point to documentation that suggests the behaviour you're seeing is wrong, your issue is likely to receive more attention. You may want to start with perldoc perltrap for pointers to common traps that new (and experienced) Perl programmers run into. If you're unsure of the meaning of an error message you've run across, perldoc perldiag for an explanation. If the message isn't in perldiag, it probably isn't generated by Perl. You may have luck consulting your operating system documentation instead. If you are on a non-UNIX platform perldoc perlport, as some features may be unimplemented or work differently. You may be able to figure out what's going wrong using the Perl debugger. For information about how to use the debugger perldoc perldebug. Do you have a proper test case? The easier it is to reproduce your bug, the more likely it will be fixed -- if nobody can duplicate your problem, it probably won't be addressed. A good test case has most of these attributes: short, simple code; few dependencies on external commands, modules, or libraries; no platform-dependent code (unless it's a platform-specific bug); clear, simple documentation. A good test case is almost always a good candidate to be included in Perl's test suite. If you have the time, consider writing your test case so that it can be easily included into the standard test suite. Have you included all relevant information? Be sure to include the exact error messages, if any. \"Perl gave an error\" is not an exact error message. If you get a core dump (or equivalent), you may use a debugger (dbx, gdb, etc) to produce a stack trace to include in the bug report. NOTE: unless your Perl has been compiled with debug info (often -g), the stack trace is likely to be somewhat hard to use because it will most probably contain only the function names and not their arguments. If possible, recompile your Perl with debug info and reproduce the crash and the stack trace. Can you describe the bug in plain English? The easier it is to understand a reproducible bug, the more likely it will be fixed. Any insight you can provide into the problem will help a great deal. In other words, try to analyze the problem (to the extent you can) and report your discoveries. Can you fix the bug yourself? A bug report which includes a patch to fix it will almost definitely be fixed. When sending a patch, please use the \"diff\" program with the \"-u\" option to generate \"unified\" diff files. Bug reports with patches are likely to receive significantly more attention and interest than those without patches. Your patch may be returned with requests for changes, or requests for more detailed explanations about your fix. Here are a few hints for creating high-quality patches: Make sure the patch is not reversed (the first argument to diff is typically the original file, the second argument your changed file). Make sure you test your patch by applying it with the \"patch\" program before you send it on its way. Try to follow the same style as the code you are trying to patch. Make sure your patch really does work (\"make test\", if the thing you're patching is covered by Perl's test suite). Can you use \"perlbug\" to submit the report? perlbug will, amongst other things, ensure your report includes crucial information about your version of perl. If \"perlbug\" is unable to mail your report after you have typed it in, you may have to compose the message yourself, add the output produced by \"perlbug -d\" and email it to perlbug@perl.org. If, for some reason, you cannot run \"perlbug\" at all on your system, be sure to include the entire output produced by running \"perl -V\" (note the uppercase V). Whether you use \"perlbug\" or send the email manually, please make your Subject line informative. \"a bug\" is not informative. Neither is \"perl crashes\" nor is \" HELP !!!\". These don't help. A compact description of what's wrong is fine. Can you use \"perlbug\" to submit a thank-you note? Yes, you can do this by either using the \"-T\" option, or by invoking the program as \"perlthanks\". Thank-you notes are good. It makes people smile. Having done your bit, please be prepared to wait, to be told the bug is in your code, or possibly to get no reply at all. The volunteers who maintain Perl are busy folks, so if your problem is an obvious bug in your own code, is difficult to understand or is a duplicate of an existing report, you may not receive a personal reply. If it is important to you that your bug be fixed, do monitor the perl5-porters@perl.org mailing list and the commit logs to development versions of Perl, and encourage the maintainers with kind words or offers of frosty beverages. (Please do be kind to the maintainers. Harassing or flaming them is likely to have the opposite effect of the one you want.) Feel free to update the ticket about your bug on http:\/\/rt.perl.org if a new version of Perl is released and your bug is still present.","Process Name":"perlbug","Link":"https:\/\/linux.die.net\/man\/1\/perlbug"}},{"Process":{"Description":"The purpose of this document is to show you how to call Perl subroutines directly from C, i.e., how to write callbacks. Apart from discussing the C interface provided by Perl for writing callbacks the document uses a series of examples to show how the interface actually works in practice. In addition some techniques for coding callbacks are covered. Examples where callbacks are necessary include \u2022 An Error Handler You have created an XSUB interface to an application's C API . A fairly common feature in applications is to allow you to define a C function that will be called whenever something nasty occurs. What we would like is to be able to specify a Perl subroutine that will be called instead. \u2022 An Event Driven Program The classic example of where callbacks are used is when writing an event driven program like for an X windows application. In this case you register functions to be called whenever specific events occur, e.g., a mouse button is pressed, the cursor moves into a window or a menu item is selected. Although the techniques described here are applicable when embedding Perl in a C program, this is not the primary goal of this document. There are other details that must be considered and are specific to embedding Perl. For details on embedding Perl in C refer to perlembed. Before you launch yourself head first into the rest of this document, it would be a good idea to have read the following two documents - perlxs and perlguts.","Process Name":"perlcall","Link":"https:\/\/linux.die.net\/man\/1\/perlcall"}},{"Process":{"Description":"perlcc creates standalone executables from Perl programs, using the code generators provided by the B module. At present, you may either create executable Perl bytecode, using the \"-B\" option, or generate and compile C files using the standard and 'optimised' C backends. The code generated in this way is not guaranteed to work. The whole codegen suite (\"perlcc\" included) should be considered very experimental. Use for production purposes is strongly discouraged.","Process Name":"perlcc","Link":"https:\/\/linux.die.net\/man\/1\/perlcc"}},{"Process":{"Description":"","Process Name":"perlce","Link":"https:\/\/linux.die.net\/man\/1\/perlce"}},{"Process":{"Description":"This 'cheat sheet' is a handy reference, meant for beginning Perl programmers. Not everything is mentioned, but 195 features may already be overwhelming. The sheet CONTEXTS  SIGILS             ARRAYS        HASHES\nvoid      $scalar   whole:   @array        %hash\nscalar    @array    slice:   @array[0, 2]  @hash{'a', 'b'}\nlist      %hash     element: $array[0]     $hash{'a'}\n          &sub\n          *glob    SCALAR VALUES\n                   number, string, reference, glob, undef\nREFERENCES\n\\     references      $$foo[1]       aka $foo->[1]\n$@%&* dereference     $$foo{bar}     aka $foo->{bar}\n[]    anon. arrayref  ${$$foo[1]}[2] aka $foo->[1]->[2]\n{}    anon. hashref   ${$$foo[1]}[2] aka $foo->[1][2]\n\\()   list of refs\n                        NUMBERS vs STRINGS  LINKS\nOPERATOR PRECEDENCE     =          =        perl.plover.com\n->                      +          .        search.cpan.org\n++ --                   == !=      eq ne         cpan.org\n**                      < > <= >=  lt gt le ge   pm.org\n! ~ \\ u+ u-             <=>        cmp           tpj.com\n=~ !~                                            perldoc.com\n* \/ % x                 SYNTAX\n+ - .                   for    (LIST) { }, for (a;b;c) { }\n<< >>                   while  ( ) { }, until ( ) { }\nnamed uops              if     ( ) { } elsif ( ) { } else { }\n< > <= >= lt gt le ge   unless ( ) { } elsif ( ) { } else { }\n== != <=> eq ne cmp     for equals foreach (ALWAYS)\n&\n| ^              REGEX METACHARS            REGEX MODIFIERS\n&&               ^     string begin         \/i case insens.\n||               $     str. end (before \\n) \/m line based ^$\n.. ...           +     one or more          \/s . includes \\n\n?:               *     zero or more         \/x ign. wh.space\n= += -= *= etc.  ?     zero or one          \/g global\n, =>             {3,7} repeat in range      \/o cmpl pat. once\nlist ops         ()    capture\nnot              (?:)  no capture       REGEX CHARCLASSES\nand              []    character class  .  == [^\\n]\nor xor           |     alternation      \\s == whitespace\n                 \\b    word boundary    \\w == word characters\n                 \\z    string end       \\d == digits\nDO                                      \\S, \\W and \\D negate\nuse strict;        DON'T\nuse warnings;      \"$foo\"           LINKS\nmy $var;           $$variable_name  perl.com\nopen() or die $!;  `$userinput`     use.perl.org\nuse Modules;       \/$userinput\/     perl.apache.org\n\nFUNCTION RETURN LISTS\nstat      localtime    caller         SPECIAL VARIABLES\n 0 dev    0 second     0 package      $_    default variable\n 1 ino    1 minute     1 filename     $0    program name\n 2 mode   2 hour       2 line         $\/    input separator\n 3 nlink  3 day        3 subroutine   $\\    output separator\n 4 uid    4 month-1    4 hasargs      $|    autoflush\n 5 gid    5 year-1900  5 wantarray    $!    sys\/libcall error\n 6 rdev   6 weekday    6 evaltext     $@    eval error\n 7 size   7 yearday    7 is_require   $$    process ID\n 8 atime  8 is_dst     8 hints        $.    line number\n 9 mtime               9 bitmask      @ARGV command line args\n10 ctime  just use                    @INC  include paths\n11 blksz  POSIX::      3..9 only      @_    subroutine args\n12 blcks  strftime!    with EXPR      %ENV  environment","Process Name":"perlcheat","Link":"https:\/\/linux.die.net\/man\/1\/perlcheat"}},{"Process":{"Description":"One thing Perl porters should note is that perl doesn't tend to use that much of the C standard library internally; you'll see very little use of, for example, the ctype.h functions in there. This is because Perl tends to reimplement or abstract standard library functions, so that we know exactly how they're going to operate. This is a reference card for people who are familiar with the C library and who want to do things the Perl way; to tell them which functions they ought to use instead of the more normal C functions. Conventions In the following tables: \"t\" is a type. \"p\" is a pointer. \"n\" is a number. \"s\" is a string. \"sv\", \"av\", \"hv\", etc. represent variables of their respective types. File Operations Instead of the stdio.h functions, you should use the Perl abstraction layer. Instead of \"FILE*\" types, you need to be handling \"PerlIO*\" types. Don't forget that with the new PerlIO layered I\/O abstraction \"FILE*\" types may not even be available. See also the \"perlapio\" documentation for more information about the following functions: Instead Of:                 Use:\n\nstdin                       PerlIO_stdin()\nstdout                      PerlIO_stdout()\nstderr                      PerlIO_stderr()\n\nfopen(fn, mode)             PerlIO_open(fn, mode)\nfreopen(fn, mode, stream)   PerlIO_reopen(fn, mode, perlio) (Deprecated)\nfflush(stream)              PerlIO_flush(perlio)\nfclose(stream)              PerlIO_close(perlio) File Input and Output Instead Of:                 Use:\n\nfprintf(stream, fmt, ...)   PerlIO_printf(perlio, fmt, ...)\n\n[f]getc(stream)             PerlIO_getc(perlio)\n[f]putc(stream, n)          PerlIO_putc(perlio, n)\nungetc(n, stream)           PerlIO_ungetc(perlio, n) Note that the PerlIO equivalents of \"fread\" and \"fwrite\" are slightly different from their C library counterparts: fread(p, size, n, stream)   PerlIO_read(perlio, buf, numbytes)\nfwrite(p, size, n, stream)  PerlIO_write(perlio, buf, numbytes)\n\nfputs(s, stream)            PerlIO_puts(perlio, s) There is no equivalent to \"fgets\"; one should use \"sv_gets\" instead: fgets(s, n, stream)         sv_gets(sv, perlio, append) File Positioning Instead Of:                 Use:\n\nfeof(stream)                PerlIO_eof(perlio)\nfseek(stream, n, whence)    PerlIO_seek(perlio, n, whence)\nrewind(stream)              PerlIO_rewind(perlio)\n\nfgetpos(stream, p)          PerlIO_getpos(perlio, sv)\nfsetpos(stream, p)          PerlIO_setpos(perlio, sv)\n\nferror(stream)              PerlIO_error(perlio)\nclearerr(stream)            PerlIO_clearerr(perlio) Memory Management and String Handling Instead Of:                         Use:\n\nt* p = malloc(n)                    Newx(id, p, n, t)\nt* p = calloc(n, s)                 Newxz(id, p, n, t)\np = realloc(p, n)                   Renew(p, n, t)\nmemcpy(dst, src, n)                 Copy(src, dst, n, t)\nmemmove(dst, src, n)                Move(src, dst, n, t)\nmemcpy(dst, src, sizeof(t))         StructCopy(src, dst, t)\nmemset(dst, 0, n * sizeof(t))       Zero(dst, n, t)\nmemzero(dst, 0)                     Zero(dst, n, char)\nfree(p)                             Safefree(p)\n\nstrdup(p)                   savepv(p)\nstrndup(p, n)               savepvn(p, n) (Hey, strndup doesn't exist!)\n\nstrstr(big, little)         instr(big, little)\nstrcmp(s1, s2)              strLE(s1, s2) \/ strEQ(s1, s2) \/ strGT(s1,s2)\nstrncmp(s1, s2, n)          strnNE(s1, s2, n) \/ strnEQ(s1, s2, n) Notice the different order of arguments to \"Copy\" and \"Move\" than used in \"memcpy\" and \"memmove\". Most of the time, though, you'll want to be dealing with SVs internally instead of raw \"char *\" strings: strlen(s)                   sv_len(sv)\nstrcpy(dt, src)             sv_setpv(sv, s)\nstrncpy(dt, src, n)         sv_setpvn(sv, s, n)\nstrcat(dt, src)             sv_catpv(sv, s)\nstrncat(dt, src)            sv_catpvn(sv, s)\nsprintf(s, fmt, ...)        sv_setpvf(sv, fmt, ...) Note also the existence of \"sv_catpvf\" and \"sv_vcatpvfn\", combining concatenation with formatting. Sometimes instead of zeroing the allocated heap by using Newxz() you should consider \"poisoning\" the data. This means writing a bit pattern into it that should be illegal as pointers (and floating point numbers), and also hopefully surprising enough as integers, so that any code attempting to use the data without forethought will break sooner rather than later. Poisoning can be done using the Poison() macros, which have similar arguments as Zero(): PoisonWith(dst, n, t, b)    scribble memory with byte b\nPoisonNew(dst, n, t)        equal to PoisonWith(dst, n, t, 0xAB)\nPoisonFree(dst, n, t)       equal to PoisonWith(dst, n, t, 0xEF)\nPoison(dst, n, t)           equal to PoisonFree(dst, n, t) Character Class Tests There are two types of character class tests that Perl implements: one type deals in \"char\"s and are thus not Unicode aware (and hence deprecated unless you know you should use them) and the other type deal in \"UV\"s and know about Unicode properties. In the following table, \"c\" is a \"char\", and \"u\" is a Unicode codepoint. Instead Of:                 Use:            But better use:\n\nisalnum(c)                  isALNUM(c)      isALNUM_uni(u)\nisalpha(c)                  isALPHA(c)      isALPHA_uni(u)\niscntrl(c)                  isCNTRL(c)      isCNTRL_uni(u)\nisdigit(c)                  isDIGIT(c)      isDIGIT_uni(u)\nisgraph(c)                  isGRAPH(c)      isGRAPH_uni(u)\nislower(c)                  isLOWER(c)      isLOWER_uni(u)\nisprint(c)                  isPRINT(c)      isPRINT_uni(u)\nispunct(c)                  isPUNCT(c)      isPUNCT_uni(u)\nisspace(c)                  isSPACE(c)      isSPACE_uni(u)\nisupper(c)                  isUPPER(c)      isUPPER_uni(u)\nisxdigit(c)                 isXDIGIT(c)     isXDIGIT_uni(u)\n\ntolower(c)                  toLOWER(c)      toLOWER_uni(u)\ntoupper(c)                  toUPPER(c)      toUPPER_uni(u) stdlib.h functions Instead Of:                 Use:\n\natof(s)                     Atof(s)\natol(s)                     Atol(s)\nstrtod(s, &p)               Nothing.  Just don't use it.\nstrtol(s, &p, n)            Strtol(s, &p, n)\nstrtoul(s, &p, n)           Strtoul(s, &p, n) Notice also the \"grok_bin\", \"grok_hex\", and \"grok_oct\" functions in numeric.c for converting strings representing numbers in the respective bases into \"NV\"s. In theory \"Strtol\" and \"Strtoul\" may not be defined if the machine perl is built on doesn't actually have strtol and strtoul. But as those 2 functions are part of the 1989 ANSI C spec we suspect you'll find them everywhere by now. int rand()                  double Drand01()\nsrand(n)                    { seedDrand01((Rand_seed_t)n);\n                              PL_srand_called = TRUE; }\n\nexit(n)                     my_exit(n)\nsystem(s)                   Don't. Look at pp_system or use my_popen\n\ngetenv(s)                   PerlEnv_getenv(s)\nsetenv(s, val)              my_putenv(s, val) Miscellaneous functions You should not even want to use setjmp.h functions, but if you think you do, use the \"JMPENV\" stack in scope.h instead. For \"signal\"\/\"sigaction\", use \"rsignal(signo, handler)\".","Process Name":"perlclib","Link":"https:\/\/linux.die.net\/man\/1\/perlclib"}},{"Process":{"Description":"XXXXXXXXX Perl XXXXXXX ! XX 5.8.0 XXXXXXX , Perl XXXXXXXXXXXXXXX Unicode ( XXXXXXX ) XXXXXX , XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX ; CJK ( XXXXXXX ) XXXXXXXXXXXXXXXXX . Unicode XXXXXXXXXXXXXXXXXXX , XXXXXXXXXXXXXXXXXXXXXXXXXXXXX: XXXXXXXXX , XXXXXXXXXX , XXXXXXXXXXXXXXXXXX ( XXXXXXXX , XXXXXXXXXXX , XXXXXXXXXX , XXXXXXXXX , XXXXXXX , XXXXXXXXXX , XXXX ). XXXXXXXXXXXXXXXXXXXXXXXXXXX ( XX PC XXXXXXXXXX ). Perl XXXXXXX Unicode XXXXXXXXX . XXXXX Perl XXXXXXXXXXXXXXXXXXXXXXXX Unicode XXX ; Perl XXXXXXXXXXXXXX ( XXXXXXXXXXXXXXXXX ) XXXXXXX Unicode XXXXXXXXX . XXXXXXXXXXXXXXXXX , XXXXXXXXXXX Unicode XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX , Perl XXXXXXX Encode XXXXXXXX , XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX . Encode XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX ('gb2312' XXX 'euc-cn'): euc-cn      Unix XXXXXXXXXX, XXXXXXXXXXXXXXXXXXXX\ngb2312-raw  XXXXXXXXXXXXX (XXXXXXX) GB2312 XXXXX\ngb12345     XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\niso-ir-165  GB2312 + GB6345 + GB8565 + XXXXXXXX\ncp936       XXXXXXX 936, XXXXXXXXX 'GBK' (XXXXXXXXXXXXX) XXXXXX\nhz          7 XXXXXXXXXXX GB2312 XXXXX XXXXXXXXX , XX EUC-CN XXXXXXXXXXXXXXXXX Unicode, XXXXXXXXXXXXXXXXXXXXX: perl -Mencoding=euc-cn,STDOUT,utf8 -pe1 < file.euc-cn > file.utf8 Perl XXXXXXXXXX \"piconv\", XXXXXXXXXXX Perl XXXXXXXXXXXXXXXXXXXXXXXXXX , XXXXXXXXX: piconv -f euc-cn -t utf8 < file.euc-cn > file.utf8\npiconv -f utf8 -t euc-cn < file.utf8 > file.euc-cn XXXXX , XXXXX encoding XXXX , XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX , XXXXXXXXX: #!\/usr\/bin\/env perl\n# XXXXXX euc-cn XXXXXXXX; XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX euc-cn XXXXX\nuse encoding 'euc-cn', STDIN => 'euc-cn', STDOUT => 'euc-cn';\nprint length(\"XXXX\");            #  2 (XXXXXXXXXXXXXXX)\nprint length('XXXX');            #  4 (XXXXXXXXXXXXXXXX)\nprint index(\"XXXXXXXXX\", \"XXXXXX\"); # -1 (XXXXXXXXXXXXXXXXXX)\nprint index('XXXXXXXXX', 'XXXXXX'); #  1 (XXXXXXXXXXXXXXXXX) XXXXXXXXXXXXXXXXXXXX , \" XX \" XXXXXXXXXXXXXXXX \" XX \" XXXXXXXXXXXXXXXXXXXXXX EUC-CN XXXXXX \" XXX \"; \" XX \" XXXXXXXXXXXXXXXXXXX \" XXX \" XXXXXXXXXXXXXXXXXXXXXX \" XXX \". XXXXXXXXXXXX EUC-CN XXXXXXXXXXXXXXXXXXXXXXXXXX . XXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXXXXX , XXXXXXX CPAN (< http:\/\/www.cpan.org\/>) XXX Encode::HanExtra XXXX . XXXXXXXXXXXXXXXXXXXXXXXXXXXX: gb18030     XXXXXXXXXXXXXXXXXX, XXXXXXXXXXXXXXX XXXXX , Encode::HanConvert XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX: big5-simp   Big5 XXXXXXXXXXX Unicode XXXXXXXXXXXXX\ngbk-trad    GBK XXXXXXXXXXX Unicode XXXXXXXXXXXXX XXXXXXX GBK XX Big5 XXXXXXXXX , XXXXXXXXXXXXXXXXXXXXXX b2g.pl XX g2b.pl XXXXXXXX , XXXXXXXXXXXXXXXXXXXXXXXXXXX: use Encode::HanConvert;\n$euc_cn = big5_to_gb($big5); # XX Big5 XXXX GBK\n$big5 = gb_to_big5($euc_cn); # XX GBK XXXX Big5 XXXXXXXXXXXX XXXXXXX Perl XXXXXXXXXXXXXXXXXXXXXX ( XXXXXXXXXXXXXXXXXXXXX ), XXXXXXXXXXXXXXXXX Perl XXXXXXXX , XXXX Unicode XXXXXXXXXXX . XXXX , XXXXXXXXXXXXXXXXXXXX: XXXXX Perl XXXXXXXXXXXX < http:\/\/www.perl.com\/> Perl XXXXXXX ( XXXXXXXXXXXXXXXXXX ) < http:\/\/www.cpan.org\/> Perl XXXXXXXXXXX (Comprehensive Perl Archive Network) < http:\/\/lists.perl.org\/> Perl XXXXXXXXXXXXXX XXXX Perl XXXXXXXX < http:\/\/www.oreilly.com.cn\/html\/perl.html> XXXXXXXXXXXXXXXXXXXX Perl XXXXX Perl XXXXXXXXXXX < http:\/\/www.pm.org\/groups\/asia.html> XXXXX Perl XXXXXXXXXX Unicode XXXXXXXXXX < http:\/\/www.unicode.org\/> Unicode XXXXXXXXX (Unicode XXXXXXXXXXXXXXXXX ) < http:\/\/www.cl.cam.ac.uk\/%7Emgk25\/unicode.html> Unix\/Linux XXXXX UTF-8 XXX Unicode XXXXXX","Process Name":"perlcn","Link":"https:\/\/linux.die.net\/man\/1\/perlcn"}},{"Process":{"Description":"This document aims to provide an overview of the vast perl community, which is far too large and diverse to provide a detailed listing. If any specific niche has been forgotten, it is not meant as an insult but an omission for the sake of brevity. The Perl community is as diverse as Perl, and there is a large amount of evidence that the Perl users apply TMTOWTDI to all endeavors, not just programming. From websites, to IRC , to mailing lists, there is more than one way to get involved in the community. Where to find the community There is a central directory for the Perl community: < http:\/\/perl.org> maintained by the Perl Foundation (< http:\/\/www.perlfoundation.org\/>), which tracks and provides services for a variety of other community sites. Mailing lists and Newsgroups Perl runs on e-mail, there is no doubt about it. The Camel book was originally written mostly over e-mail and today Perl's development is co-ordinated through mailing lists. The largest repository of Perl mailing lists is located at < http:\/\/lists.perl.org>. Most Perl-related projects set up mailing lists for both users and contributors. If you don't see a certain project listed at <http:\/\/lists.perl.org>, check the particular website for that project. Most mailing lists are archived at <http:\/\/nntp.perl.org\/>. There are also plenty of Perl related newsgroups located under \"comp.lang.perl.*\". IRC The Perl community has a rather large IRC presence. For starters, it has its own IRC network, <irc:\/\/irc.perl.org>. General (not help-oriented) chat can be found at <irc:\/\/irc.perl.org\/#perl>. Many other more specific chats are also hosted on the network. Information about irc.perl.org is located on the network's website: < http:\/\/www.irc.perl.org>. For a more help oriented #perl, check out <irc:\/\/irc.freenode.net\/#perl>. Perl 6 development also has a presence in <irc:\/\/irc.freenode.net\/#perl6>. Most Perl-related channels will be kind enough to point you in the right direction if you ask nicely. Any large IRC network (Dalnet, EFnet) is also likely to have a #perl channel, with varying activity levels. Websites Perl websites come in a variety of forms, but they fit into two large categories: forums and news websites. There are many Perl related websites, so only a few of the community's largest are mentioned here. News sites < http:\/\/perl.com\/> Run by O'Reilly Media (The publisher of the Camel Book among other Perl-related literature), perl.com provides current Perl news, articles, and resources for Perl developers as well as a directory of other useful websites. < http:\/\/use.perl.org\/> use Perl; provides a slashdot-style Perl news website covering all things Perl, from minutes of the meetings of the Perl 6 Design team to conference announcements with (ir)relevant discussion. Forums < http:\/\/www.perlmonks.org\/> PerlMonks is one of the largest Perl forums, and describes itself as \"A place for individuals to polish, improve, and showcase their Perl skills.\" and \"A community which allows everyone to grow and learn from each other.\" User Groups Many cities around the world have local Perl Mongers chapters. A Perl Mongers chapter is a local user group which typically holds regular in-person meetings, both social and technical; helps organize local conferences, workshops, and hackathons; and provides a mailing list or other continual contact method for its members to keep in touch. To find your local Perl Mongers (or PM as they're commonly abbreviated) group check the international Perl Mongers directory at <http:\/\/www.pm.org\/>. Workshops Perl workshops are, as the name might suggest, workshops where Perl is taught in a variety of ways. At the workshops, subjects range from a beginner's introduction (such as the Pittsburgh Perl Workshop's \"Zero To Perl\") to much more advanced subjects. There are several great resources for locating workshops: the websites mentioned above, the calendar mentioned below, and the YAPC Europe website, <http:\/\/www.yapceurope.org\/>, which is probably the best resource for European Perl events. Hackathons Hackathons are a very different kind of gathering where Perl hackers gather to do just that, hack nonstop for an extended (several day) period on a specific project or projects. Information about hackathons can be located in the same place as information about workshops as well as in <irc:\/\/irc.perl.org\/#perl>. If you have never been to a hackathon, here are a few basic things you need to know before attending: have a working laptop and know how to use it; check out the involved projects before hand; have the necessary version control client; and bring backup equipment (an extra LAN cable, additional power strips, etc.) because someone will forget. Conventions Perl has two major annual conventions: The Perl Conference (now part of OSCON ), put on by O'Reilly, and Yet Another Perl Conference or YAPC (pronounced yap-see), which is localized into several regional YAPCs (North America, Europe, Asia) in a stunning grassroots display by the Perl community. For more information about either conference, check out their respective web pages: OSCON < http:\/\/conferences.oreillynet.com\/>; YAPC < http:\/\/www.yapc.org>. A relatively new conference franchise with a large Perl portion is the Open Source Developers Conference or OSDC . First held in Australia it has recently also spread to Israel. More information can be found at: <http:\/\/www.osdc.com.au\/> for Australia, and <http:\/\/www.osdc.org.il> for Israel. Calendar of Perl Events The Perl Review, < http:\/\/www.theperlreview.com> maintains a website and Google calendar (< http:\/\/www.theperlreview.com\/community_calendar>) for tracking workshops, hackathons, Perl Mongers meetings, and other events. Views of this calendar are at < http:\/\/www.perl.org\/events.html> and < http:\/\/www.yapc.org>. Not every event or Perl Mongers group is on that calendar, so don't lose heart if you don't see yours posted. To have your event or group listed, contact brian d foy (brian@theperlreview.com).","Process Name":"perlcommunity","Link":"https:\/\/linux.die.net\/man\/1\/perlcommunity"}},{"Process":{"Description":"Perl has always had a compiler: your source is compiled into an internal form (a parse tree) which is then optimized before being run. Since version 5.005, Perl has shipped with a module capable of inspecting the optimized parse tree (\"B\"), and this has been used to write many useful utilities, including a module that lets you turn your Perl into C source code that can be compiled into a native executable. The \"B\" module provides access to the parse tree, and other modules (\"back ends\") do things with the tree. Some write it out as semi-human-readable text. Another traverses the parse tree to build a cross-reference of which subroutines, formats, and variables are used where. Another checks your code for dubious constructs. Yet another back end dumps the parse tree back out as Perl source, acting as a source code beautifier or deobfuscator. Because its original purpose was to be a way to produce C code corresponding to a Perl program, and in turn a native executable, the \"B\" module and its associated back ends are known as \"the compiler\", even though they don't really compile anything. Different parts of the compiler are more accurately a \"translator\", or an \"inspector\", but people want Perl to have a \"compiler option\" not an \"inspector gadget\". What can you do? This document covers the use of the Perl compiler: which modules it comprises, how to use the most important of the back end modules, what problems there are, and how to work around them. Layout The compiler back ends are in the \"B::\" hierarchy, and the front-end (the module that you, the user of the compiler, will sometimes interact with) is the O module. Here are the important back ends to know about, with their status expressed as a number from 0 (outline for later implementation) to 10 (if there's a bug in it, we're very surprised): B::Lint Complains if it finds dubious constructs in your source code. Status: 6 (it works adequately, but only has a very limited number of areas that it checks). B::Deparse Recreates the Perl source, making an attempt to format it coherently. Status: 8 (it works nicely, but a few obscure things are missing). B::Xref Reports on the declaration and use of subroutines and variables. Status: 8 (it works nicely, but still has a few lingering bugs).","Process Name":"perlcompile","Link":"https:\/\/linux.die.net\/man\/1\/perlcompile"}},{"Process":{"Description":"\"perlcritic\" is a Perl source code analyzer. It is the executable front-end to the Perl::Critic engine, which attempts to identify awkward, hard to read, error-prone, or unconventional constructs in your code. Most of the rules are based on Damian Conway's book Perl Best Practices. However, \"perlcritic\" is not limited to enforcing PBP , and it will even support rules that contradict Conway. All rules can easily be configured or disabled to your liking. This documentation only covers how to drive this command. For all other information, including how to persistently configure this command so that you don't have to say so much on the command-line, see the documentation for Perl::Critic itself.","Process Name":"perlcritic","Link":"https:\/\/linux.die.net\/man\/1\/perlcritic"}},{"Process":{"Description":"","Process Name":"perlcygwin","Link":"https:\/\/linux.die.net\/man\/1\/perlcygwin"}},{"Process":{"Description":"Variable names Perl has three built-in data types: scalars, arrays of scalars, and associative arrays of scalars, known as \"hashes\". A scalar is a single string (of any size, limited only by the available memory), number, or a reference to something (which will be discussed in perlref). Normal arrays are ordered lists of scalars indexed by number, starting with 0. Hashes are unordered collections of scalar values indexed by their associated string key. Values are usually referred to by name, or through a named reference. The first character of the name tells you to what sort of data structure it refers. The rest of the name tells you the particular value to which it refers. Usually this name is a single identifier, that is, a string beginning with a letter or underscore, and containing letters, underscores, and digits. In some cases, it may be a chain of identifiers, separated by \"::\" (or by the slightly archaic \"'\"); all but the last are interpreted as names of packages, to locate the namespace in which to look up the final identifier (see \"Packages\" in perlmod for details). It's possible to substitute for a simple identifier, an expression that produces a reference to the value at runtime. This is described in more detail below and in perlref. Perl also has its own built-in variables whose names don't follow these rules. They have strange names so they don't accidentally collide with one of your normal variables. Strings that match parenthesized parts of a regular expression are saved under names containing only digits after the \"$\" (see perlop and perlre). In addition, several special variables that provide windows into the inner working of Perl have names containing punctuation characters and control characters. These are documented in perlvar. Scalar values are always named with '$', even when referring to a scalar that is part of an array or a hash. The '$' symbol works semantically like the English word \"the\" in that it indicates a single value is expected. $days               # the simple scalar value \"days\"\n$days[28]           # the 29th element of array @days\n$days{'Feb'}        # the 'Feb' value from hash %days\n$#days              # the last index of array @days Entire arrays (and slices of arrays and hashes) are denoted by '@', which works much like the word \"these\" or \"those\" does in English, in that it indicates multiple values are expected. @days               # ($days[0], $days[1],... $days[n])\n@days[3,4,5]        # same as ($days[3],$days[4],$days[5])\n@days{'a','c'}      # same as ($days{'a'},$days{'c'}) Entire hashes are denoted by '%': %days               # (key1, val1, key2, val2 ...) In addition, subroutines are named with an initial '&', though this is optional when unambiguous, just as the word \"do\" is often redundant in English. Symbol table entries can be named with an initial '*', but you don't really care about that yet (if ever :-). Every variable type has its own namespace, as do several non-variable identifiers. This means that you can, without fear of conflict, use the same name for a scalar variable, an array, or a hash--or, for that matter, for a filehandle, a directory handle, a subroutine name, a format name, or a label. This means that $foo and @foo are two different variables. It also means that $foo[1] is a part of @foo, not a part of $foo. This may seem a bit weird, but that's okay, because it is weird. Because variable references always start with '$', '@', or '%', the \"reserved\" words aren't in fact reserved with respect to variable names. They are reserved with respect to labels and filehandles, however, which don't have an initial special character. You can't have a filehandle named \"log\", for instance. Hint: you could say \"open(LOG,'logfile')\" rather than \"open(log,'logfile')\". Using uppercase filehandles also improves readability and protects you from conflict with future reserved words. Case is significant--\" FOO \", \"Foo\", and \"foo\" are all different names. Names that start with a letter or underscore may also contain digits and underscores. It is possible to replace such an alphanumeric name with an expression that returns a reference to the appropriate type. For a description of this, see perlref. Names that start with a digit may contain only more digits. Names that do not start with a letter, underscore, digit or a caret (i.e. a control character) are limited to one character, e.g., $% or $$. (Most of these one character names have a predefined significance to Perl. For instance, $$ is the current process id.) Context The interpretation of operations and values in Perl sometimes depends on the requirements of the context around the operation or value. There are two major contexts: list and scalar. Certain operations return list values in contexts wanting a list, and scalar values otherwise. If this is true of an operation it will be mentioned in the documentation for that operation. In other words, Perl overloads certain operations based on whether the expected return value is singular or plural. Some words in English work this way, like \"fish\" and \"sheep\". In a reciprocal fashion, an operation provides either a scalar or a list context to each of its arguments. For example, if you say int( <STDIN> ) the integer operation provides scalar context for the <> operator, which responds by reading one line from STDIN and passing it back to the integer operation, which will then find the integer value of that line and return that. If, on the other hand, you say sort( <STDIN> ) then the sort operation provides list context for <>, which will proceed to read every line available up to the end of file, and pass that list of lines back to the sort routine, which will then sort those lines and return them as a list to whatever the context of the sort was. Assignment is a little bit special in that it uses its left argument to determine the context for the right argument. Assignment to a scalar evaluates the right-hand side in scalar context, while assignment to an array or hash evaluates the righthand side in list context. Assignment to a list (or slice, which is just a list anyway) also evaluates the righthand side in list context. When you use the \"use warnings\" pragma or Perl's -w command-line option, you may see warnings about useless uses of constants or functions in \"void context\". Void context just means the value has been discarded, such as a statement containing only \"\"fred\";\" or \"getpwuid(0);\". It still counts as scalar context for functions that care whether or not they're being called in list context. User-defined subroutines may choose to care whether they are being called in a void, scalar, or list context. Most subroutines do not need to bother, though. That's because both scalars and lists are automatically interpolated into lists. See \"wantarray\" in perlfunc for how you would dynamically discern your function's calling context. Scalar values All data in Perl is a scalar, an array of scalars, or a hash of scalars. A scalar may contain one single value in any of three different flavors: a number, a string, or a reference. In general, conversion from one form to another is transparent. Although a scalar may not directly hold multiple values, it may contain a reference to an array or hash which in turn contains multiple values. Scalars aren't necessarily one thing or another. There's no place to declare a scalar variable to be of type \"string\", type \"number\", type \"reference\", or anything else. Because of the automatic conversion of scalars, operations that return scalars don't need to care (and in fact, cannot care) whether their caller is looking for a string, a number, or a reference. Perl is a contextually polymorphic language whose scalars can be strings, numbers, or references (which includes objects). Although strings and numbers are considered pretty much the same thing for nearly all purposes, references are strongly-typed, uncastable pointers with builtin reference-counting and destructor invocation. A scalar value is interpreted as TRUE in the Boolean sense if it is not the null string or the number 0 (or its string equivalent, \"0\"). The Boolean context is just a special kind of scalar context where no conversion to a string or a number is ever performed. There are actually two varieties of null strings (sometimes referred to as \"empty\" strings), a defined one and an undefined one. The defined version is just a string of length zero, such as \"\". The undefined version is the value that indicates that there is no real value for something, such as when there was an error, or at end of file, or when you refer to an uninitialized variable or element of an array or hash. Although in early versions of Perl, an undefined scalar could become defined when first used in a place expecting a defined value, this no longer happens except for rare cases of autovivification as explained in perlref. You can use the defined() operator to determine whether a scalar value is defined (this has no meaning on arrays or hashes), and the undef() operator to produce an undefined value. To find out whether a given string is a valid non-zero number, it's sometimes enough to test it against both numeric 0 and also lexical \"0\" (although this will cause noises if warnings are on). That's because strings that aren't numbers count as 0, just as they do in awk: if ($str == 0 && $str ne \"0\")  {\n    warn \"That doesn't look like a number\";\n} That method may be best because otherwise you won't treat IEEE notations like \"NaN\" or \"Infinity\" properly. At other times, you might prefer to determine whether string data can be used numerically by calling the POSIX::strtod() function or by inspecting your string with a regular expression (as documented in perlre). warn \"has nondigits\"        if     \/\\D\/;\nwarn \"not a natural number\" unless \/^\\d+$\/;             # rejects -3\nwarn \"not an integer\"       unless \/^-?\\d+$\/;           # rejects +3\nwarn \"not an integer\"       unless \/^[+-]?\\d+$\/;\nwarn \"not a decimal number\" unless \/^-?\\d+\\.?\\d*$\/;     # rejects .2\nwarn \"not a decimal number\" unless \/^-?(?:\\d+(?:\\.\\d*)?|\\.\\d+)$\/;\nwarn \"not a C float\"\n    unless \/^([+-]?)(?=\\d|\\.\\d)\\d*(\\.\\d*)?([Ee]([+-]?\\d+))?$\/; The length of an array is a scalar value. You may find the length of array @days by evaluating $#days, as in csh. However, this isn't the length of the array; it's the subscript of the last element, which is a different value since there is ordinarily a 0th element. Assigning to $#days actually changes the length of the array. Shortening an array this way destroys intervening values. Lengthening an array that was previously shortened does not recover values that were in those elements. (It used to do so in Perl 4, but we had to break this to make sure destructors were called when expected.) You can also gain some minuscule measure of efficiency by pre-extending an array that is going to get big. You can also extend an array by assigning to an element that is off the end of the array. You can truncate an array down to nothing by assigning the null list () to it. The following are equivalent: @whatever = ();\n$#whatever = -1; If you evaluate an array in scalar context, it returns the length of the array. (Note that this is not true of lists, which return the last value, like the C comma operator, nor of built-in functions, which return whatever they feel like returning.) The following is always true: scalar(@whatever) == $#whatever - $[ + 1; Version 5 of Perl changed the semantics of $[: files that don't set the value of $[ no longer need to worry about whether another file changed its value. (In other words, use of $[ is deprecated.) So in general you can assume that scalar(@whatever) == $#whatever + 1; Some programmers choose to use an explicit conversion so as to leave nothing to doubt: $element_count = scalar(@whatever); If you evaluate a hash in scalar context, it returns false if the hash is empty. If there are any key\/value pairs, it returns true; more precisely, the value returned is a string consisting of the number of used buckets and the number of allocated buckets, separated by a slash. This is pretty much useful only to find out whether Perl's internal hashing algorithm is performing poorly on your data set. For example, you stick 10,000 things in a hash, but evaluating %HASH in scalar context reveals \"1\/16\", which means only one out of sixteen buckets has been touched, and presumably contains all 10,000 of your items. This isn't supposed to happen. If a tied hash is evaluated in scalar context, a fatal error will result, since this bucket usage information is currently not available for tied hashes. You can preallocate space for a hash by assigning to the keys() function. This rounds up the allocated buckets to the next power of two: keys(%users) = 1000;                # allocate 1024 buckets Scalar value constructors Numeric literals are specified in any of the following floating point or integer formats: 12345\n12345.67\n.23E-10             # a very small number\n3.14_15_92          # a very important number\n4_294_967_296       # underscore for legibility\n0xff                # hex\n0xdead_beef         # more hex\n0377                # octal (only numbers, begins with 0)\n0b011011            # binary You are allowed to use underscores (underbars) in numeric literals between digits for legibility. You could, for example, group binary digits by threes (as for a Unix-style mode argument such as 0b110_100_100) or by fours (to represent nibbles, as in 0b1010_0110) or in other groups. String literals are usually delimited by either single or double quotes. They work much like quotes in the standard Unix shells: double-quoted string literals are subject to backslash and variable substitution; single-quoted strings are not (except for \"\\'\" and \"\\\\\"). The usual C-style backslash rules apply for making characters such as newline, tab, etc., as well as some more exotic forms. See \"Quote and Quote-like Operators\" in perlop for a list. Hexadecimal, octal, or binary, representations in string literals (e.g. '0xff') are not automatically converted to their integer representation. The hex() and oct() functions make these conversions for you. See \"hex\" in perlfunc and \"oct\" in perlfunc for more details. You can also embed newlines directly in your strings, i.e., they can end on a different line than they begin. This is nice, but if you forget your trailing quote, the error will not be reported until Perl finds another line containing the quote character, which may be much further on in the script. Variable substitution inside strings is limited to scalar variables, arrays, and array or hash slices. (In other words, names beginning with $ or @, followed by an optional bracketed expression as a subscript.) The following code segment prints out \"The price is $100.\" $Price = '$100';    # not interpolated\nprint \"The price is $Price.\\n\";     # interpolated There is no double interpolation in Perl, so the $100 is left as is. By default floating point numbers substituted inside strings use the dot (\".\") as the decimal separator. If \"use locale\" is in effect, and POSIX::setlocale() has been called, the character used for the decimal separator is affected by the LC_NUMERIC locale. See perllocale and POSIX . As in some shells, you can enclose the variable name in braces to disambiguate it from following alphanumerics (and underscores). You must also do this when interpolating a variable into a string to separate the variable name from a following double-colon or an apostrophe, since these would be otherwise treated as a package separator: $who = \"Larry\";\nprint PASSWD \"${who}::0:0:Superuser:\/:\/bin\/perl\\n\";\nprint \"We use ${who}speak when ${who}'s here.\\n\"; Without the braces, Perl would have looked for a $whospeak, a $who::0, and a \"$who's\" variable. The last two would be the $0 and the $s variables in the (presumably) non-existent package \"who\". In fact, an identifier within such curlies is forced to be a string, as is any simple identifier within a hash subscript. Neither need quoting. Our earlier example, $days{'Feb'} can be written as $days{Feb} and the quotes will be assumed automatically. But anything more complicated in the subscript will be interpreted as an expression. This means for example that \"$version{2.0}++\" is equivalent to \"$version{2}++\", not to \"$version{'2.0'}++\". Version Strings Note: Version Strings (v-strings) have been deprecated. They will be removed in some future release after Perl 5.8.1. The marginal benefits of v-strings were greatly outweighed by the potential for Surprise and Confusion. A literal of the form \"v1.20.300.4000\" is parsed as a string composed of characters with the specified ordinals. This form, known as v-strings, provides an alternative, more readable way to construct strings, rather than use the somewhat less readable interpolation form \"\\x{1}\\x{14}\\x{12c}\\x{fa0}\". This is useful for representing Unicode strings, and for comparing version \"numbers\" using the string comparison operators, \"cmp\", \"gt\", \"lt\" etc. If there are two or more dots in the literal, the leading \"v\" may be omitted. print v9786;              # prints SMILEY, \"\\x{263a}\"\nprint v102.111.111;       # prints \"foo\"\nprint 102.111.111;        # same Such literals are accepted by both \"require\" and \"use\" for doing a version check. Note that using the v-strings for IPv4 addresses is not portable unless you also use the inet_aton()\/ inet_ntoa() routines of the Socket package. Note that since Perl 5.8.1 the single-number v-strings (like \"v65\") are not v-strings before the \"=>\" operator (which is usually used to separate a hash key from a hash value), instead they are interpreted as literal strings ('v65'). They were v-strings from Perl 5.6.0 to Perl 5.8.0, but that caused more confusion and breakage than good. Multi-number v-strings like \"v65.66\" and 65.66.67 continue to be v-strings always. Special Literals The special literals __FILE__, __LINE__, and __PACKAGE__ represent the current filename, line number, and package name at that point in your program. They may be used only as separate tokens; they will not be interpolated into strings. If there is no current package (due to an empty \"package;\" directive), __PACKAGE__ is the undefined value. The two control characters ^D and ^Z, and the tokens __END__ and __DATA__ may be used to indicate the logical end of the script before the actual end of file. Any following text is ignored. Text after __DATA__ may be read via the filehandle \"PACKNAME::DATA\", where \"PACKNAME\" is the package that was current when the __DATA__ token was encountered. The filehandle is left open pointing to the contents after __DATA__. It is the program's responsibility to \"close DATA\" when it is done reading from it. For compatibility with older scripts written before __DATA__ was introduced, __END__ behaves like __DATA__ in the top level script (but not in files loaded with \"require\" or \"do\") and leaves the remaining contents of the file accessible via \"main::DATA\". See SelfLoader for more description of __DATA__, and an example of its use. Note that you cannot read from the DATA filehandle in a BEGIN block: the BEGIN block is executed as soon as it is seen (during compilation), at which point the corresponding __DATA__ (or __END__) token has not yet been seen. Barewords A word that has no other interpretation in the grammar will be treated as if it were a quoted string. These are known as \"barewords\". As with filehandles and labels, a bareword that consists entirely of lowercase letters risks conflict with future reserved words, and if you use the \"use warnings\" pragma or the -w switch, Perl will warn you about any such words. Perl limits barewords (like identifiers) to about 250 characters. Future versions of Perl are likely to eliminate these arbitrary limitations. Some people may wish to outlaw barewords entirely. If you say use strict 'subs'; then any bareword that would NOT be interpreted as a subroutine call produces a compile-time error instead. The restriction lasts to the end of the enclosing block. An inner block may countermand this by saying \"no strict 'subs'\". Array Joining Delimiter Arrays and slices are interpolated into double-quoted strings by joining the elements with the delimiter specified in the $\" variable ($LIST_SEPARATOR if \"use English;\" is specified), space by default. The following are equivalent: $temp = join($\", @ARGV);\nsystem \"echo $temp\";\n\nsystem \"echo @ARGV\"; Within search patterns (which also undergo double-quotish substitution) there is an unfortunate ambiguity: Is \"\/$foo[bar]\/\" to be interpreted as \"\/${foo}[bar]\/\" (where \"[bar]\" is a character class for the regular expression) or as \"\/${foo[bar]}\/\" (where \"[bar]\" is the subscript to array @foo)? If @foo doesn't otherwise exist, then it's obviously a character class. If @foo exists, Perl takes a good guess about \"[bar]\", and is almost always right. If it does guess wrong, or if you're just plain paranoid, you can force the correct interpretation with curly braces as above. If you're looking for the information on how to use here-documents, which used to be here, that's been moved to \"Quote and Quote-like Operators\" in perlop. List value constructors List values are denoted by separating individual values by commas (and enclosing the list in parentheses where precedence requires it): (LIST) In a context not requiring a list value, the value of what appears to be a list literal is simply the value of the final element, as with the C comma operator. For example, @foo = ('cc', '-E', $bar); assigns the entire list value to array @foo, but $foo = ('cc', '-E', $bar); assigns the value of variable $bar to the scalar variable $foo. Note that the value of an actual array in scalar context is the length of the array; the following assigns the value 3 to $foo: @foo = ('cc', '-E', $bar);\n$foo = @foo;                # $foo gets 3 You may have an optional comma before the closing parenthesis of a list literal, so that you can say: @foo = (\n    1,\n    2,\n    3,\n); To use a here-document to assign an array, one line per element, you might use an approach like this: @sauces = <<End_Lines =~ m\/(\\S.*\\S)\/g;\n    normal tomato\n    spicy tomato\n    green chile\n    pesto\n    white wine\nEnd_Lines LISTs do automatic interpolation of sublists. That is, when a LIST is evaluated, each element of the list is evaluated in list context, and the resulting list value is interpolated into LIST just as if each individual element were a member of LIST . Thus arrays and hashes lose their identity in a LIST--the list (@foo,@bar,&SomeSub,%glarch) contains all the elements of @foo followed by all the elements of @bar, followed by all the elements returned by the subroutine named SomeSub called in list context, followed by the key\/value pairs of %glarch. To make a list reference that does NOT interpolate, see perlref. The null list is represented by (). Interpolating it in a list has no effect. Thus ((),(),()) is equivalent to (). Similarly, interpolating an array with no elements is the same as if no array had been interpolated at that point. This interpolation combines with the facts that the opening and closing parentheses are optional (except when necessary for precedence) and lists may end with an optional comma to mean that multiple commas within lists are legal syntax. The list \"1,,3\" is a concatenation of two lists, \"1,\" and 3, the first of which ends with that optional comma. \"1,,3\" is \"(1,),(3)\" is \"1,3\" (And similarly for \"1,,,3\" is \"(1,),(,),3\" is \"1,3\" and so on.) Not that we'd advise you to use this obfuscation. A list value may also be subscripted like a normal array. You must put the list in parentheses to avoid ambiguity. For example: # Stat returns list value.\n$time = (stat($file))[8];\n\n# SYNTAX ERROR HERE.\n$time = stat($file)[8];  # OOPS, FORGOT PARENTHESES\n\n# Find a hex digit.\n$hexdigit = ('a','b','c','d','e','f')[$digit-10];\n\n# A \"reverse comma operator\".\nreturn (pop(@foo),pop(@foo))[0]; Lists may be assigned to only when each element of the list is itself legal to assign to: ($a, $b, $c) = (1, 2, 3);\n\n($map{'red'}, $map{'blue'}, $map{'green'}) = (0x00f, 0x0f0, 0xf00); An exception to this is that you may assign to \"undef\" in a list. This is useful for throwing away some of the return values of a function: ($dev, $ino, undef, undef, $uid, $gid) = stat($file); List assignment in scalar context returns the number of elements produced by the expression on the right side of the assignment: $x = (($foo,$bar) = (3,2,1));       # set $x to 3, not 2\n$x = (($foo,$bar) = f());           # set $x to f()'s return count This is handy when you want to do a list assignment in a Boolean context, because most list functions return a null list when finished, which when assigned produces a 0, which is interpreted as FALSE . It's also the source of a useful idiom for executing a function or performing an operation in list context and then counting the number of return values, by assigning to an empty list and then using that assignment in scalar context. For example, this code: $count = () = $string =~ \/\\d+\/g; will place into $count the number of digit groups found in $string. This happens because the pattern match is in list context (since it is being assigned to the empty list), and will therefore return a list of all matching parts of the string. The list assignment in scalar context will translate that into the number of elements (here, the number of times the pattern matched) and assign that to $count. Note that simply using $count = $string =~ \/\\d+\/g; would not have worked, since a pattern match in scalar context will only return true or false, rather than a count of matches. The final element of a list assignment may be an array or a hash: ($a, $b, @rest) = split;\nmy($a, $b, %rest) = @_; You can actually put an array or hash anywhere in the list, but the first one in the list will soak up all the values, and anything after it will become undefined. This may be useful in a my() or local(). A hash can be initialized using a literal list holding pairs of items to be interpreted as a key and a value: # same as map assignment above\n%map = ('red',0x00f,'blue',0x0f0,'green',0xf00); While literal lists and named arrays are often interchangeable, that's not the case for hashes. Just because you can subscript a list value like a normal array does not mean that you can subscript a list value as a hash. Likewise, hashes included as parts of other lists (including parameters lists and return lists from functions) always flatten out into key\/value pairs. That's why it's good to use references sometimes. It is often more readable to use the \"=>\" operator between key\/value pairs. The \"=>\" operator is mostly just a more visually distinctive synonym for a comma, but it also arranges for its left-hand operand to be interpreted as a string -- if it's a bareword that would be a legal simple identifier (\"=>\" doesn't quote compound identifiers, that contain double colons). This makes it nice for initializing hashes:  %map = (\n              red   => 0x00f,\n              blue  => 0x0f0,\n              green => 0xf00,\n); or for initializing hash references to be used as records: $rec = {\n            witch => 'Mable the Merciless',\n            cat   => 'Fluffy the Ferocious',\n            date  => '10\/31\/1776',\n}; or for using call-by-named-parameter to complicated functions: $field = $query->radio_group(\n            name      => 'group_name',\n            values    => ['eenie','meenie','minie'],\n            default   => 'meenie',\n            linebreak => 'true',\n            labels    => \\%labels\n); Note that just because a hash is initialized in that order doesn't mean that it comes out in that order. See \"sort\" in perlfunc for examples of how to arrange for an output ordering. Subscripts An array is subscripted by specifying a dollar sign ( \"$\"), then the name of the array (without the leading \"@\"), then the subscript inside square brackets. For example: @myarray = (5, 50, 500, 5000);\nprint \"The Third Element is\", $myarray[2], \"\\n\"; The array indices start with 0. A negative subscript retrieves its value from the end. In our example, $myarray[-1] would have been 5000, and $myarray[-2] would have been 500. Hash subscripts are similar, only instead of square brackets curly brackets are used. For example: %scientists =\n(\n    \"Newton\" => \"Isaac\",\n    \"Einstein\" => \"Albert\",\n    \"Darwin\" => \"Charles\",\n    \"Feynman\" => \"Richard\",\n);\n\nprint \"Darwin's First Name is \", $scientists{\"Darwin\"}, \"\\n\"; Slices A common way to access an array or a hash is one scalar element at a time. You can also subscript a list to get a single element from it. $whoami = $ENV{\"USER\"};             # one element from the hash\n$parent = $ISA[0];                  # one element from the array\n$dir    = (getpwnam(\"daemon\"))[7];  # likewise, but with list A slice accesses several elements of a list, an array, or a hash simultaneously using a list of subscripts. It's more convenient than writing out the individual elements as a list of separate scalar values. ($him, $her)   = @folks[0,-1];              # array slice\n@them          = @folks[0 .. 3];            # array slice\n($who, $home)  = @ENV{\"USER\", \"HOME\"};      # hash slice\n($uid, $dir)   = (getpwnam(\"daemon\"))[2,7]; # list slice Since you can assign to a list of variables, you can also assign to an array or hash slice. @days[3..5]    = qw\/Wed Thu Fri\/;\n@colors{'red','blue','green'}\n               = (0xff0000, 0x0000ff, 0x00ff00);\n@folks[0, -1]  = @folks[-1, 0]; The previous assignments are exactly equivalent to ($days[3], $days[4], $days[5]) = qw\/Wed Thu Fri\/;\n($colors{'red'}, $colors{'blue'}, $colors{'green'})\n               = (0xff0000, 0x0000ff, 0x00ff00);\n($folks[0], $folks[-1]) = ($folks[-1], $folks[0]); Since changing a slice changes the original array or hash that it's slicing, a \"foreach\" construct will alter some--or even all--of the values of the array or hash. foreach (@array[ 4 .. 10 ]) { s\/peter\/paul\/ }\n\nforeach (@hash{qw[key1 key2]}) {\n    s\/^\\s+\/\/;           # trim leading whitespace\n    s\/\\s+$\/\/;           # trim trailing whitespace\n    s\/(\\w+)\/\\u\\L$1\/g;   # \"titlecase\" words\n} A slice of an empty list is still an empty list. Thus: @a = ()[1,0];           # @a has no elements\n@b = (@a)[0,1];         # @b has no elements\n@c = (0,1)[2,3];        # @c has no elements But: @a = (1)[1,0];          # @a has two elements\n@b = (1,undef)[1,0,2];  # @b has three elements This makes it easy to write loops that terminate when a null list is returned: while ( ($home, $user) = (getpwent)[7,0]) {\n    printf \"%-8s %s\\n\", $user, $home;\n} As noted earlier in this document, the scalar sense of list assignment is the number of elements on the right-hand side of the assignment. The null list contains no elements, so when the password file is exhausted, the result is 0, not 2. If you're confused about why you use an '@' there on a hash slice instead of a '%', think of it like this. The type of bracket (square or curly) governs whether it's an array or a hash being looked at. On the other hand, the leading symbol ('$' or '@') on the array or hash indicates whether you are getting back a singular value (a scalar) or a plural one (a list). Typeglobs and Filehandles Perl uses an internal type called a typeglob to hold an entire symbol table entry. The type prefix of a typeglob is a \"*\", because it represents all types. This used to be the preferred way to pass arrays and hashes by reference into a function, but now that we have real references, this is seldom needed. The main use of typeglobs in modern Perl is create symbol table aliases. This assignment: *this = *that; makes $this an alias for $that, @this an alias for @that, %this an alias for %that, &this an alias for &that, etc. Much safer is to use a reference. This: local *Here::blue = \\$There::green; temporarily makes $Here::blue an alias for $There::green, but doesn't make @Here::blue an alias for @There::green, or %Here::blue an alias for %There::green, etc. See \"Symbol Tables\" in perlmod for more examples of this. Strange though this may seem, this is the basis for the whole module import\/export system. Another use for typeglobs is to pass filehandles into a function or to create new filehandles. If you need to use a typeglob to save away a filehandle, do it this way: $fh = *STDOUT; or perhaps as a real reference, like this: $fh = \\*STDOUT; See perlsub for examples of using these as indirect filehandles in functions. Typeglobs are also a way to create a local filehandle using the local() operator. These last until their block is exited, but may be passed back. For example: sub newopen {\n    my $path = shift;\n    local  *FH;  # not my!\n    open   (FH, $path)          or  return undef;\n    return *FH;\n}\n$fh = newopen('\/etc\/passwd'); Now that we have the *foo{THING} notation, typeglobs aren't used as much for filehandle manipulations, although they're still needed to pass brand new file and directory handles into or out of functions. That's because *HANDLE{IO} only works if HANDLE has already been used as a handle. In other words, *FH must be used to create new symbol table entries; *foo{THING} cannot. When in doubt, use *FH. All functions that are capable of creating filehandles (open(), opendir(), pipe(), socketpair(), sysopen(), socket(), and accept()) automatically create an anonymous filehandle if the handle passed to them is an uninitialized scalar variable. This allows the constructs such as \"open(my $fh, ...)\" and \"open(local $fh,...)\" to be used to create filehandles that will conveniently be closed automatically when the scope ends, provided there are no other references to them. This largely eliminates the need for typeglobs when opening filehandles that must be passed around, as in the following example: sub myopen {\n    open my $fh, \"@_\"\n         or die \"Can't open '@_': $!\";\n    return $fh;\n}\n\n{\n    my $f = myopen(\"<\/etc\/motd\");\n    print <$f>;\n    # $f implicitly closed here\n} Note that if an initialized scalar variable is used instead the result is different: \"my $fh='zzz'; open($fh, ...)\" is equivalent to \"open( *{'zzz'}, ...)\". \"use strict 'refs'\" forbids such practice. Another way to create anonymous filehandles is with the Symbol module or with the IO::Handle module and its ilk. These modules have the advantage of not hiding different types of the same name during the local(). See the bottom of \"open()\" in perlfunc for an example.","Process Name":"perldata","Link":"https:\/\/linux.die.net\/man\/1\/perldata"}},{"Process":{"Description":"The four \"filter_*\" methods shown above are available in all the DBM modules that ship with Perl, namely DB_File, GDBM_File, NDBM_File, ODBM_File and SDBM_File. Each of the methods work identically, and are used to install (or uninstall) a single DBM Filter. The only difference between them is the place that the filter is installed. To summarise: filter_store_key If a filter has been installed with this method, it will be invoked every time you write a key to a DBM database. filter_store_value If a filter has been installed with this method, it will be invoked every time you write a value to a DBM database. filter_fetch_key If a filter has been installed with this method, it will be invoked every time you read a key from a DBM database. filter_fetch_value If a filter has been installed with this method, it will be invoked every time you read a value from a DBM database. You can use any combination of the methods from none to all four. All filter methods return the existing filter, if present, or \"undef\" in not. To delete a filter pass \"undef\" to it. The Filter When each filter is called by Perl, a local copy of $_ will contain the key or value to be filtered. Filtering is achieved by modifying the contents of $_. The return code from the filter is ignored. An Example -- the NULL termination problem. DBM Filters are useful for a class of problems where you always want to make the same transformation to all keys, all values or both. For example, consider the following scenario. You have a DBM database that you need to share with a third-party C application. The C application assumes that all keys and values are NULL terminated. Unfortunately when Perl writes to DBM databases it doesn't use NULL termination, so your Perl application will have to manage NULL termination itself. When you write to the database you will have to use something like this: $hash{\"$key\\0\"} = \"$value\\0\"; Similarly the NULL needs to be taken into account when you are considering the length of existing keys\/values. It would be much better if you could ignore the NULL terminations issue in the main application code and have a mechanism that automatically added the terminating NULL to all keys and values whenever you write to the database and have them removed when you read from the database. As I'm sure you have already guessed, this is a problem that DBM Filters can fix very easily. use strict;\nuse warnings;\nuse SDBM_File;\nuse Fcntl;\n\nmy %hash;\nmy $filename = \"filt\";\nunlink $filename;\n\nmy $db = tie(%hash, 'SDBM_File', $filename, O_RDWR|O_CREAT, 0640)\n  or die \"Cannot open $filename: $!\\n\";\n\n# Install DBM Filters\n$db->filter_fetch_key  ( sub { s\/\\0$\/\/    } );\n$db->filter_store_key  ( sub { $_ .= \"\\0\" } );\n$db->filter_fetch_value(\n    sub { no warnings 'uninitialized'; s\/\\0$\/\/ } );\n$db->filter_store_value( sub { $_ .= \"\\0\" } );\n\n$hash{\"abc\"} = \"def\";\nmy $a = $hash{\"ABC\"};\n# ...\nundef $db;\nuntie %hash; The code above uses SDBM_File, but it will work with any of the DBM modules. Hopefully the contents of each of the filters should be self-explanatory. Both \"fetch\" filters remove the terminating NULL , and both \"store\" filters add a terminating NULL . Another Example -- Key is a C int. Here is another real-life example. By default, whenever Perl writes to a DBM database it always writes the key and value as strings. So when you use this: $hash{12345} = \"something\"; the key 12345 will get stored in the DBM database as the 5 byte string \"12345\". If you actually want the key to be stored in the DBM database as a C int, you will have to use \"pack\" when writing, and \"unpack\" when reading. Here is a DBM Filter that does it: use strict;\nuse warnings;\nuse DB_File;\nmy %hash;\nmy $filename = \"filt\";\nunlink $filename;\n\nmy $db = tie %hash, 'DB_File', $filename, O_CREAT|O_RDWR, 0666, $DB_HASH\n  or die \"Cannot open $filename: $!\\n\";\n\n$db->filter_fetch_key  ( sub { $_ = unpack(\"i\", $_) } );\n$db->filter_store_key  ( sub { $_ = pack (\"i\", $_) } );\n$hash{123} = \"def\";\n# ...\nundef $db;\nuntie %hash; The code above uses DB_File, but again it will work with any of the DBM modules. This time only two filters have been used -- we only need to manipulate the contents of the key, so it wasn't necessary to install any value filters.","Process Name":"perldbmfilter","Link":"https:\/\/linux.die.net\/man\/1\/perldbmfilter"}},{"Process":{"Description":"This is not the perldebug(1) manpage, which tells you how to use the debugger. This manpage describes low-level details concerning the debugger's internals, which range from difficult to impossible to understand for anyone who isn't incredibly intimate with Perl's guts. Caveat lector.","Process Name":"perldebguts","Link":"https:\/\/linux.die.net\/man\/1\/perldebguts"}},{"Process":{"Description":"A (very) lightweight introduction in the use of the perl debugger, and a pointer to existing, deeper sources of information on the subject of debugging perl programs. There's an extraordinary number of people out there who don't appear to know anything about using the perl debugger, though they use the language every day. This is for them.","Process Name":"perldebtut","Link":"https:\/\/linux.die.net\/man\/1\/perldebtut"}},{"Process":{"Description":"First of all, have you tried using the -w switch? If you're new to the Perl debugger, you may prefer to read perldebtut, which is a tutorial introduction to the debugger .","Process Name":"perldebug","Link":"https:\/\/linux.die.net\/man\/1\/perldebug"}},{"Process":{"Description":"This document describes differences between the 5.10.0 release and the 5.10.1 release. If you are upgrading from an earlier release such as 5.8.8, first read the perl5100delta, which describes differences between 5.8.8 and 5.10.0","Process Name":"perldelta","Link":"https:\/\/linux.die.net\/man\/1\/perldelta"}},{"Process":{"Description":"Perl 5.7\/8.x for DG\/UX ix86 R4.20MU0x","Process Name":"perldgux","Link":"https:\/\/linux.die.net\/man\/1\/perldgux"}},{"Process":{"Description":"These messages are classified as follows (listed in increasing order of desperation): (W) A warning (optional).\n(D) A deprecation (optional).\n(S) A severe warning (enabled by default).\n(F) A fatal error (trappable).\n(P) An internal error you should never see (trappable).\n(X) A very fatal error (nontrappable).\n(A) An alien error message (not generated by Perl). The majority of messages from the first three classifications above (W, D & S) can be controlled using the \"warnings\" pragma. If a message can be controlled by the \"warnings\" pragma, its warning category is included with the classification letter in the description below. Optional warnings are enabled by using the \"warnings\" pragma or the -w and -W switches. Warnings may be captured by setting $SIG{__WARN__} to a reference to a routine that will be called on each warning instead of printing it. See perlvar. Severe warnings are always enabled, unless they are explicitly disabled with the \"warnings\" pragma or the -X switch. Trappable errors may be trapped using the eval operator. See \"eval\" in perlfunc. In almost all cases, warnings may be selectively disabled or promoted to fatal errors using the \"warnings\" pragma. See warnings. The messages are in alphabetical order, without regard to upper or lower-case. Some of these messages are generic. Spots that vary are denoted with a %s or other printf-style escape. These escapes are ignored by the alphabetical order, as are all characters other than letters. To look up your message, just ignore anything that is not a letter. accept() on closed socket %s (W closed) You tried to do an accept on a closed socket. Did you forget to check the return value of your socket() call? See \"accept\" in perlfunc. Allocation too large: %lx (X) You can't allocate more than 64K on an MS-DOS machine. '%c' allowed only after types %s (F) The modifiers '!', '<' and '>' are allowed in pack() or unpack() only after certain types. See \"pack\" in perlfunc. Ambiguous call resolved as CORE::%s(), qualify as such or use & (W ambiguous) A subroutine you have declared has the same name as a Perl keyword, and you have used the name without qualification for calling one or the other. Perl decided to call the builtin because the subroutine is not imported. To force interpretation as a subroutine call, either put an ampersand before the subroutine name, or qualify the name with its package. Alternatively, you can import the subroutine (or pretend that it's imported with the \"use subs\" pragma). To silently interpret it as the Perl operator, use the \"CORE::\" prefix on the operator (e.g. \"CORE::log($x)\") or declare the subroutine to be an object method (see \"Subroutine Attributes\" in perlsub or attributes). Ambiguous range in transliteration operator (F) You wrote something like \"tr\/a-z-0\/\/\" which doesn't mean anything at all. To include a \"-\" character in a transliteration, put it either first or last. (In the past, \"tr\/a-z-0\/\/\" was synonymous with \"tr\/a-y\/\/\", which was probably not what you would have expected.) Ambiguous use of %s resolved as %s (W ambiguous)(S) You said something that may not be interpreted the way you thought. Normally it's pretty easy to disambiguate it by supplying a missing quote, operator, parenthesis pair or declaration. '|' and '<' may not both be specified on command line (F) An error peculiar to VMS . Perl does its own command line redirection, and found that STDIN was a pipe, and that you also tried to redirect STDIN using '<'. Only one STDIN stream to a customer, please. '|' and '>' may not both be specified on command line (F) An error peculiar to VMS . Perl does its own command line redirection, and thinks you tried to redirect stdout both to a file and into a pipe to another command. You need to choose one or the other, though nothing's stopping you from piping into a program or Perl script which 'splits' output into two streams, such as open(OUT,\">$ARGV[0]\") or die \"Can't write to $ARGV[0]: $!\";\nwhile (<STDIN>) {\n    print;\n    print OUT;\n}\nclose OUT; Applying %s to %s will act on scalar(%s) (W misc) The pattern match ( \"\/\/\"), substitution ( \"s\/\/\/\"), and transliteration ( \"tr\/\/\/\") operators work on scalar values. If you apply one of them to an array or a hash, it will convert the array or hash to a scalar value -- the length of an array, or the population info of a hash -- and then work on that scalar value. This is probably not what you meant to do. See \"grep\" in perlfunc and \"map\" in perlfunc for alternatives. Args must match #! line (F) The setuid emulator requires that the arguments Perl was invoked with match the arguments specified on the #! line. Since some systems impose a one-argument limit on the #! line, try combining switches; for example, turn \"-w -U\" into \"-wU\". Arg too short for msgsnd (F) msgsnd() requires a string at least as long as sizeof(long). %s argument is not a HASH or ARRAY element or a subroutine (F) The argument to exists() must be a hash or array element or a subroutine with an ampersand, such as: $foo{$bar}\n$ref->{\"susie\"}[12]\n&do_something %s argument is not a HASH or ARRAY element or slice (F) The argument to delete() must be either a hash or array element, such as: $foo{$bar}\n$ref->{\"susie\"}[12] or a hash or array slice, such as: @foo[$bar, $baz, $xyzzy]\n@{$ref->[12]}{\"susie\", \"queue\"} %s argument is not a subroutine name (F) The argument to exists() for \"exists &sub\" must be a subroutine name, and not a subroutine call. \"exists &sub()\" will generate this error. Argument \"%s\" isn't numeric%s (W numeric) The indicated string was fed as an argument to an operator that expected a numeric value instead. If you're fortunate the message will identify which operator was so unfortunate. Argument list not closed for PerlIO layer \"%s\" (W layer) When pushing a layer with arguments onto the Perl I\/O system you forgot the ) that closes the argument list. (Layers take care of transforming data between external and internal representations.) Perl stopped parsing the layer list at this point and did not attempt to push this layer. If your program didn't explicitly request the failing operation, it may be the result of the value of the environment variable PERLIO . Array @%s missing the @ in argument %d of %s() (D deprecated) Really old Perl let you omit the @ on array names in some spots. This is now heavily deprecated. assertion botched: %s (P) The malloc package that comes with Perl had an internal failure. Assertion failed: file \"%s\" (P) A general assertion failed. The file in question must be examined. Assignment to both a list and a scalar (F) If you assign to a conditional operator, the 2nd and 3rd arguments must either both be scalars or both be lists. Otherwise Perl won't know which context to supply to the right side. A thread exited while %d threads were running (W threads)(S) When using threaded Perl, a thread (not necessarily the main thread) exited while there were still other threads running. Usually it's a good idea to first collect the return values of the created threads by joining them, and only then exit from the main thread. See threads. Attempt to access disallowed key '%s' in a restricted hash (F) The failing code has attempted to get or set a key which is not in the current set of allowed keys of a restricted hash. Attempt to bless into a reference (F) The CLASSNAME argument to the bless() operator is expected to be the name of the package to bless the resulting object into. You've supplied instead a reference to something: perhaps you wrote bless $self, $proto; when you intended bless $self, ref($proto) || $proto; If you actually want to bless into the stringified version of the reference supplied, you need to stringify it yourself, for example by: bless $self, \"$proto\"; Attempt to delete disallowed key '%s' from a restricted hash (F) The failing code attempted to delete from a restricted hash a key which is not in its key set. Attempt to delete readonly key '%s' from a restricted hash (F) The failing code attempted to delete a key whose value has been declared readonly from a restricted hash. Attempt to free non-arena SV: 0x%lx (P internal) All SV objects are supposed to be allocated from arenas that will be garbage collected on exit. An SV was discovered to be outside any of those arenas. Attempt to free nonexistent shared string (P internal) Perl maintains a reference counted internal table of strings to optimize the storage and access of hash keys and other strings. This indicates someone tried to decrement the reference count of a string that can no longer be found in the table. Attempt to free temp prematurely (W debugging) Mortalized values are supposed to be freed by the free_tmps() routine. This indicates that something else is freeing the SV before the free_tmps() routine gets a chance, which means that the free_tmps() routine will be freeing an unreferenced scalar when it does try to free it. Attempt to free unreferenced glob pointers (P internal) The reference counts got screwed up on symbol aliases. Attempt to free unreferenced scalar (W internal) Perl went to decrement the reference count of a scalar to see if it would go to 0, and discovered that it had already gone to 0 earlier, and should have been freed, and in fact, probably was freed. This could indicate that SvREFCNT_dec() was called too many times, or that SvREFCNT_inc() was called too few times, or that the SV was mortalized when it shouldn't have been, or that memory has been corrupted. Attempt to join self (F) You tried to join a thread from within itself, which is an impossible task. You may be joining the wrong thread, or you may need to move the join() to some other thread. Attempt to pack pointer to temporary value (W pack) You tried to pass a temporary value (like the result of a function, or a computed expression) to the \"p\" pack() template. This means the result contains a pointer to a location that could become invalid anytime, even before the end of the current statement. Use literals or global values as arguments to the \"p\" pack() template to avoid this warning. Attempt to reload %s aborted. (F) You tried to load a file with \"use\" or \"require\" that failed to compile once already. Perl will not try to compile this file again unless you delete its entry from %INC. See \"require\" in perlfunc and \"%INC\" in perlvar. Attempt to set length of freed array (W) You tried to set the length of an array which has been freed. You can do this by storing a reference to the scalar representing the last index of an array and later assigning through that reference. For example $r = do {my @a; \\$#a};\n$$r = 503 Attempt to use reference as lvalue in substr (W substr) You supplied a reference as the first argument to substr() used as an lvalue, which is pretty strange. Perhaps you forgot to dereference it first. See \"substr\" in perlfunc. Bad arg length for %s, is %d, should be %s (F) You passed a buffer of the wrong size to one of msgctl(), semctl() or shmctl(). In C parlance, the correct sizes are, respectively, sizeof(struct msqid_ds *), sizeof(struct semid_ds *), and sizeof(struct shmid_ds *). Bad evalled substitution pattern (F) You've used the \"\/e\" switch to evaluate the replacement for a substitution, but perl found a syntax error in the code to evaluate, most likely an unexpected right brace '}'. Bad filehandle: %s (F) A symbol was passed to something wanting a filehandle, but the symbol has no filehandle associated with it. Perhaps you didn't do an open(), or did it in another package. Bad free() ignored (S malloc) An internal routine called free() on something that had never been malloc()ed in the first place. Mandatory, but can be disabled by setting environment variable \"PERL_BADFREE\" to 0. This message can be seen quite often with DB_File on systems with \"hard\" dynamic linking, like \"AIX\" and \"OS\/2\". It is a bug of \"Berkeley DB\" which is left unnoticed if \"DB\" uses forgiving system malloc(). Bad hash (P) One of the internal hash routines was passed a null HV pointer. Badly placed ()'s (A) You've accidentally run your script through csh instead of Perl. Check the #! line, or manually feed your script into Perl yourself. Bad name after %s:: (F) You started to name a symbol by using a package prefix, and then didn't finish the symbol. In particular, you can't interpolate outside of quotes, so $var = 'myvar';\n$sym = mypack::$var; is not the same as $var = 'myvar';\n$sym = \"mypack::$var\"; Bad realloc() ignored (S malloc) An internal routine called realloc() on something that had never been malloc()ed in the first place. Mandatory, but can be disabled by setting environment variable \"PERL_BADFREE\" to 1. Bad symbol for array (P) An internal request asked to add an array entry to something that wasn't a symbol table entry. Bad symbol for dirhandle (P) An internal request asked to add a dirhandle entry to something that wasn't a symbol table entry. Bad symbol for filehandle (P) An internal request asked to add a filehandle entry to something that wasn't a symbol table entry. Bad symbol for hash (P) An internal request asked to add a hash entry to something that wasn't a symbol table entry. Bareword found in conditional (W bareword) The compiler found a bareword where it expected a conditional, which often indicates that an || or && was parsed as part of the last argument of the previous construct, for example: open FOO || die; It may also indicate a misspelled constant that has been interpreted as a bareword: use constant TYPO => 1;\nif (TYOP) { print \"foo\" } The \"strict\" pragma is useful in avoiding such errors. Bareword \"%s\" not allowed while \"strict subs\" in use (F) With \"strict subs\" in use, a bareword is only allowed as a subroutine identifier, in curly brackets or to the left of the \"=>\" symbol. Perhaps you need to predeclare a subroutine? Bareword \"%s\" refers to nonexistent package (W bareword) You used a qualified bareword of the form \"Foo::\", but the compiler saw no other uses of that namespace before that point. Perhaps you need to predeclare a package? BEGIN failed--compilation aborted (F) An untrapped exception was raised while executing a BEGIN subroutine. Compilation stops immediately and the interpreter is exited. BEGIN not safe after errors--compilation aborted (F) Perl found a \"BEGIN {}\" subroutine (or a \"use\" directive, which implies a \"BEGIN {}\") after one or more compilation errors had already occurred. Since the intended environment for the \"BEGIN {}\" could not be guaranteed (due to the errors), and since subsequent code likely depends on its correct operation, Perl just gave up. \\1 better written as $1 (W syntax) Outside of patterns, backreferences live on as variables. The use of backslashes is grandfathered on the right-hand side of a substitution, but stylistically it's better to use the variable form because other Perl programmers will expect it, and it works better if there are more than 9 backreferences. Binary number > 0b11111111111111111111111111111111 non-portable (W portable) The binary number you specified is larger than 2**32-1 (4294967295) and therefore non-portable between systems. See perlport for more on portability concerns. bind() on closed socket %s (W closed) You tried to do a bind on a closed socket. Did you forget to check the return value of your socket() call? See \"bind\" in perlfunc. binmode() on closed filehandle %s (W unopened) You tried binmode() on a filehandle that was never opened. Check you control flow and number of arguments. Bit vector size > 32 non-portable (W portable) Using bit vector sizes larger than 32 is non-portable. Bizarre copy of %s in %s (P) Perl detected an attempt to copy an internal value that is not copyable. Buffer overflow in prime_env_iter: %s (W internal) A warning peculiar to VMS . While Perl was preparing to iterate over %ENV, it encountered a logical name or symbol definition which was too long, so it was truncated to the string shown. Callback called exit (F) A subroutine invoked from an external package via call_sv() exited by calling exit. %s() called too early to check prototype (W prototype) You've called a function that has a prototype before the parser saw a definition or declaration for it, and Perl could not check that the call conforms to the prototype. You need to either add an early prototype declaration for the subroutine in question, or move the subroutine definition ahead of the call to get proper prototype checking. Alternatively, if you are certain that you're calling the function correctly, you may put an ampersand before the name to avoid the warning. See perlsub. Cannot compress integer in pack (F) An argument to pack(\"w\",...) was too large to compress. The BER compressed integer format can only be used with positive integers, and you attempted to compress Infinity or a very large number (> 1e308). See \"pack\" in perlfunc. Cannot compress negative numbers in pack (F) An argument to pack(\"w\",...) was negative. The BER compressed integer format can only be used with positive integers. See \"pack\" in perlfunc. Cannot convert a reference to %s to typeglob (F) You manipulated Perl's symbol table directly, stored a reference in it, then tried to access that symbol via conventional Perl syntax. The access triggers Perl to autovivify that typeglob, but it there is no legal conversion from that type of reference to a typeglob. Cannot copy to %s in %s (P) Perl detected an attempt to copy a value to an internal type that cannot be directly assigned not. Can only compress unsigned integers in pack (F) An argument to pack(\"w\",...) was not an integer. The BER compressed integer format can only be used with positive integers, and you attempted to compress something else. See \"pack\" in perlfunc. Can't bless non-reference value (F) Only hard references may be blessed. This is how Perl \"enforces\" encapsulation of objects. See perlobj. Can't \"break\" in a loop topicalizer (F) You called \"break\", but you're in a \"foreach\" block rather than a \"given\" block. You probably meant to use \"next\" or \"last\". Can't \"break\" outside a given block (F) You called \"break\", but you're not inside a \"given\" block. Can't call method \"%s\" in empty package \"%s\" (F) You called a method correctly, and it correctly indicated a package functioning as a class, but that package doesn't have ANYTHING defined in it, let alone methods. See perlobj. Can't call method \"%s\" on an undefined value (F) You used the syntax of a method call, but the slot filled by the object reference or package name contains an undefined value. Something like this will reproduce the error: $BADREF = undef;\nprocess $BADREF 1,2,3;\n$BADREF->process(1,2,3); Can't call method \"%s\" on unblessed reference (F) A method call must know in what package it's supposed to run. It ordinarily finds this out from the object reference you supply, but you didn't supply an object reference in this case. A reference isn't an object reference until it has been blessed. See perlobj. Can't call method \"%s\" without a package or object reference (F) You used the syntax of a method call, but the slot filled by the object reference or package name contains an expression that returns a defined value which is neither an object reference nor a package name. Something like this will reproduce the error: $BADREF = 42;\nprocess $BADREF 1,2,3;\n$BADREF->process(1,2,3); Can't chdir to %s (F) You called \"perl -x\/foo\/bar\", but \"\/foo\/bar\" is not a directory that you can chdir to, possibly because it doesn't exist. Can't check filesystem of script \"%s\" for nosuid (P) For some reason you can't check the filesystem of the script for nosuid. Can't coerce array into hash (F) You used an array where a hash was expected, but the array has no information on how to map from keys to array indices. You can do that only with arrays that have a hash reference at index 0. Can't coerce %s to integer in %s (F) Certain types of SVs, in particular real symbol table entries (typeglobs), can't be forced to stop being what they are. So you can't say things like: *foo += 1; You CAN say $foo = *foo;\n$foo += 1; but then $foo no longer contains a glob. Can't coerce %s to number in %s (F) Certain types of SVs, in particular real symbol table entries (typeglobs), can't be forced to stop being what they are. Can't coerce %s to string in %s (F) Certain types of SVs, in particular real symbol table entries (typeglobs), can't be forced to stop being what they are. Can't \"continue\" outside a when block (F) You called \"continue\", but you're not inside a \"when\" or \"default\" block. Can't create pipe mailbox (P) An error peculiar to VMS . The process is suffering from exhausted quotas or other plumbing problems. Can't declare class for non-scalar %s in \"%s\" (F) Currently, only scalar variables can be declared with a specific class qualifier in a \"my\", \"our\" or \"state\" declaration. The semantics may be extended for other types of variables in future. Can't declare %s in \"%s\" (F) Only scalar, array, and hash variables may be declared as \"my\", \"our\" or \"state\" variables. They must have ordinary identifiers as names. Can't do inplace edit: %s is not a regular file (S inplace) You tried to use the -i switch on a special file, such as a file in \/dev, or a FIFO . The file was ignored. Can't do inplace edit on %s: %s (S inplace) The creation of the new file failed for the indicated reason. Can't do inplace edit without backup (F) You're on a system such as MS-DOS that gets confused if you try reading from a deleted (but still opened) file. You have to say \"-i.bak\", or some such. Can't do inplace edit: %s would not be unique (S inplace) Your filesystem does not support filenames longer than 14 characters and Perl was unable to create a unique filename during inplace editing with the -i switch. The file was ignored. Can't do {n,m} with n > m in regex; marked by <-- HERE in m\/%s\/ (F) Minima must be less than or equal to maxima. If you really want your regexp to match something 0 times, just put {0}. The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Can't do setegid! (P) The setegid() call failed for some reason in the setuid emulator of suidperl. Can't do seteuid! (P) The setuid emulator of suidperl failed for some reason. Can't do setuid (F) This typically means that ordinary perl tried to exec suidperl to do setuid emulation, but couldn't exec it. It looks for a name of the form sperl5.000 in the same directory that the perl executable resides under the name perl5.000, typically \/usr\/local\/bin on Unix machines. If the file is there, check the execute permissions. If it isn't, ask your sysadmin why he and\/or she removed it. Can't do waitpid with flags (F) This machine doesn't have either waitpid() or wait4(), so only waitpid() without flags is emulated. Can't emulate -%s on #! line (F) The #! line specifies a switch that doesn't make sense at this point. For example, it'd be kind of silly to put a -x on the #! line. Can't %s %s-endian %ss on this platform (F) Your platform's byte-order is neither big-endian nor little-endian, or it has a very strange pointer size. Packing and unpacking big- or little-endian floating point values and pointers may not be possible. See \"pack\" in perlfunc. Can't exec \"%s\": %s (W exec) A system(), exec(), or piped open call could not execute the named program for the indicated reason. Typical reasons include: the permissions were wrong on the file, the file wasn't found in $ENV{PATH}, the executable in question was compiled for another architecture, or the #! line in a script points to an interpreter that can't be run for similar reasons. (Or maybe your system doesn't support #! at all.) Can't exec %s (F) Perl was trying to execute the indicated program for you because that's what the #! line said. If that's not what you wanted, you may need to mention \"perl\" on the #! line somewhere. Can't execute %s (F) You used the -S switch, but the copies of the script to execute found in the PATH did not have correct permissions. Can't find an opnumber for \"%s\" (F) A string of a form \"CORE::word\" was given to prototype(), but there is no builtin with the name \"word\". Can't find %s character property \"%s\" (F) You used \"\\p{}\" or \"\\P{}\" but the character property by that name could not be found. Maybe you misspelled the name of the property (remember that the names of character properties consist only of alphanumeric characters), or maybe you forgot the \"Is\" or \"In\" prefix? Can't find label %s (F) You said to goto a label that isn't mentioned anywhere that it's possible for us to go to. See \"goto\" in perlfunc. Can't find %s on PATH (F) You used the -S switch, but the script to execute could not be found in the PATH . Can't find %s on PATH , '.' not in PATH (F) You used the -S switch, but the script to execute could not be found in the PATH , or at least not with the correct permissions. The script exists in the current directory, but PATH prohibits running it. Can't find string terminator %s anywhere before EOF (F) Perl strings can stretch over multiple lines. This message means that the closing delimiter was omitted. Because bracketed quotes count nesting levels, the following is missing its final parenthesis: print q(The character '(' starts a side comment.); If you're getting this error from a here-document, you may have included unseen whitespace before or after your closing tag. A good programmer's editor will have a way to help you find these characters. Can't find Unicode property definition \"%s\" (F) You may have tried to use \"\\p\" which means a Unicode property (for example \"\\p{Lu}\" is all uppercase letters). If you did mean to use a Unicode property, see perlunicode for the list of known properties. If you didn't mean to use a Unicode property, escape the \"\\p\", either by \"\\\\p\" (just the \"\\p\") or by \"\\Q\\p\" (the rest of the string, until possible \"\\E\"). Can't fork (F) A fatal error occurred while trying to fork while opening a pipeline. Can't get filespec - stale stat buffer? (S) A warning peculiar to VMS . This arises because of the difference between access checks under VMS and under the Unix model Perl assumes. Under VMS , access checks are done by filename, rather than by bits in the stat buffer, so that ACLs and other protections can be taken into account. Unfortunately, Perl assumes that the stat buffer contains all the necessary information, and passes it, instead of the filespec, to the access checking routine. It will try to retrieve the filespec using the device name and FID present in the stat buffer, but this works only if you haven't made a subsequent call to the CRTL stat() routine, because the device name is overwritten with each call. If this warning appears, the name lookup failed, and the access checking routine gave up and returned FALSE , just to be conservative. (Note: The access checking routine knows about the Perl \"stat\" operator and file tests, so you shouldn't ever see this warning in response to a Perl command; it arises only if some internal code takes stat buffers lightly.) Can't get pipe mailbox device name (P) An error peculiar to VMS . After creating a mailbox to act as a pipe, Perl can't retrieve its name for later use. Can't get SYSGEN parameter value for MAXBUF (P) An error peculiar to VMS . Perl asked $GETSYI how big you want your mailbox buffers to be, and didn't get an answer. Can't \"goto\" into the middle of a foreach loop (F) A \"goto\" statement was executed to jump into the middle of a foreach loop. You can't get there from here. See \"goto\" in perlfunc. Can't \"goto\" out of a pseudo block (F) A \"goto\" statement was executed to jump out of what might look like a block, except that it isn't a proper block. This usually occurs if you tried to jump out of a sort() block or subroutine, which is a no-no. See \"goto\" in perlfunc. Can't goto subroutine from a sort sub (or similar callback) (F) The \"goto subroutine\" call can't be used to jump out of the comparison sub for a sort(), or from a similar callback (such as the reduce() function in List::Util). Can't goto subroutine from an eval-%s (F) The \"goto subroutine\" call can't be used to jump out of an eval \"string\" or block. Can't goto subroutine outside a subroutine (F) The deeply magical \"goto subroutine\" call can only replace one subroutine call for another. It can't manufacture one out of whole cloth. In general you should be calling it out of only an AUTOLOAD routine anyway. See \"goto\" in perlfunc. Can't ignore signal CHLD , forcing to default (W signal) Perl has detected that it is being run with the SIGCHLD signal (sometimes known as SIGCLD ) disabled. Since disabling this signal will interfere with proper determination of exit status of child processes, Perl has reset the signal to its default value. This situation typically indicates that the parent program under which Perl may be running (e.g. cron) is being very careless. Can't \"last\" outside a loop block (F) A \"last\" statement was executed to break out of the current block, except that there's this itty bitty problem called there isn't a current block. Note that an \"if\" or \"else\" block doesn't count as a \"loopish\" block, as doesn't a block given to sort(), map() or grep(). You can usually double the curlies to get the same effect though, because the inner curlies will be considered a block that loops once. See \"last\" in perlfunc. Can't linearize anonymous symbol table (F) Perl tried to calculate the method resolution order ( MRO ) of a package, but failed because the package stash has no name. Can't load '%s' for module %s (F) The module you tried to load failed to load a dynamic extension. This may either mean that you upgraded your version of perl to one that is incompatible with your old dynamic extensions (which is known to happen between major versions of perl), or (more likely) that your dynamic extension was built against an older version of the library that is installed on your system. You may need to rebuild your old dynamic extensions. Can't localize lexical variable %s (F) You used local on a variable name that was previously declared as a lexical variable using \"my\" or \"state\". This is not allowed. If you want to localize a package variable of the same name, qualify it with the package name. Can't localize through a reference (F) You said something like \"local $$ref\", which Perl can't currently handle, because when it goes to restore the old value of whatever $ref pointed to after the scope of the local() is finished, it can't be sure that $ref will still be a reference. Can't locate %s (F) You said to \"do\" (or \"require\", or \"use\") a file that couldn't be found. Perl looks for the file in all the locations mentioned in @INC, unless the file name included the full path to the file. Perhaps you need to set the PERL5LIB or PERL5OPT environment variable to say where the extra library is, or maybe the script needs to add the library name to @INC. Or maybe you just misspelled the name of the file. See \"require\" in perlfunc and lib. Can't locate auto\/%s.al in @INC (F) A function (or method) was called in a package which allows autoload, but there is no function to autoload. Most probable causes are a misprint in a function\/method name or a failure to \"AutoSplit\" the file, say, by doing \"make install\". Can't locate loadable object for module %s in @INC (F) The module you loaded is trying to load an external library, like for example, \"foo.so\" or \"bar.dll\", but the DynaLoader module was unable to locate this library. See DynaLoader. Can't locate object method \"%s\" via package \"%s\" (F) You called a method correctly, and it correctly indicated a package functioning as a class, but that package doesn't define that particular method, nor does any of its base classes. See perlobj. Can't locate package %s for @%s::ISA (W syntax) The @ISA array contained the name of another package that doesn't seem to exist. Can't locate PerlIO%s (F) You tried to use in open() a PerlIO layer that does not exist, e.g. open( FH , \">:nosuchlayer\", \"somefile\"). Can't make list assignment to \\%ENV on this system (F) List assignment to %ENV is not supported on some systems, notably VMS . Can't modify %s in %s (F) You aren't allowed to assign to the item indicated, or otherwise try to change it, such as with an auto-increment. Can't modify nonexistent substring (P) The internal routine that does assignment to a substr() was handed a NULL . Can't modify non-lvalue subroutine call (F) Subroutines meant to be used in lvalue context should be declared as such, see \"Lvalue subroutines\" in perlsub. Can't msgrcv to read-only var (F) The target of a msgrcv must be modifiable to be used as a receive buffer. Can't \"next\" outside a loop block (F) A \"next\" statement was executed to reiterate the current block, but there isn't a current block. Note that an \"if\" or \"else\" block doesn't count as a \"loopish\" block, as doesn't a block given to sort(), map() or grep(). You can usually double the curlies to get the same effect though, because the inner curlies will be considered a block that loops once. See \"next\" in perlfunc. Can't open %s: %s (S inplace) The implicit opening of a file through use of the \"<>\" filehandle, either implicitly under the \"-n\" or \"-p\" command-line switches, or explicitly, failed for the indicated reason. Usually this is because you don't have read permission for a file which you named on the command line. Can't open a reference (W io) You tried to open a scalar reference for reading or writing, using the 3-arg open() syntax : open FH, '>', $ref; but your version of perl is compiled without perlio, and this form of open is not supported. Can't open bidirectional pipe (W pipe) You tried to say \"open(CMD, \"|cmd|\")\", which is not supported. You can try any of several modules in the Perl library to do this, such as IPC::Open2. Alternately, direct the pipe's output to a file using \">\", and then read it in under a different file handle. Can't open error file %s as stderr (F) An error peculiar to VMS . Perl does its own command line redirection, and couldn't open the file specified after '2>' or '2>>' on the command line for writing. Can't open input file %s as stdin (F) An error peculiar to VMS . Perl does its own command line redirection, and couldn't open the file specified after '<' on the command line for reading. Can't open output file %s as stdout (F) An error peculiar to VMS . Perl does its own command line redirection, and couldn't open the file specified after '>' or '>>' on the command line for writing. Can't open output pipe (name: %s) (P) An error peculiar to VMS . Perl does its own command line redirection, and couldn't open the pipe into which to send data destined for stdout. Can't open perl script%s (F) The script you specified can't be opened for the indicated reason. If you're debugging a script that uses #!, and normally relies on the shell's $PATH search, the -S option causes perl to do that search, so you don't have to type the path or \"`which $scriptname`\". Can't read CRTL environ (S) A warning peculiar to VMS . Perl tried to read an element of %ENV from the CRTL 's internal environment array and discovered the array was missing. You need to figure out where your CRTL misplaced its environ or define PERL_ENV_TABLES (see perlvms) so that environ is not searched. Can't \"redo\" outside a loop block (F) A \"redo\" statement was executed to restart the current block, but there isn't a current block. Note that an \"if\" or \"else\" block doesn't count as a \"loopish\" block, as doesn't a block given to sort(), map() or grep(). You can usually double the curlies to get the same effect though, because the inner curlies will be considered a block that loops once. See \"redo\" in perlfunc. Can't remove %s: %s, skipping file (S inplace) You requested an inplace edit without creating a backup file. Perl was unable to remove the original file to replace it with the modified file. The file was left unmodified. Can't rename %s to %s: %s, skipping file (S inplace) The rename done by the -i switch failed for some reason, probably because you don't have write permission to the directory. Can't reopen input pipe (name: %s) in binary mode (P) An error peculiar to VMS . Perl thought stdin was a pipe, and tried to reopen it to accept binary data. Alas, it failed. Can't resolve method '%s' overloading '%s' in package '%s' (F|P) Error resolving overloading specified by a method name (as opposed to a subroutine reference): no such method callable via the package. If method name is \"???\", this is an internal error. Can't reswap uid and euid (P) The setreuid() call failed for some reason in the setuid emulator of suidperl. Can't return %s from lvalue subroutine (F) Perl detected an attempt to return illegal lvalues (such as temporary or readonly values) from a subroutine used as an lvalue. This is not allowed. Can't return outside a subroutine (F) The return statement was executed in mainline code, that is, where there was no subroutine call to return out of. See perlsub. Can't return %s to lvalue scalar context (F) You tried to return a complete array or hash from an lvalue subroutine, but you called the subroutine in a way that made Perl think you meant to return only one value. You probably meant to write parentheses around the call to the subroutine, which tell Perl that the call should be in list context. Can't stat script \"%s\" (P) For some reason you can't fstat() the script even though you have it open already. Bizarre. Can't swap uid and euid (P) The setreuid() call failed for some reason in the setuid emulator of suidperl. Can't take log of %g (F) For ordinary real numbers, you can't take the logarithm of a negative number or zero. There's a Math::Complex package that comes standard with Perl, though, if you really want to do that for the negative numbers. Can't take sqrt of %g (F) For ordinary real numbers, you can't take the square root of a negative number. There's a Math::Complex package that comes standard with Perl, though, if you really want to do that. Can't undef active subroutine (F) You can't undefine a routine that's currently running. You can, however, redefine it while it's running, and you can even undef the redefined subroutine while the old routine is running. Go figure. Can't unshift (F) You tried to unshift an \"unreal\" array that can't be unshifted, such as the main Perl stack. Can't upgrade %s (%d) to %d (P) The internal sv_upgrade routine adds \"members\" to an SV , making it into a more specialized kind of SV . The top several SV types are so specialized, however, that they cannot be interconverted. This message indicates that such a conversion was attempted. Can't use anonymous symbol table for method lookup (F) The internal routine that does method lookup was handed a symbol table that doesn't have a name. Symbol tables can become anonymous for example by undefining stashes: \"undef %Some::Package::\". Can't use an undefined value as %s reference (F) A value used as either a hard reference or a symbolic reference must be a defined value. This helps to delurk some insidious errors. Can't use bareword (\"%s\") as %s ref while \"strict refs\" in use (F) Only hard references are allowed by \"strict refs\". Symbolic references are disallowed. See perlref. Can't use %! because Errno.pm is not available (F) The first time the %! hash is used, perl automatically loads the Errno.pm module. The Errno module is expected to tie the %! hash to provide symbolic names for $! errno values. Can't use both '<' and '>' after type '%c' in %s (F) A type cannot be forced to have both big-endian and little-endian byte-order at the same time, so this combination of modifiers is not allowed. See \"pack\" in perlfunc. Can't use %s for loop variable (F) Only a simple scalar variable may be used as a loop variable on a foreach. Can't use global %s in \"%s\" (F) You tried to declare a magical variable as a lexical variable. This is not allowed, because the magic can be tied to only one location (namely the global variable) and it would be incredibly confusing to have variables in your program that looked like magical variables but weren't. Can't use '%c' in a group with different byte-order in %s (F) You attempted to force a different byte-order on a type that is already inside a group with a byte-order modifier. For example you cannot force little-endianness on a type that is inside a big-endian group. Can't use \"my %s\" in sort comparison (F) The global variables $a and $b are reserved for sort comparisons. You mentioned $a or $b in the same line as the <=> or cmp operator, and the variable had earlier been declared as a lexical variable. Either qualify the sort variable with the package name, or rename the lexical variable. Can't use %s ref as %s ref (F) You've mixed up your reference types. You have to dereference a reference of the type needed. You can use the ref() function to test the type of the reference, if need be. Can't use string (\"%s\") as %s ref while \"strict refs\" in use (F) Only hard references are allowed by \"strict refs\". Symbolic references are disallowed. See perlref. Can't use subscript on %s (F) The compiler tried to interpret a bracketed expression as a subscript. But to the left of the brackets was an expression that didn't look like a hash or array reference, or anything else subscriptable. Can't use \\%c to mean $%c in expression (W syntax) In an ordinary expression, backslash is a unary operator that creates a reference to its argument. The use of backslash to indicate a backreference to a matched substring is valid only as part of a regular expression pattern. Trying to do this in ordinary Perl code produces a value that prints out looking like SCALAR (0xdecaf). Use the $1 form instead. Can't use \"when\" outside a topicalizer (F) You have used a when() block that is neither inside a \"foreach\" loop nor a \"given\" block. (Note that this error is issued on exit from the \"when\" block, so you won't get the error if the match fails, or if you use an explicit \"continue\".) Can't weaken a nonreference (F) You attempted to weaken something that was not a reference. Only references can be weakened. Can't x= to read-only value (F) You tried to repeat a constant value (often the undefined value) with an assignment operator, which implies modifying the value itself. Perhaps you need to copy the value to a temporary, and repeat that. Character in 'C' format wrapped in pack (W pack) You said pack(\"C\", $x) where $x is either less than 0 or more than 255; the \"C\" format is only for encoding native operating system characters ( ASCII , EBCDIC , and so on) and not for Unicode characters, so Perl behaved as if you meant pack(\"C\", $x & 255) If you actually want to pack Unicode codepoints, use the \"U\" format instead. Character in 'W' format wrapped in pack (W pack) You said pack(\"U0W\", $x) where $x is either less than 0 or more than 255. However, \"U0\"-mode expects all values to fall in the interval [0, 255], so Perl behaved as if you meant: pack(\"U0W\", $x & 255) Character in 'c' format wrapped in pack (W pack) You said pack(\"c\", $x) where $x is either less than -128 or more than 127; the \"c\" format is only for encoding native operating system characters ( ASCII , EBCDIC , and so on) and not for Unicode characters, so Perl behaved as if you meant pack(\"c\", $x & 255); If you actually want to pack Unicode codepoints, use the \"U\" format instead. Character in '%c' format wrapped in unpack (W unpack) You tried something like unpack(\"H\", \"\\x{2a1}\") where the format expects to process a byte (a character with a value below 256), but a higher value was provided instead. Perl uses the value modulus 256 instead, as if you had provided: unpack(\"H\", \"\\x{a1}\") Character(s) in '%c' format wrapped in pack (W pack) You tried something like pack(\"u\", \"\\x{1f3}b\") where the format expects to process a sequence of bytes (character with a value below 256), but some of the characters had a higher value. Perl uses the character values modulus 256 instead, as if you had provided: pack(\"u\", \"\\x{f3}b\") Character(s) in '%c' format wrapped in unpack (W unpack) You tried something like unpack(\"s\", \"\\x{1f3}b\") where the format expects to process a sequence of bytes (character with a value below 256), but some of the characters had a higher value. Perl uses the character values modulus 256 instead, as if you had provided: unpack(\"s\", \"\\x{f3}b\") close() on unopened filehandle %s (W unopened) You tried to close a filehandle that was never opened. closedir() attempted on invalid dirhandle %s (W io) The dirhandle you tried to close is either closed or not really a dirhandle. Check your control flow. Code missing after '\/' (F) You had a (sub-)template that ends with a '\/'. There must be another template code following the slash. See \"pack\" in perlfunc. %s: Command not found (A) You've accidentally run your script through csh instead of Perl. Check the #! line, or manually feed your script into Perl yourself. Compilation failed in require (F) Perl could not compile a file specified in a \"require\" statement. Perl uses this generic message when none of the errors that it encountered were severe enough to halt compilation immediately. Complex regular subexpression recursion limit (%d) exceeded (W regexp) The regular expression engine uses recursion in complex situations where back-tracking is required. Recursion depth is limited to 32766, or perhaps less in architectures where the stack cannot grow arbitrarily. (\"Simple\" and \"medium\" situations are handled without recursion and are not subject to a limit.) Try shortening the string under examination; looping in Perl code (e.g. with \"while\") rather than in the regular expression engine; or rewriting the regular expression so that it is simpler or backtracks less. (See perlfaq2 for information on Mastering Regular Expressions.) cond_broadcast() called on unlocked variable (W threads) Within a thread-enabled program, you tried to call cond_broadcast() on a variable which wasn't locked. The cond_broadcast() function is used to wake up another thread that is waiting in a cond_wait(). To ensure that the signal isn't sent before the other thread has a chance to enter the wait, it is usual for the signaling thread to first wait for a lock on variable. This lock attempt will only succeed after the other thread has entered cond_wait() and thus relinquished the lock. cond_signal() called on unlocked variable (W threads) Within a thread-enabled program, you tried to call cond_signal() on a variable which wasn't locked. The cond_signal() function is used to wake up another thread that is waiting in a cond_wait(). To ensure that the signal isn't sent before the other thread has a chance to enter the wait, it is usual for the signaling thread to first wait for a lock on variable. This lock attempt will only succeed after the other thread has entered cond_wait() and thus relinquished the lock. connect() on closed socket %s (W closed) You tried to do a connect on a closed socket. Did you forget to check the return value of your socket() call? See \"connect\" in perlfunc. Constant(%s)%s: %s (F) The parser found inconsistencies either while attempting to define an overloaded constant, or when trying to find the character name specified in the \"\\N{...}\" escape. Perhaps you forgot to load the corresponding \"overload\" or \"charnames\" pragma? See charnames and overload. Constant(%s)%s: %s in regex; marked by <-- HERE in m\/%s\/ (F) The parser found inconsistencies while attempting to find the character name specified in the \"\\N{...}\" escape. Perhaps you forgot to load the corresponding \"charnames\" pragma? See charnames. Constant is not %s reference (F) A constant value (perhaps declared using the \"use constant\" pragma) is being dereferenced, but it amounts to the wrong type of reference. The message indicates the type of reference that was expected. This usually indicates a syntax error in dereferencing the constant value. See \"Constant Functions\" in perlsub and constant. Constant subroutine %s redefined (S) You redefined a subroutine which had previously been eligible for inlining. See \"Constant Functions\" in perlsub for commentary and workarounds. Constant subroutine %s undefined (W misc) You undefined a subroutine which had previously been eligible for inlining. See \"Constant Functions\" in perlsub for commentary and workarounds. Copy method did not return a reference (F) The method which overloads \"=\" is buggy. See \"Copy Constructor\" in overload. CORE::%s is not a keyword (F) The CORE:: namespace is reserved for Perl keywords. corrupted regexp pointers (P) The regular expression engine got confused by what the regular expression compiler gave it. corrupted regexp program (P) The regular expression engine got passed a regexp program without a valid magic number. Corrupt malloc ptr 0x%lx at 0x%lx (P) The malloc package that comes with Perl had an internal failure. Count after length\/code in unpack (F) You had an unpack template indicating a counted-length string, but you have also specified an explicit size for the string. See \"pack\" in perlfunc. Deep recursion on subroutine \"%s\" (W recursion) This subroutine has called itself (directly or indirectly) 100 times more than it has returned. This probably indicates an infinite recursion, unless you're writing strange benchmark programs, in which case it indicates something else. This threshold can be changed from 100, by recompiling the perl binary, setting the C pre-processor macro \"PERL_SUB_DEPTH_WARN\" to the desired value. defined(@array) is deprecated (D deprecated) defined() is not usually useful on arrays because it checks for an undefined scalar value. If you want to see if the array is empty, just use \"if (@array) { # not empty }\" for example. defined(%hash) is deprecated (D deprecated) defined() is not usually useful on hashes because it checks for an undefined scalar value. If you want to see if the hash is empty, just use \"if (%hash) { # not empty }\" for example. %s defines neither package nor VERSION--version check failed (F) You said something like \"use Module 42\" but in the Module file there are neither package declarations nor a $VERSION. Delimiter for here document is too long (F) In a here document construct like \"<<FOO\", the label \"FOO\" is too long for Perl to handle. You have to be seriously twisted to write code that triggers this error. Deprecated use of my() in false conditional (D deprecated) You used a declaration similar to \"my $x if 0\". There has been a long-standing bug in Perl that causes a lexical variable not to be cleared at scope exit when its declaration includes a false conditional. Some people have exploited this bug to achieve a kind of static variable. Since we intend to fix this bug, we don't want people relying on this behavior. You can achieve a similar static effect by declaring the variable in a separate block outside the function, eg sub f { my $x if 0; return $x++ } becomes { my $x; sub f { return $x++ } } Beginning with perl 5.9.4, you can also use \"state\" variables to have lexicals that are initialized only once (see feature): sub f { state $x; return $x++ } DESTROY created new reference to dead object '%s' (F) A DESTROY () method created a new reference to the object which is just being DESTROYed. Perl is confused, and prefers to abort rather than to create a dangling reference. Did not produce a valid header See Server error. %s did not return a true value (F) A required (or used) file must return a true value to indicate that it compiled correctly and ran its initialization code correctly. It's traditional to end such a file with a \"1;\", though any true value would do. See \"require\" in perlfunc. (Did you mean &%s instead?) (W) You probably referred to an imported subroutine &FOO as $FOO or some such. (Did you mean \"local\" instead of \"our\"?) (W misc) Remember that \"our\" does not localize the declared global variable. You have declared it again in the same lexical scope, which seems superfluous. (Did you mean $ or @ instead of %?) (W) You probably said %hash{$key} when you meant $hash{$key} or @hash{@keys}. On the other hand, maybe you just meant %hash and got carried away. Died (F) You passed die() an empty string (the equivalent of \"die \"\"\") or you called it with no args and both $@ and $_ were empty. Document contains no data See Server error. %s does not define %s::VERSION--version check failed (F) You said something like \"use Module 42\" but the Module did not define a \"$VERSION.\" '\/' does not take a repeat count (F) You cannot put a repeat count of any kind right after the '\/' code. See \"pack\" in perlfunc. Don't know how to handle magic of type '%s' (P) The internal handling of magical variables has been cursed. do_study: out of memory (P) This should have been caught by safemalloc() instead. (Do you need to predeclare %s?) (S syntax) This is an educated guess made in conjunction with the message \"%s found where operator expected\". It often means a subroutine or module name is being referenced that hasn't been declared yet. This may be because of ordering problems in your file, or because of a missing \"sub\", \"package\", \"require\", or \"use\" statement. If you're referencing something that isn't defined yet, you don't actually have to define the subroutine or package before the current location. You can use an empty \"sub foo;\" or \"package FOO ;\" to enter a \"forward\" declaration. dump() better written as CORE::dump() (W misc) You used the obsolescent \"dump()\" built-in function, without fully qualifying it as \"CORE::dump()\". Maybe it's a typo. See \"dump\" in perlfunc. dump is not supported (F) Your machine doesn't support dump\/undump. Duplicate free() ignored (S malloc) An internal routine called free() on something that had already been freed. Duplicate modifier '%c' after '%c' in %s (W) You have applied the same modifier more than once after a type in a pack template. See \"pack\" in perlfunc. elseif should be elsif (S syntax) There is no keyword \"elseif\" in Perl because Larry thinks it's ugly. Your code will be interpreted as an attempt to call a method named \"elseif\" for the class returned by the following block. This is unlikely to be what you want. Empty %s (F) \"\\p\" and \"\\P\" are used to introduce a named Unicode property, as described in perlunicode and perlre. You used \"\\p\" or \"\\P\" in a regular expression without specifying the property name. entering effective %s failed (F) While under the \"use filetest\" pragma, switching the real and effective uids or gids failed. %ENV is aliased to %s (F) You're running under taint mode, and the %ENV variable has been aliased to another hash, so it doesn't reflect anymore the state of the program's environment. This is potentially insecure. Error converting file specification %s (F) An error peculiar to VMS . Because Perl may have to deal with file specifications in either VMS or Unix syntax, it converts them to a single form when it must operate on them directly. Either you've passed an invalid file specification to Perl, or you've found a case the conversion routines don't handle. Drat. %s: Eval-group in insecure regular expression (F) Perl detected tainted data when trying to compile a regular expression that contains the \"(?{ ... })\" zero-width assertion, which is unsafe. See \"(?{ code })\" in perlre, and perlsec. %s: Eval-group not allowed at runtime, use re 'eval' (F) Perl tried to compile a regular expression containing the \"(?{ ... })\" zero-width assertion at run time, as it would when the pattern contains interpolated values. Since that is a security risk, it is not allowed. If you insist, you may still do this by explicitly building the pattern from an interpolated string at run time and using that in an eval(). See \"(?{ code })\" in perlre. %s: Eval-group not allowed, use re 'eval' (F) A regular expression contained the \"(?{ ... })\" zero-width assertion, but that construct is only allowed when the \"use re 'eval'\" pragma is in effect. See \"(?{ code })\" in perlre. EVAL without pos change exceeded limit in regex; marked by <-- HERE in m\/%s\/ (F) You used a pattern that nested too many EVAL calls without consuming any text. Restructure the pattern so that text is consumed. The <-- HERE shows in the regular expression about where the problem was discovered. Excessively long <> operator (F) The contents of a <> operator may not exceed the maximum size of a Perl identifier. If you're just trying to glob a long list of filenames, try using the glob() operator, or put the filenames into a variable and glob that. exec? I'm not *that* kind of operating system (F) The \"exec\" function is not implemented in MacPerl. See perlport. Execution of %s aborted due to compilation errors (F) The final summary message when a Perl compilation fails. Exiting eval via %s (W exiting) You are exiting an eval by unconventional means, such as a goto, or a loop control statement. Exiting format via %s (W exiting) You are exiting a format by unconventional means, such as a goto, or a loop control statement. Exiting pseudo-block via %s (W exiting) You are exiting a rather special block construct (like a sort block or subroutine) by unconventional means, such as a goto, or a loop control statement. See \"sort\" in perlfunc. Exiting subroutine via %s (W exiting) You are exiting a subroutine by unconventional means, such as a goto, or a loop control statement. Exiting substitution via %s (W exiting) You are exiting a substitution by unconventional means, such as a return, a goto, or a loop control statement. Explicit blessing to '' (assuming package main) (W misc) You are blessing a reference to a zero length string. This has the effect of blessing the reference into the package main. This is usually not what you want. Consider providing a default target package, e.g. bless($ref, $p || 'MyPackage'); %s: Expression syntax (A) You've accidentally run your script through csh instead of Perl. Check the #! line, or manually feed your script into Perl yourself. %s failed--call queue aborted (F) An untrapped exception was raised while executing a UNITCHECK , CHECK , INIT , or END subroutine. Processing of the remainder of the queue of such routines has been prematurely ended. False [] range \"%s\" in regex; marked by <-- HERE in m\/%s\/ (W regexp) A character class range must start and end at a literal character, not another character class like \"\\d\" or \"[:alpha:]\". The \"-\" in your false range is interpreted as a literal \"-\". Consider quoting the \"-\", \"\\-\". The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Fatal VMS error at %s, line %d (P) An error peculiar to VMS . Something untoward happened in a VMS system service or RTL routine; Perl's exit status should provide more details. The filename in \"at %s\" and the line number in \"line %d\" tell you which section of the Perl source code is distressed. fcntl is not implemented (F) Your machine apparently doesn't implement fcntl(). What is this, a PDP-11 or something? FETCHSIZE returned a negative value (F) A tied array claimed to have a negative number of elements, which is not possible. Field too wide in 'u' format in pack (W pack) Each line in an uuencoded string start with a length indicator which can't encode values above 63. So there is no point in asking for a line length bigger than that. Perl will behave as if you specified \"u63\" as format. Filehandle %s opened only for input (W io) You tried to write on a read-only filehandle. If you intended it to be a read-write filehandle, you needed to open it with \"+<\" or \"+>\" or \"+>>\" instead of with \"<\" or nothing. If you intended only to write the file, use \">\" or \">>\". See \"open\" in perlfunc. Filehandle %s opened only for output (W io) You tried to read from a filehandle opened only for writing, If you intended it to be a read\/write filehandle, you needed to open it with \"+<\" or \"+>\" or \"+>>\" instead of with \"<\" or nothing. If you intended only to read from the file, use \"<\". See \"open\" in perlfunc. Another possibility is that you attempted to open filedescriptor 0 (also known as STDIN ) for output (maybe you closed STDIN earlier?). Filehandle %s reopened as %s only for input (W io) You opened for reading a filehandle that got the same filehandle id as STDOUT or STDERR . This occurred because you closed STDOUT or STDERR previously. Filehandle STDIN reopened as %s only for output (W io) You opened for writing a filehandle that got the same filehandle id as STDIN . This occurred because you closed STDIN previously. Final $ should be \\$ or $name (F) You must now decide whether the final $ in a string was meant to be a literal dollar sign, or was meant to introduce a variable name that happens to be missing. So you have to put either the backslash or the name. flock() on closed filehandle %s (W closed) The filehandle you're attempting to flock() got itself closed some time before now. Check your control flow. flock() operates on filehandles. Are you attempting to call flock() on a dirhandle by the same name? Format not terminated (F) A format must be terminated by a line with a solitary dot. Perl got to the end of your file without finding such a line. Format %s redefined (W redefine) You redefined a format. To suppress this warning, say {\n    no warnings 'redefine';\n    eval \"format NAME =...\";\n} Found = in conditional, should be == (W syntax) You said if ($foo = 123) when you meant if ($foo == 123) (or something like that). %s found where operator expected (S syntax) The Perl lexer knows whether to expect a term or an operator. If it sees what it knows to be a term when it was expecting to see an operator, it gives you this warning. Usually it indicates that an operator or delimiter was omitted, such as a semicolon. gdbm store returned %d, errno %d, key \"%s\" (S) A warning from the GDBM_File extension that a store failed. gethostent not implemented (F) Your C library apparently doesn't implement gethostent(), probably because if it did, it'd feel morally obligated to return every hostname on the Internet. get% sname() on closed socket %s (W closed) You tried to get a socket or peer socket name on a closed socket. Did you forget to check the return value of your socket() call? getpwnam returned invalid UIC %#o for user \"%s\" (S) A warning peculiar to VMS . The call to \"sys$getuai\" underlying the \"getpwnam\" operator returned an invalid UIC . getsockopt() on closed socket %s (W closed) You tried to get a socket option on a closed socket. Did you forget to check the return value of your socket() call? See \"getsockopt\" in perlfunc. Global symbol \"%s\" requires explicit package name (F) You've said \"use strict\" or \"use strict vars\", which indicates that all variables must either be lexically scoped (using \"my\" or \"state\"), declared beforehand using \"our\", or explicitly qualified to say which package the global variable is in (using \"::\"). glob failed (%s) (W glob) Something went wrong with the external program(s) used for \"glob\" and \"<*.c>\". Usually, this means that you supplied a \"glob\" pattern that caused the external program to fail and exit with a nonzero status. If the message indicates that the abnormal exit resulted in a coredump, this may also mean that your csh (C shell) is broken. If so, you should change all of the csh-related variables in config.sh: If you have tcsh, make the variables refer to it as if it were csh (e.g. \"full_csh='\/usr\/bin\/tcsh'\"); otherwise, make them all empty (except that \"d_csh\" should be 'undef') so that Perl will think csh is missing. In either case, after editing config.sh, run \".\/Configure -S\" and rebuild Perl. Glob not terminated (F) The lexer saw a left angle bracket in a place where it was expecting a term, so it's looking for the corresponding right angle bracket, and not finding it. Chances are you left some needed parentheses out earlier in the line, and you really meant a \"less than\". Got an error from DosAllocMem (P) An error peculiar to OS\/2 . Most probably you're using an obsolete version of Perl, and this should not happen anyway. goto must have label (F) Unlike with \"next\" or \"last\", you're not allowed to goto an unspecified destination. See \"goto\" in perlfunc. ()-group starts with a count (F) A ()-group started with a count. A count is supposed to follow something: a template character or a ()-group. See \"pack\" in perlfunc. %s had compilation errors (F) The final summary message when a \"perl -c\" fails. Had to create %s unexpectedly (S internal) A routine asked for a symbol from a symbol table that ought to have existed already, but for some reason it didn't, and had to be created on an emergency basis to prevent a core dump. Hash %%s missing the % in argument %d of %s() (D deprecated) Really old Perl let you omit the % on hash names in some spots. This is now heavily deprecated. %s has too many errors (F) The parser has given up trying to parse the program after 10 errors. Further error messages would likely be uninformative. Hexadecimal number > 0xffffffff non-portable (W portable) The hexadecimal number you specified is larger than 2**32-1 (4294967295) and therefore non-portable between systems. See perlport for more on portability concerns. Identifier too long (F) Perl limits identifiers (names for variables, functions, etc.) to about 250 characters for simple names, and somewhat more for compound names (like $A::B). You've exceeded Perl's limits. Future versions of Perl are likely to eliminate these arbitrary limitations. Ignoring %s in character class in regex; marked by <-- HERE in m\/%s\/ (W) Named Unicode character escapes (\\N{...}) may return multi-char or zero length sequences. When such an escape is used in a character class its behaviour is not well defined. Check that the correct escape has been used, and the correct charname handler is in scope. Illegal binary digit %s (F) You used a digit other than 0 or 1 in a binary number. Illegal binary digit %s ignored (W digit) You may have tried to use a digit other than 0 or 1 in a binary number. Interpretation of the binary number stopped before the offending digit. Illegal character %s (carriage return) (F) Perl normally treats carriage returns in the program text as it would any other whitespace, which means you should never see this error when Perl was built using standard options. For some reason, your version of Perl appears to have been built without this support. Talk to your Perl administrator. Illegal character in prototype for %s : %s (W syntax) An illegal character was found in a prototype declaration. Legal characters in prototypes are $, @, %, *, ;, [, ], &, and \\. Illegal declaration of anonymous subroutine (F) When using the \"sub\" keyword to construct an anonymous subroutine, you must always specify a block of code. See perlsub. Illegal declaration of subroutine %s (F) A subroutine was not declared correctly. See perlsub. Illegal division by zero (F) You tried to divide a number by 0. Either something was wrong in your logic, or you need to put a conditional in to guard against meaningless input. Illegal hexadecimal digit %s ignored (W digit) You may have tried to use a character other than 0 - 9 or A - F, a - f in a hexadecimal number. Interpretation of the hexadecimal number stopped before the illegal character. Illegal modulus zero (F) You tried to divide a number by 0 to get the remainder. Most numbers don't take to this kindly. Illegal number of bits in vec (F) The number of bits in vec() (the third argument) must be a power of two from 1 to 32 (or 64, if your platform supports that). Illegal octal digit %s (F) You used an 8 or 9 in an octal number. Illegal octal digit %s ignored (W digit) You may have tried to use an 8 or 9 in an octal number. Interpretation of the octal number stopped before the 8 or 9. Illegal switch in PERL5OPT: %s (X) The PERL5OPT environment variable may only be used to set the following switches: -[CDIMUdmtw]. Ill-formed CRTL environ value \"%s\" (W internal) A warning peculiar to VMS . Perl tried to read the CRTL 's internal environ array, and encountered an element without the \"=\" delimiter used to separate keys from values. The element is ignored. Ill-formed message in prime_env_iter: |%s| (W internal) A warning peculiar to VMS . Perl tried to read a logical name or CLI symbol definition when preparing to iterate over %ENV, and didn't see the expected delimiter between key and value, so the line was ignored. (in cleanup) %s (W misc) This prefix usually indicates that a DESTROY () method raised the indicated exception. Since destructors are usually called by the system at arbitrary points during execution, and often a vast number of times, the warning is issued only once for any number of failures that would otherwise result in the same message being repeated. Failure of user callbacks dispatched using the \"G_KEEPERR\" flag could also result in this warning. See \"G_KEEPERR\" in perlcall. Inconsistent hierarchy during C3 merge of class '%s': merging failed on parent '%s' (F) The method resolution order ( MRO ) of the given class is not C3-consistent, and you have enabled the C3 MRO for this class. See the C3 documentation in mro for more information. In EBCDIC the v-string components cannot exceed 2147483647 (F) An error peculiar to EBCDIC . Internally, v-strings are stored as Unicode code points, and encoded in EBCDIC as UTF-EBCDIC. The UTF-EBCDIC encoding is limited to code points no larger than 2147483647 (0x7FFFFFFF). Infinite recursion in regex; marked by <-- HERE in m\/%s\/ (F) You used a pattern that references itself without consuming any input text. You should check the pattern to ensure that recursive patterns either consume text or fail. The <-- HERE shows in the regular expression about where the problem was discovered. Initialization of state variables in list context currently forbidden (F) Currently the implementation of \"state\" only permits the initialization of scalar variables in scalar context. Re-write \"state ($a) = 42\" as \"state $a = 42\" to change from list to scalar context. Constructions such as \"state (@a) = foo()\" will be supported in a future perl release. Insecure dependency in %s (F) You tried to do something that the tainting mechanism didn't like. The tainting mechanism is turned on when you're running setuid or setgid, or when you specify -T to turn it on explicitly. The tainting mechanism labels all data that's derived directly or indirectly from the user, who is considered to be unworthy of your trust. If any such data is used in a \"dangerous\" operation, you get this error. See perlsec for more information. Insecure directory in %s (F) You can't use system(), exec(), or a piped open in a setuid or setgid script if $ENV{PATH} contains a directory that is writable by the world. Also, the PATH must not contain any relative directory. See perlsec. Insecure $ENV{%s} while running %s (F) You can't use system(), exec(), or a piped open in a setuid or setgid script if any of $ENV{PATH}, $ENV{IFS}, $ENV{CDPATH}, $ENV{ENV}, $ENV{BASH_ENV} or $ENV{TERM} are derived from data supplied (or potentially supplied) by the user. The script must set the path to a known value, using trustworthy data. See perlsec. Integer overflow in %s number (W overflow) The hexadecimal, octal or binary number you have specified either as a literal or as an argument to hex() or oct() is too big for your architecture, and has been converted to a floating point number. On a 32-bit architecture the largest hexadecimal, octal or binary number representable without overflow is 0xFFFFFFFF, 037777777777, or 0b11111111111111111111111111111111 respectively. Note that Perl transparently promotes all numbers to a floating point representation internally--subject to loss of precision errors in subsequent operations. Integer overflow in format string for %s (F) The indexes and widths specified in the format string of \"printf()\" or \"sprintf()\" are too large. The numbers must not overflow the size of integers for your architecture. Integer overflow in version (F) Some portion of a version initialization is too large for the size of integers for your architecture. This is not a warning because there is no rational reason for a version to try and use a element larger than typically 2**32. This is usually caused by trying to use some odd mathematical operation as a version, like 100\/9. Internal disaster in regex; marked by <-- HERE in m\/%s\/ (P) Something went badly wrong in the regular expression parser. The <-- HERE shows in the regular expression about where the problem was discovered. Internal inconsistency in tracking vforks (S) A warning peculiar to VMS . Perl keeps track of the number of times you've called \"fork\" and \"exec\", to determine whether the current call to \"exec\" should affect the current script or a subprocess (see \"exec LIST \" in perlvms). Somehow, this count has become scrambled, so Perl is making a guess and treating this \"exec\" as a request to terminate the Perl script and execute the specified command. Internal urp in regex; marked by <-- HERE in m\/%s\/ (P) Something went badly awry in the regular expression parser. The <-- HERE shows in the regular expression about where the problem was discovered. %s (...) interpreted as function (W syntax) You've run afoul of the rule that says that any list operator followed by parentheses turns into a function, with all the list operators arguments found inside the parentheses. See \"Terms and List Operators (Leftward)\" in perlop. Invalid %s attribute: %s The indicated attribute for a subroutine or variable was not recognized by Perl or by a user-supplied handler. See attributes. Invalid %s attributes: %s The indicated attributes for a subroutine or variable were not recognized by Perl or by a user-supplied handler. See attributes. Invalid conversion in %s: \"%s\" (W printf) Perl does not understand the given format conversion. See \"sprintf\" in perlfunc. Invalid escape in the specified encoding in regex; marked by <-- HERE in m\/%s\/ (W regexp) The numeric escape (for example \"\\xHH\") of value < 256 didn't correspond to a single character through the conversion from the encoding specified by the encoding pragma. The escape was replaced with REPLACEMENT CHARACTER (U+FFFD) instead. The <-- HERE shows in the regular expression about where the escape was discovered. Invalid mro name: '%s' (F) You tried to \"mro::set_mro(\"classname\", \"foo\")\" or \"use mro 'foo'\", where \"foo\" is not a valid method resolution order ( MRO ). (Currently, the only valid ones are \"dfs\" and \"c3\"). See mro. Invalid [] range \"%s\" in regex; marked by <-- HERE in m\/%s\/ (F) The range specified in a character class had a minimum character greater than the maximum character. One possibility is that you forgot the \"{}\" from your ending \"\\x{}\" - \"\\x\" without the curly braces can go only up to \"ff\". The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Invalid range \"%s\" in transliteration operator (F) The range specified in the tr\/\/\/ or y\/\/\/ operator had a minimum character greater than the maximum character. See perlop. Invalid separator character %s in attribute list (F) Something other than a colon or whitespace was seen between the elements of an attribute list. If the previous attribute had a parenthesised parameter list, perhaps that list was terminated too soon. See attributes. Invalid separator character %s in PerlIO layer specification %s (W layer) When pushing layers onto the Perl I\/O system, something other than a colon or whitespace was seen between the elements of a layer list. If the previous attribute had a parenthesised parameter list, perhaps that list was terminated too soon. Invalid type '%s' in %s (F) The given character is not a valid pack or unpack type. See \"pack\" in perlfunc. (W) The given character is not a valid pack or unpack type but used to be silently ignored. Invalid version format (multiple underscores) (F) Versions may contain at most a single underscore, which signals that the version is a beta release. See version for the allowed version formats. Invalid version format (underscores before decimal) (F) Versions may not contain decimals after the optional underscore. See version for the allowed version formats. ioctl is not implemented (F) Your machine apparently doesn't implement ioctl(), which is pretty strange for a machine that supports C. ioctl() on unopened %s (W unopened) You tried ioctl() on a filehandle that was never opened. Check you control flow and number of arguments. IO layers (like \"%s\") unavailable (F) Your Perl has not been configured to have PerlIO, and therefore you cannot use IO layers. To have PerlIO Perl must be configured with 'useperlio'. IO::Socket::atmark not implemented on this architecture (F) Your machine doesn't implement the sockatmark() functionality, neither as a system call or an ioctl call ( SIOCATMARK ). $* is no longer supported (S deprecated, syntax) The special variable $*, deprecated in older perls, has been removed as of 5.9.0 and is no longer supported. In previous versions of perl the use of $* enabled or disabled multi-line matching within a string. Instead of using $* you should use the \"\/m\" (and maybe \"\/s\") regexp modifiers. (In older versions: when $* was set to a true value then all regular expressions behaved as if they were written using \"\/m\".) $# is no longer supported (S deprecated, syntax) The special variable $#, deprecated in older perls, has been removed as of 5.9.3 and is no longer supported. You should use the printf\/sprintf functions instead. '%s' is not a code reference (W overload) The second (fourth, sixth, ...) argument of overload::constant needs to be a code reference. Either an anonymous subroutine, or a reference to a subroutine. '%s' is not an overloadable type (W overload) You tried to overload a constant type the overload package is unaware of. junk on end of regexp (P) The regular expression parser is confused. Label not found for \"last %s\" (F) You named a loop to break out of, but you're not currently in a loop of that name, not even if you count where you were called from. See \"last\" in perlfunc. Label not found for \"next %s\" (F) You named a loop to continue, but you're not currently in a loop of that name, not even if you count where you were called from. See \"last\" in perlfunc. Label not found for \"redo %s\" (F) You named a loop to restart, but you're not currently in a loop of that name, not even if you count where you were called from. See \"last\" in perlfunc. leaving effective %s failed (F) While under the \"use filetest\" pragma, switching the real and effective uids or gids failed. length\/code after end of string in unpack (F) While unpacking, the string buffer was already used up when an unpack length\/code combination tried to obtain more data. This results in an undefined value for the length. See \"pack\" in perlfunc. listen() on closed socket %s (W closed) You tried to do a listen on a closed socket. Did you forget to check the return value of your socket() call? See \"listen\" in perlfunc. Lookbehind longer than %d not implemented in regex m\/%s\/ (F) There is currently a limit on the length of string which lookbehind can handle. This restriction may be eased in a future release. lstat() on filehandle %s (W io) You tried to do an lstat on a filehandle. What did you mean by that? lstat() makes sense only on filenames. (Perl did a fstat() instead on the filehandle.) Lvalue subs returning %s not implemented yet (F) Due to limitations in the current implementation, array and hash values cannot be returned in subroutines used in lvalue context. See \"Lvalue subroutines\" in perlsub. Malformed integer in [] in pack (F) Between the brackets enclosing a numeric repeat count only digits are permitted. See \"pack\" in perlfunc. Malformed integer in [] in unpack (F) Between the brackets enclosing a numeric repeat count only digits are permitted. See \"pack\" in perlfunc. Malformed PERLLIB_PREFIX (F) An error peculiar to OS\/2 . PERLLIB_PREFIX should be of the form prefix1;prefix2 or prefix1 prefix2 with nonempty prefix1 and prefix2. If \"prefix1\" is indeed a prefix of a builtin library search path, prefix2 is substituted. The error may appear if components are not found, or are too long. See \" PERLLIB_PREFIX \" in perlos2. Malformed prototype for %s: %s (F) You tried to use a function with a malformed prototype. The syntax of function prototypes is given a brief compile-time check for obvious errors like invalid characters. A more rigorous check is run when the function is called. Malformed UTF-8 character (%s) (S utf8) (F) Perl detected a string that didn't comply with UTF-8 encoding rules, even though it had the UTF8 flag on. One possible cause is that you set the UTF8 flag yourself for data that you thought to be in UTF-8 but it wasn't (it was for example legacy 8-bit data). To guard against this, you can use Encode::decode_utf8. If you use the \":encoding(UTF-8)\" PerlIO layer for input, invalid byte sequences are handled gracefully, but if you use \":utf8\", the flag is set without validating the data, possibly resulting in this error message. See also \"Handling Malformed Data\" in Encode. Malformed UTF-16 surrogate Perl thought it was reading UTF-16 encoded character data but while doing it Perl met a malformed Unicode surrogate. Malformed UTF-8 string in pack (F) You tried to pack something that didn't comply with UTF-8 encoding rules and perl was unable to guess how to make more progress. Malformed UTF-8 string in unpack (F) You tried to unpack something that didn't comply with UTF-8 encoding rules and perl was unable to guess how to make more progress. Malformed UTF-8 string in '%c' format in unpack (F) You tried to unpack something that didn't comply with UTF-8 encoding rules and perl was unable to guess how to make more progress. Maximal count of pending signals (%s) exceeded (F) Perl aborted due to a too important number of signals pending. This usually indicates that your operating system tried to deliver signals too fast (with a very high priority), starving the perl process from resources it would need to reach a point where it can process signals safely. (See \"Deferred Signals (Safe Signals)\" in perlipc.) %s matches null string many times in regex; marked by <-- HERE in m\/%s\/ (W regexp) The pattern you've specified would be an infinite loop if the regular expression engine didn't specifically check for that. The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. \"%s\" may clash with future reserved word (W) This warning may be due to running a perl5 script through a perl4 interpreter, especially if the word that is being warned about is \"use\" or \"my\". % may not be used in pack (F) You can't pack a string by supplying a checksum, because the checksumming process loses information, and you can't go the other way. See \"unpack\" in perlfunc. Method for operation %s not found in package %s during blessing (F) An attempt was made to specify an entry in an overloading table that doesn't resolve to a valid subroutine. See overload. Method %s not permitted See Server error. Might be a runaway multi-line %s string starting on line %d (S) An advisory indicating that the previous error may have been caused by a missing delimiter on a string or pattern, because it eventually ended earlier on the current line. Misplaced _ in number (W syntax) An underscore (underbar) in a numeric constant did not separate two digits. Missing argument to -%c (F) The argument to the indicated command line switch must follow immediately after the switch, without intervening spaces. Missing %sbrace%s on \\N{} (F) Wrong syntax of character name literal \"\\N{charname}\" within double-quotish context. Missing comma after first argument to %s function (F) While certain functions allow you to specify a filehandle or an \"indirect object\" before the argument list, this ain't one of them. Missing command in piped open (W pipe) You used the \"open(FH, \"| command\")\" or \"open(FH, \"command |\")\" construction, but the command was missing or blank. Missing control char name in \\c (F) A double-quoted string ended with \"\\c\", without the required control character name. Missing name in \"my sub\" (F) The reserved syntax for lexically scoped subroutines requires that they have a name with which they can be found. Missing $ on loop variable (F) Apparently you've been programming in csh too much. Variables are always mentioned with the $ in Perl, unlike in the shells, where it can vary from one line to the next. (Missing operator before %s?) (S syntax) This is an educated guess made in conjunction with the message \"%s found where operator expected\". Often the missing operator is a comma. Missing right brace on %s (F) Missing right brace in \"\\x{...}\", \"\\p{...}\" or \"\\P{...}\". Missing right curly or square bracket (F) The lexer counted more opening curly or square brackets than closing ones. As a general rule, you'll find it's missing near the place you were last editing. (Missing semicolon on previous line?) (S syntax) This is an educated guess made in conjunction with the message \"%s found where operator expected\". Don't automatically put a semicolon on the previous line just because you saw this message. Modification of a read-only value attempted (F) You tried, directly or indirectly, to change the value of a constant. You didn't, of course, try \"2 = 1\", because the compiler catches that. But an easy way to do the same thing is: sub mod { $_[0] = 1 }\nmod(2); Another way is to assign to a substr() that's off the end of the string. Yet another way is to assign to a \"foreach\" loop VAR when VAR is aliased to a constant in the look LIST : $x = 1;\nforeach my $n ($x, 2) {\n    $n *= 2; # modifies the $x, but fails on attempt to modify the 2\n} Modification of non-creatable array value attempted, %s (F) You tried to make an array value spring into existence, and the subscript was probably negative, even counting from end of the array backwards. Modification of non-creatable hash value attempted, %s (P) You tried to make a hash value spring into existence, and it couldn't be created for some peculiar reason. Module name must be constant (F) Only a bare module name is allowed as the first argument to a \"use\". Module name required with -%c option (F) The \"-M\" or \"-m\" options say that Perl should load some module, but you omitted the name of the module. Consult perlrun for full details about \"-M\" and \"-m\". More than one argument to open (F) The \"open\" function has been asked to open multiple files. This can happen if you are trying to open a pipe to a command that takes a list of arguments, but have forgotten to specify a piped open mode. See \"open\" in perlfunc for details. msg%s not implemented (F) You don't have System V message IPC on your system. Multidimensional syntax %s not supported (W syntax) Multidimensional arrays aren't written like $foo[1,2,3]. They're written like $foo[1][2][3], as in C. '\/' must follow a numeric type in unpack (F) You had an unpack template that contained a '\/', but this did not follow some unpack specification producing a numeric value. See \"pack\" in perlfunc. \"my sub\" not yet implemented (F) Lexically scoped subroutines are not yet implemented. Don't try that yet. \"%s\" variable %s can't be in a package (F) Lexically scoped variables aren't in a package, so it doesn't make sense to try to declare one with a package qualifier on the front. Use local() if you want to localize a package variable. Name \"%s::%s\" used only once: possible typo (W once) Typographical errors often show up as unique variable names. If you had a good reason for having a unique name, then just mention it again somehow to suppress the message. The \"our\" declaration is provided for this purpose. NOTE: This warning detects symbols that have been used only once so $c, @c, %c, *c, &c, sub c{}, c(), and c (the filehandle or format) are considered the same; if a program uses $c only once but also uses any of the others it will not trigger this warning. Negative '\/' count in unpack (F) The length count obtained from a length\/code unpack operation was negative. See \"pack\" in perlfunc. Negative length (F) You tried to do a read\/write\/send\/recv operation with a buffer length that is less than 0. This is difficult to imagine. Negative offset to vec in lvalue context (F) When \"vec\" is called in an lvalue context, the second argument must be greater than or equal to zero. Nested quantifiers in regex; marked by <-- HERE in m\/%s\/ (F) You can't quantify a quantifier without intervening parentheses. So things like ** or +* or ?* are illegal. The <-- HERE shows in the regular expression about where the problem was discovered. Note that the minimal matching quantifiers, \"*?\", \"+?\", and \"??\" appear to be nested quantifiers, but aren't. See perlre. %s never introduced (S internal) The symbol in question was declared but somehow went out of scope before it could possibly have been used. next::method\/next::can\/maybe::next::method cannot find enclosing method (F) \"next::method\" needs to be called within the context of a real method in a real package, and it could not find such a context. See mro. No %s allowed while running setuid (F) Certain operations are deemed to be too insecure for a setuid or setgid script to even be allowed to attempt. Generally speaking there will be another way to do what you want that is, if not secure, at least securable. See perlsec. No comma allowed after %s (F) A list operator that has a filehandle or \"indirect object\" is not allowed to have a comma between that and the following arguments. Otherwise it'd be just another one of the arguments. One possible cause for this is that you expected to have imported a constant to your name space with use or import while no such importing took place, it may for example be that your operating system does not support that particular constant. Hopefully you did use an explicit import list for the constants you expect to see, please see \"use\" in perlfunc and \"import\" in perlfunc. While an explicit import list would probably have caught this error earlier it naturally does not remedy the fact that your operating system still does not support that constant. Maybe you have a typo in the constants of the symbol import list of use or import or in the constant name at the line where this error was triggered? No command into which to pipe on command line (F) An error peculiar to VMS . Perl handles its own command line redirection, and found a '|' at the end of the command line, so it doesn't know where you want to pipe the output from this command. No DB::DB routine defined (F) The currently executing code was compiled with the -d switch, but for some reason the current debugger (e.g. perl5db.pl or a \"Devel::\" module) didn't define a routine to be called at the beginning of each statement. No dbm on this machine (P) This is counted as an internal error, because every machine should supply dbm nowadays, because Perl comes with SDBM . See SDBM_File. No DB::sub routine defined (F) The currently executing code was compiled with the -d switch, but for some reason the current debugger (e.g. perl5db.pl or a \"Devel::\" module) didn't define a \"DB::sub\" routine to be called at the beginning of each ordinary subroutine call. No -e allowed in setuid scripts (F) A setuid script can't be specified by the user. No error file after 2> or 2>> on command line (F) An error peculiar to VMS . Perl handles its own command line redirection, and found a '2>' or a '2>>' on the command line, but can't find the name of the file to which to write data destined for stderr. No group ending character '%c' found in template (F) A pack or unpack template has an opening '(' or '[' without its matching counterpart. See \"pack\" in perlfunc. No input file after < on command line (F) An error peculiar to VMS . Perl handles its own command line redirection, and found a '<' on the command line, but can't find the name of the file from which to read data for stdin. No #! line (F) The setuid emulator requires that scripts have a well-formed #! line even on machines that don't support the #! construct. No next::method '%s' found for %s (F) \"next::method\" found no further instances of this method name in the remaining packages of the MRO of this class. If you don't want it throwing an exception, use \"maybe::next::method\" or \"next::can\". See mro. \"no\" not allowed in expression (F) The \"no\" keyword is recognized and executed at compile time, and returns no useful value. See perlmod. No output file after > on command line (F) An error peculiar to VMS . Perl handles its own command line redirection, and found a lone '>' at the end of the command line, so it doesn't know where you wanted to redirect stdout. No output file after > or >> on command line (F) An error peculiar to VMS . Perl handles its own command line redirection, and found a '>' or a '>>' on the command line, but can't find the name of the file to which to write data destined for stdout. No package name allowed for variable %s in \"our\" (F) Fully qualified variable names are not allowed in \"our\" declarations, because that doesn't make much sense under existing semantics. Such syntax is reserved for future extensions. No Perl script found in input (F) You called \"perl -x\", but no line was found in the file beginning with #! and containing the word \"perl\". No setregid available (F) Configure didn't find anything resembling the setregid() call for your system. No setreuid available (F) Configure didn't find anything resembling the setreuid() call for your system. No %s specified for -%c (F) The indicated command line switch needs a mandatory argument, but you haven't specified one. No such class field \"%s\" in variable %s of type %s (F) You tried to access a key from a hash through the indicated typed variable but that key is not allowed by the package of the same type. The indicated package has restricted the set of allowed keys using the fields pragma. No such class %s (F) You provided a class qualifier in a \"my\", \"our\" or \"state\" declaration, but this class doesn't exist at this point in your program. No such hook: %s (F) You specified a signal hook that was not recognized by Perl. Currently, Perl accepts \"__DIE__\" and \"__WARN__\" as valid signal hooks No such pipe open (P) An error peculiar to VMS . The internal routine my_pclose() tried to close a pipe which hadn't been opened. This should have been caught earlier as an attempt to close an unopened filehandle. No such signal: SIG%s (W signal) You specified a signal name as a subscript to %SIG that was not recognized. Say \"kill -l\" in your shell to see the valid signal names on your system. Not a CODE reference (F) Perl was trying to evaluate a reference to a code value (that is, a subroutine), but found a reference to something else instead. You can use the ref() function to find out what kind of ref it really was. See also perlref. Not a format reference (F) I'm not sure how you managed to generate a reference to an anonymous format, but this indicates you did, and that it didn't exist. Not a GLOB reference (F) Perl was trying to evaluate a reference to a \"typeglob\" (that is, a symbol table entry that looks like *foo), but found a reference to something else instead. You can use the ref() function to find out what kind of ref it really was. See perlref. Not a HASH reference (F) Perl was trying to evaluate a reference to a hash value, but found a reference to something else instead. You can use the ref() function to find out what kind of ref it really was. See perlref. Not an ARRAY reference (F) Perl was trying to evaluate a reference to an array value, but found a reference to something else instead. You can use the ref() function to find out what kind of ref it really was. See perlref. Not a perl script (F) The setuid emulator requires that scripts have a well-formed #! line even on machines that don't support the #! construct. The line must mention perl. Not a SCALAR reference (F) Perl was trying to evaluate a reference to a scalar value, but found a reference to something else instead. You can use the ref() function to find out what kind of ref it really was. See perlref. Not a subroutine reference (F) Perl was trying to evaluate a reference to a code value (that is, a subroutine), but found a reference to something else instead. You can use the ref() function to find out what kind of ref it really was. See also perlref. Not a subroutine reference in overload table (F) An attempt was made to specify an entry in an overloading table that doesn't somehow point to a valid subroutine. See overload. Not enough arguments for %s (F) The function requires more arguments than you specified. Not enough format arguments (W syntax) A format specified more picture fields than the next line supplied. See perlform. %s: not found (A) You've accidentally run your script through the Bourne shell instead of Perl. Check the #! line, or manually feed your script into Perl yourself. no UTC offset information; assuming local time is UTC (S) A warning peculiar to VMS . Perl was unable to find the local timezone offset, so it's assuming that local system time is equivalent to UTC . If it's not, define the logical name SYS$TIMEZONE_DIFFERENTIAL to translate to the number of seconds which need to be added to UTC to get local time. Non-string passed as bitmask (W misc) A number has been passed as a bitmask argument to select(). Use the vec() function to construct the file descriptor bitmasks for select. See \"select\" in perlfunc Null filename used (F) You can't require the null filename, especially because on many machines that means the current directory! See \"require\" in perlfunc. NULL OP IN RUN (P debugging) Some internal routine called run() with a null opcode pointer. Null picture in formline (F) The first argument to formline must be a valid format picture specification. It was found to be empty, which probably means you supplied it an uninitialized value. See perlform. Null realloc (P) An attempt was made to realloc NULL . NULL regexp argument (P) The internal pattern matching routines blew it big time. NULL regexp parameter (P) The internal pattern matching routines are out of their gourd. Number too long (F) Perl limits the representation of decimal numbers in programs to about 250 characters. You've exceeded that length. Future versions of Perl are likely to eliminate this arbitrary limitation. In the meantime, try using scientific notation (e.g. \"1e6\" instead of \"1_000_000\"). Octal number in vector unsupported (F) Numbers with a leading 0 are not currently allowed in vectors. The octal number interpretation of such numbers may be supported in a future version. Octal number > 037777777777 non-portable (W portable) The octal number you specified is larger than 2**32-1 (4294967295) and therefore non-portable between systems. See perlport for more on portability concerns. See also perlport for writing portable code. Odd number of arguments for overload::constant (W overload) The call to overload::constant contained an odd number of arguments. The arguments should come in pairs. Odd number of elements in anonymous hash (W misc) You specified an odd number of elements to initialize a hash, which is odd, because hashes come in key\/value pairs. Odd number of elements in hash assignment (W misc) You specified an odd number of elements to initialize a hash, which is odd, because hashes come in key\/value pairs. Offset outside string (F, W layer) You tried to do a read\/write\/send\/recv\/seek operation with an offset pointing outside the buffer. This is difficult to imagine. The sole exceptions to this are that zero padding will take place when going past the end of the string when either \"sysread()\"ing a file, or when seeking past the end of a scalar opened for I\/O (in anticipation of future reads and to imitate the behaviour with real files). %s() on unopened %s (W unopened) An I\/O operation was attempted on a filehandle that was never initialized. You need to do an open(), a sysopen(), or a socket() call, or call a constructor from the FileHandle package. -%s on unopened filehandle %s (W unopened) You tried to invoke a file test operator on a filehandle that isn't open. Check your control flow. See also \"-X\" in perlfunc. oops: oopsAV (S internal) An internal warning that the grammar is screwed up. oops: oopsHV (S internal) An internal warning that the grammar is screwed up. Opening dirhandle %s also as a file (W io deprecated) You used open() to associate a filehandle to a symbol (glob or scalar) that already holds a dirhandle. Although legal, this idiom might render your code confusing and is deprecated. Opening filehandle %s also as a directory (W io deprecated) You used opendir() to associate a dirhandle to a symbol (glob or scalar) that already holds a filehandle. Although legal, this idiom might render your code confusing and is deprecated. Operation \"%s\": no method found, %s (F) An attempt was made to perform an overloaded operation for which no handler was defined. While some handlers can be autogenerated in terms of other handlers, there is no default handler for any operation, unless \"fallback\" overloading key is specified to be true. See overload. Operator or semicolon missing before %s (S ambiguous) You used a variable or subroutine call where the parser was expecting an operator. The parser has assumed you really meant to use an operator, but this is highly likely to be incorrect. For example, if you say \"*foo *foo\" it will be interpreted as if you said \"*foo * 'foo'\". \"our\" variable %s redeclared (W misc) You seem to have already declared the same global once before in the current lexical scope. Out of memory! (X) The malloc() function returned 0, indicating there was insufficient remaining memory (or virtual memory) to satisfy the request. Perl has no option but to exit immediately. At least in Unix you may be able to get past this by increasing your process datasize limits: in csh\/tcsh use \"limit\" and \"limit datasize n\" (where \"n\" is the number of kilobytes) to check the current limits and change them, and in ksh\/bash\/zsh use \"ulimit -a\" and \"ulimit -d n\", respectively. Out of memory during %s extend (X) An attempt was made to extend an array, a list, or a string beyond the largest possible memory allocation. Out of memory during \"large\" request for %s (F) The malloc() function returned 0, indicating there was insufficient remaining memory (or virtual memory) to satisfy the request. However, the request was judged large enough (compile-time default is 64K), so a possibility to shut down by trapping this error is granted. Out of memory during request for %s (X|F) The malloc() function returned 0, indicating there was insufficient remaining memory (or virtual memory) to satisfy the request. The request was judged to be small, so the possibility to trap it depends on the way perl was compiled. By default it is not trappable. However, if compiled for this, Perl may use the contents of $^M as an emergency pool after die()ing with this message. In this case the error is trappable once, and the error message will include the line and file where the failed request happened. Out of memory during ridiculously large request (F) You can't allocate more than 2^31+\"small amount\" bytes. This error is most likely to be caused by a typo in the Perl program. e.g., $arr[time] instead of $arr[$time]. Out of memory for yacc stack (F) The yacc parser wanted to grow its stack so it could continue parsing, but realloc() wouldn't give it more memory, virtual or otherwise. '.' outside of string in pack (F) The argument to a '.' in your template tried to move the working position to before the start of the packed string being built. '@' outside of string in unpack (F) You had a template that specified an absolute position outside the string being unpacked. See \"pack\" in perlfunc. '@' outside of string with malformed UTF-8 in unpack (F) You had a template that specified an absolute position outside the string being unpacked. The string being unpacked was also invalid UTF-8 . See \"pack\" in perlfunc. %s package attribute may clash with future reserved word: %s (W reserved) A lowercase attribute name was used that had a package-specific handler. That name might have a meaning to Perl itself some day, even though it doesn't yet. Perhaps you should use a mixed-case attribute name, instead. See attributes. pack\/unpack repeat count overflow (F) You can't specify a repeat count so large that it overflows your signed integers. See \"pack\" in perlfunc. page overflow (W io) A single call to write() produced more lines than can fit on a page. See perlform. panic: %s (P) An internal error. panic: attempt to call %s in %s (P) One of the file test operators entered a code branch that calls an ACL related-function, but that function is not available on this platform. Earlier checks mean that it should not be possible to enter this branch on this platform. panic: ck_grep (P) Failed an internal consistency check trying to compile a grep. panic: ck_split (P) Failed an internal consistency check trying to compile a split. panic: corrupt saved stack index (P) The savestack was requested to restore more localized values than there are in the savestack. panic: del_backref (P) Failed an internal consistency check while trying to reset a weak reference. panic: Devel::DProf inconsistent subroutine return (P) Devel::DProf called a subroutine that exited using goto( LABEL ), last( LABEL ) or next( LABEL ). Leaving that way a subroutine called from an XSUB will lead very probably to a crash of the interpreter. This is a bug that will hopefully one day get fixed. panic: die %s (P) We popped the context stack to an eval context, and then discovered it wasn't an eval context. panic: do_subst (P) The internal pp_subst() routine was called with invalid operational data. panic: do_trans_%s (P) The internal do_trans routines were called with invalid operational data. panic: fold_constants JMPENV_PUSH returned %d (P) While attempting folding constants an exception other than an \"eval\" failure was caught. panic: frexp (P) The library function frexp() failed, making printf(\"%f\") impossible. panic: goto (P) We popped the context stack to a context with the specified label, and then discovered it wasn't a context we know how to do a goto in. panic: hfreeentries failed to free hash (P) The internal routine used to clear a hashes entries tried repeatedly, but each time something added more entries to the hash. Most likely the hash contains an object with a reference back to the hash and a destructor that adds a new object to the hash. panic: INTERPCASEMOD (P) The lexer got into a bad state at a case modifier. panic: INTERPCONCAT (P) The lexer got into a bad state parsing a string with brackets. panic: kid popen errno read (F) forked child returned an incomprehensible message about its errno. panic: last (P) We popped the context stack to a block context, and then discovered it wasn't a block context. panic: leave_scope clearsv (P) A writable lexical variable became read-only somehow within the scope. panic: leave_scope inconsistency (P) The savestack probably got out of sync. At least, there was an invalid enum on the top of it. panic: magic_killbackrefs (P) Failed an internal consistency check while trying to reset all weak references to an object. panic: malloc (P) Something requested a negative number of bytes of malloc. panic: memory wrap (P) Something tried to allocate more memory than possible. panic: pad_alloc (P) The compiler got confused about which scratch pad it was allocating and freeing temporaries and lexicals from. panic: pad_free curpad (P) The compiler got confused about which scratch pad it was allocating and freeing temporaries and lexicals from. panic: pad_free po (P) An invalid scratch pad offset was detected internally. panic: pad_reset curpad (P) The compiler got confused about which scratch pad it was allocating and freeing temporaries and lexicals from. panic: pad_sv po (P) An invalid scratch pad offset was detected internally. panic: pad_swipe curpad (P) The compiler got confused about which scratch pad it was allocating and freeing temporaries and lexicals from. panic: pad_swipe po (P) An invalid scratch pad offset was detected internally. panic: pp_iter (P) The foreach iterator got called in a non-loop context frame. panic: pp_match%s (P) The internal pp_match() routine was called with invalid operational data. panic: pp_split (P) Something terrible went wrong in setting up for the split. panic: realloc (P) Something requested a negative number of bytes of realloc. panic: restartop (P) Some internal routine requested a goto (or something like it), and didn't supply the destination. panic: return (P) We popped the context stack to a subroutine or eval context, and then discovered it wasn't a subroutine or eval context. panic: scan_num (P) scan_num() got called on something that wasn't a number. panic: sv_chop %s (P) The sv_chop() routine was passed a position that is not within the scalar's string buffer. panic: sv_insert (P) The sv_insert() routine was told to remove more string than there was string. panic: top_env (P) The compiler attempted to do a goto, or something weird like that. panic: unimplemented op %s (#%d) called (P) The compiler is screwed up and attempted to use an op that isn't permitted at run time. panic: utf16_to_utf8: odd bytelen (P) Something tried to call utf16_to_utf8 with an odd (as opposed to even) byte length. panic: yylex (P) The lexer got into a bad state while processing a case modifier. Pattern subroutine nesting without pos change exceeded limit in regex; marked by <-- HERE in m\/%s\/ (F) You used a pattern that uses too many nested subpattern calls without consuming any text. Restructure the pattern so text is consumed before the nesting limit is exceeded. The <-- HERE shows in the regular expression about where the problem was discovered. Parentheses missing around \"%s\" list (W parenthesis) You said something like my $foo, $bar = @_; when you meant my ($foo, $bar) = @_; Remember that \"my\", \"our\", \"local\" and \"state\" bind tighter than comma. \"-p\" destination: %s (F) An error occurred during the implicit output invoked by the \"-p\" command-line switch. (This output goes to STDOUT unless you've redirected it with select().) (perhaps you forgot to load \"%s\"?) (F) This is an educated guess made in conjunction with the message \"Can't locate object method \\\"%s\\\" via package \\\"%s\\\"\". It often means that a method requires a package that has not been loaded. Perl_my_%s() not available (F) Your platform has very uncommon byte-order and integer size, so it was not possible to set up some or all fixed-width byte-order conversion functions. This is only a problem when you're using the '<' or '>' modifiers in (un)pack templates. See \"pack\" in perlfunc. Perl %s required--this is only version %s, stopped (F) The module in question uses features of a version of Perl more recent than the currently running version. How long has it been since you upgraded, anyway? See \"require\" in perlfunc. PERL_SH_DIR too long (F) An error peculiar to OS\/2 . PERL_SH_DIR is the directory to find the \"sh\"-shell in. See \" PERL_SH_DIR \" in perlos2. PERL_SIGNALS illegal: \"%s\" See \" PERL_SIGNALS \" in perlrun for legal values. perl: warning: Setting locale failed. (S) The whole warning message will look something like: perl: warning: Setting locale failed.\nperl: warning: Please check that your locale settings:\n        LC_ALL = \"En_US\",\n        LANG = (unset)\n    are supported and installed on your system.\nperl: warning: Falling back to the standard locale (\"C\"). Exactly what were the failed locale settings varies. In the above the settings were that the LC_ALL was \"En_US\" and the LANG had no value. This error means that Perl detected that you and\/or your operating system supplier and\/or system administrator have set up the so-called locale system but Perl could not use those settings. This was not dead serious, fortunately: there is a \"default locale\" called \"C\" that Perl can and will use, the script will be run. Before you really fix the problem, however, you will get the same error message each time you run Perl. How to really fix the problem can be found in perllocale section LOCALE PROBLEMS . Permission denied (F) The setuid emulator in suidperl decided you were up to no good. pid %x not a child (W exec) A warning peculiar to VMS . Waitpid() was asked to wait for a process which isn't a subprocess of the current process. While this is fine from VMS ' perspective, it's probably not what you intended. 'P' must have an explicit size in unpack (F) The unpack format P must have an explicit size, not \"*\". -P not allowed for setuid\/setgid script (F) The script would have to be opened by the C preprocessor by name, which provides a race condition that breaks security. POSIX class [:%s:] unknown in regex; marked by <-- HERE in m\/%s\/ (F) The class in the character class [: :] syntax is unknown. The <-- HERE shows in the regular expression about where the problem was discovered. Note that the POSIX character classes do not have the \"is\" prefix the corresponding C interfaces have: in other words, it's \"[[:print:]]\", not \"isprint\". See perlre. POSIX getpgrp can't take an argument (F) Your system has POSIX getpgrp(), which takes no argument, unlike the BSD version, which takes a pid. POSIX syntax [%s] belongs inside character classes in regex; marked by <-- HERE in m\/%s\/ (W regexp) The character class constructs [: :], [= =], and [. .] go inside character classes, the [] are part of the construct, for example: \/[012[:alpha:]345]\/. Note that [= =] and [. .] are not currently implemented; they are simply placeholders for future extensions and will cause fatal errors. The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. POSIX syntax [. .] is reserved for future extensions in regex; marked by <-- HERE in m\/%s\/ (F regexp) Within regular expression character classes ([]) the syntax beginning with \"[.\" and ending with \".]\" is reserved for future extensions. If you need to represent those character sequences inside a regular expression character class, just quote the square brackets with the backslash: \"\\[.\" and \".\\]\". The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. POSIX syntax [= =] is reserved for future extensions in regex; marked by <-- HERE in m\/%s\/ (F) Within regular expression character classes ([]) the syntax beginning with \"[=\" and ending with \"=]\" is reserved for future extensions. If you need to represent those character sequences inside a regular expression character class, just quote the square brackets with the backslash: \"\\[=\" and \"=\\]\". The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Possible attempt to put comments in qw() list (W qw) qw() lists contain items separated by whitespace; as with literal strings, comment characters are not ignored, but are instead treated as literal data. (You may have used different delimiters than the parentheses shown here; braces are also frequently used.) You probably wrote something like this: @list = qw(\n    a # a comment\n    b # another comment\n); when you should have written this: @list = qw(\n    a\n    b\n); If you really want comments, build your list the old-fashioned way, with quotes and commas: @list = (\n    'a',    # a comment\n    'b',    # another comment\n); Possible attempt to separate words with commas (W qw) qw() lists contain items separated by whitespace; therefore commas aren't needed to separate the items. (You may have used different delimiters than the parentheses shown here; braces are also frequently used.) You probably wrote something like this: qw! a, b, c !; which puts literal commas into some of the list items. Write it without commas if you don't want them to appear in your data: qw! a b c !; Possible memory corruption: %s overflowed 3rd argument (F) An ioctl() or fcntl() returned more than Perl was bargaining for. Perl guesses a reasonable buffer size, but puts a sentinel byte at the end of the buffer just in case. This sentinel byte got clobbered, and Perl assumes that memory is now corrupted. See \"ioctl\" in perlfunc. Possible precedence problem on bitwise %c operator (W precedence) Your program uses a bitwise logical operator in conjunction with a numeric comparison operator, like this : if ($x & $y == 0) { ... } This expression is actually equivalent to \"$x & ($y == 0)\", due to the higher precedence of \"==\". This is probably not what you want. (If you really meant to write this, disable the warning, or, better, put the parentheses explicitly and write \"$x & ($y == 0)\"). Possible unintended interpolation of %s in string (W ambiguous) You said something like '@foo' in a double-quoted string but there was no array @foo in scope at the time. If you wanted a literal @foo, then write it as \\@foo; otherwise find out what happened to the array you apparently lost track of. pragma \"attrs\" is deprecated, use \"sub NAME : ATTRS \" instead (D deprecated) You have written something like this: sub doit\n{\n    use attrs qw(locked);\n} You should use the new declaration syntax instead. sub doit : locked\n{\n    ... The \"use attrs\" pragma is now obsolete, and is only provided for backward-compatibility. See \"Subroutine Attributes\" in perlsub. Precedence problem: open %s should be open(%s) (S precedence) The old irregular construct open FOO || die; is now misinterpreted as open(FOO || die); because of the strict regularization of Perl 5's grammar into unary and list operators. (The old open was a little of both.) You must put parentheses around the filehandle, or use the new \"or\" operator instead of \"||\". Premature end of script headers See Server error. printf() on closed filehandle %s (W closed) The filehandle you're writing to got itself closed sometime before now. Check your control flow. print() on closed filehandle %s (W closed) The filehandle you're printing on got itself closed sometime before now. Check your control flow. Process terminated by SIG%s (W) This is a standard message issued by OS\/2 applications, while *nix applications die in silence. It is considered a feature of the OS\/2 port. One can easily disable this by appropriate sighandlers, see \"Signals\" in perlipc. See also \"Process terminated by SIGTERM\/SIGINT \" in perlos2. Prototype mismatch: %s vs %s (S prototype) The subroutine being declared or defined had previously been declared or defined with a different function prototype. Prototype not terminated (F) You've omitted the closing parenthesis in a function prototype definition. Quantifier follows nothing in regex; marked by <-- HERE in m\/%s\/ (F) You started a regular expression with a quantifier. Backslash it if you meant it literally. The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Quantifier in {,} bigger than %d in regex; marked by <-- HERE in m\/%s\/ (F) There is currently a limit to the size of the min and max values of the {min,max} construct. The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Quantifier unexpected on zero-length expression; marked by <-- HERE in m\/%s\/ (W regexp) You applied a regular expression quantifier in a place where it makes no sense, such as on a zero-width assertion. Try putting the quantifier inside the assertion instead. For example, the way to match \"abc\" provided that it is followed by three repetitions of \"xyz\" is \"\/abc(?=(?:xyz){3})\/\", not \"\/abc(?=xyz){3}\/\". The <-- HERE shows in the regular expression about where the problem was discovered. Range iterator outside integer range (F) One (or both) of the numeric arguments to the range operator \"..\" are outside the range which can be represented by integers internally. One possible workaround is to force Perl to use magical string increment by prepending \"0\" to your numbers. readdir() attempted on invalid dirhandle %s (W io) The dirhandle you're reading from is either closed or not really a dirhandle. Check your control flow. readline() on closed filehandle %s (W closed) The filehandle you're reading from got itself closed sometime before now. Check your control flow. read() on closed filehandle %s (W closed) You tried to read from a closed filehandle. read() on unopened filehandle %s (W unopened) You tried to read from a filehandle that was never opened. Reallocation too large: %lx (F) You can't allocate more than 64K on an MS-DOS machine. realloc() of freed memory ignored (S malloc) An internal routine called realloc() on something that had already been freed. Recompile perl with -D DEBUGGING to use -D switch (F debugging) You can't use the -D option unless the code to produce the desired output is compiled into Perl, which entails some overhead, which is why it's currently left out of your copy. Recursive inheritance detected in package '%s' (F) While calculating the method resolution order ( MRO ) of a package, Perl believes it found an infinite loop in the @ISA hierarchy. This is a crude check that bails out after 100 levels of @ISA depth. Recursive inheritance detected while looking for method %s (F) More than 100 levels of inheritance were encountered while invoking a method. Probably indicates an unintended loop in your inheritance hierarchy. Reference found where even-sized list expected (W misc) You gave a single reference where Perl was expecting a list with an even number of elements (for assignment to a hash). This usually means that you used the anon hash constructor when you meant to use parens. In any case, a hash requires key\/value pairs. %hash = { one => 1, two => 2, };    # WRONG\n%hash = [ qw\/ an anon array \/ ];    # WRONG\n%hash = ( one => 1, two => 2, );    # right\n%hash = qw( one 1 two 2 );                  # also fine Reference is already weak (W misc) You have attempted to weaken a reference that is already weak. Doing so has no effect. Reference miscount in sv_replace() (W internal) The internal sv_replace() function was handed a new SV with a reference count of other than 1. Reference to invalid group 0 (F) You used \"\\g0\" or similar in a regular expression. You may refer to capturing parentheses only with strictly positive integers (normal backreferences) or with strictly negative integers (relative backreferences), but using 0 does not make sense. Reference to nonexistent group in regex; marked by <-- HERE in m\/%s\/ (F) You used something like \"\\7\" in your regular expression, but there are not at least seven sets of capturing parentheses in the expression. If you wanted to have the character with value 7 inserted into the regular expression, prepend a zero to make the number at least two digits: \"\\07\" The <-- HERE shows in the regular expression about where the problem was discovered. Reference to nonexistent or unclosed group in regex; marked by <-- HERE in m\/%s\/ (F) You used something like \"\\g{-7}\" in your regular expression, but there are not at least seven sets of closed capturing parentheses in the expression before where the \"\\g{-7}\" was located. The <-- HERE shows in the regular expression about where the problem was discovered. Reference to nonexistent named group in regex; marked by <-- HERE in m\/%s\/ (F) You used something like \"\\k'NAME'\" or \"\\k<NAME>\" in your regular expression, but there is no corresponding named capturing parentheses such as \"(?'NAME'...)\" or \"(?<NAME\"...). Check if the name has been spelled correctly both in the backreference and the declaration. The <-- HERE shows in the regular expression about where the problem was discovered. (?( DEFINE )....) does not allow branches in regex; marked by <-- HERE in m\/%s\/ (F) You used something like \"(?(DEFINE)...|..)\" which is illegal. The most likely cause of this error is that you left out a parenthesis inside of the \"....\" part. The <-- HERE shows in the regular expression about where the problem was discovered. regexp memory corruption (P) The regular expression engine got confused by what the regular expression compiler gave it. Regexp out of space (P) A \"can't happen\" error, because safemalloc() should have caught it earlier. Repeated format line will never terminate (~~ and @# incompatible) (F) Your format contains the ~~ repeat-until-blank sequence and a numeric field that will never go blank so that the repetition never terminates. You might use ^# instead. See perlform. Reversed %s= operator (W syntax) You wrote your assignment operator backwards. The = must always comes last, to avoid ambiguity with subsequent unary operators. rewinddir() attempted on invalid dirhandle %s (W io) The dirhandle you tried to do a rewinddir() on is either closed or not really a dirhandle. Check your control flow. Runaway format (F) Your format contained the ~~ repeat-until-blank sequence, but it produced 200 lines at once, and the 200th line looked exactly like the 199th line. Apparently you didn't arrange for the arguments to exhaust themselves, either by using ^ instead of @ (for scalar variables), or by shifting or popping (for array variables). See perlform. Scalars leaked: %d (P) Something went wrong in Perl's internal bookkeeping of scalars: not all scalar variables were deallocated by the time Perl exited. What this usually indicates is a memory leak, which is of course bad, especially if the Perl program is intended to be long-running. Scalar value @%s[%s] better written as $%s[%s] (W syntax) You've used an array slice (indicated by @) to select a single element of an array. Generally it's better to ask for a scalar value (indicated by $). The difference is that $foo[&bar] always behaves like a scalar, both when assigning to it and when evaluating its argument, while @foo[&bar] behaves like a list when you assign to it, and provides a list context to its subscript, which can do weird things if you're expecting only one subscript. On the other hand, if you were actually hoping to treat the array element as a list, you need to look into how references work, because Perl will not magically convert between scalars and lists for you. See perlref. Scalar value @%s{%s} better written as $%s{%s} (W syntax) You've used a hash slice (indicated by @) to select a single element of a hash. Generally it's better to ask for a scalar value (indicated by $). The difference is that $foo{&bar} always behaves like a scalar, both when assigning to it and when evaluating its argument, while @foo{&bar} behaves like a list when you assign to it, and provides a list context to its subscript, which can do weird things if you're expecting only one subscript. On the other hand, if you were actually hoping to treat the hash element as a list, you need to look into how references work, because Perl will not magically convert between scalars and lists for you. See perlref. Script is not setuid\/setgid in suidperl (F) Oddly, the suidperl program was invoked on a script without a setuid or setgid bit set. This doesn't make much sense. Search pattern not terminated (F) The lexer couldn't find the final delimiter of a \/\/ or m{} construct. Remember that bracketing delimiters count nesting level. Missing the leading \"$\" from a variable $m may cause this error. Note that since Perl 5.9.0 a \/\/ can also be the defined-or construct, not just the empty search pattern. Therefore code written in Perl 5.9.0 or later that uses the \/\/ as the defined-or can be misparsed by pre-5.9.0 Perls as a non-terminated search pattern. Search pattern not terminated or ternary operator parsed as search pattern (F) The lexer couldn't find the final delimiter of a \"?PATTERN?\" construct. The question mark is also used as part of the ternary operator (as in \"foo ? 0 : 1\") leading to some ambiguous constructions being wrongly parsed. One way to disambiguate the parsing is to put parentheses around the conditional expression, i.e. \"(foo) ? 0 : 1\". % sseek() on unopened filehandle (W unopened) You tried to use the seek() or sysseek() function on a filehandle that was either never opened or has since been closed. seekdir() attempted on invalid dirhandle %s (W io) The dirhandle you are doing a seekdir() on is either closed or not really a dirhandle. Check your control flow. select not implemented (F) This machine doesn't implement the select() system call. Self-ties of arrays and hashes are not supported (F) Self-ties are of arrays and hashes are not supported in the current implementation. Semicolon seems to be missing (W semicolon) A nearby syntax error was probably caused by a missing semicolon, or possibly some other missing operator, such as a comma. semi-panic: attempt to dup freed string (S internal) The internal newSVsv() routine was called to duplicate a scalar that had previously been marked as free. sem%s not implemented (F) You don't have System V semaphore IPC on your system. send() on closed socket %s (W closed) The socket you're sending to got itself closed sometime before now. Check your control flow. Sequence (? incomplete in regex; marked by <-- HERE in m\/%s\/ (F) A regular expression ended with an incomplete extension (?. The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Sequence (?%s...) not implemented in regex; marked by <-- HERE in m\/%s\/ (F) A proposed regular expression extension has the character reserved but has not yet been written. The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Sequence (?%s...) not recognized in regex; marked by <-- HERE in m\/%s\/ (F) You used a regular expression extension that doesn't make sense. The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Sequence \\\\%s... not terminated in regex; marked by <-- HERE in m\/%s\/ (F) The regular expression expects a mandatory argument following the escape sequence and this has been omitted or incorrectly written. Sequence (?#... not terminated in regex; marked by <-- HERE in m\/%s\/ (F) A regular expression comment must be terminated by a closing parenthesis. Embedded parentheses aren't allowed. The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Sequence (?{...}) not terminated or not {}-balanced in regex; marked by <-- HERE in m\/%s\/ (F) If the contents of a (?{...}) clause contains braces, they must balance for Perl to properly detect the end of the clause. The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. 500 Server error See Server error. Server error This is the error message generally seen in a browser window when trying to run a CGI program (including SSI ) over the web. The actual error text varies widely from server to server. The most frequently-seen variants are \"500 Server error\", \"Method (something) not permitted\", \"Document contains no data\", \"Premature end of script headers\", and \"Did not produce a valid header\". This is a CGI error, not a Perl error. You need to make sure your script is executable, is accessible by the user CGI is running the script under (which is probably not the user account you tested it under), does not rely on any environment variables (like PATH ) from the user it isn't running under, and isn't in a location where the CGI server can't find it, basically, more or less. Please see the following for more information: http:\/\/www.perl.org\/CGI_MetaFAQ.html\nhttp:\/\/www.htmlhelp.org\/faq\/cgifaq.html\nhttp:\/\/www.w3.org\/Security\/Faq\/ You should also look at perlfaq9. setegid() not implemented (F) You tried to assign to $), and your operating system doesn't support the setegid() system call (or equivalent), or at least Configure didn't think so. seteuid() not implemented (F) You tried to assign to $>, and your operating system doesn't support the seteuid() system call (or equivalent), or at least Configure didn't think so. setpgrp can't take arguments (F) Your system has the setpgrp() from BSD 4.2, which takes no arguments, unlike POSIX setpgid(), which takes a process ID and process group ID . setrgid() not implemented (F) You tried to assign to $(, and your operating system doesn't support the setrgid() system call (or equivalent), or at least Configure didn't think so. setruid() not implemented (F) You tried to assign to $<, and your operating system doesn't support the setruid() system call (or equivalent), or at least Configure didn't think so. setsockopt() on closed socket %s (W closed) You tried to set a socket option on a closed socket. Did you forget to check the return value of your socket() call? See \"setsockopt\" in perlfunc. Setuid\/gid script is writable by world (F) The setuid emulator won't run a script that is writable by the world, because the world might have written on it already. Setuid script not plain file (F) The setuid emulator won't run a script that isn't read from a file, but from a socket, a pipe or another device. shm%s not implemented (F) You don't have System V shared memory IPC on your system. !=~ should be !~ (W syntax) The non-matching operator is !~, not !=~. !=~ will be interpreted as the != (numeric not equal) and ~ (1's complement) operators: probably not what you intended. <> should be quotes (F) You wrote \"require <file>\" when you should have written \"require 'file'\". \/%s\/ should probably be written as \"%s\" (W syntax) You have used a pattern where Perl expected to find a string, as in the first argument to \"join\". Perl will treat the true or false result of matching the pattern against $_ as the string, which is probably not what you had in mind. shutdown() on closed socket %s (W closed) You tried to do a shutdown on a closed socket. Seems a bit superfluous. SIG%s handler \"%s\" not defined (W signal) The signal handler named in %SIG doesn't, in fact, exist. Perhaps you put it into the wrong package? Smart matching a non-overloaded object breaks encapsulation (F) You should not use the \"~~\" operator on an object that does not overload it: Perl refuses to use the object's underlying structure for the smart match. sort is now a reserved word (F) An ancient error message that almost nobody ever runs into anymore. But before sort was a keyword, people sometimes used it as a filehandle. Sort subroutine didn't return a numeric value (F) A sort comparison routine must return a number. You probably blew it by not using \"<=>\" or \"cmp\", or by not using them correctly. See \"sort\" in perlfunc. Sort subroutine didn't return single value (F) A sort comparison subroutine may not return a list value with more or less than one element. See \"sort\" in perlfunc. splice() offset past end of array (W misc) You attempted to specify an offset that was past the end of the array passed to splice(). Splicing will instead commence at the end of the array, rather than past it. If this isn't what you want, try explicitly pre-extending the array by assigning $#array = $offset. See \"splice\" in perlfunc. Split loop (P) The split was looping infinitely. (Obviously, a split shouldn't iterate more times than there are characters of input, which is what happened.) See \"split\" in perlfunc. Statement unlikely to be reached (W exec) You did an exec() with some statement after it other than a die(). This is almost always an error, because exec() never returns unless there was a failure. You probably wanted to use system() instead, which does return. To suppress this warning, put the exec() in a block by itself. stat() on unopened filehandle %s (W unopened) You tried to use the stat() function on a filehandle that was either never opened or has since been closed. Stub found while resolving method \"%s\" overloading \"%s\" (P) Overloading resolution over @ISA tree may be broken by importation stubs. Stubs should never be implicitly created, but explicit calls to \"can\" may break this. Subroutine %s redefined (W redefine) You redefined a subroutine. To suppress this warning, say {\n    no warnings 'redefine';\n    eval \"sub name { ... }\";\n} Substitution loop (P) The substitution was looping infinitely. (Obviously, a substitution shouldn't iterate more times than there are characters of input, which is what happened.) See the discussion of substitution in \"Regexp Quote-Like Operators\" in perlop. Substitution pattern not terminated (F) The lexer couldn't find the interior delimiter of an s\/\/\/ or s{}{} construct. Remember that bracketing delimiters count nesting level. Missing the leading \"$\" from variable $s may cause this error. Substitution replacement not terminated (F) The lexer couldn't find the final delimiter of an s\/\/\/ or s{}{} construct. Remember that bracketing delimiters count nesting level. Missing the leading \"$\" from variable $s may cause this error. substr outside of string (W substr),(F) You tried to reference a substr() that pointed outside of a string. That is, the absolute value of the offset was larger than the length of the string. See \"substr\" in perlfunc. This warning is fatal if substr is used in an lvalue context (as the left hand side of an assignment or as a subroutine argument for example). suidperl is no longer needed since %s (F) Your Perl was compiled with -D SETUID_SCRIPTS_ARE_SECURE_NOW , but a version of the setuid emulator somehow got run anyway. sv_upgrade from type %d down to type %d (P) Perl tried to force the upgrade an SV to a type which was actually inferior to its current type. Switch (?(condition)... contains too many branches in regex; marked by <-- HERE in m\/%s\/ (F) A (?(condition)if-clause|else-clause) construct can have at most two branches (the if-clause and the else-clause). If you want one or both to contain alternation, such as using \"this|that|other\", enclose it in clustering parentheses: (?(condition)(?:this|that|other)|else-clause) The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Switch condition not recognized in regex; marked by <-- HERE in m\/%s\/ (F) If the argument to the (?(...)if-clause|else-clause) construct is a number, it can be only a number. The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. switching effective %s is not implemented (F) While under the \"use filetest\" pragma, we cannot switch the real and effective uids or gids. %s syntax (F) The final summary message when a \"perl -c\" succeeds. syntax error (F) Probably means you had a syntax error. Common reasons include: A keyword is misspelled.\nA semicolon is missing.\nA comma is missing.\nAn opening or closing parenthesis is missing.\nAn opening or closing brace is missing.\nA closing quote is missing. Often there will be another error message associated with the syntax error giving more information. (Sometimes it helps to turn on -w.) The error message itself often tells you where it was in the line when it decided to give up. Sometimes the actual error is several tokens before this, because Perl is good at understanding random input. Occasionally the line number may be misleading, and once in a blue moon the only way to figure out what's triggering the error is to call \"perl -c\" repeatedly, chopping away half the program each time to see if the error went away. Sort of the cybernetic version of 20 questions. syntax error at line %d: '%s' unexpected (A) You've accidentally run your script through the Bourne shell instead of Perl. Check the #! line, or manually feed your script into Perl yourself. syntax error in file %s at line %d, next 2 tokens \"%s\" (F) This error is likely to occur if you run a perl5 script through a perl4 interpreter, especially if the next 2 tokens are \"use strict\" or \"my $var\" or \"our $var\". sysread() on closed filehandle %s (W closed) You tried to read from a closed filehandle. sysread() on unopened filehandle %s (W unopened) You tried to read from a filehandle that was never opened. System V %s is not implemented on this machine (F) You tried to do something with a function beginning with \"sem\", \"shm\", or \"msg\" but that System V IPC is not implemented in your machine. In some machines the functionality can exist but be unconfigured. Consult your system support. syswrite() on closed filehandle %s (W closed) The filehandle you're writing to got itself closed sometime before now. Check your control flow. \"-T\" and \"-B\" not implemented on filehandles (F) Perl can't peek at the stdio buffer of filehandles when it doesn't know about your kind of stdio. You'll have to use a filename instead. Target of goto is too deeply nested (F) You tried to use \"goto\" to reach a label that was too deeply nested for Perl to reach. Perl is doing you a favor by refusing. tell() on unopened filehandle (W unopened) You tried to use the tell() function on a filehandle that was either never opened or has since been closed. telldir() attempted on invalid dirhandle %s (W io) The dirhandle you tried to telldir() is either closed or not really a dirhandle. Check your control flow. That use of $[ is unsupported (F) Assignment to $[ is now strictly circumscribed, and interpreted as a compiler directive. You may say only one of $[ = 0;\n$[ = 1;\n...\nlocal $[ = 0;\nlocal $[ = 1;\n... This is to prevent the problem of one module changing the array base out from under another module inadvertently. See \"$[\" in perlvar. The crypt() function is unimplemented due to excessive paranoia (F) Configure couldn't find the crypt() function on your machine, probably because your vendor didn't supply it, probably because they think the U.S. Government thinks it's a secret, or at least that they will continue to pretend that it is. And if you quote me on that, I will deny it. The %s function is unimplemented The function indicated isn't implemented on this architecture, according to the probings of Configure. The stat preceding %s wasn't an lstat (F) It makes no sense to test the current stat buffer for symbolic linkhood if the last stat that wrote to the stat buffer already went past the symlink to get to the real file. Use an actual filename instead. The 'unique' attribute may only be applied to 'our' variables (F) This attribute was never supported on \"my\" or \"sub\" declarations. This Perl can't reset CRTL environ elements (%s) This Perl can't set CRTL environ elements (%s=%s) (W internal) Warnings peculiar to VMS . You tried to change or delete an element of the CRTL 's internal environ array, but your copy of Perl wasn't built with a CRTL that contained the setenv() function. You'll need to rebuild Perl with a CRTL that does, or redefine PERL_ENV_TABLES (see perlvms) so that the environ array isn't the target of the change to %ENV which produced the warning. thread failed to start: %s (W threads)(S) The entry point function of threads-> create() failed for some reason. times not implemented (F) Your version of the C library apparently doesn't do times(). I suspect you're not running on Unix. \"-T\" is on the #! line, it must also be used on the command line (X) The #! line (or local equivalent) in a Perl script contains the -T option, but Perl was not invoked with -T in its command line. This is an error because, by the time Perl discovers a -T in a script, it's too late to properly taint everything from the environment. So Perl gives up. If the Perl script is being executed as a command using the #! mechanism (or its local equivalent), this error can usually be fixed by editing the #! line so that the -T option is a part of Perl's first argument: e.g. change \"perl -n -T\" to \"perl -T -n\". If the Perl script is being executed as \"perl scriptname\", then the -T option must appear on the command line: \"perl -T scriptname\". To%s: illegal mapping '%s' (F) You tried to define a customized To-mapping for lc(), lcfirst, uc(), or ucfirst() (or their string-inlined versions), but you specified an illegal mapping. See \"User-Defined Character Properties\" in perlunicode. Too deeply nested ()-groups (F) Your template contains ()-groups with a ridiculously deep nesting level. Too few args to syscall (F) There has to be at least one argument to syscall() to specify the system call to call, silly dilly. Too late for \"-%s\" option (X) The #! line (or local equivalent) in a Perl script contains the -M, -m or -C option. In the case of -M and -m, this is an error because those options are not intended for use inside scripts. Use the \"use\" pragma instead. The -C option only works if it is specified on the command line as well (with the same sequence of letters or numbers following). Either specify this option on the command line, or, if your system supports it, make your script executable and run it directly instead of passing it to perl. Too late to run %s block (W void) A CHECK or INIT block is being defined during run time proper, when the opportunity to run them has already passed. Perhaps you are loading a file with \"require\" or \"do\" when you should be using \"use\" instead. Or perhaps you should put the \"require\" or \"do\" inside a BEGIN block. Too many args to syscall (F) Perl supports a maximum of only 14 args to syscall(). Too many arguments for %s (F) The function requires fewer arguments than you specified. Too many )'s (A) You've accidentally run your script through csh instead of Perl. Check the #! line, or manually feed your script into Perl yourself. Too many ('s (A) You've accidentally run your script through csh instead of Perl. Check the #! line, or manually feed your script into Perl yourself. Trailing \\ in regex m\/%s\/ (F) The regular expression ends with an unbackslashed backslash. Backslash it. See perlre. Transliteration pattern not terminated (F) The lexer couldn't find the interior delimiter of a tr\/\/\/ or tr[][] or y\/\/\/ or y[][] construct. Missing the leading \"$\" from variables $tr or $y may cause this error. Transliteration replacement not terminated (F) The lexer couldn't find the final delimiter of a tr\/\/\/, tr[][], y\/\/\/ or y[][] construct. '%s' trapped by operation mask (F) You tried to use an operator from a Safe compartment in which it's disallowed. See Safe. truncate not implemented (F) Your machine doesn't implement a file truncation mechanism that Configure knows about. Type of arg %d to %s must be %s (not %s) (F) This function requires the argument in that position to be of a certain type. Arrays must be @NAME or \"@{EXPR}\". Hashes must be %NAME or \"%{EXPR}\". No implicit dereferencing is allowed--use the { EXPR } forms as an explicit dereference. See perlref. umask not implemented (F) Your machine doesn't implement the umask function and you tried to use it to restrict permissions for yourself ( EXPR & 0700). Unable to create sub named \"%s\" (F) You attempted to create or access a subroutine with an illegal name. Unbalanced context: %d more PUSHes than POPs (W internal) The exit code detected an internal inconsistency in how many execution contexts were entered and left. Unbalanced saves: %d more saves than restores (W internal) The exit code detected an internal inconsistency in how many values were temporarily localized. Unbalanced scopes: %d more ENTERs than LEAVEs (W internal) The exit code detected an internal inconsistency in how many blocks were entered and left. Unbalanced tmps: %d more allocs than frees (W internal) The exit code detected an internal inconsistency in how many mortal scalars were allocated and freed. Undefined format \"%s\" called (F) The format indicated doesn't seem to exist. Perhaps it's really in another package? See perlform. Undefined sort subroutine \"%s\" called (F) The sort comparison routine specified doesn't seem to exist. Perhaps it's in a different package? See \"sort\" in perlfunc. Undefined subroutine &%s called (F) The subroutine indicated hasn't been defined, or if it was, it has since been undefined. Undefined subroutine called (F) The anonymous subroutine you're trying to call hasn't been defined, or if it was, it has since been undefined. Undefined subroutine in sort (F) The sort comparison routine specified is declared but doesn't seem to have been defined yet. See \"sort\" in perlfunc. Undefined top format \"%s\" called (F) The format indicated doesn't seem to exist. Perhaps it's really in another package? See perlform. Undefined value assigned to typeglob (W misc) An undefined value was assigned to a typeglob, a la \"*foo = undef\". This does nothing. It's possible that you really mean \"undef *foo\". %s: Undefined variable (A) You've accidentally run your script through csh instead of Perl. Check the #! line, or manually feed your script into Perl yourself. unexec of %s into %s failed! (F) The unexec() routine failed for some reason. See your local FSF representative, who probably put it there in the first place. Unicode character %s is illegal (W utf8) Certain Unicode characters have been designated off-limits by the Unicode standard and should not be generated. If you really know what you are doing you can turn off this warning by \"no warnings 'utf8';\". Unknown BYTEORDER (F) There are no byte-swapping functions for a machine with this byte order. Unknown open() mode '%s' (F) The second argument of 3-argument open() is not among the list of valid modes: \"<\", \">\", \">>\", \"+<\", \"+>\", \"+>>\", \"-|\", \"|-\", \"<&\", \">&\". Unknown PerlIO layer \"%s\" (W layer) An attempt was made to push an unknown layer onto the Perl I\/O system. (Layers take care of transforming data between external and internal representations.) Note that some layers, such as \"mmap\", are not supported in all environments. If your program didn't explicitly request the failing operation, it may be the result of the value of the environment variable PERLIO . Unknown process %x sent message to prime_env_iter: %s (P) An error peculiar to VMS . Perl was reading values for %ENV before iterating over it, and someone else stuck a message in the stream of data Perl expected. Someone's very confused, or perhaps trying to subvert Perl's population of %ENV for nefarious purposes. Unknown \"re\" subpragma '%s' (known ones are: %s) You tried to use an unknown subpragma of the \"re\" pragma. Unknown switch condition (?(%.2s in regex; marked by <-- HERE in m\/%s\/ (F) The condition part of a (?(condition)if-clause|else-clause) construct is not known. The condition may be lookahead or lookbehind (the condition is true if the lookahead or lookbehind is true), a (?{...}) construct (the condition is true if the code evaluates to a true value), or a number (the condition is true if the set of capturing parentheses named by the number matched). The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Unknown Unicode option letter '%c' You specified an unknown Unicode option. See perlrun documentation of the \"-C\" switch for the list of known options. Unknown Unicode option value %x You specified an unknown Unicode option. See perlrun documentation of the \"-C\" switch for the list of known options. Unknown warnings category '%s' (F) An error issued by the \"warnings\" pragma. You specified a warnings category that is unknown to perl at this point. Note that if you want to enable a warnings category registered by a module (e.g. \"use warnings 'File::Find'\"), you must have imported this module Unknown verb pattern '%s' in regex; marked by <-- HERE in m\/%s\/ (F) You either made a typo or have incorrectly put a \"*\" quantifier after an open brace in your pattern. Check the pattern and review perlre for details on legal verb patterns. first. unmatched [ in regex; marked by <-- HERE in m\/%s\/ (F) The brackets around a character class must match. If you wish to include a closing bracket in a character class, backslash it or put it first. The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. unmatched ( in regex; marked by <-- HERE in m\/%s\/ (F) Unbackslashed parentheses must always be balanced in regular expressions. If you're a vi user, the % key is valuable for finding the matching parenthesis. The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Unmatched right %s bracket (F) The lexer counted more closing curly or square brackets than opening ones, so you're probably missing a matching opening bracket. As a general rule, you'll find the missing one (so to speak) near the place you were last editing. Unquoted string \"%s\" may clash with future reserved word (W reserved) You used a bareword that might someday be claimed as a reserved word. It's best to put such a word in quotes, or capitalize it somehow, or insert an underbar into it. You might also declare it as a subroutine. Unrecognized character %s in column %d (F) The Perl parser has no idea what to do with the specified character in your Perl script (or eval) at the specified column. Perhaps you tried to run a compressed script, a binary program, or a directory as a Perl program. Unrecognized escape \\\\%c in character class passed through in regex; marked by <-- HERE in m\/%s\/ (W regexp) You used a backslash-character combination which is not recognized by Perl inside character classes. The character was understood literally. The <-- HERE shows in the regular expression about where the escape was discovered. Unrecognized escape \\\\%c passed through (W misc) You used a backslash-character combination which is not recognized by Perl. The character was understood literally. Unrecognized escape \\\\%c passed through in regex; marked by <-- HERE in m\/%s\/ (W regexp) You used a backslash-character combination which is not recognized by Perl. The character was understood literally. The <-- HERE shows in the regular expression about where the escape was discovered. Unrecognized signal name \"%s\" (F) You specified a signal name to the kill() function that was not recognized. Say \"kill -l\" in your shell to see the valid signal names on your system. Unrecognized switch: -%s (-h will show valid options) (F) You specified an illegal option to Perl. Don't do that. (If you think you didn't do that, check the #! line to see if it's supplying the bad switch on your behalf.) Unsuccessful %s on filename containing newline (W newline) A file operation was attempted on a filename, and that operation failed, PROBABLY because the filename contained a newline, PROBABLY because you forgot to chomp() it off. See \"chomp\" in perlfunc. Unsupported directory function \"%s\" called (F) Your machine doesn't support opendir() and readdir(). Unsupported function %s (F) This machine doesn't implement the indicated function, apparently. At least, Configure doesn't think so. Unsupported function fork (F) Your version of executable does not support forking. Note that under some systems, like OS\/2 , there may be different flavors of Perl executables, some of which may support fork, some not. Try changing the name you call Perl by to \"perl_\", \"perl__\", and so on. Unsupported script encoding %s (F) Your program file begins with a Unicode Byte Order Mark ( BOM ) which declares it to be in a Unicode encoding that Perl cannot read. Unsupported socket function \"%s\" called (F) Your machine doesn't support the Berkeley socket mechanism, or at least that's what Configure thought. Unterminated attribute list (F) The lexer found something other than a simple identifier at the start of an attribute, and it wasn't a semicolon or the start of a block. Perhaps you terminated the parameter list of the previous attribute too soon. See attributes. Unterminated attribute parameter in attribute list (F) The lexer saw an opening (left) parenthesis character while parsing an attribute list, but the matching closing (right) parenthesis character was not found. You may need to add (or remove) a backslash character to get your parentheses to balance. See attributes. Unterminated compressed integer (F) An argument to unpack(\"w\",...) was incompatible with the BER compressed integer format and could not be converted to an integer. See \"pack\" in perlfunc. Unterminated verb pattern in regex; marked by <-- HERE in m\/%s\/ (F) You used a pattern of the form \"(*VERB)\" but did not terminate the pattern with a \")\". Fix the pattern and retry. Unterminated verb pattern argument in regex; marked by <-- HERE in m\/%s\/ (F) You used a pattern of the form \"(*VERB:ARG)\" but did not terminate the pattern with a \")\". Fix the pattern and retry. Unterminated \\g{...} pattern in regex; marked by <-- HERE in m\/%s\/ (F) You missed a close brace on a \\g{..} pattern (group reference) in a regular expression. Fix the pattern and retry. Unterminated <> operator (F) The lexer saw a left angle bracket in a place where it was expecting a term, so it's looking for the corresponding right angle bracket, and not finding it. Chances are you left some needed parentheses out earlier in the line, and you really meant a \"less than\". untie attempted while %d inner references still exist (W untie) A copy of the object returned from \"tie\" (or \"tied\") was still valid when \"untie\" was called. Usage: POSIX::%s(%s) (F) You called a POSIX function with incorrect arguments. See \" FUNCTIONS \" in POSIX for more information. Usage: Win32::%s(%s) (F) You called a Win32 function with incorrect arguments. See Win32 for more information. Useless (?-%s) - don't use \/%s modifier in regex; marked by <-- HERE in m\/%s\/ (W regexp) You have used an internal modifier such as (?-o) that has no meaning unless removed from the entire regexp: if ($string =~ \/(?-o)$pattern\/o) { ... } must be written as if ($string =~ \/$pattern\/) { ... } The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Useless localization of %s (W syntax) The localization of lvalues such as \"local($x=10)\" is legal, but in fact the local() currently has no effect. This may change at some point in the future, but in the meantime such code is discouraged. Useless (?%s) - use \/%s modifier in regex; marked by <-- HERE in m\/%s\/ (W regexp) You have used an internal modifier such as (?o) that has no meaning unless applied to the entire regexp: if ($string =~ \/(?o)$pattern\/) { ... } must be written as if ($string =~ \/$pattern\/o) { ... } The <-- HERE shows in the regular expression about where the problem was discovered. See perlre. Useless use of %s in void context (W void) You did something without a side effect in a context that does nothing with the return value, such as a statement that doesn't return a value from a block, or the left side of a scalar comma operator. Very often this points not to stupidity on your part, but a failure of Perl to parse your program the way you thought it would. For example, you'd get this if you mixed up your C precedence with Python precedence and said $one, $two = 1, 2; when you meant to say ($one, $two) = (1, 2); Another common error is to use ordinary parentheses to construct a list reference when you should be using square or curly brackets, for example, if you say $array = (1,2); when you should have said $array = [1,2]; The square brackets explicitly turn a list value into a scalar value, while parentheses do not. So when a parenthesized list is evaluated in a scalar context, the comma is treated like C's comma operator, which throws away the left argument, which is not what you want. See perlref for more on this. This warning will not be issued for numerical constants equal to 0 or 1 since they are often used in statements like 1 while sub_with_side_effects(); String constants that would normally evaluate to 0 or 1 are warned about. Useless use of \"re\" pragma (W) You did \"use re;\" without any arguments. That isn't very useful. Useless use of sort in scalar context (W void) You used sort in scalar context, as in : my $x = sort @y; This is not very useful, and perl currently optimizes this away. Useless use of %s with no values (W syntax) You used the push() or unshift() function with no arguments apart from the array, like \"push(@x)\" or \"unshift(@foo)\". That won't usually have any effect on the array, so is completely useless. It's possible in principle that push(@tied_array) could have some effect if the array is tied to a class which implements a PUSH method. If so, you can write it as \"push(@tied_array,())\" to avoid this warning. \"use\" not allowed in expression (F) The \"use\" keyword is recognized and executed at compile time, and returns no useful value. See perlmod. Use of bare << to mean <<\"\" is deprecated (D deprecated, W syntax) You are now encouraged to use the explicitly quoted form if you wish to use an empty line as the terminator of the here-document. Use of comma-less variable list is deprecated (D deprecated, W syntax) The values you give to a format should be separated by commas, not just aligned on a line. Use of chdir('') or chdir(undef) as chdir() deprecated (D deprecated) chdir() with no arguments is documented to change to $ENV{ HOME } or $ENV{ LOGDIR }. chdir(undef) and chdir('') share this behavior, but that has been deprecated. In future versions they will simply fail. Be careful to check that what you pass to chdir() is defined and not blank, else you might find yourself in your home directory. Use of \/c modifier is meaningless in s\/\/\/ (W regexp) You used the \/c modifier in a substitution. The \/c modifier is not presently meaningful in substitutions. Use of \/c modifier is meaningless without \/g (W regexp) You used the \/c modifier with a regex operand, but didn't use the \/g modifier. Currently, \/c is meaningful only when \/g is used. (This may change in the future.) Use of freed value in iteration (F) Perhaps you modified the iterated array within the loop? This error is typically caused by code like the following: @a = (3,4);\n@a = () for (1,2,@a); You are not supposed to modify arrays while they are being iterated over. For speed and efficiency reasons, Perl internally does not do full reference-counting of iterated items, hence deleting such an item in the middle of an iteration causes Perl to see a freed value. Use of *glob{ FILEHANDLE } is deprecated (D deprecated) You are now encouraged to use the shorter *glob{ IO } form to access the filehandle slot within a typeglob. Use of \/g modifier is meaningless in split (W regexp) You used the \/g modifier on the pattern for a \"split\" operator. Since \"split\" always tries to match the pattern repeatedly, the \"\/g\" has no effect. Use of implicit split to @_ is deprecated (D deprecated, W syntax) It makes a lot of work for the compiler when you clobber a subroutine's argument list, so it's better if you assign the results of a split() explicitly to an array (or list). Use of inherited AUTOLOAD for non-method %s() is deprecated (D deprecated) As an (ahem) accidental feature, \"AUTOLOAD\" subroutines are looked up as methods (using the @ISA hierarchy) even when the subroutines to be autoloaded were called as plain functions (e.g. \"Foo::bar()\"), not as methods (e.g. \"Foo->bar()\" or \"$obj->bar()\"). This bug will be rectified in future by using method lookup only for methods' \"AUTOLOAD\"s. However, there is a significant base of existing code that may be using the old behavior. So, as an interim step, Perl currently issues an optional warning when non-methods use inherited \"AUTOLOAD\"s. The simple rule is: Inheritance will not work when autoloading non-methods. The simple fix for old code is: In any module that used to depend on inheriting \"AUTOLOAD\" for non-methods from a base class named \"BaseClass\", execute \"*AUTOLOAD = \\&BaseClass::AUTOLOAD\" during startup. In code that currently says \"use AutoLoader; @ISA = qw(AutoLoader);\" you should remove AutoLoader from @ISA and change \"use AutoLoader;\" to \"use AutoLoader 'AUTOLOAD';\". Use of %s in printf format not supported (F) You attempted to use a feature of printf that is accessible from only C. This usually means there's a better way to do it in Perl. Use of %s is deprecated (D deprecated) The construct indicated is no longer recommended for use, generally because there's a better way to do it, and also because the old way has bad side effects. Use of -l on filehandle %s (W io) A filehandle represents an opened file, and when you opened the file it already went past any symlink you are presumably trying to look for. The operation returned \"undef\". Use a filename instead. Use of \"package\" with no arguments is deprecated (D deprecated) You used the \"package\" keyword without specifying a package name. So no namespace is current at all. Using this can cause many otherwise reasonable constructs to fail in baffling ways. \"use strict;\" instead. Use of reference \"%s\" as array index (W misc) You tried to use a reference as an array index; this probably isn't what you mean, because references in numerical context tend to be huge numbers, and so usually indicates programmer error. If you really do mean it, explicitly numify your reference, like so: $array[0+$ref]. This warning is not given for overloaded objects, either, because you can overload the numification and stringification operators and then you assumably know what you are doing. Use of reserved word \"%s\" is deprecated (D deprecated) The indicated bareword is a reserved word. Future versions of perl may use it as a keyword, so you're better off either explicitly quoting the word in a manner appropriate for its context of use, or using a different name altogether. The warning can be suppressed for subroutine names by either adding a \"&\" prefix, or using a package qualifier, e.g. \"&our()\", or \"Foo::our()\". Use of tainted arguments in %s is deprecated (W taint, deprecated) You have supplied \"system()\" or \"exec()\" with multiple arguments and at least one of them is tainted. This used to be allowed but will become a fatal error in a future version of perl. Untaint your arguments. See perlsec. Use of uninitialized value%s (W uninitialized) An undefined value was used as if it were already defined. It was interpreted as a \"\" or a 0, but maybe it was a mistake. To suppress this warning assign a defined value to your variables. To help you figure out what was undefined, perl will try to tell you the name of the variable (if any) that was undefined. In some cases it cannot do this, so it also tells you what operation you used the undefined value in. Note, however, that perl optimizes your program and the operation displayed in the warning may not necessarily appear literally in your program. For example, \"that $foo\" is usually optimized into \"\"that \" . $foo\", and the warning will refer to the \"concatenation (.)\" operator, even though there is no \".\" in your program. Using a hash as a reference is deprecated (D deprecated) You tried to use a hash as a reference, as in \"%foo->{\"bar\"}\" or \"%$ref->{\"hello\"}\". Versions of perl <= 5.6.1 used to allow this syntax, but shouldn't have. It is now deprecated, and will be removed in a future version. Using an array as a reference is deprecated (D deprecated) You tried to use an array as a reference, as in \"@foo->[23]\" or \"@$ref->[99]\". Versions of perl <= 5.6.1 used to allow this syntax, but shouldn't have. It is now deprecated, and will be removed in a future version. UTF-16 surrogate %s (W utf8) You tried to generate half of an UTF-16 surrogate by requesting a Unicode character between the code points 0xD800 and 0xDFFF (inclusive). That range is reserved exclusively for the use of UTF-16 encoding (by having two 16-bit UCS-2 characters); but Perl encodes its characters in UTF-8 , so what you got is a very illegal character. If you really know what you are doing you can turn off this warning by \"no warnings 'utf8';\". Value of %s can be \"0\"; test with defined() (W misc) In a conditional expression, you used < HANDLE >, <*> (glob), \"each()\", or \"readdir()\" as a boolean value. Each of these constructs can return a value of \"0\"; that would make the conditional expression false, which is probably not what you intended. When using these constructs in conditional expressions, test their values with the \"defined\" operator. Value of CLI symbol \"%s\" too long (W misc) A warning peculiar to VMS . Perl tried to read the value of an %ENV element from a CLI symbol table, and found a resultant string longer than 1024 characters. The return value has been truncated to 1024 characters. Variable \"%s\" is not available (W closure) During compilation, an inner named subroutine or eval is attempting to capture an outer lexical that is not currently available. This can happen for one of two reasons. First, the outer lexical may be declared in an outer anonymous subroutine that has not yet been created. (Remember that named subs are created at compile time, while anonymous subs are created at run-time.) For example, sub { my $a; sub f { $a } } At the time that f is created, it can't capture the current value of $a, since the anonymous subroutine hasn't been created yet. Conversely, the following won't give a warning since the anonymous subroutine has by now been created and is live: sub { my $a; eval 'sub f { $a }' }->(); The second situation is caused by an eval accessing a variable that has gone out of scope, for example, sub f {\n    my $a;\n    sub { eval '$a' }\n}\nf()->(); Here, when the '$a' in the eval is being compiled, f() is not currently being executed, so its $a is not available for capture. Variable \"%s\" is not imported%s (F) While \"use strict\" in effect, you referred to a global variable that you apparently thought was imported from another module, because something else of the same name (usually a subroutine) is exported by that module. It usually means you put the wrong funny character on the front of your variable. Variable length lookbehind not implemented in m\/%s\/ (F) Lookbehind is allowed only for subexpressions whose length is fixed and known at compile time. See perlre. \"%s\" variable %s masks earlier declaration in same %s (W misc) A \"my\", \"our\" or \"state\" variable has been redeclared in the current scope or statement, effectively eliminating all access to the previous instance. This is almost always a typographical error. Note that the earlier variable will still exist until the end of the scope or until all closure referents to it are destroyed. Variable syntax (A) You've accidentally run your script through csh instead of Perl. Check the #! line, or manually feed your script into Perl yourself. Variable \"%s\" will not stay shared (W closure) An inner (nested) named subroutine is referencing a lexical variable defined in an outer named subroutine. When the inner subroutine is called, it will see the value of the outer subroutine's variable as it was before and during the *first* call to the outer subroutine; in this case, after the first call to the outer subroutine is complete, the inner and outer subroutines will no longer share a common value for the variable. In other words, the variable will no longer be shared. This problem can usually be solved by making the inner subroutine anonymous, using the \"sub {}\" syntax. When inner anonymous subs that reference variables in outer subroutines are created, they are automatically rebound to the current values of such variables. Verb pattern '%s' has a mandatory argument in regex; marked by <-- HERE in m\/%s\/ (F) You used a verb pattern that requires an argument. Supply an argument or check that you are using the right verb. Verb pattern '%s' may not have an argument in regex; marked by <-- HERE in m\/%s\/ (F) You used a verb pattern that is not allowed an argument. Remove the argument or check that you are using the right verb. Version number must be a constant number (P) The attempt to translate a \"use Module n.n LIST\" statement into its equivalent \"BEGIN\" block found an internal inconsistency with the version number. Version string '%s' contains invalid data; ignoring: '%s' (W misc) The version string contains invalid characters at the end, which are being ignored. Warning: something's wrong (W) You passed warn() an empty string (the equivalent of \"warn \"\"\") or you called it with no args and $@ was empty. Warning: unable to close filehandle %s properly (S) The implicit close() done by an open() got an error indication on the close(). This usually indicates your file system ran out of disk space. Warning: Use of \"%s\" without parentheses is ambiguous (S ambiguous) You wrote a unary operator followed by something that looks like a binary operator that could also have been interpreted as a term or unary operator. For instance, if you know that the rand function has a default argument of 1.0, and you write rand + 5; you may THINK you wrote the same thing as rand() + 5; but in actual fact, you got rand(+5); So put in parentheses to say what you really mean. Wide character in %s (S utf8) Perl met a wide character (>255) when it wasn't expecting one. This warning is by default on for I\/O (like print). The easiest way to quiet this warning is simply to add the \":utf8\" layer to the output, e.g. \"binmode STDOUT, ':utf8'\". Another way to turn off the warning is to add \"no warnings 'utf8';\" but that is often closer to cheating. In general, you are supposed to explicitly mark the filehandle with an encoding, see open and \"binmode\" in perlfunc. Within []-length '%c' not allowed (F) The count in the (un)pack template may be replaced by \"[TEMPLATE]\" only if \"TEMPLATE\" always matches the same amount of packed bytes that can be determined from the template alone. This is not possible if it contains an of the codes @, \/, U, u, w or a *-length. Redesign the template. write() on closed filehandle %s (W closed) The filehandle you're writing to got itself closed sometime before now. Check your control flow. %s \"\\x%s\" does not map to Unicode When reading in different encodings Perl tries to map everything into Unicode characters. The bytes you read in are not legal in this encoding, for example utf8 \"\\xE4\" does not map to Unicode if you try to read in the a-diaereses Latin-1 as UTF-8 . 'X' outside of string (F) You had a (un)pack template that specified a relative position before the beginning of the string being (un)packed. See \"pack\" in perlfunc. 'x' outside of string in unpack (F) You had a pack template that specified a relative position after the end of the string being unpacked. See \"pack\" in perlfunc. YOU HAVEN 'T DISABLED SET-ID SCRIPTS IN THE KERNEL YET ! (F) And you probably never will, because you probably don't have the sources to your kernel, and your vendor probably doesn't give a rip about what you want. Your best bet is to put a setuid C wrapper around your script. You need to quote \"%s\" (W syntax) You assigned a bareword as a signal handler name. Unfortunately, you already have a subroutine of that name declared, which means that Perl 5 will try to call the subroutine when the assignment is executed, which is probably not what you want. (If it IS what you want, put an & in front.) Your random numbers are not that random (F) When trying to initialise the random seed for hashes, Perl could not get any randomness out of your system. This usually indicates Something Very Wrong.","Process Name":"perldiag","Link":"https:\/\/linux.die.net\/man\/1\/perldiag"}},{"Process":{"Description":"The program perldl is a simple shell (written in perl) for interactive use of PDL . It consists of a command-line interface that supports immediate interpretation of perl commands and expressions. Perl expressions, including PDL constructs, can be entered directly at the keyboard and are compiled and executed immediately. The syntax is not exactly identical to Perl, in that under most circumstances ending a line causes immediate execution of the command entered so far (no trailing ';' is required). The synonym pdl is a compiled executable that is useful as a script interpreter using UNIX shebang (\"#!\") syntax. This is useful for generating and re-executing command-journal files from perldl. The perldl shell runs an initial startup file (\"~\/.perldlrc\") that can be used to pre-load perl modules or configure the global perl environment. It features a path mechanism for autoloading perl subroutines. There is a command-history mechanism, and several other useful features such as command preprocessing, shortcuts for commonly used commands such as \"print\", and the ability to execute arbitrary code whenever a prompt is printed. Depending on your configuration settings, perldl can be set to honor or ignore the ^D (end-of-file) character when sent from a terminal, or to attempt to do the Right Thing when a block construct spanning multiple lines is encountered. perldl and pdl support several command-line options, which are discussed near the end of this document. Reference manual & online help The PDL reference manual and online help are available from within perldl, using the help and apropos commands (which may also be abbreviated ? and ??.) The help command alone prints a summary of help syntax, and help <module-name> will print POD documentation from the module you mention ( POD is the Perl format for embedding documentation in your perl code; see perlpod for details). If you include POD documentation in your autoload subroutines (see path mechanism below), then both help and apropos will find it and be able to format and display it on demand. History mechanism If you have the perl modules ReadLines and ReadKeys installed, then perldl supports a history and line-editing mechanism using editing keys similar to emacs(1). The last 50 commands are always stored in the file .perldl_hist in your home directory between sessions. Set $PERLDL::HISTFILESIZE to change the number of lines saved. The command \"l [number]\" shows you the last \"number\" commands you typed where \"number\" defaults to 20. e.g.: bash$ perldl\nReadLines enabled\npdl> $a = rfits \"foo.fits\"\nBITPIX =  -32  size = 88504 pixels\nReading  354016 bytes\nBSCALE =  &&  BZERO =\n\npdl> imag log($a+400)\nDisplaying 299 x 296 image from 4.6939525604248 to 9.67116928100586 ... Command execution If you enter a simple command at the perldl command line, it is immediately executed in a Perl eval(). The environment is almost identical to that within a perl script, with some important exceptions: \u2022 $_ is not preserved across lines $_ is used to hold the command line for initial processing, so at the beginning of processing of each command line, $_ contains the command itself. Use variables other than $_ to store values across lines. \u2022 Scope is not preserved across lines Each command line is executed in a separate \"eval\" block within perl, so scoping commands such as \"my\" and \"local\" may not perform exactly as expected -- in particular, if you declare a variable with \"my\", it is local to the particular command line on which you typed the \"my\" command, which means that it will evaporate before the next prompt is printed. (You can use \"my\" variables in a multi-line block or to isolate values within a single command line, of course). \u2022 Execution is immediate Under most circumstances, as soon as you end a line of input the line is parsed and executed. This breaks Perl's normal dependence on semicolons as command delimiters. For example, the two-line expression print \"Hello \",\n   \"world\"; prints the phrase \"Hello world\" in Perl, but (under most circumstances) \"Hello \" in perldl. \u2022 Multi-line execution In multiline mode (which is enabled by default, see Shell variables, below), perldl searches for searches for block-like constructs with curly braces, parentheses, quotes, and related delimiters. If you leave such a construct open, perldl accepts more lines of input until you close the construct or explictly end the multi-line expression with ^D. Following the example above, the phrase { print \"Hello \",\n     \"world\"; } will print \"Hello world\" from either Perl or (in multi-line mode) perldl. Warning: The multi-line parsing uses Damian Conway's Text::Balanced module, which contains some flaws -- so it can be fooled by quote-like operators such as \"q\/...\/\", included POD documentation, multi-line \"<<\" quotes, and some particularly bizarre-but-valid \"m\/...\/\" matches and \"s\/...\/...\/\" substitutions. In such cases, use ^D to close out the multi-line construct and force compilation-and-execution. If you want to preserve this behavior in a script (for example to replay a command journal file; see below on how to create one), you can use pdl instead of perl as the interpreter in the script's initial shebang line. Terminating \"perldl\" A \"perldl\" session can be terminated with any of the commands \"quit\", \"exit\" or the shorthands \"x\" or \"q\". If EOF handling is switched on (the default) you can also type ^D at the command prompt. If the command input is NOT a terminal (for example if you are running from a command journal file), then EOF will always terminate perldl. Terminating commands (Ctrl-C handling) Commands executed within \"perldl\" can be terminated prematurely using \"Ctrl-C\" (or whichever key sequence sends an INT signal to the process on your terminal). Provided your PDL code does not ignore \"sigint\"s this should throw you back at the \"perldl\" command prompt:  pdl> $result = start_lengthy_computation()\n  <Ctrl-C>\nCtrl-C detected\n\n pdl> Shortcuts and aliases \u2022 The shell aliases \"p\" to be a convenient short form of \"print\", e.g. pdl> p ones 5,3\n\n[\n [1 1 1 1 1]\n [1 1 1 1 1]\n [1 1 1 1 1]\n] \u2022 \"q\" and \"x\" are short-hand for \"quit\". \u2022 \"l\" lists the history buffer pdl> l # list last 20 commands\n\npdl> l 40 # list last 40 commands \u2022 \"?\" is an alias for help pdl> ? pdl2    # get help for new pdl2 shell \u2022 \"??\" is an alias for apropos pdl> ?? PDL::Doc \u2022 help, apropos, usage and sig: all words after these commands are used verbatim and not evaluated by perl. So you can write, e.g., pdl> help help instead of pdl> help 'help' Command-line options perldl and pdl support several command-line options to adjust the behavior of the session. Most of them are equivalent to commands that can be entered at the perldl> prompt. They are: -tk Load Tk when starting the shell (the perl Tk module, which is available from CPAN must be installed). This enables readline event loop processing. -f file Loads the file before processing any user input. Any errors during the execution of the file are fatal. -w Runs with warning messages (i.e. the normal perl \"-w\" warnings) turned-on. -M module Loads the module before processing any user input. Compare corresponding \"perl\" switch. -m module Unloads the module before processing any user input. -I directory Adds directory to the include path. (i.e. the @INC array) Compare corresponding \"perl\" switch. -V Prints a summary of PDL config. This information should be included with any PDL bug report. Compare corresponding \"perl\" switch. The startup file ~\/.perldlrc If the file ~\/.perldlrc is found it is sourced at start-up to load default modules, set shell variables, etc. If it is NOT found the distribution file PDL\/default.perldlrc is read instead. This loads various modules considered useful by default, and which ensure compatibility with v1.11. If you don't like this and want a more streamlined set of your own favourite modules simple create your own ~\/.perldlrc. You may wish to start from the existing PDL\/default.perldlrc as a template since it will not be sourced once you replace it with your own version. To set even more local defaults the file local.perldlrc (in the current directory) is sourced if found. This lets you load modules and define subroutines for the project in the current directory. The name is chosen specfically because it was found hidden files were NOT wanted in these circumstances. The startup file should normally include \"use PDL::AutoLoader;\", as many of the nicer interactive features won't work without it. Shell variables Shell variables: ( Note: if you don't like the defaults change them in ~\/.perldlrc) \u2022 $PERLDL::ESCAPE - default value '#' Any line starting with this character is treated as a shell escape. The default value is chosen because it escapes the code from the standard perl interpreter. \u2022 $PERLDL::HISTFILESIZE - default value 500 This is the number of lines of perldl shell command history to keep. \u2022 $PERLDL::PAGER - default value \"more\" External program to filter the output of commands. Using \"more\" prints output one screenful at a time. On Unix, setting page(1) and $PERLDL::PAGER to \"tee -a outfile\" will keep a record of the output generated by subsequent perldl commands (without paging). \u2022 $PERLDL::PROMPT - default value 'perldl> ' Enough said But can also be set to a subroutine reference, e.g. $PERLDL::PROMPT = sub {join(':',(gmtime)[2,1,0]).'> '} puts the current time into the prompt. \u2022 $PERLDL::MULTI - default value 1 If this is set to a true value, then perldl will parse multi-line perl blocks: your input will not be executed until you finish a line with no outstanding group operators (such as quotes, blocks, parenthesis, or brackets) still active. Continuation lines have a different prompt that shows you what delimiters are still active. Note that this is not (yet!) a complete perl parser. In particular, Text::Balanced appears to be able to ignore quoting operatores like \"q\/ ... \/\" within a line, but not to be able to extend them across lines. Likewise, there is no support for the '<<' operator. Multiline conventional strings and {}, [], and () groupings are well supported. \u2022 $PERLDL::NO_EOF - default value 0 \/ 1 on MSWin32 Protects against accidental use of \"^D\" from the terminal. If this is set to a true value, then you can't accidentally exit perldl by typing \"^D\". If you set it to a value larger than 1 (and PERLDL::MULTI is set), then you can't use \"^D\" to exit multiline commands either. If you're piping commands in from a file or pipe, this variable has no effect. \u2022 $HOME The user's home directory \u2022 $PERLDL::TERM This is the Term::ReadLine object associated with the perldl shell. It can be used by routines called from perldl if your command is interactive. Executing scripts from the \"perldl\" prompt A useful idiom for developing perldl scripts or editing functions on-line is pdl> # emacs script &\n  -- add perldl code to script and save the file\n\npdl> do 'script' -- substitute your favourite window-based editor for 'emacs' (you may also need to change the '&' on non-Unix systems). Running \"do 'script'\" again updates any variables and function definitions from the current version of 'script'. Executing perldl scripts from the command line PDL scripts are just perl scripts that happen to use PDL (and possibly PDL::NiceSlice). But for the truly lazy, perldl can be invokes as a script interpreter. Because perldl is itself an interpreted perl script, most unices won't allow you to say \"#!\/usr\/bin\/perldl\" at the top of your script. Instead, say \"#!\/usr\/bin\/pdl\" and your script will be executed exactly as if you typed it, line-by-line, into the perldl shell. Command preprocessing NOTE: This feature is used by default by PDL::NiceSlice. See below for more about slicing at the \"perldl\" prompt In some cases, it is convenient to process commands before they are sent to perl for execution. For example, this is the case where the shell is being presented to people unfamiliar with perl but who wish to take advantage of commands added locally (eg by automatically quoting arguments to certain commands). * NOTE *: The preprocessing interface has changed from earlier versions! The old way using $PERLDL::PREPROCESS will still work but is strongly deprecated and might go away in the future. You can enable preprocessing by registering a filter with the \"preproc_add\" function. \"preproc_add\" takes one argument which is the filter to be installed. A filter is a Perl code reference (usually set in a local configuration file) that will be called, with the current command string as argument, just prior to the string being executed by the shell. The modified string should be returned. Note that you can make \"perldl\" completely unusable if you fail to return the modified string; quitting is then your only option. Filters can be removed from the preprocessing pipeline by calling \"preproc_del\" with the filter to be removed as argument. To find out if a filter is currently installed in the preprocessing pipeline use \"preproc_registered\": pdl> preproc_add $myfilter unless preproc_registered $myfilter; Previous versions of \"perldl\" used the variable $PERLDL::PREPROCESS. This will still work but should be avoided. Please change your scripts to use the \"preproc_add\" etc functions. The following code would check for a call to function 'mysub' and bracket arguments with qw. $filter = preproc_add sub {\n   my $str = shift;\n   $str =~ s\/^\\s+\/\/;  # Strip leading space\n   if ($str =~ \/^mysub\/) {\n      my ($command, $arguments) = split(\/\\s+\/,$str, 2);\n      $str = \"$command qw( $arguments )\"\n      if (defined $arguments && $arguments !~ \/^qw\/);\n   };\n   # Return the input string, modified as required\n   return $str;\n }; This would convert: pdl> mysub arg1 arg2 to pdl> mysub qw( arg1 arg2 ) which Perl will understand as a list. Obviously, a little more effort is required to check for cases where the caller has supplied a normal list (and so does not require automatic quoting) or variable interpolation is required. You can remove this preprocessor using the \"preproc_del\" function which takes one argument (the filter to be removed, it must be the same coderef that was returned from a previous \"preproc_add\" call): pdl> preproc_del $filter; An example of actual usage can be found in the \"perldl\" script. Look at the function \"trans\" to see how the niceslicing preprocessor is enabled\/disabled. \"perldl\" and PDL::NiceSlice PDL::NiceSlice introduces a more convenient slicing syntax for piddles. In current versions of \"perldl\" niceslicing is enabled by default (if the required CPAN modules are installed on your machine). At startup \"perldl\" will let you know if niceslicing is enabled. The startup message will contain info to this end, something like this: perlDL shell v1.XX\n PDL comes with ABSOLUTELY NO WARRANTY. For details, see the file\n 'COPYING' in the PDL distribution. This is free software and you\n are welcome to redistribute it under certain conditions, see\n the same file for details.\nReadLines, NiceSlice  enabled\nReading \/home\/csoelle\/.perldlrc...\nType 'demo' for online demos\nLoaded PDL v2.XX When you get such a message that indicates \"NiceSlice\" is enabled you can use the enhanced slicing syntax: pdl> $a = sequence 10;\npdl> p $a(3:8:2) For details consult PDL::NiceSlice. PDL::NiceSlice installs a filter in the preprocessing pipeline (see above) to enable the enhanced slicing syntax. You can use a few commands in the \"perldl\" shell to switch this preprocessing on or off and also explicitly check the substitutions that the NiceSlice filter makes. You can switch the PDL::NiceSlice filter on and off by typing pdl> trans # switch niceslicing on and pdl> notrans # switch niceslicing off respectively. The filter is on by default. To see how your commands are translated switch reporting on: pdl> report 1;\npdl> p $a(3:8:2)\nprocessed p $a->nslice([3,8,2])\n[3 5 7] Similarly, switch reporting off as needed pdl> report 0;\npdl>  p $a(3:8:2)\n[3 5 7] Reporting is off by default. Automatically execute your own hooks The variable @PERLDL::AUTO is a simple list of perl code strings and\/or code reference. It is used to define code to be executed automatically every time the user enters a new line. A simple example would be to print the time of each command: pdl> push @PERLDL::AUTO,'print scalar(gmtime),\"\\n\"'\n\npdl> print zeroes(3,3)\nSun May  3 04:49:05 1998\n\n[\n [0 0 0]\n [0 0 0]\n [0 0 0]\n]\n\npdl> print \"Boo\"\nSun May  3 04:49:18 1998\nBoo\npdl> Or to make sure any changes in the file 'local.perldlrc' are always picked up :- pdl> push @PERLDL::AUTO,\"do 'local.perldlrc'\" This code can of course be put *in* 'local.perldlrc', but be careful :-) [Hint: add \"unless ($started++)\" to above to ensure it only gets done once!] Another example application is as a hook for Autoloaders (e.g. PDL::AutoLoader) to add code too which allows them to automatically re-scan their files for changes. This is extremely convenient at the interactive command line. Since this hook is only in the shell it imposes no inefficiency on PDL scripts. Finally note this is a very powerful facility - which means it should be used with caution!","Process Name":"perldl","Link":"https:\/\/linux.die.net\/man\/1\/perldl"}},{"Process":{"Description":"perldoc looks up a piece of documentation in .pod format that is embedded in the perl installation tree or in a perl script, and displays it via \"pod2man | nroff -man | $PAGER\". (In addition, if running under HP-UX, \"col -x\" will be used.) This is primarily used for the documentation for the perl library modules. Your system may also have man pages installed for those modules, in which case you can probably just use the man(1) command. If you are looking for a table of contents to the Perl library modules documentation, see the perltoc page.","Process Name":"perldoc","Link":"https:\/\/linux.die.net\/man\/1\/perldoc"}},{"Process":{"Description":"Before you start, you should glance through the README file found in the top-level directory where the Perl distribution was extracted. Make sure you read and understand the terms under which this software is being distributed. This port currently supports MakeMaker (the set of modules that is used to build extensions to perl). Therefore, you should be able to build and install most extensions found in the CPAN sites. Detailed instructions on how to build and install perl extension modules, including XS-type modules, is included. See ' BUILDING AND INSTALLING MODULES '. Prerequisites for Compiling Perl on DOS DJGPP DJGPP is a port of GNU C\/C ++ compiler and development tools to 32-bit, protected-mode environment on Intel 32-bit CPUs running MS-DOS and compatible operating systems, by DJ Delorie < dj@delorie.com> and friends. For more details ( FAQ ), check out the home of DJGPP at: http:\/\/www.delorie.com\/djgpp\/ If you have questions about DJGPP , try posting to the DJGPP newsgroup: comp.os.msdos.djgpp, or use the email gateway djgpp@delorie.com. You can find the full DJGPP distribution on any of the mirrors listed here: http:\/\/www.delorie.com\/djgpp\/getting.html You need the following files to build perl (or add new modules): v2\/djdev203.zip\nv2gnu\/bnu2112b.zip\nv2gnu\/gcc2953b.zip\nv2gnu\/bsh204b.zip\nv2gnu\/mak3791b.zip\nv2gnu\/fil40b.zip\nv2gnu\/sed3028b.zip\nv2gnu\/txt20b.zip\nv2gnu\/dif272b.zip\nv2gnu\/grep24b.zip\nv2gnu\/shl20jb.zip\nv2gnu\/gwk306b.zip\nv2misc\/csdpmi5b.zip or possibly any newer version. Pthreads Thread support is not tested in this version of the djgpp perl. Shortcomings of Perl under DOS Perl under DOS lacks some features of perl under UNIX because of deficiencies in the UNIX-emulation, most notably: \u2022 fork() and pipe() \u2022 some features of the UNIX filesystem regarding link count and file dates \u2022 in-place operation is a little bit broken with short filenames \u2022 sockets Building Perl on DOS \u2022 Unpack the source package perl5.8*.tar.gz with djtarx. If you want to use long file names under w95 and also to get Perl to pass all its tests, don't forget to use set LFN=y\nset FNCASE=y before unpacking the archive. \u2022 Create a \"symlink\" or copy your bash.exe to sh.exe in your \"($DJDIR)\/bin\" directory. ln -s bash.exe sh.exe [If you have the recommended version of bash for DJGPP , this is already done for you.] And make the \"SHELL\" environment variable point to this sh.exe: set SHELL=c:\/djgpp\/bin\/sh.exe (use full path name!) You can do this in djgpp.env too. Add this line BEFORE any section definition: +SHELL=%DJDIR%\/bin\/sh.exe \u2022 If you have split.exe and gsplit.exe in your path, then rename split.exe to djsplit.exe, and gsplit.exe to split.exe. Copy or link gecho.exe to echo.exe if you don't have echo.exe. Copy or link gawk.exe to awk.exe if you don't have awk.exe. [If you have the recommended versions of djdev, shell utilities and gawk, all these are already done for you, and you will not need to do anything.] \u2022 Chdir to the djgpp subdirectory of perl toplevel and type the following commands: set FNCASE=y\nconfigure.bat This will do some preprocessing then run the Configure script for you. The Configure script is interactive, but in most cases you just need to press ENTER . The \"set\" command ensures that DJGPP preserves the letter case of file names when reading directories. If you already issued this set command when unpacking the archive, and you are in the same DOS session as when you unpacked the archive, you don't have to issue the set command again. This command is necessary *before* you start to (re)configure or (re)build perl in order to ensure both that perl builds correctly and that building XS-type modules can succeed. See the DJGPP info entry for \"_preserve_fncase\" for more information: info libc alphabetical _preserve_fncase If the script says that your package is incomplete, and asks whether to continue, just answer with Y (this can only happen if you don't use long filenames or forget to issue \"set FNCASE=y\" first). When Configure asks about the extensions, I suggest IO and Fcntl, and if you want database handling then SDBM_File or GDBM_File (you need to install gdbm for this one). If you want to use the POSIX extension (this is the default), make sure that the stack size of your cc1.exe is at least 512kbyte (you can check this with: \"stubedit cc1.exe\"). You can use the Configure script in non-interactive mode too. When I built my perl.exe, I used something like this: configure.bat -des You can find more info about Configure's command line switches in the INSTALL file. When the script ends, and you want to change some values in the generated config.sh file, then run sh Configure -S after you made your modifications. IMPORTANT: if you use this \"-S\" switch, be sure to delete the CONFIG environment variable before running the script: set CONFIG= \u2022 Now you can compile Perl. Type: make Testing Perl on DOS Type: make test If you're lucky you should see \"All tests successful\". But there can be a few failed subtests (less than 5 hopefully) depending on some external conditions (e.g. some subtests fail under linux\/dosemu or plain dos with short filenames only). Installation of Perl on DOS Type: make install This will copy the newly compiled perl and libraries into your DJGPP directory structure. Perl.exe and the utilities go into \"($DJDIR)\/bin\", and the library goes under \"($DJDIR)\/lib\/perl5\". The pod documentation goes under \"($DJDIR)\/lib\/perl5\/pod\".","Process Name":"perldos","Link":"https:\/\/linux.die.net\/man\/1\/perldos"}},{"Process":{"Description":"The single feature most sorely lacking in the Perl programming language prior to its 5.0 release was complex data structures. Even without direct language support, some valiant programmers did manage to emulate them, but it was hard work and not for the faint of heart. You could occasionally get away with the $m{$AoA,$b} notation borrowed from awk in which the keys are actually more like a single concatenated string \"$AoA$b\", but traversal and sorting were difficult. More desperate programmers even hacked Perl's internal symbol table directly, a strategy that proved hard to develop and maintain--to put it mildly. The 5.0 release of Perl let us have complex data structures. You may now write something like this and all of a sudden, you'd have an array with three dimensions! for $x (1 .. 10) {\n    for $y (1 .. 10) {\n        for $z (1 .. 10) {\n            $AoA[$x][$y][$z] =\n                $x ** $y + $z;\n        }\n    }\n} Alas, however simple this may appear, underneath it's a much more elaborate construct than meets the eye! How do you print it out? Why can't you say just \"print @AoA\"? How do you sort it? How can you pass it to a function or get one of these back from a function? Is it an object? Can you save it to disk to read back later? How do you access whole rows or columns of that matrix? Do all the values have to be numeric? As you see, it's quite easy to become confused. While some small portion of the blame for this can be attributed to the reference-based implementation, it's really more due to a lack of existing documentation with examples designed for the beginner. This document is meant to be a detailed but understandable treatment of the many different sorts of data structures you might want to develop. It should also serve as a cookbook of examples. That way, when you need to create one of these complex data structures, you can just pinch, pilfer, or purloin a drop-in example from here. Let's look at each of these possible constructs in detail. There are separate sections on each of the following: \u2022 arrays of arrays \u2022 hashes of arrays \u2022 arrays of hashes \u2022 hashes of hashes \u2022 more elaborate constructs But for now, let's look at general issues common to all these types of data structures.","Process Name":"perldsc","Link":"https:\/\/linux.die.net\/man\/1\/perldsc"}},{"Process":{"Description":"An exploration of some of the issues facing Perl programmers on EBCDIC based computers. We do not cover localization, internationalization, or multi byte character set issues other than some discussion of UTF-8 and UTF-EBCDIC. Portions that are still incomplete are marked with XXX .","Process Name":"perlebcdic","Link":"https:\/\/linux.die.net\/man\/1\/perlebcdic"}},{"Process":{"Description":"PREAMBLE Do you want to: Use C from Perl? Read perlxstut, perlxs, h2xs, perlguts, and perlapi. Use a Unix program from Perl? Read about back-quotes and about \"system\" and \"exec\" in perlfunc. Use Perl from Perl? Read about \"do\" in perlfunc and \"eval\" in perlfunc and \"require\" in perlfunc and \"use\" in perlfunc. Use C from C? Rethink your design. Use Perl from C? Read on... ROADMAP \u2022 Compiling your C program \u2022 Adding a Perl interpreter to your C program \u2022 Calling a Perl subroutine from your C program \u2022 Evaluating a Perl statement from your C program \u2022 Performing Perl pattern matches and substitutions from your C program \u2022 Fiddling with the Perl stack from your C program \u2022 Maintaining a persistent interpreter \u2022 Maintaining multiple interpreter instances \u2022 Using Perl modules, which themselves use C libraries, from your C program \u2022 Embedding Perl under Win32 Compiling your C program If you have trouble compiling the scripts in this documentation, you're not alone. The cardinal rule: COMPILE THE PROGRAMS IN EXACTLY THE SAME WAY THAT YOUR PERL WAS COMPILED . (Sorry for yelling.) Also, every C program that uses Perl must link in the perl library. What's that, you ask? Perl is itself written in C; the perl library is the collection of compiled C programs that were used to create your perl executable (\/usr\/bin\/perl or equivalent). (Corollary: you can't use Perl from your C program unless Perl has been compiled on your machine, or installed properly--that's why you shouldn't blithely copy Perl executables from machine to machine without also copying the lib directory.) When you use Perl from C, your C program will--usually--allocate, \"run\", and deallocate a PerlInterpreter object, which is defined by the perl library. If your copy of Perl is recent enough to contain this documentation (version 5.002 or later), then the perl library (and EXTERN .h and perl.h, which you'll also need) will reside in a directory that looks like this: \/usr\/local\/lib\/perl5\/your_architecture_here\/CORE or perhaps just \/usr\/local\/lib\/perl5\/CORE or maybe something like \/usr\/opt\/perl5\/CORE Execute this statement for a hint about where to find CORE: perl -MConfig -e 'print $Config{archlib}' Here's how you'd compile the example in the next section, \"Adding a Perl interpreter to your C program\", on my Linux box: % gcc -O2 -Dbool=char -DHAS_BOOL -I\/usr\/local\/include\n-I\/usr\/local\/lib\/perl5\/i586-linux\/5.003\/CORE\n-L\/usr\/local\/lib\/perl5\/i586-linux\/5.003\/CORE\n-o interp interp.c -lperl -lm (That's all one line.) On my DEC Alpha running old 5.003_05, the incantation is a bit different: % cc -O2 -Olimit 2900 -DSTANDARD_C -I\/usr\/local\/include\n-I\/usr\/local\/lib\/perl5\/alpha-dec_osf\/5.00305\/CORE\n-L\/usr\/local\/lib\/perl5\/alpha-dec_osf\/5.00305\/CORE -L\/usr\/local\/lib\n-D__LANGUAGE_C__ -D_NO_PROTO -o interp interp.c -lperl -lm How can you figure out what to add? Assuming your Perl is post-5.001, execute a \"perl -V\" command and pay special attention to the \"cc\" and \"ccflags\" information. You'll have to choose the appropriate compiler (cc, gcc, et al.) for your machine: \"perl -MConfig -e 'print $Config{cc}'\" will tell you what to use. You'll also have to choose the appropriate library directory (\/usr\/local\/lib\/...) for your machine. If your compiler complains that certain functions are undefined, or that it can't locate -lperl, then you need to change the path following the \"-L\". If it complains that it can't find EXTERN .h and perl.h, you need to change the path following the \"-I\". You may have to add extra libraries as well. Which ones? Perhaps those printed by perl -MConfig -e 'print $Config{libs}' Provided your perl binary was properly configured and installed the ExtUtils::Embed module will determine all of this information for you: % cc -o interp interp.c `perl -MExtUtils::Embed -e ccopts -e ldopts` If the ExtUtils::Embed module isn't part of your Perl distribution, you can retrieve it from http:\/\/www.perl.com\/perl\/CPAN\/modules\/by-module\/ExtUtils\/ (If this documentation came from your Perl distribution, then you're running 5.004 or better and you already have it.) The ExtUtils::Embed kit on CPAN also contains all source code for the examples in this document, tests, additional examples and other information you may find useful. Adding a Perl interpreter to your C program In a sense, perl (the C program) is a good example of embedding Perl (the language), so I'll demonstrate embedding with miniperlmain.c, included in the source distribution. Here's a bastardized, non-portable version of miniperlmain.c containing the essentials of embedding: #include <EXTERN.h>               \/* from the Perl distribution     *\/\n#include <perl.h>                 \/* from the Perl distribution     *\/\n\nstatic PerlInterpreter *my_perl;  \/***    The Perl interpreter    ***\/\n\nint main(int argc, char **argv, char **env)\n{\n    PERL_SYS_INIT3(&argc,&argv,&env);\n    my_perl = perl_alloc();\n    perl_construct(my_perl);\n    PL_exit_flags |= PERL_EXIT_DESTRUCT_END;\n    perl_parse(my_perl, NULL, argc, argv, (char **)NULL);\n    perl_run(my_perl);\n    perl_destruct(my_perl);\n    perl_free(my_perl);\n    PERL_SYS_TERM();\n} Notice that we don't use the \"env\" pointer. Normally handed to \"perl_parse\" as its final argument, \"env\" here is replaced by \"NULL\", which means that the current environment will be used. The macros PERL_SYS_INIT3 () and PERL_SYS_TERM () provide system-specific tune up of the C runtime environment necessary to run Perl interpreters; they should only be called once regardless of how many interpreters you create or destroy. Call PERL_SYS_INIT3 () before you create your first interpreter, and PERL_SYS_TERM () after you free your last interpreter. Since PERL_SYS_INIT3 () may change \"env\", it may be more appropriate to provide \"env\" as an argument to perl_parse(). Also notice that no matter what arguments you pass to perl_parse(), PERL_SYS_INIT3 () must be invoked on the C main() argc, argv and env and only once. Now compile this program (I'll call it interp.c) into an executable: % cc -o interp interp.c `perl -MExtUtils::Embed -e ccopts -e ldopts` After a successful compilation, you'll be able to use interp just like perl itself: % interp\nprint \"Pretty Good Perl \\n\";\nprint \"10890 - 9801 is \", 10890 - 9801;\n<CTRL-D>\nPretty Good Perl\n10890 - 9801 is 1089 or % interp -e 'printf(\"%x\", 3735928559)'\ndeadbeef You can also read and execute Perl statements from a file while in the midst of your C program, by placing the filename in argv[1] before calling perl_run. Calling a Perl subroutine from your C program To call individual Perl subroutines, you can use any of the call_* functions documented in perlcall. In this example we'll use \"call_argv\". That's shown below, in a program I'll call showtime.c. #include <EXTERN.h>\n#include <perl.h>\n\nstatic PerlInterpreter *my_perl;\n\nint main(int argc, char **argv, char **env)\n{\n    char *args[] = { NULL };\n    PERL_SYS_INIT3(&argc,&argv,&env);\n    my_perl = perl_alloc();\n    perl_construct(my_perl);\n\n    perl_parse(my_perl, NULL, argc, argv, NULL);\n    PL_exit_flags |= PERL_EXIT_DESTRUCT_END;\n\n    \/*** skipping perl_run() ***\/\n\n    call_argv(\"showtime\", G_DISCARD | G_NOARGS, args);\n\n    perl_destruct(my_perl);\n    perl_free(my_perl);\n    PERL_SYS_TERM();\n} where showtime is a Perl subroutine that takes no arguments (that's the G_NOARGS) and for which I'll ignore the return value (that's the G_DISCARD). Those flags, and others, are discussed in perlcall. I'll define the showtime subroutine in a file called showtime.pl: print \"I shan't be printed.\";\n\nsub showtime {\n    print time;\n} Simple enough. Now compile and run: % cc -o showtime showtime.c `perl -MExtUtils::Embed -e ccopts -e ldopts`\n\n% showtime showtime.pl\n818284590 yielding the number of seconds that elapsed between January 1, 1970 (the beginning of the Unix epoch), and the moment I began writing this sentence. In this particular case we don't have to call perl_run, as we set the PL_exit_flag PERL_EXIT_DESTRUCT_END which executes END blocks in perl_destruct. If you want to pass arguments to the Perl subroutine, you can add strings to the \"NULL\"-terminated \"args\" list passed to call_argv. For other data types, or to examine return values, you'll need to manipulate the Perl stack. That's demonstrated in \"Fiddling with the Perl stack from your C program\". Evaluating a Perl statement from your C program Perl provides two API functions to evaluate pieces of Perl code. These are \"eval_sv\" in perlapi and \"eval_pv\" in perlapi. Arguably, these are the only routines you'll ever need to execute snippets of Perl code from within your C program. Your code can be as long as you wish; it can contain multiple statements; it can employ \"use\" in perlfunc, \"require\" in perlfunc, and \"do\" in perlfunc to include external Perl files. eval_pv lets us evaluate individual Perl strings, and then extract variables for coercion into C types. The following program, string.c, executes three Perl strings, extracting an \"int\" from the first, a \"float\" from the second, and a \"char *\" from the third. #include <EXTERN.h>\n#include <perl.h>\n\nstatic PerlInterpreter *my_perl;\n\nmain (int argc, char **argv, char **env)\n{\n    char *embedding[] = { \"\", \"-e\", \"0\" };\n\n    PERL_SYS_INIT3(&argc,&argv,&env);\n    my_perl = perl_alloc();\n    perl_construct( my_perl );\n\n    perl_parse(my_perl, NULL, 3, embedding, NULL);\n    PL_exit_flags |= PERL_EXIT_DESTRUCT_END;\n    perl_run(my_perl);\n\n    \/** Treat $a as an integer **\/\n    eval_pv(\"$a = 3; $a **= 2\", TRUE);\n    printf(\"a = %d\\n\", SvIV(get_sv(\"a\", 0)));\n\n    \/** Treat $a as a float **\/\n    eval_pv(\"$a = 3.14; $a **= 2\", TRUE);\n    printf(\"a = %f\\n\", SvNV(get_sv(\"a\", 0)));\n\n    \/** Treat $a as a string **\/\n    eval_pv(\"$a = 'rekcaH lreP rehtonA tsuJ'; $a = reverse($a);\", TRUE);\n    printf(\"a = %s\\n\", SvPV_nolen(get_sv(\"a\", 0)));\n\n    perl_destruct(my_perl);\n    perl_free(my_perl);\n    PERL_SYS_TERM();\n} All of those strange functions with sv in their names help convert Perl scalars to C types. They're described in perlguts and perlapi. If you compile and run string.c, you'll see the results of using SvIV() to create an \"int\", SvNV() to create a \"float\", and SvPV() to create a string: a = 9\na = 9.859600\na = Just Another Perl Hacker In the example above, we've created a global variable to temporarily store the computed value of our eval'ed expression. It is also possible and in most cases a better strategy to fetch the return value from eval_pv() instead. Example: ...\nSV *val = eval_pv(\"reverse 'rekcaH lreP rehtonA tsuJ'\", TRUE);\nprintf(\"%s\\n\", SvPV_nolen(val));\n... This way, we avoid namespace pollution by not creating global variables and we've simplified our code as well. Performing Perl pattern matches and substitutions from your C program The eval_sv() function lets us evaluate strings of Perl code, so we can define some functions that use it to \"specialize\" in matches and substitutions: match(), substitute(), and matches(). I32 match(SV *string, char *pattern); Given a string and a pattern (e.g., \"m\/clasp\/\" or \"\/\\b\\w*\\b\/\", which in your C program might appear as \"\/\\\\b\\\\w*\\\\b\/\"), match() returns 1 if the string matches the pattern and 0 otherwise. int substitute(SV **string, char *pattern); Given a pointer to an \"SV\" and an \"=~\" operation (e.g., \"s\/bob\/robert\/g\" or \"tr[A-Z][a-z]\"), substitute() modifies the string within the \"SV\" as according to the operation, returning the number of substitutions made. int matches(SV *string, char *pattern, AV **matches); Given an \"SV\", a pattern, and a pointer to an empty \"AV\", matches() evaluates \"$string =~ $pattern\" in a list context, and fills in matches with the array elements, returning the number of matches found. Here's a sample program, match.c, that uses all three (long lines have been wrapped here): #include <EXTERN.h>\n#include <perl.h>\n\nstatic PerlInterpreter *my_perl;\n\n\/** my_eval_sv(code, error_check)\n** kinda like eval_sv(),\n** but we pop the return value off the stack\n**\/\nSV* my_eval_sv(SV *sv, I32 croak_on_error)\n{\n    dSP;\n    SV* retval;\n\n    PUSHMARK(SP);\n    eval_sv(sv, G_SCALAR);\n\n    SPAGAIN;\n    retval = POPs;\n    PUTBACK;\n\n    if (croak_on_error && SvTRUE(ERRSV))\n       croak(SvPVx_nolen(ERRSV));\n\n    return retval;\n}\n\n\/** match(string, pattern)\n**\n** Used for matches in a scalar context.\n**\n** Returns 1 if the match was successful; 0 otherwise.\n**\/\n\nI32 match(SV *string, char *pattern)\n{\n    SV *command = newSV(0), *retval;\n\n    sv_setpvf(command, \"my $string = '%s'; $string =~ %s\",\n             SvPV_nolen(string), pattern);\n\n    retval = my_eval_sv(command, TRUE);\n    SvREFCNT_dec(command);\n\n    return SvIV(retval);\n}\n\n\/** substitute(string, pattern)\n**\n** Used for =~ operations that modify their left-hand side (s\/\/\/ and tr\/\/\/)\n**\n** Returns the number of successful matches, and\n** modifies the input string if there were any.\n**\/\n\nI32 substitute(SV **string, char *pattern)\n{\n    SV *command = newSV(0), *retval;\n\n    sv_setpvf(command, \"$string = '%s'; ($string =~ %s)\",\n             SvPV_nolen(*string), pattern);\n\n    retval = my_eval_sv(command, TRUE);\n    SvREFCNT_dec(command);\n\n    *string = get_sv(\"string\", 0);\n    return SvIV(retval);\n}\n\n\/** matches(string, pattern, matches)\n**\n** Used for matches in a list context.\n**\n** Returns the number of matches,\n** and fills in **matches with the matching substrings\n**\/\n\nI32 matches(SV *string, char *pattern, AV **match_list)\n{\n    SV *command = newSV(0);\n    I32 num_matches;\n\n    sv_setpvf(command, \"my $string = '%s'; @array = ($string =~ %s)\",\n             SvPV_nolen(string), pattern);\n\n    my_eval_sv(command, TRUE);\n    SvREFCNT_dec(command);\n\n    *match_list = get_av(\"array\", 0);\n    num_matches = av_len(*match_list) + 1; \/** assume $[ is 0 **\/\n\n    return num_matches;\n}\n\nmain (int argc, char **argv, char **env)\n{\n    char *embedding[] = { \"\", \"-e\", \"0\" };\n    AV *match_list;\n    I32 num_matches, i;\n    SV *text;\n\n    PERL_SYS_INIT3(&argc,&argv,&env);\n    my_perl = perl_alloc();\n    perl_construct(my_perl);\n    perl_parse(my_perl, NULL, 3, embedding, NULL);\n    PL_exit_flags |= PERL_EXIT_DESTRUCT_END;\n\n    text = newSV(0);\n    sv_setpv(text, \"When he is at a convenience store and the \"\n       \"bill comes to some amount like 76 cents, Maynard is \"\n       \"aware that there is something he *should* do, something \"\n       \"that will enable him to get back a quarter, but he has \"\n       \"no idea *what*.  He fumbles through his red squeezey \"\n       \"changepurse and gives the boy three extra pennies with \"\n       \"his dollar, hoping that he might luck into the correct \"\n       \"amount.  The boy gives him back two of his own pennies \"\n       \"and then the big shiny quarter that is his prize. \"\n       \"-RICHH\");\n\n    if (match(text, \"m\/quarter\/\")) \/** Does text contain 'quarter'? **\/\n       printf(\"match: Text contains the word 'quarter'.\\n\\n\");\n    else\n       printf(\"match: Text doesn't contain the word 'quarter'.\\n\\n\");\n\n    if (match(text, \"m\/eighth\/\")) \/** Does text contain 'eighth'? **\/\n       printf(\"match: Text contains the word 'eighth'.\\n\\n\");\n    else\n       printf(\"match: Text doesn't contain the word 'eighth'.\\n\\n\");\n\n    \/** Match all occurrences of \/wi..\/ **\/\n    num_matches = matches(text, \"m\/(wi..)\/g\", &match_list);\n    printf(\"matches: m\/(wi..)\/g found %d matches...\\n\", num_matches);\n\n    for (i = 0; i < num_matches; i++)\n       printf(\"match: %s\\n\", SvPV_nolen(*av_fetch(match_list, i, FALSE)));\n    printf(\"\\n\");\n\n    \/** Remove all vowels from text **\/\n    num_matches = substitute(&text, \"s\/[aeiou]\/\/gi\");\n    if (num_matches) {\n       printf(\"substitute: s\/[aeiou]\/\/gi...%d substitutions made.\\n\",\n              num_matches);\n       printf(\"Now text is: %s\\n\\n\", SvPV_nolen(text));\n    }\n\n    \/** Attempt a substitution **\/\n    if (!substitute(&text, \"s\/Perl\/C\/\")) {\n       printf(\"substitute: s\/Perl\/C...No substitution made.\\n\\n\");\n    }\n\n    SvREFCNT_dec(text);\n    PL_perl_destruct_level = 1;\n    perl_destruct(my_perl);\n    perl_free(my_perl);\n    PERL_SYS_TERM();\n} which produces the output (again, long lines have been wrapped here) match: Text contains the word 'quarter'.\n\nmatch: Text doesn't contain the word 'eighth'.\n\nmatches: m\/(wi..)\/g found 2 matches...\nmatch: will\nmatch: with\n\nsubstitute: s\/[aeiou]\/\/gi...139 substitutions made.\nNow text is: Whn h s t  cnvnnc str nd th bll cms t sm mnt lk 76 cnts,\nMynrd s wr tht thr s smthng h *shld* d, smthng tht wll nbl hm t gt bck\nqrtr, bt h hs n d *wht*.  H fmbls thrgh hs rd sqzy chngprs nd gvs th by\nthr xtr pnns wth hs dllr, hpng tht h mght lck nt th crrct mnt.  Th by gvs\nhm bck tw f hs wn pnns nd thn th bg shny qrtr tht s hs prz. -RCHH\n\nsubstitute: s\/Perl\/C...No substitution made. Fiddling with the Perl stack from your C program When trying to explain stacks, most computer science textbooks mumble something about spring-loaded columns of cafeteria plates: the last thing you pushed on the stack is the first thing you pop off. That'll do for our purposes: your C program will push some arguments onto \"the Perl stack\", shut its eyes while some magic happens, and then pop the results--the return value of your Perl subroutine--off the stack. First you'll need to know how to convert between C types and Perl types, with newSViv() and sv_setnv() and newAV() and all their friends. They're described in perlguts and perlapi. Then you'll need to know how to manipulate the Perl stack. That's described in perlcall. Once you've understood those, embedding Perl in C is easy. Because C has no builtin function for integer exponentiation, let's make Perl's ** operator available to it (this is less useful than it sounds, because Perl implements ** with C's pow() function). First I'll create a stub exponentiation function in power.pl: sub expo {\n    my ($a, $b) = @_;\n    return $a ** $b;\n} Now I'll create a C program, power.c, with a function PerlPower() that contains all the perlguts necessary to push the two arguments into expo() and to pop the return value out. Take a deep breath... #include <EXTERN.h>\n#include <perl.h>\n\nstatic PerlInterpreter *my_perl;\n\nstatic void\nPerlPower(int a, int b)\n{\n  dSP;                            \/* initialize stack pointer      *\/\n  ENTER;                          \/* everything created after here *\/\n  SAVETMPS;                       \/* ...is a temporary variable.   *\/\n  PUSHMARK(SP);                   \/* remember the stack pointer    *\/\n  XPUSHs(sv_2mortal(newSViv(a))); \/* push the base onto the stack  *\/\n  XPUSHs(sv_2mortal(newSViv(b))); \/* push the exponent onto stack  *\/\n  PUTBACK;                      \/* make local stack pointer global *\/\n  call_pv(\"expo\", G_SCALAR);      \/* call the function             *\/\n  SPAGAIN;                        \/* refresh stack pointer         *\/\n                                \/* pop the return value from stack *\/\n  printf (\"%d to the %dth power is %d.\\n\", a, b, POPi);\n  PUTBACK;\n  FREETMPS;                       \/* free that return value        *\/\n  LEAVE;                       \/* ...and the XPUSHed \"mortal\" args.*\/\n}\n\nint main (int argc, char **argv, char **env)\n{\n  char *my_argv[] = { \"\", \"power.pl\" };\n\n  PERL_SYS_INIT3(&argc,&argv,&env);\n  my_perl = perl_alloc();\n  perl_construct( my_perl );\n\n  perl_parse(my_perl, NULL, 2, my_argv, (char **)NULL);\n  PL_exit_flags |= PERL_EXIT_DESTRUCT_END;\n  perl_run(my_perl);\n\n  PerlPower(3, 4);                      \/*** Compute 3 ** 4 ***\/\n\n  perl_destruct(my_perl);\n  perl_free(my_perl);\n  PERL_SYS_TERM();\n} Compile and run: % cc -o power power.c `perl -MExtUtils::Embed -e ccopts -e ldopts`\n\n% power\n3 to the 4th power is 81. Maintaining a persistent interpreter When developing interactive and\/or potentially long-running applications, it's a good idea to maintain a persistent interpreter rather than allocating and constructing a new interpreter multiple times. The major reason is speed: since Perl will only be loaded into memory once. However, you have to be more cautious with namespace and variable scoping when using a persistent interpreter. In previous examples we've been using global variables in the default package \"main\". We knew exactly what code would be run, and assumed we could avoid variable collisions and outrageous symbol table growth. Let's say your application is a server that will occasionally run Perl code from some arbitrary file. Your server has no way of knowing what code it's going to run. Very dangerous. If the file is pulled in by \"perl_parse()\", compiled into a newly constructed interpreter, and subsequently cleaned out with \"perl_destruct()\" afterwards, you're shielded from most namespace troubles. One way to avoid namespace collisions in this scenario is to translate the filename into a guaranteed-unique package name, and then compile the code into that package using \"eval\" in perlfunc. In the example below, each file will only be compiled once. Or, the application might choose to clean out the symbol table associated with the file after it's no longer needed. Using \"call_argv\" in perlapi, We'll call the subroutine \"Embed::Persistent::eval_file\" which lives in the file \"persistent.pl\" and pass the filename and boolean cleanup\/cache flag as arguments. Note that the process will continue to grow for each file that it uses. In addition, there might be \"AUTOLOAD\"ed subroutines and other conditions that cause Perl's symbol table to grow. You might want to add some logic that keeps track of the process size, or restarts itself after a certain number of requests, to ensure that memory consumption is minimized. You'll also want to scope your variables with \"my\" in perlfunc whenever possible. package Embed::Persistent;\n#persistent.pl\n\nuse strict;\nour %Cache;\nuse Symbol qw(delete_package);\n\nsub valid_package_name {\n    my($string) = @_;\n    $string =~ s\/([^A-Za-z0-9\\\/])\/sprintf(\"_%2x\",unpack(\"C\",$1))\/eg;\n    # second pass only for words starting with a digit\n    $string =~ s|\/(\\d)|sprintf(\"\/_%2x\",unpack(\"C\",$1))|eg;\n\n    # Dress it up as a real package name\n    $string =~ s|\/|::|g;\n    return \"Embed\" . $string;\n}\n\nsub eval_file {\n    my($filename, $delete) = @_;\n    my $package = valid_package_name($filename);\n    my $mtime = -M $filename;\n    if(defined $Cache{$package}{mtime}\n       &&\n       $Cache{$package}{mtime} <= $mtime)\n    {\n       # we have compiled this subroutine already,\n       # it has not been updated on disk, nothing left to do\n       print STDERR \"already compiled $package->handler\\n\";\n    }\n    else {\n       local *FH;\n       open FH, $filename or die \"open '$filename' $!\";\n       local($\/) = undef;\n       my $sub = <FH>;\n       close FH;\n\n       #wrap the code into a subroutine inside our unique package\n       my $eval = qq{package $package; sub handler { $sub; }};\n       {\n           # hide our variables within this block\n           my($filename,$mtime,$package,$sub);\n           eval $eval;\n       }\n       die $@ if $@;\n\n       #cache it unless we're cleaning out each time\n       $Cache{$package}{mtime} = $mtime unless $delete;\n    }\n\n    eval {$package->handler;};\n    die $@ if $@;\n\n    delete_package($package) if $delete;\n\n    #take a look if you want\n    #print Devel::Symdump->rnew($package)->as_string, $\/;\n}\n\n1;\n\n__END__\n\n\/* persistent.c *\/\n#include <EXTERN.h>\n#include <perl.h>\n\n\/* 1 = clean out filename's symbol table after each request, 0 = don't *\/\n#ifndef DO_CLEAN\n#define DO_CLEAN 0\n#endif\n\n#define BUFFER_SIZE 1024\n\nstatic PerlInterpreter *my_perl = NULL;\n\nint\nmain(int argc, char **argv, char **env)\n{\n    char *embedding[] = { \"\", \"persistent.pl\" };\n    char *args[] = { \"\", DO_CLEAN, NULL };\n    char filename[BUFFER_SIZE];\n    int exitstatus = 0;\n\n    PERL_SYS_INIT3(&argc,&argv,&env);\n    if((my_perl = perl_alloc()) == NULL) {\n       fprintf(stderr, \"no memory!\");\n       exit(1);\n    }\n    perl_construct(my_perl);\n\n    PL_origalen = 1; \/* don't let $0 assignment update the proctitle or embedding[0] *\/\n    exitstatus = perl_parse(my_perl, NULL, 2, embedding, NULL);\n    PL_exit_flags |= PERL_EXIT_DESTRUCT_END;\n    if(!exitstatus) {\n       exitstatus = perl_run(my_perl);\n\n       while(printf(\"Enter file name: \") &&\n             fgets(filename, BUFFER_SIZE, stdin)) {\n\n           filename[strlen(filename)-1] = '\\0'; \/* strip \\n *\/\n           \/* call the subroutine, passing it the filename as an argument *\/\n           args[0] = filename;\n           call_argv(\"Embed::Persistent::eval_file\",\n                          G_DISCARD | G_EVAL, args);\n\n           \/* check $@ *\/\n           if(SvTRUE(ERRSV))\n               fprintf(stderr, \"eval error: %s\\n\", SvPV_nolen(ERRSV));\n       }\n    }\n\n    PL_perl_destruct_level = 0;\n    perl_destruct(my_perl);\n    perl_free(my_perl);\n    PERL_SYS_TERM();\n    exit(exitstatus);\n} Now compile: % cc -o persistent persistent.c `perl -MExtUtils::Embed -e ccopts -e ldopts` Here's an example script file: #test.pl\nmy $string = \"hello\";\nfoo($string);\n\nsub foo {\n    print \"foo says: @_\\n\";\n} Now run: % persistent\nEnter file name: test.pl\nfoo says: hello\nEnter file name: test.pl\nalready compiled Embed::test_2epl->handler\nfoo says: hello\nEnter file name: ^C Execution of END blocks Traditionally END blocks have been executed at the end of the perl_run. This causes problems for applications that never call perl_run. Since perl 5.7.2 you can specify \"PL_exit_flags |= PERL_EXIT_DESTRUCT_END\" to get the new behaviour. This also enables the running of END blocks if the perl_parse fails and \"perl_destruct\" will return the exit value. $0 assignments When a perl script assigns a value to $0 then the perl runtime will try to make this value show up as the program name reported by \"ps\" by updating the memory pointed to by the argv passed to perl_parse() and also calling API functions like setproctitle() where available. This behaviour might not be appropriate when embedding perl and can be disabled by assigning the value 1 to the variable \"PL_origalen\" before perl_parse() is called. The persistent.c example above is for instance likely to segfault when $0 is assigned to if the \"PL_origalen = 1;\" assignment is removed. This because perl will try to write to the read only memory of the \"embedding[]\" strings. Maintaining multiple interpreter instances Some rare applications will need to create more than one interpreter during a session. Such an application might sporadically decide to release any resources associated with the interpreter. The program must take care to ensure that this takes place before the next interpreter is constructed. By default, when perl is not built with any special options, the global variable \"PL_perl_destruct_level\" is set to 0, since extra cleaning isn't usually needed when a program only ever creates a single interpreter in its entire lifetime. Setting \"PL_perl_destruct_level\" to 1 makes everything squeaky clean: while(1) {\n    ...\n    \/* reset global variables here with PL_perl_destruct_level = 1 *\/\n    PL_perl_destruct_level = 1;\n    perl_construct(my_perl);\n    ...\n    \/* clean and reset _everything_ during perl_destruct *\/\n    PL_perl_destruct_level = 1;\n    perl_destruct(my_perl);\n    perl_free(my_perl);\n    ...\n    \/* let's go do it again! *\/\n} When perl_destruct() is called, the interpreter's syntax parse tree and symbol tables are cleaned up, and global variables are reset. The second assignment to \"PL_perl_destruct_level\" is needed because perl_construct resets it to 0. Now suppose we have more than one interpreter instance running at the same time. This is feasible, but only if you used the Configure option \"-Dusemultiplicity\" or the options \"-Dusethreads -Duseithreads\" when building perl. By default, enabling one of these Configure options sets the per-interpreter global variable \"PL_perl_destruct_level\" to 1, so that thorough cleaning is automatic and interpreter variables are initialized correctly. Even if you don't intend to run two or more interpreters at the same time, but to run them sequentially, like in the above example, it is recommended to build perl with the \"-Dusemultiplicity\" option otherwise some interpreter variables may not be initialized correctly between consecutive runs and your application may crash. See also \"Thread-aware system interfaces\" in perlxs. Using \"-Dusethreads -Duseithreads\" rather than \"-Dusemultiplicity\" is more appropriate if you intend to run multiple interpreters concurrently in different threads, because it enables support for linking in the thread libraries of your system with the interpreter. Let's give it a try: #include <EXTERN.h>\n#include <perl.h>\n\n\/* we're going to embed two interpreters *\/\n\/* we're going to embed two interpreters *\/\n\n#define SAY_HELLO \"-e\", \"print qq(Hi, I'm $^X\\n)\"\n\nint main(int argc, char **argv, char **env)\n{\n    PerlInterpreter *one_perl, *two_perl;\n    char *one_args[] = { \"one_perl\", SAY_HELLO };\n    char *two_args[] = { \"two_perl\", SAY_HELLO };\n\n    PERL_SYS_INIT3(&argc,&argv,&env);\n    one_perl = perl_alloc();\n    two_perl = perl_alloc();\n\n    PERL_SET_CONTEXT(one_perl);\n    perl_construct(one_perl);\n    PERL_SET_CONTEXT(two_perl);\n    perl_construct(two_perl);\n\n    PERL_SET_CONTEXT(one_perl);\n    perl_parse(one_perl, NULL, 3, one_args, (char **)NULL);\n    PERL_SET_CONTEXT(two_perl);\n    perl_parse(two_perl, NULL, 3, two_args, (char **)NULL);\n\n    PERL_SET_CONTEXT(one_perl);\n    perl_run(one_perl);\n    PERL_SET_CONTEXT(two_perl);\n    perl_run(two_perl);\n\n    PERL_SET_CONTEXT(one_perl);\n    perl_destruct(one_perl);\n    PERL_SET_CONTEXT(two_perl);\n    perl_destruct(two_perl);\n\n    PERL_SET_CONTEXT(one_perl);\n    perl_free(one_perl);\n    PERL_SET_CONTEXT(two_perl);\n    perl_free(two_perl);\n    PERL_SYS_TERM();\n} Note the calls to PERL_SET_CONTEXT (). These are necessary to initialize the global state that tracks which interpreter is the \"current\" one on the particular process or thread that may be running it. It should always be used if you have more than one interpreter and are making perl API calls on both interpreters in an interleaved fashion. PERL_SET_CONTEXT (interp) should also be called whenever \"interp\" is used by a thread that did not create it (using either perl_alloc(), or the more esoteric perl_clone()). Compile as usual: % cc -o multiplicity multiplicity.c `perl -MExtUtils::Embed -e ccopts -e ldopts` Run it, Run it: % multiplicity\nHi, I'm one_perl\nHi, I'm two_perl Using Perl modules, which themselves use C libraries, from your C program If you've played with the examples above and tried to embed a script that use()s a Perl module (such as Socket) which itself uses a C or C ++ library, this probably happened: Can't load module Socket, dynamic loading not available in this perl.\n (You may need to build a new perl executable which either supports\n dynamic loading or has the Socket module statically linked into it.) What's wrong? Your interpreter doesn't know how to communicate with these extensions on its own. A little glue will help. Up until now you've been calling perl_parse(), handing it NULL for the second argument: perl_parse(my_perl, NULL, argc, my_argv, NULL); That's where the glue code can be inserted to create the initial contact between Perl and linked C\/C ++ routines. Let's take a look some pieces of perlmain.c to see how Perl does this: static void xs_init (pTHX);\n\nEXTERN_C void boot_DynaLoader (pTHX_ CV* cv);\nEXTERN_C void boot_Socket (pTHX_ CV* cv);\n\nEXTERN_C void\nxs_init(pTHX)\n{\n       char *file = __FILE__;\n       \/* DynaLoader is a special case *\/\n       newXS(\"DynaLoader::boot_DynaLoader\", boot_DynaLoader, file);\n       newXS(\"Socket::bootstrap\", boot_Socket, file);\n} Simply put: for each extension linked with your Perl executable (determined during its initial configuration on your computer or when adding a new extension), a Perl subroutine is created to incorporate the extension's routines. Normally, that subroutine is named Module::bootstrap() and is invoked when you say use Module. In turn, this hooks into an XSUB , boot_Module, which creates a Perl counterpart for each of the extension's XSUBs. Don't worry about this part; leave that to the xsubpp and extension authors. If your extension is dynamically loaded, DynaLoader creates Module::bootstrap() for you on the fly. In fact, if you have a working DynaLoader then there is rarely any need to link in any other extensions statically. Once you have this code, slap it into the second argument of perl_parse(): perl_parse(my_perl, xs_init, argc, my_argv, NULL); Then compile: % cc -o interp interp.c `perl -MExtUtils::Embed -e ccopts -e ldopts`\n\n% interp\n  use Socket;\n  use SomeDynamicallyLoadedModule;\n\n  print \"Now I can use extensions!\\n\"' ExtUtils::Embed can also automate writing the xs_init glue code. % perl -MExtUtils::Embed -e xsinit -- -o perlxsi.c\n% cc -c perlxsi.c `perl -MExtUtils::Embed -e ccopts`\n% cc -c interp.c  `perl -MExtUtils::Embed -e ccopts`\n% cc -o interp perlxsi.o interp.o `perl -MExtUtils::Embed -e ldopts` Consult perlxs, perlguts, and perlapi for more details.","Process Name":"perlembed","Link":"https:\/\/linux.die.net\/man\/1\/perlembed"}},{"Process":{"Description":"","Process Name":"perlepoc","Link":"https:\/\/linux.die.net\/man\/1\/perlepoc"}},{"Process":{"Description":"The perlfaq comprises several documents that answer the most commonly asked questions about Perl and Perl programming. It's divided by topic into nine major sections outlined in this document. Where to get the perlfaq The perlfaq comes with the standard Perl distribution, so if you have Perl you should have the perlfaq. You should also have the \"perldoc\" tool that lets you read the perlfaq: $ perldoc perlfaq Besides your local system, you can find the perlfaq on the web, including at http:\/\/perldoc.perl.org\/ . The perlfaq is an evolving document and you can read the latest version at http:\/\/faq.perl.org\/ . The perlfaq-workers periodically post extracts of the latest perlfaq to comp.lang.perl.misc. You can view the source tree at https:\/\/github.com\/briandfoy\/perlfaq (which is outside of the main Perl source tree). The git repository notes all changes to the FAQ and holds the latest version of the working documents and may vary significantly from the version distributed with the latest version of Perl. Check the repository before sending your corrections. How to contribute to the perlfaq You can mail corrections, additions, and suggestions to \"<perlfaq-workers AT perl DOT org>\". The perlfaq volunteers use this address to coordinate their efforts and track the perlfaq development. They appreciate your contributions to the FAQ but do not have time to provide individual help, so don't use this address to ask FAQs. The perlfaq server posts extracts of the perlfaq to that newsgroup every 6 hours (or so), and the community of volunteers reviews and updates the answers. If you'd like to help review and update the answers, check out comp.lang.perl.misc. You can also fork the git repository for the perlfaq and send a pull request so the main repository can pull your changes. The repository is at: https:\/\/github.com\/briandfoy\/perlfaq What will happen if you mail your Perl programming problems to the authors? The perlfaq-workers like to keep all traffic on the perlfaq-workers list so that everyone can see the work being done (and the work that needs to be done). The mailing list serves as an official record. If you email the authors or maintainers directly, you'll probably get a reply asking you to post to the mailing list. If you don't get a reply, it probably means that the person never saw the message or didn't have time to deal with it. Posting to the list allows the volunteers with time to deal with it when others are busy. If you have a question that isn't in the FAQ and you would like help with it, try the resources in perlfaq2.","Process Name":"perlfaq","Link":"https:\/\/linux.die.net\/man\/1\/perlfaq"}},{"Process":{"Description":"This section of the FAQ answers very general, high-level questions about Perl. What is Perl? Perl is a high-level programming language with an eclectic heritage written by Larry Wall and a cast of thousands. It derives from the ubiquitous C programming language and to a lesser extent from sed, awk, the Unix shell, and at least a dozen other tools and languages. Perl's process, file, and text manipulation facilities make it particularly well-suited for tasks involving quick prototyping, system utilities, software tools, system management tasks, database access, graphical programming, networking, and world wide web programming. These strengths make it especially popular with system administrators and CGI script authors, but mathematicians, geneticists, journalists, and even managers also use Perl. Maybe you should, too. Who supports Perl? Who develops it? Why is it free? The original culture of the pre-populist Internet and the deeply-held beliefs of Perl's author, Larry Wall, gave rise to the free and open distribution policy of perl. Perl is supported by its users. The core, the standard Perl library, the optional modules, and the documentation you're reading now were all written by volunteers. See the personal note at the end of the README file in the perl source distribution for more details. See perlhist (new as of 5.005) for Perl's milestone releases. In particular, the core development team (known as the Perl Porters) are a rag-tag band of highly altruistic individuals committed to producing better software for free than you could hope to purchase for money. You may snoop on pending developments via the archives at http:\/\/www.xray.mpe.mpg.de\/mailing-lists\/perl5-porters\/ and http:\/\/archive.develooper.com\/perl5-porters@perl.org\/ or the news gateway nntp:\/\/nntp.perl.org\/perl.perl5.porters or its web interface at http:\/\/nntp.perl.org\/group\/perl.perl5.porters , or read the faq at http:\/\/dev.perl.org\/perl5\/docs\/p5p-faq.html , or you can subscribe to the mailing list by sending perl5-porters-request@perl.org a subscription request (an empty message with no subject is fine). While the GNU project includes Perl in its distributions, there's no such thing as \" GNU Perl\". Perl is not produced nor maintained by the Free Software Foundation. Perl's licensing terms are also more open than GNU software's tend to be. You can get commercial support of Perl if you wish, although for most users the informal support will more than suffice. See the answer to \"Where can I buy a commercial version of perl?\" for more information. Which version of Perl should I use? (contributed by brian d foy) There is often a matter of opinion and taste, and there isn't any one answer that fits everyone. In general, you want to use either the current stable release, or the stable release immediately prior to that one. Currently, those are perl5.10.x and perl5.8.x, respectively. Beyond that, you have to consider several things and decide which is best for you. \u2022 If things aren't broken, upgrading perl may break them (or at least issue new warnings). \u2022 The latest versions of perl have more bug fixes. \u2022 The Perl community is geared toward supporting the most recent releases, so you'll have an easier time finding help for those. \u2022 Versions prior to perl5.004 had serious security problems with buffer overflows, and in some cases have CERT advisories (for instance, http:\/\/www.cert.org\/advisories\/CA-1997-17.html ). \u2022 The latest versions are probably the least deployed and widely tested, so you may want to wait a few months after their release and see what problems others have if you are risk averse. \u2022 The immediate, previous releases (i.e. perl5.8.x ) are usually maintained for a while, although not at the same level as the current releases. \u2022 No one is actively supporting Perl 4. Five years ago it was a dead camel carcass (according to this document). Now it's barely a skeleton as its whitewashed bones have fractured or eroded. \u2022 There is no Perl 6 release scheduled, but it will be available when it's ready. Stay tuned, but don't worry that you'll have to change major versions of Perl; no one is going to take Perl 5 away from you. \u2022 There are really two tracks of perl development: a maintenance version and an experimental version. The maintenance versions are stable, and have an even number as the minor release (i.e. perl5.10.x, where 10 is the minor release). The experimental versions may include features that don't make it into the stable versions, and have an odd number as the minor release (i.e. perl5.9.x, where 9 is the minor release). What are Perl 4, Perl 5, or Perl 6? (contributed by brian d foy) In short, Perl 4 is the past, Perl 5 is the present, and Perl 6 is the future. The number after perl (i.e. the 5 after Perl 5) is the major release of the perl interpreter as well as the version of the language. Each major version has significant differences that earlier versions cannot support. The current major release of Perl is Perl 5, and was released in 1994. It can run scripts from the previous major release, Perl 4 (March 1991), but has significant differences. It introduced the concept of references, complex data structures, and modules. The Perl 5 interpreter was a complete re-write of the previous perl sources. Perl 6 is the next major version of Perl, but it's still in development in both its syntax and design. The work started in 2002 and is still ongoing. Many of the most interesting features have shown up in the latest versions of Perl 5, and some Perl 5 modules allow you to use some Perl 6 syntax in your programs. You can learn more about Perl 6 at http:\/\/dev.perl.org\/perl6\/ . See perlhist for a history of Perl revisions. What was Ponie? (contributed by brian d foy) Ponie stands for \"Perl On the New Internal Engine\", started by Arthur Bergman from Fotango in 2003, and subsequently run as a project of The Perl Foundation. It was abandoned in 2006 ( http:\/\/www.nntp.perl.org\/group\/perl.ponie.dev\/487 ). Instead of using the current Perl internals, Ponie aimed to create a new one that would provide a translation path from Perl 5 to Perl 6 (or anything else that targets Parrot, actually). You would have been able to just keep using Perl 5 with Parrot, the virtual machine which will compile and run Perl 6 bytecode. What is Perl 6? At The Second O'Reilly Open Source Software Convention, Larry Wall announced Perl 6 development would begin in earnest. Perl 6 was an oft used term for Chip Salzenberg's project to rewrite Perl in C ++ named Topaz. However, Topaz provided valuable insights to the next version of Perl and its implementation, but was ultimately abandoned. If you want to learn more about Perl 6, or have a desire to help in the crusade to make Perl a better place then peruse the Perl 6 developers page at http:\/\/dev.perl.org\/perl6\/ and get involved. Perl 6 is not scheduled for release yet, and Perl 5 will still be supported for quite awhile after its release. Do not wait for Perl 6 to do whatever you need to do. \"We're really serious about reinventing everything that needs reinventing.\" --Larry Wall How stable is Perl? Production releases, which incorporate bug fixes and new functionality, are widely tested before release. Since the 5.000 release, we have averaged only about one production release per year. Larry and the Perl development team occasionally make changes to the internal core of the language, but all possible efforts are made toward backward compatibility. While not quite all Perl 4 scripts run flawlessly under Perl 5, an update to perl should nearly never invalidate a program written for an earlier version of perl (barring accidental bug fixes and the rare new keyword). Is Perl difficult to learn? No, Perl is easy to start learning--and easy to keep learning. It looks like most programming languages you're likely to have experience with, so if you've ever written a C program, an awk script, a shell script, or even a BASIC program, you're already partway there. Most tasks only require a small subset of the Perl language. One of the guiding mottos for Perl development is \"there's more than one way to do it\" ( TMTOWTDI , sometimes pronounced \"tim toady\"). Perl's learning curve is therefore shallow (easy to learn) and long (there's a whole lot you can do if you really want). Finally, because Perl is frequently (but not always, and certainly not by definition) an interpreted language, you can write your programs and test them without an intermediate compilation step, allowing you to experiment and test\/debug quickly and easily. This ease of experimentation flattens the learning curve even more. Things that make Perl easier to learn: Unix experience, almost any kind of programming experience, an understanding of regular expressions, and the ability to understand other people's code. If there's something you need to do, then it's probably already been done, and a working example is usually available for free. Don't forget Perl modules, either. They're discussed in Part 3 of this FAQ , along with CPAN , which is discussed in Part 2. How does Perl compare with other languages like Java, Python, REXX , Scheme, or Tcl? Favorably in some areas, unfavorably in others. Precisely which areas are good and bad is often a personal choice, so asking this question on Usenet runs a strong risk of starting an unproductive Holy War. Probably the best thing to do is try to write equivalent code to do a set of tasks. These languages have their own newsgroups in which you can learn about (but hopefully not argue about) them. Some comparison documents can be found at http:\/\/www.perl.com\/doc\/FMTEYEWTK\/versus\/ if you really can't stop yourself. Can I do [task] in Perl? Perl is flexible and extensible enough for you to use on virtually any task, from one-line file-processing tasks to large, elaborate systems. For many people, Perl serves as a great replacement for shell scripting. For others, it serves as a convenient, high-level replacement for most of what they'd program in low-level languages like C or C ++ . It's ultimately up to you (and possibly your management) which tasks you'll use Perl for and which you won't. If you have a library that provides an API , you can make any component of it available as just another Perl function or variable using a Perl extension written in C or C ++ and dynamically linked into your main perl interpreter. You can also go the other direction, and write your main program in C or C ++ , and then link in some Perl code on the fly, to create a powerful application. See perlembed. That said, there will always be small, focused, special-purpose languages dedicated to a specific problem domain that are simply more convenient for certain kinds of problems. Perl tries to be all things to all people, but nothing special to anyone. Examples of specialized languages that come to mind include prolog and matlab. When shouldn't I program in Perl? When your manager forbids it--but do consider replacing them :-). Actually, one good reason is when you already have an existing application written in another language that's all done (and done well), or you have an application language specifically designed for a certain task (e.g. prolog, make). For various reasons, Perl is probably not well-suited for real-time embedded systems, low-level operating systems development work like device drivers or context-switching code, complex multi-threaded shared-memory applications, or extremely large applications. You'll notice that perl is not itself written in Perl. Perl remains fundamentally a dynamically typed language, not a statically typed one. You certainly won't be chastised if you don't trust nuclear-plant or brain-surgery monitoring code to it. And Larry will sleep easier, too--Wall Street programs not withstanding. :-) What's the difference between \"perl\" and \"Perl\"? One bit. Oh, you weren't talking ASCII ? :-) Larry now uses \"Perl\" to signify the language proper and \"perl\" the implementation of it, i.e. the current interpreter. Hence Tom's quip that \"Nothing but perl can parse Perl.\" Before the first edition of Programming perl, people commonly referred to the language as \"perl\", and its name appeared that way in the title because it referred to the interpreter. In the book, Randal Schwartz capitalised the language's name to make it stand out better when typeset. This convention was adopted by the community, and the second edition became Programming Perl, using the capitalized version of the name to refer to the language. You may or may not choose to follow this usage. For example, parallelism means \"awk and perl\" and \"Python and Perl\" look good, while \"awk and Perl\" and \"Python and perl\" do not. But never write \" PERL \", because perl is not an acronym, apocryphal folklore and post-facto expansions notwithstanding. Is it a Perl program or a Perl script? Larry doesn't really care. He says (half in jest) that \"a script is what you give the actors. A program is what you give the audience.\" Originally, a script was a canned sequence of normally interactive commands--that is, a chat script. Something like a UUCP or PPP chat script or an expect script fits the bill nicely, as do configuration scripts run by a program at its start up, such .cshrc or .ircrc, for example. Chat scripts were just drivers for existing programs, not stand-alone programs in their own right. A computer scientist will correctly explain that all programs are interpreted and that the only question is at what level. But if you ask this question of someone who isn't a computer scientist, they might tell you that a program has been compiled to physical machine code once and can then be run multiple times, whereas a script must be translated by a program each time it's used. Now that \"script\" and \"scripting\" are terms that have been seized by unscrupulous or unknowing marketeers for their own nefarious purposes, they have begun to take on strange and often pejorative meanings, like \"non serious\" or \"not real programming\". Consequently, some Perl programmers prefer to avoid them altogether. What is a JAPH ? (contributed by brian d foy) JAPH stands for \"Just another Perl hacker,\", which Randal Schwartz used to sign email and usenet messages starting in the late 1980s. He previously used the phrase with many subjects (\"Just another x hacker,\"), so to distinguish his JAPH , he started to write them as Perl programs: print \"Just another Perl hacker,\"; Other people picked up on this and started to write clever or obfuscated programs to produce the same output, spinning things quickly out of control while still providing hours of amusement for their creators and readers. CPAN has several JAPH programs at http:\/\/www.cpan.org\/misc\/japh . Where can I get a list of Larry Wall witticisms? (contributed by brian d foy) Google \"larry wall quotes\"! You might even try the \"I feel lucky\" button. :) Wikiquote has the witticisms from Larry along with their source, including his usenet postings and source code comments. If you want a plain text file, try http:\/\/www.cpan.org\/misc\/lwall-quotes.txt.gz . How can I convince others to use Perl? (contributed by brian d foy) Appeal to their self interest! If Perl is new (and thus scary) to them, find something that Perl can do to solve one of their problems. That might mean that Perl either saves them something (time, headaches, money) or gives them something (flexibility, power, testability). In general, the benefit of a language is closely related to the skill of the people using that language. If you or your team can be more faster, better, and stronger through Perl, you'll deliver more value. Remember, people often respond better to what they get out of it. If you run into resistance, figure out what those people get out of the other choice and how Perl might satisfy that requirement. You don't have to worry about finding or paying for Perl; it's freely available and several popular operating systems come with Perl. Community support in places such as Perlmonks ( http:\/\/www.perlmonks.com ) and the various Perl mailing lists ( http:\/\/lists.perl.org ) means that you can usually get quick answers to your problems. Finally, keep in mind that Perl might not be the right tool for every job. You're a much better advocate if your claims are reasonable and grounded in reality. Dogmatically advocating anything tends to make people discount your message. Be honest about possible disadvantages to your choice of Perl since any choice has trade-offs. You might find these links useful: \u2022 http:\/\/perltraining.com.au\/whyperl.html \u2022 http:\/\/www.perl.org\/advocacy\/whyperl.html","Process Name":"perlfaq1","Link":"https:\/\/linux.die.net\/man\/1\/perlfaq1"}},{"Process":{"Description":"This section of the FAQ answers questions about where to find source and documentation for Perl, support, and related matters. What machines support perl? Where do I get it? The standard release of perl (the one maintained by the perl development team) is distributed only in source code form. You can find the latest releases at http:\/\/www.cpan.org\/src\/README.html . Perl builds and runs on a bewildering number of platforms. Virtually all known and current Unix derivatives are supported (perl's native platform), as are other systems like VMS , DOS , OS\/2 , Windows, QNX , BeOS, OS X, MPE\/iX and the Amiga. Binary distributions for some proprietary platforms can be found http:\/\/www.cpan.org\/ports\/ directory. Because these are not part of the standard distribution, they may and in fact do differ from the base perl port in a variety of ways. You'll have to check their respective release notes to see just what the differences are. These differences can be either positive (e.g. extensions for the features of the particular platform that are not supported in the source release of perl) or negative (e.g. might be based upon a less current source release of perl). How can I get a binary version of perl? (contributed by brian d foy) ActiveState: Windows, Linux, Mac OS X, Solaris, AIX and HP-UX http:\/\/www.activestate.com\/ Sunfreeware.com: Solaris 2.5 to Solaris 10 ( SPARC and x86) http:\/\/www.sunfreeware.com\/ Strawberry Perl: Windows, Perl 5.8.8 and 5.10.0 http:\/\/www.strawberryperl.com IndigoPerl: Windows http:\/\/indigostar.com\/ I don't have a C compiler. How can I build my own Perl interpreter? Since you don't have a C compiler, you're doomed and your vendor should be sacrificed to the Sun gods. But that doesn't help you. What you need to do is get a binary version of gcc for your system first. Consult the Usenet FAQs for your operating system for information on where to get such a binary version. You might look around the net for a pre-built binary of Perl (or a C compiler!) that meets your needs, though: For Windows, Vanilla Perl ( http:\/\/vanillaperl.com\/ ) and Strawberry Perl ( http:\/\/strawberryperl.com\/ ) come with a bundled C compiler. ActivePerl is a pre-compiled version of Perl ready-to-use. For Sun systems, SunFreeware.com provides binaries of most popular applications, including compilers and Perl. I copied the perl binary from one machine to another, but scripts don't work. That's probably because you forgot libraries, or library paths differ. You really should build the whole distribution on the machine it will eventually live on, and then type \"make install\". Most other approaches are doomed to failure. One simple way to check that things are in the right place is to print out the hard-coded @INC that perl looks through for libraries: % perl -le 'print for @INC' If this command lists any paths that don't exist on your system, then you may need to move the appropriate libraries to these locations, or create symbolic links, aliases, or shortcuts appropriately. @INC is also printed as part of the output of % perl -V You might also want to check out \"How do I keep my own module\/library directory?\" in perlfaq8. I grabbed the sources and tried to compile but gdbm\/dynamic loading\/malloc\/linking\/... failed. How do I make it work? Read the INSTALL file, which is part of the source distribution. It describes in detail how to cope with most idiosyncrasies that the Configure script can't work around for any given system or architecture. What modules and extensions are available for Perl? What is CPAN ? What does CPAN\/src\/... mean? CPAN stands for Comprehensive Perl Archive Network, a multi-gigabyte archive replicated on hundreds of machines all over the world. CPAN contains source code, non-native ports, documentation, scripts, and many third-party modules and extensions, designed for everything from commercial database interfaces to keyboard\/screen control to web walking and CGI scripts. The master web site for CPAN is http:\/\/www.cpan.org\/ and there is the CPAN Multiplexer at http:\/\/www.cpan.org\/CPAN.html which will choose a mirror near you via DNS . See http:\/\/www.perl.com\/CPAN (without a slash at the end) for how this process works. Also, http:\/\/mirror.cpan.org\/ has a nice interface to the http:\/\/www.cpan.org\/MIRRORED.BY mirror directory. See the CPAN FAQ at http:\/\/www.cpan.org\/misc\/cpan-faq.html for answers to the most frequently asked questions about CPAN including how to become a mirror. CPAN\/path\/... is a naming convention for files available on CPAN sites. CPAN indicates the base directory of a CPAN mirror, and the rest of the path is the path from that directory to the file. For instance, if you're using ftp:\/\/ftp.funet.fi\/pub\/languages\/perl\/CPAN as your CPAN site, the file CPAN\/misc\/japh is downloadable as ftp:\/\/ftp.funet.fi\/pub\/languages\/perl\/CPAN\/misc\/japh . Considering that, as of 2006, there are over ten thousand existing modules in the archive, one probably exists to do nearly anything you can think of. Current categories under CPAN\/modules\/by-category\/ include Perl core modules; development support; operating system interfaces; networking, devices, and interprocess communication; data type utilities; database interfaces; user interfaces; interfaces to other languages; filenames, file systems, and file locking; internationalization and locale; world wide web support; server and daemon utilities; archiving and compression; image manipulation; mail and news; control flow utilities; filehandle and I\/O; Microsoft Windows modules; and miscellaneous modules. See http:\/\/www.cpan.org\/modules\/00modlist.long.html or http:\/\/search.cpan.org\/ for a more complete list of modules by category. CPAN is a free service and is not affiliated with O'Reilly Media. Is there an ISO or ANSI certified version of Perl? Certainly not. Larry expects that he'll be certified before Perl is. Where can I get information on Perl? The complete Perl documentation is available with the Perl distribution. If you have Perl installed locally, you probably have the documentation installed as well: type \"man perl\" if you're on a system resembling Unix. This will lead you to other important man pages, including how to set your $MANPATH. If you're not on a Unix system, access to the documentation will be different; for example, documentation might only be in HTML format. All proper perl installations have fully-accessible documentation. You might also try \"perldoc perl\" in case your system doesn't have a proper man command, or it's been misinstalled. If that doesn't work, try looking in \/usr\/local\/lib\/perl5\/pod for documentation. If all else fails, consult http:\/\/perldoc.perl.org\/ which has the complete documentation in HTML and PDF format. Many good books have been written about Perl--see the section later in perlfaq2 for more details. Tutorial documents are included in current or upcoming Perl releases include perltoot for objects or perlboot for a beginner's approach to objects, perlopentut for file opening semantics, perlreftut for managing references, perlretut for regular expressions, perlthrtut for threads, perldebtut for debugging, and perlxstut for linking C and Perl together. There may be more by the time you read this. These URLs might also be useful: http:\/\/perldoc.perl.org\/\nhttp:\/\/bookmarks.cpan.org\/search.cgi?cat=Training%2FTutorials What are the Perl newsgroups on Usenet? Where do I post questions? Several groups devoted to the Perl language are on Usenet: comp.lang.perl.announce      Moderated announcement group\ncomp.lang.perl.misc          High traffic general Perl discussion\ncomp.lang.perl.moderated     Moderated discussion group\ncomp.lang.perl.modules       Use and development of Perl modules\ncomp.lang.perl.tk            Using Tk (and X) from Perl Some years ago, comp.lang.perl was divided into those groups, and comp.lang.perl itself officially removed. While that group may still be found on some news servers, it is unwise to use it, because postings there will not appear on news servers which honour the official list of group names. Use comp.lang.perl.misc for topics which do not have a more-appropriate specific group. There is also a Usenet gateway to Perl mailing lists sponsored by perl.org at nntp:\/\/nntp.perl.org , a web interface to the same lists at http:\/\/nntp.perl.org\/group\/ and these lists are also available under the \"perl.*\" hierarchy at http:\/\/groups.google.com . Other groups are listed at http:\/\/lists.perl.org\/ ( also known as http:\/\/lists.cpan.org\/ ). A nice place to ask questions is the PerlMonks site, http:\/\/www.perlmonks.org\/ , or the Perl Beginners mailing list http:\/\/lists.perl.org\/showlist.cgi?name=beginners . Note that none of the above are supposed to write your code for you: asking questions about particular problems or general advice is fine, but asking someone to write your code for free is not very cool. Where should I post source code? You should post source code to whichever group is most appropriate, but feel free to cross-post to comp.lang.perl.misc. If you want to cross-post to alt.sources, please make sure it follows their posting standards, including setting the Followup-To header line to NOT include alt.sources; see their FAQ ( http:\/\/www.faqs.org\/faqs\/alt-sources-intro\/ ) for details. If you're just looking for software, first use Google ( http:\/\/www.google.com ), Google's usenet search interface ( http:\/\/groups.google.com ), and CPAN Search ( http:\/\/search.cpan.org ). This is faster and more productive than just posting a request. Perl Books A number of books on Perl and\/or CGI programming are available. A few of these are good, some are OK , but many aren't worth your money. There is a list of these books, some with extensive reviews, at http:\/\/books.perl.org\/ . If you don't see your book listed here, you can write to perlfaq-workers@perl.org . The incontestably definitive reference book on Perl, written by the creator of Perl, is Programming Perl: Programming Perl (the \"Camel Book\"):\nby Larry Wall, Tom Christiansen, and Jon Orwant\nISBN 0-596-00027-8  [3rd edition July 2000]\nhttp:\/\/www.oreilly.com\/catalog\/pperl3\/\n(English, translations to several languages are also available) The companion volume to the Camel containing thousands of real-world examples, mini-tutorials, and complete programs is: The Perl Cookbook (the \"Ram Book\"):\nby Tom Christiansen and Nathan Torkington,\n    with Foreword by Larry Wall\nISBN 0-596-00313-7 [2nd Edition August 2003]\nhttp:\/\/www.oreilly.com\/catalog\/perlckbk2\/ If you're already a seasoned programmer, then the Camel Book might suffice for you to learn Perl. If you're not, check out the Llama book: Learning Perl\nby Randal L. Schwartz, Tom Phoenix, and brian d foy\nISBN 0-596-10105-8 [4th edition July 2005]\nhttp:\/\/www.oreilly.com\/catalog\/learnperl4\/ And for more advanced information on writing larger programs, presented in the same style as the Llama book, continue your education with the Alpaca book: Intermediate Perl (the \"Alpaca Book\")\nby Randal L. Schwartz and brian d foy, with Tom Phoenix (foreword by Damian Conway)\nISBN 0-596-10206-2 [1st edition March 2006]\nhttp:\/\/www.oreilly.com\/catalog\/lrnperlorm\/ Addison-Wesley ( http:\/\/www.awlonline.com\/ ) and Manning ( http:\/\/www.manning.com\/ ) are also publishers of some fine Perl books such as Object Oriented Programming with Perl by Damian Conway and Network Programming with Perl by Lincoln Stein. An excellent technical book discounter is Bookpool at http:\/\/www.bookpool.com\/ where a 30% discount or more is not unusual. What follows is a list of the books that the FAQ authors found personally useful. Your mileage may (but, we hope, probably won't) vary. Recommended books on (or mostly on) Perl follow. References Programming Perl\nby Larry Wall, Tom Christiansen, and Jon Orwant\nISBN 0-596-00027-8 [3rd edition July 2000]\nhttp:\/\/www.oreilly.com\/catalog\/pperl3\/\n\nPerl 5 Pocket Reference\nby Johan Vromans\nISBN 0-596-00374-9 [4th edition July 2002]\nhttp:\/\/www.oreilly.com\/catalog\/perlpr4\/ Tutorials Beginning Perl\nby James Lee\nISBN 1-59059-391-X [2nd edition August 2004]\nhttp:\/\/apress.com\/book\/bookDisplay.html?bID=344\n\nElements of Programming with Perl\nby Andrew L. Johnson\nISBN 1-884777-80-5 [1st edition October 1999]\nhttp:\/\/www.manning.com\/johnson\/\n\nLearning Perl\nby Randal L. Schwartz, Tom Phoenix, and brian d foy\nISBN 0-596-52010-7 [5th edition June 2008]\nhttp:\/\/oreilly.com\/catalog\/9780596520106\/\n\nIntermediate Perl (the \"Alpaca Book\")\nby Randal L. Schwartz and brian d foy, with Tom Phoenix (foreword by Damian Conway)\nISBN 0-596-10206-2 [1st edition March 2006]\nhttp:\/\/www.oreilly.com\/catalog\/intermediateperl\/\n\nMastering Perl\nby brian d foy\nISBN 0-596-52724-1 [1st edition July 2007]\nhttp:\/\/www.oreilly.com\/catalog\/9780596527242\/ Task-Oriented Writing Perl Modules for CPAN\nby Sam Tregar\nISBN 1-59059-018-X [1st edition Aug 2002]\nhttp:\/\/apress.com\/book\/bookDisplay.html?bID=14\n\nThe Perl Cookbook\nby Tom Christiansen and Nathan Torkington\n    with foreword by Larry Wall\nISBN 1-56592-243-3 [1st edition August 1998]\nhttp:\/\/www.oreilly.com\/catalog\/cookbook\/\n\nEffective Perl Programming\nby Joseph Hall\nISBN 0-201-41975-0 [1st edition 1998]\nhttp:\/\/www.awl.com\/\n\nReal World SQL Server Administration with Perl\nby Linchi Shea\nISBN 1-59059-097-X [1st edition July 2003]\nhttp:\/\/apress.com\/book\/bookDisplay.html?bID=171 Special Topics Perl Best Practices\nby Damian Conway\nISBN: 0-596-00173-8 [1st edition July 2005]\nhttp:\/\/www.oreilly.com\/catalog\/perlbp\/\n\nHigher Order Perl\nby Mark-Jason Dominus\nISBN: 1558607013 [1st edition March 2005]\nhttp:\/\/hop.perl.plover.com\/\n\nPerl 6 Now: The Core Ideas Illustrated with Perl 5\nby Scott Walters\nISBN 1-59059-395-2 [1st edition December 2004]\nhttp:\/\/apress.com\/book\/bookDisplay.html?bID=355\n\nMastering Regular Expressions\nby Jeffrey E. F. Friedl\nISBN 0-596-00289-0 [2nd edition July 2002]\nhttp:\/\/www.oreilly.com\/catalog\/regex2\/\n\nNetwork Programming with Perl\nby Lincoln Stein\nISBN 0-201-61571-1 [1st edition 2001]\nhttp:\/\/www.awlonline.com\/\n\nObject Oriented Perl\nDamian Conway\n    with foreword by Randal L. Schwartz\nISBN 1-884777-79-1 [1st edition August 1999]\nhttp:\/\/www.manning.com\/conway\/\n\nData Munging with Perl\nDave Cross\nISBN 1-930110-00-6 [1st edition 2001]\nhttp:\/\/www.manning.com\/cross\n\nMastering Perl\/Tk\nby Steve Lidie and Nancy Walsh\nISBN 1-56592-716-8 [1st edition January 2002]\nhttp:\/\/www.oreilly.com\/catalog\/mastperltk\/\n\nExtending and Embedding Perl\nby Tim Jenness and Simon Cozens\nISBN 1-930110-82-0 [1st edition August 2002]\nhttp:\/\/www.manning.com\/jenness\n\nPerl Debugger Pocket Reference\nby Richard Foley\nISBN 0-596-00503-2 [1st edition January 2004]\nhttp:\/\/www.oreilly.com\/catalog\/perldebugpr\/\n\nPro Perl Debugging\nby Richard Foley with Andy Lester\nISBN 1-59059-454-1 [1st edition July 2005]\nhttp:\/\/www.apress.com\/book\/view\/1590594541 Which magazines have Perl content? The Perl Review ( http:\/\/www.theperlreview.com ) focuses on Perl almost completely (although it sometimes sneaks in an article about another language). There's also $foo Magazin, a german magazine dedicated to Perl, at ( http:\/\/www.foo-magazin.de ). Magazines that frequently carry quality articles on Perl include The Perl Review ( http:\/\/www.theperlreview.com ), Unix Review ( http:\/\/www.unixreview.com\/ ), Linux Magazine ( http:\/\/www.linuxmagazine.com\/ ), and Usenix's newsletter\/magazine to its members, login: ( http:\/\/www.usenix.org\/ ) The Perl columns of Randal L. Schwartz are available on the web at http:\/\/www.stonehenge.com\/merlyn\/WebTechniques\/ , http:\/\/www.stonehenge.com\/merlyn\/UnixReview\/ , and http:\/\/www.stonehenge.com\/merlyn\/LinuxMag\/ . The first (and for a long time, only) periodical devoted to All Things Perl, The Perl Journal contains tutorials, demonstrations, case studies, announcements, contests, and much more. TPJ has columns on web development, databases, Win32 Perl, graphical programming, regular expressions, and networking, and sponsors the Obfuscated Perl Contest and the Perl Poetry Contests. Beginning in November 2002, TPJ moved to a reader-supported monthly e-zine format in which subscribers can download issues as PDF documents. In 2006, TPJ merged with Dr. Dobbs Journal (online edition). To read old TPJ articles, see http:\/\/www.ddj.com\/ . What mailing lists are there for Perl? Most of the major modules (Tk, CGI , libwww-perl) have their own mailing lists. Consult the documentation that came with the module for subscription information. A comprehensive list of Perl related mailing lists can be found at: http:\/\/lists.perl.org\/ Where are the archives for comp.lang.perl.misc? The Google search engine now carries archived and searchable newsgroup content. http:\/\/groups.google.com\/group\/comp.lang.perl.misc\/topics If you have a question, you can be sure someone has already asked the same question at some point on c.l.p.m. It requires some time and patience to sift through all the content but often you will find the answer you seek. Where can I buy a commercial version of perl? In a real sense, perl already is commercial software: it has a license that you can grab and carefully read to your manager. It is distributed in releases and comes in well-defined packages. There is a very large user community and an extensive literature. The comp.lang.perl.* newsgroups and several of the mailing lists provide free answers to your questions in near real-time. Perl has traditionally been supported by Larry, scores of software designers and developers, and myriad programmers, all working for free to create a useful thing to make life better for everyone. However, these answers may not suffice for managers who require a purchase order from a company whom they can sue should anything go awry. Or maybe they need very serious hand-holding and contractual obligations. Shrink-wrapped CDs with perl on them are available from several sources if that will help. For example, many Perl books include a distribution of perl, as do the O'Reilly Perl Resource Kits (in both the Unix flavor and in the proprietary Microsoft flavor); the free Unix distributions also all come with perl. Where do I send bug reports? (contributed by brian d foy) First, ensure that you've found an actual bug. Second, ensure you've found an actual bug. If you've found a bug with the perl interpreter or one of the modules in the standard library (those that come with Perl), you can use the \"perlbug\" utility that comes with Perl (>= 5.004). It collects information about your installation to include with your message, then sends the message to the right place. To determine if a module came with your version of Perl, you can use the \"Module::CoreList\" module. It has the information about the modules (with their versions) included with each release of Perl. Every CPAN module has a bug tracker set up in RT , http:\/\/rt.cpan.org . You can submit bugs to RT either through its web interface or by email. To email a bug report, send it to bug-<distribution-name>@rt.cpan.org . For example, if you wanted to report a bug in \"Business::ISBN\", you could send a message to bug-Business-ISBN@rt.cpan.org . Some modules might have special reporting requirements, such as a Sourceforge or Google Code tracking system, so you should check the module documentation too. What is perl.com? Perl Mongers? pm.org? perl.org? cpan.org? Perl.com at http:\/\/www.perl.com\/ is part of the O'Reilly Network, a subsidiary of O'Reilly Media. The Perl Foundation is an advocacy organization for the Perl language which maintains the web site http:\/\/www.perl.org\/ as a general advocacy site for the Perl language. It uses the domain to provide general support services to the Perl community, including the hosting of mailing lists, web sites, and other services. There are also many other sub-domains for special topics like learning Perl, Perl news, jobs in Perl, such as: http:\/\/learn.perl.org\/\nhttp:\/\/use.perl.org\/\nhttp:\/\/jobs.perl.org\/\nhttp:\/\/lists.perl.org\/ Perl Mongers uses the pm.org domain for services related to Perl user groups, including the hosting of mailing lists and web sites. See the Perl user group web site at http:\/\/www.pm.org\/ for more information about joining, starting, or requesting services for a Perl user group. http:\/\/www.cpan.org\/ is the Comprehensive Perl Archive Network, a replicated worldwide repository of Perl software, see the What is CPAN ? question earlier in this document.","Process Name":"perlfaq2","Link":"https:\/\/linux.die.net\/man\/1\/perlfaq2"}},{"Process":{"Description":"This section of the FAQ answers questions related to programmer tools and programming support. How do I do (anything)? Have you looked at CPAN (see perlfaq2)? The chances are that someone has already written a module that can solve your problem. Have you read the appropriate manpages? Here's a brief index: Basics          perldata, perlvar, perlsyn, perlop, perlsub\nExecution       perlrun, perldebug\nFunctions       perlfunc\nObjects         perlref, perlmod, perlobj, perltie\nData Structures perlref, perllol, perldsc\nModules         perlmod, perlmodlib, perlsub\nRegexes         perlre, perlfunc, perlop, perllocale\nMoving to perl5 perltrap, perl\nLinking w\/C     perlxstut, perlxs, perlcall, perlguts, perlembed\nVarious         http:\/\/www.cpan.org\/misc\/olddoc\/FMTEYEWTK.tgz\n                (not a man-page but still useful, a collection\n                 of various essays on Perl techniques) A crude table of contents for the Perl manpage set is found in perltoc. How can I use Perl interactively? The typical approach uses the Perl debugger, described in the perldebug(1) manpage, on an \"empty\" program, like this: perl -de 42 Now just type in any legal Perl code, and it will be immediately evaluated. You can also examine the symbol table, get stack backtraces, check variable values, set breakpoints, and other operations typically found in symbolic debuggers. Is there a Perl shell? The psh (Perl sh) is currently at version 1.8. The Perl Shell is a shell that combines the interactive nature of a Unix shell with the power of Perl. The goal is a full featured shell that behaves as expected for normal shell activity and uses Perl syntax and functionality for control-flow statements and other things. You can get psh at http:\/\/sourceforge.net\/projects\/psh\/ . Zoidberg is a similar project and provides a shell written in perl, configured in perl and operated in perl. It is intended as a login shell and development environment. It can be found at http:\/\/pardus-larus.student.utwente.nl\/~pardus\/projects\/zoidberg\/ or your local CPAN mirror. The Shell.pm module (distributed with Perl) makes Perl try commands which aren't part of the Perl language as shell commands. perlsh from the source distribution is simplistic and uninteresting, but may still be what you want. How do I find which modules are installed on my system? From the command line, you can use the \"cpan\" command's \"-l\" switch: $ cpan -l You can also use \"cpan\"'s \"-a\" switch to create an autobundle file that \"CPAN.pm\" understands and cna use to re-install every module: $ cpan -a Inside a Perl program, you can use the ExtUtils::Installed module to show all installed distributions, although it can take awhile to do its magic. The standard library which comes with Perl just shows up as \"Perl\" (although you can get those with Module::CoreList). use ExtUtils::Installed;\n\nmy $inst    = ExtUtils::Installed->new();\nmy @modules = $inst->modules(); If you want a list of all of the Perl module filenames, you can use File::Find::Rule. use File::Find::Rule;\n\nmy @files = File::Find::Rule->\n        extras({follow => 1})->\n        file()->\n        name( '*.pm' )->\n        in( @INC )\n        ; If you do not have that module, you can do the same thing with File::Find which is part of the standard library. use File::Find;\nmy @files;\n\nfind(\n    {\n        wanted => sub {\n            push @files, $File::Find::fullname\n                if -f $File::Find::fullname && \/\\.pm$\/\n        },\n        follow => 1,\n        follow_skip => 2,\n    },\n    @INC\n);\n\nprint join \"\\n\", @files; If you simply need to quickly check to see if a module is available, you can check for its documentation. If you can read the documentation the module is most likely installed. If you cannot read the documentation, the module might not have any (in rare cases). $ perldoc Module::Name You can also try to include the module in a one-liner to see if perl finds it. $ perl -MModule::Name -e1 How do I debug my Perl programs? (contributed by brian d foy) Before you do anything else, you can help yourself by ensuring that you let Perl tell you about problem areas in your code. By turning on warnings and strictures, you can head off many problems before they get too big. You can find out more about these in strict and warnings. #!\/usr\/bin\/perl\nuse strict;\nuse warnings; Beyond that, the simplest debugger is the \"print\" function. Use it to look at values as you run your program: print STDERR \"The value is [$value]\\n\"; The \"Data::Dumper\" module can pretty-print Perl data structures: use Data::Dumper qw( Dumper );\nprint STDERR \"The hash is \" . Dumper( \\%hash ) . \"\\n\"; Perl comes with an interactive debugger, which you can start with the \"-d\" switch. It's fully explained in perldebug. If you'd like a graphical user interface and you have Tk, you can use \"ptkdb\". It's on CPAN and available for free. If you need something much more sophisticated and controllable, Leon Brocard's Devel::ebug (which you can call with the -D switch as -Debug) gives you the programmatic hooks into everything you need to write your own (without too much pain and suffering). You can also use a commercial debugger such as Affrus (Mac OS X), Komodo from Activestate (Windows and Mac OS X), or EPIC (most platforms). How do I profile my Perl programs? (contributed by brian d foy, updated Fri Jul 25 12:22:26 PDT 2008) The \"Devel\" namespace has several modules which you can use to profile your Perl programs. The \"Devel::DProf\" module comes with Perl and you can invoke it with the \"-d\" switch: perl -d:DProf program.pl After running your program under \"DProf\", you'll get a tmon.out file with the profile data. To look at the data, you can turn it into a human-readable report with the \"dprofpp\" program that comes with \"Devel::DProf\". dprofpp You can also do the profiling and reporting in one step with the \"-p\" switch to <dprofpp>: dprofpp -p program.pl The \"Devel::NYTProf\" (New York Times Profiler) does both statement and subroutine profiling. It's available from CPAN and you also invoke it with the \"-d\" switch: perl -d:NYTProf some_perl.pl Like \"DProf\", it creates a database of the profile information that you can turn into reports. The \"nytprofhtml\" command turns the data into an HTML report similar to the \"Devel::Cover\" report: nytprofhtml CPAN has several other profilers that you can invoke in the same fashion. You might also be interested in using the \"Benchmark\" to measure and compare code snippets. You can read more about profiling in Programming Perl, chapter 20, or Mastering Perl, chapter 5. perldebguts documents creating a custom debugger if you need to create a special sort of profiler. brian d foy describes the process in The Perl Journal, \"Creating a Perl Debugger\", http:\/\/www.ddj.com\/184404522 , and \"Profiling in Perl\" http:\/\/www.ddj.com\/184404580 . Perl.com has two interesting articles on profiling: \"Profiling Perl\", by Simon Cozens, http:\/\/www.perl.com\/lpt\/a\/850 and \"Debugging and Profiling mod_perl Applications\", by Frank Wiles, http:\/\/www.perl.com\/pub\/a\/2006\/02\/09\/debug_mod_perl.html . Randal L. Schwartz writes about profiling in \"Speeding up Your Perl Programs\" for Unix Review, http:\/\/www.stonehenge.com\/merlyn\/UnixReview\/col49.html , and \"Profiling in Template Toolkit via Overriding\" for Linux Magazine, http:\/\/www.stonehenge.com\/merlyn\/LinuxMag\/col75.html . How do I cross-reference my Perl programs? The B::Xref module can be used to generate cross-reference reports for Perl programs. perl -MO=Xref[,OPTIONS] scriptname.plx Is there a pretty-printer (formatter) for Perl? Perltidy is a Perl script which indents and reformats Perl scripts to make them easier to read by trying to follow the rules of the perlstyle. If you write Perl scripts, or spend much time reading them, you will probably find it useful. It is available at http:\/\/perltidy.sourceforge.net Of course, if you simply follow the guidelines in perlstyle, you shouldn't need to reformat. The habit of formatting your code as you write it will help prevent bugs. Your editor can and should help you with this. The perl-mode or newer cperl-mode for emacs can provide remarkable amounts of help with most (but not all) code, and even less programmable editors can provide significant assistance. Tom Christiansen and many other VI users swear by the following settings in vi and its clones: set ai sw=4\nmap! ^O {^M}^[O^T Put that in your .exrc file (replacing the caret characters with control characters) and away you go. In insert mode, ^T is for indenting, ^D is for undenting, and ^O is for blockdenting--as it were. A more complete example, with comments, can be found at http:\/\/www.cpan.org\/authors\/id\/TOMC\/scripts\/toms.exrc.gz The a2ps http:\/\/www-inf.enst.fr\/%7Edemaille\/a2ps\/black+white.ps.gz does lots of things related to generating nicely printed output of documents. Is there a ctags for Perl? (contributed by brian d foy) Ctags uses an index to quickly find things in source code, and many popular editors support ctags for several different languages, including Perl. Exuberent ctags supports Perl: http:\/\/ctags.sourceforge.net\/ You might also try pltags: http:\/\/www.mscha.com\/pltags.zip Is there an IDE or Windows Perl Editor? Perl programs are just plain text, so any editor will do. If you're on Unix, you already have an IDE--Unix itself. The UNIX philosophy is the philosophy of several small tools that each do one thing and do it well. It's like a carpenter's toolbox. If you want an IDE , check the following (in alphabetical order, not order of preference): Eclipse http:\/\/e-p-i-c.sf.net\/ The Eclipse Perl Integration Project integrates Perl editing\/debugging with Eclipse. Enginsite http:\/\/www.enginsite.com\/ Perl Editor by EngInSite is a complete integrated development environment ( IDE ) for creating, testing, and debugging Perl scripts; the tool runs on Windows 9x\/NT\/2000\/XP or later. Komodo http:\/\/www.ActiveState.com\/Products\/Komodo\/ ActiveState's cross-platform (as of October 2004, that's Windows, Linux, and Solaris), multi-language IDE has Perl support, including a regular expression debugger and remote debugging. Open Perl IDE http:\/\/open-perl-ide.sourceforge.net\/ Open Perl IDE is an integrated development environment for writing and debugging Perl scripts with ActiveState's ActivePerl distribution under Windows 95\/98\/NT\/2000. OptiPerl http:\/\/www.optiperl.com\/ OptiPerl is a Windows IDE with simulated CGI environment, including debugger and syntax highlighting editor. Padre http:\/\/padre.perlide.org\/ Padre is cross-platform IDE for Perl written in Perl using the the wxWidgets to provide a native look and feel. It's open source under the Artistic License. PerlBuilder http:\/\/www.solutionsoft.com\/perl.htm PerlBuilder is an integrated development environment for Windows that supports Perl development. visiPerl+ http:\/\/helpconsulting.net\/visiperl\/ From Help Consulting, for Windows. Visual Perl http:\/\/www.activestate.com\/Products\/Visual_Perl\/ Visual Perl is a Visual Studio.NET plug-in from ActiveState. Zeus http:\/\/www.zeusedit.com\/lookmain.html Zeus for Window is another Win32 multi-language editor\/IDE that comes with support for Perl: For editors: if you're on Unix you probably have vi or a vi clone already, and possibly an emacs too, so you may not need to download anything. In any emacs the cperl-mode (M-x cperl-mode) gives you perhaps the best available Perl editing mode in any editor. If you are using Windows, you can use any editor that lets you work with plain text, such as NotePad or WordPad. Word processors, such as Microsoft Word or WordPerfect, typically do not work since they insert all sorts of behind-the-scenes information, although some allow you to save files as \"Text Only\". You can also download text editors designed specifically for programming, such as Textpad ( http:\/\/www.textpad.com\/ ) and UltraEdit ( http:\/\/www.ultraedit.com\/ ), among others. If you are using MacOS, the same concerns apply. MacPerl (for Classic environments) comes with a simple editor. Popular external editors are BBEdit ( http:\/\/www.bbedit.com\/ ) or Alpha ( http:\/\/www.his.com\/~jguyer\/Alpha\/Alpha8.html ). MacOS X users can use Unix editors as well. GNU Emacs http:\/\/www.gnu.org\/software\/emacs\/windows\/ntemacs.html MicroEMACS http:\/\/www.microemacs.de\/ XEmacs http:\/\/www.xemacs.org\/Download\/index.html Jed http:\/\/space.mit.edu\/~davis\/jed\/ or a vi clone such as Elvis ftp:\/\/ftp.cs.pdx.edu\/pub\/elvis\/ http:\/\/www.fh-wedel.de\/elvis\/ Vile http:\/\/dickey.his.com\/vile\/vile.html Vim http:\/\/www.vim.org\/ For vi lovers in general, Windows or elsewhere: http:\/\/www.thomer.com\/thomer\/vi\/vi.html nvi ( http:\/\/www.bostic.com\/vi\/ , available from CPAN in src\/misc\/) is yet another vi clone, unfortunately not available for Windows, but in UNIX platforms you might be interested in trying it out, firstly because strictly speaking it is not a vi clone, it is the real vi, or the new incarnation of it, and secondly because you can embed Perl inside it to use Perl as the scripting language. nvi is not alone in this, though: at least also vim and vile offer an embedded Perl. The following are Win32 multilanguage editor\/IDEs that support Perl: Codewright http:\/\/www.borland.com\/codewright\/ MultiEdit http:\/\/www.MultiEdit.com\/ SlickEdit http:\/\/www.slickedit.com\/ ConTEXT http:\/\/www.contexteditor.org\/ There is also a toyedit Text widget based editor written in Perl that is distributed with the Tk module on CPAN . The ptkdb ( http:\/\/ptkdb.sourceforge.net\/ ) is a Perl\/tk based debugger that acts as a development environment of sorts. Perl Composer ( http:\/\/perlcomposer.sourceforge.net\/ ) is an IDE for Perl\/Tk GUI creation. In addition to an editor\/IDE you might be interested in a more powerful shell environment for Win32. Your options include Bash from the Cygwin package ( http:\/\/sources.redhat.com\/cygwin\/ ) Ksh from the MKS Toolkit ( http:\/\/www.mkssoftware.com\/ ), or the Bourne shell of the U\/WIN environment ( http:\/\/www.research.att.com\/sw\/tools\/uwin\/ ) Tcsh ftp:\/\/ftp.astron.com\/pub\/tcsh\/ , see also http:\/\/www.primate.wisc.edu\/software\/csh-tcsh-book\/ Zsh http:\/\/www.zsh.org\/ MKS and U\/WIN are commercial (U\/WIN is free for educational and research purposes), Cygwin is covered by the GNU General Public License (but that shouldn't matter for Perl use). The Cygwin, MKS , and U\/WIN all contain (in addition to the shells) a comprehensive set of standard UNIX toolkit utilities. If you're transferring text files between Unix and Windows using FTP be sure to transfer them in ASCII mode so the ends of lines are appropriately converted. On Mac OS the MacPerl Application comes with a simple 32k text editor that behaves like a rudimentary IDE . In contrast to the MacPerl Application the MPW Perl tool can make use of the MPW Shell itself as an editor (with no 32k limit). Affrus is a full Perl development environment with full debugger support ( http:\/\/www.latenightsw.com ). Alpha is an editor, written and extensible in Tcl, that nonetheless has built in support for several popular markup and programming languages including Perl and HTML ( http:\/\/www.his.com\/~jguyer\/Alpha\/Alpha8.html ). BBEdit and BBEdit Lite are text editors for Mac OS that have a Perl sensitivity mode ( http:\/\/web.barebones.com\/ ). Where can I get Perl macros for vi? For a complete version of Tom Christiansen's vi configuration file, see http:\/\/www.cpan.org\/authors\/Tom_Christiansen\/scripts\/toms.exrc.gz , the standard benchmark file for vi emulators. The file runs best with nvi, the current version of vi out of Berkeley, which incidentally can be built with an embedded Perl interpreter--see http:\/\/www.cpan.org\/src\/misc\/ . Where can I get perl-mode for emacs? Since Emacs version 19 patchlevel 22 or so, there have been both a perl-mode.el and support for the Perl debugger built in. These should come with the standard Emacs 19 distribution. In the Perl source directory, you'll find a directory called \"emacs\", which contains a cperl-mode that color-codes keywords, provides context-sensitive help, and other nifty things. Note that the perl-mode of emacs will have fits with \"main'foo\" (single quote), and mess up the indentation and highlighting. You are probably using \"main::foo\" in new Perl code anyway, so this shouldn't be an issue. How can I use curses with Perl? The Curses module from CPAN provides a dynamically loadable object module interface to a curses library. A small demo can be found at the directory http:\/\/www.cpan.org\/authors\/Tom_Christiansen\/scripts\/rep.gz ; this program repeats a command and updates the screen as needed, rendering rep ps axu similar to top. How can I write a GUI (X, Tk, Gtk, etc.) in Perl? (contributed by Ben Morrow) There are a number of modules which let you write GUIs in Perl. Most GUI toolkits have a perl interface: an incomplete list follows. Tk This works under Unix and Windows, and the current version doesn't look half as bad under Windows as it used to. Some of the gui elements still don't 'feel' quite right, though. The interface is very natural and 'perlish', making it easy to use in small scripts that just need a simple gui. It hasn't been updated in a while. Wx This is a Perl binding for the cross-platform wxWidgets toolkit ( http:\/\/www.wxwidgets.org ). It works under Unix, Win32 and Mac OS X, using native widgets (Gtk under Unix). The interface follows the C ++ interface closely, but the documentation is a little sparse for someone who doesn't know the library, mostly just referring you to the C ++ documentation. Gtk and Gtk2 These are Perl bindings for the Gtk toolkit ( http:\/\/www.gtk.org ). The interface changed significantly between versions 1 and 2 so they have separate Perl modules. It runs under Unix, Win32 and Mac OS X (currently it requires an X server on Mac OS , but a 'native' port is underway), and the widgets look the same on every plaform: i.e., they don't match the native widgets. As with Wx, the Perl bindings follow the C API closely, and the documentation requires you to read the C documentation to understand it. Win32::GUI This provides access to most of the Win32 GUI widgets from Perl. Obviously, it only runs under Win32, and uses native widgets. The Perl interface doesn't really follow the C interface: it's been made more Perlish, and the documentation is pretty good. More advanced stuff may require familiarity with the C Win32 APIs, or reference to MSDN . CamelBones CamelBones ( http:\/\/camelbones.sourceforge.net ) is a Perl interface to Mac OS X's Cocoa GUI toolkit, and as such can be used to produce native GUIs on Mac OS X. It's not on CPAN , as it requires frameworks that CPAN .pm doesn't know how to install, but installation is via the standard OSX package installer. The Perl API is, again, very close to the ObjC API it's wrapping, and the documentation just tells you how to translate from one to the other. Qt There is a Perl interface to TrollTech's Qt toolkit, but it does not appear to be maintained. Athena Sx is an interface to the Athena widget set which comes with X, but again it appears not to be much used nowadays. How can I make my Perl program run faster? The best way to do this is to come up with a better algorithm. This can often make a dramatic difference. Jon Bentley's book Programming Pearls (that's not a misspelling!) has some good tips on optimization, too. Advice on benchmarking boils down to: benchmark and profile to make sure you're optimizing the right part, look for better algorithms instead of microtuning your code, and when all else fails consider just buying faster hardware. You will probably want to read the answer to the earlier question \"How do I profile my Perl programs?\" if you haven't done so already. A different approach is to autoload seldom-used Perl code. See the AutoSplit and AutoLoader modules in the standard distribution for that. Or you could locate the bottleneck and think about writing just that part in C, the way we used to take bottlenecks in C code and write them in assembler. Similar to rewriting in C, modules that have critical sections can be written in C (for instance, the PDL module from CPAN ). If you're currently linking your perl executable to a shared libc.so, you can often gain a 10-25% performance benefit by rebuilding it to link with a static libc.a instead. This will make a bigger perl executable, but your Perl programs (and programmers) may thank you for it. See the INSTALL file in the source distribution for more information. The undump program was an ancient attempt to speed up Perl program by storing the already-compiled form to disk. This is no longer a viable option, as it only worked on a few architectures, and wasn't a good solution anyway. How can I make my Perl program take less memory? When it comes to time-space tradeoffs, Perl nearly always prefers to throw memory at a problem. Scalars in Perl use more memory than strings in C, arrays take more than that, and hashes use even more. While there's still a lot to be done, recent releases have been addressing these issues. For example, as of 5.004, duplicate hash keys are shared amongst all hashes using them, so require no reallocation. In some cases, using substr() or vec() to simulate arrays can be highly beneficial. For example, an array of a thousand booleans will take at least 20,000 bytes of space, but it can be turned into one 125-byte bit vector--a considerable memory savings. The standard Tie::SubstrHash module can also help for certain types of data structure. If you're working with specialist data structures (matrices, for instance) modules that implement these in C may use less memory than equivalent Perl modules. Another thing to try is learning whether your Perl was compiled with the system malloc or with Perl's builtin malloc. Whichever one it is, try using the other one and see whether this makes a difference. Information about malloc is in the INSTALL file in the source distribution. You can find out whether you are using perl's malloc by typing \"perl -V:usemymalloc\". Of course, the best way to save memory is to not do anything to waste it in the first place. Good programming practices can go a long way toward this: \u2022 Don't slurp! Don't read an entire file into memory if you can process it line by line. Or more concretely, use a loop like this: #\n# Good Idea\n#\nwhile (<FILE>) {\n   # ...\n} instead of this: #\n# Bad Idea\n#\n@data = <FILE>;\nforeach (@data) {\n    # ...\n} When the files you're processing are small, it doesn't much matter which way you do it, but it makes a huge difference when they start getting larger. \u2022 Use map and grep selectively Remember that both map and grep expect a LIST argument, so doing this: @wanted = grep {\/pattern\/} <FILE>; will cause the entire file to be slurped. For large files, it's better to loop: while (<FILE>) {\n        push(@wanted, $_) if \/pattern\/;\n} \u2022 Avoid unnecessary quotes and stringification Don't quote large strings unless absolutely necessary: my $copy = \"$large_string\"; makes 2 copies of $large_string (one for $copy and another for the quotes), whereas my $copy = $large_string; only makes one copy. Ditto for stringifying large arrays: {\n        local $, = \"\\n\";\n        print @big_array;\n} is much more memory-efficient than either print join \"\\n\", @big_array; or {\n        local $\" = \"\\n\";\n        print \"@big_array\";\n} \u2022 Pass by reference Pass arrays and hashes by reference, not by value. For one thing, it's the only way to pass multiple lists or hashes (or both) in a single call\/return. It also avoids creating a copy of all the contents. This requires some judgement, however, because any changes will be propagated back to the original data. If you really want to mangle (er, modify) a copy, you'll have to sacrifice the memory needed to make one. \u2022 Tie large variables to disk. For \"big\" data stores (i.e. ones that exceed available memory) consider using one of the DB modules to store it on disk instead of in RAM . This will incur a penalty in access time, but that's probably better than causing your hard disk to thrash due to massive swapping. Is it safe to return a reference to local or lexical data? Yes. Perl's garbage collection system takes care of this so everything works out right. sub makeone {\n    my @a = ( 1 .. 10 );\n    return \\@a;\n}\n\nfor ( 1 .. 10 ) {\n    push @many, makeone();\n}\n\nprint $many[4][5], \"\\n\";\n\nprint \"@many\\n\"; How can I free an array or hash so my program shrinks? (contributed by Michael Carman) You usually can't. Memory allocated to lexicals (i.e. my() variables) cannot be reclaimed or reused even if they go out of scope. It is reserved in case the variables come back into scope. Memory allocated to global variables can be reused (within your program) by using undef() and\/or delete(). On most operating systems, memory allocated to a program can never be returned to the system. That's why long-running programs sometimes re- exec themselves. Some operating systems (notably, systems that use mmap(2) for allocating large chunks of memory) can reclaim memory that is no longer used, but on such systems, perl must be configured and compiled to use the OS 's malloc, not perl's. In general, memory allocation and de-allocation isn't something you can or should be worrying about much in Perl. See also \"How can I make my Perl program take less memory?\" How can I make my CGI script more efficient? Beyond the normal measures described to make general Perl programs faster or smaller, a CGI program has additional issues. It may be run several times per second. Given that each time it runs it will need to be re-compiled and will often allocate a megabyte or more of system memory, this can be a killer. Compiling into C isn't going to help you because the process start-up overhead is where the bottleneck is. There are two popular ways to avoid this overhead. One solution involves running the Apache HTTP server (available from http:\/\/www.apache.org\/ ) with either of the mod_perl or mod_fastcgi plugin modules. With mod_perl and the Apache::Registry module (distributed with mod_perl), httpd will run with an embedded Perl interpreter which pre-compiles your script and then executes it within the same address space without forking. The Apache extension also gives Perl access to the internal server API , so modules written in Perl can do just about anything a module written in C can. For more on mod_perl, see http:\/\/perl.apache.org\/ With the FCGI module (from CPAN ) and the mod_fastcgi module (available from http:\/\/www.fastcgi.com\/ ) each of your Perl programs becomes a permanent CGI daemon process. Both of these solutions can have far-reaching effects on your system and on the way you write your CGI programs, so investigate them with care. See http:\/\/www.cpan.org\/modules\/by-category\/15_World_Wide_Web_HTML_HTTP_CGI\/ . How can I hide the source for my Perl program? Delete it. :-) Seriously, there are a number of (mostly unsatisfactory) solutions with varying levels of \"security\". First of all, however, you can't take away read permission, because the source code has to be readable in order to be compiled and interpreted. (That doesn't mean that a CGI script's source is readable by people on the web, though--only by people with access to the filesystem.) So you have to leave the permissions at the socially friendly 0755 level. Some people regard this as a security problem. If your program does insecure things and relies on people not knowing how to exploit those insecurities, it is not secure. It is often possible for someone to determine the insecure things and exploit them without viewing the source. Security through obscurity, the name for hiding your bugs instead of fixing them, is little security indeed. You can try using encryption via source filters (Starting from Perl 5.8 the Filter::Simple and Filter::Util::Call modules are included in the standard distribution), but any decent programmer will be able to decrypt it. You can try using the byte code compiler and interpreter described later in perlfaq3, but the curious might still be able to de-compile it. You can try using the native-code compiler described later, but crackers might be able to disassemble it. These pose varying degrees of difficulty to people wanting to get at your code, but none can definitively conceal it (true of every language, not just Perl). It is very easy to recover the source of Perl programs. You simply feed the program to the perl interpreter and use the modules in the B:: hierarchy. The B::Deparse module should be able to defeat most attempts to hide source. Again, this is not unique to Perl. If you're concerned about people profiting from your code, then the bottom line is that nothing but a restrictive license will give you legal security. License your software and pepper it with threatening statements like \"This is unpublished proprietary software of XYZ Corp. Your access to it does not give you permission to use it blah blah blah.\" We are not lawyers, of course, so you should see a lawyer if you want to be sure your license's wording will stand up in court. How can I compile my Perl program into byte code or C? (contributed by brian d foy) In general, you can't do this. There are some things that may work for your situation though. People usually ask this question because they want to distribute their works without giving away the source code, and most solutions trade disk space for convenience. You probably won't see much of a speed increase either, since most solutions simply bundle a Perl interpreter in the final product (but see \"How can I make my Perl program run faster?\"). The Perl Archive Toolkit ( http:\/\/par.perl.org\/ ) is Perl's analog to Java's JAR . It's freely available and on CPAN ( http:\/\/search.cpan.org\/dist\/PAR\/ ). There are also some commercial products that may work for you, although you have to buy a license for them. The Perl Dev Kit ( http:\/\/www.activestate.com\/Products\/Perl_Dev_Kit\/ ) from ActiveState can \"Turn your Perl programs into ready-to-run executables for HP-UX, Linux, Solaris and Windows.\" Perl2Exe ( http:\/\/www.indigostar.com\/perl2exe.htm ) is a command line program for converting perl scripts to executable files. It targets both Windows and unix platforms. How can I get \"#!perl\" to work on [ MS-DOS ,NT,...]? For OS\/2 just use extproc perl -S -your_switches as the first line in \"*.cmd\" file ( \"-S\" due to a bug in cmd.exe's \"extproc\" handling). For DOS one should first invent a corresponding batch file and codify it in \"ALTERNATE_SHEBANG\" (see the dosish.h file in the source distribution for more information). The Win95\/NT installation, when using the ActiveState port of Perl, will modify the Registry to associate the \".pl\" extension with the perl interpreter. If you install another port, perhaps even building your own Win95\/NT Perl from the standard sources by using a Windows port of gcc (e.g., with cygwin or mingw32), then you'll have to modify the Registry yourself. In addition to associating \".pl\" with the interpreter, NT people can use: \"SET PATHEXT=%PATHEXT%;.PL\" to let them run the program \"install-linux.pl\" merely by typing \"install-linux\". Under \"Classic\" MacOS, a perl program will have the appropriate Creator and Type, so that double-clicking them will invoke the MacPerl application. Under Mac OS X, clickable apps can be made from any \"#!\" script using Wil Sanchez' DropScript utility: http:\/\/www.wsanchez.net\/software\/ . IMPORTANT !: Whatever you do, PLEASE don't get frustrated, and just throw the perl interpreter into your cgi-bin directory, in order to get your programs working for a web server. This is an EXTREMELY big security risk. Take the time to figure out how to do it correctly. Can I write useful Perl programs on the command line? Yes. Read perlrun for more information. Some examples follow. (These assume standard Unix shell quoting rules.) # sum first and last fields\nperl -lane 'print $F[0] + $F[-1]' *\n\n# identify text files\nperl -le 'for(@ARGV) {print if -f && -T _}' *\n\n# remove (most) comments from C program\nperl -0777 -pe 's{\/\\*.*?\\*\/}{}gs' foo.c\n\n# make file a month younger than today, defeating reaper daemons\nperl -e '$X=24*60*60; utime(time(),time() + 30 * $X,@ARGV)' *\n\n# find first unused uid\nperl -le '$i++ while getpwuid($i); print $i'\n\n# display reasonable manpath\necho $PATH | perl -nl -072 -e '\n    s![^\/+]*$!man!&&-d&&!$s{$_}++&&push@m,$_;END{print\"@m\"}' OK , the last one was actually an Obfuscated Perl Contest entry. :-) Why don't Perl one-liners work on my DOS\/Mac\/VMS system? The problem is usually that the command interpreters on those systems have rather different ideas about quoting than the Unix shells under which the one-liners were created. On some systems, you may have to change single-quotes to double ones, which you must NOT do on Unix or Plan9 systems. You might also have to change a single % to a %%. For example: # Unix (including Mac OS X)\nperl -e 'print \"Hello world\\n\"'\n\n# DOS, etc.\nperl -e \"print \\\"Hello world\\n\\\"\"\n\n# Mac Classic\nprint \"Hello world\\n\"\n (then Run \"Myscript\" or Shift-Command-R)\n\n# MPW\nperl -e 'print \"Hello world\\n\"'\n\n# VMS\nperl -e \"print \"\"Hello world\\n\"\"\" The problem is that none of these examples are reliable: they depend on the command interpreter. Under Unix, the first two often work. Under DOS , it's entirely possible that neither works. If 4DOS was the command shell, you'd probably have better luck like this: perl -e \"print <Ctrl-x>\"Hello world\\n<Ctrl-x>\"\" Under the Mac, it depends which environment you are using. The MacPerl shell, or MPW , is much like Unix shells in its support for several quoting variants, except that it makes free use of the Mac's non-ASCII characters as control characters. Using qq(), q(), and qx(), instead of \"double quotes\", 'single quotes', and 'backticks', may make one-liners easier to write. There is no general solution to all of this. It is a mess. [Some of this answer was contributed by Kenneth Albanowski.] Where can I learn about CGI or Web programming in Perl? For modules, get the CGI or LWP modules from CPAN . For textbooks, see the two especially dedicated to web stuff in the question on books. For problems and questions related to the web, like \"Why do I get 500 Errors\" or \"Why doesn't it run from the browser right when it runs fine on the command line\", see the troubleshooting guides and references in perlfaq9 or in the CGI MetaFAQ: http:\/\/www.perl.org\/CGI_MetaFAQ.html Where can I learn about object-oriented Perl programming? A good place to start is perltoot, and you can use perlobj, perlboot, perltoot, perltooc, and perlbot for reference. A good book on OO on Perl is the \"Object-Oriented Perl\" by Damian Conway from Manning Publications, or \"Intermediate Perl\" by Randal Schwartz, brian d foy, and Tom Phoenix from O'Reilly Media. Where can I learn about linking C with Perl? If you want to call C from Perl, start with perlxstut, moving on to perlxs, xsubpp, and perlguts. If you want to call Perl from C, then read perlembed, perlcall, and perlguts. Don't forget that you can learn a lot from looking at how the authors of existing extension modules wrote their code and solved their problems. You might not need all the power of XS . The Inline::C module lets you put C code directly in your Perl source. It handles all the magic to make it work. You still have to learn at least some of the perl API but you won't have to deal with the complexity of the XS support files. I've read perlembed, perlguts, etc., but I can't embed perl in my C program; what am I doing wrong? Download the ExtUtils::Embed kit from CPAN and run 'make test'. If the tests pass, read the pods again and again and again. If they fail, see perlbug and send a bug report with the output of \"make test TEST_VERBOSE=1\" along with \"perl -V\". When I tried to run my script, I got this message. What does it mean? A complete list of Perl's error messages and warnings with explanatory text can be found in perldiag. You can also use the splain program (distributed with Perl) to explain the error messages: perl program 2>diag.out\nsplain [-v] [-p] diag.out or change your program to explain the messages for you: use diagnostics; or use diagnostics -verbose; What's MakeMaker? (contributed by brian d foy) The \"ExtUtils::MakeMaker\" module, better known simply as \"MakeMaker\", turns a Perl script, typically called \"Makefile.PL\", into a Makefile. The unix tool \"make\" uses this file to manage dependencies and actions to process and install a Perl distribution.","Process Name":"perlfaq3","Link":"https:\/\/linux.die.net\/man\/1\/perlfaq3"}},{"Process":{"Description":"This section of the FAQ answers questions related to manipulating numbers, dates, strings, arrays, hashes, and miscellaneous data issues.","Process Name":"perlfaq4","Link":"https:\/\/linux.die.net\/man\/1\/perlfaq4"}},{"Process":{"Description":"This section deals with I\/O and the \"f\" issues: filehandles, flushing, formats, and footers. How do I flush\/unbuffer an output filehandle? Why must I do this? (contributed by brian d foy) You might like to read Mark Jason Dominus's \"Suffering From Buffering\" at http:\/\/perl.plover.com\/FAQs\/Buffering.html . Perl normally buffers output so it doesn't make a system call for every bit of output. By saving up output, it makes fewer expensive system calls. For instance, in this little bit of code, you want to print a dot to the screen for every line you process to watch the progress of your program. Instead of seeing a dot for every line, Perl buffers the output and you have a long wait before you see a row of 50 dots all at once: # long wait, then row of dots all at once\nwhile( <> ) {\n        print \".\";\n        print \"\\n\" unless ++$count % 50;\n\n        #... expensive line processing operations\n        } To get around this, you have to unbuffer the output filehandle, in this case, \"STDOUT\". You can set the special variable $| to a true value (mnemonic: making your filehandles \"piping hot\"): $|++;\n\n# dot shown immediately\nwhile( <> ) {\n        print \".\";\n        print \"\\n\" unless ++$count % 50;\n\n        #... expensive line processing operations\n        } The $| is one of the per-filehandle special variables, so each filehandle has its own copy of its value. If you want to merge standard output and standard error for instance, you have to unbuffer each (although STDERR might be unbuffered by default): {\nmy $previous_default = select(STDOUT);  # save previous default\n$|++;                                   # autoflush STDOUT\nselect(STDERR);\n$|++;                                   # autoflush STDERR, to be sure\nselect($previous_default);              # restore previous default\n}\n\n# now should alternate . and +\nwhile( 1 )\n        {\n        sleep 1;\n        print STDOUT \".\";\n        print STDERR \"+\";\n        print STDOUT \"\\n\" unless ++$count % 25;\n        } Besides the $| special variable, you can use \"binmode\" to give your filehandle a \":unix\" layer, which is unbuffered: binmode( STDOUT, \":unix\" );\n\nwhile( 1 ) {\n        sleep 1;\n        print \".\";\n        print \"\\n\" unless ++$count % 50;\n        } For more information on output layers, see the entries for \"binmode\" and \"open\" in perlfunc, and the \"PerlIO\" module documentation. If you are using \"IO::Handle\" or one of its subclasses, you can call the \"autoflush\" method to change the settings of the filehandle: use IO::Handle;\nopen my( $io_fh ), \">\", \"output.txt\";\n$io_fh->autoflush(1); The \"IO::Handle\" objects also have a \"flush\" method. You can flush the buffer any time you want without auto-buffering $io_fh->flush; How do I change, delete, or insert a line in a file, or append to the beginning of a file? (contributed by brian d foy) The basic idea of inserting, changing, or deleting a line from a text file involves reading and printing the file to the point you want to make the change, making the change, then reading and printing the rest of the file. Perl doesn't provide random access to lines (especially since the record input separator, $\/, is mutable), although modules such as \"Tie::File\" can fake it. A Perl program to do these tasks takes the basic form of opening a file, printing its lines, then closing the file:      open my $in,  '<',  $file      or die \"Can't read old file: $!\";\n     open my $out, '>', \"$file.new\" or die \"Can't write new file: $!\";\n\n     while( <$in> )\n             {\n             print $out $_;\n             }\n\nclose $out; Within that basic form, add the parts that you need to insert, change, or delete lines. To prepend lines to the beginning, print those lines before you enter the loop that prints the existing lines.      open my $in,  '<',  $file      or die \"Can't read old file: $!\";\n     open my $out, '>', \"$file.new\" or die \"Can't write new file: $!\";\n\n     print $out \"# Add this line to the top\\n\"; # <--- HERE'S THE MAGIC\n\n     while( <$in> )\n             {\n             print $out $_;\n             }\n\nclose $out; To change existing lines, insert the code to modify the lines inside the \"while\" loop. In this case, the code finds all lowercased versions of \"perl\" and uppercases them. The happens for every line, so be sure that you're supposed to do that on every line!      open my $in,  '<',  $file      or die \"Can't read old file: $!\";\n     open my $out, '>', \"$file.new\" or die \"Can't write new file: $!\";\n\n     print $out \"# Add this line to the top\\n\";\n\n     while( <$in> )\n             {\n             s\/\\b(perl)\\b\/Perl\/g;\n             print $out $_;\n             }\n\nclose $out; To change only a particular line, the input line number, $., is useful. First read and print the lines up to the one you want to change. Next, read the single line you want to change, change it, and print it. After that, read the rest of the lines and print those: while( <$in> )   # print the lines before the change\n        {\n        print $out $_;\n        last if $. == 4; # line number before change\n        }\n\nmy $line = <$in>;\n$line =~ s\/\\b(perl)\\b\/Perl\/g;\nprint $out $line;\n\nwhile( <$in> )   # print the rest of the lines\n        {\n        print $out $_;\n        } To skip lines, use the looping controls. The \"next\" in this example skips comment lines, and the \"last\" stops all processing once it encounters either \"__END__\" or \"__DATA__\". while( <$in> )\n        {\n        next if \/^\\s+#\/;             # skip comment lines\n        last if \/^__(END|DATA)__$\/;  # stop at end of code marker\n        print $out $_;\n        } Do the same sort of thing to delete a particular line by using \"next\" to skip the lines you don't want to show up in the output. This example skips every fifth line: while( <$in> )\n        {\n        next unless $. % 5;\n        print $out $_;\n        } If, for some odd reason, you really want to see the whole file at once rather than processing line by line, you can slurp it in (as long as you can fit the whole thing in memory!): open my $in,  '<',  $file      or die \"Can't read old file: $!\"\nopen my $out, '>', \"$file.new\" or die \"Can't write new file: $!\";\n\nmy @lines = do { local $\/; <$in> }; # slurp!\n\n        # do your magic here\n\nprint $out @lines; Modules such as \"File::Slurp\" and \"Tie::File\" can help with that too. If you can, however, avoid reading the entire file at once. Perl won't give that memory back to the operating system until the process finishes. You can also use Perl one-liners to modify a file in-place. The following changes all 'Fred' to 'Barney' in inFile.txt, overwriting the file with the new contents. With the \"-p\" switch, Perl wraps a \"while\" loop around the code you specify with \"-e\", and \"-i\" turns on in-place editing. The current line is in $_. With \"-p\", Perl automatically prints the value of $_ at the end of the loop. See perlrun for more details. perl -pi -e 's\/Fred\/Barney\/' inFile.txt To make a backup of \"inFile.txt\", give \"-i\" a file extension to add: perl -pi.bak -e 's\/Fred\/Barney\/' inFile.txt To change only the fifth line, you can add a test checking $., the input line number, then only perform the operation when the test passes: perl -pi -e 's\/Fred\/Barney\/ if $. == 5' inFile.txt To add lines before a certain line, you can add a line (or lines!) before Perl prints $_: perl -pi -e 'print \"Put before third line\\n\" if $. == 3' inFile.txt You can even add a line to the beginning of a file, since the current line prints at the end of the loop: perl -pi -e 'print \"Put before first line\\n\" if $. == 1' inFile.txt To insert a line after one already in the file, use the \"-n\" switch. It's just like \"-p\" except that it doesn't print $_ at the end of the loop, so you have to do that yourself. In this case, print $_ first, then print the line that you want to add. perl -ni -e 'print; print \"Put after fifth line\\n\" if $. == 5' inFile.txt To delete lines, only print the ones that you want. perl -ni -e 'print unless \/d\/' inFile.txt\n\n        ... or ...\n\nperl -pi -e 'next unless \/d\/' inFile.txt How do I count the number of lines in a file? One fairly efficient way is to count newlines in the file. The following program uses a feature of tr\/\/\/, as documented in perlop. If your text file doesn't end with a newline, then it's not really a proper text file, so this may report one fewer line than you expect. $lines = 0;\nopen(FILE, $filename) or die \"Can't open `$filename': $!\";\nwhile (sysread FILE, $buffer, 4096) {\n        $lines += ($buffer =~ tr\/\\n\/\/);\n        }\nclose FILE; This assumes no funny games with newline translations. How can I use Perl's \"-i\" option from within a program? \"-i\" sets the value of Perl's $^I variable, which in turn affects the behavior of \"<>\"; see perlrun for more details. By modifying the appropriate variables directly, you can get the same behavior within a larger program. For example: # ...\n{\nlocal($^I, @ARGV) = ('.orig', glob(\"*.c\"));\nwhile (<>) {\n        if ($. == 1) {\n                print \"This line should appear at the top of each file\\n\";\n        }\n        s\/\\b(p)earl\\b\/${1}erl\/i;        # Correct typos, preserving case\n        print;\n        close ARGV if eof;              # Reset $.\n        }\n}\n# $^I and @ARGV return to their old values here This block modifies all the \".c\" files in the current directory, leaving a backup of the original data from each file in a new \".c.orig\" file. How can I copy a file? (contributed by brian d foy) Use the \"File::Copy\" module. It comes with Perl and can do a true copy across file systems, and it does its magic in a portable fashion. use File::Copy;\n\ncopy( $original, $new_copy ) or die \"Copy failed: $!\"; If you can't use \"File::Copy\", you'll have to do the work yourself: open the original file, open the destination file, then print to the destination file as you read the original. You also have to remember to copy the permissions, owner, and group to the new file. How do I make a temporary file name? If you don't need to know the name of the file, you can use \"open()\" with \"undef\" in place of the file name. In Perl 5.8 or later, the \"open()\" function creates an anonymous temporary file: open my $tmp, '+>', undef or die $!; Otherwise, you can use the File::Temp module. use File::Temp qw\/ tempfile tempdir \/;\n\n$dir = tempdir( CLEANUP => 1 );\n($fh, $filename) = tempfile( DIR => $dir );\n\n# or if you don't need to know the filename\n\n$fh = tempfile( DIR => $dir ); The File::Temp has been a standard module since Perl 5.6.1. If you don't have a modern enough Perl installed, use the \"new_tmpfile\" class method from the IO::File module to get a filehandle opened for reading and writing. Use it if you don't need to know the file's name: use IO::File;\n$fh = IO::File->new_tmpfile()\nor die \"Unable to make new temporary file: $!\"; If you're committed to creating a temporary file by hand, use the process ID and\/or the current time-value. If you need to have many temporary files in one process, use a counter: BEGIN {\nuse Fcntl;\nmy $temp_dir = -d '\/tmp' ? '\/tmp' : $ENV{TMPDIR} || $ENV{TEMP};\nmy $base_name = sprintf \"%s\/%d-%d-0000\", $temp_dir, $$, time;\n\nsub temp_file {\n        local *FH;\n        my $count = 0;\n        until( defined(fileno(FH)) || $count++ > 100 ) {\n                $base_name =~ s\/-(\\d+)$\/\"-\" . (1 + $1)\/e;\n                # O_EXCL is required for security reasons.\n                sysopen FH, $base_name, O_WRONLY|O_EXCL|O_CREAT;\n                }\n\n        if( defined fileno(FH) ) {\n                return (*FH, $base_name);\n                }\n        else {\n                return ();\n                }\n        }\n\n} How can I manipulate fixed-record-length files? The most efficient way is using pack() and unpack(). This is faster than using substr() when taking many, many strings. It is slower for just a few. Here is a sample chunk of code to break up and put back together again some fixed-format input lines, in this case from the output of a normal, Berkeley-style ps: # sample input line:\n#   15158 p5  T      0:00 perl \/home\/tchrist\/scripts\/now-what\nmy $PS_T = 'A6 A4 A7 A5 A*';\nopen my $ps, '-|', 'ps';\nprint scalar <$ps>;\nmy @fields = qw( pid tt stat time command );\nwhile (<$ps>) {\n        my %process;\n        @process{@fields} = unpack($PS_T, $_);\nfor my $field ( @fields ) {\n        print \"$field: <$process{$field}>\\n\";\n}\nprint 'line=', pack($PS_T, @process{@fields} ), \"\\n\";\n} We've used a hash slice in order to easily handle the fields of each row. Storing the keys in an array means it's easy to operate on them as a group or loop over them with for. It also avoids polluting the program with global variables and using symbolic references. How can I make a filehandle local to a subroutine? How do I pass filehandles between subroutines? How do I make an array of filehandles? As of perl5.6, open() autovivifies file and directory handles as references if you pass it an uninitialized scalar variable. You can then pass these references just like any other scalar, and use them in the place of named handles. open my    $fh, $file_name;\n\nopen local $fh, $file_name;\n\nprint $fh \"Hello World!\\n\";\n\nprocess_file( $fh ); If you like, you can store these filehandles in an array or a hash. If you access them directly, they aren't simple scalars and you need to give \"print\" a little help by placing the filehandle reference in braces. Perl can only figure it out on its own when the filehandle reference is a simple scalar. my @fhs = ( $fh1, $fh2, $fh3 );\n\nfor( $i = 0; $i <= $#fhs; $i++ ) {\n        print {$fhs[$i]} \"just another Perl answer, \\n\";\n        } Before perl5.6, you had to deal with various typeglob idioms which you may see in older code. open FILE, \"> $filename\";\nprocess_typeglob(   *FILE );\nprocess_reference( \\*FILE );\n\nsub process_typeglob  { local *FH = shift; print FH  \"Typeglob!\" }\nsub process_reference { local $fh = shift; print $fh \"Reference!\" } If you want to create many anonymous handles, you should check out the Symbol or IO::Handle modules. How can I use a filehandle indirectly? An indirect filehandle is using something other than a symbol in a place that a filehandle is expected. Here are ways to get indirect filehandles: $fh =   SOME_FH;       # bareword is strict-subs hostile\n$fh =  \"SOME_FH\";      # strict-refs hostile; same package only\n$fh =  *SOME_FH;       # typeglob\n$fh = \\*SOME_FH;       # ref to typeglob (bless-able)\n$fh =  *SOME_FH{IO};   # blessed IO::Handle from *SOME_FH typeglob Or, you can use the \"new\" method from one of the IO::* modules to create an anonymous filehandle, store that in a scalar variable, and use it as though it were a normal filehandle. use IO::Handle;                     # 5.004 or higher\n$fh = IO::Handle->new(); Then use any of those as you would a normal filehandle. Anywhere that Perl is expecting a filehandle, an indirect filehandle may be used instead. An indirect filehandle is just a scalar variable that contains a filehandle. Functions like \"print\", \"open\", \"seek\", or the \"<FH>\" diamond operator will accept either a named filehandle or a scalar variable containing one: ($ifh, $ofh, $efh) = (*STDIN, *STDOUT, *STDERR);\nprint $ofh \"Type it: \";\n$got = <$ifh>\nprint $efh \"What was that: $got\"; If you're passing a filehandle to a function, you can write the function in two ways: sub accept_fh {\n        my $fh = shift;\n        print $fh \"Sending to indirect filehandle\\n\";\n} Or it can localize a typeglob and use the filehandle directly: sub accept_fh {\n        local *FH = shift;\n        print  FH \"Sending to localized filehandle\\n\";\n} Both styles work with either objects or typeglobs of real filehandles. (They might also work with strings under some circumstances, but this is risky.) accept_fh(*STDOUT);\naccept_fh($handle); In the examples above, we assigned the filehandle to a scalar variable before using it. That is because only simple scalar variables, not expressions or subscripts of hashes or arrays, can be used with built-ins like \"print\", \"printf\", or the diamond operator. Using something other than a simple scalar variable as a filehandle is illegal and won't even compile: @fd = (*STDIN, *STDOUT, *STDERR);\nprint $fd[1] \"Type it: \";                           # WRONG\n$got = <$fd[0]>                                     # WRONG\nprint $fd[2] \"What was that: $got\";                 # WRONG With \"print\" and \"printf\", you get around this by using a block and an expression where you would place the filehandle: print  { $fd[1] } \"funny stuff\\n\";\nprintf { $fd[1] } \"Pity the poor %x.\\n\", 3_735_928_559;\n# Pity the poor deadbeef. That block is a proper block like any other, so you can put more complicated code there. This sends the message out to one of two places: $ok = -x \"\/bin\/cat\";\nprint { $ok ? $fd[1] : $fd[2] } \"cat stat $ok\\n\";\nprint { $fd[ 1+ ($ok || 0) ]  } \"cat stat $ok\\n\"; This approach of treating \"print\" and \"printf\" like object methods calls doesn't work for the diamond operator. That's because it's a real operator, not just a function with a comma-less argument. Assuming you've been storing typeglobs in your structure as we did above, you can use the built-in function named \"readline\" to read a record just as \"<>\" does. Given the initialization shown above for @fd, this would work, but only because readline() requires a typeglob. It doesn't work with objects or strings, which might be a bug we haven't fixed yet. $got = readline($fd[0]); Let it be noted that the flakiness of indirect filehandles is not related to whether they're strings, typeglobs, objects, or anything else. It's the syntax of the fundamental operators. Playing the object game doesn't help you at all here. How can I set up a footer format to be used with write()? There's no builtin way to do this, but perlform has a couple of techniques to make it possible for the intrepid hacker. How can I write() into a string? See \"Accessing Formatting Internals\" in perlform for an \"swrite()\" function. How can I open a filehandle to a string? (contributed by Peter J. Holzer, hjp-usenet2@hjp.at) Since Perl 5.8.0 a file handle referring to a string can be created by calling open with a reference to that string instead of the filename. This file handle can then be used to read from or write to the string: open(my $fh, '>', \\$string) or die \"Could not open string for writing\";\nprint $fh \"foo\\n\";\nprint $fh \"bar\\n\";      # $string now contains \"foo\\nbar\\n\"\n\nopen(my $fh, '<', \\$string) or die \"Could not open string for reading\";\nmy $x = <$fh>;  # $x now contains \"foo\\n\" With older versions of Perl, the \"IO::String\" module provides similar functionality. How can I output my numbers with commas added? (contributed by brian d foy and Benjamin Goldberg) You can use Number::Format to separate places in a number. It handles locale information for those of you who want to insert full stops instead (or anything else that they want to use, really). This subroutine will add commas to your number: sub commify {\n        local $_  = shift;\n        1 while s\/^([-+]?\\d+)(\\d{3})\/$1,$2\/;\n        return $_;\n        } This regex from Benjamin Goldberg will add commas to numbers: s\/(^[-+]?\\d+?(?=(?>(?:\\d{3})+)(?!\\d))|\\G\\d{3}(?=\\d))\/$1,\/g; It is easier to see with comments: s\/(\n        ^[-+]?             # beginning of number.\n        \\d+?               # first digits before first comma\n        (?=                # followed by, (but not included in the match) :\n                (?>(?:\\d{3})+) # some positive multiple of three digits.\n                (?!\\d)         # an *exact* multiple, not x * 3 + 1 or whatever.\n        )\n        |                  # or:\n        \\G\\d{3}            # after the last group, get three digits\n        (?=\\d)             # but they have to have more digits after them.\n)\/$1,\/xg; How can I translate tildes (~) in a filename? Use the <> ( \"glob()\") operator, documented in perlfunc. Versions of Perl older than 5.6 require that you have a shell installed that groks tildes. Later versions of Perl have this feature built in. The \"File::KGlob\" module (available from CPAN ) gives more portable glob functionality. Within Perl, you may use this directly: $filename =~ s{\n  ^ ~             # find a leading tilde\n  (               # save this in $1\n      [^\/]        # a non-slash character\n            *     # repeated 0 or more times (0 means me)\n  )\n}{\n  $1\n      ? (getpwnam($1))[7]\n      : ( $ENV{HOME} || $ENV{LOGDIR} )\n}ex; How come when I open a file read-write it wipes it out? Because you're using something like this, which truncates the file and then gives you read-write access: open(FH, \"+> \/path\/name\");              # WRONG (almost always) Whoops. You should instead use this, which will fail if the file doesn't exist. open(FH, \"+< \/path\/name\");      # open for update Using \">\" always clobbers or creates. Using \"<\" never does either. The \"+\" doesn't change this. Here are examples of many kinds of file opens. Those using sysopen() all assume use Fcntl; To open file for reading: open(FH, \"< $path\")                                 || die $!;\nsysopen(FH, $path, O_RDONLY)                        || die $!; To open file for writing, create new file if needed or else truncate old file: open(FH, \"> $path\") || die $!;\nsysopen(FH, $path, O_WRONLY|O_TRUNC|O_CREAT)        || die $!;\nsysopen(FH, $path, O_WRONLY|O_TRUNC|O_CREAT, 0666)  || die $!; To open file for writing, create new file, file must not exist: sysopen(FH, $path, O_WRONLY|O_EXCL|O_CREAT)         || die $!;\nsysopen(FH, $path, O_WRONLY|O_EXCL|O_CREAT, 0666)   || die $!; To open file for appending, create if necessary: open(FH, \">> $path\") || die $!;\nsysopen(FH, $path, O_WRONLY|O_APPEND|O_CREAT)       || die $!;\nsysopen(FH, $path, O_WRONLY|O_APPEND|O_CREAT, 0666) || die $!; To open file for appending, file must exist: sysopen(FH, $path, O_WRONLY|O_APPEND)               || die $!; To open file for update, file must exist: open(FH, \"+< $path\")                                || die $!;\nsysopen(FH, $path, O_RDWR)                          || die $!; To open file for update, create file if necessary: sysopen(FH, $path, O_RDWR|O_CREAT)                  || die $!;\nsysopen(FH, $path, O_RDWR|O_CREAT, 0666)            || die $!; To open file for update, file must not exist: sysopen(FH, $path, O_RDWR|O_EXCL|O_CREAT)           || die $!;\nsysopen(FH, $path, O_RDWR|O_EXCL|O_CREAT, 0666)     || die $!; To open a file without blocking, creating if necessary: sysopen(FH, \"\/foo\/somefile\", O_WRONLY|O_NDELAY|O_CREAT)\n    or die \"can't open \/foo\/somefile: $!\": Be warned that neither creation nor deletion of files is guaranteed to be an atomic operation over NFS . That is, two processes might both successfully create or unlink the same file! Therefore O_EXCL isn't as exclusive as you might wish. See also the new perlopentut if you have it (new for 5.6). Why do I sometimes get an \"Argument list too long\" when I use <*>? The \"<>\" operator performs a globbing operation (see above). In Perl versions earlier than v5.6.0, the internal glob() operator forks csh(1) to do the actual glob expansion, but csh can't handle more than 127 items and so gives the error message \"Argument list too long\". People who installed tcsh as csh won't have this problem, but their users may be surprised by it. To get around this, either upgrade to Perl v5.6.0 or later, do the glob yourself with readdir() and patterns, or use a module like File::KGlob, one that doesn't use the shell to do globbing. Is there a leak\/bug in glob()? Due to the current implementation on some operating systems, when you use the glob() function or its angle-bracket alias in a scalar context, you may cause a memory leak and\/or unpredictable behavior. It's best therefore to use glob() only in list context. How can I open a file with a leading \">\" or trailing blanks? (contributed by Brian McCauley) The special two argument form of Perl's open() function ignores trailing blanks in filenames and infers the mode from certain leading characters (or a trailing \"|\"). In older versions of Perl this was the only version of open() and so it is prevalent in old code and books. Unless you have a particular reason to use the two argument form you should use the three argument form of open() which does not treat any characters in the filename as special. open FILE, \"<\", \"  file  \";  # filename is \"   file   \"\nopen FILE, \">\", \">file\";     # filename is \">file\" How can I reliably rename a file? If your operating system supports a proper mv(1) utility or its functional equivalent, this works: rename($old, $new) or system(\"mv\", $old, $new); It may be more portable to use the File::Copy module instead. You just copy to the new file to the new name (checking return values), then delete the old one. This isn't really the same semantically as a rename(), which preserves meta-information like permissions, timestamps, inode info, etc. Newer versions of File::Copy export a move() function. How can I lock a file? Perl's builtin flock() function (see perlfunc for details) will call flock(2) if that exists, fcntl(2) if it doesn't (on perl version 5.004 and later), and lockf(3) if neither of the two previous system calls exists. On some systems, it may even use a different form of native locking. Here are some gotchas with Perl's flock(): 1. Produces a fatal error if none of the three system calls (or their close equivalent) exists. 2. lockf(3) does not provide shared locking, and requires that the filehandle be open for writing (or appending, or read\/writing). 3. Some versions of flock() can't lock files over a network (e.g. on NFS file systems), so you'd need to force the use of fcntl(2) when you build Perl. But even this is dubious at best. See the flock entry of perlfunc and the INSTALL file in the source distribution for information on building Perl to do this. Two potentially non-obvious but traditional flock semantics are that it waits indefinitely until the lock is granted, and that its locks are merely advisory. Such discretionary locks are more flexible, but offer fewer guarantees. This means that files locked with flock() may be modified by programs that do not also use flock(). Cars that stop for red lights get on well with each other, but not with cars that don't stop for red lights. See the perlport manpage, your port's specific documentation, or your system-specific local manpages for details. It's best to assume traditional behavior if you're writing portable programs. (If you're not, you should as always feel perfectly free to write for your own system's idiosyncrasies (sometimes called \"features\"). Slavish adherence to portability concerns shouldn't get in the way of your getting your job done.) For more information on file locking, see also \"File Locking\" in perlopentut if you have it (new for 5.6). Why can't I just open( FH , \">file.lock\")? A common bit of code NOT TO USE is this: sleep(3) while -e \"file.lock\";  # PLEASE DO NOT USE\nopen(LCK, \"> file.lock\");               # THIS BROKEN CODE This is a classic race condition: you take two steps to do something which must be done in one. That's why computer hardware provides an atomic test-and-set instruction. In theory, this \"ought\" to work: sysopen(FH, \"file.lock\", O_WRONLY|O_EXCL|O_CREAT)\n        or die \"can't open  file.lock: $!\"; except that lamentably, file creation (and deletion) is not atomic over NFS , so this won't work (at least, not every time) over the net. Various schemes involving link() have been suggested, but these tend to involve busy-wait, which is also less than desirable. I still don't get locking. I just want to increment the number in the file. How can I do this? Didn't anyone ever tell you web-page hit counters were useless? They don't count number of hits, they're a waste of time, and they serve only to stroke the writer's vanity. It's better to pick a random number; they're more realistic. Anyway, this is what you can do if you can't help yourself. use Fcntl qw(:DEFAULT :flock);\nsysopen(FH, \"numfile\", O_RDWR|O_CREAT)   or die \"can't open numfile: $!\";\nflock(FH, LOCK_EX)                               or die \"can't flock numfile: $!\";\n$num = <FH> || 0;\nseek(FH, 0, 0)                           or die \"can't rewind numfile: $!\";\ntruncate(FH, 0)                                  or die \"can't truncate numfile: $!\";\n(print FH $num+1, \"\\n\")                  or die \"can't write numfile: $!\";\nclose FH                                         or die \"can't close numfile: $!\"; Here's a much better web-page hit counter: $hits = int( (time() - 850_000_000) \/ rand(1_000) ); If the count doesn't impress your friends, then the code might. :-) All I want to do is append a small amount of text to the end of a file. Do I still have to use locking? If you are on a system that correctly implements \"flock\" and you use the example appending code from \"perldoc -f flock\" everything will be OK even if the OS you are on doesn't implement append mode correctly (if such a system exists.) So if you are happy to restrict yourself to OSs that implement \"flock\" (and that's not really much of a restriction) then that is what you should do. If you know you are only going to use a system that does correctly implement appending (i.e. not Win32) then you can omit the \"seek\" from the code in the previous answer. If you know you are only writing code to run on an OS and filesystem that does implement append mode correctly (a local filesystem on a modern Unix for example), and you keep the file in block-buffered mode and you write less than one buffer-full of output between each manual flushing of the buffer then each bufferload is almost guaranteed to be written to the end of the file in one chunk without getting intermingled with anyone else's output. You can also use the \"syswrite\" function which is simply a wrapper around your system's write(2) system call. There is still a small theoretical chance that a signal will interrupt the system level \"write()\" operation before completion. There is also a possibility that some STDIO implementations may call multiple system level \"write()\"s even if the buffer was empty to start. There may be some systems where this probability is reduced to zero, and this is not a concern when using \":perlio\" instead of your system's STDIO . How do I randomly update a binary file? If you're just trying to patch a binary, in many cases something as simple as this works: perl -i -pe 's{window manager}{window mangler}g' \/usr\/bin\/emacs However, if you have fixed sized records, then you might do something more like this: $RECSIZE = 220; # size of record, in bytes\n$recno   = 37;  # which record to update\nopen(FH, \"+<somewhere\") || die \"can't update somewhere: $!\";\nseek(FH, $recno * $RECSIZE, 0);\nread(FH, $record, $RECSIZE) == $RECSIZE || die \"can't read record $recno: $!\";\n# munge the record\nseek(FH, -$RECSIZE, 1);\nprint FH $record;\nclose FH; Locking and error checking are left as an exercise for the reader. Don't forget them or you'll be quite sorry. How do I get a file's timestamp in perl? If you want to retrieve the time at which the file was last read, written, or had its meta-data (owner, etc) changed, you use the -A, -M, or -C file test operations as documented in perlfunc. These retrieve the age of the file (measured against the start-time of your program) in days as a floating point number. Some platforms may not have all of these times. See perlport for details. To retrieve the \"raw\" time in seconds since the epoch, you would call the stat function, then use localtime(), gmtime(), or POSIX::strftime() to convert this into human-readable form. Here's an example: $write_secs = (stat($file))[9];\nprintf \"file %s updated at %s\\n\", $file,\nscalar localtime($write_secs); If you prefer something more legible, use the File::stat module (part of the standard distribution in version 5.004 and later): # error checking left as an exercise for reader.\nuse File::stat;\nuse Time::localtime;\n$date_string = ctime(stat($file)->mtime);\nprint \"file $file updated at $date_string\\n\"; The POSIX::strftime() approach has the benefit of being, in theory, independent of the current locale. See perllocale for details. How do I set a file's timestamp in perl? You use the utime() function documented in \"utime\" in perlfunc. By way of example, here's a little program that copies the read and write times from its first argument to all the rest of them. if (@ARGV < 2) {\n        die \"usage: cptimes timestamp_file other_files ...\\n\";\n        }\n$timestamp = shift;\n($atime, $mtime) = (stat($timestamp))[8,9];\nutime $atime, $mtime, @ARGV; Error checking is, as usual, left as an exercise for the reader. The perldoc for utime also has an example that has the same effect as touch(1) on files that already exist. Certain file systems have a limited ability to store the times on a file at the expected level of precision. For example, the FAT and HPFS filesystem are unable to create dates on files with a finer granularity than two seconds. This is a limitation of the filesystems, not of utime(). How do I print to more than one file at once? To connect one filehandle to several output filehandles, you can use the IO::Tee or Tie::FileHandle::Multiplex modules. If you only have to do this once, you can print individually to each filehandle. for $fh (FH1, FH2, FH3) { print $fh \"whatever\\n\" } How can I read in an entire file all at once? You can use the File::Slurp module to do it in one step. use File::Slurp;\n\n$all_of_it = read_file($filename); # entire file in scalar\n@all_lines = read_file($filename); # one line per element The customary Perl approach for processing all the lines in a file is to do so one line at a time: open (INPUT, $file)     || die \"can't open $file: $!\";\nwhile (<INPUT>) {\n        chomp;\n        # do something with $_\n        }\nclose(INPUT)            || die \"can't close $file: $!\"; This is tremendously more efficient than reading the entire file into memory as an array of lines and then processing it one element at a time, which is often--if not almost always--the wrong approach. Whenever you see someone do this: @lines = <INPUT>; you should think long and hard about why you need everything loaded at once. It's just not a scalable solution. You might also find it more fun to use the standard Tie::File module, or the DB_File module's $DB_RECNO bindings, which allow you to tie an array to a file so that accessing an element the array actually accesses the corresponding line in the file. You can read the entire filehandle contents into a scalar. {\nlocal(*INPUT, $\/);\nopen (INPUT, $file)     || die \"can't open $file: $!\";\n$var = <INPUT>;\n} That temporarily undefs your record separator, and will automatically close the file at block exit. If the file is already open, just use this: $var = do { local $\/; <INPUT> }; For ordinary files you can also use the read function. read( INPUT, $var, -s INPUT ); The third argument tests the byte size of the data on the INPUT filehandle and reads that many bytes into the buffer $var. How can I read in a file by paragraphs? Use the $\/ variable (see perlvar for details). You can either set it to \"\" to eliminate empty paragraphs ( \"abc\\n\\n\\n\\ndef\", for instance, gets treated as two paragraphs and not three), or \"\\n\\n\" to accept empty paragraphs. Note that a blank line must have no blanks in it. Thus \"fred\\n \\nstuff\\n\\n\" is one paragraph, but \"fred\\n\\nstuff\\n\\n\" is two. How can I read a single character from a file? From the keyboard? You can use the builtin \"getc()\" function for most filehandles, but it won't (easily) work on a terminal device. For STDIN , either use the Term::ReadKey module from CPAN or use the sample code in \"getc\" in perlfunc. If your system supports the portable operating system programming interface ( POSIX ), you can use the following code, which you'll note turns off echo processing as well.     #!\/usr\/bin\/perl -w\n    use strict;\n    $| = 1;\n    for (1..4) {\n            my $got;\n            print \"gimme: \";\n            $got = getone();\n            print \"--> $got\\n\";\n            }\nexit;\n\n    BEGIN {\n    use POSIX qw(:termios_h);\n\n    my ($term, $oterm, $echo, $noecho, $fd_stdin);\n\n    $fd_stdin = fileno(STDIN);\n\n    $term     = POSIX::Termios->new();\n    $term->getattr($fd_stdin);\n    $oterm     = $term->getlflag();\n\n    $echo     = ECHO | ECHOK | ICANON;\n    $noecho   = $oterm & ~$echo;\n\n    sub cbreak {\n            $term->setlflag($noecho);\n            $term->setcc(VTIME, 1);\n            $term->setattr($fd_stdin, TCSANOW);\n            }\n\n    sub cooked {\n            $term->setlflag($oterm);\n            $term->setcc(VTIME, 0);\n            $term->setattr($fd_stdin, TCSANOW);\n            }\n\n    sub getone {\n            my $key = '';\n            cbreak();\n            sysread(STDIN, $key, 1);\n            cooked();\n            return $key;\n            }\n\n    }\n\n    END { cooked() } The Term::ReadKey module from CPAN may be easier to use. Recent versions include also support for non-portable systems as well. use Term::ReadKey;\nopen(TTY, \"<\/dev\/tty\");\nprint \"Gimme a char: \";\nReadMode \"raw\";\n$key = ReadKey 0, *TTY;\nReadMode \"normal\";\nprintf \"\\nYou said %s, char number %03d\\n\",\n        $key, ord $key; How can I tell whether there's a character waiting on a filehandle? The very first thing you should do is look into getting the Term::ReadKey extension from CPAN . As we mentioned earlier, it now even has limited support for non-portable (read: not open systems, closed, proprietary, not POSIX , not Unix, etc) systems. You should also check out the Frequently Asked Questions list in comp.unix.* for things like this: the answer is essentially the same. It's very system dependent. Here's one solution that works on BSD systems: sub key_ready {\n        my($rin, $nfd);\n        vec($rin, fileno(STDIN), 1) = 1;\n        return $nfd = select($rin,undef,undef,0);\n        } If you want to find out how many characters are waiting, there's also the FIONREAD ioctl call to be looked at. The h2ph tool that comes with Perl tries to convert C include files to Perl code, which can be \"require\"d. FIONREAD ends up defined as a function in the sys\/ioctl.ph file: require 'sys\/ioctl.ph';\n\n$size = pack(\"L\", 0);\nioctl(FH, FIONREAD(), $size)    or die \"Couldn't call ioctl: $!\\n\";\n$size = unpack(\"L\", $size); If h2ph wasn't installed or doesn't work for you, you can grep the include files by hand: % grep FIONREAD \/usr\/include\/*\/*\n\/usr\/include\/asm\/ioctls.h:#define FIONREAD      0x541B Or write a small C program using the editor of champions: % cat > fionread.c\n#include <sys\/ioctl.h>\nmain() {\n    printf(\"%#08x\\n\", FIONREAD);\n}\n^D\n% cc -o fionread fionread.c\n% .\/fionread\n0x4004667f And then hard code it, leaving porting as an exercise to your successor. $FIONREAD = 0x4004667f;         # XXX: opsys dependent\n\n$size = pack(\"L\", 0);\nioctl(FH, $FIONREAD, $size)     or die \"Couldn't call ioctl: $!\\n\";\n$size = unpack(\"L\", $size); FIONREAD requires a filehandle connected to a stream, meaning that sockets, pipes, and tty devices work, but not files. How do I do a \"tail -f\" in perl? First try seek(GWFILE, 0, 1); The statement \"seek(GWFILE, 0, 1)\" doesn't change the current position, but it does clear the end-of-file condition on the handle, so that the next \"<GWFILE>\" makes Perl try again to read something. If that doesn't work (it relies on features of your stdio implementation), then you need something more like this: for (;;) {\n  for ($curpos = tell(GWFILE); <GWFILE>; $curpos = tell(GWFILE)) {\n    # search for some stuff and put it into files\n  }\n  # sleep for a while\n  seek(GWFILE, $curpos, 0);  # seek to where we had been\n} If this still doesn't work, look into the \"clearerr\" method from \"IO::Handle\", which resets the error and end-of-file states on the handle. There's also a \"File::Tail\" module from CPAN . How do I dup() a filehandle in Perl? If you check \"open\" in perlfunc, you'll see that several of the ways to call open() should do the trick. For example: open(LOG, \">>\/foo\/logfile\");\nopen(STDERR, \">&LOG\"); Or even with a literal numeric descriptor: $fd = $ENV{MHCONTEXTFD};\nopen(MHCONTEXT, \"<&=$fd\");   # like fdopen(3S) Note that \"<&STDIN\" makes a copy, but \"<&=STDIN\" make an alias. That means if you close an aliased handle, all aliases become inaccessible. This is not true with a copied one. Error checking, as always, has been left as an exercise for the reader. How do I close a file descriptor by number? If, for some reason, you have a file descriptor instead of a filehandle (perhaps you used \"POSIX::open\"), you can use the \"close()\" function from the \"POSIX\" module: use POSIX ();\n\nPOSIX::close( $fd ); This should rarely be necessary, as the Perl \"close()\" function is to be used for things that Perl opened itself, even if it was a dup of a numeric descriptor as with \"MHCONTEXT\" above. But if you really have to, you may be able to do this: require 'sys\/syscall.ph';\n$rc = syscall(&SYS_close, $fd + 0);  # must force numeric\ndie \"can't sysclose $fd: $!\" unless $rc == -1; Or, just use the fdopen(3S) feature of \"open()\": {\nopen my( $fh ), \"<&=$fd\" or die \"Cannot reopen fd=$fd: $!\";\nclose $fh;\n} Why can't I use \"C:\\temp\\foo\" in DOS paths? Why doesn't 'C:\\temp\\foo.exe' work? Whoops! You just put a tab and a formfeed into that filename! Remember that within double quoted strings (\"like\\this\"), the backslash is an escape character. The full list of these is in \"Quote and Quote-like Operators\" in perlop. Unsurprisingly, you don't have a file called \"c:(tab)emp(formfeed)oo\" or \"c:(tab)emp(formfeed)oo.exe\" on your legacy DOS filesystem. Either single-quote your strings, or (preferably) use forward slashes. Since all DOS and Windows versions since something like MS-DOS 2.0 or so have treated \"\/\" and \"\\\" the same in a path, you might as well use the one that doesn't clash with Perl--or the POSIX shell, ANSI C and C ++ , awk, Tcl, Java, or Python, just to mention a few. POSIX paths are more portable, too. Why doesn't glob(\"*.*\") get all the files? Because even on non-Unix ports, Perl's glob function follows standard Unix globbing semantics. You'll need \"glob(\"*\")\" to get all (non-hidden) files. This makes glob() portable even to legacy systems. Your port may include proprietary globbing functions as well. Check its documentation for details. Why does Perl let me delete read-only files? Why does \"-i\" clobber protected files? Isn't this a bug in Perl? This is elaborately and painstakingly described in the file-dir-perms article in the \"Far More Than You Ever Wanted To Know\" collection in http:\/\/www.cpan.org\/misc\/olddoc\/FMTEYEWTK.tgz . The executive summary: learn how your filesystem works. The permissions on a file say what can happen to the data in that file. The permissions on a directory say what can happen to the list of files in that directory. If you delete a file, you're removing its name from the directory (so the operation depends on the permissions of the directory, not of the file). If you try to write to the file, the permissions of the file govern whether you're allowed to. How do I select a random line from a file? Short of loading the file into a database or pre-indexing the lines in the file, there are a couple of things that you can do. Here's a reservoir-sampling algorithm from the Camel Book: srand;\nrand($.) < 1 && ($line = $_) while <>; This has a significant advantage in space over reading the whole file in. You can find a proof of this method in The Art of Computer Programming, Volume 2, Section 3.4.2, by Donald E. Knuth. You can use the \"File::Random\" module which provides a function for that algorithm: use File::Random qw\/random_line\/;\nmy $line = random_line($filename); Another way is to use the \"Tie::File\" module, which treats the entire file as an array. Simply access a random array element. Why do I get weird spaces when I print an array of lines? (contributed by brian d foy) If you are seeing spaces between the elements of your array when you print the array, you are probably interpolating the array in double quotes: my @animals = qw(camel llama alpaca vicuna);\nprint \"animals are: @animals\\n\"; It's the double quotes, not the \"print\", doing this. Whenever you interpolate an array in a double quote context, Perl joins the elements with spaces (or whatever is in $\", which is a space by default): animals are: camel llama alpaca vicuna This is different than printing the array without the interpolation: my @animals = qw(camel llama alpaca vicuna);\nprint \"animals are: \", @animals, \"\\n\"; Now the output doesn't have the spaces between the elements because the elements of @animals simply become part of the list to \"print\": animals are: camelllamaalpacavicuna You might notice this when each of the elements of @array end with a newline. You expect to print one element per line, but notice that every line after the first is indented: this is a line\n this is another line\n this is the third line That extra space comes from the interpolation of the array. If you don't want to put anything between your array elements, don't use the array in double quotes. You can send it to print without them: print @lines; How do I traverse a directory tree? (contributed by brian d foy) The \"File::Find\" module, which comes with Perl, does all of the hard work to traverse a directory structure. It comes with Perl. You simply call the \"find\" subroutine with a callback subroutine and the directories you want to traverse: use File::Find;\n\nfind( \\&wanted, @directories );\n\nsub wanted {\n        # full path in $File::Find::name\n        # just filename in $_\n        ... do whatever you want to do ...\n        } The \"File::Find::Closures\", which you can download from CPAN , provides many ready-to-use subroutines that you can use with \"File::Find\". The \"File::Finder\", which you can download from CPAN , can help you create the callback subroutine using something closer to the syntax of the \"find\" command-line utility: use File::Find;\nuse File::Finder;\n\nmy $deep_dirs = File::Finder->depth->type('d')->ls->exec('rmdir','{}');\n\nfind( $deep_dirs->as_options, @places ); The \"File::Find::Rule\" module, which you can download from CPAN , has a similar interface, but does the traversal for you too: use File::Find::Rule;\n\nmy @files = File::Find::Rule->file()\n                                                 ->name( '*.pm' )\n                                                 ->in( @INC ); How do I delete a directory tree? (contributed by brian d foy) If you have an empty directory, you can use Perl's built-in \"rmdir\". If the directory is not empty (so, no files or subdirectories), you either have to empty it yourself (a lot of work) or use a module to help you. The \"File::Path\" module, which comes with Perl, has a \"rmtree\" which can take care of all of the hard work for you: use File::Path qw(rmtree);\n\nrmtree( \\@directories, 0, 0 ); The first argument to \"rmtree\" is either a string representing a directory path or an array reference. The second argument controls progress messages, and the third argument controls the handling of files you don't have permissions to delete. See the \"File::Path\" module for the details. How do I copy an entire directory? (contributed by Shlomi Fish) To do the equivalent of \"cp -R\" (i.e. copy an entire directory tree recursively) in portable Perl, you'll either need to write something yourself or find a good CPAN module such as File::Copy::Recursive. =head1 REVISION Revision: $Revision$ Date: $Date$ See perlfaq for source control details and availability.","Process Name":"perlfaq5","Link":"https:\/\/linux.die.net\/man\/1\/perlfaq5"}},{"Process":{"Description":"This section is surprisingly small because the rest of the FAQ is littered with answers involving regular expressions. For example, decoding a URL and checking whether something is a number are handled with regular expressions, but those answers are found elsewhere in this document (in perlfaq9: \"How do I decode or create those %-encodings on the web\" and perlfaq4: \"How do I determine whether a scalar is a number\/whole\/integer\/float\", to be precise). How can I hope to use regular expressions without creating illegible and unmaintainable code? Three techniques can make regular expressions maintainable and understandable. Comments Outside the Regex Describe what you're doing and how you're doing it, using normal Perl comments. # turn the line into the first word, a colon, and the\n# number of characters on the rest of the line\ns\/^(\\w+)(.*)\/ lc($1) . \":\" . length($2) \/meg; Comments Inside the Regex The \"\/x\" modifier causes whitespace to be ignored in a regex pattern (except in a character class), and also allows you to use normal comments there, too. As you can imagine, whitespace and comments help a lot. \"\/x\" lets you turn this: s{<(?:[^>'\"]*|\".*?\"|'.*?')+>}{}gs; into this: s{ <                    # opening angle bracket\n        (?:                 # Non-backreffing grouping paren\n                [^>'\"] *        # 0 or more things that are neither > nor ' nor \"\n                        |           #    or else\n                \".*?\"           # a section between double quotes (stingy match)\n                        |           #    or else\n                '.*?'           # a section between single quotes (stingy match)\n        ) +                 #   all occurring one or more times\n        >                   # closing angle bracket\n}{}gsx;                 # replace with nothing, i.e. delete It's still not quite so clear as prose, but it is very useful for describing the meaning of each part of the pattern. Different Delimiters While we normally think of patterns as being delimited with \"\/\" characters, they can be delimited by almost any character. perlre describes this. For example, the \"s\/\/\/\" above uses braces as delimiters. Selecting another delimiter can avoid quoting the delimiter within the pattern: s\/\\\/usr\\\/local\/\\\/usr\\\/share\/g;  # bad delimiter choice\ns#\/usr\/local#\/usr\/share#g;              # better I'm having trouble matching over more than one line. What's wrong? Either you don't have more than one line in the string you're looking at (probably), or else you aren't using the correct modifier(s) on your pattern (possibly). There are many ways to get multiline data into a string. If you want it to happen automatically while reading input, you'll want to set $\/ (probably to '' for paragraphs or \"undef\" for the whole file) to allow you to read more than one line at a time. Read perlre to help you decide which of \"\/s\" and \"\/m\" (or both) you might want to use: \"\/s\" allows dot to include newline, and \"\/m\" allows caret and dollar to match next to a newline, not just at the end of the string. You do need to make sure that you've actually got a multiline string in there. For example, this program detects duplicate words, even when they span line breaks (but not paragraph ones). For this example, we don't need \"\/s\" because we aren't using dot in a regular expression that we want to cross line boundaries. Neither do we need \"\/m\" because we aren't wanting caret or dollar to match at any point inside the record next to newlines. But it's imperative that $\/ be set to something other than the default, or else we won't actually ever have a multiline record read in. $\/ = '';                # read in whole paragraph, not just one line\nwhile ( <> ) {\n        while ( \/\\b([\\w'-]+)(\\s+\\1)+\\b\/gi ) {   # word starts alpha\n                print \"Duplicate $1 at paragraph $.\\n\";\n        }\n} Here's code that finds sentences that begin with \"From \" (which would be mangled by many mailers): $\/ = '';                # read in whole paragraph, not just one line\nwhile ( <> ) {\n        while ( \/^From \/gm ) { # \/m makes ^ match next to \\n\n        print \"leading from in paragraph $.\\n\";\n        }\n} Here's code that finds everything between START and END in a paragraph: undef $\/;               # read in whole file, not just one line or paragraph\nwhile ( <> ) {\n        while ( \/START(.*?)END\/sgm ) { # \/s makes . cross line boundaries\n            print \"$1\\n\";\n        }\n} How can I pull out lines between two patterns that are themselves on different lines? You can use Perl's somewhat exotic \"..\" operator (documented in perlop): perl -ne 'print if \/START\/ .. \/END\/' file1 file2 ... If you wanted text and not lines, you would use perl -0777 -ne 'print \"$1\\n\" while \/START(.*?)END\/gs' file1 file2 ... But if you want nested occurrences of \"START\" through \"END\", you'll run up against the problem described in the question in this section on matching balanced text. Here's another example of using \"..\": while (<>) {\n        $in_header =   1  .. \/^$\/;\n        $in_body   = \/^$\/ .. eof;\n# now choose between them\n} continue {\n        $. = 0 if eof;  # fix $.\n} How do I match XML , HTML , or other nasty, ugly things with a regex? (contributed by brian d foy) If you just want to get work done, use a module and forget about the regular expressions. The \"XML::Parser\" and \"HTML::Parser\" modules are good starts, although each namespace has other parsing modules specialized for certain tasks and different ways of doing it. Start at CPAN Search ( http:\/\/search.cpan.org ) and wonder at all the work people have done for you already! :) The problem with things such as XML is that they have balanced text containing multiple levels of balanced text, but sometimes it isn't balanced text, as in an empty tag (\"<br\/>\", for instance). Even then, things can occur out-of-order. Just when you think you've got a pattern that matches your input, someone throws you a curveball. If you'd like to do it the hard way, scratching and clawing your way toward a right answer but constantly being disappointed, beseiged by bug reports, and weary from the inordinate amount of time you have to spend reinventing a triangular wheel, then there are several things you can try before you give up in frustration: \u2022 Solve the balanced text problem from another question in perlfaq6 \u2022 Try the recursive regex features in Perl 5.10 and later. See perlre \u2022 Try defining a grammar using Perl 5.10's \"(?DEFINE)\" feature. \u2022 Break the problem down into sub-problems instead of trying to use a single regex \u2022 Convince everyone not to use XML or HTML in the first place Good luck! I put a regular expression into $\/ but it didn't work. What's wrong? $\/ has to be a string. You can use these examples if you really need to do this. If you have File::Stream, this is easy. use File::Stream;\n\nmy $stream = File::Stream->new(\n        $filehandle,\n        separator => qr\/\\s*,\\s*\/,\n        );\n\nprint \"$_\\n\" while <$stream>; If you don't have File::Stream, you have to do a little more work. You can use the four-argument form of sysread to continually add to a buffer. After you add to the buffer, you check if you have a complete line (using your regular expression). local $_ = \"\";\nwhile( sysread FH, $_, 8192, length ) {\n        while( s\/^((?s).*?)your_pattern\/\/ ) {\n                my $record = $1;\n                # do stuff here.\n        }\n} You can do the same thing with foreach and a match using the c flag and the \\G anchor, if you do not mind your entire file being in memory at the end. local $_ = \"\";\nwhile( sysread FH, $_, 8192, length ) {\n        foreach my $record ( m\/\\G((?s).*?)your_pattern\/gc ) {\n                # do stuff here.\n        }\nsubstr( $_, 0, pos ) = \"\" if pos;\n} How do I substitute case insensitively on the LHS while preserving case on the RHS ? Here's a lovely Perlish solution by Larry Rosler. It exploits properties of bitwise xor on ASCII strings. $_= \"this is a TEsT case\";\n\n$old = 'test';\n$new = 'success';\n\ns{(\\Q$old\\E)}\n{ uc $new | (uc $1 ^ $1) .\n        (uc(substr $1, -1) ^ substr $1, -1) x\n        (length($new) - length $1)\n}egi;\n\nprint; And here it is as a subroutine, modeled after the above:     sub preserve_case($$) {\n            my ($old, $new) = @_;\n            my $mask = uc $old ^ $old;\n\n            uc $new | $mask .\n                    substr($mask, -1) x (length($new) - length($old))\n}\n\n    $string = \"this is a TEsT case\";\n    $string =~ s\/(test)\/preserve_case($1, \"success\")\/egi;\n    print \"$string\\n\"; This prints: this is a SUcCESS case As an alternative, to keep the case of the replacement word if it is longer than the original, you can use this code, by Jeff Pinyan: sub preserve_case {\n        my ($from, $to) = @_;\n        my ($lf, $lt) = map length, @_;\n\n        if ($lt < $lf) { $from = substr $from, 0, $lt }\n        else { $from .= substr $to, $lf }\n\n        return uc $to | ($from ^ uc $from);\n        } This changes the sentence to \"this is a SUcCess case.\" Just to show that C programmers can write C in any programming language, if you prefer a more C-like solution, the following script makes the substitution have the same case, letter by letter, as the original. (It also happens to run about 240% slower than the Perlish solution runs.) If the substitution has more characters than the string being substituted, the case of the last character is used for the rest of the substitution. # Original by Nathan Torkington, massaged by Jeffrey Friedl\n#\nsub preserve_case($$)\n{\n        my ($old, $new) = @_;\n        my ($state) = 0; # 0 = no change; 1 = lc; 2 = uc\n        my ($i, $oldlen, $newlen, $c) = (0, length($old), length($new));\n        my ($len) = $oldlen < $newlen ? $oldlen : $newlen;\n\n        for ($i = 0; $i < $len; $i++) {\n                if ($c = substr($old, $i, 1), $c =~ \/[\\W\\d_]\/) {\n                        $state = 0;\n                } elsif (lc $c eq $c) {\n                        substr($new, $i, 1) = lc(substr($new, $i, 1));\n                        $state = 1;\n                } else {\n                        substr($new, $i, 1) = uc(substr($new, $i, 1));\n                        $state = 2;\n                }\n        }\n        # finish up with any remaining new (for when new is longer than old)\n        if ($newlen > $oldlen) {\n                if ($state == 1) {\n                        substr($new, $oldlen) = lc(substr($new, $oldlen));\n                } elsif ($state == 2) {\n                        substr($new, $oldlen) = uc(substr($new, $oldlen));\n                }\n        }\n        return $new;\n} How can I make \"\\w\" match national character sets? Put \"use locale;\" in your script. The \\w character class is taken from the current locale. See perllocale for details. How can I match a locale-smart version of \"\/[a-zA-Z]\/\"? You can use the POSIX character class syntax \"\/[[:alpha:]]\/\" documented in perlre. No matter which locale you are in, the alphabetic characters are the characters in \\w without the digits and the underscore. As a regex, that looks like \"\/[^\\W\\d_]\/\". Its complement, the non-alphabetics, is then everything in \\W along with the digits and the underscore, or \"\/[\\W\\d_]\/\". How can I quote a variable to use in a regex? The Perl parser will expand $variable and @variable references in regular expressions unless the delimiter is a single quote. Remember, too, that the right-hand side of a \"s\/\/\/\" substitution is considered a double-quoted string (see perlop for more details). Remember also that any regex special characters will be acted on unless you precede the substitution with \\Q. Here's an example: $string = \"Placido P. Octopus\";\n$regex  = \"P.\";\n\n$string =~ s\/$regex\/Polyp\/;\n# $string is now \"Polypacido P. Octopus\" Because \".\" is special in regular expressions, and can match any single character, the regex \"P.\" here has matched the <Pl> in the original string. To escape the special meaning of \".\", we use \"\\Q\": $string = \"Placido P. Octopus\";\n$regex  = \"P.\";\n\n$string =~ s\/\\Q$regex\/Polyp\/;\n# $string is now \"Placido Polyp Octopus\" The use of \"\\Q\" causes the <.> in the regex to be treated as a regular character, so that \"P.\" matches a \"P\" followed by a dot. What is \"\/o\" really for? (contributed by brian d foy) The \"\/o\" option for regular expressions (documented in perlop and perlreref) tells Perl to compile the regular expression only once. This is only useful when the pattern contains a variable. Perls 5.6 and later handle this automatically if the pattern does not change. Since the match operator \"m\/\/\", the substitution operator \"s\/\/\/\", and the regular expression quoting operator \"qr\/\/\" are double-quotish constructs, you can interpolate variables into the pattern. See the answer to \"How can I quote a variable to use in a regex?\" for more details. This example takes a regular expression from the argument list and prints the lines of input that match it: my $pattern = shift @ARGV;\n\nwhile( <> ) {\n        print if m\/$pattern\/;\n        } Versions of Perl prior to 5.6 would recompile the regular expression for each iteration, even if $pattern had not changed. The \"\/o\" would prevent this by telling Perl to compile the pattern the first time, then reuse that for subsequent iterations: my $pattern = shift @ARGV;\n\nwhile( <> ) {\n        print if m\/$pattern\/o; # useful for Perl < 5.6\n        } In versions 5.6 and later, Perl won't recompile the regular expression if the variable hasn't changed, so you probably don't need the \"\/o\" option. It doesn't hurt, but it doesn't help either. If you want any version of Perl to compile the regular expression only once even if the variable changes (thus, only using its initial value), you still need the \"\/o\". You can watch Perl's regular expression engine at work to verify for yourself if Perl is recompiling a regular expression. The \"use re 'debug'\" pragma (comes with Perl 5.005 and later) shows the details. With Perls before 5.6, you should see \"re\" reporting that its compiling the regular expression on each iteration. With Perl 5.6 or later, you should only see \"re\" report that for the first iteration. use re 'debug';\n\n$regex = 'Perl';\nforeach ( qw(Perl Java Ruby Python) ) {\n        print STDERR \"-\" x 73, \"\\n\";\n        print STDERR \"Trying $_...\\n\";\n        print STDERR \"\\t$_ is good!\\n\" if m\/$regex\/;\n        } How do I use a regular expression to strip C style comments from a file? While this actually can be done, it's much harder than you'd think. For example, this one-liner perl -0777 -pe 's{\/\\*.*?\\*\/}{}gs' foo.c will work in many but not all cases. You see, it's too simple-minded for certain kinds of C programs, in particular, those with what appear to be comments in quoted strings. For that, you'd need something like this, created by Jeffrey Friedl and later modified by Fred Curtis. $\/ = undef;\n$_ = <>;\ns#\/\\*[^*]*\\*+([^\/*][^*]*\\*+)*\/|(\"(\\\\.|[^\"\\\\])*\"|'(\\\\.|[^'\\\\])*'|.[^\/\"'\\\\]*)#defined $2 ? $2 : \"\"#gse;\nprint; This could, of course, be more legibly written with the \"\/x\" modifier, adding whitespace and comments. Here it is expanded, courtesy of Fred Curtis. s{\n   \/\\*         ##  Start of \/* ... *\/ comment\n   [^*]*\\*+    ##  Non-* followed by 1-or-more *'s\n   (\n     [^\/*][^*]*\\*+\n   )*          ##  0-or-more things which don't start with \/\n               ##    but do end with '*'\n   \/           ##  End of \/* ... *\/ comment\n\n |         ##     OR  various things which aren't comments:\n\n   (\n     \"           ##  Start of \" ... \" string\n     (\n       \\\\.           ##  Escaped char\n     |               ##    OR\n       [^\"\\\\]        ##  Non \"\\\n     )*\n     \"           ##  End of \" ... \" string\n\n   |         ##     OR\n\n     '           ##  Start of ' ... ' string\n     (\n       \\\\.           ##  Escaped char\n     |               ##    OR\n       [^'\\\\]        ##  Non '\\\n     )*\n     '           ##  End of ' ... ' string\n\n   |         ##     OR\n\n     .           ##  Anything other char\n     [^\/\"'\\\\]*   ##  Chars which doesn't start a comment, string or escape\n   )\n }{defined $2 ? $2 : \"\"}gxse; A slight modification also removes C ++ comments, possibly spanning multiple lines using a continuation character: s#\/\\*[^*]*\\*+([^\/*][^*]*\\*+)*\/|\/\/([^\\\\]|[^\\n][\\n]?)*?\\n|(\"(\\\\.|[^\"\\\\])*\"|'(\\\\.|[^'\\\\])*'|.[^\/\"'\\\\]*)#defined $3 ? $3 : \"\"#gse; Can I use Perl regular expressions to match balanced text? (contributed by brian d foy) Your first try should probably be the \"Text::Balanced\" module, which is in the Perl standard library since Perl 5.8. It has a variety of functions to deal with tricky text. The \"Regexp::Common\" module can also help by providing canned patterns you can use. As of Perl 5.10, you can match balanced text with regular expressions using recursive patterns. Before Perl 5.10, you had to resort to various tricks such as using Perl code in \"(??{})\" sequences. Here's an example using a recursive regular expression. The goal is to capture all of the text within angle brackets, including the text in nested angle brackets. This sample text has two \"major\" groups: a group with one level of nesting and a group with two levels of nesting. There are five total groups in angle brackets: I have some <brackets in <nested brackets> > and\n<another group <nested once <nested twice> > >\nand that's it. The regular expression to match the balanced text uses two new (to Perl 5.10) regular expression features. These are covered in perlre and this example is a modified version of one in that documentation. First, adding the new possesive \"+\" to any quantifier finds the longest match and does not backtrack. That's important since you want to handle any angle brackets through the recursion, not backtracking. The group \"[^<>]++\" finds one or more non-angle brackets without backtracking. Second, the new \"(?PARNO)\" refers to the sub-pattern in the particular capture buffer given by \"PARNO\". In the following regex, the first capture buffer finds (and remembers) the balanced text, and you need that same pattern within the first buffer to get past the nested text. That's the recursive part. The \"(?1)\" uses the pattern in the outer capture buffer as an independent part of the regex. Putting it all together, you have: #!\/usr\/local\/bin\/perl5.10.0\n\nmy $string =<<\"HERE\";\nI have some <brackets in <nested brackets> > and\n<another group <nested once <nested twice> > >\nand that's it.\nHERE\n\nmy @groups = $string =~ m\/\n                (                   # start of capture buffer 1\n                <                   # match an opening angle bracket\n                        (?:\n                                [^<>]++     # one or more non angle brackets, non backtracking\n                                  |\n                                (?1)        # found < or >, so recurse to capture buffer 1\n                        )*\n                >                   # match a closing angle bracket\n                )                   # end of capture buffer 1\n                \/xg;\n\n$\" = \"\\n\\t\";\nprint \"Found:\\n\\t@groups\\n\"; The output shows that Perl found the two major groups: Found:\n        <brackets in <nested brackets> >\n        <another group <nested once <nested twice> > > With a little extra work, you can get the all of the groups in angle brackets even if they are in other angle brackets too. Each time you get a balanced match, remove its outer delimiter (that's the one you just matched so don't match it again) and add it to a queue of strings to process. Keep doing that until you get no matches: #!\/usr\/local\/bin\/perl5.10.0\n\nmy @queue =<<\"HERE\";\nI have some <brackets in <nested brackets> > and\n<another group <nested once <nested twice> > >\nand that's it.\nHERE\n\nmy $regex = qr\/\n                (                   # start of bracket 1\n                <                   # match an opening angle bracket\n                        (?:\n                                [^<>]++     # one or more non angle brackets, non backtracking\n                                  |\n                                (?1)        # recurse to bracket 1\n                        )*\n                >                   # match a closing angle bracket\n                )                   # end of bracket 1\n                \/x;\n\n$\" = \"\\n\\t\";\n\nwhile( @queue )\n        {\n        my $string = shift @queue;\n\n        my @groups = $string =~ m\/$regex\/g;\n        print \"Found:\\n\\t@groups\\n\\n\" if @groups;\n\n        unshift @queue, map { s\/^<\/\/; s\/>$\/\/; $_ } @groups;\n        } The output shows all of the groups. The outermost matches show up first and the nested matches so up later: Found:\n        <brackets in <nested brackets> >\n        <another group <nested once <nested twice> > >\n\nFound:\n        <nested brackets>\n\nFound:\n        <nested once <nested twice> >\n\nFound:\n        <nested twice> What does it mean that regexes are greedy? How can I get around it? Most people mean that greedy regexes match as much as they can. Technically speaking, it's actually the quantifiers ( \"?\", \"*\", \"+\", \"{}\") that are greedy rather than the whole pattern; Perl prefers local greed and immediate gratification to overall greed. To get non-greedy versions of the same quantifiers, use ( \"??\", \"*?\", \"+?\", \"{}?\"). An example: $s1 = $s2 = \"I am very very cold\";\n$s1 =~ s\/ve.*y \/\/;      # I am cold\n$s2 =~ s\/ve.*?y \/\/;     # I am very cold Notice how the second substitution stopped matching as soon as it encountered \"y \". The \"*?\" quantifier effectively tells the regular expression engine to find a match as quickly as possible and pass control on to whatever is next in line, like you would if you were playing hot potato. How do I process each word on each line? Use the split function: while (<>) {\n        foreach $word ( split ) {\n                # do something with $word here\n        }\n} Note that this isn't really a word in the English sense; it's just chunks of consecutive non-whitespace characters. To work with only alphanumeric sequences (including underscores), you might consider while (<>) {\n        foreach $word (m\/(\\w+)\/g) {\n                # do something with $word here\n        }\n} How can I print out a word-frequency or line-frequency summary? To do this, you have to parse out each word in the input stream. We'll pretend that by word you mean chunk of alphabetics, hyphens, or apostrophes, rather than the non-whitespace chunk idea of a word given in the previous question: while (<>) {\n        while ( \/(\\b[^\\W_\\d][\\w'-]+\\b)\/g ) {   # misses \"`sheep'\"\n                $seen{$1}++;\n        }\n}\n\nwhile ( ($word, $count) = each %seen ) {\n        print \"$count $word\\n\";\n        } If you wanted to do the same thing for lines, you wouldn't need a regular expression: while (<>) {\n        $seen{$_}++;\n        }\n\nwhile ( ($line, $count) = each %seen ) {\n        print \"$count $line\";\n} If you want these output in a sorted order, see perlfaq4: \"How do I sort a hash (optionally by value instead of key)?\". How can I do approximate matching? See the module String::Approx available from CPAN . How do I efficiently match many regular expressions at once? ( contributed by brian d foy ) Avoid asking Perl to compile a regular expression every time you want to match it. In this example, perl must recompile the regular expression for every iteration of the \"foreach\" loop since it has no way to know what $pattern will be. @patterns = qw( foo bar baz );\n\nLINE: while( <DATA> )\n        {\n        foreach $pattern ( @patterns )\n                {\n                if( \/\\b$pattern\\b\/i )\n                        {\n                        print;\n                        next LINE;\n                        }\n                }\n        } The \"qr\/\/\" operator showed up in perl 5.005. It compiles a regular expression, but doesn't apply it. When you use the pre-compiled version of the regex, perl does less work. In this example, I inserted a \"map\" to turn each pattern into its pre-compiled form. The rest of the script is the same, but faster. @patterns = map { qr\/\\b$_\\b\/i } qw( foo bar baz );\n\nLINE: while( <> )\n        {\n        foreach $pattern ( @patterns )\n                {\n                if( \/$pattern\/ )\n                        {\n                        print;\n                        next LINE;\n                        }\n                }\n        } In some cases, you may be able to make several patterns into a single regular expression. Beware of situations that require backtracking though. $regex = join '|', qw( foo bar baz );\n\nLINE: while( <> )\n        {\n        print if \/\\b(?:$regex)\\b\/i;\n        } For more details on regular expression efficiency, see Mastering Regular Expressions by Jeffrey Freidl. He explains how regular expressions engine work and why some patterns are surprisingly inefficient. Once you understand how perl applies regular expressions, you can tune them for individual situations. Why don't word-boundary searches with \"\\b\" work for me? (contributed by brian d foy) Ensure that you know what \\b really does: it's the boundary between a word character, \\w, and something that isn't a word character. That thing that isn't a word character might be \\W, but it can also be the start or end of the string. It's not (not!) the boundary between whitespace and non-whitespace, and it's not the stuff between words we use to create sentences. In regex speak, a word boundary (\\b) is a \"zero width assertion\", meaning that it doesn't represent a character in the string, but a condition at a certain position. For the regular expression, \/\\bPerl\\b\/, there has to be a word boundary before the \"P\" and after the \"l\". As long as something other than a word character precedes the \"P\" and succeeds the \"l\", the pattern will match. These strings match \/\\bPerl\\b\/. \"Perl\"    # no word char before P or after l\n\"Perl \"   # same as previous (space is not a word char)\n\"'Perl'\"  # the ' char is not a word char\n\"Perl's\"  # no word char before P, non-word char after \"l\" These strings do not match \/\\bPerl\\b\/. \"Perl_\"   # _ is a word char!\n\"Perler\"  # no word char before P, but one after l You don't have to use \\b to match words though. You can look for non-word characters surrounded by word characters. These strings match the pattern \/\\b'\\b\/. \"don't\"   # the ' char is surrounded by \"n\" and \"t\"\n\"qep'a'\"  # the ' char is surrounded by \"p\" and \"a\" These strings do not match \/\\b'\\b\/. \"foo'\"    # there is no word char after non-word ' You can also use the complement of \\b, \\B, to specify that there should not be a word boundary. In the pattern \/\\Bam\\B\/, there must be a word character before the \"a\" and after the \"m\". These patterns match \/\\Bam\\B\/: \"llama\"   # \"am\" surrounded by word chars\n\"Samuel\"  # same These strings do not match \/\\Bam\\B\/ \"Sam\"      # no word boundary before \"a\", but one after \"m\"\n\"I am Sam\" # \"am\" surrounded by non-word chars Why does using $&, $', or $' slow my program down? (contributed by Anno Siegel) Once Perl sees that you need one of these variables anywhere in the program, it provides them on each and every pattern match. That means that on every pattern match the entire string will be copied, part of it to $', part to $&, and part to $'. Thus the penalty is most severe with long strings and patterns that match often. Avoid $&, $', and $' if you can, but if you can't, once you've used them at all, use them at will because you've already paid the price. Remember that some algorithms really appreciate them. As of the 5.005 release, the $& variable is no longer \"expensive\" the way the other two are. Since Perl 5.6.1 the special variables @- and @+ can functionally replace $', $& and $'. These arrays contain pointers to the beginning and end of each match (see perlvar for the full story), so they give you essentially the same information, but without the risk of excessive string copying. Perl 5.10 added three specials, \"${^MATCH}\", \"${^PREMATCH}\", and \"${^POSTMATCH}\" to do the same job but without the global performance penalty. Perl 5.10 only sets these variables if you compile or execute the regular expression with the \"\/p\" modifier. What good is \"\\G\" in a regular expression? You use the \"\\G\" anchor to start the next match on the same string where the last match left off. The regular expression engine cannot skip over any characters to find the next match with this anchor, so \"\\G\" is similar to the beginning of string anchor, \"^\". The \"\\G\" anchor is typically used with the \"g\" flag. It uses the value of \"pos()\" as the position to start the next match. As the match operator makes successive matches, it updates \"pos()\" with the position of the next character past the last match (or the first character of the next match, depending on how you like to look at it). Each string has its own \"pos()\" value. Suppose you want to match all of consecutive pairs of digits in a string like \"1122a44\" and stop matching when you encounter non-digits. You want to match 11 and 22 but the letter <a> shows up between 22 and 44 and you want to stop at \"a\". Simply matching pairs of digits skips over the \"a\" and still matches 44. $_ = \"1122a44\";\nmy @pairs = m\/(\\d\\d)\/g;   # qw( 11 22 44 ) If you use the \"\\G\" anchor, you force the match after 22 to start with the \"a\". The regular expression cannot match there since it does not find a digit, so the next match fails and the match operator returns the pairs it already found. $_ = \"1122a44\";\nmy @pairs = m\/\\G(\\d\\d)\/g; # qw( 11 22 ) You can also use the \"\\G\" anchor in scalar context. You still need the \"g\" flag. $_ = \"1122a44\";\nwhile( m\/\\G(\\d\\d)\/g )\n        {\n        print \"Found $1\\n\";\n        } After the match fails at the letter \"a\", perl resets \"pos()\" and the next match on the same string starts at the beginning. $_ = \"1122a44\";\nwhile( m\/\\G(\\d\\d)\/g )\n        {\n        print \"Found $1\\n\";\n        }\n\nprint \"Found $1 after while\" if m\/(\\d\\d)\/g; # finds \"11\" You can disable \"pos()\" resets on fail with the \"c\" flag, documented in perlop and perlreref. Subsequent matches start where the last successful match ended (the value of \"pos()\") even if a match on the same string has failed in the meantime. In this case, the match after the \"while()\" loop starts at the \"a\" (where the last match stopped), and since it does not use any anchor it can skip over the \"a\" to find 44. $_ = \"1122a44\";\nwhile( m\/\\G(\\d\\d)\/gc )\n        {\n        print \"Found $1\\n\";\n        }\n\nprint \"Found $1 after while\" if m\/(\\d\\d)\/g; # finds \"44\" Typically you use the \"\\G\" anchor with the \"c\" flag when you want to try a different match if one fails, such as in a tokenizer. Jeffrey Friedl offers this example which works in 5.004 or later. while (<>) {\n        chomp;\n        PARSER: {\n                m\/ \\G( \\d+\\b    )\/gcx   && do { print \"number: $1\\n\";  redo; };\n                m\/ \\G( \\w+      )\/gcx   && do { print \"word:   $1\\n\";  redo; };\n                m\/ \\G( \\s+      )\/gcx   && do { print \"space:  $1\\n\";  redo; };\n                m\/ \\G( [^\\w\\d]+ )\/gcx   && do { print \"other:  $1\\n\";  redo; };\n        }\n} For each line, the \"PARSER\" loop first tries to match a series of digits followed by a word boundary. This match has to start at the place the last match left off (or the beginning of the string on the first match). Since \"m\/ \\G( \\d+\\b )\/gcx\" uses the \"c\" flag, if the string does not match that regular expression, perl does not reset pos() and the next match starts at the same position to try a different pattern. Are Perl regexes DFAs or NFAs? Are they POSIX compliant? While it's true that Perl's regular expressions resemble the DFAs (deterministic finite automata) of the egrep(1) program, they are in fact implemented as NFAs (non-deterministic finite automata) to allow backtracking and backreferencing. And they aren't POSIX-style either, because those guarantee worst-case behavior for all cases. (It seems that some people prefer guarantees of consistency, even when what's guaranteed is slowness.) See the book \"Mastering Regular Expressions\" (from O'Reilly) by Jeffrey Friedl for all the details you could ever hope to know on these matters (a full citation appears in perlfaq2). What's wrong with using grep in a void context? The problem is that grep builds a return list, regardless of the context. This means you're making Perl go to the trouble of building a list that you then just throw away. If the list is large, you waste both time and space. If your intent is to iterate over the list, then use a for loop for this purpose. In perls older than 5.8.1, map suffers from this problem as well. But since 5.8.1, this has been fixed, and map is context aware - in void context, no lists are constructed. How can I match strings with multibyte characters? Starting from Perl 5.6 Perl has had some level of multibyte character support. Perl 5.8 or later is recommended. Supported multibyte character repertoires include Unicode, and legacy encodings through the Encode module. See perluniintro, perlunicode, and Encode. If you are stuck with older Perls, you can do Unicode with the \"Unicode::String\" module, and character conversions using the \"Unicode::Map8\" and \"Unicode::Map\" modules. If you are using Japanese encodings, you might try using the jperl 5.005_03. Finally, the following set of approaches was offered by Jeffrey Friedl, whose article in issue #5 of The Perl Journal talks about this very matter. Let's suppose you have some weird Martian encoding where pairs of ASCII uppercase letters encode single Martian letters (i.e. the two bytes \" CV \" make a single Martian letter, as do the two bytes \" SG \", \" VS \", \" XX \", etc.). Other bytes represent single characters, just like ASCII . So, the string of Martian \"I am CVSGXX !\" uses 12 bytes to encode the nine characters 'I', ' ', 'a', 'm', ' ', ' CV ', ' SG ', ' XX ', '!'. Now, say you want to search for the single character \"\/GX\/\". Perl doesn't know about Martian, so it'll find the two bytes \" GX \" in the \"I am CVSGXX !\" string, even though that character isn't there: it just looks like it is because \" SG \" is next to \" XX \", but there's no real \" GX \". This is a big problem. Here are a few ways, all painful, to deal with it: # Make sure adjacent \"martian\" bytes are no longer adjacent.\n$martian =~ s\/([A-Z][A-Z])\/ $1 \/g;\n\nprint \"found GX!\\n\" if $martian =~ \/GX\/; Or like this: @chars = $martian =~ m\/([A-Z][A-Z]|[^A-Z])\/g;\n# above is conceptually similar to:     @chars = $text =~ m\/(.)\/g;\n#\nforeach $char (@chars) {\nprint \"found GX!\\n\", last if $char eq 'GX';\n} Or like this: while ($martian =~ m\/\\G([A-Z][A-Z]|.)\/gs) {  # \\G probably unneeded\n        print \"found GX!\\n\", last if $1 eq 'GX';\n        } Here's another, slightly less painful, way to do it from Benjamin Goldberg, who uses a zero-width negative look-behind assertion. print \"found GX!\\n\" if  $martian =~ m\/\n        (?<![A-Z])\n        (?:[A-Z][A-Z])*?\n        GX\n        \/x; This succeeds if the \"martian\" character GX is in the string, and fails otherwise. If you don't like using (?<!), a zero-width negative look-behind assertion, you can replace (?<![A-Z]) with (?:^|[^A-Z]). It does have the drawback of putting the wrong thing in $-[0] and $+[0], but this usually can be worked around. How do I match a regular expression that's in a variable? , (contributed by brian d foy) We don't have to hard-code patterns into the match operator (or anything else that works with regular expressions). We can put the pattern in a variable for later use. The match operator is a double quote context, so you can interpolate your variable just like a double quoted string. In this case, you read the regular expression as user input and store it in $regex. Once you have the pattern in $regex, you use that variable in the match operator. chomp( my $regex = <STDIN> );\n\nif( $string =~ m\/$regex\/ ) { ... } Any regular expression special characters in $regex are still special, and the pattern still has to be valid or Perl will complain. For instance, in this pattern there is an unpaired parenthesis. my $regex = \"Unmatched ( paren\";\n\n\"Two parens to bind them all\" =~ m\/$regex\/; When Perl compiles the regular expression, it treats the parenthesis as the start of a memory match. When it doesn't find the closing parenthesis, it complains: Unmatched ( in regex; marked by <-- HERE in m\/Unmatched ( <-- HERE  paren\/ at script line 3. You can get around this in several ways depending on our situation. First, if you don't want any of the characters in the string to be special, you can escape them with \"quotemeta\" before you use the string. chomp( my $regex = <STDIN> );\n$regex = quotemeta( $regex );\n\nif( $string =~ m\/$regex\/ ) { ... } You can also do this directly in the match operator using the \"\\Q\" and \"\\E\" sequences. The \"\\Q\" tells Perl where to start escaping special characters, and the \"\\E\" tells it where to stop (see perlop for more details). chomp( my $regex = <STDIN> );\n\nif( $string =~ m\/\\Q$regex\\E\/ ) { ... } Alternately, you can use \"qr\/\/\", the regular expression quote operator (see perlop for more details). It quotes and perhaps compiles the pattern, and you can apply regular expression flags to the pattern. chomp( my $input = <STDIN> );\n\nmy $regex = qr\/$input\/is;\n\n$string =~ m\/$regex\/  # same as m\/$input\/is; You might also want to trap any errors by wrapping an \"eval\" block around the whole thing. chomp( my $input = <STDIN> );\n\neval {\n        if( $string =~ m\/\\Q$input\\E\/ ) { ... }\n        };\nwarn $@ if $@; Or... my $regex = eval { qr\/$input\/is };\nif( defined $regex ) {\n        $string =~ m\/$regex\/;\n        }\nelse {\n        warn $@;\n        }","Process Name":"perlfaq6","Link":"https:\/\/linux.die.net\/man\/1\/perlfaq6"}},{"Process":{"Description":"This section deals with general Perl language issues that don't clearly fit into any of the other sections. Can I get a BNF\/yacc\/RE for the Perl language? There is no BNF , but you can paw your way through the yacc grammar in perly.y in the source distribution if you're particularly brave. The grammar relies on very smart tokenizing code, so be prepared to venture into toke.c as well. In the words of Chaim Frenkel: \"Perl's grammar can not be reduced to BNF . The work of parsing perl is distributed between yacc, the lexer, smoke and mirrors.\" What are all these $@%&* punctuation signs, and how do I know when to use them? They are type specifiers, as detailed in perldata: $ for scalar values (number, string or reference)\n@ for arrays\n% for hashes (associative arrays)\n& for subroutines (aka functions, procedures, methods)\n* for all types of that symbol name.  In version 4 you used them like\n  pointers, but in modern perls you can just use references. There are couple of other symbols that you're likely to encounter that aren't really type specifiers: <> are used for inputting a record from a filehandle.\n\\  takes a reference to something. Note that < FILE > is neither the type specifier for files nor the name of the handle. It is the \"<>\" operator applied to the handle FILE . It reads one line (well, record--see \"$\/\" in perlvar) from the handle FILE in scalar context, or all lines in list context. When performing open, close, or any other operation besides \"<>\" on files, or even when talking about the handle, do not use the brackets. These are correct: \"eof(FH)\", \"seek(FH, 0, 2)\" and \"copying from STDIN to FILE \". Do I always\/never have to quote my strings or use semicolons and commas? Normally, a bareword doesn't need to be quoted, but in most cases probably should be (and must be under \"use strict\"). But a hash key consisting of a simple word (that isn't the name of a defined subroutine) and the left-hand operand to the \"=>\" operator both count as though they were quoted: This                    is like this\n------------            ---------------\n$foo{line}              $foo{'line'}\nbar => stuff            'bar' => stuff The final semicolon in a block is optional, as is the final comma in a list. Good style (see perlstyle) says to put them in except for one-liners: if ($whoops) { exit 1 }\n@nums = (1, 2, 3);\n\nif ($whoops) {\n        exit 1;\n}\n\n@lines = (\n\"There Beren came from mountains cold\",\n\"And lost he wandered under leaves\",\n); How do I skip some return values? One way is to treat the return values as a list and index into it: $dir = (getpwnam($user))[7]; Another way is to use undef as an element on the left-hand-side: ($dev, $ino, undef, undef, $uid, $gid) = stat($file); You can also use a list slice to select only the elements that you need: ($dev, $ino, $uid, $gid) = ( stat($file) )[0,1,4,5]; How do I temporarily block warnings? If you are running Perl 5.6.0 or better, the \"use warnings\" pragma allows fine control of what warning are produced. See perllexwarn for more details. {\nno warnings;          # temporarily turn off warnings\n$a = $b + $c;         # I know these might be undef\n} Additionally, you can enable and disable categories of warnings. You turn off the categories you want to ignore and you can still get other categories of warnings. See perllexwarn for the complete details, including the category names and hierarchy. {\nno warnings 'uninitialized';\n$a = $b + $c;\n} If you have an older version of Perl, the $^W variable (documented in perlvar) controls runtime warnings for a block: {\nlocal $^W = 0;        # temporarily turn off warnings\n$a = $b + $c;         # I know these might be undef\n} Note that like all the punctuation variables, you cannot currently use my() on $^W, only local(). What's an extension? An extension is a way of calling compiled C code from Perl. Reading perlxstut is a good place to learn more about extensions. Why do Perl operators have different precedence than C operators? Actually, they don't. All C operators that Perl copies have the same precedence in Perl as they do in C. The problem is with operators that C doesn't have, especially functions that give a list context to everything on their right, eg. print, chmod, exec, and so on. Such functions are called \"list operators\" and appear as such in the precedence table in perlop. A common mistake is to write: unlink $file || die \"snafu\"; This gets interpreted as: unlink ($file || die \"snafu\"); To avoid this problem, either put in extra parentheses or use the super low precedence \"or\" operator: (unlink $file) || die \"snafu\";\nunlink $file or die \"snafu\"; The \"English\" operators ( \"and\", \"or\", \"xor\", and \"not\") deliberately have precedence lower than that of list operators for just such situations as the one above. Another operator with surprising precedence is exponentiation. It binds more tightly even than unary minus, making \"-2**2\" produce a negative not a positive four. It is also right-associating, meaning that \"2**3**2\" is two raised to the ninth power, not eight squared. Although it has the same precedence as in C, Perl's \"?:\" operator produces an lvalue. This assigns $x to either $a or $b, depending on the trueness of $maybe: ($maybe ? $a : $b) = $x; How do I declare\/create a structure? In general, you don't \"declare\" a structure. Just use a (probably anonymous) hash reference. See perlref and perldsc for details. Here's an example: $person = {};                   # new anonymous hash\n$person->{AGE}  = 24;           # set field AGE to 24\n$person->{NAME} = \"Nat\";        # set field NAME to \"Nat\" If you're looking for something a bit more rigorous, try perltoot. How do I create a module? (contributed by brian d foy) perlmod, perlmodlib, perlmodstyle explain modules in all the gory details. perlnewmod gives a brief overview of the process along with a couple of suggestions about style. If you need to include C code or C library interfaces in your module, you'll need h2xs. h2xs will create the module distribution structure and the initial interface files you'll need. perlxs and perlxstut explain the details. If you don't need to use C code, other tools such as ExtUtils::ModuleMaker and Module::Starter, can help you create a skeleton module distribution. You may also want to see Sam Tregar's \"Writing Perl Modules for CPAN \" ( http:\/\/apress.com\/book\/bookDisplay.html?bID=14 ) which is the best hands-on guide to creating module distributions. How do I adopt or take over a module already on CPAN ? (contributed by brian d foy) The full answer to this can be found at http:\/\/cpan.org\/modules\/04pause.html#takeover The easiest way to take over a module is to have the current module maintainer either make you a co-maintainer or transfer the module to you. If you can't reach the author for some reason (e.g. email bounces), the PAUSE admins at modules@perl.org can help. The PAUSE admins treat each case individually. \u2022 Get a login for the Perl Authors Upload Server ( PAUSE ) if you don't already have one: http:\/\/pause.perl.org \u2022 Write to modules@perl.org explaining what you did to contact the current maintainer. The PAUSE admins will also try to reach the maintainer. \u2022 Post a public message in a heavily trafficked site announcing your intention to take over the module. \u2022 Wait a bit. The PAUSE admins don't want to act too quickly in case the current maintainer is on holiday. If there's no response to private communication or the public post, a PAUSE admin can transfer it to you. How do I create a class? (contributed by brian d foy) In Perl, a class is just a package, and methods are just subroutines. Perl doesn't get more formal than that and lets you set up the package just the way that you like it (that is, it doesn't set up anything for you). The Perl documentation has several tutorials that cover class creation, including perlboot (Barnyard Object Oriented Tutorial), perltoot (Tom's Object Oriented Tutorial), perlbot (Bag o' Object Tricks), and perlobj. How can I tell if a variable is tainted? You can use the tainted() function of the Scalar::Util module, available from CPAN (or included with Perl since release 5.8.0). See also \"Laundering and Detecting Tainted Data\" in perlsec. What's a closure? Closures are documented in perlref. Closure is a computer science term with a precise but hard-to-explain meaning. Usually, closures are implemented in Perl as anonymous subroutines with lasting references to lexical variables outside their own scopes. These lexicals magically refer to the variables that were around when the subroutine was defined (deep binding). Closures are most often used in programming languages where you can have the return value of a function be itself a function, as you can in Perl. Note that some languages provide anonymous functions but are not capable of providing proper closures: the Python language, for example. For more information on closures, check out any textbook on functional programming. Scheme is a language that not only supports but encourages closures. Here's a classic non-closure function-generating function: sub add_function_generator {\n        return sub { shift() + shift() };\n        }\n\n$add_sub = add_function_generator();\n$sum = $add_sub->(4,5);                # $sum is 9 now. The anonymous subroutine returned by add_function_generator() isn't technically a closure because it refers to no lexicals outside its own scope. Using a closure gives you a function template with some customization slots left out to be filled later. Contrast this with the following make_adder() function, in which the returned anonymous function contains a reference to a lexical variable outside the scope of that function itself. Such a reference requires that Perl return a proper closure, thus locking in for all time the value that the lexical had when the function was created. sub make_adder {\n        my $addpiece = shift;\n        return sub { shift() + $addpiece };\n}\n\n$f1 = make_adder(20);\n$f2 = make_adder(555); Now \"&$f1($n)\" is always 20 plus whatever $n you pass in, whereas \"&$f2($n)\" is always 555 plus whatever $n you pass in. The $addpiece in the closure sticks around. Closures are often used for less esoteric purposes. For example, when you want to pass in a bit of code into a function: my $line;\ntimeout( 30, sub { $line = <STDIN> } ); If the code to execute had been passed in as a string, '$line = <STDIN>', there would have been no way for the hypothetical timeout() function to access the lexical variable $line back in its caller's scope. Another use for a closure is to make a variable private to a named subroutine, e.g. a counter that gets initialized at creation time of the sub and can only be modified from within the sub. This is sometimes used with a BEGIN block in package files to make sure a variable doesn't get meddled with during the lifetime of the package: BEGIN {\n        my $id = 0;\n        sub next_id { ++$id }\n} This is discussed in more detail in perlsub, see the entry on Persistent Private Variables. What is variable suicide and how can I prevent it? This problem was fixed in perl 5.004_05, so preventing it means upgrading your version of perl. ;) Variable suicide is when you (temporarily or permanently) lose the value of a variable. It is caused by scoping through my() and local() interacting with either closures or aliased foreach() iterator variables and subroutine arguments. It used to be easy to inadvertently lose a variable's value this way, but now it's much harder. Take this code: my $f = 'foo';\nsub T {\n        while ($i++ < 3) { my $f = $f; $f .= \"bar\"; print $f, \"\\n\" }\n        }\n\nT;\nprint \"Finally $f\\n\"; If you are experiencing variable suicide, that \"my $f\" in the subroutine doesn't pick up a fresh copy of the $f whose value is <foo>. The output shows that inside the subroutine the value of $f leaks through when it shouldn't, as in this output: foobar\nfoobarbar\nfoobarbarbar\nFinally foo The $f that has \"bar\" added to it three times should be a new $f \"my $f\" should create a new lexical variable each time through the loop. The expected output is: foobar\nfoobar\nfoobar\nFinally foo How can I pass\/return a {Function, FileHandle, Array, Hash, Method, Regex}? With the exception of regexes, you need to pass references to these objects. See \"Pass by Reference\" in perlsub for this particular question, and perlref for information on references. See \"Passing Regexes\", later in perlfaq7, for information on passing regular expressions. Passing Variables and Functions Regular variables and functions are quite easy to pass: just pass in a reference to an existing or anonymous variable or function: func( \\$some_scalar );\n\nfunc( \\@some_array  );\nfunc( [ 1 .. 10 ]   );\n\nfunc( \\%some_hash   );\nfunc( { this => 10, that => 20 }   );\n\nfunc( \\&some_func   );\nfunc( sub { $_[0] ** $_[1] }   ); Passing Filehandles As of Perl 5.6, you can represent filehandles with scalar variables which you treat as any other scalar. open my $fh, $filename or die \"Cannot open $filename! $!\";\nfunc( $fh );\n\nsub func {\n        my $passed_fh = shift;\n\n        my $line = <$passed_fh>;\n        } Before Perl 5.6, you had to use the *FH or \"\\*FH\" notations. These are \"typeglobs\"--see \"Typeglobs and Filehandles\" in perldata and especially \"Pass by Reference\" in perlsub for more information. Passing Regexes To pass regexes around, you'll need to be using a release of Perl sufficiently recent as to support the \"qr\/\/\" construct, pass around strings and use an exception-trapping eval, or else be very, very clever. Here's an example of how to pass in a string to be regex compared using \"qr\/\/\": sub compare($$) {\n        my ($val1, $regex) = @_;\n        my $retval = $val1 =~ \/$regex\/;\nreturn $retval;\n}\n$match = compare(\"old McDonald\", qr\/d.*D\/i); Notice how \"qr\/\/\" allows flags at the end. That pattern was compiled at compile time, although it was executed later. The nifty \"qr\/\/\" notation wasn't introduced until the 5.005 release. Before that, you had to approach this problem much less intuitively. For example, here it is again if you don't have \"qr\/\/\": sub compare($$) {\n        my ($val1, $regex) = @_;\n        my $retval = eval { $val1 =~ \/$regex\/ };\ndie if $@;\nreturn $retval;\n}\n\n$match = compare(\"old McDonald\", q\/($?i)d.*D\/); Make sure you never say something like this: return eval \"\\$val =~ \/$regex\/\";   # WRONG or someone can sneak shell escapes into the regex due to the double interpolation of the eval and the double-quoted string. For example: $pattern_of_evil = 'danger ${ system(\"rm -rf * &\") } danger';\n\neval \"\\$string =~ \/$pattern_of_evil\/\"; Those preferring to be very, very clever might see the O'Reilly book, Mastering Regular Expressions, by Jeffrey Friedl. Page 273's Build_MatchMany_Function() is particularly interesting. A complete citation of this book is given in perlfaq2. Passing Methods To pass an object method into a subroutine, you can do this: call_a_lot(10, $some_obj, \"methname\")\nsub call_a_lot {\n        my ($count, $widget, $trick) = @_;\n        for (my $i = 0; $i < $count; $i++) {\n                $widget->$trick();\n        }\n} Or, you can use a closure to bundle up the object, its method call, and arguments: my $whatnot =  sub { $some_obj->obfuscate(@args) };\nfunc($whatnot);\nsub func {\n        my $code = shift;\n        &$code();\n} You could also investigate the can() method in the UNIVERSAL class (part of the standard perl distribution). How do I create a static variable? (contributed by brian d foy) In Perl 5.10, declare the variable with \"state\". The \"state\" declaration creates the lexical variable that persists between calls to the subroutine: sub counter { state $count = 1; $counter++ } You can fake a static variable by using a lexical variable which goes out of scope. In this example, you define the subroutine \"counter\", and it uses the lexical variable $count. Since you wrap this in a BEGIN block, $count is defined at compile-time, but also goes out of scope at the end of the BEGIN block. The BEGIN block also ensures that the subroutine and the value it uses is defined at compile-time so the subroutine is ready to use just like any other subroutine, and you can put this code in the same place as other subroutines in the program text (i.e. at the end of the code, typically). The subroutine \"counter\" still has a reference to the data, and is the only way you can access the value (and each time you do, you increment the value). The data in chunk of memory defined by $count is private to \"counter\". BEGIN {\n        my $count = 1;\n        sub counter { $count++ }\n}\n\nmy $start = counter();\n\n.... # code that calls counter();\n\nmy $end = counter(); In the previous example, you created a function-private variable because only one function remembered its reference. You could define multiple functions while the variable is in scope, and each function can share the \"private\" variable. It's not really \"static\" because you can access it outside the function while the lexical variable is in scope, and even create references to it. In this example, \"increment_count\" and \"return_count\" share the variable. One function adds to the value and the other simply returns the value. They can both access $count, and since it has gone out of scope, there is no other way to access it. BEGIN {\n        my $count = 1;\n        sub increment_count { $count++ }\n        sub return_count    { $count }\n} To declare a file-private variable, you still use a lexical variable. A file is also a scope, so a lexical variable defined in the file cannot be seen from any other file. See \"Persistent Private Variables\" in perlsub for more information. The discussion of closures in perlref may help you even though we did not use anonymous subroutines in this answer. See \"Persistent Private Variables\" in perlsub for details. What's the difference between dynamic and lexical (static) scoping? Between local() and my()? \"local($x)\" saves away the old value of the global variable $x and assigns a new value for the duration of the subroutine which is visible in other functions called from that subroutine. This is done at run-time, so is called dynamic scoping. local() always affects global variables, also called package variables or dynamic variables. \"my($x)\" creates a new variable that is only visible in the current subroutine. This is done at compile-time, so it is called lexical or static scoping. my() always affects private variables, also called lexical variables or (improperly) static(ly scoped) variables. For instance: sub visible {\n        print \"var has value $var\\n\";\n        }\n\nsub dynamic {\n        local $var = 'local';   # new temporary value for the still-global\n        visible();              #   variable called $var\n        }\n\nsub lexical {\n        my $var = 'private';    # new private variable, $var\n        visible();              # (invisible outside of sub scope)\n        }\n\n$var = 'global';\n\nvisible();                      # prints global\ndynamic();                      # prints local\nlexical();                      # prints global Notice how at no point does the value \"private\" get printed. That's because $var only has that value within the block of the lexical() function, and it is hidden from called subroutine. In summary, local() doesn't make what you think of as private, local variables. It gives a global variable a temporary value. my() is what you're looking for if you want private variables. See \"Private Variables via my()\" in perlsub and \"Temporary Values via local()\" in perlsub for excruciating details. How can I access a dynamic variable while a similarly named lexical is in scope? If you know your package, you can just mention it explicitly, as in $Some_Pack::var. Note that the notation $::var is not the dynamic $var in the current package, but rather the one in the \"main\" package, as though you had written $main::var. use vars '$var';\nlocal $var = \"global\";\nmy    $var = \"lexical\";\n\nprint \"lexical is $var\\n\";\nprint \"global  is $main::var\\n\"; Alternatively you can use the compiler directive our() to bring a dynamic variable into the current lexical scope. require 5.006; # our() did not exist before 5.6\nuse vars '$var';\n\nlocal $var = \"global\";\nmy $var    = \"lexical\";\n\nprint \"lexical is $var\\n\";\n\n{\n        our $var;\n        print \"global  is $var\\n\";\n} What's the difference between deep and shallow binding? In deep binding, lexical variables mentioned in anonymous subroutines are the same ones that were in scope when the subroutine was created. In shallow binding, they are whichever variables with the same names happen to be in scope when the subroutine is called. Perl always uses deep binding of lexical variables (i.e., those created with my()). However, dynamic variables (aka global, local, or package variables) are effectively shallowly bound. Consider this just one more reason not to use them. See the answer to \"What's a closure?\". Why doesn't \"my($foo) = < FILE >;\" work right? \"my()\" and \"local()\" give list context to the right hand side of \"=\". The < FH > read operation, like so many of Perl's functions and operators, can tell which context it was called in and behaves appropriately. In general, the scalar() function can help. This function does nothing to the data itself (contrary to popular myth) but rather tells its argument to behave in whatever its scalar fashion is. If that function doesn't have a defined scalar behavior, this of course doesn't help you (such as with sort()). To enforce scalar context in this particular case, however, you need merely omit the parentheses: local($foo) = <FILE>;       # WRONG\nlocal($foo) = scalar(<FILE>);   # ok\nlocal $foo  = <FILE>;       # right You should probably be using lexical variables anyway, although the issue is the same here: my($foo) = <FILE>;      # WRONG\nmy $foo  = <FILE>;      # right How do I redefine a builtin function, operator, or method? Why do you want to do that? :-) If you want to override a predefined function, such as open(), then you'll have to import the new definition from a different module. See \"Overriding Built-in Functions\" in perlsub. There's also an example in \"Class::Template\" in perltoot. If you want to overload a Perl operator, such as \"+\" or \"**\", then you'll want to use the \"use overload\" pragma, documented in overload. If you're talking about obscuring method calls in parent classes, see \"Overridden Methods\" in perltoot. What's the difference between calling a function as &foo and foo()? (contributed by brian d foy) Calling a subroutine as &foo with no trailing parentheses ignores the prototype of \"foo\" and passes it the current value of the argumet list, @_. Here's an example; the \"bar\" subroutine calls &foo, which prints what its arguments list: sub bar { &foo }\n\nsub foo { print \"Args in foo are: @_\\n\" }\n\nbar( qw( a b c ) ); When you call \"bar\" with arguments, you see that \"foo\" got the same @_: Args in foo are: a b c Calling the subroutine with trailing parentheses, with or without arguments, does not use the current @_ and respects the subroutine prototype. Changing the example to put parentheses after the call to \"foo\" changes the program: sub bar { &foo() }\n\nsub foo { print \"Args in foo are: @_\\n\" }\n\nbar( qw( a b c ) ); Now the output shows that \"foo\" doesn't get the @_ from its caller. Args in foo are: The main use of the @_ pass-through feature is to write subroutines whose main job it is to call other subroutines for you. For further details, see perlsub. How do I create a switch or case statement? In Perl 5.10, use the \"given-when\" construct described in perlsyn: use 5.010;\n\ngiven ( $string ) {\n        when( 'Fred' )        { say \"I found Fred!\" }\n        when( 'Barney' )      { say \"I found Barney!\" }\n        when( \/Bamm-?Bamm\/ )  { say \"I found Bamm-Bamm!\" }\n        default               { say \"I don't recognize the name!\" }\n        }; If one wants to use pure Perl and to be compatible with Perl versions prior to 5.10, the general answer is to use \"if-elsif-else\": for ($variable_to_test) {\n        if    (\/pat1\/)  { }     # do something\n        elsif (\/pat2\/)  { }     # do something else\n        elsif (\/pat3\/)  { }     # do something else\n        else            { }     # default\n        } Here's a simple example of a switch based on pattern matching, lined up in a way to make it look more like a switch statement. We'll do a multiway conditional based on the type of reference stored in $whatchamacallit: SWITCH: for (ref $whatchamacallit) {\n\n    \/^$\/            && die \"not a reference\";\n\n    \/SCALAR\/        && do {\n                            print_scalar($$ref);\n                            last SWITCH;\n                    };\n\n    \/ARRAY\/         && do {\n                            print_array(@$ref);\n                            last SWITCH;\n                    };\n\n    \/HASH\/          && do {\n                            print_hash(%$ref);\n                            last SWITCH;\n                    };\n\n    \/CODE\/          && do {\n                            warn \"can't print function ref\";\n                            last SWITCH;\n                    };\n\n    # DEFAULT\n\n    warn \"User defined type skipped\";\n\n} See perlsyn for other examples in this style. Sometimes you should change the positions of the constant and the variable. For example, let's say you wanted to test which of many answers you were given, but in a case-insensitive way that also allows abbreviations. You can use the following technique if the strings all start with different characters or if you want to arrange the matches so that one takes precedence over another, as \"SEND\" has precedence over \"STOP\" here: chomp($answer = <>);\nif    (\"SEND\"  =~ \/^\\Q$answer\/i) { print \"Action is send\\n\"  }\nelsif (\"STOP\"  =~ \/^\\Q$answer\/i) { print \"Action is stop\\n\"  }\nelsif (\"ABORT\" =~ \/^\\Q$answer\/i) { print \"Action is abort\\n\" }\nelsif (\"LIST\"  =~ \/^\\Q$answer\/i) { print \"Action is list\\n\"  }\nelsif (\"EDIT\"  =~ \/^\\Q$answer\/i) { print \"Action is edit\\n\"  } A totally different approach is to create a hash of function references. my %commands = (\n        \"happy\" => \\&joy,\n        \"sad\",  => \\&sullen,\n        \"done\"  => sub { die \"See ya!\" },\n        \"mad\"   => \\&angry,\n);\n\nprint \"How are you? \";\nchomp($string = <STDIN>);\nif ($commands{$string}) {\n        $commands{$string}->();\n} else {\n        print \"No such command: $string\\n\";\n} Starting from Perl 5.8, a source filter module, \"Switch\", can also be used to get switch and case. Its use is now discouraged, because it's not fully compatible with the native switch of Perl 5.10, and because, as it's implemented as a source filter, it doesn't always work as intended when complex syntax is involved. How can I catch accesses to undefined variables, functions, or methods? The AUTOLOAD method, discussed in \"Autoloading\" in perlsub and \" AUTOLOAD: Proxy Methods\" in perltoot, lets you capture calls to undefined functions and methods. When it comes to undefined variables that would trigger a warning under \"use warnings\", you can promote the warning to an error. use warnings FATAL => qw(uninitialized); Why can't a method included in this same file be found? Some possible reasons: your inheritance is getting confused, you've misspelled the method name, or the object is of the wrong type. Check out perltoot for details about any of the above cases. You may also use \"print ref($object)\" to find out the class $object was blessed into. Another possible reason for problems is because you've used the indirect object syntax (eg, \"find Guru \"Samy\"\") on a class name before Perl has seen that such a package exists. It's wisest to make sure your packages are all defined before you start using them, which will be taken care of if you use the \"use\" statement instead of \"require\". If not, make sure to use arrow notation (eg., \"Guru->find(\"Samy\")\") instead. Object notation is explained in perlobj. Make sure to read about creating modules in perlmod and the perils of indirect objects in \"Method Invocation\" in perlobj. How can I find out my current or calling package? (contributed by brian d foy) To find the package you are currently in, use the special literal \"__PACKAGE__\", as documented in perldata. You can only use the special literals as separate tokens, so you can't interpolate them into strings like you can with variables: my $current_package = __PACKAGE__;\nprint \"I am in package $current_package\\n\"; This is different from finding out the package an object is blessed into, which might not be the current package. For that, use \"blessed\" from \"Scalar::Util\", part of the Standard Library since Perl 5.8: use Scalar::Util qw(blessed);\nmy $object_package = blessed( $object ); Most of the time, you shouldn't care what package an object is blessed into, however, as long as it claims to inherit from that class: my $is_right_class = eval { $object->isa( $package ) }; # true or false If you want to find the package calling your code, perhaps to give better diagnostics as \"Carp\" does, use the \"caller\" built-in: sub foo {\n        my @args = ...;\n        my( $package, $filename, $line ) = caller;\n\n        print \"I was called from package $package\\n\";\n        ); By default, your program starts in package \"main\", so you should always be in some package unless someone uses the \"package\" built-in with no namespace. See the \"package\" entry in perlfunc for the details of empty packges. How can I comment out a large block of Perl code? (contributed by brian d foy) The quick-and-dirty way to comment out more than one line of Perl is to surround those lines with Pod directives. You have to put these directives at the beginning of the line and somewhere where Perl expects a new statement (so not in the middle of statements like the # comments). You end the comment with \"=cut\", ending the Pod section: =pod\n\nmy $object = NotGonnaHappen->new();\n\nignored_sub();\n\n$wont_be_assigned = 37;\n\n=cut The quick-and-dirty method only works well when you don't plan to leave the commented code in the source. If a Pod parser comes along, you're multiline comment is going to show up in the Pod translation. A better way hides it from Pod parsers as well. The \"=begin\" directive can mark a section for a particular purpose. If the Pod parser doesn't want to handle it, it just ignores it. Label the comments with \"comment\". End the comment using \"=end\" with the same label. You still need the \"=cut\" to go back to Perl code from the Pod comment: =begin comment\n\nmy $object = NotGonnaHappen->new();\n\nignored_sub();\n\n$wont_be_assigned = 37;\n\n=end comment\n\n=cut For more information on Pod, check out perlpod and perlpodspec. How do I clear a package? Use this code, provided by Mark-Jason Dominus: sub scrub_package {\n        no strict 'refs';\n        my $pack = shift;\n        die \"Shouldn't delete main package\"\n                if $pack eq \"\" || $pack eq \"main\";\n        my $stash = *{$pack . '::'}{HASH};\n        my $name;\n        foreach $name (keys %$stash) {\n                my $fullname = $pack . '::' . $name;\n                # Get rid of everything with that name.\n                undef $$fullname;\n                undef @$fullname;\n                undef %$fullname;\n                undef &$fullname;\n                undef *$fullname;\n}\n} Or, if you're using a recent release of Perl, you can just use the Symbol::delete_package() function instead. How can I use a variable as a variable name? Beginners often think they want to have a variable contain the name of a variable. $fred    = 23;\n$varname = \"fred\";\n++$$varname;         # $fred now 24 This works sometimes, but it is a very bad idea for two reasons. The first reason is that this technique only works on global variables. That means that if $fred is a lexical variable created with my() in the above example, the code wouldn't work at all: you'd accidentally access the global and skip right over the private lexical altogether. Global variables are bad because they can easily collide accidentally and in general make for non-scalable and confusing code. Symbolic references are forbidden under the \"use strict\" pragma. They are not true references and consequently are not reference counted or garbage collected. The other reason why using a variable to hold the name of another variable is a bad idea is that the question often stems from a lack of understanding of Perl data structures, particularly hashes. By using symbolic references, you are just using the package's symbol-table hash (like %main::) instead of a user-defined hash. The solution is to use your own hash or a real reference instead. $USER_VARS{\"fred\"} = 23;\n$varname = \"fred\";\n$USER_VARS{$varname}++;  # not $$varname++ There we're using the %USER_VARS hash instead of symbolic references. Sometimes this comes up in reading strings from the user with variable references and wanting to expand them to the values of your perl program's variables. This is also a bad idea because it conflates the program-addressable namespace and the user-addressable one. Instead of reading a string and expanding it to the actual contents of your program's own variables: $str = 'this has a $fred and $barney in it';\n$str =~ s\/(\\$\\w+)\/$1\/eeg;                 # need double eval it would be better to keep a hash around like %USER_VARS and have variable references actually refer to entries in that hash: $str =~ s\/\\$(\\w+)\/$USER_VARS{$1}\/g;   # no \/e here at all That's faster, cleaner, and safer than the previous approach. Of course, you don't need to use a dollar sign. You could use your own scheme to make it less confusing, like bracketed percent symbols, etc. $str = 'this has a %fred% and %barney% in it';\n$str =~ s\/%(\\w+)%\/$USER_VARS{$1}\/g;   # no \/e here at all Another reason that folks sometimes think they want a variable to contain the name of a variable is because they don't know how to build proper data structures using hashes. For example, let's say they wanted two hashes in their program: %fred and %barney, and that they wanted to use another scalar variable to refer to those by name. $name = \"fred\";\n$$name{WIFE} = \"wilma\";     # set %fred\n\n$name = \"barney\";\n$$name{WIFE} = \"betty\"; # set %barney This is still a symbolic reference, and is still saddled with the problems enumerated above. It would be far better to write: $folks{\"fred\"}{WIFE}   = \"wilma\";\n$folks{\"barney\"}{WIFE} = \"betty\"; And just use a multilevel hash to start with. The only times that you absolutely must use symbolic references are when you really must refer to the symbol table. This may be because it's something that can't take a real reference to, such as a format name. Doing so may also be important for method calls, since these always go through the symbol table for resolution. In those cases, you would turn off \"strict 'refs'\" temporarily so you can play around with the symbol table. For example: @colors = qw(red blue green yellow orange purple violet);\nfor my $name (@colors) {\n        no strict 'refs';  # renege for the block\n        *$name = sub { \"<FONT COLOR='$name'>@_<\/FONT>\" };\n} All those functions ( red(), blue(), green(), etc.) appear to be separate, but the real code in the closure actually was compiled only once. So, sometimes you might want to use symbolic references to directly manipulate the symbol table. This doesn't matter for formats, handles, and subroutines, because they are always global--you can't use my() on them. For scalars, arrays, and hashes, though--and usually for subroutines-- you probably only want to use hard references. What does \"bad interpreter\" mean? (contributed by brian d foy) The \"bad interpreter\" message comes from the shell, not perl. The actual message may vary depending on your platform, shell, and locale settings. If you see \"bad interpreter - no such file or directory\", the first line in your perl script (the \"shebang\" line) does not contain the right path to perl (or any other program capable of running scripts). Sometimes this happens when you move the script from one machine to another and each machine has a different path to perl--\/usr\/bin\/perl versus \/usr\/local\/bin\/perl for instance. It may also indicate that the source machine has CRLF line terminators and the destination machine has LF only: the shell tries to find \/usr\/bin\/perl< CR >, but can't. If you see \"bad interpreter: Permission denied\", you need to make your script executable. In either case, you should still be able to run the scripts with perl explicitly: % perl script.pl If you get a message like \"perl: command not found\", perl is not in your PATH , which might also mean that the location of perl is not where you expect it so you need to adjust your shebang line.","Process Name":"perlfaq7","Link":"https:\/\/linux.die.net\/man\/1\/perlfaq7"}},{"Process":{"Description":"This section of the Perl FAQ covers questions involving operating system interaction. Topics include interprocess communication ( IPC ), control over the user-interface (keyboard, screen and pointing devices), and most anything else not related to data manipulation. Read the FAQs and documentation specific to the port of perl to your operating system (eg, perlvms, perlplan9, ...). These should contain more detailed information on the vagaries of your perl. How do I find out which operating system I'm running under? The $^O variable ($OSNAME if you use English) contains an indication of the name of the operating system (not its release number) that your perl binary was built for. How come exec() doesn't return? (contributed by brian d foy) The \"exec\" function's job is to turn your process into another command and never to return. If that's not what you want to do, don't use \"exec\". :) If you want to run an external command and still keep your Perl process going, look at a piped \"open\", \"fork\", or \"system\". How do I do fancy stuff with the keyboard\/screen\/mouse? How you access\/control keyboards, screens, and pointing devices (\"mice\") is system-dependent. Try the following modules: Keyboard Term::Cap               Standard perl distribution\nTerm::ReadKey           CPAN\nTerm::ReadLine::Gnu     CPAN\nTerm::ReadLine::Perl    CPAN\nTerm::Screen            CPAN Screen Term::Cap               Standard perl distribution\nCurses                  CPAN\nTerm::ANSIColor         CPAN Mouse Tk                      CPAN Some of these specific cases are shown as examples in other answers in this section of the perlfaq. How do I print something out in color? In general, you don't, because you don't know whether the recipient has a color-aware display device. If you know that they have an ANSI terminal that understands color, you can use the Term::ANSIColor module from CPAN: use Term::ANSIColor;\nprint color(\"red\"), \"Stop!\\n\", color(\"reset\");\nprint color(\"green\"), \"Go!\\n\", color(\"reset\"); Or like this: use Term::ANSIColor qw(:constants);\nprint RED, \"Stop!\\n\", RESET;\nprint GREEN, \"Go!\\n\", RESET; How do I read just one key without waiting for a return key? Controlling input buffering is a remarkably system-dependent matter. On many systems, you can just use the stty command as shown in \"getc\" in perlfunc, but as you see, that's already getting you into portability snags. open(TTY, \"+<\/dev\/tty\") or die \"no tty: $!\";\nsystem \"stty  cbreak <\/dev\/tty >\/dev\/tty 2>&1\";\n$key = getc(TTY);               # perhaps this works\n# OR ELSE\nsysread(TTY, $key, 1);  # probably this does\nsystem \"stty -cbreak <\/dev\/tty >\/dev\/tty 2>&1\"; The Term::ReadKey module from CPAN offers an easy-to-use interface that should be more efficient than shelling out to stty for each key. It even includes limited support for Windows. use Term::ReadKey;\nReadMode('cbreak');\n$key = ReadKey(0);\nReadMode('normal'); However, using the code requires that you have a working C compiler and can use it to build and install a CPAN module. Here's a solution using the standard POSIX module, which is already on your systems (assuming your system supports POSIX ). use HotKey;\n$key = readkey(); And here's the HotKey module, which hides the somewhat mystifying calls to manipulate the POSIX termios structures. # HotKey.pm\npackage HotKey;\n\n@ISA = qw(Exporter);\n@EXPORT = qw(cbreak cooked readkey);\n\nuse strict;\nuse POSIX qw(:termios_h);\nmy ($term, $oterm, $echo, $noecho, $fd_stdin);\n\n$fd_stdin = fileno(STDIN);\n$term     = POSIX::Termios->new();\n$term->getattr($fd_stdin);\n$oterm     = $term->getlflag();\n\n$echo     = ECHO | ECHOK | ICANON;\n$noecho   = $oterm & ~$echo;\n\nsub cbreak {\n        $term->setlflag($noecho);  # ok, so i don't want echo either\n        $term->setcc(VTIME, 1);\n        $term->setattr($fd_stdin, TCSANOW);\n}\n\nsub cooked {\n        $term->setlflag($oterm);\n        $term->setcc(VTIME, 0);\n        $term->setattr($fd_stdin, TCSANOW);\n}\n\nsub readkey {\n        my $key = '';\n        cbreak();\n        sysread(STDIN, $key, 1);\n        cooked();\n        return $key;\n}\n\nEND { cooked() }\n\n1; How do I check whether input is ready on the keyboard? The easiest way to do this is to read a key in nonblocking mode with the Term::ReadKey module from CPAN , passing it an argument of -1 to indicate not to block: use Term::ReadKey;\n\nReadMode('cbreak');\n\nif (defined ($char = ReadKey(-1)) ) {\n        # input was waiting and it was $char\n} else {\n        # no input was waiting\n}\n\nReadMode('normal');                  # restore normal tty settings How do I clear the screen? (contributed by brian d foy) To clear the screen, you just have to print the special sequence that tells the terminal to clear the screen. Once you have that sequence, output it when you want to clear the screen. You can use the \"Term::ANSIScreen\" module to get the special sequence. Import the \"cls\" function (or the \":screen\" tag): use Term::ANSIScreen qw(cls);\nmy $clear_screen = cls();\n\nprint $clear_screen; The \"Term::Cap\" module can also get the special sequence if you want to deal with the low-level details of terminal control. The \"Tputs\" method returns the string for the given capability: use Term::Cap;\n\n$terminal = Term::Cap->Tgetent( { OSPEED => 9600 } );\n$clear_string = $terminal->Tputs('cl');\n\nprint $clear_screen; On Windows, you can use the \"Win32::Console\" module. After creating an object for the output filehandle you want to affect, call the \"Cls\" method: Win32::Console;\n\n$OUT = Win32::Console->new(STD_OUTPUT_HANDLE);\nmy $clear_string = $OUT->Cls;\n\nprint $clear_screen; If you have a command-line program that does the job, you can call it in backticks to capture whatever it outputs so you can use it later: $clear_string = `clear`;\n\nprint $clear_string; How do I get the screen size? If you have Term::ReadKey module installed from CPAN , you can use it to fetch the width and height in characters and in pixels: use Term::ReadKey;\n($wchar, $hchar, $wpixels, $hpixels) = GetTerminalSize(); This is more portable than the raw \"ioctl\", but not as illustrative: require 'sys\/ioctl.ph';\ndie \"no TIOCGWINSZ \" unless defined &TIOCGWINSZ;\nopen(TTY, \"+<\/dev\/tty\")                     or die \"No tty: $!\";\nunless (ioctl(TTY, &TIOCGWINSZ, $winsize='')) {\n        die sprintf \"$0: ioctl TIOCGWINSZ (%08x: $!)\\n\", &TIOCGWINSZ;\n}\n($row, $col, $xpixel, $ypixel) = unpack('S4', $winsize);\nprint \"(row,col) = ($row,$col)\";\nprint \"  (xpixel,ypixel) = ($xpixel,$ypixel)\" if $xpixel || $ypixel;\nprint \"\\n\"; How do I ask the user for a password? (This question has nothing to do with the web. See a different FAQ for that.) There's an example of this in \"crypt\" in perlfunc). First, you put the terminal into \"no echo\" mode, then just read the password normally. You may do this with an old-style ioctl() function, POSIX terminal control (see POSIX or its documentation the Camel Book), or a call to the stty program, with varying degrees of portability. You can also do this for most systems using the Term::ReadKey module from CPAN , which is easier to use and in theory more portable. use Term::ReadKey;\n\nReadMode('noecho');\n$password = ReadLine(0); How do I read and write the serial port? This depends on which operating system your program is running on. In the case of Unix, the serial ports will be accessible through files in \/dev; on other systems, device names will doubtless differ. Several problem areas common to all device interaction are the following: lockfiles Your system may use lockfiles to control multiple access. Make sure you follow the correct protocol. Unpredictable behavior can result from multiple processes reading from one device. open mode If you expect to use both read and write operations on the device, you'll have to open it for update (see \"open\" in perlfunc for details). You may wish to open it without running the risk of blocking by using sysopen() and \"O_RDWR|O_NDELAY|O_NOCTTY\" from the Fcntl module (part of the standard perl distribution). See \"sysopen\" in perlfunc for more on this approach. end of line Some devices will be expecting a \"\\r\" at the end of each line rather than a \"\\n\". In some ports of perl, \"\\r\" and \"\\n\" are different from their usual (Unix) ASCII values of \"\\012\" and \"\\015\". You may have to give the numeric values you want directly, using octal (\"\\015\"), hex (\"0x0D\"), or as a control-character specification (\"\\cM\"). print DEV \"atv1\\012\";   # wrong, for some devices\nprint DEV \"atv1\\015\";   # right, for some devices Even though with normal text files a \"\\n\" will do the trick, there is still no unified scheme for terminating a line that is portable between Unix, DOS\/Win, and Macintosh, except to terminate ALL line ends with \"\\015\\012\", and strip what you don't need from the output. This applies especially to socket I\/O and autoflushing, discussed next. flushing output If you expect characters to get to your device when you print() them, you'll want to autoflush that filehandle. You can use select() and the $| variable to control autoflushing (see \"$|\" in perlvar and \"select\" in perlfunc, or perlfaq5, \"How do I flush\/unbuffer an output filehandle? Why must I do this?\"): $oldh = select(DEV);\n$| = 1;\nselect($oldh); You'll also see code that does this without a temporary variable, as in select((select(DEV), $| = 1)[0]); Or if you don't mind pulling in a few thousand lines of code just because you're afraid of a little $| variable: use IO::Handle;\nDEV->autoflush(1); As mentioned in the previous item, this still doesn't work when using socket I\/O between Unix and Macintosh. You'll need to hard code your line terminators, in that case. non-blocking input If you are doing a blocking read() or sysread(), you'll have to arrange for an alarm handler to provide a timeout (see \"alarm\" in perlfunc). If you have a non-blocking open, you'll likely have a non-blocking read, which means you may have to use a 4-arg select() to determine whether I\/O is ready on that device (see \"select\" in perlfunc. While trying to read from his caller-id box, the notorious Jamie Zawinski \"<jwz@netscape.com>\", after much gnashing of teeth and fighting with sysread, sysopen, POSIX 's tcgetattr business, and various other functions that go bump in the night, finally came up with this: sub open_modem {\n        use IPC::Open2;\n        my $stty = `\/bin\/stty -g`;\n        open2( \\*MODEM_IN, \\*MODEM_OUT, \"cu -l$modem_device -s2400 2>&1\");\n        # starting cu hoses \/dev\/tty's stty settings, even when it has\n        # been opened on a pipe...\n        system(\"\/bin\/stty $stty\");\n        $_ = <MODEM_IN>;\n        chomp;\n        if ( !m\/^Connected\/ ) {\n                print STDERR \"$0: cu printed `$_' instead of `Connected'\\n\";\n        }\n} How do I decode encrypted password files? You spend lots and lots of money on dedicated hardware, but this is bound to get you talked about. Seriously, you can't if they are Unix password files--the Unix password system employs one-way encryption. It's more like hashing than encryption. The best you can do is check whether something else hashes to the same string. You can't turn a hash back into the original string. Programs like Crack can forcibly (and intelligently) try to guess passwords, but don't (can't) guarantee quick success. If you're worried about users selecting bad passwords, you should proactively check when they try to change their password (by modifying passwd(1), for example). How do I start a process in the background? (contributed by brian d foy) There's not a single way to run code in the background so you don't have to wait for it to finish before your program moves on to other tasks. Process management depends on your particular operating system, and many of the techniques are in perlipc. Several CPAN modules may be able to help, including IPC::Open2 or IPC::Open3, IPC::Run, Parallel::Jobs, Parallel::ForkManager, POE , Proc::Background, and Win32::Process. There are many other modules you might use, so check those namespaces for other options too. If you are on a unix-like system, you might be able to get away with a system call where you put an \"&\" on the end of the command: system(\"cmd &\") You can also try using \"fork\", as described in perlfunc (although this is the same thing that many of the modules will do for you). STDIN , STDOUT , and STDERR are shared Both the main process and the backgrounded one (the \"child\" process) share the same STDIN , STDOUT and STDERR filehandles. If both try to access them at once, strange things can happen. You may want to close or reopen these for the child. You can get around this with \"open\"ing a pipe (see \"open\" in perlfunc) but on some systems this means that the child process cannot outlive the parent. Signals You'll have to catch the SIGCHLD signal, and possibly SIGPIPE too. SIGCHLD is sent when the backgrounded process finishes. SIGPIPE is sent when you write to a filehandle whose child process has closed (an untrapped SIGPIPE can cause your program to silently die). This is not an issue with \"system(\"cmd&\")\". Zombies You have to be prepared to \"reap\" the child process when it finishes. $SIG{CHLD} = sub { wait };\n\n$SIG{CHLD} = 'IGNORE'; You can also use a double fork. You immediately wait() for your first child, and the init daemon will wait() for your grandchild once it exits. unless ($pid = fork) {\n    unless (fork) {\n        exec \"what you really wanna do\";\n        die \"exec failed!\";\n    }\n    exit 0;\n}\nwaitpid($pid, 0); See \"Signals\" in perlipc for other examples of code to do this. Zombies are not an issue with \"system(\"prog &\")\". How do I trap control characters\/signals? You don't actually \"trap\" a control character. Instead, that character generates a signal which is sent to your terminal's currently foregrounded process group, which you then trap in your process. Signals are documented in \"Signals\" in perlipc and the section on \"Signals\" in the Camel. You can set the values of the %SIG hash to be the functions you want to handle the signal. After perl catches the signal, it looks in %SIG for a key with the same name as the signal, then calls the subroutine value for that key. # as an anonymous subroutine\n\n$SIG{INT} = sub { syswrite(STDERR, \"ouch\\n\", 5 ) };\n\n# or a reference to a function\n\n$SIG{INT} = \\&ouch;\n\n# or the name of the function as a string\n\n$SIG{INT} = \"ouch\"; Perl versions before 5.8 had in its C source code signal handlers which would catch the signal and possibly run a Perl function that you had set in %SIG. This violated the rules of signal handling at that level causing perl to dump core. Since version 5.8.0, perl looks at %SIG *after* the signal has been caught, rather than while it is being caught. Previous versions of this answer were incorrect. How do I modify the shadow password file on a Unix system? If perl was installed correctly and your shadow library was written properly, the getpw*() functions described in perlfunc should in theory provide (read-only) access to entries in the shadow password file. To change the file, make a new shadow password file (the format varies from system to system--see passwd for specifics) and use pwd_mkdb(8) to install it (see pwd_mkdb for more details). How do I set the time and date? Assuming you're running under sufficient permissions, you should be able to set the system-wide date and time by running the date(1) program. (There is no way to set the time and date on a per-process basis.) This mechanism will work for Unix, MS-DOS, Windows, and NT ; the VMS equivalent is \"set time\". However, if all you want to do is change your time zone, you can probably get away with setting an environment variable: $ENV{TZ} = \"MST7MDT\";              # unixish\n$ENV{'SYS$TIMEZONE_DIFFERENTIAL'}=\"-5\" # vms\nsystem \"trn comp.lang.perl.misc\"; How can I sleep() or alarm() for under a second? If you want finer granularity than the 1 second that the \"sleep()\" function provides, the easiest way is to use the \"select()\" function as documented in \"select\" in perlfunc. Try the \"Time::HiRes\" and the \"BSD::Itimer\" modules (available from CPAN , and starting from Perl 5.8 \"Time::HiRes\" is part of the standard distribution). How can I measure time under a second? (contributed by brian d foy) The \"Time::HiRes\" module (part of the standard distribution as of Perl 5.8) measures time with the \"gettimeofday()\" system call, which returns the time in microseconds since the epoch. If you can't install \"Time::HiRes\" for older Perls and you are on a Unixish system, you may be able to call gettimeofday(2) directly. See \"syscall\" in perlfunc. How can I do an atexit() or setjmp()\/longjmp()? (Exception handling) Release 5 of Perl added the END block, which can be used to simulate atexit(). Each package's END block is called when the program or thread ends (see perlmod manpage for more details). For example, you can use this to make sure your filter program managed to finish its output without filling up the disk: END {\n        close(STDOUT) || die \"stdout close failed: $!\";\n} The END block isn't called when untrapped signals kill the program, though, so if you use END blocks you should also use use sigtrap qw(die normal-signals); Perl's exception-handling mechanism is its eval() operator. You can use eval() as setjmp and die() as longjmp. For details of this, see the section on signals, especially the time-out handler for a blocking flock() in \"Signals\" in perlipc or the section on \"Signals\" in the Camel Book. If exception handling is all you're interested in, try the exceptions.pl library (part of the standard perl distribution). If you want the atexit() syntax (and an rmexit() as well), try the AtExit module available from CPAN . Why doesn't my sockets program work under System V (Solaris)? What does the error message \"Protocol not supported\" mean? Some Sys-V based systems, notably Solaris 2.X, redefined some of the standard socket constants. Since these were constant across all architectures, they were often hardwired into perl code. The proper way to deal with this is to \"use Socket\" to get the correct values. Note that even though SunOS and Solaris are binary compatible, these values are different. Go figure. How can I call my system's unique C functions from Perl? In most cases, you write an external module to do it--see the answer to \"Where can I learn about linking C with Perl? [h2xs, xsubpp]\". However, if the function is a system call, and your system supports syscall(), you can use the syscall function (documented in perlfunc). Remember to check the modules that came with your distribution, and CPAN as well--someone may already have written a module to do it. On Windows, try Win32::API. On Macs, try Mac::Carbon. If no module has an interface to the C function, you can inline a bit of C in your Perl source with Inline::C. Where do I get the include files to do ioctl() or syscall()? Historically, these would be generated by the h2ph tool, part of the standard perl distribution. This program converts cpp(1) directives in C header files to files containing subroutine definitions, like &SYS_getitimer, which you can use as arguments to your functions. It doesn't work perfectly, but it usually gets most of the job done. Simple files like errno.h, syscall.h, and socket.h were fine, but the hard ones like ioctl.h nearly always need to hand-edited. Here's how to install the *.ph files: 1.  become super-user\n2.  cd \/usr\/include\n3.  h2ph *.h *\/*.h If your system supports dynamic loading, for reasons of portability and sanity you probably ought to use h2xs (also part of the standard perl distribution). This tool converts C header files to Perl extensions. See perlxstut for how to get started with h2xs. If your system doesn't support dynamic loading, you still probably ought to use h2xs. See perlxstut and ExtUtils::MakeMaker for more information (in brief, just use make perl instead of a plain make to rebuild perl with a new static extension). Why do setuid perl scripts complain about kernel problems? Some operating systems have bugs in the kernel that make setuid scripts inherently insecure. Perl gives you a number of options (described in perlsec) to work around such systems. How can I open a pipe both to and from a command? The IPC::Open2 module (part of the standard perl distribution) is an easy-to-use approach that internally uses pipe(), fork(), and exec() to do the job. Make sure you read the deadlock warnings in its documentation, though (see IPC::Open2). See \"Bidirectional Communication with Another Process\" in perlipc and \"Bidirectional Communication with Yourself\" in perlipc You may also use the IPC::Open3 module (part of the standard perl distribution), but be warned that it has a different order of arguments from IPC::Open2 (see IPC::Open3). Why can't I get the output of a command with system()? You're confusing the purpose of system() and backticks (''). system() runs a command and returns exit status information (as a 16 bit value: the low 7 bits are the signal the process died from, if any, and the high 8 bits are the actual exit value). Backticks ('') run a command and return what it sent to STDOUT . $exit_status   = system(\"mail-users\");\n$output_string = `ls`; How can I capture STDERR from an external command? There are three basic ways of running external commands: system $cmd;            # using system()\n$output = `$cmd`;               # using backticks (``)\nopen (PIPE, \"cmd |\");   # using open() With system(), both STDOUT and STDERR will go the same place as the script's STDOUT and STDERR , unless the system() command redirects them. Backticks and open() read only the STDOUT of your command. You can also use the open3() function from IPC::Open3. Benjamin Goldberg provides some sample code: To capture a program's STDOUT , but discard its STDERR: use IPC::Open3;\nuse File::Spec;\nuse Symbol qw(gensym);\nopen(NULL, \">\", File::Spec->devnull);\nmy $pid = open3(gensym, \\*PH, \">&NULL\", \"cmd\");\nwhile( <PH> ) { }\nwaitpid($pid, 0); To capture a program's STDERR , but discard its STDOUT: use IPC::Open3;\nuse File::Spec;\nuse Symbol qw(gensym);\nopen(NULL, \">\", File::Spec->devnull);\nmy $pid = open3(gensym, \">&NULL\", \\*PH, \"cmd\");\nwhile( <PH> ) { }\nwaitpid($pid, 0); To capture a program's STDERR , and let its STDOUT go to our own STDERR: use IPC::Open3;\nuse Symbol qw(gensym);\nmy $pid = open3(gensym, \">&STDERR\", \\*PH, \"cmd\");\nwhile( <PH> ) { }\nwaitpid($pid, 0); To read both a command's STDOUT and its STDERR separately, you can redirect them to temp files, let the command run, then read the temp files: use IPC::Open3;\nuse Symbol qw(gensym);\nuse IO::File;\nlocal *CATCHOUT = IO::File->new_tmpfile;\nlocal *CATCHERR = IO::File->new_tmpfile;\nmy $pid = open3(gensym, \">&CATCHOUT\", \">&CATCHERR\", \"cmd\");\nwaitpid($pid, 0);\nseek $_, 0, 0 for \\*CATCHOUT, \\*CATCHERR;\nwhile( <CATCHOUT> ) {}\nwhile( <CATCHERR> ) {} But there's no real need for *both* to be tempfiles... the following should work just as well, without deadlocking: use IPC::Open3;\nuse Symbol qw(gensym);\nuse IO::File;\nlocal *CATCHERR = IO::File->new_tmpfile;\nmy $pid = open3(gensym, \\*CATCHOUT, \">&CATCHERR\", \"cmd\");\nwhile( <CATCHOUT> ) {}\nwaitpid($pid, 0);\nseek CATCHERR, 0, 0;\nwhile( <CATCHERR> ) {} And it'll be faster, too, since we can begin processing the program's stdout immediately, rather than waiting for the program to finish. With any of these, you can change file descriptors before the call: open(STDOUT, \">logfile\");\nsystem(\"ls\"); or you can use Bourne shell file-descriptor redirection: $output = `$cmd 2>some_file`;\nopen (PIPE, \"cmd 2>some_file |\"); You can also use file-descriptor redirection to make STDERR a duplicate of STDOUT: $output = `$cmd 2>&1`;\nopen (PIPE, \"cmd 2>&1 |\"); Note that you cannot simply open STDERR to be a dup of STDOUT in your Perl program and avoid calling the shell to do the redirection. This doesn't work: open(STDERR, \">&STDOUT\");\n$alloutput = `cmd args`;  # stderr still escapes This fails because the open() makes STDERR go to where STDOUT was going at the time of the open(). The backticks then make STDOUT go to a string, but don't change STDERR (which still goes to the old STDOUT ). Note that you must use Bourne shell (sh(1)) redirection syntax in backticks, not csh(1)! Details on why Perl's system() and backtick and pipe opens all use the Bourne shell are in the versus\/csh.whynot article in the \"Far More Than You Ever Wanted To Know\" collection in http:\/\/www.cpan.org\/misc\/olddoc\/FMTEYEWTK.tgz . To capture a command's STDERR and STDOUT together: $output = `cmd 2>&1`;                       # either with backticks\n$pid = open(PH, \"cmd 2>&1 |\");              # or with an open pipe\nwhile (<PH>) { }                            #    plus a read To capture a command's STDOUT but discard its STDERR: $output = `cmd 2>\/dev\/null`;                # either with backticks\n$pid = open(PH, \"cmd 2>\/dev\/null |\");       # or with an open pipe\nwhile (<PH>) { }                            #    plus a read To capture a command's STDERR but discard its STDOUT: $output = `cmd 2>&1 1>\/dev\/null`;           # either with backticks\n$pid = open(PH, \"cmd 2>&1 1>\/dev\/null |\");  # or with an open pipe\nwhile (<PH>) { }                            #    plus a read To exchange a command's STDOUT and STDERR in order to capture the STDERR but leave its STDOUT to come out our old STDERR: $output = `cmd 3>&1 1>&2 2>&3 3>&-`;        # either with backticks\n$pid = open(PH, \"cmd 3>&1 1>&2 2>&3 3>&-|\");# or with an open pipe\nwhile (<PH>) { }                            #    plus a read To read both a command's STDOUT and its STDERR separately, it's easiest to redirect them separately to files, and then read from those files when the program is done: system(\"program args 1>program.stdout 2>program.stderr\"); Ordering is important in all these examples. That's because the shell processes file descriptor redirections in strictly left to right order. system(\"prog args 1>tmpfile 2>&1\");\nsystem(\"prog args 2>&1 1>tmpfile\"); The first command sends both standard out and standard error to the temporary file. The second command sends only the old standard output there, and the old standard error shows up on the old standard out. Why doesn't open() return an error when a pipe open fails? If the second argument to a piped open() contains shell metacharacters, perl fork()s, then exec()s a shell to decode the metacharacters and eventually run the desired program. If the program couldn't be run, it's the shell that gets the message, not Perl. All your Perl program can find out is whether the shell itself could be successfully started. You can still capture the shell's STDERR and check it for error messages. See \"How can I capture STDERR from an external command?\" elsewhere in this document, or use the IPC::Open3 module. If there are no shell metacharacters in the argument of open(), Perl runs the command directly, without using the shell, and can correctly report whether the command started. What's wrong with using backticks in a void context? Strictly speaking, nothing. Stylistically speaking, it's not a good way to write maintainable code. Perl has several operators for running external commands. Backticks are one; they collect the output from the command for use in your program. The \"system\" function is another; it doesn't do this. Writing backticks in your program sends a clear message to the readers of your code that you wanted to collect the output of the command. Why send a clear message that isn't true? Consider this line: `cat \/etc\/termcap`; You forgot to check $? to see whether the program even ran correctly. Even if you wrote print `cat \/etc\/termcap`; this code could and probably should be written as system(\"cat \/etc\/termcap\") == 0\nor die \"cat program failed!\"; which will echo the cat command's output as it is generated, instead of waiting until the program has completed to print it out. It also checks the return value. \"system\" also provides direct control over whether shell wildcard processing may take place, whereas backticks do not. How can I call backticks without shell processing? This is a bit tricky. You can't simply write the command like this: @ok = `grep @opts '$search_string' @filenames`; As of Perl 5.8.0, you can use \"open()\" with multiple arguments. Just like the list forms of \"system()\" and \"exec()\", no shell escapes happen. open( GREP, \"-|\", 'grep', @opts, $search_string, @filenames );\nchomp(@ok = <GREP>);\nclose GREP; You can also: my @ok = ();\nif (open(GREP, \"-|\")) {\n        while (<GREP>) {\n                chomp;\n                push(@ok, $_);\n        }\n        close GREP;\n} else {\n        exec 'grep', @opts, $search_string, @filenames;\n} Just as with \"system()\", no shell escapes happen when you \"exec()\" a list. Further examples of this can be found in \"Safe Pipe Opens\" in perlipc. Note that if you're using Windows, no solution to this vexing issue is even possible. Even if Perl were to emulate \"fork()\", you'd still be stuck, because Windows does not have an argc\/argv-style API . Why can't my script read from STDIN after I gave it EOF (^D on Unix, ^Z on MS-DOS)? Some stdio's set error and eof flags that need clearing. The POSIX module defines clearerr() that you can use. That is the technically correct way to do it. Here are some less reliable workarounds: 1. Try keeping around the seekpointer and go there, like this: $where = tell(LOG);\nseek(LOG, $where, 0); 2. If that doesn't work, try seeking to a different part of the file and then back. 3. If that doesn't work, try seeking to a different part of the file, reading something, and then seeking back. 4. If that doesn't work, give up on your stdio package and use sysread. How can I convert my shell script to perl? Learn Perl and rewrite it. Seriously, there's no simple converter. Things that are awkward to do in the shell are easy to do in Perl, and this very awkwardness is what would make a shell->perl converter nigh-on impossible to write. By rewriting it, you'll think about what you're really trying to do, and hopefully will escape the shell's pipeline datastream paradigm, which while convenient for some matters, causes many inefficiencies. Can I use perl to run a telnet or ftp session? Try the Net::FTP, TCP::Client, and Net::Telnet modules (available from CPAN ). http:\/\/www.cpan.org\/scripts\/netstuff\/telnet.emul.shar will also help for emulating the telnet protocol, but Net::Telnet is quite probably easier to use.. If all you want to do is pretend to be telnet but don't need the initial telnet handshaking, then the standard dual-process approach will suffice: use IO::Socket;             # new in 5.004\n$handle = IO::Socket::INET->new('www.perl.com:80')\n    or die \"can't connect to port 80 on www.perl.com: $!\";\n$handle->autoflush(1);\nif (fork()) {               # XXX: undef means failure\n    select($handle);\n    print while <STDIN>;    # everything from stdin to socket\n} else {\n    print while <$handle>;  # everything from socket to stdout\n}\nclose $handle;\nexit; How can I write expect in Perl? Once upon a time, there was a library called chat2.pl (part of the standard perl distribution), which never really got finished. If you find it somewhere, don't use it. These days, your best bet is to look at the Expect module available from CPAN , which also requires two other modules from CPAN , IO::Pty and IO::Stty. Is there a way to hide perl's command line from programs such as \"ps\"? First of all note that if you're doing this for security reasons (to avoid people seeing passwords, for example) then you should rewrite your program so that critical information is never given as an argument. Hiding the arguments won't make your program completely secure. To actually alter the visible command line, you can assign to the variable $0 as documented in perlvar. This won't work on all operating systems, though. Daemon programs like sendmail place their state there, as in: $0 = \"orcus [accepting connections]\"; I {changed directory, modified my environment} in a perl script. How come the change disappeared when I exited the script? How do I get my changes to be visible? Unix In the strictest sense, it can't be done--the script executes as a different process from the shell it was started from. Changes to a process are not reflected in its parent--only in any children created after the change. There is shell magic that may allow you to fake it by eval()ing the script's output in your shell; check out the comp.unix.questions FAQ for details. How do I close a process's filehandle without waiting for it to complete? Assuming your system supports such things, just send an appropriate signal to the process (see \"kill\" in perlfunc). It's common to first send a TERM signal, wait a little bit, and then send a KILL signal to finish it off. How do I fork a daemon process? If by daemon process you mean one that's detached (disassociated from its tty), then the following process is reported to work on most Unixish systems. Non-Unix users should check their Your_OS::Process module for other solutions. \u2022 Open \/dev\/tty and use the TIOCNOTTY ioctl on it. See tty for details. Or better yet, you can just use the POSIX::setsid() function, so you don't have to worry about process groups. \u2022 Change directory to \/ \u2022 Reopen STDIN , STDOUT , and STDERR so they're not connected to the old tty. \u2022 Background yourself like this: fork && exit; The Proc::Daemon module, available from CPAN , provides a function to perform these actions for you. How do I find out if I'm running interactively or not? Good question. Sometimes \"-t STDIN\" and \"-t STDOUT\" can give clues, sometimes not. if (-t STDIN && -t STDOUT) {\n        print \"Now what? \";\n        } On POSIX systems, you can test whether your own process group matches the current process group of your controlling terminal as follows: use POSIX qw\/getpgrp tcgetpgrp\/;\n\n# Some POSIX systems, such as Linux, can be\n# without a \/dev\/tty at boot time.\nif (!open(TTY, \"\/dev\/tty\")) {\n        print \"no tty\\n\";\n} else {\n        $tpgrp = tcgetpgrp(fileno(*TTY));\n        $pgrp = getpgrp();\n        if ($tpgrp == $pgrp) {\n                print \"foreground\\n\";\n        } else {\n                print \"background\\n\";\n        }\n} How do I timeout a slow event? Use the alarm() function, probably in conjunction with a signal handler, as documented in \"Signals\" in perlipc and the section on \"Signals\" in the Camel. You may instead use the more flexible Sys::AlarmCall module available from CPAN . The alarm() function is not implemented on all versions of Windows. Check the documentation for your specific version of Perl. How do I set CPU limits? (contributed by Xho) Use the \"BSD::Resource\" module from CPAN . As an example: use BSD::Resource;\nsetrlimit(RLIMIT_CPU,10,20) or die $!; This sets the soft and hard limits to 10 and 20 seconds, respectively. After 10 seconds of time spent running on the CPU (not \"wall\" time), the process will be sent a signal ( XCPU on some systems) which, if not trapped, will cause the process to terminate. If that signal is trapped, then after 10 more seconds (20 seconds in total) the process will be killed with a non-trappable signal. See the \"BSD::Resource\" and your systems documentation for the gory details. How do I avoid zombies on a Unix system? Use the reaper code from \"Signals\" in perlipc to call wait() when a SIGCHLD is received, or else use the double-fork technique described in \"How do I start a process in the background?\" in perlfaq8. How do I use an SQL database? The DBI module provides an abstract interface to most database servers and types, including Oracle, DB2 , Sybase, mysql, Postgresql, ODBC , and flat files. The DBI module accesses each database type through a database driver, or DBD . You can see a complete list of available drivers on CPAN: http:\/\/www.cpan.org\/modules\/by-module\/DBD\/ . You can read more about DBI on http:\/\/dbi.perl.org . Other modules provide more specific access: Win32::ODBC, Alzabo, iodbc, and others found on CPAN Search: http:\/\/search.cpan.org . How do I make a system() exit on control-C? You can't. You need to imitate the system() call (see perlipc for sample code) and then have a signal handler for the INT signal that passes the signal on to the subprocess. Or you can check for it: $rc = system($cmd);\nif ($rc & 127) { die \"signal death\" } How do I open a file without blocking? If you're lucky enough to be using a system that supports non-blocking reads (most Unixish systems do), you need only to use the O_NDELAY or O_NONBLOCK flag from the Fcntl module in conjunction with sysopen(): use Fcntl;\nsysopen(FH, \"\/foo\/somefile\", O_WRONLY|O_NDELAY|O_CREAT, 0644)\n        or die \"can't open \/foo\/somefile: $!\": How do I tell the difference between errors from the shell and perl? (answer contributed by brian d foy) When you run a Perl script, something else is running the script for you, and that something else may output error messages. The script might emit its own warnings and error messages. Most of the time you cannot tell who said what. You probably cannot fix the thing that runs perl, but you can change how perl outputs its warnings by defining a custom warning and die functions. Consider this script, which has an error you may not notice immediately. #!\/usr\/locl\/bin\/perl\n\nprint \"Hello World\\n\"; I get an error when I run this from my shell (which happens to be bash). That may look like perl forgot it has a print() function, but my shebang line is not the path to perl, so the shell runs the script, and I get the error. $ .\/test\n.\/test: line 3: print: command not found A quick and dirty fix involves a little bit of code, but this may be all you need to figure out the problem. #!\/usr\/bin\/perl -w\n\nBEGIN {\n$SIG{__WARN__} = sub{ print STDERR \"Perl: \", @_; };\n$SIG{__DIE__}  = sub{ print STDERR \"Perl: \", @_; exit 1};\n}\n\n$a = 1 + undef;\n$x \/ 0;\n__END__ The perl message comes out with \"Perl\" in front. The BEGIN block works at compile time so all of the compilation errors and warnings get the \"Perl:\" prefix too. Perl: Useless use of division (\/) in void context at .\/test line 9.\nPerl: Name \"main::a\" used only once: possible typo at .\/test line 8.\nPerl: Name \"main::x\" used only once: possible typo at .\/test line 9.\nPerl: Use of uninitialized value in addition (+) at .\/test line 8.\nPerl: Use of uninitialized value in division (\/) at .\/test line 9.\nPerl: Illegal division by zero at .\/test line 9.\nPerl: Illegal division by zero at -e line 3. If I don't see that \"Perl:\", it's not from perl. You could also just know all the perl errors, and although there are some people who may know all of them, you probably don't. However, they all should be in the perldiag manpage. If you don't find the error in there, it probably isn't a perl error. Looking up every message is not the easiest way, so let perl to do it for you. Use the diagnostics pragma with turns perl's normal messages into longer discussions on the topic. use diagnostics; If you don't get a paragraph or two of expanded discussion, it might not be perl's message. How do I install a module from CPAN ? The easiest way is to have a module also named CPAN do it for you. This module comes with perl version 5.004 and later. $ perl -MCPAN -e shell\n\ncpan shell -- CPAN exploration and modules installation (v1.59_54)\nReadLine support enabled\n\ncpan> install Some::Module To manually install the CPAN module, or any well-behaved CPAN module for that matter, follow these steps: 1. Unpack the source into a temporary area. 2. perl Makefile.PL 3. make 4. make test 5. make install If your version of perl is compiled without dynamic loading, then you just need to replace step 3 ( make) with make perl and you will get a new perl binary with your extension linked in. See ExtUtils::MakeMaker for more details on building extensions. See also the next question, \"What's the difference between require and use?\". What's the difference between require and use? (contributed by brian d foy) Perl runs \"require\" statement at run-time. Once Perl loads, compiles, and runs the file, it doesn't do anything else. The \"use\" statement is the same as a \"require\" run at compile-time, but Perl also calls the \"import\" method for the loaded package. These two are the same: use MODULE qw(import list);\n\nBEGIN {\n        require MODULE;\n        MODULE->import(import list);\n        } However, you can suppress the \"import\" by using an explicit, empty import list. Both of these still happen at compile-time: use MODULE ();\n\nBEGIN {\n        require MODULE;\n        } Since \"use\" will also call the \"import\" method, the actual value for \"MODULE\" must be a bareword. That is, \"use\" cannot load files by name, although \"require\" can: require \"$ENV{HOME}\/lib\/Foo.pm\"; # no @INC searching! See the entry for \"use\" in perlfunc for more details. How do I keep my own module\/library directory? When you build modules, tell Perl where to install the modules. For \"Makefile.PL\"-based distributions, use the INSTALL_BASE option when generating Makefiles: perl Makefile.PL INSTALL_BASE=\/mydir\/perl You can set this in your CPAN .pm configuration so modules automatically install in your private library directory when you use the CPAN .pm shell: % cpan\ncpan> o conf makepl_arg INSTALL_BASE=\/mydir\/perl\ncpan> o conf commit For \"Build.PL\"-based distributions, use the --install_base option: perl Build.PL --install_base \/mydir\/perl You can configure CPAN .pm to automatically use this option too: % cpan\ncpan> o conf mbuild_arg --install_base \/mydir\/perl\ncpan> o conf commit INSTALL_BASE tells these tools to put your modules into \/mydir\/perl\/lib\/perl5. See \"How do I add a directory to my include path (@INC) at runtime?\" for details on how to run your newly installed moudles. There is one caveat with INSTALL_BASE , though, since it acts differently than the PREFIX and LIB settings that older versions of ExtUtils::MakeMaker advocated. INSTALL_BASE does not support installing modules for multiple versions of Perl or different architectures under the same directory. You should consider if you really want that , and if you do, use the older PREFIX and LIB settings. See the ExtUtils::Makemaker documentation for more details. How do I add the directory my program lives in to the module\/library search path? (contributed by brian d foy) If you know the directory already, you can add it to @INC as you would for any other directory. You might <use lib> if you know the directory at compile time: use lib $directory; The trick in this task is to find the directory. Before your script does anything else (such as a \"chdir\"), you can get the current working directory with the \"Cwd\" module, which comes with Perl: BEGIN {\n        use Cwd;\n        our $directory = cwd;\n        }\n\nuse lib $directory; You can do a similar thing with the value of $0, which holds the script name. That might hold a relative path, but \"rel2abs\" can turn it into an absolute path. Once you have the BEGIN {\n        use File::Spec::Functions qw(rel2abs);\n        use File::Basename qw(dirname);\n\n        my $path   = rel2abs( $0 );\n        our $directory = dirname( $path );\n        }\n\nuse lib $directory; The \"FindBin\" module, which comes with Perl, might work. It finds the directory of the currently running script and puts it in $Bin, which you can then use to construct the right library path: use FindBin qw($Bin); How do I add a directory to my include path (@INC) at runtime? Here are the suggested ways of modifying your include path, including environment variables, run-time switches, and in-code statements: the PERLLIB environment variable $ export PERLLIB=\/path\/to\/my\/dir\n$ perl program.pl the PERL5LIB environment variable $ export PERL5LIB=\/path\/to\/my\/dir\n$ perl program.pl the perl -Idir command line flag $ perl -I\/path\/to\/my\/dir program.pl the use lib pragma: use lib \"$ENV{HOME}\/myown_perllib\"; The last is particularly useful because it knows about machine dependent architectures. The lib.pm pragmatic module was first included with the 5.002 release of Perl. What is socket.ph and where do I get it? It's a Perl 4 style file defining values for system networking constants. Sometimes it is built using h2ph when Perl is installed, but other times it is not. Modern programs \"use Socket;\" instead.","Process Name":"perlfaq8","Link":"https:\/\/linux.die.net\/man\/1\/perlfaq8"}},{"Process":{"Description":"This section deals with questions related to networking, the internet, and a few on the web. What is the correct form of response from a CGI script? (Alan Flavell <flavell+ www@a5.ph.gla.ac.uk> answers...) The Common Gateway Interface ( CGI ) specifies a software interface between a program (\" CGI script\") and a web server ( HTTPD ). It is not specific to Perl, and has its own FAQs and tutorials, and usenet group, comp.infosystems.www.authoring.cgi The CGI specification is outlined in an informational RFC: http:\/\/www.ietf.org\/rfc\/rfc3875 Other relevant documentation listed in: http:\/\/www.perl.org\/CGI_MetaFAQ.html These Perl FAQs very selectively cover some CGI issues. However, Perl programmers are strongly advised to use the CGI .pm module, to take care of the details for them. The similarity between CGI response headers (defined in the CGI specification) and HTTP response headers (defined in the HTTP specification, RFC2616 ) is intentional, but can sometimes be confusing. The CGI specification defines two kinds of script: the \"Parsed Header\" script, and the \"Non Parsed Header\" ( NPH ) script. Check your server documentation to see what it supports. \"Parsed Header\" scripts are simpler in various respects. The CGI specification allows any of the usual newline representations in the CGI response (it's the server's job to create an accurate HTTP response based on it). So \"\\n\" written in text mode is technically correct, and recommended. NPH scripts are more tricky: they must put out a complete and accurate set of HTTP transaction response headers; the HTTP specification calls for records to be terminated with carriage-return and line-feed, i.e ASCII \\015\\012 written in binary mode. Using CGI .pm gives excellent platform independence, including EBCDIC systems. CGI .pm selects an appropriate newline representation ($CGI::CRLF) and sets binmode as appropriate. My CGI script runs from the command line but not the browser. (500 Server Error) Several things could be wrong. You can go through the \"Troubleshooting Perl CGI scripts\" guide at http:\/\/www.perl.org\/troubleshooting_CGI.html If, after that, you can demonstrate that you've read the FAQs and that your problem isn't something simple that can be easily answered, you'll probably receive a courteous and useful reply to your question if you post it on comp.infosystems.www.authoring.cgi (if it's something to do with HTTP or the CGI protocols). Questions that appear to be Perl questions but are really CGI ones that are posted to comp.lang.perl.misc are not so well received. The useful FAQs, related documents, and troubleshooting guides are listed in the CGI Meta FAQ: http:\/\/www.perl.org\/CGI_MetaFAQ.html How can I get better error messages from a CGI program? Use the CGI::Carp module. It replaces \"warn\" and \"die\", plus the normal Carp modules \"carp\", \"croak\", and \"confess\" functions with more verbose and safer versions. It still sends them to the normal server error log. use CGI::Carp;\nwarn \"This is a complaint\";\ndie \"But this one is serious\"; The following use of CGI::Carp also redirects errors to a file of your choice, placed in a BEGIN block to catch compile-time warnings as well: BEGIN {\n        use CGI::Carp qw(carpout);\n        open(LOG, \">>\/var\/local\/cgi-logs\/mycgi-log\")\n                or die \"Unable to append to mycgi-log: $!\\n\";\n        carpout(*LOG);\n} You can even arrange for fatal errors to go back to the client browser, which is nice for your own debugging, but might confuse the end user. use CGI::Carp qw(fatalsToBrowser);\ndie \"Bad error here\"; Even if the error happens before you get the HTTP header out, the module will try to take care of this to avoid the dreaded server 500 errors. Normal warnings still go out to the server error log (or wherever you've sent them with \"carpout\") with the application name and date stamp prepended. How do I remove HTML from a string? The most correct way (albeit not the fastest) is to use HTML::Parser from CPAN . Another mostly correct way is to use HTML::FormatText which not only removes HTML but also attempts to do a little simple formatting of the resulting plain text. Many folks attempt a simple-minded regular expression approach, like \"s\/<.*?>\/\/g\", but that fails in many cases because the tags may continue over line breaks, they may contain quoted angle-brackets, or HTML comment may be present. Plus, folks forget to convert entities--like \"&lt;\" for example. Here's one \"simple-minded\" approach, that works for most files: #!\/usr\/bin\/perl -p0777\ns\/<(?:[^>'\"]*|(['\"]).*?\\1)*>\/\/gs If you want a more complete solution, see the 3-stage striphtml program in http:\/\/www.cpan.org\/authors\/Tom_Christiansen\/scripts\/striphtml.gz . Here are some tricky cases that you should think about when picking a solution: <IMG SRC = \"foo.gif\" ALT = \"A > B\">\n\n<IMG SRC = \"foo.gif\"\n ALT = \"A > B\">\n\n<!-- <A comment> -->\n\n<script>if (a<b && a>c)<\/script>\n\n<# Just data #>\n\n<![INCLUDE CDATA [ >>>>>>>>>>>> ]]> If HTML comments include other tags, those solutions would also break on text like this: <!-- This section commented out.\n        <B>You can't see me!<\/B>\n--> How do I extract URLs? You can easily extract all sorts of URLs from HTML with \"HTML::SimpleLinkExtor\" which handles anchors, images, objects, frames, and many other tags that can contain a URL . If you need anything more complex, you can create your own subclass of \"HTML::LinkExtor\" or \"HTML::Parser\". You might even use \"HTML::SimpleLinkExtor\" as an example for something specifically suited to your needs. You can use URI::Find to extract URLs from an arbitrary text document. Less complete solutions involving regular expressions can save you a lot of processing time if you know that the input is simple. One solution from Tom Christiansen runs 100 times faster than most module based approaches but only extracts URLs from anchors where the first attribute is HREF and there are no other attributes. #!\/usr\/bin\/perl -n00\n# qxurl - tchrist@perl.com\nprint \"$2\\n\" while m{\n        < \\s*\n          A \\s+ HREF \\s* = \\s* ([\"']) (.*?) \\1\n        \\s* >\n}gsix; How do I download a file from the user's machine? How do I open a file on another machine? In this case, download means to use the file upload feature of HTML forms. You allow the web surfer to specify a file to send to your web server. To you it looks like a download, and to the user it looks like an upload. No matter what you call it, you do it with what's known as multipart\/form-data encoding. The CGI .pm module (which comes with Perl as part of the Standard Library) supports this in the start_multipart_form() method, which isn't the same as the startform() method. See the section in the CGI .pm documentation on file uploads for code examples and details. How do I make an HTML pop-up menu with Perl? (contributed by brian d foy) The CGI .pm module (which comes with Perl) has functions to create the HTML form widgets. See the CGI .pm documentation for more examples. use CGI qw\/:standard\/;\nprint header,\n        start_html('Favorite Animals'),\n\n        start_form,\n                \"What's your favorite animal? \",\n        popup_menu(\n                -name   => 'animal',\n                -values => [ qw( Llama Alpaca Camel Ram ) ]\n                ),\n        submit,\n\n        end_form,\n        end_html; How do I fetch an HTML file? (contributed by brian d foy) Use the libwww-perl distribution. The \"LWP::Simple\" module can fetch web resources and give their content back to you as a string: use LWP::Simple qw(get);\n\nmy $html = get( \"http:\/\/www.example.com\/index.html\" ); It can also store the resource directly in a file: use LWP::Simple qw(getstore);\n\ngetstore( \"http:\/\/www.example.com\/index.html\", \"foo.html\" ); If you need to do something more complicated, you can use \"LWP::UserAgent\" module to create your own user-agent (e.g. browser) to get the job done. If you want to simulate an interactive web browser, you can use the \"WWW::Mechanize\" module. How do I automate an HTML form submission? If you are doing something complex, such as moving through many pages and forms or a web site, you can use \"WWW::Mechanize\". See its documentation for all the details. If you're submitting values using the GET method, create a URL and encode the form using the \"query_form\" method: use LWP::Simple;\nuse URI::URL;\n\nmy $url = url('http:\/\/www.perl.com\/cgi-bin\/cpan_mod');\n$url->query_form(module => 'DB_File', readme => 1);\n$content = get($url); If you're using the POST method, create your own user agent and encode the content appropriately. use HTTP::Request::Common qw(POST);\nuse LWP::UserAgent;\n\n$ua = LWP::UserAgent->new();\nmy $req = POST 'http:\/\/www.perl.com\/cgi-bin\/cpan_mod',\n                           [ module => 'DB_File', readme => 1 ];\n$content = $ua->request($req)->as_string; How do I decode or create those %-encodings on the web? (contributed by brian d foy) Those \"%\" encodings handle reserved characters in URIs, as described in RFC 2396, Section 2. This encoding replaces the reserved character with the hexadecimal representation of the character's number from the US-ASCII table. For instance, a colon, \":\", becomes %3A. In CGI scripts, you don't have to worry about decoding URIs if you are using \"CGI.pm\". You shouldn't have to process the URI yourself, either on the way in or the way out. If you have to encode a string yourself, remember that you should never try to encode an already-composed URI . You need to escape the components separately then put them together. To encode a string, you can use the the \"URI::Escape\" module. The \"uri_escape\" function returns the escaped string: my $original = \"Colon : Hash # Percent %\";\n\nmy $escaped = uri_escape( $original )\n\nprint \"$string\\n\"; # 'Colon%20%3A%20Hash%20%23%20Percent%20%25%20' To decode the string, use the \"uri_unescape\" function: my $unescaped = uri_unescape( $escaped );\n\nprint $unescaped; # back to original If you wanted to do it yourself, you simply need to replace the reserved characters with their encodings. A global substitution is one way to do it: # encode\n$string =~ s\/([^^A-Za-z0-9\\-_.!~*'()])\/ sprintf \"%%%0x\", ord $1 \/eg;\n\n#decode\n$string =~ s\/%([A-Fa-f\\d]{2})\/chr hex $1\/eg; How do I redirect to another page? Specify the complete URL of the destination (even if it is on the same server). This is one of the two different kinds of CGI \"Location:\" responses which are defined in the CGI specification for a Parsed Headers script. The other kind (an absolute URLpath) is resolved internally to the server without any HTTP redirection. The CGI specifications do not allow relative URLs in either case. Use of CGI .pm is strongly recommended. This example shows redirection with a complete URL . This redirection is handled by the web browser. use CGI qw\/:standard\/;\n\nmy $url = 'http:\/\/www.cpan.org\/';\nprint redirect($url); This example shows a redirection with an absolute URLpath. This redirection is handled by the local web server. my $url = '\/CPAN\/index.html';\nprint redirect($url); But if coded directly, it could be as follows (the final \"\\n\" is shown separately, for clarity), using either a complete URL or an absolute URLpath. print \"Location: $url\\n\";   # CGI response header\nprint \"\\n\";                 # end of headers How do I put a password on my web pages? To enable authentication for your web server, you need to configure your web server. The configuration is different for different sorts of web servers--apache does it differently from iPlanet which does it differently from IIS . Check your web server documentation for the details for your particular server. How do I edit my .htpasswd and .htgroup files with Perl? The HTTPD::UserAdmin and HTTPD::GroupAdmin modules provide a consistent OO interface to these files, regardless of how they're stored. Databases may be text, dbm, Berkeley DB or any database with a DBI compatible driver. HTTPD::UserAdmin supports files used by the \"Basic\" and \"Digest\" authentication schemes. Here's an example: use HTTPD::UserAdmin ();\nHTTPD::UserAdmin\n  ->new(DB => \"\/foo\/.htpasswd\")\n  ->add($username => $password); How do I make sure users can't enter values into a form that cause my CGI script to do bad things? See the security references listed in the CGI Meta FAQ http:\/\/www.perl.org\/CGI_MetaFAQ.html How do I parse a mail header? For a quick-and-dirty solution, try this solution derived from \"split\" in perlfunc: $\/ = '';\n$header = <MSG>;\n$header =~ s\/\\n\\s+\/ \/g;  # merge continuation lines\n%head = ( UNIX_FROM_LINE, split \/^([-\\w]+):\\s*\/m, $header ); That solution doesn't do well if, for example, you're trying to maintain all the Received lines. A more complete approach is to use the Mail::Header module from CPAN (part of the MailTools package). How do I decode a CGI form? (contributed by brian d foy) Use the CGI .pm module that comes with Perl. It's quick, it's easy, and it actually does quite a bit of work to ensure things happen correctly. It handles GET , POST , and HEAD requests, multipart forms, multivalued fields, query string and message body combinations, and many other things you probably don't want to think about. It doesn't get much easier: the CGI module automatically parses the input and makes each value available through the \"param()\" function. use CGI qw(:standard);\n\nmy $total = param( 'price' ) + param( 'shipping' );\n\nmy @items = param( 'item' ); # multiple values, same field name If you want an object-oriented approach, CGI .pm can do that too. use CGI;\n\nmy $cgi = CGI->new();\n\nmy $total = $cgi->param( 'price' ) + $cgi->param( 'shipping' );\n\nmy @items = $cgi->param( 'item' ); You might also try CGI::Minimal which is a lightweight version of the same thing. Other CGI::* modules on CPAN might work better for you, too. Many people try to write their own decoder (or copy one from another program) and then run into one of the many \"gotchas\" of the task. It's much easier and less hassle to use CGI .pm. How do I check a valid mail address? (partly contributed by Aaron Sherman) This isn't as simple a question as it sounds. There are two parts: a) How do I verify that an email address is correctly formatted? b) How do I verify that an email address targets a valid recipient? Without sending mail to the address and seeing whether there's a human on the other end to answer you, you cannot fully answer part b, but either the \"Email::Valid\" or the \"RFC::RFC822::Address\" module will do both part a and part b as far as you can in real-time. If you want to just check part a to see that the address is valid according to the mail header standard with a simple regular expression, you can have problems, because there are deliverable addresses that aren't RFC-2822 (the latest mail header standard) compliant, and addresses that aren't deliverable which, are compliant. However, the following will match valid RFC-2822 addresses that do not have comments, folding whitespace, or any other obsolete or non-essential elements. This just matches the address itself: my $atom       = qr{[a-zA-Z0-9_!#\\$\\%&'*+\/=?\\^`{}~|\\-]+};\nmy $dot_atom   = qr{$atom(?:\\.$atom)*};\nmy $quoted     = qr{\"(?:\\\\[^\\r\\n]|[^\\\\\"])*\"};\nmy $local      = qr{(?:$dot_atom|$quoted)};\nmy $quotedpair = qr{\\\\[\\x00-\\x09\\x0B-\\x0c\\x0e-\\x7e]};\nmy $domain_lit = qr{\\[(?:$quotedpair|[\\x21-\\x5a\\x5e-\\x7e])*\\]};\nmy $domain     = qr{(?:$dot_atom|$domain_lit)};\nmy $addr_spec  = qr{$local\\@$domain}; Just match an address against \"\/^${addr_spec}$\/\" to see if it follows the RFC2822 specification. However, because it is impossible to be sure that such a correctly formed address is actually the correct way to reach a particular person or even has a mailbox associated with it, you must be very careful about how you use this. Our best advice for verifying a person's mail address is to have them enter their address twice, just as you normally do to change a password. This usually weeds out typos. If both versions match, send mail to that address with a personal message. If you get the message back and they've followed your directions, you can be reasonably assured that it's real. A related strategy that's less open to forgery is to give them a PIN (personal ID number). Record the address and PIN (best that it be a random one) for later processing. In the mail you send, ask them to include the PIN in their reply. But if it bounces, or the message is included via a \"vacation\" script, it'll be there anyway. So it's best to ask them to mail back a slight alteration of the PIN , such as with the characters reversed, one added or subtracted to each digit, etc. How do I decode a MIME\/BASE64 string? The MIME-Base64 package (available from CPAN ) handles this as well as the MIME\/QP encoding. Decoding BASE64 becomes as simple as: use MIME::Base64;\n$decoded = decode_base64($encoded); The MIME-Tools package (available from CPAN ) supports extraction with decoding of BASE64 encoded attachments and content directly from email messages. If the string to decode is short (less than 84 bytes long) a more direct approach is to use the unpack() function's \"u\" format after minor transliterations: tr#A-Za-z0-9+\/##cd;                   # remove non-base64 chars\ntr#A-Za-z0-9+\/# -_#;                  # convert to uuencoded format\n$len = pack(\"c\", 32 + 0.75*length);   # compute length byte\nprint unpack(\"u\", $len . $_);         # uudecode and print How do I return the user's mail address? On systems that support getpwuid, the $< variable, and the Sys::Hostname module (which is part of the standard perl distribution), you can probably try using something like this: use Sys::Hostname;\n$address = sprintf('%s@%s', scalar getpwuid($<), hostname); Company policies on mail address can mean that this generates addresses that the company's mail system will not accept, so you should ask for users' mail addresses when this matters. Furthermore, not all systems on which Perl runs are so forthcoming with this information as is Unix. The Mail::Util module from CPAN (part of the MailTools package) provides a mailaddress() function that tries to guess the mail address of the user. It makes a more intelligent guess than the code above, using information given when the module was installed, but it could still be incorrect. Again, the best way is often just to ask the user. How do I send mail? Use the \"sendmail\" program directly: open(SENDMAIL, \"|\/usr\/lib\/sendmail -oi -t -odq\")\n        or die \"Can't fork for sendmail: $!\\n\";\nprint SENDMAIL <<\"EOF\";\nFrom: User Originating Mail <me\\@host>\nTo: Final Destination <you\\@otherhost>\nSubject: A relevant subject line\n\nBody of the message goes here after the blank line\nin as many lines as you like.\nEOF\nclose(SENDMAIL)     or warn \"sendmail didn't close nicely\"; The -oi option prevents sendmail from interpreting a line consisting of a single dot as \"end of message\". The -t option says to use the headers to decide who to send the message to, and -odq says to put the message into the queue. This last option means your message won't be immediately delivered, so leave it out if you want immediate delivery. Alternate, less convenient approaches include calling mail (sometimes called mailx) directly or simply opening up port 25 have having an intimate conversation between just you and the remote SMTP daemon, probably sendmail. Or you might be able use the CPAN module Mail::Mailer: use Mail::Mailer;\n\n$mailer = Mail::Mailer->new();\n$mailer->open({ From    => $from_address,\n                                To      => $to_address,\n                                Subject => $subject,\n                          })\n        or die \"Can't open: $!\\n\";\nprint $mailer $body;\n$mailer->close(); The Mail::Internet module uses Net::SMTP which is less Unix-centric than Mail::Mailer, but less reliable. Avoid raw SMTP commands. There are many reasons to use a mail transport agent like sendmail. These include queuing, MX records, and security. How do I use MIME to make an attachment to a mail message? This answer is extracted directly from the MIME::Lite documentation. Create a multipart message (i.e., one with attachments). use MIME::Lite;\n\n### Create a new multipart message:\n$msg = MIME::Lite->new(\n                         From    =>'me@myhost.com',\n                         To      =>'you@yourhost.com',\n                         Cc      =>'some@other.com, some@more.com',\n                         Subject =>'A message with 2 parts...',\n                         Type    =>'multipart\/mixed'\n                         );\n\n### Add parts (each \"attach\" has same arguments as \"new\"):\n$msg->attach(Type     =>'TEXT',\n                         Data     =>\"Here's the GIF file you wanted\"\n                         );\n$msg->attach(Type     =>'image\/gif',\n                         Path     =>'aaa000123.gif',\n                         Filename =>'logo.gif'\n                         );\n\n$text = $msg->as_string; MIME::Lite also includes a method for sending these things. $msg->send; This defaults to using sendmail but can be customized to use SMTP via Net::SMTP. How do I read mail? While you could use the Mail::Folder module from CPAN (part of the MailFolder package) or the Mail::Internet module from CPAN (part of the MailTools package), often a module is overkill. Here's a mail sorter. #!\/usr\/bin\/perl\n\nmy(@msgs, @sub);\nmy $msgno = -1;\n$\/ = '';                    # paragraph reads\nwhile (<>) {\n        if (\/^From \/m) {\n                \/^Subject:\\s*(?:Re:\\s*)*(.*)\/mi;\n                $sub[++$msgno] = lc($1) || '';\n        }\n        $msgs[$msgno] .= $_;\n}\nfor my $i (sort { $sub[$a] cmp $sub[$b] || $a <=> $b } (0 .. $#msgs)) {\n        print $msgs[$i];\n} Or more succinctly, #!\/usr\/bin\/perl -n00\n# bysub2 - awkish sort-by-subject\nBEGIN { $msgno = -1 }\n$sub[++$msgno] = (\/^Subject:\\s*(?:Re:\\s*)*(.*)\/mi)[0] if \/^From\/m;\n$msg[$msgno] .= $_;\nEND { print @msg[ sort { $sub[$a] cmp $sub[$b] || $a <=> $b } (0 .. $#msg) ] } How do I find out my hostname, domainname, or IP address? gethostbyname, Socket, Net::Domain, Sys::Hostname\" (contributed by brian d foy) The Net::Domain module, which is part of the standard distribution starting in perl5.7.3, can get you the fully qualified domain name ( FQDN ), the host name, or the domain name. use Net::Domain qw(hostname hostfqdn hostdomain);\n\nmy $host = hostfqdn(); The \"Sys::Hostname\" module, included in the standard distribution since perl5.6, can also get the hostname. use Sys::Hostname;\n\n$host = hostname(); To get the IP address, you can use the \"gethostbyname\" built-in function to turn the name into a number. To turn that number into the dotted octet form (a.b.c.d) that most people expect, use the \"inet_ntoa\" function from the <Socket> module, which also comes with perl. use Socket;\n\nmy $address = inet_ntoa(\n        scalar gethostbyname( $host || 'localhost' )\n        ); How do I fetch a news article or the active newsgroups? Use the Net::NNTP or News::NNTPClient modules, both available from CPAN . This can make tasks like fetching the newsgroup list as simple as perl -MNews::NNTPClient\n  -e 'print News::NNTPClient->new->list(\"newsgroups\")' How do I fetch\/put an FTP file? LWP::Simple (available from CPAN ) can fetch but not put. Net::FTP (also available from CPAN ) is more complex but can put as well as fetch. How can I do RPC in Perl? (Contributed by brian d foy) Use one of the RPC modules you can find on CPAN ( http:\/\/search.cpan.org\/search?query=RPC&mode=all ).","Process Name":"perlfaq9","Link":"https:\/\/linux.die.net\/man\/1\/perlfaq9"}},{"Process":{"Description":"This article is about a little-known feature of Perl called source filters. Source filters alter the program text of a module before Perl sees it, much as a C preprocessor alters the source text of a C program before the compiler sees it. This article tells you more about what source filters are, how they work, and how to write your own. The original purpose of source filters was to let you encrypt your program source to prevent casual piracy. This isn't all they can do, as you'll soon learn. But first, the basics.","Process Name":"perlfilter","Link":"https:\/\/linux.die.net\/man\/1\/perlfilter"}},{"Process":{"Description":"The fork() emulation is implemented at the level of the Perl interpreter. What this means in general is that running fork() will actually clone the running interpreter and all its state, and run the cloned interpreter in a separate thread, beginning execution in the new thread just after the point where the fork() was called in the parent. We will refer to the thread that implements this child \"process\" as the pseudo-process. To the Perl program that called fork(), all this is designed to be transparent. The parent returns from the fork() with a pseudo-process ID that can be subsequently used in any process manipulation functions; the child returns from the fork() with a value of 0 to signify that it is the child pseudo-process. Behavior of other Perl features in forked pseudo-processes Most Perl features behave in a natural way within pseudo-processes. $$ or $PROCESS_ID This special variable is correctly set to the pseudo-process ID . It can be used to identify pseudo-processes within a particular session. Note that this value is subject to recycling if any pseudo-processes are launched after others have been wait()-ed on. %ENV Each pseudo-process maintains its own virtual environment. Modifications to %ENV affect the virtual environment, and are only visible within that pseudo-process, and in any processes (or pseudo-processes) launched from it. chdir() and all other builtins that accept filenames Each pseudo-process maintains its own virtual idea of the current directory. Modifications to the current directory using chdir() are only visible within that pseudo-process, and in any processes (or pseudo-processes) launched from it. All file and directory accesses from the pseudo-process will correctly map the virtual working directory to the real working directory appropriately. wait() and waitpid() wait() and waitpid() can be passed a pseudo-process ID returned by fork(). These calls will properly wait for the termination of the pseudo-process and return its status. kill() kill() can be used to terminate a pseudo-process by passing it the ID returned by fork(). This should not be used except under dire circumstances, because the operating system may not guarantee integrity of the process resources when a running thread is terminated. Note that using kill() on a pseudo-process() may typically cause memory leaks, because the thread that implements the pseudo-process does not get a chance to clean up its resources. exec() Calling exec() within a pseudo-process actually spawns the requested executable in a separate process and waits for it to complete before exiting with the same exit status as that process. This means that the process ID reported within the running executable will be different from what the earlier Perl fork() might have returned. Similarly, any process manipulation functions applied to the ID returned by fork() will affect the waiting pseudo-process that called exec(), not the real process it is waiting for after the exec(). When exec() is called inside a pseudo-process then DESTROY methods and END blocks will still be called after the external process returns. exit() exit() always exits just the executing pseudo-process, after automatically wait()-ing for any outstanding child pseudo-processes. Note that this means that the process as a whole will not exit unless all running pseudo-processes have exited. See below for some limitations with open filehandles. Open handles to files, directories and network sockets All open handles are dup()-ed in pseudo-processes, so that closing any handles in one process does not affect the others. See below for some limitations. Resource limits In the eyes of the operating system, pseudo-processes created via the fork() emulation are simply threads in the same process. This means that any process-level limits imposed by the operating system apply to all pseudo-processes taken together. This includes any limits imposed by the operating system on the number of open file, directory and socket handles, limits on disk space usage, limits on memory size, limits on CPU utilization etc. Killing the parent process If the parent process is killed (either using Perl's kill() builtin, or using some external means) all the pseudo-processes are killed as well, and the whole process exits. Lifetime of the parent process and pseudo-processes During the normal course of events, the parent process and every pseudo-process started by it will wait for their respective pseudo-children to complete before they exit. This means that the parent and every pseudo-child created by it that is also a pseudo-parent will only exit after their pseudo-children have exited. A way to mark a pseudo-processes as running detached from their parent (so that the parent would not have to wait() for them if it doesn't want to) will be provided in future. CAVEATS AND LIMITATIONS BEGIN blocks The fork() emulation will not work entirely correctly when called from within a BEGIN block. The forked copy will run the contents of the BEGIN block, but will not continue parsing the source stream after the BEGIN block. For example, consider the following code: BEGIN {\n    fork and exit;          # fork child and exit the parent\n    print \"inner\\n\";\n}\nprint \"outer\\n\"; This will print: inner rather than the expected: inner\nouter This limitation arises from fundamental technical difficulties in cloning and restarting the stacks used by the Perl parser in the middle of a parse. Open filehandles Any filehandles open at the time of the fork() will be dup()-ed. Thus, the files can be closed independently in the parent and child, but beware that the dup()-ed handles will still share the same seek pointer. Changing the seek position in the parent will change it in the child and vice-versa. One can avoid this by opening files that need distinct seek pointers separately in the child. On some operating systems, notably Solaris and Unixware, calling \"exit()\" from a child process will flush and close open filehandles in the parent, thereby corrupting the filehandles. On these systems, calling \"_exit()\" is suggested instead. \"_exit()\" is available in Perl through the \"POSIX\" module. Please consult your systems manpages for more information on this. Forking pipe open() not yet implemented The \"open(FOO, \"|-\")\" and \"open(BAR, \"-|\")\" constructs are not yet implemented. This limitation can be easily worked around in new code by creating a pipe explicitly. The following example shows how to write to a forked child: # simulate open(FOO, \"|-\")\nsub pipe_to_fork ($) {\n    my $parent = shift;\n    pipe my $child, $parent or die;\n    my $pid = fork();\n    die \"fork() failed: $!\" unless defined $pid;\n    if ($pid) {\n        close $child;\n    }\n    else {\n        close $parent;\n        open(STDIN, \"<&=\" . fileno($child)) or die;\n    }\n    $pid;\n}\n\nif (pipe_to_fork('FOO')) {\n    # parent\n    print FOO \"pipe_to_fork\\n\";\n    close FOO;\n}\nelse {\n    # child\n    while (<STDIN>) { print; }\n    exit(0);\n} And this one reads from the child: # simulate open(FOO, \"-|\")\nsub pipe_from_fork ($) {\n    my $parent = shift;\n    pipe $parent, my $child or die;\n    my $pid = fork();\n    die \"fork() failed: $!\" unless defined $pid;\n    if ($pid) {\n        close $child;\n    }\n    else {\n        close $parent;\n        open(STDOUT, \">&=\" . fileno($child)) or die;\n    }\n    $pid;\n}\n\nif (pipe_from_fork('BAR')) {\n    # parent\n    while (<BAR>) { print; }\n    close BAR;\n}\nelse {\n    # child\n    print \"pipe_from_fork\\n\";\n    exit(0);\n} Forking pipe open() constructs will be supported in future. Global state maintained by XSUBs External subroutines (XSUBs) that maintain their own global state may not work correctly. Such XSUBs will either need to maintain locks to protect simultaneous access to global data from different pseudo-processes, or maintain all their state on the Perl symbol table, which is copied naturally when fork() is called. A callback mechanism that provides extensions an opportunity to clone their state will be provided in the near future. Interpreter embedded in larger application The fork() emulation may not behave as expected when it is executed in an application which embeds a Perl interpreter and calls Perl APIs that can evaluate bits of Perl code. This stems from the fact that the emulation only has knowledge about the Perl interpreter's own data structures and knows nothing about the containing application's state. For example, any state carried on the application's own call stack is out of reach. Thread-safety of extensions Since the fork() emulation runs code in multiple threads, extensions calling into non-thread-safe libraries may not work reliably when calling fork(). As Perl's threading support gradually becomes more widely adopted even on platforms with a native fork(), such extensions are expected to be fixed for thread-safety.","Process Name":"perlfork","Link":"https:\/\/linux.die.net\/man\/1\/perlfork"}},{"Process":{"Description":"Perl has a mechanism to help you generate simple reports and charts. To facilitate this, Perl helps you code up your output page close to how it will look when it's printed. It can keep track of things like how many lines are on a page, what page you're on, when to print page headers, etc. Keywords are borrowed from FORTRAN: format() to declare and write() to execute; see their entries in perlfunc. Fortunately, the layout is much more legible, more like BASIC 's PRINT USING statement. Think of it as a poor man's nroff(1). Formats, like packages and subroutines, are declared rather than executed, so they may occur at any point in your program. (Usually it's best to keep them all together though.) They have their own namespace apart from all the other \"types\" in Perl. This means that if you have a function named \"Foo\", it is not the same thing as having a format named \"Foo\". However, the default name for the format associated with a given filehandle is the same as the name of the filehandle. Thus, the default format for STDOUT is named \" STDOUT \", and the default format for filehandle TEMP is named \" TEMP \". They just look the same. They aren't. Output record formats are declared as follows: format NAME =\nFORMLIST\n. If the name is omitted, format \" STDOUT \" is defined. A single \".\" in column 1 is used to terminate a format. FORMLIST consists of a sequence of lines, each of which may be one of three types: 1. A comment, indicated by putting a '#' in the first column. 2. A \"picture\" line giving the format for one output line. 3. An argument line supplying values to plug into the previous picture line. Picture lines contain output field definitions, intermingled with literal text. These lines do not undergo any kind of variable interpolation. Field definitions are made up from a set of characters, for starting and extending a field to its desired width. This is the complete set of characters for field definitions: @    start of regular field\n^    start of special field\n<    pad character for left justification\n|    pad character for centering\n>    pad character for right justification\n#    pad character for a right justified numeric field\n0    instead of first #: pad number with leading zeroes\n.    decimal point within a numeric field\n...  terminate a text field, show \"...\" as truncation evidence\n@*   variable width field for a multi-line value\n^*   variable width field for next line of a multi-line value\n~    suppress line with all fields empty\n~~   repeat line until all fields are exhausted Each field in a picture line starts with either \"@\" (at) or \"^\" (caret), indicating what we'll call, respectively, a \"regular\" or \"special\" field. The choice of pad characters determines whether a field is textual or numeric. The tilde operators are not part of a field. Let's look at the various possibilities in detail. Text Fields The length of the field is supplied by padding out the field with multiple \"<\", \">\", or \"|\" characters to specify a non-numeric field with, respectively, left justification, right justification, or centering. For a regular field, the value (up to the first newline) is taken and printed according to the selected justification, truncating excess characters. If you terminate a text field with \"...\", three dots will be shown if the value is truncated. A special text field may be used to do rudimentary multi-line text block filling; see \"Using Fill Mode\" for details. Example:\n   format STDOUT =\n   @<<<<<<   @||||||   @>>>>>>\n   \"left\",   \"middle\", \"right\"\n   .\nOutput:\n   left      middle    right Numeric Fields Using \"#\" as a padding character specifies a numeric field, with right justification. An optional \".\" defines the position of the decimal point. With a \"0\" (zero) instead of the first \"#\", the formatted number will be padded with leading zeroes if necessary. A special numeric field is blanked out if the value is undefined. If the resulting value would exceed the width specified the field is filled with \"#\" as overflow evidence. Example:\n   format STDOUT =\n   @###   @.###   @##.###  @###   @###   ^####\n    42,   3.1415,  undef,    0, 10000,   undef\n   .\nOutput:\n     42   3.142     0.000     0   #### The Field @* for Variable Width Multi-Line Text The field \"@*\" can be used for printing multi-line, nontruncated values; it should (but need not) appear by itself on a line. A final line feed is chomped off, but all other characters are emitted verbatim. The Field ^* for Variable Width One-line-at-a-time Text Like \"@*\", this is a variable width field. The value supplied must be a scalar variable. Perl puts the first line (up to the first \"\\n\") of the text into the field, and then chops off the front of the string so that the next time the variable is referenced, more of the text can be printed. The variable will not be restored. Example:\n   $text = \"line 1\\nline 2\\nline 3\";\n   format STDOUT =\n   Text: ^*\n         $text\n   ~~    ^*\n         $text\n   .\nOutput:\n   Text: line 1\n         line 2\n         line 3 Specifying Values The values are specified on the following format line in the same order as the picture fields. The expressions providing the values must be separated by commas. They are all evaluated in a list context before the line is processed, so a single list expression could produce multiple list elements. The expressions may be spread out to more than one line if enclosed in braces. If so, the opening brace must be the first token on the first line. If an expression evaluates to a number with a decimal part, and if the corresponding picture specifies that the decimal part should appear in the output (that is, any picture except multiple \"#\" characters without an embedded \".\"), the character used for the decimal point is always determined by the current LC_NUMERIC locale. This means that, if, for example, the run-time environment happens to specify a German locale, \",\" will be used instead of the default \".\". See perllocale and \" WARNINGS \" for more information. Using Fill Mode On text fields the caret enables a kind of fill mode. Instead of an arbitrary expression, the value supplied must be a scalar variable that contains a text string. Perl puts the next portion of the text into the field, and then chops off the front of the string so that the next time the variable is referenced, more of the text can be printed. (Yes, this means that the variable itself is altered during execution of the write() call, and is not restored.) The next portion of text is determined by a crude line breaking algorithm. You may use the carriage return character ( \"\\r\") to force a line break. You can change which characters are legal to break on by changing the variable $: (that's $FORMAT_LINE_BREAK_CHARACTERS if you're using the English module) to a list of the desired characters. Normally you would use a sequence of fields in a vertical stack associated with the same scalar variable to print out a block of text. You might wish to end the final field with the text \"...\", which will appear in the output if the text was too long to appear in its entirety. Suppressing Lines Where All Fields Are Void Using caret fields can produce lines where all fields are blank. You can suppress such lines by putting a \"~\" (tilde) character anywhere in the line. The tilde will be translated to a space upon output. Repeating Format Lines If you put two contiguous tilde characters \"~~\" anywhere into a line, the line will be repeated until all the fields on the line are exhausted, i.e. undefined. For special (caret) text fields this will occur sooner or later, but if you use a text field of the at variety, the expression you supply had better not give the same value every time forever! ( \"shift(@f)\" is a simple example that would work.) Don't use a regular (at) numeric field in such lines, because it will never go blank. Top of Form Processing Top-of-form processing is by default handled by a format with the same name as the current filehandle with \"_TOP\" concatenated to it. It's triggered at the top of each page. See \"write\" in perlfunc. Examples: # a report on the \/etc\/passwd file\nformat STDOUT_TOP =\n                        Passwd File\nName                Login    Office   Uid   Gid Home\n------------------------------------------------------------------\n.\nformat STDOUT =\n@<<<<<<<<<<<<<<<<<< @||||||| @<<<<<<@>>>> @>>>> @<<<<<<<<<<<<<<<<<\n$name,              $login,  $office,$uid,$gid, $home\n.\n\n# a report from a bug report form\nformat STDOUT_TOP =\n                        Bug Reports\n@<<<<<<<<<<<<<<<<<<<<<<<     @|||         @>>>>>>>>>>>>>>>>>>>>>>>\n$system,                      $%,         $date\n------------------------------------------------------------------\n.\nformat STDOUT =\nSubject: @<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n         $subject\nIndex: @<<<<<<<<<<<<<<<<<<<<<<<<<<<< ^<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n       $index,                       $description\nPriority: @<<<<<<<<<< Date: @<<<<<<< ^<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n          $priority,        $date,   $description\nFrom: @<<<<<<<<<<<<<<<<<<<<<<<<<<<<< ^<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n      $from,                         $description\nAssigned to: @<<<<<<<<<<<<<<<<<<<<<< ^<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n             $programmer,            $description\n~                                    ^<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n                                     $description\n~                                    ^<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n                                     $description\n~                                    ^<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n                                     $description\n~                                    ^<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n                                     $description\n~                                    ^<<<<<<<<<<<<<<<<<<<<<<<...\n                                     $description\n. It is possible to intermix print()s with write()s on the same output channel, but you'll have to handle \"$-\" ( $FORMAT_LINES_LEFT) yourself. Format Variables The current format name is stored in the variable $~ ( $FORMAT_NAME), and the current top of form format name is in $^ ( $FORMAT_TOP_NAME). The current output page number is stored in $% ( $FORMAT_PAGE_NUMBER), and the number of lines on the page is in $= ( $FORMAT_LINES_PER_PAGE). Whether to autoflush output on this handle is stored in $| ( $OUTPUT_AUTOFLUSH). The string output before each top of page (except the first) is stored in $^L ( $FORMAT_FORMFEED). These variables are set on a per-filehandle basis, so you'll need to select() into a different one to affect them: select((select(OUTF),\n        $~ = \"My_Other_Format\",\n        $^ = \"My_Top_Format\"\n       )[0]); Pretty ugly, eh? It's a common idiom though, so don't be too surprised when you see it. You can at least use a temporary variable to hold the previous filehandle: (this is a much better approach in general, because not only does legibility improve, you now have intermediary stage in the expression to single-step the debugger through): $ofh = select(OUTF);\n$~ = \"My_Other_Format\";\n$^ = \"My_Top_Format\";\nselect($ofh); If you use the English module, you can even read the variable names: use English '-no_match_vars';\n$ofh = select(OUTF);\n$FORMAT_NAME     = \"My_Other_Format\";\n$FORMAT_TOP_NAME = \"My_Top_Format\";\nselect($ofh); But you still have those funny select()s. So just use the FileHandle module. Now, you can access these special variables using lowercase method names instead: use FileHandle;\nformat_name     OUTF \"My_Other_Format\";\nformat_top_name OUTF \"My_Top_Format\"; Much better!","Process Name":"perlform","Link":"https:\/\/linux.die.net\/man\/1\/perlform"}},{"Process":{"Description":"This document describes various features of FreeBSD that will affect how Perl version 5 (hereafter just Perl) is compiled and\/or runs. FreeBSD core dumps from readdir_r with ithreads When perl is configured to use ithreads, it will use re-entrant library calls in preference to non-re-entrant versions. There is a bug in FreeBSD's \"readdir_r\" function in versions 4.5 and earlier that can cause a SEGV when reading large directories. A patch for FreeBSD libc is available (see http:\/\/www.freebsd.org\/cgi\/query-pr.cgi?pr=misc\/30631 ) which has been integrated into FreeBSD 4.6. $^X doesn't always contain a full path in FreeBSD perl 5.8.0 sets $^X where possible to a full path by asking the operating system. On FreeBSD the full path of the perl interpreter is found by reading the symlink \/proc\/curproc\/file. There is a bug on FreeBSD, where the result of reading this symlink is can be wrong in certain circumstances (see http:\/\/www.freebsd.org\/cgi\/query-pr.cgi?pr=35703 ). In these cases perl will fall back to the old behaviour of using C's argv[0] value for $^X. Perl will no longer be part of \"base FreeBSD\" Not as bad as it sounds--what this means is that Perl will no longer be part of the kernel build system of FreeBSD. Perl will still very probably be part of the \"default install\", and in any case the latest version will be in the ports system. The first FreeBSD version this change will affect is 5.0, all 4.n versions will keep the status quo.","Process Name":"perlfreebsd","Link":"https:\/\/linux.die.net\/man\/1\/perlfreebsd"}},{"Process":{"Description":"The functions in this section can serve as terms in an expression. They fall into two major categories: list operators and named unary operators. These differ in their precedence relationship with a following comma. (See the precedence table in perlop.) List operators take more than one argument, while unary operators can never take more than one argument. Thus, a comma terminates the argument of a unary operator, but merely separates the arguments of a list operator. A unary operator generally provides a scalar context to its argument, while a list operator may provide either scalar or list contexts for its arguments. If it does both, the scalar arguments will be first, and the list argument will follow. (Note that there can ever be only one such list argument.) For instance, splice() has three scalar arguments followed by a list, whereas gethostbyname() has four scalar arguments. In the syntax descriptions that follow, list operators that expect a list (and provide list context for the elements of the list) are shown with LIST as an argument. Such a list may consist of any combination of scalar arguments or list values; the list values will be included in the list as if each individual element were interpolated at that point in the list, forming a longer single-dimensional list value. Commas should separate elements of the LIST . Any function in the list below may be used either with or without parentheses around its arguments. (The syntax descriptions omit the parentheses.) If you use the parentheses, the simple (but occasionally surprising) rule is this: It looks like a function, therefore it is a function, and precedence doesn't matter. Otherwise it's a list operator or unary operator, and precedence does matter. And whitespace between the function and left parenthesis doesn't count--so you need to be careful sometimes: print 1+2+4;        # Prints 7.\nprint(1+2) + 4;     # Prints 3.\nprint (1+2)+4;      # Also prints 3!\nprint +(1+2)+4;     # Prints 7.\nprint ((1+2)+4);    # Prints 7. If you run Perl with the -w switch it can warn you about this. For example, the third line above produces: print (...) interpreted as function at - line 1.\nUseless use of integer addition in void context at - line 1. A few functions take no arguments at all, and therefore work as neither unary nor list operators. These include such functions as \"time\" and \"endpwent\". For example, \"time+86_400\" always means \"time() + 86_400\". For functions that can be used in either a scalar or list context, nonabortive failure is generally indicated in a scalar context by returning the undefined value, and in a list context by returning the null list. Remember the following important rule: There is no rule that relates the behavior of an expression in list context to its behavior in scalar context, or vice versa. It might do two totally different things. Each operator and function decides which sort of value it would be most appropriate to return in scalar context. Some operators return the length of the list that would have been returned in list context. Some operators return the first value in the list. Some operators return the last value in the list. Some operators return a count of successful operations. In general, they do what you want, unless you want consistency. A named array in scalar context is quite different from what would at first glance appear to be a list in scalar context. You can't get a list like \"(1,2,3)\" into being in scalar context, because the compiler knows the context at compile time. It would generate the scalar comma operator there, not the list construction version of the comma. That means it was never a list to start with. In general, functions in Perl that serve as wrappers for system calls of the same name (like chown(2), fork(2), closedir(2), etc.) all return true when they succeed and \"undef\" otherwise, as is usually mentioned in the descriptions below. This is different from the C interfaces, which return \"-1\" on failure. Exceptions to this rule are \"wait\", \"waitpid\", and \"syscall\". System calls also set the special $! variable on failure. Other functions do not, except accidentally. Perl Functions by Category Here are Perl's functions (including things that look like functions, like some keywords and named operators) arranged by category. Some functions appear in more than one place. Functions for SCALARs or strings \"chomp\", \"chop\", \"chr\", \"crypt\", \"hex\", \"index\", \"lc\", \"lcfirst\", \"length\", \"oct\", \"ord\", \"pack\", \"q\/\/\", \"qq\/\/\", \"reverse\", \"rindex\", \"sprintf\", \"substr\", \"tr\/\/\/\", \"uc\", \"ucfirst\", \"y\/\/\/\" Regular expressions and pattern matching \"m\/\/\", \"pos\", \"quotemeta\", \"s\/\/\/\", \"split\", \"study\", \"qr\/\/\" Numeric functions \"abs\", \"atan2\", \"cos\", \"exp\", \"hex\", \"int\", \"log\", \"oct\", \"rand\", \"sin\", \"sqrt\", \"srand\" Functions for real @ARRAYs \"pop\", \"push\", \"shift\", \"splice\", \"unshift\" Functions for list data \"grep\", \"join\", \"map\", \"qw\/\/\", \"reverse\", \"sort\", \"unpack\" Functions for real %HASHes \"delete\", \"each\", \"exists\", \"keys\", \"values\" Input and output functions \"binmode\", \"close\", \"closedir\", \"dbmclose\", \"dbmopen\", \"die\", \"eof\", \"fileno\", \"flock\", \"format\", \"getc\", \"print\", \"printf\", \"read\", \"readdir\", \"rewinddir\", \"say\", \"seek\", \"seekdir\", \"select\", \"syscall\", \"sysread\", \"sysseek\", \"syswrite\", \"tell\", \"telldir\", \"truncate\", \"warn\", \"write\" Functions for fixed length data or records \"pack\", \"read\", \"syscall\", \"sysread\", \"syswrite\", \"unpack\", \"vec\" Functions for filehandles, files, or directories \"- X \", \"chdir\", \"chmod\", \"chown\", \"chroot\", \"fcntl\", \"glob\", \"ioctl\", \"link\", \"lstat\", \"mkdir\", \"open\", \"opendir\", \"readlink\", \"rename\", \"rmdir\", \"stat\", \"symlink\", \"sysopen\", \"umask\", \"unlink\", \"utime\" Keywords related to the control flow of your Perl program \"caller\", \"continue\", \"die\", \"do\", \"dump\", \"eval\", \"exit\", \"goto\", \"last\", \"next\", \"redo\", \"return\", \"sub\", \"wantarray\" Keywords related to switch \"break\", \"continue\", \"given\", \"when\", \"default\" (These are only available if you enable the \"switch\" feature. See feature and \"Switch statements\" in perlsyn.) Keywords related to scoping \"caller\", \"import\", \"local\", \"my\", \"our\", \"state\", \"package\", \"use\" (\"state\" is only available if the \"state\" feature is enabled. See feature.) Miscellaneous functions \"defined\", \"dump\", \"eval\", \"formline\", \"local\", \"my\", \"our\", \"reset\", \"scalar\", \"state\", \"undef\", \"wantarray\" Functions for processes and process groups \"alarm\", \"exec\", \"fork\", \"getpgrp\", \"getppid\", \"getpriority\", \"kill\", \"pipe\", \"qx\/\/\", \"setpgrp\", \"setpriority\", \"sleep\", \"system\", \"times\", \"wait\", \"waitpid\" Keywords related to perl modules \"do\", \"import\", \"no\", \"package\", \"require\", \"use\" Keywords related to classes and object-orientation \"bless\", \"dbmclose\", \"dbmopen\", \"package\", \"ref\", \"tie\", \"tied\", \"untie\", \"use\" Low-level socket functions \"accept\", \"bind\", \"connect\", \"getpeername\", \"getsockname\", \"getsockopt\", \"listen\", \"recv\", \"send\", \"setsockopt\", \"shutdown\", \"socket\", \"socketpair\" System V interprocess communication functions \"msgctl\", \"msgget\", \"msgrcv\", \"msgsnd\", \"semctl\", \"semget\", \"semop\", \"shmctl\", \"shmget\", \"shmread\", \"shmwrite\" Fetching user and group info \"endgrent\", \"endhostent\", \"endnetent\", \"endpwent\", \"getgrent\", \"getgrgid\", \"getgrnam\", \"getlogin\", \"getpwent\", \"getpwnam\", \"getpwuid\", \"setgrent\", \"setpwent\" Fetching network info \"endprotoent\", \"endservent\", \"gethostbyaddr\", \"gethostbyname\", \"gethostent\", \"getnetbyaddr\", \"getnetbyname\", \"getnetent\", \"getprotobyname\", \"getprotobynumber\", \"getprotoent\", \"getservbyname\", \"getservbyport\", \"getservent\", \"sethostent\", \"setnetent\", \"setprotoent\", \"setservent\" Time-related functions \"gmtime\", \"localtime\", \"time\", \"times\" Functions new in perl5 \"abs\", \"bless\", \"break\", \"chomp\", \"chr\", \"continue\", \"default\", \"exists\", \"formline\", \"given\", \"glob\", \"import\", \"lc\", \"lcfirst\", \"lock\", \"map\", \"my\", \"no\", \"our\", \"prototype\", \"qr\/\/\", \"qw\/\/\", \"qx\/\/\", \"readline\", \"readpipe\", \"ref\", \"sub\"*, \"sysopen\", \"tie\", \"tied\", \"uc\", \"ucfirst\", \"untie\", \"use\", \"when\" * - \"sub\" was a keyword in perl4, but in perl5 it is an operator, which can be used in expressions. Functions obsoleted in perl5 \"dbmclose\", \"dbmopen\" Portability Perl was born in Unix and can therefore access all common Unix system calls. In non-Unix environments, the functionality of some Unix system calls may not be available, or details of the available functionality may differ slightly. The Perl functions affected by this are: \"-X\", \"binmode\", \"chmod\", \"chown\", \"chroot\", \"crypt\", \"dbmclose\", \"dbmopen\", \"dump\", \"endgrent\", \"endhostent\", \"endnetent\", \"endprotoent\", \"endpwent\", \"endservent\", \"exec\", \"fcntl\", \"flock\", \"fork\", \"getgrent\", \"getgrgid\", \"gethostbyname\", \"gethostent\", \"getlogin\", \"getnetbyaddr\", \"getnetbyname\", \"getnetent\", \"getppid\", \"getpgrp\", \"getpriority\", \"getprotobynumber\", \"getprotoent\", \"getpwent\", \"getpwnam\", \"getpwuid\", \"getservbyport\", \"getservent\", \"getsockopt\", \"glob\", \"ioctl\", \"kill\", \"link\", \"lstat\", \"msgctl\", \"msgget\", \"msgrcv\", \"msgsnd\", \"open\", \"pipe\", \"readlink\", \"rename\", \"select\", \"semctl\", \"semget\", \"semop\", \"setgrent\", \"sethostent\", \"setnetent\", \"setpgrp\", \"setpriority\", \"setprotoent\", \"setpwent\", \"setservent\", \"setsockopt\", \"shmctl\", \"shmget\", \"shmread\", \"shmwrite\", \"socket\", \"socketpair\", \"stat\", \"symlink\", \"syscall\", \"sysopen\", \"system\", \"times\", \"truncate\", \"umask\", \"unlink\", \"utime\", \"wait\", \"waitpid\" For more information about the portability of these functions, see perlport and other available platform-specific documentation. Alphabetical Listing of Perl Functions -X FILEHANDLE -X EXPR -X DIRHANDLE -X A file test, where X is one of the letters listed below. This unary operator takes one argument, either a filename, a filehandle, or a dirhandle, and tests the associated file to see if something is true about it. If the argument is omitted, tests $_, except for \"-t\", which tests STDIN . Unless otherwise documented, it returns 1 for true and '' for false, or the undefined value if the file doesn't exist. Despite the funny names, precedence is the same as any other named unary operator. The operator may be any of: -r  File is readable by effective uid\/gid.\n-w  File is writable by effective uid\/gid.\n-x  File is executable by effective uid\/gid.\n-o  File is owned by effective uid.\n\n-R  File is readable by real uid\/gid.\n-W  File is writable by real uid\/gid.\n-X  File is executable by real uid\/gid.\n-O  File is owned by real uid.\n\n-e  File exists.\n-z  File has zero size (is empty).\n-s  File has nonzero size (returns size in bytes).\n\n-f  File is a plain file.\n-d  File is a directory.\n-l  File is a symbolic link.\n-p  File is a named pipe (FIFO), or Filehandle is a pipe.\n-S  File is a socket.\n-b  File is a block special file.\n-c  File is a character special file.\n-t  Filehandle is opened to a tty.\n\n-u  File has setuid bit set.\n-g  File has setgid bit set.\n-k  File has sticky bit set.\n\n-T  File is an ASCII text file (heuristic guess).\n-B  File is a \"binary\" file (opposite of -T).\n\n-M  Script start time minus file modification time, in days.\n-A  Same for access time.\n-C  Same for inode change time (Unix, may differ for other platforms) Example: while (<>) {\n    chomp;\n    next unless -f $_;      # ignore specials\n    #...\n} The interpretation of the file permission operators \"-r\", \"-R\", \"-w\", \"-W\", \"-x\", and \"-X\" is by default based solely on the mode of the file and the uids and gids of the user. There may be other reasons you can't actually read, write, or execute the file: for example network filesystem access controls, ACLs (access control lists), read-only filesystems, and unrecognized executable formats. Note that the use of these six specific operators to verify if some operation is possible is usually a mistake, because it may be open to race conditions. Also note that, for the superuser on the local filesystems, the \"-r\", \"-R\", \"-w\", and \"-W\" tests always return 1, and \"-x\" and \"-X\" return 1 if any execute bit is set in the mode. Scripts run by the superuser may thus need to do a stat() to determine the actual mode of the file, or temporarily set their effective uid to something else. If you are using ACLs, there is a pragma called \"filetest\" that may produce more accurate results than the bare stat() mode bits. When under the \"use filetest 'access'\" the above-mentioned filetests will test whether the permission can (not) be granted using the access() family of system calls. Also note that the \"-x\" and \"-X\" may under this pragma return true even if there are no execute permission bits set (nor any extra execute permission ACLs). This strangeness is due to the underlying system calls' definitions. Note also that, due to the implementation of \"use filetest 'access'\", the \"_\" special filehandle won't cache the results of the file tests when this pragma is in effect. Read the documentation for the \"filetest\" pragma for more information. Note that \"-s\/a\/b\/\" does not do a negated substitution. Saying \"-exp($foo)\" still works as expected, however--only single letters following a minus are interpreted as file tests. The \"-T\" and \"-B\" switches work as follows. The first block or so of the file is examined for odd characters such as strange control codes or characters with the high bit set. If too many strange characters (>30%) are found, it's a \"-B\" file; otherwise it's a \"-T\" file. Also, any file containing null in the first block is considered a binary file. If \"-T\" or \"-B\" is used on a filehandle, the current IO buffer is examined rather than the first block. Both \"-T\" and \"-B\" return true on a null file, or a file at EOF when testing a filehandle. Because you have to read a file to do the \"-T\" test, on most occasions you want to use a \"-f\" against the file first, as in \"next unless -f $file && -T $file\". If any of the file tests (or either the \"stat\" or \"lstat\" operators) are given the special filehandle consisting of a solitary underline, then the stat structure of the previous file test (or stat operator) is used, saving a system call. (This doesn't work with \"-t\", and you need to remember that lstat() and \"-l\" will leave values in the stat structure for the symbolic link, not the real file.) (Also, if the stat buffer was filled by an \"lstat\" call, \"-T\" and \"-B\" will reset it with the results of \"stat _\"). Example: print \"Can do.\\n\" if -r $a || -w _ || -x _;\n\nstat($filename);\nprint \"Readable\\n\" if -r _;\nprint \"Writable\\n\" if -w _;\nprint \"Executable\\n\" if -x _;\nprint \"Setuid\\n\" if -u _;\nprint \"Setgid\\n\" if -g _;\nprint \"Sticky\\n\" if -k _;\nprint \"Text\\n\" if -T _;\nprint \"Binary\\n\" if -B _; As of Perl 5.9.1, as a form of purely syntactic sugar, you can stack file test operators, in a way that \"-f -w -x $file\" is equivalent to \"-x $file && -w _ && -f _\". (This is only syntax fancy: if you use the return value of \"-f $file\" as an argument to another filetest operator, no special magic will happen.) abs VALUE abs Returns the absolute value of its argument. If VALUE is omitted, uses $_. accept NEWSOCKET ,GENERICSOCKET Accepts an incoming socket connect, just as the accept(2) system call does. Returns the packed address if it succeeded, false otherwise. See the example in \"Sockets: Client\/Server Communication\" in perlipc. On systems that support a close-on-exec flag on files, the flag will be set for the newly opened file descriptor, as determined by the value of $^F. See \"$^F\" in perlvar. alarm SECONDS alarm Arranges to have a SIGALRM delivered to this process after the specified number of wallclock seconds has elapsed. If SECONDS is not specified, the value stored in $_ is used. (On some machines, unfortunately, the elapsed time may be up to one second less or more than you specified because of how seconds are counted, and process scheduling may delay the delivery of the signal even further.) Only one timer may be counting at once. Each call disables the previous timer, and an argument of 0 may be supplied to cancel the previous timer without starting a new one. The returned value is the amount of time remaining on the previous timer. For delays of finer granularity than one second, the Time::HiRes module (from CPAN , and starting from Perl 5.8 part of the standard distribution) provides ualarm(). You may also use Perl's four-argument version of select() leaving the first three arguments undefined, or you might be able to use the \"syscall\" interface to access setitimer(2) if your system supports it. See perlfaq8 for details. It is usually a mistake to intermix \"alarm\" and \"sleep\" calls. (\"sleep\" may be internally implemented in your system with \"alarm\") If you want to use \"alarm\" to time out a system call you need to use an \"eval\"\/\"die\" pair. You can't rely on the alarm causing the system call to fail with $! set to \"EINTR\" because Perl sets up signal handlers to restart system calls on some systems. Using \"eval\"\/\"die\" always works, modulo the caveats given in \"Signals\" in perlipc. eval {\n    local $SIG{ALRM} = sub { die \"alarm\\n\" }; # NB: \\n required\n    alarm $timeout;\n    $nread = sysread SOCKET, $buffer, $size;\n    alarm 0;\n};\nif ($@) {\n    die unless $@ eq \"alarm\\n\";   # propagate unexpected errors\n    # timed out\n}\nelse {\n    # didn't\n} For more information see perlipc. atan2 Y,X Returns the arctangent of Y\/X in the range -PI to PI . For the tangent operation, you may use the \"Math::Trig::tan\" function, or use the familiar relation: sub tan { sin($_[0]) \/ cos($_[0])  } The return value for \"atan2(0,0)\" is implementation-defined; consult your atan2(3) manpage for more information. bind SOCKET ,NAME Binds a network address to a socket, just as the bind system call does. Returns true if it succeeded, false otherwise. NAME should be a packed address of the appropriate type for the socket. See the examples in \"Sockets: Client\/Server Communication\" in perlipc. binmode FILEHANDLE , LAYER binmode FILEHANDLE Arranges for FILEHANDLE to be read or written in \"binary\" or \"text\" mode on systems where the run-time libraries distinguish between binary and text files. If FILEHANDLE is an expression, the value is taken as the name of the filehandle. Returns true on success, otherwise it returns \"undef\" and sets $! (errno). On some systems (in general, DOS and Windows-based systems) binmode() is necessary when you're not working with a text file. For the sake of portability it is a good idea to always use it when appropriate, and to never use it when it isn't appropriate. Also, people can set their I\/O to be by default UTF-8 encoded Unicode, not bytes. In other words: regardless of platform, use binmode() on binary data, like for example images. If LAYER is present it is a single string, but may contain multiple directives. The directives alter the behaviour of the file handle. When LAYER is present using binmode on a text file makes sense. If LAYER is omitted or specified as \":raw\" the filehandle is made suitable for passing binary data. This includes turning off possible CRLF translation and marking it as bytes (as opposed to Unicode characters). Note that, despite what may be implied in \"Programming Perl\" (the Camel) or elsewhere, \":raw\" is not simply the inverse of \":crlf\" -- other layers which would affect the binary nature of the stream are also disabled. See PerlIO, perlrun and the discussion about the PERLIO environment variable. The \":bytes\", \":crlf\", and \":utf8\", and any other directives of the form \":...\", are called I\/O layers. The \"open\" pragma can be used to establish default I\/O layers. See open. The LAYER parameter of the binmode() function is described as \" DISCIPLINE \" in \"Programming Perl, 3rd Edition\". However, since the publishing of this book, by many known as \"Camel III \", the consensus of the naming of this functionality has moved from \"discipline\" to \"layer\". All documentation of this version of Perl therefore refers to \"layers\" rather than to \"disciplines\". Now back to the regularly scheduled documentation... To mark FILEHANDLE as UTF-8 , use \":utf8\" or \":encoding(utf8)\". \":utf8\" just marks the data as UTF-8 without further checking, while \":encoding(utf8)\" checks the data for actually being valid UTF-8 . More details can be found in PerlIO::encoding. In general, binmode() should be called after open() but before any I\/O is done on the filehandle. Calling binmode() will normally flush any pending buffered output data (and perhaps pending input data) on the handle. An exception to this is the \":encoding\" layer that changes the default character encoding of the handle, see open. The \":encoding\" layer sometimes needs to be called in mid-stream, and it doesn't flush the stream. The \":encoding\" also implicitly pushes on top of itself the \":utf8\" layer because internally Perl will operate on UTF-8 encoded Unicode characters. The operating system, device drivers, C libraries, and Perl run-time system all work together to let the programmer treat a single character (\"\\n\") as the line terminator, irrespective of the external representation. On many operating systems, the native text file representation matches the internal representation, but on some platforms the external representation of \"\\n\" is made up of more than one character. Mac OS , all variants of Unix, and Stream_LF files on VMS use a single character to end each line in the external representation of text (even though that single character is CARRIAGE RETURN on Mac OS and LINE FEED on Unix and most VMS files). In other systems like OS\/2 , DOS and the various flavors of MS-Windows your program sees a \"\\n\" as a simple \"\\cJ\", but what's stored in text files are the two characters \"\\cM\\cJ\". That means that, if you don't use binmode() on these systems, \"\\cM\\cJ\" sequences on disk will be converted to \"\\n\" on input, and any \"\\n\" in your program will be converted back to \"\\cM\\cJ\" on output. This is what you want for text files, but it can be disastrous for binary files. Another consequence of using binmode() (on some systems) is that special end-of-file markers will be seen as part of the data stream. For systems from the Microsoft family this means that if your binary data contains \"\\cZ\", the I\/O subsystem will regard it as the end of the file, unless you use binmode(). binmode() is not only important for readline() and print() operations, but also when using read(), seek(), sysread(), syswrite() and tell() (see perlport for more details). See the $\/ and \"$\\\" variables in perlvar for how to manually set your input and output line-termination sequences. bless REF ,CLASSNAME bless REF This function tells the thingy referenced by REF that it is now an object in the CLASSNAME package. If CLASSNAME is omitted, the current package is used. Because a \"bless\" is often the last thing in a constructor, it returns the reference for convenience. Always use the two-argument version if a derived class might inherit the function doing the blessing. See perltoot and perlobj for more about the blessing (and blessings) of objects. Consider always blessing objects in CLASSNAMEs that are mixed case. Namespaces with all lowercase names are considered reserved for Perl pragmata. Builtin types have all uppercase names. To prevent confusion, you may wish to avoid such package names as well. Make sure that CLASSNAME is a true value. See \"Perl Modules\" in perlmod. break Break out of a \"given()\" block. This keyword is enabled by the \"switch\" feature: see feature for more information. caller EXPR caller Returns the context of the current subroutine call. In scalar context, returns the caller's package name if there is a caller, that is, if we're in a subroutine or \"eval\" or \"require\", and the undefined value otherwise. In list context, returns # 0         1          2\n($package, $filename, $line) = caller; With EXPR , it returns some extra information that the debugger uses to print a stack trace. The value of EXPR indicates how many call frames to go back before the current one. #  0         1          2      3            4\n($package, $filename, $line, $subroutine, $hasargs,\n\n#  5          6          7            8       9         10\n$wantarray, $evaltext, $is_require, $hints, $bitmask, $hinthash)\n = caller($i); Here $subroutine may be \"(eval)\" if the frame is not a subroutine call, but an \"eval\". In such a case additional elements $evaltext and $is_require are set: $is_require is true if the frame is created by a \"require\" or \"use\" statement, $evaltext contains the text of the \"eval EXPR\" statement. In particular, for an \"eval BLOCK\" statement, $subroutine is \"(eval)\", but $evaltext is undefined. (Note also that each \"use\" statement creates a \"require\" frame inside an \"eval EXPR\" frame.) $subroutine may also be \"(unknown)\" if this particular subroutine happens to have been deleted from the symbol table. $hasargs is true if a new instance of @_ was set up for the frame. $hints and $bitmask contain pragmatic hints that the caller was compiled with. The $hints and $bitmask values are subject to change between versions of Perl, and are not meant for external use. $hinthash is a reference to a hash containing the value of \"%^H\" when the caller was compiled, or \"undef\" if \"%^H\" was empty. Do not modify the values of this hash, as they are the actual values stored in the optree. Furthermore, when called from within the DB package, caller returns more detailed information: it sets the list variable @DB::args to be the arguments with which the subroutine was invoked. Be aware that the optimizer might have optimized call frames away before \"caller\" had a chance to get the information. That means that caller(N) might not return information about the call frame you expect it do, for \"N > 1\". In particular, @DB::args might have information from the previous time \"caller\" was called. chdir EXPR chdir FILEHANDLE chdir DIRHANDLE chdir Changes the working directory to EXPR , if possible. If EXPR is omitted, changes to the directory specified by $ENV{HOME}, if set; if not, changes to the directory specified by $ENV{LOGDIR}. (Under VMS , the variable $ENV{SYS$LOGIN} is also checked, and used if it is set.) If neither is set, \"chdir\" does nothing. It returns true upon success, false otherwise. See the example under \"die\". On systems that support fchdir, you might pass a file handle or directory handle as argument. On systems that don't support fchdir, passing handles produces a fatal error at run time. chmod LIST Changes the permissions of a list of files. The first element of the list must be the numerical mode, which should probably be an octal number, and which definitely should not be a string of octal digits: 0644 is okay, '0644' is not. Returns the number of files successfully changed. See also \"oct\", if all you have is a string. $cnt = chmod 0755, 'foo', 'bar';\nchmod 0755, @executables;\n$mode = '0644'; chmod $mode, 'foo';      # !!! sets mode to\n                                         # --w----r-T\n$mode = '0644'; chmod oct($mode), 'foo'; # this is better\n$mode = 0644;   chmod $mode, 'foo';      # this is best On systems that support fchmod, you might pass file handles among the files. On systems that don't support fchmod, passing file handles produces a fatal error at run time. The file handles must be passed as globs or references to be recognized. Barewords are considered file names. open(my $fh, \"<\", \"foo\");\nmy $perm = (stat $fh)[2] & 07777;\nchmod($perm | 0600, $fh); You can also import the symbolic \"S_I*\" constants from the Fcntl module: use Fcntl ':mode';\n\nchmod S_IRWXU|S_IRGRP|S_IXGRP|S_IROTH|S_IXOTH, @executables;\n# This is identical to the chmod 0755 of the above example. chomp VARIABLE chomp( LIST ) chomp This safer version of \"chop\" removes any trailing string that corresponds to the current value of $\/ (also known as $INPUT_RECORD_SEPARATOR in the \"English\" module). It returns the total number of characters removed from all its arguments. It's often used to remove the newline from the end of an input record when you're worried that the final record may be missing its newline. When in paragraph mode (\"$\/ = \"\"\"), it removes all trailing newlines from the string. When in slurp mode (\"$\/ = undef\") or fixed-length record mode ($\/ is a reference to an integer or the like, see perlvar) chomp() won't remove anything. If VARIABLE is omitted, it chomps $_. Example: while (<>) {\n    chomp;  # avoid \\n on last field\n    @array = split(\/:\/);\n    # ...\n} If VARIABLE is a hash, it chomps the hash's values, but not its keys. You can actually chomp anything that's an lvalue, including an assignment: chomp($cwd = `pwd`);\nchomp($answer = <STDIN>); If you chomp a list, each element is chomped, and the total number of characters removed is returned. Note that parentheses are necessary when you're chomping anything that is not a simple variable. This is because \"chomp $cwd = `pwd`;\" is interpreted as \"(chomp $cwd) = `pwd`;\", rather than as \"chomp( $cwd = `pwd` )\" which you might expect. Similarly, \"chomp $a, $b\" is interpreted as \"chomp($a), $b\" rather than as \"chomp($a, $b)\". chop VARIABLE chop( LIST ) chop Chops off the last character of a string and returns the character chopped. It is much more efficient than \"s\/.$\/\/s\" because it neither scans nor copies the string. If VARIABLE is omitted, chops $_. If VARIABLE is a hash, it chops the hash's values, but not its keys. You can actually chop anything that's an lvalue, including an assignment. If you chop a list, each element is chopped. Only the value of the last \"chop\" is returned. Note that \"chop\" returns the last character. To return all but the last character, use \"substr($string, 0, -1)\". See also \"chomp\". chown LIST Changes the owner (and group) of a list of files. The first two elements of the list must be the numeric uid and gid, in that order. A value of -1 in either position is interpreted by most systems to leave that value unchanged. Returns the number of files successfully changed. $cnt = chown $uid, $gid, 'foo', 'bar';\nchown $uid, $gid, @filenames; On systems that support fchown, you might pass file handles among the files. On systems that don't support fchown, passing file handles produces a fatal error at run time. The file handles must be passed as globs or references to be recognized. Barewords are considered file names. Here's an example that looks up nonnumeric uids in the passwd file: print \"User: \";\nchomp($user = <STDIN>);\nprint \"Files: \";\nchomp($pattern = <STDIN>);\n\n($login,$pass,$uid,$gid) = getpwnam($user)\n    or die \"$user not in passwd file\";\n\n@ary = glob($pattern);      # expand filenames\nchown $uid, $gid, @ary; On most systems, you are not allowed to change the ownership of the file unless you're the superuser, although you should be able to change the group to any of your secondary groups. On insecure systems, these restrictions may be relaxed, but this is not a portable assumption. On POSIX systems, you can detect this condition this way: use POSIX qw(sysconf _PC_CHOWN_RESTRICTED);\n$can_chown_giveaway = not sysconf(_PC_CHOWN_RESTRICTED); chr NUMBER chr Returns the character represented by that NUMBER in the character set. For example, \"chr(65)\" is \"A\" in either ASCII or Unicode, and chr(0x263a) is a Unicode smiley face. Negative values give the Unicode replacement character ( chr(0xfffd)), except under the bytes pragma, where low eight bits of the value (truncated to an integer) are used. If NUMBER is omitted, uses $_. For the reverse, use \"ord\". Note that characters from 128 to 255 (inclusive) are by default internally not encoded as UTF-8 for backward compatibility reasons. See perlunicode for more about Unicode. chroot FILENAME chroot This function works like the system call by the same name: it makes the named directory the new root directory for all further pathnames that begin with a \"\/\" by your process and all its children. (It doesn't change your current working directory, which is unaffected.) For security reasons, this call is restricted to the superuser. If FILENAME is omitted, does a \"chroot\" to $_. close FILEHANDLE close Closes the file or pipe associated with the file handle, flushes the IO buffers, and closes the system file descriptor. Returns true if those operations have succeeded and if no error was reported by any PerlIO layer. Closes the currently selected filehandle if the argument is omitted. You don't have to close FILEHANDLE if you are immediately going to do another \"open\" on it, because \"open\" will close it for you. (See \"open\".) However, an explicit \"close\" on an input file resets the line counter ( $.), while the implicit close done by \"open\" does not. If the file handle came from a piped open, \"close\" will additionally return false if one of the other system calls involved fails, or if the program exits with non-zero status. (If the only problem was that the program exited non-zero, $! will be set to 0.) Closing a pipe also waits for the process executing on the pipe to complete, in case you want to look at the output of the pipe afterwards, and implicitly puts the exit status value of that command into $? and \"${^CHILD_ERROR_NATIVE}\". Prematurely closing the read end of a pipe (i.e. before the process writing to it at the other end has closed it) will result in a SIGPIPE being delivered to the writer. If the other end can't handle that, be sure to read all the data before closing the pipe. Example: open(OUTPUT, '|sort >foo')  # pipe to sort\n    or die \"Can't start sort: $!\";\n#...                        # print stuff to output\nclose OUTPUT                # wait for sort to finish\n    or warn $! ? \"Error closing sort pipe: $!\"\n               : \"Exit status $? from sort\";\nopen(INPUT, 'foo')          # get sort's results\n    or die \"Can't open 'foo' for input: $!\"; FILEHANDLE may be an expression whose value can be used as an indirect filehandle, usually the real filehandle name. closedir DIRHANDLE Closes a directory opened by \"opendir\" and returns the success of that system call. connect SOCKET ,NAME Attempts to connect to a remote socket, just as the connect system call does. Returns true if it succeeded, false otherwise. NAME should be a packed address of the appropriate type for the socket. See the examples in \"Sockets: Client\/Server Communication\" in perlipc. continue BLOCK continue \"continue\" is actually a flow control statement rather than a function. If there is a \"continue\" BLOCK attached to a BLOCK (typically in a \"while\" or \"foreach\"), it is always executed just before the conditional is about to be evaluated again, just like the third part of a \"for\" loop in C. Thus it can be used to increment a loop variable, even when the loop has been continued via the \"next\" statement (which is similar to the C \"continue\" statement). \"last\", \"next\", or \"redo\" may appear within a \"continue\" block. \"last\" and \"redo\" will behave as if they had been executed within the main block. So will \"next\", but since it will execute a \"continue\" block, it may be more entertaining. while (EXPR) {\n    ### redo always comes here\n    do_something;\n} continue {\n    ### next always comes here\n    do_something_else;\n    # then back the top to re-check EXPR\n}\n### last always comes here Omitting the \"continue\" section is semantically equivalent to using an empty one, logically enough. In that case, \"next\" goes directly back to check the condition at the top of the loop. If the \"switch\" feature is enabled, \"continue\" is also a function that will break out of the current \"when\" or \"default\" block, and fall through to the next case. See feature and \"Switch statements\" in perlsyn for more information. cos EXPR cos Returns the cosine of EXPR (expressed in radians). If EXPR is omitted, takes cosine of $_. For the inverse cosine operation, you may use the \"Math::Trig::acos()\" function, or use this relation: sub acos { atan2( sqrt(1 - $_[0] * $_[0]), $_[0] ) } crypt PLAINTEXT ,SALT Creates a digest string exactly like the crypt(3) function in the C library (assuming that you actually have a version there that has not been extirpated as a potential munition). crypt() is a one-way hash function. The PLAINTEXT and SALT is turned into a short string, called a digest, which is returned. The same PLAINTEXT and SALT will always return the same string, but there is no (known) way to get the original PLAINTEXT from the hash. Small changes in the PLAINTEXT or SALT will result in large changes in the digest. There is no decrypt function. This function isn't all that useful for cryptography (for that, look for Crypt modules on your nearby CPAN mirror) and the name \"crypt\" is a bit of a misnomer. Instead it is primarily used to check if two pieces of text are the same without having to transmit or store the text itself. An example is checking if a correct password is given. The digest of the password is stored, not the password itself. The user types in a password that is crypt()'d with the same salt as the stored digest. If the two digests match the password is correct. When verifying an existing digest string you should use the digest as the salt (like \"crypt($plain, $digest) eq $digest\"). The SALT used to create the digest is visible as part of the digest. This ensures crypt() will hash the new string with the same salt as the digest. This allows your code to work with the standard crypt and with more exotic implementations. In other words, do not assume anything about the returned string itself, or how many bytes in the digest matter. Traditionally the result is a string of 13 bytes: two first bytes of the salt, followed by 11 bytes from the set \"[.\/0-9A-Za-z]\", and only the first eight bytes of PLAINTEXT mattered. But alternative hashing schemes (like MD5 ), higher level security schemes (like C2), and implementations on non-UNIX platforms may produce different strings. When choosing a new salt create a random two character string whose characters come from the set \"[.\/0-9A-Za-z]\" (like \"join '', ('.', '\/', 0..9, 'A'..'Z', 'a'..'z')[rand 64, rand 64]\"). This set of characters is just a recommendation; the characters allowed in the salt depend solely on your system's crypt library, and Perl can't restrict what salts \"crypt()\" accepts. Here's an example that makes sure that whoever runs this program knows their password: $pwd = (getpwuid($<))[1];\n\nsystem \"stty -echo\";\nprint \"Password: \";\nchomp($word = <STDIN>);\nprint \"\\n\";\nsystem \"stty echo\";\n\nif (crypt($word, $pwd) ne $pwd) {\n    die \"Sorry...\\n\";\n} else {\n    print \"ok\\n\";\n} Of course, typing in your own password to whoever asks you for it is unwise. The crypt function is unsuitable for hashing large quantities of data, not least of all because you can't get the information back. Look at the Digest module for more robust algorithms. If using crypt() on a Unicode string (which potentially has characters with codepoints above 255), Perl tries to make sense of the situation by trying to downgrade (a copy of the string) the string back to an eight-bit byte string before calling crypt() (on that copy). If that works, good. If not, crypt() dies with \"Wide character in crypt\". dbmclose HASH [This function has been largely superseded by the \"untie\" function.] Breaks the binding between a DBM file and a hash. dbmopen HASH ,DBNAME,MASK [This function has been largely superseded by the \"tie\" function.] This binds a dbm(3), ndbm(3), sdbm(3), gdbm(3), or Berkeley DB file to a hash. HASH is the name of the hash. (Unlike normal \"open\", the first argument is not a filehandle, even though it looks like one). DBNAME is the name of the database (without the .dir or .pag extension if any). If the database does not exist, it is created with protection specified by MASK (as modified by the \"umask\"). If your system supports only the older DBM functions, you may perform only one \"dbmopen\" in your program. In older versions of Perl, if your system had neither DBM nor ndbm, calling \"dbmopen\" produced a fatal error; it now falls back to sdbm(3). If you don't have write access to the DBM file, you can only read hash variables, not set them. If you want to test whether you can write, either use file tests or try setting a dummy hash entry inside an \"eval\", which will trap the error. Note that functions such as \"keys\" and \"values\" may return huge lists when used on large DBM files. You may prefer to use the \"each\" function to iterate over large DBM files. Example: # print out history file offsets\ndbmopen(%HIST,'\/usr\/lib\/news\/history',0666);\nwhile (($key,$val) = each %HIST) {\n    print $key, ' = ', unpack('L',$val), \"\\n\";\n}\ndbmclose(%HIST); See also AnyDBM_File for a more general description of the pros and cons of the various dbm approaches, as well as DB_File for a particularly rich implementation. You can control which DBM library you use by loading that library before you call dbmopen(): use DB_File;\ndbmopen(%NS_Hist, \"$ENV{HOME}\/.netscape\/history.db\")\n    or die \"Can't open netscape history file: $!\"; defined EXPR defined Returns a Boolean value telling whether EXPR has a value other than the undefined value \"undef\". If EXPR is not present, $_ will be checked. Many operations return \"undef\" to indicate failure, end of file, system error, uninitialized variable, and other exceptional conditions. This function allows you to distinguish \"undef\" from other values. (A simple Boolean test will not distinguish among \"undef\", zero, the empty string, and \"0\", which are all equally false.) Note that since \"undef\" is a valid scalar, its presence doesn't necessarily indicate an exceptional condition: \"pop\" returns \"undef\" when its argument is an empty array, or when the element to return happens to be \"undef\". You may also use \"defined(&func)\" to check whether subroutine &func has ever been defined. The return value is unaffected by any forward declarations of &func. Note that a subroutine which is not defined may still be callable: its package may have an \"AUTOLOAD\" method that makes it spring into existence the first time that it is called -- see perlsub. Use of \"defined\" on aggregates (hashes and arrays) is deprecated. It used to report whether memory for that aggregate has ever been allocated. This behavior may disappear in future versions of Perl. You should instead use a simple test for size: if (@an_array) { print \"has array elements\\n\" }\nif (%a_hash)   { print \"has hash members\\n\"   } When used on a hash element, it tells you whether the value is defined, not whether the key exists in the hash. Use \"exists\" for the latter purpose. Examples: print if defined $switch{'D'};\nprint \"$val\\n\" while defined($val = pop(@ary));\ndie \"Can't readlink $sym: $!\"\n    unless defined($value = readlink $sym);\nsub foo { defined &$bar ? &$bar(@_) : die \"No bar\"; }\n$debugging = 0 unless defined $debugging; Note: Many folks tend to overuse \"defined\", and then are surprised to discover that the number 0 and \"\" (the zero-length string) are, in fact, defined values. For example, if you say \"ab\" =~ \/a(.*)b\/; The pattern match succeeds, and $1 is defined, despite the fact that it matched \"nothing\". It didn't really fail to match anything. Rather, it matched something that happened to be zero characters long. This is all very above-board and honest. When a function returns an undefined value, it's an admission that it couldn't give you an honest answer. So you should use \"defined\" only when you're questioning the integrity of what you're trying to do. At other times, a simple comparison to 0 or \"\" is what you want. See also \"undef\", \"exists\", \"ref\". delete EXPR Given an expression that specifies a hash element, array element, hash slice, or array slice, deletes the specified element(s) from the hash or array. In the case of an array, if the array elements happen to be at the end, the size of the array will shrink to the highest element that tests true for exists() (or 0 if no such element exists). Returns a list with the same number of elements as the number of elements for which deletion was attempted. Each element of that list consists of either the value of the element deleted, or the undefined value. In scalar context, this means that you get the value of the last element deleted (or the undefined value if that element did not exist). %hash = (foo => 11, bar => 22, baz => 33);\n$scalar = delete $hash{foo};             # $scalar is 11\n$scalar = delete @hash{qw(foo bar)};     # $scalar is 22\n@array  = delete @hash{qw(foo bar baz)}; # @array  is (undef,undef,33) Deleting from %ENV modifies the environment. Deleting from a hash tied to a DBM file deletes the entry from the DBM file. Deleting from a \"tie\"d hash or array may not necessarily return anything. Deleting an array element effectively returns that position of the array to its initial, uninitialized state. Subsequently testing for the same element with exists() will return false. Also, deleting array elements in the middle of an array will not shift the index of the elements after them down. Use splice() for that. See \"exists\". The following (inefficiently) deletes all the values of %HASH and @ARRAY: foreach $key (keys %HASH) {\n    delete $HASH{$key};\n}\n\nforeach $index (0 .. $#ARRAY) {\n    delete $ARRAY[$index];\n} And so do these: delete @HASH{keys %HASH};\n\ndelete @ARRAY[0 .. $#ARRAY]; But both of these are slower than just assigning the empty list or undefining %HASH or @ARRAY: %HASH = ();         # completely empty %HASH\nundef %HASH;        # forget %HASH ever existed\n\n@ARRAY = ();        # completely empty @ARRAY\nundef @ARRAY;       # forget @ARRAY ever existed Note that the EXPR can be arbitrarily complicated as long as the final operation is a hash element, array element, hash slice, or array slice lookup: delete $ref->[$x][$y]{$key};\ndelete @{$ref->[$x][$y]}{$key1, $key2, @morekeys};\n\ndelete $ref->[$x][$y][$index];\ndelete @{$ref->[$x][$y]}[$index1, $index2, @moreindices]; die LIST Outside an \"eval\", prints the value of LIST to \"STDERR\" and exits with the current value of $! (errno). If $! is 0, exits with the value of \"($? >> 8)\" (backtick 'command' status). If \"($? >> 8)\" is 0, exits with 255. Inside an \"eval(),\" the error message is stuffed into $@ and the \"eval\" is terminated with the undefined value. This makes \"die\" the way to raise an exception. Equivalent examples: die \"Can't cd to spool: $!\\n\" unless chdir '\/usr\/spool\/news';\nchdir '\/usr\/spool\/news' or die \"Can't cd to spool: $!\\n\" If the last element of LIST does not end in a newline, the current script line number and input line number (if any) are also printed, and a newline is supplied. Note that the \"input line number\" (also known as \"chunk\") is subject to whatever notion of \"line\" happens to be currently in effect, and is also available as the special variable $.. See \"$\/\" in perlvar and \"$.\" in perlvar. Hint: sometimes appending \", stopped\" to your message will cause it to make better sense when the string \"at foo line 123\" is appended. Suppose you are running script \"canasta\". die \"\/etc\/games is no good\";\ndie \"\/etc\/games is no good, stopped\"; produce, respectively \/etc\/games is no good at canasta line 123.\n\/etc\/games is no good, stopped at canasta line 123. See also exit(), warn(), and the Carp module. If LIST is empty and $@ already contains a value (typically from a previous eval) that value is reused after appending \"\\t...propagated\". This is useful for propagating exceptions: eval { ... };\ndie unless $@ =~ \/Expected exception\/; If LIST is empty and $@ contains an object reference that has a \"PROPAGATE\" method, that method will be called with additional file and line number parameters. The return value replaces the value in $@. i.e. as if \"$@ = eval { $@->PROPAGATE(__FILE__, __LINE__) };\" were called. If $@ is empty then the string \"Died\" is used. die() can also be called with a reference argument. If this happens to be trapped within an eval(), $@ contains the reference. This behavior permits a more elaborate exception handling implementation using objects that maintain arbitrary state about the nature of the exception. Such a scheme is sometimes preferable to matching particular string values of $@ using regular expressions. Because $@ is a global variable, and eval() may be used within object implementations, care must be taken that analyzing the error object doesn't replace the reference in the global variable. The easiest solution is to make a local copy of the reference before doing other manipulations. Here's an example: use Scalar::Util 'blessed';\n\neval { ... ; die Some::Module::Exception->new( FOO => \"bar\" ) };\nif (my $ev_err = $@) {\n    if (blessed($ev_err) && $ev_err->isa(\"Some::Module::Exception\")) {\n        # handle Some::Module::Exception\n    }\n    else {\n        # handle all other possible exceptions\n    }\n} Because perl will stringify uncaught exception messages before displaying them, you may want to overload stringification operations on such custom exception objects. See overload for details about that. You can arrange for a callback to be run just before the \"die\" does its deed, by setting the $SIG{__DIE__} hook. The associated handler will be called with the error text and can change the error message, if it sees fit, by calling \"die\" again. See \"$SIG{expr}\" in perlvar for details on setting %SIG entries, and \"eval BLOCK \" for some examples. Although this feature was to be run only right before your program was to exit, this is not currently the case--the $SIG{__DIE__} hook is currently called even inside eval()ed blocks\/strings! If one wants the hook to do nothing in such situations, put die @_ if $^S; as the first line of the handler (see \"$^S\" in perlvar). Because this promotes strange action at a distance, this counterintuitive behavior may be fixed in a future release. do BLOCK Not really a function. Returns the value of the last command in the sequence of commands indicated by BLOCK . When modified by the \"while\" or \"until\" loop modifier, executes the BLOCK once before testing the loop condition. (On other statements the loop modifiers test the conditional first.) \"do BLOCK\" does not count as a loop, so the loop control statements \"next\", \"last\", or \"redo\" cannot be used to leave or restart the block. See perlsyn for alternative strategies. do SUBROUTINE ( LIST ) This form of subroutine call is deprecated. See perlsub. do EXPR Uses the value of EXPR as a filename and executes the contents of the file as a Perl script. do 'stat.pl'; is just like eval `cat stat.pl`; except that it's more efficient and concise, keeps track of the current filename for error messages, searches the @INC directories, and updates %INC if the file is found. See \"Predefined Names\" in perlvar for these variables. It also differs in that code evaluated with \"do FILENAME\" cannot see lexicals in the enclosing scope; \"eval STRING\" does. It's the same, however, in that it does reparse the file every time you call it, so you probably don't want to do this inside a loop. If \"do\" cannot read the file, it returns undef and sets $! to the error. If \"do\" can read the file but cannot compile it, it returns undef and sets an error message in $@. If the file is successfully compiled, \"do\" returns the value of the last expression evaluated. Note that inclusion of library modules is better done with the \"use\" and \"require\" operators, which also do automatic error checking and raise an exception if there's a problem. You might like to use \"do\" to read in a program configuration file. Manual error checking can be done this way:  # read in config files: system first, then user\n for $file (\"\/share\/prog\/defaults.rc\",\n            \"$ENV{HOME}\/.someprogrc\")\n{\n     unless ($return = do $file) {\n         warn \"couldn't parse $file: $@\" if $@;\n         warn \"couldn't do $file: $!\"    unless defined $return;\n         warn \"couldn't run $file\"       unless $return;\n     }\n } dump LABEL dump This function causes an immediate core dump. See also the -u command-line switch in perlrun, which does the same thing. Primarily this is so that you can use the undump program (not supplied) to turn your core dump into an executable binary after having initialized all your variables at the beginning of the program. When the new binary is executed it will begin by executing a \"goto LABEL\" (with all the restrictions that \"goto\" suffers). Think of it as a goto with an intervening core dump and reincarnation. If \"LABEL\" is omitted, restarts the program from the top. WARNING : Any files opened at the time of the dump will not be open any more when the program is reincarnated, with possible resulting confusion on the part of Perl. This function is now largely obsolete, mostly because it's very hard to convert a core file into an executable. That's why you should now invoke it as \"CORE::dump()\", if you don't want to be warned against a possible typo. each HASH When called in list context, returns a 2-element list consisting of the key and value for the next element of a hash, so that you can iterate over it. When called in scalar context, returns only the key for the next element in the hash. Entries are returned in an apparently random order. The actual random order is subject to change in future versions of perl, but it is guaranteed to be in the same order as either the \"keys\" or \"values\" function would produce on the same (unmodified) hash. Since Perl 5.8.2 the ordering can be different even between different runs of Perl for security reasons (see \"Algorithmic Complexity Attacks\" in perlsec). When the hash is entirely read, a null array is returned in list context (which when assigned produces a false (0) value), and \"undef\" in scalar context. The next call to \"each\" after that will start iterating again. There is a single iterator for each hash, shared by all \"each\", \"keys\", and \"values\" function calls in the program; it can be reset by reading all the elements from the hash, or by evaluating \"keys HASH\" or \"values HASH\". If you add or delete elements of a hash while you're iterating over it, you may get entries skipped or duplicated, so don't. Exception: It is always safe to delete the item most recently returned by \"each()\", which means that the following code will work: while (($key, $value) = each %hash) {\n  print $key, \"\\n\";\n  delete $hash{$key};   # This is safe\n} The following prints out your environment like the printenv(1) program, only in a different order: while (($key,$value) = each %ENV) {\n    print \"$key=$value\\n\";\n} See also \"keys\", \"values\" and \"sort\". eof FILEHANDLE eof () eof Returns 1 if the next read on FILEHANDLE will return end of file, or if FILEHANDLE is not open. FILEHANDLE may be an expression whose value gives the real filehandle. (Note that this function actually reads a character and then \"ungetc\"s it, so isn't very useful in an interactive context.) Do not read from a terminal file (or call \"eof(FILEHANDLE)\" on it) after end-of-file is reached. File types such as terminals may lose the end-of-file condition if you do. An \"eof\" without an argument uses the last file read. Using \"eof()\" with empty parentheses is very different. It refers to the pseudo file formed from the files listed on the command line and accessed via the \"<>\" operator. Since \"<>\" isn't explicitly opened, as a normal filehandle is, an \"eof()\" before \"<>\" has been used will cause @ARGV to be examined to determine if input is available. Similarly, an \"eof()\" after \"<>\" has returned end-of-file will assume you are processing another @ARGV list, and if you haven't set @ARGV, will read input from \"STDIN\"; see \"I\/O Operators\" in perlop. In a \"while (<>)\" loop, \"eof\" or \"eof(ARGV)\" can be used to detect the end of each file, \"eof()\" will only detect the end of the last file. Examples: # reset line numbering on each input file\nwhile (<>) {\n    next if \/^\\s*#\/;        # skip comments\n    print \"$.\\t$_\";\n} continue {\n    close ARGV  if eof;     # Not eof()!\n}\n\n# insert dashes just before last line of last file\nwhile (<>) {\n    if (eof()) {            # check for end of last file\n        print \"--------------\\n\";\n    }\n    print;\n    last if eof();          # needed if we're reading from a terminal\n} Practical hint: you almost never need to use \"eof\" in Perl, because the input operators typically return \"undef\" when they run out of data, or if there was an error. eval EXPR eval BLOCK eval In the first form, the return value of EXPR is parsed and executed as if it were a little Perl program. The value of the expression (which is itself determined within scalar context) is first parsed, and if there weren't any errors, executed in the lexical context of the current Perl program, so that any variable settings or subroutine and format definitions remain afterwards. Note that the value is parsed every time the \"eval\" executes. If EXPR is omitted, evaluates $_. This form is typically used to delay parsing and subsequent execution of the text of EXPR until run time. In the second form, the code within the BLOCK is parsed only once--at the same time the code surrounding the \"eval\" itself was parsed--and executed within the context of the current Perl program. This form is typically used to trap exceptions more efficiently than the first (see below), while also providing the benefit of checking the code within BLOCK at compile time. The final semicolon, if any, may be omitted from the value of EXPR or within the BLOCK . In both forms, the value returned is the value of the last expression evaluated inside the mini-program; a return statement may be also used, just as with subroutines. The expression providing the return value is evaluated in void, scalar, or list context, depending on the context of the \"eval\" itself. See \"wantarray\" for more on how the evaluation context can be determined. If there is a syntax error or runtime error, or a \"die\" statement is executed, \"eval\" returns an undefined value in scalar context or an empty list in list context, and $@ is set to the error message. If there was no error, $@ is guaranteed to be a null string. Beware that using \"eval\" neither silences perl from printing warnings to STDERR , nor does it stuff the text of warning messages into $@. To do either of those, you have to use the $SIG{__WARN__} facility, or turn off warnings inside the BLOCK or EXPR using \"no warnings 'all'\". See \"warn\", perlvar, warnings and perllexwarn. Note that, because \"eval\" traps otherwise-fatal errors, it is useful for determining whether a particular feature (such as \"socket\" or \"symlink\") is implemented. It is also Perl's exception trapping mechanism, where the die operator is used to raise exceptions. If you want to trap errors when loading an XS module, some problems with the binary interface (such as Perl version skew) may be fatal even with \"eval\" unless $ENV{PERL_DL_NONLAZY} is set. See perlrun. If the code to be executed doesn't vary, you may use the eval-BLOCK form to trap run-time errors without incurring the penalty of recompiling each time. The error, if any, is still returned in $@. Examples: # make divide-by-zero nonfatal\neval { $answer = $a \/ $b; }; warn $@ if $@;\n\n# same thing, but less efficient\neval '$answer = $a \/ $b'; warn $@ if $@;\n\n# a compile-time error\neval { $answer = };                 # WRONG\n\n# a run-time error\neval '$answer =';   # sets $@ Using the \"eval{}\" form as an exception trap in libraries does have some issues. Due to the current arguably broken state of \"__DIE__\" hooks, you may wish not to trigger any \"__DIE__\" hooks that user code may have installed. You can use the \"local $SIG{__DIE__}\" construct for this purpose, as shown in this example: # a very private exception trap for divide-by-zero\neval { local $SIG{'__DIE__'}; $answer = $a \/ $b; };\nwarn $@ if $@; This is especially significant, given that \"__DIE__\" hooks can call \"die\" again, which has the effect of changing their error messages: # __DIE__ hooks may modify error messages\n{\n   local $SIG{'__DIE__'} =\n          sub { (my $x = $_[0]) =~ s\/foo\/bar\/g; die $x };\n   eval { die \"foo lives here\" };\n   print $@ if $@;                # prints \"bar lives here\"\n} Because this promotes action at a distance, this counterintuitive behavior may be fixed in a future release. With an \"eval\", you should be especially careful to remember what's being looked at when: eval $x;            # CASE 1\neval \"$x\";          # CASE 2\n\neval '$x';          # CASE 3\neval { $x };        # CASE 4\n\neval \"\\$$x++\";      # CASE 5\n$$x++;              # CASE 6 Cases 1 and 2 above behave identically: they run the code contained in the variable $x. (Although case 2 has misleading double quotes making the reader wonder what else might be happening (nothing is).) Cases 3 and 4 likewise behave in the same way: they run the code '$x', which does nothing but return the value of $x. (Case 4 is preferred for purely visual reasons, but it also has the advantage of compiling at compile-time instead of at run-time.) Case 5 is a place where normally you would like to use double quotes, except that in this particular situation, you can just use symbolic references instead, as in case 6. The assignment to $@ occurs before restoration of localised variables, which means a temporary is required if you want to mask some but not all errors: # alter $@ on nefarious repugnancy only\n{\n   my $e;\n   {\n      local $@; # protect existing $@\n      eval { test_repugnancy() };\n      # $@ =~ \/nefarious\/ and die $@; # DOES NOT WORK\n      $@ =~ \/nefarious\/ and $e = $@;\n   }\n   die $e if defined $e\n} \"eval BLOCK\" does not count as a loop, so the loop control statements \"next\", \"last\", or \"redo\" cannot be used to leave or restart the block. Note that as a very special case, an \"eval ''\" executed within the \"DB\" package doesn't see the usual surrounding lexical scope, but rather the scope of the first non-DB piece of code that called it. You don't normally need to worry about this unless you are writing a Perl debugger. exec LIST exec PROGRAM LIST The \"exec\" function executes a system command and never returns-- use \"system\" instead of \"exec\" if you want it to return. It fails and returns false only if the command does not exist and it is executed directly instead of via your system's command shell (see below). Since it's a common mistake to use \"exec\" instead of \"system\", Perl warns you if there is a following statement which isn't \"die\", \"warn\", or \"exit\" (if \"-w\" is set - but you always do that). If you really want to follow an \"exec\" with some other statement, you can use one of these styles to avoid the warning: exec ('foo')   or print STDERR \"couldn't exec foo: $!\";\n{ exec ('foo') }; print STDERR \"couldn't exec foo: $!\"; If there is more than one argument in LIST , or if LIST is an array with more than one value, calls execvp(3) with the arguments in LIST . If there is only one scalar argument or an array with one element in it, the argument is checked for shell metacharacters, and if there are any, the entire argument is passed to the system's command shell for parsing (this is \"\/bin\/sh -c\" on Unix platforms, but varies on other platforms). If there are no shell metacharacters in the argument, it is split into words and passed directly to \"execvp\", which is more efficient. Examples: exec '\/bin\/echo', 'Your arguments are: ', @ARGV;\nexec \"sort $outfile | uniq\"; If you don't really want to execute the first argument, but want to lie to the program you are executing about its own name, you can specify the program you actually want to run as an \"indirect object\" (without a comma) in front of the LIST . (This always forces interpretation of the LIST as a multivalued list, even if there is only a single scalar in the list.) Example: $shell = '\/bin\/csh';\nexec $shell '-sh';          # pretend it's a login shell or, more directly, exec {'\/bin\/csh'} '-sh';    # pretend it's a login shell When the arguments get executed via the system shell, results will be subject to its quirks and capabilities. See \"'STRING'\" in perlop for details. Using an indirect object with \"exec\" or \"system\" is also more secure. This usage (which also works fine with system()) forces interpretation of the arguments as a multivalued list, even if the list had just one argument. That way you're safe from the shell expanding wildcards or splitting up words with whitespace in them. @args = ( \"echo surprise\" );\n\nexec @args;               # subject to shell escapes\n                            # if @args == 1\nexec { $args[0] } @args;  # safe even with one-arg list The first version, the one without the indirect object, ran the echo program, passing it \"surprise\" an argument. The second version didn't--it tried to run a program literally called \"echo surprise\", didn't find it, and set $? to a non-zero value indicating failure. Beginning with v5.6.0, Perl will attempt to flush all files opened for output before the exec, but this may not be supported on some platforms (see perlport). To be safe, you may need to set $| ($AUTOFLUSH in English) or call the \"autoflush()\" method of \"IO::Handle\" on any open handles in order to avoid lost output. Note that \"exec\" will not call your \"END\" blocks, nor will it call any \"DESTROY\" methods in your objects. exists EXPR Given an expression that specifies a hash element or array element, returns true if the specified element in the hash or array has ever been initialized, even if the corresponding value is undefined. print \"Exists\\n\"    if exists $hash{$key};\nprint \"Defined\\n\"   if defined $hash{$key};\nprint \"True\\n\"      if $hash{$key};\n\nprint \"Exists\\n\"    if exists $array[$index];\nprint \"Defined\\n\"   if defined $array[$index];\nprint \"True\\n\"      if $array[$index]; A hash or array element can be true only if it's defined, and defined if it exists, but the reverse doesn't necessarily hold true. Given an expression that specifies the name of a subroutine, returns true if the specified subroutine has ever been declared, even if it is undefined. Mentioning a subroutine name for exists or defined does not count as declaring it. Note that a subroutine which does not exist may still be callable: its package may have an \"AUTOLOAD\" method that makes it spring into existence the first time that it is called -- see perlsub. print \"Exists\\n\"    if exists &subroutine;\nprint \"Defined\\n\"   if defined &subroutine; Note that the EXPR can be arbitrarily complicated as long as the final operation is a hash or array key lookup or subroutine name: if (exists $ref->{A}->{B}->{$key})  { }\nif (exists $hash{A}{B}{$key})       { }\n\nif (exists $ref->{A}->{B}->[$ix])   { }\nif (exists $hash{A}{B}[$ix])        { }\n\nif (exists &{$ref->{A}{B}{$key}})   { } Although the deepest nested array or hash will not spring into existence just because its existence was tested, any intervening ones will. Thus \"$ref->{\"A\"}\" and \"$ref->{\"A\"}->{\"B\"}\" will spring into existence due to the existence test for the $key element above. This happens anywhere the arrow operator is used, including even: undef $ref;\nif (exists $ref->{\"Some key\"})      { }\nprint $ref;             # prints HASH(0x80d3d5c) This surprising autovivification in what does not at first--or even second--glance appear to be an lvalue context may be fixed in a future release. Use of a subroutine call, rather than a subroutine name, as an argument to exists() is an error. exists &sub;        # OK\nexists &sub();      # Error exit EXPR exit Evaluates EXPR and exits immediately with that value. Example: $ans = <STDIN>;\nexit 0 if $ans =~ \/^[Xx]\/; See also \"die\". If EXPR is omitted, exits with 0 status. The only universally recognized values for EXPR are 0 for success and 1 for error; other values are subject to interpretation depending on the environment in which the Perl program is running. For example, exiting 69 ( EX_UNAVAILABLE ) from a sendmail incoming-mail filter will cause the mailer to return the item undelivered, but that's not true everywhere. Don't use \"exit\" to abort a subroutine if there's any chance that someone might want to trap whatever error happened. Use \"die\" instead, which can be trapped by an \"eval\". The exit() function does not always exit immediately. It calls any defined \"END\" routines first, but these \"END\" routines may not themselves abort the exit. Likewise any object destructors that need to be called are called before the real exit. If this is a problem, you can call \"POSIX:_exit($status)\" to avoid END and destructor processing. See perlmod for details. exp EXPR exp Returns e (the natural logarithm base) to the power of EXPR . If EXPR is omitted, gives \"exp($_)\". fcntl FILEHANDLE ,FUNCTION,SCALAR Implements the fcntl(2) function. You'll probably have to say use Fcntl; first to get the correct constant definitions. Argument processing and value return works just like \"ioctl\" below. For example: use Fcntl;\nfcntl($filehandle, F_GETFL, $packed_return_buffer)\n    or die \"can't fcntl F_GETFL: $!\"; You don't have to check for \"defined\" on the return from \"fcntl\". Like \"ioctl\", it maps a 0 return from the system call into \"0 but true\" in Perl. This string is true in boolean context and 0 in numeric context. It is also exempt from the normal -w warnings on improper numeric conversions. Note that \"fcntl\" will produce a fatal error if used on a machine that doesn't implement fcntl(2). See the Fcntl module or your fcntl(2) manpage to learn what functions are available on your system. Here's an example of setting a filehandle named \"REMOTE\" to be non-blocking at the system level. You'll have to negotiate $| on your own, though. use Fcntl qw(F_GETFL F_SETFL O_NONBLOCK);\n\n$flags = fcntl(REMOTE, F_GETFL, 0)\n            or die \"Can't get flags for the socket: $!\\n\";\n\n$flags = fcntl(REMOTE, F_SETFL, $flags | O_NONBLOCK)\n            or die \"Can't set flags for the socket: $!\\n\"; fileno FILEHANDLE Returns the file descriptor for a filehandle, or undefined if the filehandle is not open. This is mainly useful for constructing bitmaps for \"select\" and low-level POSIX tty-handling operations. If FILEHANDLE is an expression, the value is taken as an indirect filehandle, generally its name. You can use this to find out whether two handles refer to the same underlying descriptor: if (fileno(THIS) == fileno(THAT)) {\n    print \"THIS and THAT are dups\\n\";\n} (Filehandles connected to memory objects via new features of \"open\" may return undefined even though they are open.) flock FILEHANDLE ,OPERATION Calls flock(2), or an emulation of it, on FILEHANDLE . Returns true for success, false on failure. Produces a fatal error if used on a machine that doesn't implement flock(2), fcntl(2) locking, or lockf(3). \"flock\" is Perl's portable file locking interface, although it locks only entire files, not records. Two potentially non-obvious but traditional \"flock\" semantics are that it waits indefinitely until the lock is granted, and that its locks merely advisory. Such discretionary locks are more flexible, but offer fewer guarantees. This means that programs that do not also use \"flock\" may modify files locked with \"flock\". See perlport, your port's specific documentation, or your system-specific local manpages for details. It's best to assume traditional behavior if you're writing portable programs. (But if you're not, you should as always feel perfectly free to write for your own system's idiosyncrasies (sometimes called \"features\"). Slavish adherence to portability concerns shouldn't get in the way of your getting your job done.) OPERATION is one of LOCK_SH , LOCK_EX , or LOCK_UN , possibly combined with LOCK_NB . These constants are traditionally valued 1, 2, 8 and 4, but you can use the symbolic names if you import them from the Fcntl module, either individually, or as a group using the ':flock' tag. LOCK_SH requests a shared lock, LOCK_EX requests an exclusive lock, and LOCK_UN releases a previously requested lock. If LOCK_NB is bitwise-or'ed with LOCK_SH or LOCK_EX then \"flock\" will return immediately rather than blocking waiting for the lock (check the return status to see if you got it). To avoid the possibility of miscoordination, Perl now flushes FILEHANDLE before locking or unlocking it. Note that the emulation built with lockf(3) doesn't provide shared locks, and it requires that FILEHANDLE be open with write intent. These are the semantics that lockf(3) implements. Most if not all systems implement lockf(3) in terms of fcntl(2) locking, though, so the differing semantics shouldn't bite too many people. Note that the fcntl(2) emulation of flock(3) requires that FILEHANDLE be open with read intent to use LOCK_SH and requires that it be open with write intent to use LOCK_EX . Note also that some versions of \"flock\" cannot lock things over the network; you would need to use the more system-specific \"fcntl\" for that. If you like you can force Perl to ignore your system's flock(2) function, and so provide its own fcntl(2)-based emulation, by passing the switch \"-Ud_flock\" to the Configure program when you configure perl. Here's a mailbox appender for BSD systems. use Fcntl qw(:flock SEEK_END); # import LOCK_* and SEEK_END constants\n\nsub lock {\n    my ($fh) = @_;\n    flock($fh, LOCK_EX) or die \"Cannot lock mailbox - $!\\n\";\n\n    # and, in case someone appended while we were waiting...\n    seek($fh, 0, SEEK_END) or die \"Cannot seek - $!\\n\";\n}\n\nsub unlock {\n    my ($fh) = @_;\n    flock($fh, LOCK_UN) or die \"Cannot unlock mailbox - $!\\n\";\n}\n\nopen(my $mbox, \">>\", \"\/usr\/spool\/mail\/$ENV{'USER'}\")\n        or die \"Can't open mailbox: $!\";\n\nlock($mbox);\nprint $mbox $msg,\"\\n\\n\";\nunlock($mbox); On systems that support a real flock(), locks are inherited across fork() calls, whereas those that must resort to the more capricious fcntl() function lose the locks, making it harder to write servers. See also DB_File for other flock() examples. fork Does a fork(2) system call to create a new process running the same program at the same point. It returns the child pid to the parent process, 0 to the child process, or \"undef\" if the fork is unsuccessful. File descriptors (and sometimes locks on those descriptors) are shared, while everything else is copied. On most systems supporting fork(), great care has gone into making it extremely efficient (for example, using copy-on-write technology on data pages), making it the dominant paradigm for multitasking over the last few decades. Beginning with v5.6.0, Perl will attempt to flush all files opened for output before forking the child process, but this may not be supported on some platforms (see perlport). To be safe, you may need to set $| ($AUTOFLUSH in English) or call the \"autoflush()\" method of \"IO::Handle\" on any open handles in order to avoid duplicate output. If you \"fork\" without ever waiting on your children, you will accumulate zombies. On some systems, you can avoid this by setting $SIG{CHLD} to \"IGNORE\". See also perlipc for more examples of forking and reaping moribund children. Note that if your forked child inherits system file descriptors like STDIN and STDOUT that are actually connected by a pipe or socket, even if you exit, then the remote server (such as, say, a CGI script or a backgrounded job launched from a remote shell) won't think you're done. You should reopen those to \/dev\/null if it's any issue. format Declare a picture format for use by the \"write\" function. For example: format Something =\n    Test: @<<<<<<<< @||||| @>>>>>\n          $str,     $%,    '$' . int($num)\n.\n\n$str = \"widget\";\n$num = $cost\/$quantity;\n$~ = 'Something';\nwrite; See perlform for many details and examples. formline PICTURE ,LIST This is an internal function used by \"format\"s, though you may call it, too. It formats (see perlform) a list of values according to the contents of PICTURE , placing the output into the format output accumulator, $^A (or $ACCUMULATOR in English). Eventually, when a \"write\" is done, the contents of $^A are written to some filehandle. You could also read $^A and then set $^A back to \"\". Note that a format typically does one \"formline\" per line of form, but the \"formline\" function itself doesn't care how many newlines are embedded in the PICTURE . This means that the \"~\" and \"~~\" tokens will treat the entire PICTURE as a single line. You may therefore need to use multiple formlines to implement a single record format, just like the format compiler. Be careful if you put double quotes around the picture, because an \"@\" character may be taken to mean the beginning of an array name. \"formline\" always returns true. See perlform for other examples. getc FILEHANDLE getc Returns the next character from the input file attached to FILEHANDLE , or the undefined value at end of file, or if there was an error (in the latter case $! is set). If FILEHANDLE is omitted, reads from STDIN . This is not particularly efficient. However, it cannot be used by itself to fetch single characters without waiting for the user to hit enter. For that, try something more like: if ($BSD_STYLE) {\n    system \"stty cbreak <\/dev\/tty >\/dev\/tty 2>&1\";\n}\nelse {\n    system \"stty\", '-icanon', 'eol', \"\\001\";\n}\n\n$key = getc(STDIN);\n\nif ($BSD_STYLE) {\n    system \"stty -cbreak <\/dev\/tty >\/dev\/tty 2>&1\";\n}\nelse {\n    system \"stty\", 'icanon', 'eol', '^@'; # ASCII null\n}\nprint \"\\n\"; Determination of whether $BSD_STYLE should be set is left as an exercise to the reader. The \"POSIX::getattr\" function can do this more portably on systems purporting POSIX compliance. See also the \"Term::ReadKey\" module from your nearest CPAN site; details on CPAN can be found on \" CPAN \" in perlmodlib. getlogin This implements the C library function of the same name, which on most systems returns the current login from \/etc\/utmp, if any. If null, use \"getpwuid\". $login = getlogin || getpwuid($<) || \"Kilroy\"; Do not consider \"getlogin\" for authentication: it is not as secure as \"getpwuid\". getpeername SOCKET Returns the packed sockaddr address of other end of the SOCKET connection. use Socket;\n$hersockaddr    = getpeername(SOCK);\n($port, $iaddr) = sockaddr_in($hersockaddr);\n$herhostname    = gethostbyaddr($iaddr, AF_INET);\n$herstraddr     = inet_ntoa($iaddr); getpgrp PID Returns the current process group for the specified PID . Use a PID of 0 to get the current process group for the current process. Will raise an exception if used on a machine that doesn't implement getpgrp(2). If PID is omitted, returns process group of current process. Note that the POSIX version of \"getpgrp\" does not accept a PID argument, so only \"PID==0\" is truly portable. getppid Returns the process id of the parent process. Note for Linux users: on Linux, the C functions \"getpid()\" and \"getppid()\" return different values from different threads. In order to be portable, this behavior is not reflected by the perl-level function \"getppid()\", that returns a consistent value across threads. If you want to call the underlying \"getppid()\", you may use the CPAN module \"Linux::Pid\". getpriority WHICH ,WHO Returns the current priority for a process, a process group, or a user. (See getpriority(2).) Will raise a fatal exception if used on a machine that doesn't implement getpriority(2). getpwnam NAME getgrnam NAME gethostbyname NAME getnetbyname NAME getprotobyname NAME getpwuid UID getgrgid GID getservbyname NAME ,PROTO gethostbyaddr ADDR ,ADDRTYPE getnetbyaddr ADDR ,ADDRTYPE getprotobynumber NUMBER getservbyport PORT ,PROTO getpwent getgrent gethostent getnetent getprotoent getservent setpwent setgrent sethostent STAYOPEN setnetent STAYOPEN setprotoent STAYOPEN setservent STAYOPEN endpwent endgrent endhostent endnetent endprotoent endservent These routines perform the same functions as their counterparts in the system library. In list context, the return values from the various get routines are as follows: ($name,$passwd,$uid,$gid,\n   $quota,$comment,$gcos,$dir,$shell,$expire) = getpw*\n($name,$passwd,$gid,$members) = getgr*\n($name,$aliases,$addrtype,$length,@addrs) = gethost*\n($name,$aliases,$addrtype,$net) = getnet*\n($name,$aliases,$proto) = getproto*\n($name,$aliases,$port,$proto) = getserv* (If the entry doesn't exist you get a null list.) The exact meaning of the $gcos field varies but it usually contains the real name of the user (as opposed to the login name) and other information pertaining to the user. Beware, however, that in many system users are able to change this information and therefore it cannot be trusted and therefore the $gcos is tainted (see perlsec). The $passwd and $shell, user's encrypted password and login shell, are also tainted, because of the same reason. In scalar context, you get the name, unless the function was a lookup by name, in which case you get the other thing, whatever it is. (If the entry doesn't exist you get the undefined value.) For example: $uid   = getpwnam($name);\n$name  = getpwuid($num);\n$name  = getpwent();\n$gid   = getgrnam($name);\n$name  = getgrgid($num);\n$name  = getgrent();\n#etc. In getpw*() the fields $quota, $comment, and $expire are special cases in the sense that in many systems they are unsupported. If the $quota is unsupported, it is an empty scalar. If it is supported, it usually encodes the disk quota. If the $comment field is unsupported, it is an empty scalar. If it is supported it usually encodes some administrative comment about the user. In some systems the $quota field may be $change or $age, fields that have to do with password aging. In some systems the $comment field may be $class. The $expire field, if present, encodes the expiration period of the account or the password. For the availability and the exact meaning of these fields in your system, please consult your getpwnam(3) documentation and your pwd.h file. You can also find out from within Perl what your $quota and $comment fields mean and whether you have the $expire field by using the \"Config\" module and the values \"d_pwquota\", \"d_pwage\", \"d_pwchange\", \"d_pwcomment\", and \"d_pwexpire\". Shadow password files are only supported if your vendor has implemented them in the intuitive fashion that calling the regular C library routines gets the shadow versions if you're running under privilege or if there exists the shadow(3) functions as found in System V (this includes Solaris and Linux.) Those systems that implement a proprietary shadow password facility are unlikely to be supported. The $members value returned by getgr*() is a space separated list of the login names of the members of the group. For the gethost*() functions, if the \"h_errno\" variable is supported in C, it will be returned to you via $? if the function call fails. The @addrs value returned by a successful call is a list of the raw addresses returned by the corresponding system library call. In the Internet domain, each address is four bytes long and you can unpack it by saying something like: ($a,$b,$c,$d) = unpack('W4',$addr[0]); The Socket library makes this slightly easier: use Socket;\n$iaddr = inet_aton(\"127.1\"); # or whatever address\n$name  = gethostbyaddr($iaddr, AF_INET);\n\n# or going the other way\n$straddr = inet_ntoa($iaddr); In the opposite way, to resolve a hostname to the IP address you can write this: use Socket;\n$packed_ip = gethostbyname(\"www.perl.org\");\nif (defined $packed_ip) {\n    $ip_address = inet_ntoa($packed_ip);\n} Make sure < gethostbyname()> is called in SCALAR context and that its return value is checked for definedness. If you get tired of remembering which element of the return list contains which return value, by-name interfaces are provided in standard modules: \"File::stat\", \"Net::hostent\", \"Net::netent\", \"Net::protoent\", \"Net::servent\", \"Time::gmtime\", \"Time::localtime\", and \"User::grent\". These override the normal built-ins, supplying versions that return objects with the appropriate names for each field. For example: use File::stat;\nuse User::pwent;\n$is_his = (stat($filename)->uid == pwent($whoever)->uid); Even though it looks like they're the same method calls (uid), they aren't, because a \"File::stat\" object is different from a \"User::pwent\" object. getsockname SOCKET Returns the packed sockaddr address of this end of the SOCKET connection, in case you don't know the address because you have several different IPs that the connection might have come in on. use Socket;\n$mysockaddr = getsockname(SOCK);\n($port, $myaddr) = sockaddr_in($mysockaddr);\nprintf \"Connect to %s [%s]\\n\",\n   scalar gethostbyaddr($myaddr, AF_INET),\n   inet_ntoa($myaddr); getsockopt SOCKET ,LEVEL,OPTNAME Queries the option named OPTNAME associated with SOCKET at a given LEVEL . Options may exist at multiple protocol levels depending on the socket type, but at least the uppermost socket level SOL_SOCKET (defined in the \"Socket\" module) will exist. To query options at another level the protocol number of the appropriate protocol controlling the option should be supplied. For example, to indicate that an option is to be interpreted by the TCP protocol, LEVEL should be set to the protocol number of TCP , which you can get using getprotobyname. The call returns a packed string representing the requested socket option, or \"undef\" if there is an error (the error reason will be in $!). What exactly is in the packed string depends in the LEVEL and OPTNAME , consult your system documentation for details. A very common case however is that the option is an integer, in which case the result will be a packed integer which you can decode using unpack with the \"i\" (or \"I\") format. An example testing if Nagle's algorithm is turned on on a socket: use Socket qw(:all);\n\ndefined(my $tcp = getprotobyname(\"tcp\"))\n    or die \"Could not determine the protocol number for tcp\";\n# my $tcp = IPPROTO_TCP; # Alternative\nmy $packed = getsockopt($socket, $tcp, TCP_NODELAY)\n    or die \"Could not query TCP_NODELAY socket option: $!\";\nmy $nodelay = unpack(\"I\", $packed);\nprint \"Nagle's algorithm is turned \", $nodelay ? \"off\\n\" : \"on\\n\"; glob EXPR glob In list context, returns a (possibly empty) list of filename expansions on the value of EXPR such as the standard Unix shell \/bin\/csh would do. In scalar context, glob iterates through such filename expansions, returning undef when the list is exhausted. This is the internal function implementing the \"<*.c>\" operator, but you can use it directly. If EXPR is omitted, $_ is used. The \"<*.c>\" operator is discussed in more detail in \"I\/O Operators\" in perlop. Note that \"glob\" will split its arguments on whitespace, treating each segment as separate pattern. As such, \"glob('*.c *.h')\" would match all files with a .c or .h extension. The expression \"glob('.* *')\" would match all files in the current working directory. Beginning with v5.6.0, this operator is implemented using the standard \"File::Glob\" extension. See File::Glob for details, including \"bsd_glob\" which does not treat whitespace as a pattern separator. gmtime EXPR gmtime Works just like localtime but the returned values are localized for the standard Greenwich time zone. Note: when called in list context, $isdst, the last value returned by gmtime is always 0. There is no Daylight Saving Time in GMT . See \"gmtime\" in perlport for portability concerns. goto LABEL goto EXPR goto &NAME The \"goto-LABEL\" form finds the statement labeled with LABEL and resumes execution there. It may not be used to go into any construct that requires initialization, such as a subroutine or a \"foreach\" loop. It also can't be used to go into a construct that is optimized away, or to get out of a block or subroutine given to \"sort\". It can be used to go almost anywhere else within the dynamic scope, including out of subroutines, but it's usually better to use some other construct such as \"last\" or \"die\". The author of Perl has never felt the need to use this form of \"goto\" (in Perl, that is--C is another matter). (The difference being that C does not offer named loops combined with loop control. Perl does, and this replaces most structured uses of \"goto\" in other languages.) The \"goto-EXPR\" form expects a label name, whose scope will be resolved dynamically. This allows for computed \"goto\"s per FORTRAN , but isn't necessarily recommended if you're optimizing for maintainability: goto (\"FOO\", \"BAR\", \"GLARCH\")[$i]; The \"goto-&NAME\" form is quite different from the other forms of \"goto\". In fact, it isn't a goto in the normal sense at all, and doesn't have the stigma associated with other gotos. Instead, it exits the current subroutine (losing any changes set by local()) and immediately calls in its place the named subroutine using the current value of @_. This is used by \"AUTOLOAD\" subroutines that wish to load another subroutine and then pretend that the other subroutine had been called in the first place (except that any modifications to @_ in the current subroutine are propagated to the other subroutine.) After the \"goto\", not even \"caller\" will be able to tell that this routine was called first. NAME needn't be the name of a subroutine; it can be a scalar variable containing a code reference, or a block that evaluates to a code reference. grep BLOCK LIST grep EXPR ,LIST This is similar in spirit to, but not the same as, grep(1) and its relatives. In particular, it is not limited to using regular expressions. Evaluates the BLOCK or EXPR for each element of LIST (locally setting $_ to each element) and returns the list value consisting of those elements for which the expression evaluated to true. In scalar context, returns the number of times the expression was true. @foo = grep(!\/^#\/, @bar);    # weed out comments or equivalently, @foo = grep {!\/^#\/} @bar;    # weed out comments Note that $_ is an alias to the list value, so it can be used to modify the elements of the LIST . While this is useful and supported, it can cause bizarre results if the elements of LIST are not variables. Similarly, grep returns aliases into the original list, much as a for loop's index variable aliases the list elements. That is, modifying an element of a list returned by grep (for example, in a \"foreach\", \"map\" or another \"grep\") actually modifies the element in the original list. This is usually something to be avoided when writing clear code. If $_ is lexical in the scope where the \"grep\" appears (because it has been declared with \"my $_\") then, in addition to being locally aliased to the list elements, $_ keeps being lexical inside the block; i.e. it can't be seen from the outside, avoiding any potential side-effects. See also \"map\" for a list composed of the results of the BLOCK or EXPR . hex EXPR hex Interprets EXPR as a hex string and returns the corresponding value. (To convert strings that might start with either 0, \"0x\", or \"0b\", see \"oct\".) If EXPR is omitted, uses $_. print hex '0xAf'; # prints '175'\nprint hex 'aF';   # same Hex strings may only represent integers. Strings that would cause integer overflow trigger a warning. Leading whitespace is not stripped, unlike oct(). To present something as hex, look into \"printf\", \"sprintf\", or \"unpack\". import LIST There is no builtin \"import\" function. It is just an ordinary method (subroutine) defined (or inherited) by modules that wish to export names to another module. The \"use\" function calls the \"import\" method for the package used. See also \"use\", perlmod, and Exporter. index STR ,SUBSTR,POSITION index STR ,SUBSTR The index function searches for one string within another, but without the wildcard-like behavior of a full regular-expression pattern match. It returns the position of the first occurrence of SUBSTR in STR at or after POSITION . If POSITION is omitted, starts searching from the beginning of the string. POSITION before the beginning of the string or after its end is treated as if it were the beginning or the end, respectively. POSITION and the return value are based at 0 (or whatever you've set the $[ variable to--but don't do that). If the substring is not found, \"index\" returns one less than the base, ordinarily \"-1\". int EXPR int Returns the integer portion of EXPR . If EXPR is omitted, uses $_. You should not use this function for rounding: one because it truncates towards 0, and two because machine representations of floating point numbers can sometimes produce counterintuitive results. For example, \"int(-6.725\/0.025)\" produces -268 rather than the correct -269; that's because it's really more like -268.99999999999994315658 instead. Usually, the \"sprintf\", \"printf\", or the \"POSIX::floor\" and \"POSIX::ceil\" functions will serve you better than will int(). ioctl FILEHANDLE ,FUNCTION,SCALAR Implements the ioctl(2) function. You'll probably first have to say require \"sys\/ioctl.ph\";     # probably in $Config{archlib}\/sys\/ioctl.ph to get the correct function definitions. If sys\/ioctl.ph doesn't exist or doesn't have the correct definitions you'll have to roll your own, based on your C header files such as <sys\/ioctl.h>. (There is a Perl script called h2ph that comes with the Perl kit that may help you in this, but it's nontrivial.) SCALAR will be read and\/or written depending on the FUNCTION--a pointer to the string value of SCALAR will be passed as the third argument of the actual \"ioctl\" call. (If SCALAR has no string value but does have a numeric value, that value will be passed rather than a pointer to the string value. To guarantee this to be true, add a 0 to the scalar before using it.) The \"pack\" and \"unpack\" functions may be needed to manipulate the values of structures used by \"ioctl\". The return value of \"ioctl\" (and \"fcntl\") is as follows: if OS returns:          then Perl returns:\n    -1                    undefined value\n     0                  string \"0 but true\"\nanything else               that number Thus Perl returns true on success and false on failure, yet you can still easily determine the actual value returned by the operating system: $retval = ioctl(...) || -1;\nprintf \"System returned %d\\n\", $retval; The special string \"0 but true\" is exempt from -w complaints about improper numeric conversions. join EXPR ,LIST Joins the separate strings of LIST into a single string with fields separated by the value of EXPR , and returns that new string. Example: $rec = join(':', $login,$passwd,$uid,$gid,$gcos,$home,$shell); Beware that unlike \"split\", \"join\" doesn't take a pattern as its first argument. Compare \"split\". keys HASH Returns a list consisting of all the keys of the named hash. (In scalar context, returns the number of keys.) The keys are returned in an apparently random order. The actual random order is subject to change in future versions of perl, but it is guaranteed to be the same order as either the \"values\" or \"each\" function produces (given that the hash has not been modified). Since Perl 5.8.1 the ordering is different even between different runs of Perl for security reasons (see \"Algorithmic Complexity Attacks\" in perlsec). As a side effect, calling keys() resets the HASH 's internal iterator (see \"each\"). In particular, calling keys() in void context resets the iterator with no other overhead. Here is yet another way to print your environment: @keys = keys %ENV;\n@values = values %ENV;\nwhile (@keys) {\n    print pop(@keys), '=', pop(@values), \"\\n\";\n} or how about sorted by key: foreach $key (sort(keys %ENV)) {\n    print $key, '=', $ENV{$key}, \"\\n\";\n} The returned values are copies of the original keys in the hash, so modifying them will not affect the original hash. Compare \"values\". To sort a hash by value, you'll need to use a \"sort\" function. Here's a descending numeric sort of a hash by its values: foreach $key (sort { $hash{$b} <=> $hash{$a} } keys %hash) {\n    printf \"%4d %s\\n\", $hash{$key}, $key;\n} As an lvalue \"keys\" allows you to increase the number of hash buckets allocated for the given hash. This can gain you a measure of efficiency if you know the hash is going to get big. (This is similar to pre-extending an array by assigning a larger number to $#array.) If you say keys %hash = 200; then %hash will have at least 200 buckets allocated for it--256 of them, in fact, since it rounds up to the next power of two. These buckets will be retained even if you do \"%hash = ()\", use \"undef %hash\" if you want to free the storage while %hash is still in scope. You can't shrink the number of buckets allocated for the hash using \"keys\" in this way (but you needn't worry about doing this by accident, as trying has no effect). See also \"each\", \"values\" and \"sort\". kill SIGNAL , LIST Sends a signal to a list of processes. Returns the number of processes successfully signaled (which is not necessarily the same as the number actually killed). $cnt = kill 1, $child1, $child2;\nkill 9, @goners; If SIGNAL is zero, no signal is sent to the process, but the kill(2) system call will check whether it's possible to send a signal to it (that means, to be brief, that the process is owned by the same user, or we are the super-user). This is a useful way to check that a child process is alive (even if only as a zombie) and hasn't changed its UID . See perlport for notes on the portability of this construct. Unlike in the shell, if SIGNAL is negative, it kills process groups instead of processes. (On System V, a negative PROCESS number will also kill process groups, but that's not portable.) That means you usually want to use positive not negative signals. You may also use a signal name in quotes. See \"Signals\" in perlipc for more details. last LABEL last The \"last\" command is like the \"break\" statement in C (as used in loops); it immediately exits the loop in question. If the LABEL is omitted, the command refers to the innermost enclosing loop. The \"continue\" block, if any, is not executed: LINE: while (<STDIN>) {\n    last LINE if \/^$\/;      # exit when done with header\n    #...\n} \"last\" cannot be used to exit a block which returns a value such as \"eval {}\", \"sub {}\" or \"do {}\", and should not be used to exit a grep() or map() operation. Note that a block by itself is semantically identical to a loop that executes once. Thus \"last\" can be used to effect an early exit out of such a block. See also \"continue\" for an illustration of how \"last\", \"next\", and \"redo\" work. lc EXPR lc Returns a lowercased version of EXPR . This is the internal function implementing the \"\\L\" escape in double-quoted strings. Respects current LC_CTYPE locale if \"use locale\" in force. See perllocale and perlunicode for more details about locale and Unicode support. If EXPR is omitted, uses $_. lcfirst EXPR lcfirst Returns the value of EXPR with the first character lowercased. This is the internal function implementing the \"\\l\" escape in double-quoted strings. Respects current LC_CTYPE locale if \"use locale\" in force. See perllocale and perlunicode for more details about locale and Unicode support. If EXPR is omitted, uses $_. length EXPR length Returns the length in characters of the value of EXPR . If EXPR is omitted, returns length of $_. Note that this cannot be used on an entire array or hash to find out how many elements these have. For that, use \"scalar @array\" and \"scalar keys %hash\" respectively. Note the characters: if the EXPR is in Unicode, you will get the number of characters, not the number of bytes. To get the length of the internal string in bytes, use \"bytes::length(EXPR)\", see bytes. Note that the internal encoding is variable, and the number of bytes usually meaningless. To get the number of bytes that the string would have when encoded as UTF-8 , use \"length(Encoding::encode_utf8(EXPR))\". link OLDFILE ,NEWFILE Creates a new filename linked to the old filename. Returns true for success, false otherwise. listen SOCKET ,QUEUESIZE Does the same thing that the listen system call does. Returns true if it succeeded, false otherwise. See the example in \"Sockets: Client\/Server Communication\" in perlipc. local EXPR You really probably want to be using \"my\" instead, because \"local\" isn't what most people think of as \"local\". See \"Private Variables via my()\" in perlsub for details. A local modifies the listed variables to be local to the enclosing block, file, or eval. If more than one value is listed, the list must be placed in parentheses. See \"Temporary Values via local()\" in perlsub for details, including issues with tied arrays and hashes. localtime EXPR localtime Converts a time as returned by the time function to a 9-element list with the time analyzed for the local time zone. Typically used as follows: #  0    1    2     3     4    5     6     7     8\n($sec,$min,$hour,$mday,$mon,$year,$wday,$yday,$isdst) =\n                                            localtime(time); All list elements are numeric, and come straight out of the C 'struct tm'. $sec, $min, and $hour are the seconds, minutes, and hours of the specified time. $mday is the day of the month, and $mon is the month itself, in the range 0..11 with 0 indicating January and 11 indicating December. This makes it easy to get a month name from a list: my @abbr = qw( Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec );\nprint \"$abbr[$mon] $mday\";\n# $mon=9, $mday=18 gives \"Oct 18\" $year is the number of years since 1900, not just the last two digits of the year. That is, $year is 123 in year 2023. The proper way to get a complete 4-digit year is simply: $year += 1900; Otherwise you create non-Y2K-compliant programs--and you wouldn't want to do that, would you? To get the last two digits of the year (e.g., '01' in 2001) do: $year = sprintf(\"%02d\", $year % 100); $wday is the day of the week, with 0 indicating Sunday and 3 indicating Wednesday. $yday is the day of the year, in the range 0..364 (or 0..365 in leap years.) $isdst is true if the specified time occurs during Daylight Saving Time, false otherwise. If EXPR is omitted, \"localtime()\" uses the current time (as returned by time(3)). In scalar context, \"localtime()\" returns the ctime(3) value: $now_string = localtime;  # e.g., \"Thu Oct 13 04:54:34 1994\" This scalar value is not locale dependent but is a Perl builtin. For GMT instead of local time use the \"gmtime\" builtin. See also the \"Time::Local\" module (to convert the second, minutes, hours, ... back to the integer value returned by time()), and the POSIX module's strftime(3) and mktime(3) functions. To get somewhat similar but locale dependent date strings, set up your locale environment variables appropriately (please see perllocale) and try for example: use POSIX qw(strftime);\n$now_string = strftime \"%a %b %e %H:%M:%S %Y\", localtime;\n# or for GMT formatted appropriately for your locale:\n$now_string = strftime \"%a %b %e %H:%M:%S %Y\", gmtime; Note that the %a and %b, the short forms of the day of the week and the month of the year, may not necessarily be three characters wide. See \"localtime\" in perlport for portability concerns. The Time::gmtime and Time::localtime modules provides a convenient, by-name access mechanism to the gmtime() and localtime() functions, respectively. For a comprehensive date and time representation look at the DateTime module on CPAN . lock THING This function places an advisory lock on a shared variable, or referenced object contained in THING until the lock goes out of scope. lock() is a \"weak keyword\" : this means that if you've defined a function by this name (before any calls to it), that function will be called instead. (However, if you've said \"use threads\", lock() is always a keyword.) See threads. log EXPR log Returns the natural logarithm (base e) of EXPR . If EXPR is omitted, returns log of $_. To get the log of another base, use basic algebra: The base-N log of a number is equal to the natural log of that number divided by the natural log of N. For example: sub log10 {\n    my $n = shift;\n    return log($n)\/log(10);\n} See also \"exp\" for the inverse operation. lstat EXPR lstat Does the same thing as the \"stat\" function (including setting the special \"_\" filehandle) but stats a symbolic link instead of the file the symbolic link points to. If symbolic links are unimplemented on your system, a normal \"stat\" is done. For much more detailed information, please see the documentation for \"stat\". If EXPR is omitted, stats $_. m\/\/ The match operator. See \"Regexp Quote-Like Operators\" in perlop. map BLOCK LIST map EXPR ,LIST Evaluates the BLOCK or EXPR for each element of LIST (locally setting $_ to each element) and returns the list value composed of the results of each such evaluation. In scalar context, returns the total number of elements so generated. Evaluates BLOCK or EXPR in list context, so each element of LIST may produce zero, one, or more elements in the returned value. @chars = map(chr, @nums); translates a list of numbers to the corresponding characters. And %hash = map { get_a_key_for($_) => $_ } @array; is just a funny way to write %hash = ();\nforeach (@array) {\n    $hash{get_a_key_for($_)} = $_;\n} Note that $_ is an alias to the list value, so it can be used to modify the elements of the LIST . While this is useful and supported, it can cause bizarre results if the elements of LIST are not variables. Using a regular \"foreach\" loop for this purpose would be clearer in most cases. See also \"grep\" for an array composed of those items of the original list for which the BLOCK or EXPR evaluates to true. If $_ is lexical in the scope where the \"map\" appears (because it has been declared with \"my $_\"), then, in addition to being locally aliased to the list elements, $_ keeps being lexical inside the block; that is, it can't be seen from the outside, avoiding any potential side-effects. \"{\" starts both hash references and blocks, so \"map { ...\" could be either the start of map BLOCK LIST or map EXPR , LIST . Because perl doesn't look ahead for the closing \"}\" it has to take a guess at which its dealing with based what it finds just after the \"{\". Usually it gets it right, but if it doesn't it won't realize something is wrong until it gets to the \"}\" and encounters the missing (or unexpected) comma. The syntax error will be reported close to the \"}\" but you'll need to change something near the \"{\" such as using a unary \"+\" to give perl some help: %hash = map {  \"\\L$_\", 1  } @array  # perl guesses EXPR.  wrong\n%hash = map { +\"\\L$_\", 1  } @array  # perl guesses BLOCK. right\n%hash = map { (\"\\L$_\", 1) } @array  # this also works\n%hash = map {  lc($_), 1  } @array  # as does this.\n%hash = map +( lc($_), 1 ), @array  # this is EXPR and works!\n\n%hash = map  ( lc($_), 1 ), @array  # evaluates to (1, @array) or to force an anon hash constructor use \"+{\": @hashes = map +{ lc($_), 1 }, @array # EXPR, so needs , at end and you get list of anonymous hashes each with only 1 entry. mkdir FILENAME ,MASK mkdir FILENAME mkdir Creates the directory specified by FILENAME , with permissions specified by MASK (as modified by \"umask\"). If it succeeds it returns true, otherwise it returns false and sets $! (errno). If omitted, MASK defaults to 0777. If omitted, FILENAME defaults to $_. In general, it is better to create directories with permissive MASK , and let the user modify that with their \"umask\", than it is to supply a restrictive MASK and give the user no way to be more permissive. The exceptions to this rule are when the file or directory should be kept private (mail files, for instance). The perlfunc(1) entry on \"umask\" discusses the choice of MASK in more detail. Note that according to the POSIX 1003.1-1996 the FILENAME may have any number of trailing slashes. Some operating and filesystems do not get this right, so Perl automatically removes all trailing slashes to keep everyone happy. In order to recursively create a directory structure look at the \"mkpath\" function of the File::Path module. msgctl ID ,CMD,ARG Calls the System V IPC function msgctl(2). You'll probably have to say use IPC::SysV; first to get the correct constant definitions. If CMD is \"IPC_STAT\", then ARG must be a variable that will hold the returned \"msqid_ds\" structure. Returns like \"ioctl\": the undefined value for error, \"0 but true\" for zero, or the actual return value otherwise. See also \"SysV IPC \" in perlipc, \"IPC::SysV\", and \"IPC::Semaphore\" documentation. msgget KEY ,FLAGS Calls the System V IPC function msgget(2). Returns the message queue id, or the undefined value if there is an error. See also \"SysV IPC \" in perlipc and \"IPC::SysV\" and \"IPC::Msg\" documentation. msgrcv ID ,VAR,SIZE,TYPE,FLAGS Calls the System V IPC function msgrcv to receive a message from message queue ID into variable VAR with a maximum message size of SIZE . Note that when a message is received, the message type as a native long integer will be the first thing in VAR , followed by the actual message. This packing may be opened with \"unpack(\"l! a*\")\". Taints the variable. Returns true if successful, or false if there is an error. See also \"SysV IPC \" in perlipc, \"IPC::SysV\", and \"IPC::SysV::Msg\" documentation. msgsnd ID ,MSG,FLAGS Calls the System V IPC function msgsnd to send the message MSG to the message queue ID . MSG must begin with the native long integer message type, and be followed by the length of the actual message, and finally the message itself. This kind of packing can be achieved with \"pack(\"l! a*\", $type, $message)\". Returns true if successful, or false if there is an error. See also \"IPC::SysV\" and \"IPC::SysV::Msg\" documentation. my EXPR my TYPE EXPR my EXPR : ATTRS my TYPE EXPR : ATTRS A \"my\" declares the listed variables to be local (lexically) to the enclosing block, file, or \"eval\". If more than one value is listed, the list must be placed in parentheses. The exact semantics and interface of TYPE and ATTRS are still evolving. TYPE is currently bound to the use of \"fields\" pragma, and attributes are handled using the \"attributes\" pragma, or starting from Perl 5.8.0 also via the \"Attribute::Handlers\" module. See \"Private Variables via my()\" in perlsub for details, and fields, attributes, and Attribute::Handlers. next LABEL next The \"next\" command is like the \"continue\" statement in C; it starts the next iteration of the loop: LINE: while (<STDIN>) {\n    next LINE if \/^#\/;      # discard comments\n    #...\n} Note that if there were a \"continue\" block on the above, it would get executed even on discarded lines. If the LABEL is omitted, the command refers to the innermost enclosing loop. \"next\" cannot be used to exit a block which returns a value such as \"eval {}\", \"sub {}\" or \"do {}\", and should not be used to exit a grep() or map() operation. Note that a block by itself is semantically identical to a loop that executes once. Thus \"next\" will exit such a block early. See also \"continue\" for an illustration of how \"last\", \"next\", and \"redo\" work. no Module VERSION LIST no Module VERSION no Module LIST no Module no VERSION See the \"use\" function, of which \"no\" is the opposite. oct EXPR oct Interprets EXPR as an octal string and returns the corresponding value. (If EXPR happens to start off with \"0x\", interprets it as a hex string. If EXPR starts off with \"0b\", it is interpreted as a binary string. Leading whitespace is ignored in all three cases.) The following will handle decimal, binary, octal, and hex in the standard Perl or C notation: $val = oct($val) if $val =~ \/^0\/; If EXPR is omitted, uses $_. To go the other way (produce a number in octal), use sprintf() or printf(): $perms = (stat(\"filename\"))[2] & 07777;\n$oct_perms = sprintf \"%lo\", $perms; The oct() function is commonly used when a string such as 644 needs to be converted into a file mode, for example. (Although perl will automatically convert strings into numbers as needed, this automatic conversion assumes base 10.) open FILEHANDLE ,EXPR open FILEHANDLE ,MODE,EXPR open FILEHANDLE ,MODE,EXPR,LIST open FILEHANDLE ,MODE,REFERENCE open FILEHANDLE Opens the file whose filename is given by EXPR , and associates it with FILEHANDLE . Simple examples to open a file for reading: open(my $fh, '<', \"input.txt\") or die $!; and for writing: open(my $fh, '>', \"output.txt\") or die $!; (The following is a comprehensive reference to open(): for a gentler introduction you may consider perlopentut.) If FILEHANDLE is an undefined scalar variable (or array or hash element) the variable is assigned a reference to a new anonymous filehandle, otherwise if FILEHANDLE is an expression, its value is used as the name of the real filehandle wanted. (This is considered a symbolic reference, so \"use strict 'refs'\" should not be in effect.) If EXPR is omitted, the scalar variable of the same name as the FILEHANDLE contains the filename. (Note that lexical variables--those declared with \"my\"--will not work for this purpose; so if you're using \"my\", specify EXPR in your call to open.) If three or more arguments are specified then the mode of opening and the file name are separate. If MODE is '<' or nothing, the file is opened for input. If MODE is '>', the file is truncated and opened for output, being created if necessary. If MODE is '>>', the file is opened for appending, again being created if necessary. You can put a '+' in front of the '>' or '<' to indicate that you want both read and write access to the file; thus '+<' is almost always preferred for read\/write updates--the '+>' mode would clobber the file first. You can't usually use either read-write mode for updating textfiles, since they have variable length records. See the -i switch in perlrun for a better approach. The file is created with permissions of 0666 modified by the process' \"umask\" value. These various prefixes correspond to the fopen(3) modes of 'r', 'r+', 'w', 'w+', 'a', and 'a+'. In the 2-arguments (and 1-argument) form of the call the mode and filename should be concatenated (in this order), possibly separated by spaces. It is possible to omit the mode in these forms if the mode is '<'. If the filename begins with '|', the filename is interpreted as a command to which output is to be piped, and if the filename ends with a '|', the filename is interpreted as a command which pipes output to us. See \"Using open() for IPC \" in perlipc for more examples of this. (You are not allowed to \"open\" to a command that pipes both in and out, but see IPC::Open2, IPC::Open3, and \"Bidirectional Communication with Another Process\" in perlipc for alternatives.) For three or more arguments if MODE is '|-', the filename is interpreted as a command to which output is to be piped, and if MODE is '-|', the filename is interpreted as a command which pipes output to us. In the 2-arguments (and 1-argument) form one should replace dash ('-') with the command. See \"Using open() for IPC \" in perlipc for more examples of this. (You are not allowed to \"open\" to a command that pipes both in and out, but see IPC::Open2, IPC::Open3, and \"Bidirectional Communication\" in perlipc for alternatives.) In the three-or-more argument form of pipe opens, if LIST is specified (extra arguments after the command name) then LIST becomes arguments to the command invoked if the platform supports it. The meaning of \"open\" with more than three arguments for non-pipe modes is not yet specified. Experimental \"layers\" may give extra LIST arguments meaning. In the 2-arguments (and 1-argument) form opening '-' opens STDIN and opening '>-' opens STDOUT . You may use the three-argument form of open to specify IO \"layers\" (sometimes also referred to as \"disciplines\") to be applied to the handle that affect how the input and output are processed (see open and PerlIO for more details). For example open(my $fh, \"<:encoding(UTF-8)\", \"file\") will open the UTF-8 encoded file containing Unicode characters, see perluniintro. Note that if layers are specified in the three-arg form then default layers stored in ${^OPEN} (see perlvar; usually set by the open pragma or the switch -CioD) are ignored. Open returns nonzero upon success, the undefined value otherwise. If the \"open\" involved a pipe, the return value happens to be the pid of the subprocess. If you're running Perl on a system that distinguishes between text files and binary files, then you should check out \"binmode\" for tips for dealing with this. The key distinction between systems that need \"binmode\" and those that don't is their text file formats. Systems like Unix, Mac OS , and Plan 9, which delimit lines with a single character, and which encode that character in C as \"\\n\", do not need \"binmode\". The rest need it. When opening a file, it's usually a bad idea to continue normal execution if the request failed, so \"open\" is frequently used in connection with \"die\". Even if \"die\" won't do what you want (say, in a CGI script, where you want to make a nicely formatted error message (but there are modules that can help with that problem)) you should always check the return value from opening a file. The infrequent exception is when working with an unopened filehandle is actually what you want to do. As a special case the 3-arg form with a read\/write mode and the third argument being \"undef\": open(my $tmp, \"+>\", undef) or die ... opens a filehandle to an anonymous temporary file. Also using \"+<\" works for symmetry, but you really should consider writing something to the temporary file first. You will need to seek() to do the reading. Since v5.8.0, perl has built using PerlIO by default. Unless you've changed this (i.e. Configure -Uuseperlio), you can open file handles to \"in memory\" files held in Perl scalars via: open($fh, '>', \\$variable) || .. Though if you try to re-open \"STDOUT\" or \"STDERR\" as an \"in memory\" file, you have to close it first: close STDOUT;\nopen STDOUT, '>', \\$variable or die \"Can't open STDOUT: $!\"; Examples: $ARTICLE = 100;\nopen ARTICLE or die \"Can't find article $ARTICLE: $!\\n\";\nwhile (<ARTICLE>) {...\n\nopen(LOG, '>>\/usr\/spool\/news\/twitlog');     # (log is reserved)\n# if the open fails, output is discarded\n\nopen(my $dbase, '+<', 'dbase.mine')         # open for update\n    or die \"Can't open 'dbase.mine' for update: $!\";\n\nopen(my $dbase, '+<dbase.mine')                     # ditto\n    or die \"Can't open 'dbase.mine' for update: $!\";\n\nopen(ARTICLE, '-|', \"caesar <$article\")     # decrypt article\n    or die \"Can't start caesar: $!\";\n\nopen(ARTICLE, \"caesar <$article |\")         # ditto\n    or die \"Can't start caesar: $!\";\n\nopen(EXTRACT, \"|sort >Tmp$$\")               # $$ is our process id\n    or die \"Can't start sort: $!\";\n\n# in memory files\nopen(MEMORY,'>', \\$var)\n    or die \"Can't open memory file: $!\";\nprint MEMORY \"foo!\\n\";                      # output will end up in $var\n\n# process argument list of files along with any includes\n\nforeach $file (@ARGV) {\n    process($file, 'fh00');\n}\n\nsub process {\n    my($filename, $input) = @_;\n    $input++;               # this is a string increment\n    unless (open($input, $filename)) {\n        print STDERR \"Can't open $filename: $!\\n\";\n        return;\n    }\n\n    local $_;\n    while (<$input>) {              # note use of indirection\n        if (\/^#include \"(.*)\"\/) {\n            process($1, $input);\n            next;\n        }\n        #...                # whatever\n    }\n} See perliol for detailed info on PerlIO. You may also, in the Bourne shell tradition, specify an EXPR beginning with '>&', in which case the rest of the string is interpreted as the name of a filehandle (or file descriptor, if numeric) to be duped (as dup(2)) and opened. You may use \"&\" after \">\", \">>\", \"<\", \"+>\", \"+>>\", and \"+<\". The mode you specify should match the mode of the original filehandle. (Duping a filehandle does not take into account any existing contents of IO buffers.) If you use the 3-arg form then you can pass either a number, the name of a filehandle or the normal \"reference to a glob\". Here is a script that saves, redirects, and restores \"STDOUT\" and \"STDERR\" using various methods: #!\/usr\/bin\/perl\nopen my $oldout, \">&STDOUT\"     or die \"Can't dup STDOUT: $!\";\nopen OLDERR,     \">&\", \\*STDERR or die \"Can't dup STDERR: $!\";\n\nopen STDOUT, '>', \"foo.out\" or die \"Can't redirect STDOUT: $!\";\nopen STDERR, \">&STDOUT\"     or die \"Can't dup STDOUT: $!\";\n\nselect STDERR; $| = 1;      # make unbuffered\nselect STDOUT; $| = 1;      # make unbuffered\n\nprint STDOUT \"stdout 1\\n\";  # this works for\nprint STDERR \"stderr 1\\n\";  # subprocesses too\n\nopen STDOUT, \">&\", $oldout or die \"Can't dup \\$oldout: $!\";\nopen STDERR, \">&OLDERR\"    or die \"Can't dup OLDERR: $!\";\n\nprint STDOUT \"stdout 2\\n\";\nprint STDERR \"stderr 2\\n\"; If you specify '<&=X', where \"X\" is a file descriptor number or a filehandle, then Perl will do an equivalent of C's \"fdopen\" of that file descriptor (and not call dup(2)); this is more parsimonious of file descriptors. For example: # open for input, reusing the fileno of $fd\nopen(FILEHANDLE, \"<&=$fd\") or open(FILEHANDLE, \"<&=\", $fd) or # open for append, using the fileno of OLDFH\nopen(FH, \">>&=\", OLDFH) or open(FH, \">>&=OLDFH\") Being parsimonious on filehandles is also useful (besides being parsimonious) for example when something is dependent on file descriptors, like for example locking using flock(). If you do just \"open(A, '>>&B')\", the filehandle A will not have the same file descriptor as B, and therefore flock(A) will not flock(B), and vice versa. But with \"open(A, '>>&=B')\" the filehandles will share the same file descriptor. Note that if you are using Perls older than 5.8.0, Perl will be using the standard C libraries' fdopen() to implement the \"=\" functionality. On many UNIX systems fdopen() fails when file descriptors exceed a certain value, typically 255. For Perls 5.8.0 and later, PerlIO is most often the default. You can see whether Perl has been compiled with PerlIO or not by running \"perl -V\" and looking for \"useperlio=\" line. If \"useperlio\" is \"define\", you have PerlIO, otherwise you don't. If you open a pipe on the command '-', i.e., either '|-' or '-|' with 2-arguments (or 1-argument) form of open(), then there is an implicit fork done, and the return value of open is the pid of the child within the parent process, and 0 within the child process. (Use \"defined($pid)\" to determine whether the open was successful.) The filehandle behaves normally for the parent, but i\/o to that filehandle is piped from\/to the STDOUT\/STDIN of the child process. In the child process the filehandle isn't opened--i\/o happens from\/to the new STDOUT or STDIN . Typically this is used like the normal piped open when you want to exercise more control over just how the pipe command gets executed, such as when you are running setuid, and don't want to have to scan shell commands for metacharacters. The following triples are more or less equivalent: open(FOO, \"|tr '[a-z]' '[A-Z]'\");\nopen(FOO, '|-', \"tr '[a-z]' '[A-Z]'\");\nopen(FOO, '|-') || exec 'tr', '[a-z]', '[A-Z]';\nopen(FOO, '|-', \"tr\", '[a-z]', '[A-Z]');\n\nopen(FOO, \"cat -n '$file'|\");\nopen(FOO, '-|', \"cat -n '$file'\");\nopen(FOO, '-|') || exec 'cat', '-n', $file;\nopen(FOO, '-|', \"cat\", '-n', $file); The last example in each block shows the pipe as \"list form\", which is not yet supported on all platforms. A good rule of thumb is that if your platform has true \"fork()\" (in other words, if your platform is UNIX ) you can use the list form. See \"Safe Pipe Opens\" in perlipc for more examples of this. Beginning with v5.6.0, Perl will attempt to flush all files opened for output before any operation that may do a fork, but this may not be supported on some platforms (see perlport). To be safe, you may need to set $| ($AUTOFLUSH in English) or call the \"autoflush()\" method of \"IO::Handle\" on any open handles. On systems that support a close-on-exec flag on files, the flag will be set for the newly opened file descriptor as determined by the value of $^F. See \"$^F\" in perlvar. Closing any piped filehandle causes the parent process to wait for the child to finish, and returns the status value in $? and \"${^CHILD_ERROR_NATIVE}\". The filename passed to 2-argument (or 1-argument) form of open() will have leading and trailing whitespace deleted, and the normal redirection characters honored. This property, known as \"magic open\", can often be used to good effect. A user could specify a filename of \"rsh cat file |\", or you could change certain filenames as needed: $filename =~ s\/(.*\\.gz)\\s*$\/gzip -dc < $1|\/;\nopen(FH, $filename) or die \"Can't open $filename: $!\"; Use 3-argument form to open a file with arbitrary weird characters in it, open(FOO, '<', $file); otherwise it's necessary to protect any leading and trailing whitespace: $file =~ s#^(\\s)#.\/$1#;\nopen(FOO, \"< $file\\0\"); (this may not work on some bizarre filesystems). One should conscientiously choose between the magic and 3-arguments form of open(): open IN, $ARGV[0]; will allow the user to specify an argument of the form \"rsh cat file |\", but will not work on a filename which happens to have a trailing space, while open IN, '<', $ARGV[0]; will have exactly the opposite restrictions. If you want a \"real\" C \"open\" (see open(2) on your system), then you should use the \"sysopen\" function, which involves no such magic (but may use subtly different filemodes than Perl open(), which is mapped to C fopen()). This is another way to protect your filenames from interpretation. For example: use IO::Handle;\nsysopen(HANDLE, $path, O_RDWR|O_CREAT|O_EXCL)\n    or die \"sysopen $path: $!\";\n$oldfh = select(HANDLE); $| = 1; select($oldfh);\nprint HANDLE \"stuff $$\\n\";\nseek(HANDLE, 0, 0);\nprint \"File contains: \", <HANDLE>; Using the constructor from the \"IO::Handle\" package (or one of its subclasses, such as \"IO::File\" or \"IO::Socket\"), you can generate anonymous filehandles that have the scope of whatever variables hold references to them, and automatically close whenever and however you leave that scope: use IO::File;\n#...\nsub read_myfile_munged {\n    my $ALL = shift;\n    my $handle = IO::File->new;\n    open($handle, \"myfile\") or die \"myfile: $!\";\n    $first = <$handle>\n        or return ();     # Automatically closed here.\n    mung $first or die \"mung failed\";       # Or here.\n    return $first, <$handle> if $ALL;       # Or here.\n    $first;                                 # Or here.\n} See \"seek\" for some details about mixing reading and writing. opendir DIRHANDLE ,EXPR Opens a directory named EXPR for processing by \"readdir\", \"telldir\", \"seekdir\", \"rewinddir\", and \"closedir\". Returns true if successful. DIRHANDLE may be an expression whose value can be used as an indirect dirhandle, usually the real dirhandle name. If DIRHANDLE is an undefined scalar variable (or array or hash element), the variable is assigned a reference to a new anonymous dirhandle. DIRHANDLEs have their own namespace separate from FILEHANDLEs. See example at \"readdir\". ord EXPR ord Returns the numeric (the native 8-bit encoding, like ASCII or EBCDIC , or Unicode) value of the first character of EXPR . If EXPR is omitted, uses $_. For the reverse, see \"chr\". See perlunicode for more about Unicode. our EXPR our TYPE EXPR our EXPR : ATTRS our TYPE EXPR : ATTRS \"our\" associates a simple name with a package variable in the current package for use within the current scope. When \"use strict 'vars'\" is in effect, \"our\" lets you use declared global variables without qualifying them with package names, within the lexical scope of the \"our\" declaration. In this way \"our\" differs from \"use vars\", which is package scoped. Unlike \"my\", which both allocates storage for a variable and associates a simple name with that storage for use within the current scope, \"our\" associates a simple name with a package variable in the current package, for use within the current scope. In other words, \"our\" has the same scoping rules as \"my\", but does not necessarily create a variable. If more than one value is listed, the list must be placed in parentheses. our $foo;\nour($bar, $baz); An \"our\" declaration declares a global variable that will be visible across its entire lexical scope, even across package boundaries. The package in which the variable is entered is determined at the point of the declaration, not at the point of use. This means the following behavior holds: package Foo;\nour $bar;           # declares $Foo::bar for rest of lexical scope\n$bar = 20;\n\npackage Bar;\nprint $bar;         # prints 20, as it refers to $Foo::bar Multiple \"our\" declarations with the same name in the same lexical scope are allowed if they are in different packages. If they happen to be in the same package, Perl will emit warnings if you have asked for them, just like multiple \"my\" declarations. Unlike a second \"my\" declaration, which will bind the name to a fresh variable, a second \"our\" declaration in the same package, in the same scope, is merely redundant. use warnings;\npackage Foo;\nour $bar;           # declares $Foo::bar for rest of lexical scope\n$bar = 20;\n\npackage Bar;\nour $bar = 30;      # declares $Bar::bar for rest of lexical scope\nprint $bar;         # prints 30\n\nour $bar;           # emits warning but has no other effect\nprint $bar;         # still prints 30 An \"our\" declaration may also have a list of attributes associated with it. The exact semantics and interface of TYPE and ATTRS are still evolving. TYPE is currently bound to the use of \"fields\" pragma, and attributes are handled using the \"attributes\" pragma, or starting from Perl 5.8.0 also via the \"Attribute::Handlers\" module. See \"Private Variables via my()\" in perlsub for details, and fields, attributes, and Attribute::Handlers. pack TEMPLATE ,LIST Takes a LIST of values and converts it into a string using the rules given by the TEMPLATE . The resulting string is the concatenation of the converted values. Typically, each converted value looks like its machine-level representation. For example, on 32-bit machines an integer may be represented by a sequence of 4 bytes that will be converted to a sequence of 4 characters. The TEMPLATE is a sequence of characters that give the order and type of values, as follows: a   A string with arbitrary binary data, will be null padded.\nA   A text (ASCII) string, will be space padded.\nZ   A null terminated (ASCIZ) string, will be null padded.\n\nb   A bit string (ascending bit order inside each byte, like vec()).\nB   A bit string (descending bit order inside each byte).\nh   A hex string (low nybble first).\nH   A hex string (high nybble first).\n\nc   A signed char (8-bit) value.\nC   An unsigned char (octet) value.\nW   An unsigned char value (can be greater than 255).\n\ns   A signed short (16-bit) value.\nS   An unsigned short value.\n\nl   A signed long (32-bit) value.\nL   An unsigned long value.\n\nq   A signed quad (64-bit) value.\nQ   An unsigned quad value.\n      (Quads are available only if your system supports 64-bit\n       integer values _and_ if Perl has been compiled to support those.\n       Causes a fatal error otherwise.)\n\ni   A signed integer value.\nI   A unsigned integer value.\n      (This 'integer' is _at_least_ 32 bits wide.  Its exact\n       size depends on what a local C compiler calls 'int'.)\n\nn   An unsigned short (16-bit) in \"network\" (big-endian) order.\nN   An unsigned long (32-bit) in \"network\" (big-endian) order.\nv   An unsigned short (16-bit) in \"VAX\" (little-endian) order.\nV   An unsigned long (32-bit) in \"VAX\" (little-endian) order.\n\nj   A Perl internal signed integer value (IV).\nJ   A Perl internal unsigned integer value (UV).\n\nf   A single-precision float in the native format.\nd   A double-precision float in the native format.\n\nF   A Perl internal floating point value (NV) in the native format\nD   A long double-precision float in the native format.\n      (Long doubles are available only if your system supports long\n       double values _and_ if Perl has been compiled to support those.\n       Causes a fatal error otherwise.)\n\np   A pointer to a null-terminated string.\nP   A pointer to a structure (fixed-length string).\n\nu   A uuencoded string.\nU   A Unicode character number.  Encodes to a character in character mode\n    and UTF-8 (or UTF-EBCDIC in EBCDIC platforms) in byte mode.\n\nw   A BER compressed integer (not an ASN.1 BER, see perlpacktut for\n    details).  Its bytes represent an unsigned integer in base 128,\n    most significant digit first, with as few digits as possible.  Bit\n    eight (the high bit) is set on each byte except the last.\n\nx   A null byte.\nX   Back up a byte.\n@   Null fill or truncate to absolute position, counted from the\n    start of the innermost ()-group.\n.   Null fill or truncate to absolute position specified by value.\n(   Start of a ()-group. One or more of the modifiers below may optionally follow some letters in the TEMPLATE (the second column lists the letters for which the modifier is valid): !   sSlLiI     Forces native (short, long, int) sizes instead\n               of fixed (16-\/32-bit) sizes.\n\n    xX         Make x and X act as alignment commands.\n\n    nNvV       Treat integers as signed instead of unsigned.\n\n    @.         Specify position as byte offset in the internal\n               representation of the packed string. Efficient but\n               dangerous.\n\n>   sSiIlLqQ   Force big-endian byte-order on the type.\n    jJfFdDpP   (The \"big end\" touches the construct.)\n\n<   sSiIlLqQ   Force little-endian byte-order on the type.\n    jJfFdDpP   (The \"little end\" touches the construct.) The \">\" and \"<\" modifiers can also be used on \"()\"-groups, in which case they force a certain byte-order on all components of that group, including subgroups. The following rules apply: \u2022 Each letter may optionally be followed by a number giving a repeat count. With all types except \"a\", \"A\", \"Z\", \"b\", \"B\", \"h\", \"H\", \"@\", \".\", \"x\", \"X\" and \"P\" the pack function will gobble up that many values from the LIST . A \"*\" for the repeat count means to use however many items are left, except for \"@\", \"x\", \"X\", where it is equivalent to 0, for <.> where it means relative to string start and \"u\", where it is equivalent to 1 (or 45, which is the same). A numeric repeat count may optionally be enclosed in brackets, as in \"pack 'C[80]', @arr\". One can replace the numeric repeat count by a template enclosed in brackets; then the packed length of this template in bytes is used as a count. For example, \"x[L]\" skips a long (it skips the number of bytes in a long); the template \"$t X[$t] $t\" unpack()s twice what $t unpacks. If the template in brackets contains alignment commands (such as \"x![d]\"), its packed length is calculated as if the start of the template has the maximal possible alignment. When used with \"Z\", \"*\" results in the addition of a trailing null byte (so the packed result will be one longer than the byte \"length\" of the item). When used with \"@\", the repeat count represents an offset from the start of the innermost () group. When used with \".\", the repeat count is used to determine the starting position from where the value offset is calculated. If the repeat count is 0, it's relative to the current position. If the repeat count is \"*\", the offset is relative to the start of the packed string. And if its an integer \"n\" the offset is relative to the start of the n-th innermost () group (or the start of the string if \"n\" is bigger then the group level). The repeat count for \"u\" is interpreted as the maximal number of bytes to encode per line of output, with 0, 1 and 2 replaced by 45. The repeat count should not be more than 65. \u2022 The \"a\", \"A\", and \"Z\" types gobble just one value, but pack it as a string of length count, padding with nulls or spaces as necessary. When unpacking, \"A\" strips trailing whitespace and nulls, \"Z\" strips everything after the first null, and \"a\" returns data verbatim. If the value-to-pack is too long, it is truncated. If too long and an explicit count is provided, \"Z\" packs only \"$count-1\" bytes, followed by a null byte. Thus \"Z\" always packs a trailing null (except when the count is 0). \u2022 Likewise, the \"b\" and \"B\" fields pack a string that many bits long. Each character of the input field of pack() generates 1 bit of the result. Each result bit is based on the least-significant bit of the corresponding input character, i.e., on \"ord($char)%2\". In particular, characters \"0\" and \"1\" generate bits 0 and 1, as do characters \"\\0\" and \"\\1\". Starting from the beginning of the input string of pack(), each 8-tuple of characters is converted to 1 character of output. With format \"b\" the first character of the 8-tuple determines the least-significant bit of a character, and with format \"B\" it determines the most-significant bit of a character. If the length of the input string is not exactly divisible by 8, the remainder is packed as if the input string were padded by null characters at the end. Similarly, during unpack()ing the \"extra\" bits are ignored. If the input string of pack() is longer than needed, extra characters are ignored. A \"*\" for the repeat count of pack() means to use all the characters of the input field. On unpack()ing the bits are converted to a string of \"0\"s and \"1\"s. \u2022 The \"h\" and \"H\" fields pack a string that many nybbles (4-bit groups, representable as hexadecimal digits, 0-9a-f) long. Each character of the input field of pack() generates 4 bits of the result. For non-alphabetical characters the result is based on the 4 least-significant bits of the input character, i.e., on \"ord($char)%16\". In particular, characters \"0\" and \"1\" generate nybbles 0 and 1, as do bytes \"\\0\" and \"\\1\". For characters \"a\"..\"f\" and \"A\"..\"F\" the result is compatible with the usual hexadecimal digits, so that \"a\" and \"A\" both generate the nybble \"0xa==10\". The result for characters \"g\"..\"z\" and \"G\"..\"Z\" is not well-defined. Starting from the beginning of the input string of pack(), each pair of characters is converted to 1 character of output. With format \"h\" the first character of the pair determines the least-significant nybble of the output character, and with format \"H\" it determines the most-significant nybble. If the length of the input string is not even, it behaves as if padded by a null character at the end. Similarly, during unpack()ing the \"extra\" nybbles are ignored. If the input string of pack() is longer than needed, extra characters are ignored. A \"*\" for the repeat count of pack() means to use all the characters of the input field. On unpack()ing the nybbles are converted to a string of hexadecimal digits. \u2022 The \"p\" type packs a pointer to a null-terminated string. You are responsible for ensuring the string is not a temporary value (which can potentially get deallocated before you get around to using the packed result). The \"P\" type packs a pointer to a structure of the size indicated by the length. A NULL pointer is created if the corresponding value for \"p\" or \"P\" is \"undef\", similarly for unpack(). If your system has a strange pointer size (i.e. a pointer is neither as big as an int nor as big as a long), it may not be possible to pack or unpack pointers in big- or little-endian byte order. Attempting to do so will result in a fatal error. \u2022 The \"\/\" template character allows packing and unpacking of a sequence of items where the packed structure contains a packed item count followed by the packed items themselves. For \"pack\" you write length-item \"\/\" sequence-item and the length-item describes how the length value is packed. The ones likely to be of most use are integer-packing ones like \"n\" (for Java strings), \"w\" (for ASN .1 or SNMP ) and \"N\" (for Sun XDR ). For \"pack\", the sequence-item may have a repeat count, in which case the minimum of that and the number of available items is used as argument for the length-item. If it has no repeat count or uses a '*', the number of available items is used. For \"unpack\" an internal stack of integer arguments unpacked so far is used. You write \"\/\"sequence-item and the repeat count is obtained by popping off the last element from the stack. The sequence-item must not have a repeat count. If the sequence-item refers to a string type (\"A\", \"a\" or \"Z\"), the length-item is a string length, not a number of strings. If there is an explicit repeat count for pack, the packed string will be adjusted to that given length. unpack 'W\/a', \"\\04Gurusamy\";            gives ('Guru')\nunpack 'a3\/A A*', '007 Bond  J ';       gives (' Bond', 'J')\nunpack 'a3 x2 \/A A*', '007: Bond, J.';  gives ('Bond, J', '.')\npack 'n\/a* w\/a','hello,','world';       gives \"\\000\\006hello,\\005world\"\npack 'a\/W2', ord('a') .. ord('z');      gives '2ab' The length-item is not returned explicitly from \"unpack\". Adding a count to the length-item letter is unlikely to do anything useful, unless that letter is \"A\", \"a\" or \"Z\". Packing with a length-item of \"a\" or \"Z\" may introduce \"\\000\" characters, which Perl does not regard as legal in numeric strings. \u2022 The integer types \"s\", \"S\", \"l\", and \"L\" may be followed by a \"!\" modifier to signify native shorts or longs--as you can see from above for example a bare \"l\" does mean exactly 32 bits, the native \"long\" (as seen by the local C compiler) may be larger. This is an issue mainly in 64-bit platforms. You can see whether using \"!\" makes any difference by print length(pack(\"s\")), \" \", length(pack(\"s!\")), \"\\n\";\nprint length(pack(\"l\")), \" \", length(pack(\"l!\")), \"\\n\"; \"i!\" and \"I!\" also work but only because of completeness; they are identical to \"i\" and \"I\". The actual sizes (in bytes) of native shorts, ints, longs, and long longs on the platform where Perl was built are also available via Config: use Config;\nprint $Config{shortsize},    \"\\n\";\nprint $Config{intsize},      \"\\n\";\nprint $Config{longsize},     \"\\n\";\nprint $Config{longlongsize}, \"\\n\"; (The $Config{longlongsize} will be undefined if your system does not support long longs.) \u2022 The integer formats \"s\", \"S\", \"i\", \"I\", \"l\", \"L\", \"j\", and \"J\" are inherently non-portable between processors and operating systems because they obey the native byteorder and endianness. For example a 4-byte integer 0x12345678 (305419896 decimal) would be ordered natively (arranged in and handled by the CPU registers) into bytes as 0x12 0x34 0x56 0x78     # big-endian\n0x78 0x56 0x34 0x12     # little-endian Basically, the Intel and VAX CPUs are little-endian, while everybody else, for example Motorola m68k\/88k, PPC , Sparc, HP PA , Power, and Cray are big-endian. Alpha and MIPS can be either: Digital\/Compaq used\/uses them in little-endian mode; SGI\/Cray uses them in big-endian mode. The names 'big-endian' and 'little-endian' are comic references to the classic \"Gulliver's Travels\" (via the paper \"On Holy Wars and a Plea for Peace\" by Danny Cohen, USC\/ISI IEN 137, April 1, 1980) and the egg-eating habits of the Lilliputians. Some systems may have even weirder byte orders such as 0x56 0x78 0x12 0x34\n0x34 0x12 0x78 0x56 You can see your system's preference with print join(\" \", map { sprintf \"%#02x\", $_ }\n                    unpack(\"W*\",pack(\"L\",0x12345678))), \"\\n\"; The byteorder on the platform where Perl was built is also available via Config: use Config;\nprint $Config{byteorder}, \"\\n\"; Byteorders '1234' and '12345678' are little-endian, '4321' and '87654321' are big-endian. If you want portable packed integers you can either use the formats \"n\", \"N\", \"v\", and \"V\", or you can use the \">\" and \"<\" modifiers. These modifiers are only available as of perl 5.9.2. See also perlport. \u2022 All integer and floating point formats as well as \"p\" and \"P\" and \"()\"-groups may be followed by the \">\" or \"<\" modifiers to force big- or little- endian byte-order, respectively. This is especially useful, since \"n\", \"N\", \"v\" and \"V\" don't cover signed integers, 64-bit integers and floating point values. However, there are some things to keep in mind. Exchanging signed integers between different platforms only works if all platforms store them in the same format. Most platforms store signed integers in two's complement, so usually this is not an issue. The \">\" or \"<\" modifiers can only be used on floating point formats on big- or little-endian machines. Otherwise, attempting to do so will result in a fatal error. Forcing big- or little-endian byte-order on floating point values for data exchange can only work if all platforms are using the same binary representation (e.g. IEEE floating point format). Even if all platforms are using IEEE , there may be subtle differences. Being able to use \">\" or \"<\" on floating point values can be very useful, but also very dangerous if you don't know exactly what you're doing. It is definitely not a general way to portably store floating point values. When using \">\" or \"<\" on an \"()\"-group, this will affect all types inside the group that accept the byte-order modifiers, including all subgroups. It will silently be ignored for all other types. You are not allowed to override the byte-order within a group that already has a byte-order modifier suffix. \u2022 Real numbers (floats and doubles) are in the native machine format only; due to the multiplicity of floating formats around, and the lack of a standard \"network\" representation, no facility for interchange has been made. This means that packed floating point data written on one machine may not be readable on another - even if both use IEEE floating point arithmetic (as the endian-ness of the memory representation is not part of the IEEE spec). See also perlport. If you know exactly what you're doing, you can use the \">\" or \"<\" modifiers to force big- or little-endian byte-order on floating point values. Note that Perl uses doubles (or long doubles, if configured) internally for all numeric calculation, and converting from double into float and thence back to double again will lose precision (i.e., \"unpack(\"f\", pack(\"f\", $foo)\") will not in general equal $foo). \u2022 Pack and unpack can operate in two modes, character mode ( \"C0\" mode) where the packed string is processed per character and UTF-8 mode ( \"U0\" mode) where the packed string is processed in its UTF-8-encoded Unicode form on a byte by byte basis. Character mode is the default unless the format string starts with an \"U\". You can switch mode at any moment with an explicit \"C0\" or \"U0\" in the format. A mode is in effect until the next mode switch or until the end of the ()-group in which it was entered. \u2022 You must yourself do any alignment or padding by inserting for example enough 'x'es while packing. There is no way to pack() and unpack() could know where the characters are going to or coming from. Therefore \"pack\" (and \"unpack\") handle their output and input as flat sequences of characters. \u2022 A ()-group is a sub-TEMPLATE enclosed in parentheses. A group may take a repeat count, both as postfix, and for unpack() also via the \"\/\" template character. Within each repetition of a group, positioning with \"@\" starts again at 0. Therefore, the result of pack( '@1A((@2A)@3A)', 'a', 'b', 'c' ) is the string \"\\0a\\0\\0bc\". \u2022 \"x\" and \"X\" accept \"!\" modifier. In this case they act as alignment commands: they jump forward\/back to the closest position aligned at a multiple of \"count\" characters. For example, to pack() or unpack() C's \"struct {char c; double d; char cc[2]}\" one may need to use the template \"W x![d] d W[2]\"; this assumes that doubles must be aligned on the double's size. For alignment commands \"count\" of 0 is equivalent to \"count\" of 1; both result in no-ops. \u2022 \"n\", \"N\", \"v\" and \"V\" accept the \"!\" modifier. In this case they will represent signed 16-\/32-bit integers in big-\/little-endian order. This is only portable if all platforms sharing the packed data use the same binary representation for signed integers (e.g. all platforms are using two's complement representation). \u2022 A comment in a TEMPLATE starts with \"#\" and goes to the end of line. White space may be used to separate pack codes from each other, but modifiers and a repeat count must follow immediately. \u2022 If TEMPLATE requires more arguments to pack() than actually given, pack() assumes additional \"\" arguments. If TEMPLATE requires fewer arguments to pack() than actually given, extra arguments are ignored. Examples: $foo = pack(\"WWWW\",65,66,67,68);\n# foo eq \"ABCD\"\n$foo = pack(\"W4\",65,66,67,68);\n# same thing\n$foo = pack(\"W4\",0x24b6,0x24b7,0x24b8,0x24b9);\n# same thing with Unicode circled letters.\n$foo = pack(\"U4\",0x24b6,0x24b7,0x24b8,0x24b9);\n# same thing with Unicode circled letters. You don't get the UTF-8\n# bytes because the U at the start of the format caused a switch to\n# U0-mode, so the UTF-8 bytes get joined into characters\n$foo = pack(\"C0U4\",0x24b6,0x24b7,0x24b8,0x24b9);\n# foo eq \"\\xe2\\x92\\xb6\\xe2\\x92\\xb7\\xe2\\x92\\xb8\\xe2\\x92\\xb9\"\n# This is the UTF-8 encoding of the string in the previous example\n\n$foo = pack(\"ccxxcc\",65,66,67,68);\n# foo eq \"AB\\0\\0CD\"\n\n# note: the above examples featuring \"W\" and \"c\" are true\n# only on ASCII and ASCII-derived systems such as ISO Latin 1\n# and UTF-8.  In EBCDIC the first example would be\n# $foo = pack(\"WWWW\",193,194,195,196);\n\n$foo = pack(\"s2\",1,2);\n# \"\\1\\0\\2\\0\" on little-endian\n# \"\\0\\1\\0\\2\" on big-endian\n\n$foo = pack(\"a4\",\"abcd\",\"x\",\"y\",\"z\");\n# \"abcd\"\n\n$foo = pack(\"aaaa\",\"abcd\",\"x\",\"y\",\"z\");\n# \"axyz\"\n\n$foo = pack(\"a14\",\"abcdefg\");\n# \"abcdefg\\0\\0\\0\\0\\0\\0\\0\"\n\n$foo = pack(\"i9pl\", gmtime);\n# a real struct tm (on my system anyway)\n\n$utmp_template = \"Z8 Z8 Z16 L\";\n$utmp = pack($utmp_template, @utmp1);\n# a struct utmp (BSDish)\n\n@utmp2 = unpack($utmp_template, $utmp);\n# \"@utmp1\" eq \"@utmp2\"\n\nsub bintodec {\n    unpack(\"N\", pack(\"B32\", substr(\"0\" x 32 . shift, -32)));\n}\n\n$foo = pack('sx2l', 12, 34);\n# short 12, two zero bytes padding, long 34\n$bar = pack('s@4l', 12, 34);\n# short 12, zero fill to position 4, long 34\n# $foo eq $bar\n$baz = pack('s.l', 12, 4, 34);\n# short 12, zero fill to position 4, long 34\n\n$foo = pack('nN', 42, 4711);\n# pack big-endian 16- and 32-bit unsigned integers\n$foo = pack('S>L>', 42, 4711);\n# exactly the same\n$foo = pack('s<l<', -42, 4711);\n# pack little-endian 16- and 32-bit signed integers\n$foo = pack('(sl)<', -42, 4711);\n# exactly the same The same template may generally also be used in unpack(). package NAMESPACE package Declares the compilation unit as being in the given namespace. The scope of the package declaration is from the declaration itself through the end of the enclosing block, file, or eval (the same as the \"my\" operator). All further unqualified dynamic identifiers will be in this namespace. A package statement affects only dynamic variables--including those you've used \"local\" on--but not lexical variables, which are created with \"my\". Typically it would be the first declaration in a file to be included by the \"require\" or \"use\" operator. You can switch into a package in more than one place; it merely influences which symbol table is used by the compiler for the rest of that block. You can refer to variables and filehandles in other packages by prefixing the identifier with the package name and a double colon: $Package::Variable. If the package name is null, the \"main\" package as assumed. That is, $::sail is equivalent to $main::sail (as well as to \"$main'sail\", still seen in older code). See \"Packages\" in perlmod for more information about packages, modules, and classes. See perlsub for other scoping issues. pipe READHANDLE ,WRITEHANDLE Opens a pair of connected pipes like the corresponding system call. Note that if you set up a loop of piped processes, deadlock can occur unless you are very careful. In addition, note that Perl's pipes use IO buffering, so you may need to set $| to flush your WRITEHANDLE after each command, depending on the application. See IPC::Open2, IPC::Open3, and \"Bidirectional Communication\" in perlipc for examples of such things. On systems that support a close-on-exec flag on files, the flag will be set for the newly opened file descriptors as determined by the value of $^F. See \"$^F\" in perlvar. pop ARRAY pop Pops and returns the last value of the array, shortening the array by one element. If there are no elements in the array, returns the undefined value (although this may happen at other times as well). If ARRAY is omitted, pops the @ARGV array in the main program, and the @_ array in subroutines, just like \"shift\". pos SCALAR pos Returns the offset of where the last \"m\/\/g\" search left off for the variable in question ($_ is used when the variable is not specified). Note that 0 is a valid match offset. \"undef\" indicates that the search position is reset (usually due to match failure, but can also be because no match has yet been performed on the scalar). \"pos\" directly accesses the location used by the regexp engine to store the offset, so assigning to \"pos\" will change that offset, and so will also influence the \"\\G\" zero-width assertion in regular expressions. Because a failed \"m\/\/gc\" match doesn't reset the offset, the return from \"pos\" won't change either in this case. See perlre and perlop. print FILEHANDLE LIST print LIST print Prints a string or a list of strings. Returns true if successful. FILEHANDLE may be a scalar variable name, in which case the variable contains the name of or a reference to the filehandle, thus introducing one level of indirection. ( NOTE: If FILEHANDLE is a variable and the next token is a term, it may be misinterpreted as an operator unless you interpose a \"+\" or put parentheses around the arguments.) If FILEHANDLE is omitted, prints by default to standard output (or to the last selected output channel--see \"select\"). If LIST is also omitted, prints $_ to the currently selected output channel. To set the default output channel to something other than STDOUT use the select operation. The current value of $, (if any) is printed between each LIST item. The current value of \"$\\\" (if any) is printed after the entire LIST has been printed. Because print takes a LIST , anything in the LIST is evaluated in list context, and any subroutine that you call will have one or more of its expressions evaluated in list context. Also be careful not to follow the print keyword with a left parenthesis unless you want the corresponding right parenthesis to terminate the arguments to the print--interpose a \"+\" or put parentheses around all the arguments. Note that if you're storing FILEHANDLEs in an array, or if you're using any other expression more complex than a scalar variable to retrieve it, you will have to use a block returning the filehandle value instead: print { $files[$i] } \"stuff\\n\";\nprint { $OK ? STDOUT : STDERR } \"stuff\\n\"; printf FILEHANDLE FORMAT , LIST printf FORMAT , LIST Equivalent to \"print FILEHANDLE sprintf(FORMAT, LIST)\", except that \"$\\\" (the output record separator) is not appended. The first argument of the list will be interpreted as the \"printf\" format. See \"sprintf\" for an explanation of the format argument. If \"use locale\" is in effect, and POSIX::setlocale() has been called, the character used for the decimal separator in formatted floating point numbers is affected by the LC_NUMERIC locale. See perllocale and POSIX . Don't fall into the trap of using a \"printf\" when a simple \"print\" would do. The \"print\" is more efficient and less error prone. prototype FUNCTION Returns the prototype of a function as a string (or \"undef\" if the function has no prototype). FUNCTION is a reference to, or the name of, the function whose prototype you want to retrieve. If FUNCTION is a string starting with \"CORE::\", the rest is taken as a name for Perl builtin. If the builtin is not overridable (such as \"qw\/\/\") or if its arguments cannot be adequately expressed by a prototype (such as \"system\"), prototype() returns \"undef\", because the builtin does not really behave like a Perl function. Otherwise, the string describing the equivalent prototype is returned. push ARRAY ,LIST Treats ARRAY as a stack, and pushes the values of LIST onto the end of ARRAY . The length of ARRAY increases by the length of LIST . Has the same effect as for $value (LIST) {\n    $ARRAY[++$#ARRAY] = $value;\n} but is more efficient. Returns the number of elements in the array following the completed \"push\". q\/STRING\/ qq\/STRING\/ qx\/STRING\/ qw\/STRING\/ Generalized quotes. See \"Quote-Like Operators\" in perlop. qr\/STRING\/ Regexp-like quote. See \"Regexp Quote-Like Operators\" in perlop. quotemeta EXPR quotemeta Returns the value of EXPR with all non-\"word\" characters backslashed. (That is, all characters not matching \"\/[A-Za-z_0-9]\/\" will be preceded by a backslash in the returned string, regardless of any locale settings.) This is the internal function implementing the \"\\Q\" escape in double-quoted strings. If EXPR is omitted, uses $_. rand EXPR rand Returns a random fractional number greater than or equal to 0 and less than the value of EXPR . ( EXPR should be positive.) If EXPR is omitted, the value 1 is used. Currently EXPR with the value 0 is also special-cased as 1 - this has not been documented before perl 5.8.0 and is subject to change in future versions of perl. Automatically calls \"srand\" unless \"srand\" has already been called. See also \"srand\". Apply \"int()\" to the value returned by \"rand()\" if you want random integers instead of random fractional numbers. For example, int(rand(10)) returns a random integer between 0 and 9, inclusive. (Note: If your rand function consistently returns numbers that are too large or too small, then your version of Perl was probably compiled with the wrong number of RANDBITS .) read FILEHANDLE ,SCALAR,LENGTH,OFFSET read FILEHANDLE ,SCALAR,LENGTH Attempts to read LENGTH characters of data into variable SCALAR from the specified FILEHANDLE . Returns the number of characters actually read, 0 at end of file, or undef if there was an error (in the latter case $! is also set). SCALAR will be grown or shrunk so that the last character actually read is the last character of the scalar after the read. An OFFSET may be specified to place the read data at some place in the string other than the beginning. A negative OFFSET specifies placement at that many characters counting backwards from the end of the string. A positive OFFSET greater than the length of SCALAR results in the string being padded to the required size with \"\\0\" bytes before the result of the read is appended. The call is actually implemented in terms of either Perl's or system's fread() call. To get a true read(2) system call, see \"sysread\". Note the characters: depending on the status of the filehandle, either (8-bit) bytes or characters are read. By default all filehandles operate on bytes, but for example if the filehandle has been opened with the \":utf8\" I\/O layer (see \"open\", and the \"open\" pragma, open), the I\/O will operate on UTF-8 encoded Unicode characters, not bytes. Similarly for the \":encoding\" pragma: in that case pretty much any characters can be read. readdir DIRHANDLE Returns the next directory entry for a directory opened by \"opendir\". If used in list context, returns all the rest of the entries in the directory. If there are no more entries, returns an undefined value in scalar context or a null list in list context. If you're planning to filetest the return values out of a \"readdir\", you'd better prepend the directory in question. Otherwise, because we didn't \"chdir\" there, it would have been testing the wrong file. opendir(my $dh, $some_dir) || die \"can't opendir $some_dir: $!\";\n@dots = grep { \/^\\.\/ && -f \"$some_dir\/$_\" } readdir($dh);\nclosedir $dh; readline EXPR readline Reads from the filehandle whose typeglob is contained in EXPR (or from *ARGV if EXPR is not provided). In scalar context, each call reads and returns the next line, until end-of-file is reached, whereupon the subsequent call returns undef. In list context, reads until end-of-file is reached and returns a list of lines. Note that the notion of \"line\" used here is however you may have defined it with $\/ or $INPUT_RECORD_SEPARATOR). See \"$\/\" in perlvar. When $\/ is set to \"undef\", when readline() is in scalar context (i.e. file slurp mode), and when an empty file is read, it returns '' the first time, followed by \"undef\" subsequently. This is the internal function implementing the \"<EXPR>\" operator, but you can use it directly. The \"<EXPR>\" operator is discussed in more detail in \"I\/O Operators\" in perlop. $line = <STDIN>;\n$line = readline(*STDIN);           # same thing If readline encounters an operating system error, $! will be set with the corresponding error message. It can be helpful to check $! when you are reading from filehandles you don't trust, such as a tty or a socket. The following example uses the operator form of \"readline\", and takes the necessary steps to ensure that \"readline\" was successful. for (;;) {\n    undef $!;\n    unless (defined( $line = <> )) {\n        last if eof;\n        die $! if $!;\n    }\n    # ...\n} readlink EXPR readlink Returns the value of a symbolic link, if symbolic links are implemented. If not, gives a fatal error. If there is some system error, returns the undefined value and sets $! (errno). If EXPR is omitted, uses $_. readpipe EXPR readpipe EXPR is executed as a system command. The collected standard output of the command is returned. In scalar context, it comes back as a single (potentially multi-line) string. In list context, returns a list of lines (however you've defined lines with $\/ or $INPUT_RECORD_SEPARATOR). This is the internal function implementing the \"qx\/EXPR\/\" operator, but you can use it directly. The \"qx\/EXPR\/\" operator is discussed in more detail in \"I\/O Operators\" in perlop. If EXPR is omitted, uses $_. recv SOCKET ,SCALAR,LENGTH,FLAGS Receives a message on a socket. Attempts to receive LENGTH characters of data into variable SCALAR from the specified SOCKET filehandle. SCALAR will be grown or shrunk to the length actually read. Takes the same flags as the system call of the same name. Returns the address of the sender if SOCKET 's protocol supports this; returns an empty string otherwise. If there's an error, returns the undefined value. This call is actually implemented in terms of recvfrom(2) system call. See \" UDP: Message Passing\" in perlipc for examples. Note the characters: depending on the status of the socket, either (8-bit) bytes or characters are received. By default all sockets operate on bytes, but for example if the socket has been changed using binmode() to operate with the \":encoding(utf8)\" I\/O layer (see the \"open\" pragma, open), the I\/O will operate on UTF-8 encoded Unicode characters, not bytes. Similarly for the \":encoding\" pragma: in that case pretty much any characters can be read. redo LABEL redo The \"redo\" command restarts the loop block without evaluating the conditional again. The \"continue\" block, if any, is not executed. If the LABEL is omitted, the command refers to the innermost enclosing loop. Programs that want to lie to themselves about what was just input normally use this command: # a simpleminded Pascal comment stripper\n# (warning: assumes no { or } in strings)\nLINE: while (<STDIN>) {\n    while (s|({.*}.*){.*}|$1 |) {}\n    s|{.*}| |;\n    if (s|{.*| |) {\n        $front = $_;\n        while (<STDIN>) {\n            if (\/}\/) {      # end of comment?\n                s|^|$front\\{|;\n                redo LINE;\n            }\n        }\n    }\n    print;\n} \"redo\" cannot be used to retry a block which returns a value such as \"eval {}\", \"sub {}\" or \"do {}\", and should not be used to exit a grep() or map() operation. Note that a block by itself is semantically identical to a loop that executes once. Thus \"redo\" inside such a block will effectively turn it into a looping construct. See also \"continue\" for an illustration of how \"last\", \"next\", and \"redo\" work. ref EXPR ref Returns a non-empty string if EXPR is a reference, the empty string otherwise. If EXPR is not specified, $_ will be used. The value returned depends on the type of thing the reference is a reference to. Builtin types include: SCALAR\nARRAY\nHASH\nCODE\nREF\nGLOB\nLVALUE\nFORMAT\nIO\nVSTRING\nRegexp If the referenced object has been blessed into a package, then that package name is returned instead. You can think of \"ref\" as a \"typeof\" operator. if (ref($r) eq \"HASH\") {\n    print \"r is a reference to a hash.\\n\";\n}\nunless (ref($r)) {\n    print \"r is not a reference at all.\\n\";\n} The return value \"LVALUE\" indicates a reference to an lvalue that is not a variable. You get this from taking the reference of function calls like \"pos()\" or \"substr()\". \"VSTRING\" is returned if the reference points to a version string. The result \"Regexp\" indicates that the argument is a regular expression resulting from \"qr\/\/\". See also perlref. rename OLDNAME ,NEWNAME Changes the name of a file; an existing file NEWNAME will be clobbered. Returns true for success, false otherwise. Behavior of this function varies wildly depending on your system implementation. For example, it will usually not work across file system boundaries, even though the system mv command sometimes compensates for this. Other restrictions include whether it works on directories, open files, or pre-existing files. Check perlport and either the rename(2) manpage or equivalent system documentation for details. For a platform independent \"move\" function look at the File::Copy module. require VERSION require EXPR require Demands a version of Perl specified by VERSION , or demands some semantics specified by EXPR or by $_ if EXPR is not supplied. VERSION may be either a numeric argument such as 5.006, which will be compared to $], or a literal of the form v5.6.1, which will be compared to $^V (aka $PERL_VERSION). A fatal error is produced at run time if VERSION is greater than the version of the current Perl interpreter. Compare with \"use\", which can do a similar check at compile time. Specifying VERSION as a literal of the form v5.6.1 should generally be avoided, because it leads to misleading error messages under earlier versions of Perl that do not support this syntax. The equivalent numeric version should be used instead. require v5.6.1;     # run time version check\nrequire 5.6.1;      # ditto\nrequire 5.006_001;  # ditto; preferred for backwards compatibility Otherwise, \"require\" demands that a library file be included if it hasn't already been included. The file is included via the do-FILE mechanism, which is essentially just a variety of \"eval\" with the caveat that lexical variables in the invoking script will be invisible to the included code. Has semantics similar to the following subroutine: sub require {\n   my ($filename) = @_;\n   if (exists $INC{$filename}) {\n       return 1 if $INC{$filename};\n       die \"Compilation failed in require\";\n   }\n   my ($realfilename,$result);\n   ITER: {\n       foreach $prefix (@INC) {\n           $realfilename = \"$prefix\/$filename\";\n           if (-f $realfilename) {\n               $INC{$filename} = $realfilename;\n               $result = do $realfilename;\n               last ITER;\n           }\n       }\n       die \"Can't find $filename in \\@INC\";\n   }\n   if ($@) {\n       $INC{$filename} = undef;\n       die $@;\n   } elsif (!$result) {\n       delete $INC{$filename};\n       die \"$filename did not return true value\";\n   } else {\n       return $result;\n   }\n} Note that the file will not be included twice under the same specified name. The file must return true as the last statement to indicate successful execution of any initialization code, so it's customary to end such a file with \"1;\" unless you're sure it'll return true otherwise. But it's better just to put the \"1;\", in case you add more statements. If EXPR is a bareword, the require assumes a \".pm\" extension and replaces \"::\" with \"\/\" in the filename for you, to make it easy to load standard modules. This form of loading of modules does not risk altering your namespace. In other words, if you try this: require Foo::Bar;    # a splendid bareword The require function will actually look for the \" Foo\/Bar.pm\" file in the directories specified in the @INC array. But if you try this:     $class = 'Foo::Bar';\n    require $class;      # $class is not a bareword\n#or\n    require \"Foo::Bar\";  # not a bareword because of the \"\" The require function will look for the \" Foo::Bar\" file in the @INC array and will complain about not finding \" Foo::Bar\" there. In this case you can do: eval \"require $class\"; Now that you understand how \"require\" looks for files in the case of a bareword argument, there is a little extra functionality going on behind the scenes. Before \"require\" looks for a \" .pm\" extension, it will first look for a similar filename with a \" .pmc\" extension. If this file is found, it will be loaded in place of any file ending in a \" .pm\" extension. You can also insert hooks into the import facility, by putting directly Perl code into the @INC array. There are three forms of hooks: subroutine references, array references and blessed objects. Subroutine references are the simplest case. When the inclusion system walks through @INC and encounters a subroutine, this subroutine gets called with two parameters, the first being a reference to itself, and the second the name of the file to be included (e.g. \"Foo\/Bar.pm\"). The subroutine should return nothing, or a list of up to three values in the following order: 1. A filehandle, from which the file will be read. 2. A reference to a subroutine. If there is no filehandle (previous item), then this subroutine is expected to generate one line of source code per call, writing the line into $_ and returning 1, then returning 0 at \"end of file\". If there is a filehandle, then the subroutine will be called to act as a simple source filter, with the line as read in $_. Again, return 1 for each valid line, and 0 after all lines have been returned. 3. Optional state for the subroutine. The state is passed in as $_[1]. A reference to the subroutine itself is passed in as $_[0]. If an empty list, \"undef\", or nothing that matches the first 3 values above is returned then \"require\" will look at the remaining elements of @INC. Note that this file handle must be a real file handle (strictly a typeglob, or reference to a typeglob, blessed or unblessed) - tied file handles will be ignored and return value processing will stop there. If the hook is an array reference, its first element must be a subroutine reference. This subroutine is called as above, but the first parameter is the array reference. This enables to pass indirectly some arguments to the subroutine. In other words, you can write: push @INC, \\&my_sub;\nsub my_sub {\n    my ($coderef, $filename) = @_;  # $coderef is \\&my_sub\n    ...\n} or: push @INC, [ \\&my_sub, $x, $y, ... ];\nsub my_sub {\n    my ($arrayref, $filename) = @_;\n    # Retrieve $x, $y, ...\n    my @parameters = @$arrayref[1..$#$arrayref];\n    ...\n} If the hook is an object, it must provide an INC method that will be called as above, the first parameter being the object itself. (Note that you must fully qualify the sub's name, as unqualified \"INC\" is always forced into package \"main\".) Here is a typical code layout: # In Foo.pm\npackage Foo;\nsub new { ... }\nsub Foo::INC {\n    my ($self, $filename) = @_;\n    ...\n}\n\n# In the main program\npush @INC, Foo->new(...); Note that these hooks are also permitted to set the %INC entry corresponding to the files they have loaded. See \"%INC\" in perlvar. For a yet-more-powerful import facility, see \"use\" and perlmod. reset EXPR reset Generally used in a \"continue\" block at the end of a loop to clear variables and reset \"??\" searches so that they work again. The expression is interpreted as a list of single characters (hyphens allowed for ranges). All variables and arrays beginning with one of those letters are reset to their pristine state. If the expression is omitted, one-match searches (\"?pattern?\") are reset to match again. Resets only variables or searches in the current package. Always returns 1. Examples: reset 'X';          # reset all X variables\nreset 'a-z';        # reset lower case variables\nreset;              # just reset ?one-time? searches Resetting \"A-Z\" is not recommended because you'll wipe out your @ARGV and @INC arrays and your %ENV hash. Resets only package variables--lexical variables are unaffected, but they clean themselves up on scope exit anyway, so you'll probably want to use them instead. See \"my\". return EXPR return Returns from a subroutine, \"eval\", or \"do FILE\" with the value given in EXPR . Evaluation of EXPR may be in list, scalar, or void context, depending on how the return value will be used, and the context may vary from one execution to the next (see \"wantarray\"). If no EXPR is given, returns an empty list in list context, the undefined value in scalar context, and (of course) nothing at all in a void context. (Note that in the absence of an explicit \"return\", a subroutine, eval, or do FILE will automatically return the value of the last expression evaluated.) reverse LIST In list context, returns a list value consisting of the elements of LIST in the opposite order. In scalar context, concatenates the elements of LIST and returns a string value with all characters in the opposite order. print join(\", \", reverse \"world\", \"Hello\"); # Hello, world\n\nprint scalar reverse \"dlrow ,\", \"olleH\";    # Hello, world Used without arguments in scalar context, reverse() reverses $_. $_ = \"dlrow ,olleH\";\nprint reverse;                              # No output, list context\nprint scalar reverse;                       # Hello, world This operator is also handy for inverting a hash, although there are some caveats. If a value is duplicated in the original hash, only one of those can be represented as a key in the inverted hash. Also, this has to unwind one hash and build a whole new one, which may take some time on a large hash, such as from a DBM file. %by_name = reverse %by_address;     # Invert the hash rewinddir DIRHANDLE Sets the current position to the beginning of the directory for the \"readdir\" routine on DIRHANDLE . rindex STR ,SUBSTR,POSITION rindex STR ,SUBSTR Works just like index() except that it returns the position of the last occurrence of SUBSTR in STR . If POSITION is specified, returns the last occurrence beginning at or before that position. rmdir FILENAME rmdir Deletes the directory specified by FILENAME if that directory is empty. If it succeeds it returns true, otherwise it returns false and sets $! (errno). If FILENAME is omitted, uses $_. To remove a directory tree recursively ( \"rm -rf\" on unix) look at the \"rmtree\" function of the File::Path module. s\/\/\/ The substitution operator. See \"Regexp Quote-Like Operators\" in perlop. say FILEHANDLE LIST say LIST say Just like \"print\", but implicitly appends a newline. \"say LIST\" is simply an abbreviation for \"{ local $\\ = \"\\n\"; print LIST }\". This keyword is only available when the \"say\" feature is enabled: see feature. scalar EXPR Forces EXPR to be interpreted in scalar context and returns the value of EXPR . @counts = ( scalar @a, scalar @b, scalar @c ); There is no equivalent operator to force an expression to be interpolated in list context because in practice, this is never needed. If you really wanted to do so, however, you could use the construction \"@{[ (some expression) ]}\", but usually a simple \"(some expression)\" suffices. Because \"scalar\" is unary operator, if you accidentally use for EXPR a parenthesized list, this behaves as a scalar comma expression, evaluating all but the last element in void context and returning the final element evaluated in scalar context. This is seldom what you want. The following single statement: print uc(scalar(&foo,$bar)),$baz; is the moral equivalent of these two: &foo;\nprint(uc($bar),$baz); See perlop for more details on unary operators and the comma operator. seek FILEHANDLE ,POSITION,WHENCE Sets FILEHANDLE 's position, just like the \"fseek\" call of \"stdio\". FILEHANDLE may be an expression whose value gives the name of the filehandle. The values for WHENCE are 0 to set the new position in bytes to POSITION , 1 to set it to the current position plus POSITION , and 2 to set it to EOF plus POSITION (typically negative). For WHENCE you may use the constants \"SEEK_SET\", \"SEEK_CUR\", and \"SEEK_END\" (start of the file, current position, end of the file) from the Fcntl module. Returns 1 upon success, 0 otherwise. Note the in bytes: even if the filehandle has been set to operate on characters (for example by using the \":encoding(utf8)\" open layer), tell() will return byte offsets, not character offsets (because implementing that would render seek() and tell() rather slow). If you want to position file for \"sysread\" or \"syswrite\", don't use \"seek\"--buffering makes its effect on the file's system position unpredictable and non-portable. Use \"sysseek\" instead. Due to the rules and rigors of ANSI C, on some systems you have to do a seek whenever you switch between reading and writing. Amongst other things, this may have the effect of calling stdio's clearerr(3). A WHENCE of 1 (\"SEEK_CUR\") is useful for not moving the file position: seek(TEST,0,1); This is also useful for applications emulating \"tail -f\". Once you hit EOF on your read, and then sleep for a while, you might have to stick in a seek() to reset things. The \"seek\" doesn't change the current position, but it does clear the end-of-file condition on the handle, so that the next \"<FILE>\" makes Perl try again to read something. We hope. If that doesn't work (some IO implementations are particularly cantankerous), then you may need something more like this: for (;;) {\n    for ($curpos = tell(FILE); $_ = <FILE>;\n         $curpos = tell(FILE)) {\n        # search for some stuff and put it into files\n    }\n    sleep($for_a_while);\n    seek(FILE, $curpos, 0);\n} seekdir DIRHANDLE ,POS Sets the current position for the \"readdir\" routine on DIRHANDLE . POS must be a value returned by \"telldir\". \"seekdir\" also has the same caveats about possible directory compaction as the corresponding system library routine. select FILEHANDLE select Returns the currently selected filehandle. If FILEHANDLE is supplied, sets the new current default filehandle for output. This has two effects: first, a \"write\" or a \"print\" without a filehandle will default to this FILEHANDLE . Second, references to variables related to output will refer to this output channel. For example, if you have to set the top of form format for more than one output channel, you might do the following: select(REPORT1);\n$^ = 'report1_top';\nselect(REPORT2);\n$^ = 'report2_top'; FILEHANDLE may be an expression whose value gives the name of the actual filehandle. Thus: $oldfh = select(STDERR); $| = 1; select($oldfh); Some programmers may prefer to think of filehandles as objects with methods, preferring to write the last example as: use IO::Handle;\nSTDERR->autoflush(1); select RBITS ,WBITS,EBITS,TIMEOUT This calls the select(2) system call with the bit masks specified, which can be constructed using \"fileno\" and \"vec\", along these lines: $rin = $win = $ein = '';\nvec($rin,fileno(STDIN),1) = 1;\nvec($win,fileno(STDOUT),1) = 1;\n$ein = $rin | $win; If you want to select on many filehandles you might wish to write a subroutine: sub fhbits {\n    my(@fhlist) = split(' ',$_[0]);\n    my($bits);\n    for (@fhlist) {\n        vec($bits,fileno($_),1) = 1;\n    }\n    $bits;\n}\n$rin = fhbits('STDIN TTY SOCK'); The usual idiom is: ($nfound,$timeleft) =\n  select($rout=$rin, $wout=$win, $eout=$ein, $timeout); or to block until something becomes ready just do this $nfound = select($rout=$rin, $wout=$win, $eout=$ein, undef); Most systems do not bother to return anything useful in $timeleft, so calling select() in scalar context just returns $nfound. Any of the bit masks can also be undef. The timeout, if specified, is in seconds, which may be fractional. Note: not all implementations are capable of returning the $timeleft. If not, they always return $timeleft equal to the supplied $timeout. You can effect a sleep of 250 milliseconds this way: select(undef, undef, undef, 0.25); Note that whether \"select\" gets restarted after signals (say, SIGALRM ) is implementation-dependent. See also perlport for notes on the portability of \"select\". On error, \"select\" behaves like the select(2) system call : it returns -1 and sets $!. Note: on some Unixes, the select(2) system call may report a socket file descriptor as \"ready for reading\", when actually no data is available, thus a subsequent read blocks. It can be avoided using always the O_NONBLOCK flag on the socket. See select(2) and fcntl(2) for further details. WARNING : One should not attempt to mix buffered I\/O (like \"read\" or < FH >) with \"select\", except as permitted by POSIX , and even then only on POSIX systems. You have to use \"sysread\" instead. semctl ID ,SEMNUM,CMD,ARG Calls the System V IPC function \"semctl\". You'll probably have to say use IPC::SysV; first to get the correct constant definitions. If CMD is IPC_STAT or GETALL , then ARG must be a variable that will hold the returned semid_ds structure or semaphore value array. Returns like \"ioctl\": the undefined value for error, \" \"0 but true\"\" for zero, or the actual return value otherwise. The ARG must consist of a vector of native short integers, which may be created with \"pack(\"s!\",(0)x$nsem)\". See also \"SysV IPC \" in perlipc, \"IPC::SysV\", \"IPC::Semaphore\" documentation. semget KEY ,NSEMS,FLAGS Calls the System V IPC function semget. Returns the semaphore id, or the undefined value if there is an error. See also \"SysV IPC \" in perlipc, \"IPC::SysV\", \"IPC::SysV::Semaphore\" documentation. semop KEY ,OPSTRING Calls the System V IPC function semop to perform semaphore operations such as signalling and waiting. OPSTRING must be a packed array of semop structures. Each semop structure can be generated with \"pack(\"s!3\", $semnum, $semop, $semflag)\". The length of OPSTRING implies the number of semaphore operations. Returns true if successful, or false if there is an error. As an example, the following code waits on semaphore $semnum of semaphore id $semid: $semop = pack(\"s!3\", $semnum, -1, 0);\ndie \"Semaphore trouble: $!\\n\" unless semop($semid, $semop); To signal the semaphore, replace \"-1\" with 1. See also \"SysV IPC \" in perlipc, \"IPC::SysV\", and \"IPC::SysV::Semaphore\" documentation. send SOCKET ,MSG,FLAGS,TO send SOCKET ,MSG,FLAGS Sends a message on a socket. Attempts to send the scalar MSG to the SOCKET filehandle. Takes the same flags as the system call of the same name. On unconnected sockets you must specify a destination to send TO , in which case it does a C \"sendto\". Returns the number of characters sent, or the undefined value if there is an error. The C system call sendmsg(2) is currently unimplemented. See \" UDP: Message Passing\" in perlipc for examples. Note the characters: depending on the status of the socket, either (8-bit) bytes or characters are sent. By default all sockets operate on bytes, but for example if the socket has been changed using binmode() to operate with the \":encoding(utf8)\" I\/O layer (see \"open\", or the \"open\" pragma, open), the I\/O will operate on UTF-8 encoded Unicode characters, not bytes. Similarly for the \":encoding\" pragma: in that case pretty much any characters can be sent. setpgrp PID ,PGRP Sets the current process group for the specified PID , 0 for the current process. Will produce a fatal error if used on a machine that doesn't implement POSIX setpgid(2) or BSD setpgrp(2). If the arguments are omitted, it defaults to \"0,0\". Note that the BSD 4.2 version of \"setpgrp\" does not accept any arguments, so only \"setpgrp(0,0)\" is portable. See also \"POSIX::setsid()\". setpriority WHICH ,WHO,PRIORITY Sets the current priority for a process, a process group, or a user. (See setpriority(2).) Will produce a fatal error if used on a machine that doesn't implement setpriority(2). setsockopt SOCKET ,LEVEL,OPTNAME,OPTVAL Sets the socket option requested. Returns undefined if there is an error. Use integer constants provided by the \"Socket\" module for LEVEL and OPNAME . Values for LEVEL can also be obtained from getprotobyname. OPTVAL might either be a packed string or an integer. An integer OPTVAL is shorthand for pack(\"i\", OPTVAL ). An example disabling the Nagle's algorithm for a socket: use Socket qw(IPPROTO_TCP TCP_NODELAY);\nsetsockopt($socket, IPPROTO_TCP, TCP_NODELAY, 1); shift ARRAY shift Shifts the first value of the array off and returns it, shortening the array by 1 and moving everything down. If there are no elements in the array, returns the undefined value. If ARRAY is omitted, shifts the @_ array within the lexical scope of subroutines and formats, and the @ARGV array outside of a subroutine and also within the lexical scopes established by the \"eval STRING\", \"BEGIN {}\", \"INIT {}\", \"CHECK {}\", \"UNITCHECK {}\" and \"END {}\" constructs. See also \"unshift\", \"push\", and \"pop\". \"shift\" and \"unshift\" do the same thing to the left end of an array that \"pop\" and \"push\" do to the right end. shmctl ID ,CMD,ARG Calls the System V IPC function shmctl. You'll probably have to say use IPC::SysV; first to get the correct constant definitions. If CMD is \"IPC_STAT\", then ARG must be a variable that will hold the returned \"shmid_ds\" structure. Returns like ioctl: the undefined value for error, \" 0 but true\" for zero, or the actual return value otherwise. See also \"SysV IPC \" in perlipc and \"IPC::SysV\" documentation. shmget KEY ,SIZE,FLAGS Calls the System V IPC function shmget. Returns the shared memory segment id, or the undefined value if there is an error. See also \"SysV IPC \" in perlipc and \"IPC::SysV\" documentation. shmread ID ,VAR,POS,SIZE shmwrite ID ,STRING,POS,SIZE Reads or writes the System V shared memory segment ID starting at position POS for size SIZE by attaching to it, copying in\/out, and detaching from it. When reading, VAR must be a variable that will hold the data read. When writing, if STRING is too long, only SIZE bytes are used; if STRING is too short, nulls are written to fill out SIZE bytes. Return true if successful, or false if there is an error. shmread() taints the variable. See also \"SysV IPC \" in perlipc, \"IPC::SysV\" documentation, and the \"IPC::Shareable\" module from CPAN . shutdown SOCKET ,HOW Shuts down a socket connection in the manner indicated by HOW , which has the same interpretation as in the system call of the same name. shutdown(SOCKET, 0);    # I\/we have stopped reading data\nshutdown(SOCKET, 1);    # I\/we have stopped writing data\nshutdown(SOCKET, 2);    # I\/we have stopped using this socket This is useful with sockets when you want to tell the other side you're done writing but not done reading, or vice versa. It's also a more insistent form of close because it also disables the file descriptor in any forked copies in other processes. Returns 1 for success. In the case of error, returns \"undef\" if the first argument is not a valid filehandle, or returns 0 and sets $! for any other failure. sin EXPR sin Returns the sine of EXPR (expressed in radians). If EXPR is omitted, returns sine of $_. For the inverse sine operation, you may use the \"Math::Trig::asin\" function, or use this relation: sub asin { atan2($_[0], sqrt(1 - $_[0] * $_[0])) } sleep EXPR sleep Causes the script to sleep for EXPR seconds, or forever if no EXPR . Returns the number of seconds actually slept. May be interrupted if the process receives a signal such as \"SIGALRM\". eval {\n    local $SIG{ALARM} = sub { die \"Alarm!\\n\" };\n    sleep;\n};\ndie $@ unless $@ eq \"Alarm!\\n\"; You probably cannot mix \"alarm\" and \"sleep\" calls, because \"sleep\" is often implemented using \"alarm\". On some older systems, it may sleep up to a full second less than what you requested, depending on how it counts seconds. Most modern systems always sleep the full amount. They may appear to sleep longer than that, however, because your process might not be scheduled right away in a busy multitasking system. For delays of finer granularity than one second, the Time::HiRes module (from CPAN , and starting from Perl 5.8 part of the standard distribution) provides usleep(). You may also use Perl's four-argument version of select() leaving the first three arguments undefined, or you might be able to use the \"syscall\" interface to access setitimer(2) if your system supports it. See perlfaq8 for details. See also the POSIX module's \"pause\" function. socket SOCKET ,DOMAIN,TYPE,PROTOCOL Opens a socket of the specified kind and attaches it to filehandle SOCKET . DOMAIN , TYPE , and PROTOCOL are specified the same as for the system call of the same name. You should \"use Socket\" first to get the proper definitions imported. See the examples in \"Sockets: Client\/Server Communication\" in perlipc. On systems that support a close-on-exec flag on files, the flag will be set for the newly opened file descriptor, as determined by the value of $^F. See \"$^F\" in perlvar. socketpair SOCKET1 ,SOCKET2,DOMAIN,TYPE,PROTOCOL Creates an unnamed pair of sockets in the specified domain, of the specified type. DOMAIN , TYPE , and PROTOCOL are specified the same as for the system call of the same name. If unimplemented, yields a fatal error. Returns true if successful. On systems that support a close-on-exec flag on files, the flag will be set for the newly opened file descriptors, as determined by the value of $^F. See \"$^F\" in perlvar. Some systems defined \"pipe\" in terms of \"socketpair\", in which a call to \"pipe(Rdr, Wtr)\" is essentially: use Socket;\nsocketpair(Rdr, Wtr, AF_UNIX, SOCK_STREAM, PF_UNSPEC);\nshutdown(Rdr, 1);        # no more writing for reader\nshutdown(Wtr, 0);        # no more reading for writer See perlipc for an example of socketpair use. Perl 5.8 and later will emulate socketpair using IP sockets to localhost if your system implements sockets but not socketpair. sort SUBNAME LIST sort BLOCK LIST sort LIST In list context, this sorts the LIST and returns the sorted list value. In scalar context, the behaviour of \"sort()\" is undefined. If SUBNAME or BLOCK is omitted, \"sort\"s in standard string comparison order. If SUBNAME is specified, it gives the name of a subroutine that returns an integer less than, equal to, or greater than 0, depending on how the elements of the list are to be ordered. (The \"<=>\" and \"cmp\" operators are extremely useful in such routines.) SUBNAME may be a scalar variable name (unsubscripted), in which case the value provides the name of (or a reference to) the actual subroutine to use. In place of a SUBNAME , you can provide a BLOCK as an anonymous, in-line sort subroutine. If the subroutine's prototype is \"($$)\", the elements to be compared are passed by reference in @_, as for a normal subroutine. This is slower than unprototyped subroutines, where the elements to be compared are passed into the subroutine as the package global variables $a and $b (see example below). Note that in the latter case, it is usually counter-productive to declare $a and $b as lexicals. The values to be compared are always passed by reference and should not be modified. You also cannot exit out of the sort block or subroutine using any of the loop control operators described in perlsyn or with \"goto\". When \"use locale\" is in effect, \"sort LIST\" sorts LIST according to the current collation locale. See perllocale. sort() returns aliases into the original list, much as a for loop's index variable aliases the list elements. That is, modifying an element of a list returned by sort() (for example, in a \"foreach\", \"map\" or \"grep\") actually modifies the element in the original list. This is usually something to be avoided when writing clear code. Perl 5.6 and earlier used a quicksort algorithm to implement sort. That algorithm was not stable, and could go quadratic. (A stable sort preserves the input order of elements that compare equal. Although quicksort's run time is O(NlogN) when averaged over all arrays of length N, the time can be O(N**2), quadratic behavior, for some inputs.) In 5.7, the quicksort implementation was replaced with a stable mergesort algorithm whose worst-case behavior is O(NlogN). But benchmarks indicated that for some inputs, on some platforms, the original quicksort was faster. 5.8 has a sort pragma for limited control of the sort. Its rather blunt control of the underlying algorithm may not persist into future Perls, but the ability to characterize the input or output in implementation independent ways quite probably will. See the sort pragma. Examples: # sort lexically\n@articles = sort @files;\n\n# same thing, but with explicit sort routine\n@articles = sort {$a cmp $b} @files;\n\n# now case-insensitively\n@articles = sort {uc($a) cmp uc($b)} @files;\n\n# same thing in reversed order\n@articles = sort {$b cmp $a} @files;\n\n# sort numerically ascending\n@articles = sort {$a <=> $b} @files;\n\n# sort numerically descending\n@articles = sort {$b <=> $a} @files;\n\n# this sorts the %age hash by value instead of key\n# using an in-line function\n@eldest = sort { $age{$b} <=> $age{$a} } keys %age;\n\n# sort using explicit subroutine name\nsub byage {\n    $age{$a} <=> $age{$b};  # presuming numeric\n}\n@sortedclass = sort byage @class;\n\nsub backwards { $b cmp $a }\n@harry  = qw(dog cat x Cain Abel);\n@george = qw(gone chased yz Punished Axed);\nprint sort @harry;\n        # prints AbelCaincatdogx\nprint sort backwards @harry;\n        # prints xdogcatCainAbel\nprint sort @george, 'to', @harry;\n        # prints AbelAxedCainPunishedcatchaseddoggonetoxyz\n\n# inefficiently sort by descending numeric compare using\n# the first integer after the first = sign, or the\n# whole record case-insensitively otherwise\n\n@new = sort {\n    ($b =~ \/=(\\d+)\/)[0] <=> ($a =~ \/=(\\d+)\/)[0]\n                        ||\n                uc($a)  cmp  uc($b)\n} @old;\n\n# same thing, but much more efficiently;\n# we'll build auxiliary indices instead\n# for speed\n@nums = @caps = ();\nfor (@old) {\n    push @nums, \/=(\\d+)\/;\n    push @caps, uc($_);\n}\n\n@new = @old[ sort {\n                    $nums[$b] <=> $nums[$a]\n                             ||\n                    $caps[$a] cmp $caps[$b]\n                   } 0..$#old\n           ];\n\n# same thing, but without any temps\n@new = map { $_->[0] }\n       sort { $b->[1] <=> $a->[1]\n                       ||\n              $a->[2] cmp $b->[2]\n       } map { [$_, \/=(\\d+)\/, uc($_)] } @old;\n\n# using a prototype allows you to use any comparison subroutine\n# as a sort subroutine (including other package's subroutines)\npackage other;\nsub backwards ($$) { $_[1] cmp $_[0]; }     # $a and $b are not set here\n\npackage main;\n@new = sort other::backwards @old;\n\n# guarantee stability, regardless of algorithm\nuse sort 'stable';\n@new = sort { substr($a, 3, 5) cmp substr($b, 3, 5) } @old;\n\n# force use of mergesort (not portable outside Perl 5.8)\nuse sort '_mergesort';  # note discouraging _\n@new = sort { substr($a, 3, 5) cmp substr($b, 3, 5) } @old; Warning: syntactical care is required when sorting the list returned from a function. If you want to sort the list returned by the function call \"find_records(@key)\", you can use: @contact = sort { $a cmp $b } find_records @key;\n@contact = sort +find_records(@key);\n@contact = sort &find_records(@key);\n@contact = sort(find_records(@key)); If instead you want to sort the array @key with the comparison routine \"find_records()\" then you can use: @contact = sort { find_records() } @key;\n@contact = sort find_records(@key);\n@contact = sort(find_records @key);\n@contact = sort(find_records (@key)); If you're using strict, you must not declare $a and $b as lexicals. They are package globals. That means that if you're in the \"main\" package and type @articles = sort {$b <=> $a} @files; then $a and $b are $main::a and $main::b (or $::a and $::b), but if you're in the \"FooPack\" package, it's the same as typing @articles = sort {$FooPack::b <=> $FooPack::a} @files; The comparison function is required to behave. If it returns inconsistent results (sometimes saying $x[1] is less than $x[2] and sometimes saying the opposite, for example) the results are not well-defined. Because \"<=>\" returns \"undef\" when either operand is \"NaN\" (not-a-number), and because \"sort\" will trigger a fatal error unless the result of a comparison is defined, when sorting with a comparison function like \"$a <=> $b\", be careful about lists that might contain a \"NaN\". The following example takes advantage of the fact that \"NaN != NaN\" to eliminate any \"NaN\"s from the input. @result = sort { $a <=> $b } grep { $_ == $_ } @input; splice ARRAY ,OFFSET,LENGTH,LIST splice ARRAY ,OFFSET,LENGTH splice ARRAY ,OFFSET splice ARRAY Removes the elements designated by OFFSET and LENGTH from an array, and replaces them with the elements of LIST , if any. In list context, returns the elements removed from the array. In scalar context, returns the last element removed, or \"undef\" if no elements are removed. The array grows or shrinks as necessary. If OFFSET is negative then it starts that far from the end of the array. If LENGTH is omitted, removes everything from OFFSET onward. If LENGTH is negative, removes the elements from OFFSET onward except for -LENGTH elements at the end of the array. If both OFFSET and LENGTH are omitted, removes everything. If OFFSET is past the end of the array, perl issues a warning, and splices at the end of the array. The following equivalences hold (assuming \"$[ == 0 and $#a >= $i\" ) push(@a,$x,$y)      splice(@a,@a,0,$x,$y)\npop(@a)             splice(@a,-1)\nshift(@a)           splice(@a,0,1)\nunshift(@a,$x,$y)   splice(@a,0,0,$x,$y)\n$a[$i] = $y         splice(@a,$i,1,$y) Example, assuming array lengths are passed before arrays: sub aeq {   # compare two list values\n    my(@a) = splice(@_,0,shift);\n    my(@b) = splice(@_,0,shift);\n    return 0 unless @a == @b;       # same len?\n    while (@a) {\n        return 0 if pop(@a) ne pop(@b);\n    }\n    return 1;\n}\nif (&aeq($len,@foo[1..$len],0+@bar,@bar)) { ... } split \/PATTERN\/,EXPR,LIMIT split \/PATTERN\/,EXPR split \/PATTERN\/ split Splits the string EXPR into a list of strings and returns that list. By default, empty leading fields are preserved, and empty trailing ones are deleted. (If all fields are empty, they are considered to be trailing.) In scalar context, returns the number of fields found. In scalar and void context it splits into the @_ array. Use of split in scalar and void context is deprecated, however, because it clobbers your subroutine arguments. If EXPR is omitted, splits the $_ string. If PATTERN is also omitted, splits on whitespace (after skipping any leading whitespace). Anything matching PATTERN is taken to be a delimiter separating the fields. (Note that the delimiter may be longer than one character.) If LIMIT is specified and positive, it represents the maximum number of fields the EXPR will be split into, though the actual number of fields returned depends on the number of times PATTERN matches within EXPR . If LIMIT is unspecified or zero, trailing null fields are stripped (which potential users of \"pop\" would do well to remember). If LIMIT is negative, it is treated as if an arbitrarily large LIMIT had been specified. Note that splitting an EXPR that evaluates to the empty string always returns the empty list, regardless of the LIMIT specified. A pattern matching the null string (not to be confused with a null pattern \"\/\/\", which is just one member of the set of patterns matching a null string) will split the value of EXPR into separate characters at each point it matches that way. For example: print join(':', split(\/ *\/, 'hi there')), \"\\n\"; produces the output 'h:i:t:h:e:r:e'. As a special case for \"split\", using the empty pattern \"\/\/\" specifically matches only the null string, and is not be confused with the regular use of \"\/\/\" to mean \"the last successful pattern match\". So, for \"split\", the following: print join(':', split(\/\/, 'hi there')), \"\\n\"; produces the output 'h:i: :t:h:e:r:e'. Empty leading fields are produced when there are positive-width matches at the beginning of the string; a zero-width match at the beginning of the string does not produce an empty field. For example: print join(':', split(\/(?=\\w)\/, 'hi there!')); produces the output 'h:i :t:h:e:r:e!'. Empty trailing fields, on the other hand, are produced when there is a match at the end of the string (and when LIMIT is given and is not 0), regardless of the length of the match. For example: print join(':', split(\/\/,   'hi there!', -1)), \"\\n\";\nprint join(':', split(\/\\W\/, 'hi there!', -1)), \"\\n\"; produce the output 'h:i: :t:h:e:r:e:!:' and 'hi:there:', respectively, both with an empty trailing field. The LIMIT parameter can be used to split a line partially ($login, $passwd, $remainder) = split(\/:\/, $_, 3); When assigning to a list, if LIMIT is omitted, or zero, Perl supplies a LIMIT one larger than the number of variables in the list, to avoid unnecessary work. For the list above LIMIT would have been 4 by default. In time critical applications it behooves you not to split into more fields than you really need. If the PATTERN contains parentheses, additional list elements are created from each matching substring in the delimiter. split(\/([,-])\/, \"1-10,20\", 3); produces the list value (1, '-', 10, ',', 20) If you had the entire header of a normal Unix email message in $header, you could split it up into fields and their values this way: $header =~ s\/\\n(?=\\s)\/\/g;  # fix continuation lines\n%hdrs   =  (UNIX_FROM => split \/^(\\S*?):\\s*\/m, $header); The pattern \"\/PATTERN\/\" may be replaced with an expression to specify patterns that vary at runtime. (To do runtime compilation only once, use \"\/$variable\/o\".) As a special case, specifying a PATTERN of space (' ') will split on white space just as \"split\" with no arguments does. Thus, \"split(' ')\" can be used to emulate awk's default behavior, whereas \"split(\/ \/)\" will give you as many null initial fields as there are leading spaces. A \"split\" on \"\/\\s+\/\" is like a \"split(' ')\" except that any leading whitespace produces a null first field. A \"split\" with no arguments really does a \"split(' ', $_)\" internally. A PATTERN of \"\/^\/\" is treated as if it were \"\/^\/m\", since it isn't much use otherwise. Example: open(PASSWD, '\/etc\/passwd');\nwhile (<PASSWD>) {\n    chomp;\n    ($login, $passwd, $uid, $gid,\n     $gcos, $home, $shell) = split(\/:\/);\n    #...\n} As with regular pattern matching, any capturing parentheses that are not matched in a \"split()\" will be set to \"undef\" when returned: @fields = split \/(A)|B\/, \"1A2B3\";\n# @fields is (1, 'A', 2, undef, 3) sprintf FORMAT , LIST Returns a string formatted by the usual \"printf\" conventions of the C library function \"sprintf\". See below for more details and see sprintf(3) or printf(3) on your system for an explanation of the general principles. For example: # Format number with up to 8 leading zeroes\n$result = sprintf(\"%08d\", $number);\n\n# Round number to 3 digits after decimal point\n$rounded = sprintf(\"%.3f\", $number); Perl does its own \"sprintf\" formatting--it emulates the C function \"sprintf\", but it doesn't use it (except for floating-point numbers, and even then only the standard modifiers are allowed). As a result, any non-standard extensions in your local \"sprintf\" are not available from Perl. Unlike \"printf\", \"sprintf\" does not do what you probably mean when you pass it an array as your first argument. The array is given scalar context, and instead of using the 0th element of the array as the format, Perl will use the count of elements in the array as the format, which is almost never useful. Perl's \"sprintf\" permits the following universally-known conversions: %%   a percent sign\n%c   a character with the given number\n%s   a string\n%d   a signed integer, in decimal\n%u   an unsigned integer, in decimal\n%o   an unsigned integer, in octal\n%x   an unsigned integer, in hexadecimal\n%e   a floating-point number, in scientific notation\n%f   a floating-point number, in fixed decimal notation\n%g   a floating-point number, in %e or %f notation In addition, Perl permits the following widely-supported conversions: %X   like %x, but using upper-case letters\n%E   like %e, but using an upper-case \"E\"\n%G   like %g, but with an upper-case \"E\" (if applicable)\n%b   an unsigned integer, in binary\n%B   like %b, but using an upper-case \"B\" with the # flag\n%p   a pointer (outputs the Perl value's address in hexadecimal)\n%n   special: *stores* the number of characters output so far\n     into the next variable in the parameter list Finally, for backward (and we do mean \"backward\") compatibility, Perl permits these unnecessary but widely-supported conversions: %i   a synonym for %d\n%D   a synonym for %ld\n%U   a synonym for %lu\n%O   a synonym for %lo\n%F   a synonym for %f Note that the number of exponent digits in the scientific notation produced by %e, %E, %g and %G for numbers with the modulus of the exponent less than 100 is system-dependent: it may be three or less (zero-padded as necessary). In other words, 1.23 times ten to the 99th may be either \"1.23e99\" or \"1.23e099\". Between the \"%\" and the format letter, you may specify a number of additional attributes controlling the interpretation of the format. In order, these are: format parameter index An explicit format parameter index, such as \"2$\". By default sprintf will format the next unused argument in the list, but this allows you to take the arguments out of order, e.g.: printf '%2$d %1$d', 12, 34;      # prints \"34 12\"\nprintf '%3$d %d %1$d', 1, 2, 3;  # prints \"3 1 1\" flags one or more of: space   prefix non-negative number with a space\n+       prefix non-negative number with a plus sign\n-       left-justify within the field\n0       use zeros, not spaces, to right-justify\n#       ensure the leading \"0\" for any octal,\n        prefix non-zero hexadecimal with \"0x\" or \"0X\",\n        prefix non-zero binary with \"0b\" or \"0B\" For example: printf '<% d>',  12;   # prints \"< 12>\"\nprintf '<%+d>',  12;   # prints \"<+12>\"\nprintf '<%6s>',  12;   # prints \"<    12>\"\nprintf '<%-6s>', 12;   # prints \"<12    >\"\nprintf '<%06s>', 12;   # prints \"<000012>\"\nprintf '<%#o>',  12;   # prints \"<014>\"\nprintf '<%#x>',  12;   # prints \"<0xc>\"\nprintf '<%#X>',  12;   # prints \"<0XC>\"\nprintf '<%#b>',  12;   # prints \"<0b1100>\"\nprintf '<%#B>',  12;   # prints \"<0B1100>\" When a space and a plus sign are given as the flags at once, a plus sign is used to prefix a positive number. printf '<%+ d>', 12;   # prints \"<+12>\"\nprintf '<% +d>', 12;   # prints \"<+12>\" When the # flag and a precision are given in the %o conversion, the precision is incremented if it's necessary for the leading \"0\". printf '<%#.5o>', 012;      # prints \"<00012>\"\nprintf '<%#.5o>', 012345;   # prints \"<012345>\"\nprintf '<%#.0o>', 0;        # prints \"<0>\" vector flag This flag tells perl to interpret the supplied string as a vector of integers, one for each character in the string. Perl applies the format to each integer in turn, then joins the resulting strings with a separator (a dot \".\" by default). This can be useful for displaying ordinal values of characters in arbitrary strings: printf \"%vd\", \"AB\\x{100}\";           # prints \"65.66.256\"\nprintf \"version is v%vd\\n\", $^V;     # Perl's version Put an asterisk \"*\" before the \"v\" to override the string to use to separate the numbers: printf \"address is %*vX\\n\", \":\", $addr;   # IPv6 address\nprintf \"bits are %0*v8b\\n\", \" \", $bits;   # random bitstring You can also explicitly specify the argument number to use for the join string using e.g. \"*2$v\": printf '%*4$vX %*4$vX %*4$vX', @addr[1..3], \":\";   # 3 IPv6 addresses (minimum) width Arguments are usually formatted to be only as wide as required to display the given value. You can override the width by putting a number here, or get the width from the next argument (with \"*\") or from a specified argument (with e.g. \"*2$\"): printf '<%s>', \"a\";       # prints \"<a>\"\nprintf '<%6s>', \"a\";      # prints \"<     a>\"\nprintf '<%*s>', 6, \"a\";   # prints \"<     a>\"\nprintf '<%*2$s>', \"a\", 6; # prints \"<     a>\"\nprintf '<%2s>', \"long\";   # prints \"<long>\" (does not truncate) If a field width obtained through \"*\" is negative, it has the same effect as the \"-\" flag: left-justification. precision, or maximum width You can specify a precision (for numeric conversions) or a maximum width (for string conversions) by specifying a \".\" followed by a number. For floating point formats, with the exception of 'g' and 'G', this specifies the number of decimal places to show (the default being 6), e.g.: # these examples are subject to system-specific variation\nprintf '<%f>', 1;    # prints \"<1.000000>\"\nprintf '<%.1f>', 1;  # prints \"<1.0>\"\nprintf '<%.0f>', 1;  # prints \"<1>\"\nprintf '<%e>', 10;   # prints \"<1.000000e+01>\"\nprintf '<%.1e>', 10; # prints \"<1.0e+01>\" For 'g' and 'G', this specifies the maximum number of digits to show, including prior to the decimal point as well as after it, e.g.: # these examples are subject to system-specific variation\nprintf '<%g>', 1;        # prints \"<1>\"\nprintf '<%.10g>', 1;     # prints \"<1>\"\nprintf '<%g>', 100;      # prints \"<100>\"\nprintf '<%.1g>', 100;    # prints \"<1e+02>\"\nprintf '<%.2g>', 100.01; # prints \"<1e+02>\"\nprintf '<%.5g>', 100.01; # prints \"<100.01>\"\nprintf '<%.4g>', 100.01; # prints \"<100>\" For integer conversions, specifying a precision implies that the output of the number itself should be zero-padded to this width, where the 0 flag is ignored: printf '<%.6d>', 1;      # prints \"<000001>\"\nprintf '<%+.6d>', 1;     # prints \"<+000001>\"\nprintf '<%-10.6d>', 1;   # prints \"<000001    >\"\nprintf '<%10.6d>', 1;    # prints \"<    000001>\"\nprintf '<%010.6d>', 1;   # prints \"<    000001>\"\nprintf '<%+10.6d>', 1;   # prints \"<   +000001>\"\n\nprintf '<%.6x>', 1;      # prints \"<000001>\"\nprintf '<%#.6x>', 1;     # prints \"<0x000001>\"\nprintf '<%-10.6x>', 1;   # prints \"<000001    >\"\nprintf '<%10.6x>', 1;    # prints \"<    000001>\"\nprintf '<%010.6x>', 1;   # prints \"<    000001>\"\nprintf '<%#10.6x>', 1;   # prints \"<  0x000001>\" For string conversions, specifying a precision truncates the string to fit in the specified width: printf '<%.5s>', \"truncated\";   # prints \"<trunc>\"\nprintf '<%10.5s>', \"truncated\"; # prints \"<     trunc>\" You can also get the precision from the next argument using \".*\": printf '<%.6x>', 1;       # prints \"<000001>\"\nprintf '<%.*x>', 6, 1;    # prints \"<000001>\" If a precision obtained through \"*\" is negative, it has the same effect as no precision. printf '<%.*s>',  7, \"string\";   # prints \"<string>\"\nprintf '<%.*s>',  3, \"string\";   # prints \"<str>\"\nprintf '<%.*s>',  0, \"string\";   # prints \"<>\"\nprintf '<%.*s>', -1, \"string\";   # prints \"<string>\"\n\nprintf '<%.*d>',  1, 0;   # prints \"<0>\"\nprintf '<%.*d>',  0, 0;   # prints \"<>\"\nprintf '<%.*d>', -1, 0;   # prints \"<0>\" You cannot currently get the precision from a specified number, but it is intended that this will be possible in the future using e.g. \".*2$\": printf '<%.*2$x>', 1, 6;   # INVALID, but in future will print \"<000001>\" size For numeric conversions, you can specify the size to interpret the number as using \"l\", \"h\", \"V\", \"q\", \"L\", or \"ll\". For integer conversions ( \"d u o x X b i D U O\"), numbers are usually assumed to be whatever the default integer size is on your platform (usually 32 or 64 bits), but you can override this to use instead one of the standard C types, as supported by the compiler used to build Perl: l           interpret integer as C type \"long\" or \"unsigned long\"\nh           interpret integer as C type \"short\" or \"unsigned short\"\nq, L or ll  interpret integer as C type \"long long\", \"unsigned long long\".\n            or \"quads\" (typically 64-bit integers) The last will produce errors if Perl does not understand \"quads\" in your installation. (This requires that either the platform natively supports quads or Perl was specifically compiled to support quads.) You can find out whether your Perl supports quads via Config: use Config;\n($Config{use64bitint} eq 'define' || $Config{longsize} >= 8) &&\n        print \"quads\\n\"; For floating point conversions ( \"e f g E F G\"), numbers are usually assumed to be the default floating point size on your platform (double or long double), but you can force 'long double' with \"q\", \"L\", or \"ll\" if your platform supports them. You can find out whether your Perl supports long doubles via Config: use Config;\n$Config{d_longdbl} eq 'define' && print \"long doubles\\n\"; You can find out whether Perl considers 'long double' to be the default floating point size to use on your platform via Config: use Config;\n($Config{uselongdouble} eq 'define') &&\n        print \"long doubles by default\\n\"; It can also be the case that long doubles and doubles are the same thing: use Config;\n($Config{doublesize} == $Config{longdblsize}) &&\n        print \"doubles are long doubles\\n\"; The size specifier \"V\" has no effect for Perl code, but it is supported for compatibility with XS code; it means 'use the standard size for a Perl integer (or floating-point number)', which is already the default for Perl code. order of arguments Normally, sprintf takes the next unused argument as the value to format for each format specification. If the format specification uses \"*\" to require additional arguments, these are consumed from the argument list in the order in which they appear in the format specification before the value to format. Where an argument is specified using an explicit index, this does not affect the normal order for the arguments (even when the explicitly specified index would have been the next argument in any case). So: printf '<%*.*s>', $a, $b, $c; would use $a for the width, $b for the precision and $c as the value to format, while: printf '<%*1$.*s>', $a, $b; would use $a for the width and the precision, and $b as the value to format. Here are some more examples - beware that when using an explicit index, the \"$\" may need to be escaped: printf \"%2\\$d %d\\n\",    12, 34;               # will print \"34 12\\n\"\nprintf \"%2\\$d %d %d\\n\", 12, 34;               # will print \"34 12 34\\n\"\nprintf \"%3\\$d %d %d\\n\", 12, 34, 56;           # will print \"56 12 34\\n\"\nprintf \"%2\\$*3\\$d %d\\n\", 12, 34, 3;           # will print \" 34 12\\n\" If \"use locale\" is in effect, and POSIX::setlocale() has been called, the character used for the decimal separator in formatted floating point numbers is affected by the LC_NUMERIC locale. See perllocale and POSIX . sqrt EXPR sqrt Return the square root of EXPR . If EXPR is omitted, returns square root of $_. Only works on non-negative operands, unless you've loaded the standard Math::Complex module. use Math::Complex;\nprint sqrt(-2);    # prints 1.4142135623731i srand EXPR srand Sets the random number seed for the \"rand\" operator. The point of the function is to \"seed\" the \"rand\" function so that \"rand\" can produce a different sequence each time you run your program. If srand() is not called explicitly, it is called implicitly at the first use of the \"rand\" operator. However, this was not the case in versions of Perl before 5.004, so if your script will run under older Perl versions, it should call \"srand\". Most programs won't even call srand() at all, except those that need a cryptographically-strong starting point rather than the generally acceptable default, which is based on time of day, process ID , and memory allocation, or the \/dev\/urandom device, if available. You can call srand($seed) with the same $seed to reproduce the same sequence from rand(), but this is usually reserved for generating predictable results for testing or debugging. Otherwise, don't call srand() more than once in your program. Do not call srand() (i.e. without an argument) more than once in a script. The internal state of the random number generator should contain more entropy than can be provided by any seed, so calling srand() again actually loses randomness. Most implementations of \"srand\" take an integer and will silently truncate decimal numbers. This means \"srand(42)\" will usually produce the same results as \"srand(42.1)\". To be safe, always pass \"srand\" an integer. In versions of Perl prior to 5.004 the default seed was just the current \"time\". This isn't a particularly good seed, so many old programs supply their own seed value (often \"time ^ $$\" or \"time ^ ($$ + ($$ << 15))\"), but that isn't necessary any more. For cryptographic purposes, however, you need something much more random than the default seed. Checksumming the compressed output of one or more rapidly changing operating system status programs is the usual method. For example: srand (time ^ $$ ^ unpack \"%L*\", `ps axww | gzip -f`); If you're particularly concerned with this, see the \"Math::TrulyRandom\" module in CPAN . Frequently called programs (like CGI scripts) that simply use time ^ $$ for a seed can fall prey to the mathematical property that a^b == (a+1)^(b+1) one-third of the time. So don't do that. stat FILEHANDLE stat EXPR stat DIRHANDLE stat Returns a 13-element list giving the status info for a file, either the file opened via FILEHANDLE or DIRHANDLE , or named by EXPR . If EXPR is omitted, it stats $_. Returns a null list if the stat fails. Typically used as follows: ($dev,$ino,$mode,$nlink,$uid,$gid,$rdev,$size,\n   $atime,$mtime,$ctime,$blksize,$blocks)\n       = stat($filename); Not all fields are supported on all filesystem types. Here are the meanings of the fields:  0 dev      device number of filesystem\n 1 ino      inode number\n 2 mode     file mode  (type and permissions)\n 3 nlink    number of (hard) links to the file\n 4 uid      numeric user ID of file's owner\n 5 gid      numeric group ID of file's owner\n 6 rdev     the device identifier (special files only)\n 7 size     total size of file, in bytes\n 8 atime    last access time in seconds since the epoch\n 9 mtime    last modify time in seconds since the epoch\n10 ctime    inode change time in seconds since the epoch (*)\n11 blksize  preferred block size for file system I\/O\n12 blocks   actual number of blocks allocated (The epoch was at 00:00 January 1, 1970 GMT .) (*) Not all fields are supported on all filesystem types. Notably, the ctime field is non-portable. In particular, you cannot expect it to be a \"creation time\", see \"Files and Filesystems\" in perlport for details. If \"stat\" is passed the special filehandle consisting of an underline, no stat is done, but the current contents of the stat structure from the last \"stat\", \"lstat\", or filetest are returned. Example: if (-x $file && (($d) = stat(_)) && $d < 0) {\n    print \"$file is executable NFS file\\n\";\n} (This works on machines only for which the device number is negative under NFS .) Because the mode contains both the file type and its permissions, you should mask off the file type portion and (s)printf using a \"%o\" if you want to see the real permissions. $mode = (stat($filename))[2];\nprintf \"Permissions are %04o\\n\", $mode & 07777; In scalar context, \"stat\" returns a boolean value indicating success or failure, and, if successful, sets the information associated with the special filehandle \"_\". The File::stat module provides a convenient, by-name access mechanism: use File::stat;\n$sb = stat($filename);\nprintf \"File is %s, size is %s, perm %04o, mtime %s\\n\",\n    $filename, $sb->size, $sb->mode & 07777,\n    scalar localtime $sb->mtime; You can import symbolic mode constants ( \"S_IF*\") and functions ( \"S_IS*\") from the Fcntl module: use Fcntl ':mode';\n\n$mode = (stat($filename))[2];\n\n$user_rwx      = ($mode & S_IRWXU) >> 6;\n$group_read    = ($mode & S_IRGRP) >> 3;\n$other_execute =  $mode & S_IXOTH;\n\nprintf \"Permissions are %04o\\n\", S_IMODE($mode), \"\\n\";\n\n$is_setuid     =  $mode & S_ISUID;\n$is_directory  =  S_ISDIR($mode); You could write the last two using the \"-u\" and \"-d\" operators. The commonly available \"S_IF*\" constants are # Permissions: read, write, execute, for user, group, others.\n\nS_IRWXU S_IRUSR S_IWUSR S_IXUSR\nS_IRWXG S_IRGRP S_IWGRP S_IXGRP\nS_IRWXO S_IROTH S_IWOTH S_IXOTH\n\n# Setuid\/Setgid\/Stickiness\/SaveText.\n# Note that the exact meaning of these is system dependent.\n\nS_ISUID S_ISGID S_ISVTX S_ISTXT\n\n# File types.  Not necessarily all are available on your system.\n\nS_IFREG S_IFDIR S_IFLNK S_IFBLK S_IFCHR S_IFIFO S_IFSOCK S_IFWHT S_ENFMT\n\n# The following are compatibility aliases for S_IRUSR, S_IWUSR, S_IXUSR.\n\nS_IREAD S_IWRITE S_IEXEC and the \"S_IF*\" functions are S_IMODE($mode)      the part of $mode containing the permission bits\n                    and the setuid\/setgid\/sticky bits\n\nS_IFMT($mode)       the part of $mode containing the file type\n                    which can be bit-anded with e.g. S_IFREG\n                    or with the following functions\n\n# The operators -f, -d, -l, -b, -c, -p, and -S.\n\nS_ISREG($mode) S_ISDIR($mode) S_ISLNK($mode)\nS_ISBLK($mode) S_ISCHR($mode) S_ISFIFO($mode) S_ISSOCK($mode)\n\n# No direct -X operator counterpart, but for the first one\n# the -g operator is often equivalent.  The ENFMT stands for\n# record flocking enforcement, a platform-dependent feature.\n\nS_ISENFMT($mode) S_ISWHT($mode) See your native chmod(2) and stat(2) documentation for more details about the \"S_*\" constants. To get status info for a symbolic link instead of the target file behind the link, use the \"lstat\" function. state EXPR state TYPE EXPR state EXPR : ATTRS state TYPE EXPR : ATTRS \"state\" declares a lexically scoped variable, just like \"my\" does. However, those variables will never be reinitialized, contrary to lexical variables that are reinitialized each time their enclosing block is entered. \"state\" variables are only enabled when the \"feature 'state'\" pragma is in effect. See feature. study SCALAR study Takes extra time to study SCALAR ($_ if unspecified) in anticipation of doing many pattern matches on the string before it is next modified. This may or may not save time, depending on the nature and number of patterns you are searching on, and on the distribution of character frequencies in the string to be searched--you probably want to compare run times with and without it to see which runs faster. Those loops that scan for many short constant strings (including the constant parts of more complex patterns) will benefit most. You may have only one \"study\" active at a time--if you study a different scalar the first is \"unstudied\". (The way \"study\" works is this: a linked list of every character in the string to be searched is made, so we know, for example, where all the 'k' characters are. From each search string, the rarest character is selected, based on some static frequency tables constructed from some C programs and English text. Only those places that contain this \"rarest\" character are examined.) For example, here is a loop that inserts index producing entries before any line containing a certain pattern: while (<>) {\n    study;\n    print \".IX foo\\n\"       if \/\\bfoo\\b\/;\n    print \".IX bar\\n\"       if \/\\bbar\\b\/;\n    print \".IX blurfl\\n\"    if \/\\bblurfl\\b\/;\n    # ...\n    print;\n} In searching for \"\/\\bfoo\\b\/\", only those locations in $_ that contain \"f\" will be looked at, because \"f\" is rarer than \"o\". In general, this is a big win except in pathological cases. The only question is whether it saves you more time than it took to build the linked list in the first place. Note that if you have to look for strings that you don't know till runtime, you can build an entire loop as a string and \"eval\" that to avoid recompiling all your patterns all the time. Together with undefining $\/ to input entire files as one record, this can be very fast, often faster than specialized programs like fgrep(1). The following scans a list of files (@files) for a list of words (@words), and prints out the names of those files that contain a match: $search = 'while (<>) { study;';\nforeach $word (@words) {\n    $search .= \"++\\$seen{\\$ARGV} if \/\\\\b$word\\\\b\/;\\n\";\n}\n$search .= \"}\";\n@ARGV = @files;\nundef $\/;\neval $search;               # this screams\n$\/ = \"\\n\";          # put back to normal input delimiter\nforeach $file (sort keys(%seen)) {\n    print $file, \"\\n\";\n} sub NAME BLOCK sub NAME ( PROTO ) BLOCK sub NAME : ATTRS BLOCK sub NAME ( PROTO ) : ATTRS BLOCK This is subroutine definition, not a real function per se. Without a BLOCK it's just a forward declaration. Without a NAME , it's an anonymous function declaration, and does actually return a value: the CODE ref of the closure you just created. See perlsub and perlref for details about subroutines and references, and attributes and Attribute::Handlers for more information about attributes. substr EXPR ,OFFSET,LENGTH,REPLACEMENT substr EXPR ,OFFSET,LENGTH substr EXPR ,OFFSET Extracts a substring out of EXPR and returns it. First character is at offset 0, or whatever you've set $[ to (but don't do that). If OFFSET is negative (or more precisely, less than $[), starts that far from the end of the string. If LENGTH is omitted, returns everything to the end of the string. If LENGTH is negative, leaves that many characters off the end of the string. my $s = \"The black cat climbed the green tree\";\nmy $color  = substr $s, 4, 5;       # black\nmy $middle = substr $s, 4, -11;     # black cat climbed the\nmy $end    = substr $s, 14;         # climbed the green tree\nmy $tail   = substr $s, -4;         # tree\nmy $z      = substr $s, -4, 2;      # tr You can use the substr() function as an lvalue, in which case EXPR must itself be an lvalue. If you assign something shorter than LENGTH , the string will shrink, and if you assign something longer than LENGTH , the string will grow to accommodate it. To keep the string the same length you may need to pad or chop your value using \"sprintf\". If OFFSET and LENGTH specify a substring that is partly outside the string, only the part within the string is returned. If the substring is beyond either end of the string, substr() returns the undefined value and produces a warning. When used as an lvalue, specifying a substring that is entirely outside the string is a fatal error. Here's an example showing the behavior for boundary cases: my $name = 'fred';\nsubstr($name, 4) = 'dy';            # $name is now 'freddy'\nmy $null = substr $name, 6, 2;      # returns '' (no warning)\nmy $oops = substr $name, 7;         # returns undef, with warning\nsubstr($name, 7) = 'gap';           # fatal error An alternative to using substr() as an lvalue is to specify the replacement string as the 4th argument. This allows you to replace parts of the EXPR and return what was there before in one operation, just as you can with splice(). my $s = \"The black cat climbed the green tree\";\nmy $z = substr $s, 14, 7, \"jumped from\";    # climbed\n# $s is now \"The black cat jumped from the green tree\" Note that the lvalue returned by the 3-arg version of substr() acts as a 'magic bullet'; each time it is assigned to, it remembers which part of the original string is being modified; for example: $x = '1234';\nfor (substr($x,1,2)) {\n    $_ = 'a';   print $x,\"\\n\";      # prints 1a4\n    $_ = 'xyz'; print $x,\"\\n\";      # prints 1xyz4\n    $x = '56789';\n    $_ = 'pq';  print $x,\"\\n\";      # prints 5pq9\n} Prior to Perl version 5.9.1, the result of using an lvalue multiple times was unspecified. symlink OLDFILE ,NEWFILE Creates a new filename symbolically linked to the old filename. Returns 1 for success, 0 otherwise. On systems that don't support symbolic links, produces a fatal error at run time. To check for that, use eval: $symlink_exists = eval { symlink(\"\",\"\"); 1 }; syscall NUMBER , LIST Calls the system call specified as the first element of the list, passing the remaining elements as arguments to the system call. If unimplemented, produces a fatal error. The arguments are interpreted as follows: if a given argument is numeric, the argument is passed as an int. If not, the pointer to the string value is passed. You are responsible to make sure a string is pre-extended long enough to receive any result that might be written into a string. You can't use a string literal (or other read-only string) as an argument to \"syscall\" because Perl has to assume that any string pointer might be written through. If your integer arguments are not literals and have never been interpreted in a numeric context, you may need to add 0 to them to force them to look like numbers. This emulates the \"syswrite\" function (or vice versa): require 'syscall.ph';               # may need to run h2ph\n$s = \"hi there\\n\";\nsyscall(&SYS_write, fileno(STDOUT), $s, length $s); Note that Perl supports passing of up to only 14 arguments to your system call, which in practice should usually suffice. Syscall returns whatever value returned by the system call it calls. If the system call fails, \"syscall\" returns \"-1\" and sets $! (errno). Note that some system calls can legitimately return \"-1\". The proper way to handle such calls is to assign \"$!=0;\" before the call and check the value of $! if syscall returns \"-1\". There's a problem with \"syscall(&SYS_pipe)\": it returns the file number of the read end of the pipe it creates. There is no way to retrieve the file number of the other end. You can avoid this problem by using \"pipe\" instead. sysopen FILEHANDLE ,FILENAME,MODE sysopen FILEHANDLE ,FILENAME,MODE,PERMS Opens the file whose filename is given by FILENAME , and associates it with FILEHANDLE . If FILEHANDLE is an expression, its value is used as the name of the real filehandle wanted. This function calls the underlying operating system's \"open\" function with the parameters FILENAME , MODE , PERMS . The possible values and flag bits of the MODE parameter are system-dependent; they are available via the standard module \"Fcntl\". See the documentation of your operating system's \"open\" to see which values and flag bits are available. You may combine several flags using the \"|\"-operator. Some of the most common values are \"O_RDONLY\" for opening the file in read-only mode, \"O_WRONLY\" for opening the file in write-only mode, and \"O_RDWR\" for opening the file in read-write mode. For historical reasons, some values work on almost every system supported by perl: zero means read-only, one means write-only, and two means read\/write. We know that these values do not work under OS\/390 & VM\/ESA Unix and on the Macintosh; you probably don't want to use them in new code. If the file named by FILENAME does not exist and the \"open\" call creates it (typically because MODE includes the \"O_CREAT\" flag), then the value of PERMS specifies the permissions of the newly created file. If you omit the PERMS argument to \"sysopen\", Perl uses the octal value 0666. These permission values need to be in octal, and are modified by your process's current \"umask\". In many systems the \"O_EXCL\" flag is available for opening files in exclusive mode. This is not locking: exclusiveness means here that if the file already exists, sysopen() fails. \"O_EXCL\" may not work on network filesystems, and has no effect unless the \"O_CREAT\" flag is set as well. Setting \"O_CREAT|O_EXCL\" prevents the file from being opened if it is a symbolic link. It does not protect against symbolic links in the file's path. Sometimes you may want to truncate an already-existing file. This can be done using the \"O_TRUNC\" flag. The behavior of \"O_TRUNC\" with \"O_RDONLY\" is undefined. You should seldom if ever use 0644 as argument to \"sysopen\", because that takes away the user's option to have a more permissive umask. Better to omit it. See the perlfunc(1) entry on \"umask\" for more on this. Note that \"sysopen\" depends on the fdopen() C library function. On many UNIX systems, fdopen() is known to fail when file descriptors exceed a certain value, typically 255. If you need more file descriptors than that, consider rebuilding Perl to use the \"sfio\" library, or perhaps using the POSIX::open() function. See perlopentut for a kinder, gentler explanation of opening files. sysread FILEHANDLE ,SCALAR,LENGTH,OFFSET sysread FILEHANDLE ,SCALAR,LENGTH Attempts to read LENGTH bytes of data into variable SCALAR from the specified FILEHANDLE , using the system call read(2). It bypasses buffered IO , so mixing this with other kinds of reads, \"print\", \"write\", \"seek\", \"tell\", or \"eof\" can cause confusion because the perlio or stdio layers usually buffers data. Returns the number of bytes actually read, 0 at end of file, or undef if there was an error (in the latter case $! is also set). SCALAR will be grown or shrunk so that the last byte actually read is the last byte of the scalar after the read. An OFFSET may be specified to place the read data at some place in the string other than the beginning. A negative OFFSET specifies placement at that many characters counting backwards from the end of the string. A positive OFFSET greater than the length of SCALAR results in the string being padded to the required size with \"\\0\" bytes before the result of the read is appended. There is no syseof() function, which is ok, since eof() doesn't work very well on device files (like ttys) anyway. Use sysread() and check for a return value for 0 to decide whether you're done. Note that if the filehandle has been marked as \":utf8\" Unicode characters are read instead of bytes (the LENGTH , OFFSET , and the return value of sysread() are in Unicode characters). The \":encoding(...)\" layer implicitly introduces the \":utf8\" layer. See \"binmode\", \"open\", and the \"open\" pragma, open. sysseek FILEHANDLE ,POSITION,WHENCE Sets FILEHANDLE 's system position in bytes using the system call lseek(2). FILEHANDLE may be an expression whose value gives the name of the filehandle. The values for WHENCE are 0 to set the new position to POSITION , 1 to set the it to the current position plus POSITION , and 2 to set it to EOF plus POSITION (typically negative). Note the in bytes: even if the filehandle has been set to operate on characters (for example by using the \":encoding(utf8)\" I\/O layer), tell() will return byte offsets, not character offsets (because implementing that would render sysseek() very slow). sysseek() bypasses normal buffered IO , so mixing this with reads (other than \"sysread\", for example \"<>\" or read()) \"print\", \"write\", \"seek\", \"tell\", or \"eof\" may cause confusion. For WHENCE , you may also use the constants \"SEEK_SET\", \"SEEK_CUR\", and \"SEEK_END\" (start of the file, current position, end of the file) from the Fcntl module. Use of the constants is also more portable than relying on 0, 1, and 2. For example to define a \"systell\" function: use Fcntl 'SEEK_CUR';\nsub systell { sysseek($_[0], 0, SEEK_CUR) } Returns the new position, or the undefined value on failure. A position of zero is returned as the string \"0 but true\"; thus \"sysseek\" returns true on success and false on failure, yet you can still easily determine the new position. system LIST system PROGRAM LIST Does exactly the same thing as \"exec LIST\", except that a fork is done first, and the parent process waits for the child process to complete. Note that argument processing varies depending on the number of arguments. If there is more than one argument in LIST , or if LIST is an array with more than one value, starts the program given by the first element of the list with arguments given by the rest of the list. If there is only one scalar argument, the argument is checked for shell metacharacters, and if there are any, the entire argument is passed to the system's command shell for parsing (this is \"\/bin\/sh -c\" on Unix platforms, but varies on other platforms). If there are no shell metacharacters in the argument, it is split into words and passed directly to \"execvp\", which is more efficient. Beginning with v5.6.0, Perl will attempt to flush all files opened for output before any operation that may do a fork, but this may not be supported on some platforms (see perlport). To be safe, you may need to set $| ($AUTOFLUSH in English) or call the \"autoflush()\" method of \"IO::Handle\" on any open handles. The return value is the exit status of the program as returned by the \"wait\" call. To get the actual exit value, shift right by eight (see below). See also \"exec\". This is not what you want to use to capture the output from a command, for that you should use merely backticks or \"qx\/\/\", as described in \"'STRING'\" in perlop. Return value of -1 indicates a failure to start the program or an error of the wait(2) system call (inspect $! for the reason). If you'd like to make \"system\" (and many other bits of Perl) die on error, have a look at the autodie pragma. Like \"exec\", \"system\" allows you to lie to a program about its name if you use the \"system PROGRAM LIST\" syntax. Again, see \"exec\". Since \"SIGINT\" and \"SIGQUIT\" are ignored during the execution of \"system\", if you expect your program to terminate on receipt of these signals you will need to arrange to do so yourself based on the return value. @args = (\"command\", \"arg1\", \"arg2\");\nsystem(@args) == 0\n     or die \"system @args failed: $?\" If you'd like to manually inspect \"system\"'s failure, you can check all possible failure modes by inspecting $? like this: if ($? == -1) {\n    print \"failed to execute: $!\\n\";\n}\nelsif ($? & 127) {\n    printf \"child died with signal %d, %s coredump\\n\",\n        ($? & 127),  ($? & 128) ? 'with' : 'without';\n}\nelse {\n    printf \"child exited with value %d\\n\", $? >> 8;\n} Alternatively you might inspect the value of \"${^CHILD_ERROR_NATIVE}\" with the W*() calls of the POSIX extension. When the arguments get executed via the system shell, results and return codes will be subject to its quirks and capabilities. See \"'STRING'\" in perlop and \"exec\" for details. syswrite FILEHANDLE ,SCALAR,LENGTH,OFFSET syswrite FILEHANDLE ,SCALAR,LENGTH syswrite FILEHANDLE ,SCALAR Attempts to write LENGTH bytes of data from variable SCALAR to the specified FILEHANDLE , using the system call write(2). If LENGTH is not specified, writes whole SCALAR . It bypasses buffered IO , so mixing this with reads (other than sysread()), \"print\", \"write\", \"seek\", \"tell\", or \"eof\" may cause confusion because the perlio and stdio layers usually buffers data. Returns the number of bytes actually written, or \"undef\" if there was an error (in this case the errno variable $! is also set). If the LENGTH is greater than the available data in the SCALAR after the OFFSET , only as much data as is available will be written. An OFFSET may be specified to write the data from some part of the string other than the beginning. A negative OFFSET specifies writing that many characters counting backwards from the end of the string. In the case the SCALAR is empty you can use OFFSET but only zero offset. Note that if the filehandle has been marked as \":utf8\", Unicode characters are written instead of bytes (the LENGTH , OFFSET , and the return value of syswrite() are in UTF-8 encoded Unicode characters). The \":encoding(...)\" layer implicitly introduces the \":utf8\" layer. See \"binmode\", \"open\", and the \"open\" pragma, open. tell FILEHANDLE tell Returns the current position in bytes for FILEHANDLE , or -1 on error. FILEHANDLE may be an expression whose value gives the name of the actual filehandle. If FILEHANDLE is omitted, assumes the file last read. Note the in bytes: even if the filehandle has been set to operate on characters (for example by using the \":encoding(utf8)\" open layer), tell() will return byte offsets, not character offsets (because that would render seek() and tell() rather slow). The return value of tell() for the standard streams like the STDIN depends on the operating system: it may return -1 or something else. tell() on pipes, fifos, and sockets usually returns -1. There is no \"systell\" function. Use \"sysseek(FH, 0, 1)\" for that. Do not use tell() (or other buffered I\/O operations) on a file handle that has been manipulated by sysread(), syswrite() or sysseek(). Those functions ignore the buffering, while tell() does not. telldir DIRHANDLE Returns the current position of the \"readdir\" routines on DIRHANDLE . Value may be given to \"seekdir\" to access a particular location in a directory. \"telldir\" has the same caveats about possible directory compaction as the corresponding system library routine. tie VARIABLE ,CLASSNAME,LIST This function binds a variable to a package class that will provide the implementation for the variable. VARIABLE is the name of the variable to be enchanted. CLASSNAME is the name of a class implementing objects of correct type. Any additional arguments are passed to the \"new\" method of the class (meaning \"TIESCALAR\", \"TIEHANDLE\", \"TIEARRAY\", or \"TIEHASH\"). Typically these are arguments such as might be passed to the \"dbm_open()\" function of C. The object returned by the \"new\" method is also returned by the \"tie\" function, which would be useful if you want to access other methods in CLASSNAME . Note that functions such as \"keys\" and \"values\" may return huge lists when used on large objects, like DBM files. You may prefer to use the \"each\" function to iterate over such. Example: # print out history file offsets\nuse NDBM_File;\ntie(%HIST, 'NDBM_File', '\/usr\/lib\/news\/history', 1, 0);\nwhile (($key,$val) = each %HIST) {\n    print $key, ' = ', unpack('L',$val), \"\\n\";\n}\nuntie(%HIST); A class implementing a hash should have the following methods: TIEHASH classname, LIST\nFETCH this, key\nSTORE this, key, value\nDELETE this, key\nCLEAR this\nEXISTS this, key\nFIRSTKEY this\nNEXTKEY this, lastkey\nSCALAR this\nDESTROY this\nUNTIE this A class implementing an ordinary array should have the following methods: TIEARRAY classname, LIST\nFETCH this, key\nSTORE this, key, value\nFETCHSIZE this\nSTORESIZE this, count\nCLEAR this\nPUSH this, LIST\nPOP this\nSHIFT this\nUNSHIFT this, LIST\nSPLICE this, offset, length, LIST\nEXTEND this, count\nDESTROY this\nUNTIE this A class implementing a file handle should have the following methods: TIEHANDLE classname, LIST\nREAD this, scalar, length, offset\nREADLINE this\nGETC this\nWRITE this, scalar, length, offset\nPRINT this, LIST\nPRINTF this, format, LIST\nBINMODE this\nEOF this\nFILENO this\nSEEK this, position, whence\nTELL this\nOPEN this, mode, LIST\nCLOSE this\nDESTROY this\nUNTIE this A class implementing a scalar should have the following methods: TIESCALAR classname, LIST\nFETCH this,\nSTORE this, value\nDESTROY this\nUNTIE this Not all methods indicated above need be implemented. See perltie, Tie::Hash, Tie::Array, Tie::Scalar, and Tie::Handle. Unlike \"dbmopen\", the \"tie\" function will not use or require a module for you--you need to do that explicitly yourself. See DB_File or the Config module for interesting \"tie\" implementations. For further details see perltie, \"tied VARIABLE \". tied VARIABLE Returns a reference to the object underlying VARIABLE (the same value that was originally returned by the \"tie\" call that bound the variable to a package.) Returns the undefined value if VARIABLE isn't tied to a package. time Returns the number of non-leap seconds since whatever time the system considers to be the epoch, suitable for feeding to \"gmtime\" and \"localtime\". On most systems the epoch is 00:00:00 UTC , January 1, 1970; a prominent exception being Mac OS Classic which uses 00:00:00, January 1, 1904 in the current local time zone for its epoch. For measuring time in better granularity than one second, you may use either the Time::HiRes module (from CPAN , and starting from Perl 5.8 part of the standard distribution), or if you have gettimeofday(2), you may be able to use the \"syscall\" interface of Perl. See perlfaq8 for details. For date and time processing look at the many related modules on CPAN . For a comprehensive date and time representation look at the DateTime module. times Returns a four-element list giving the user and system times, in seconds, for this process and the children of this process. ($user,$system,$cuser,$csystem) = times; In scalar context, \"times\" returns $user. Note that times for children are included only after they terminate. tr\/\/\/ The transliteration operator. Same as \"y\/\/\/\". See \"Quote and Quote-like Operators\" in perlop. truncate FILEHANDLE ,LENGTH truncate EXPR ,LENGTH Truncates the file opened on FILEHANDLE , or named by EXPR , to the specified length. Produces a fatal error if truncate isn't implemented on your system. Returns true if successful, the undefined value otherwise. The behavior is undefined if LENGTH is greater than the length of the file. The position in the file of FILEHANDLE is left unchanged. You may want to call seek before writing to the file. uc EXPR uc Returns an uppercased version of EXPR . This is the internal function implementing the \"\\U\" escape in double-quoted strings. Respects current LC_CTYPE locale if \"use locale\" in force. See perllocale and perlunicode for more details about locale and Unicode support. It does not attempt to do titlecase mapping on initial letters. See \"ucfirst\" for that. If EXPR is omitted, uses $_. ucfirst EXPR ucfirst Returns the value of EXPR with the first character in uppercase (titlecase in Unicode). This is the internal function implementing the \"\\u\" escape in double-quoted strings. Respects current LC_CTYPE locale if \"use locale\" in force. See perllocale and perlunicode for more details about locale and Unicode support. If EXPR is omitted, uses $_. umask EXPR umask Sets the umask for the process to EXPR and returns the previous value. If EXPR is omitted, merely returns the current umask. The Unix permission \"rwxr-x---\" is represented as three sets of three bits, or three octal digits: 0750 (the leading 0 indicates octal and isn't one of the digits). The \"umask\" value is such a number representing disabled permissions bits. The permission (or \"mode\") values you pass \"mkdir\" or \"sysopen\" are modified by your umask, so even if you tell \"sysopen\" to create a file with permissions 0777, if your umask is 0022 then the file will actually be created with permissions 0755. If your \"umask\" were 0027 (group can't write; others can't read, write, or execute), then passing \"sysopen\" 0666 would create a file with mode 0640 ( \"0666 &~ 027\" is 0640). Here's some advice: supply a creation mode of 0666 for regular files (in \"sysopen\") and one of 0777 for directories (in \"mkdir\") and executable files. This gives users the freedom of choice: if they want protected files, they might choose process umasks of 022, 027, or even the particularly antisocial mask of 077. Programs should rarely if ever make policy decisions better left to the user. The exception to this is when writing files that should be kept private: mail files, web browser cookies, .rhosts files, and so on. If umask(2) is not implemented on your system and you are trying to restrict access for yourself (i.e., ( EXPR & 0700) > 0), produces a fatal error at run time. If umask(2) is not implemented and you are not trying to restrict access for yourself, returns \"undef\". Remember that a umask is a number, usually given in octal; it is not a string of octal digits. See also \"oct\", if all you have is a string. undef EXPR undef Undefines the value of EXPR , which must be an lvalue. Use only on a scalar value, an array (using \"@\"), a hash (using \"%\"), a subroutine (using \"&\"), or a typeglob (using \"*\"). (Saying \"undef $hash{$key}\" will probably not do what you expect on most predefined variables or DBM list values, so don't do that; see delete.) Always returns the undefined value. You can omit the EXPR , in which case nothing is undefined, but you still get an undefined value that you could, for instance, return from a subroutine, assign to a variable or pass as a parameter. Examples: undef $foo;\nundef $bar{'blurfl'};      # Compare to: delete $bar{'blurfl'};\nundef @ary;\nundef %hash;\nundef &mysub;\nundef *xyz;       # destroys $xyz, @xyz, %xyz, &xyz, etc.\nreturn (wantarray ? (undef, $errmsg) : undef) if $they_blew_it;\nselect undef, undef, undef, 0.25;\n($a, $b, undef, $c) = &foo;       # Ignore third value returned Note that this is a unary operator, not a list operator. unlink LIST unlink Deletes a list of files. Returns the number of files successfully deleted. $cnt = unlink 'a', 'b', 'c';\nunlink @goners;\nunlink <*.bak>; Note: \"unlink\" will not attempt to delete directories unless you are superuser and the -U flag is supplied to Perl. Even if these conditions are met, be warned that unlinking a directory can inflict damage on your filesystem. Finally, using \"unlink\" on directories is not supported on many operating systems. Use \"rmdir\" instead. If LIST is omitted, uses $_. unpack TEMPLATE ,EXPR unpack TEMPLATE \"unpack\" does the reverse of \"pack\": it takes a string and expands it out into a list of values. (In scalar context, it returns merely the first value produced.) If EXPR is omitted, unpacks the $_ string. The string is broken into chunks described by the TEMPLATE . Each chunk is converted separately to a value. Typically, either the string is a result of \"pack\", or the characters of the string represent a C structure of some kind. The TEMPLATE has the same format as in the \"pack\" function. Here's a subroutine that does substring: sub substr {\n    my($what,$where,$howmuch) = @_;\n    unpack(\"x$where a$howmuch\", $what);\n} and then there's sub ordinal { unpack(\"W\",$_[0]); } # same as ord() In addition to fields allowed in pack(), you may prefix a field with a %<number> to indicate that you want a <number>-bit checksum of the items instead of the items themselves. Default is a 16-bit checksum. Checksum is calculated by summing numeric values of expanded values (for string fields the sum of \"ord($char)\" is taken, for bit fields the sum of zeroes and ones). For example, the following computes the same number as the System V sum program: $checksum = do {\n    local $\/;  # slurp!\n    unpack(\"%32W*\",<>) % 65535;\n}; The following efficiently counts the number of set bits in a bit vector: $setbits = unpack(\"%32b*\", $selectmask); The \"p\" and \"P\" formats should be used with care. Since Perl has no way of checking whether the value passed to \"unpack()\" corresponds to a valid memory location, passing a pointer value that's not known to be valid is likely to have disastrous consequences. If there are more pack codes or if the repeat count of a field or a group is larger than what the remainder of the input string allows, the result is not well defined: in some cases, the repeat count is decreased, or \"unpack()\" will produce null strings or zeroes, or terminate with an error. If the input string is longer than one described by the TEMPLATE , the rest is ignored. See \"pack\" for more examples and notes. untie VARIABLE Breaks the binding between a variable and a package. (See \"tie\".) Has no effect if the variable is not tied. unshift ARRAY ,LIST Does the opposite of a \"shift\". Or the opposite of a \"push\", depending on how you look at it. Prepends list to the front of the array, and returns the new number of elements in the array. unshift(@ARGV, '-e') unless $ARGV[0] =~ \/^-\/; Note the LIST is prepended whole, not one element at a time, so the prepended elements stay in the same order. Use \"reverse\" to do the reverse. use Module VERSION LIST use Module VERSION use Module LIST use Module use VERSION Imports some semantics into the current package from the named module, generally by aliasing certain subroutine or variable names into your package. It is exactly equivalent to BEGIN { require Module; Module->import( LIST ); } except that Module must be a bareword. In the peculiar \"use VERSION\" form, VERSION may be either a numeric argument such as 5.006, which will be compared to $], or a literal of the form v5.6.1, which will be compared to $^V (aka $PERL_VERSION). A fatal error is produced if VERSION is greater than the version of the current Perl interpreter; Perl will not attempt to parse the rest of the file. Compare with \"require\", which can do a similar check at run time. Symmetrically, \"no VERSION\" allows you to specify that you want a version of perl older than the specified one. Specifying VERSION as a literal of the form v5.6.1 should generally be avoided, because it leads to misleading error messages under earlier versions of Perl (that is, prior to 5.6.0) that do not support this syntax. The equivalent numeric version should be used instead. use v5.6.1;         # compile time version check\nuse 5.6.1;          # ditto\nuse 5.006_001;      # ditto; preferred for backwards compatibility This is often useful if you need to check the current Perl version before \"use\"ing library modules that won't work with older versions of Perl. (We try not to do this more than we have to.) Also, if the specified perl version is greater than or equal to 5.9.5, \"use VERSION\" will also load the \"feature\" pragma and enable all features available in the requested version. See feature. The \"BEGIN\" forces the \"require\" and \"import\" to happen at compile time. The \"require\" makes sure the module is loaded into memory if it hasn't been yet. The \"import\" is not a builtin--it's just an ordinary static method call into the \"Module\" package to tell the module to import the list of features back into the current package. The module can implement its \"import\" method any way it likes, though most modules just choose to derive their \"import\" method via inheritance from the \"Exporter\" class that is defined in the \"Exporter\" module. See Exporter. If no \"import\" method can be found then the call is skipped, even if there is an AUTOLOAD method. If you do not want to call the package's \"import\" method (for instance, to stop your namespace from being altered), explicitly supply the empty list: use Module (); That is exactly equivalent to BEGIN { require Module } If the VERSION argument is present between Module and LIST , then the \"use\" will call the VERSION method in class Module with the given version as an argument. The default VERSION method, inherited from the UNIVERSAL class, croaks if the given version is larger than the value of the variable $Module::VERSION. Again, there is a distinction between omitting LIST (\"import\" called with no arguments) and an explicit empty LIST \"()\" (\"import\" not called). Note that there is no comma after VERSION ! Because this is a wide-open interface, pragmas (compiler directives) are also implemented this way. Currently implemented pragmas are: use constant;\nuse diagnostics;\nuse integer;\nuse sigtrap  qw(SEGV BUS);\nuse strict   qw(subs vars refs);\nuse subs     qw(afunc blurfl);\nuse warnings qw(all);\nuse sort     qw(stable _quicksort _mergesort); Some of these pseudo-modules import semantics into the current block scope (like \"strict\" or \"integer\", unlike ordinary modules, which import symbols into the current package (which are effective through the end of the file). There's a corresponding \"no\" command that unimports meanings imported by \"use\", i.e., it calls \"unimport Module LIST\" instead of \"import\". It behaves exactly as \"import\" does with respect to VERSION , an omitted LIST , empty LIST , or no unimport method being found. no integer;\nno strict 'refs';\nno warnings; See perlmodlib for a list of standard modules and pragmas. See perlrun for the \"-M\" and \"-m\" command-line options to perl that give \"use\" functionality from the command-line. utime LIST Changes the access and modification times on each file of a list of files. The first two elements of the list must be the NUMERICAL access and modification times, in that order. Returns the number of files successfully changed. The inode change time of each file is set to the current time. For example, this code has the same effect as the Unix touch(1) command when the files already exist and belong to the user running the program: #!\/usr\/bin\/perl\n$atime = $mtime = time;\nutime $atime, $mtime, @ARGV; Since perl 5.7.2, if the first two elements of the list are \"undef\", then the utime(2) function in the C library will be called with a null second argument. On most systems, this will set the file's access and modification times to the current time (i.e. equivalent to the example above) and will even work on other users' files where you have write permission: utime undef, undef, @ARGV; Under NFS this will use the time of the NFS server, not the time of the local machine. If there is a time synchronization problem, the NFS server and local machine will have different times. The Unix touch(1) command will in fact normally use this form instead of the one shown in the first example. Note that only passing one of the first two elements as \"undef\" will be equivalent of passing it as 0 and will not have the same effect as described when they are both \"undef\". This case will also trigger an uninitialized warning. On systems that support futimes, you might pass file handles among the files. On systems that don't support futimes, passing file handles produces a fatal error at run time. The file handles must be passed as globs or references to be recognized. Barewords are considered file names. values HASH Returns a list consisting of all the values of the named hash. (In a scalar context, returns the number of values.) The values are returned in an apparently random order. The actual random order is subject to change in future versions of perl, but it is guaranteed to be the same order as either the \"keys\" or \"each\" function would produce on the same (unmodified) hash. Since Perl 5.8.1 the ordering is different even between different runs of Perl for security reasons (see \"Algorithmic Complexity Attacks\" in perlsec). As a side effect, calling values() resets the HASH 's internal iterator, see \"each\". (In particular, calling values() in void context resets the iterator with no other overhead.) Note that the values are not copied, which means modifying them will modify the contents of the hash: for (values %hash)      { s\/foo\/bar\/g }   # modifies %hash values\nfor (@hash{keys %hash}) { s\/foo\/bar\/g }   # same See also \"keys\", \"each\", and \"sort\". vec EXPR ,OFFSET,BITS Treats the string in EXPR as a bit vector made up of elements of width BITS , and returns the value of the element specified by OFFSET as an unsigned integer. BITS therefore specifies the number of bits that are reserved for each element in the bit vector. This must be a power of two from 1 to 32 (or 64, if your platform supports that). If BITS is 8, \"elements\" coincide with bytes of the input string. If BITS is 16 or more, bytes of the input string are grouped into chunks of size BITS\/8 , and each group is converted to a number as with pack()\/unpack() with big-endian formats \"n\"\/\"N\" (and analogously for BITS==64). See \"pack\" for details. If bits is 4 or less, the string is broken into bytes, then the bits of each byte are broken into 8\/BITS groups. Bits of a byte are numbered in a little-endian-ish way, as in 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80. For example, breaking the single input byte \"chr(0x36)\" into two groups gives a list \"(0x6, 0x3)\"; breaking it into 4 groups gives \"(0x2, 0x1, 0x3, 0x0)\". \"vec\" may also be assigned to, in which case parentheses are needed to give the expression the correct precedence as in vec($image, $max_x * $x + $y, 8) = 3; If the selected element is outside the string, the value 0 is returned. If an element off the end of the string is written to, Perl will first extend the string with sufficiently many zero bytes. It is an error to try to write off the beginning of the string (i.e. negative OFFSET ). If the string happens to be encoded as UTF-8 internally (and thus has the UTF8 flag set), this is ignored by \"vec\", and it operates on the internal byte string, not the conceptual character string, even if you only have characters with values less than 256. Strings created with \"vec\" can also be manipulated with the logical operators \"|\", \"&\", \"^\", and \"~\". These operators will assume a bit vector operation is desired when both operands are strings. See \"Bitwise String Operators\" in perlop. The following code will build up an ASCII string saying 'PerlPerlPerl'. The comments show the string after each step. Note that this code works in the same way on big-endian or little-endian machines. my $foo = '';\nvec($foo,  0, 32) = 0x5065726C;     # 'Perl'\n\n# $foo eq \"Perl\" eq \"\\x50\\x65\\x72\\x6C\", 32 bits\nprint vec($foo, 0, 8);              # prints 80 == 0x50 == ord('P')\n\nvec($foo,  2, 16) = 0x5065;         # 'PerlPe'\nvec($foo,  3, 16) = 0x726C;         # 'PerlPerl'\nvec($foo,  8,  8) = 0x50;           # 'PerlPerlP'\nvec($foo,  9,  8) = 0x65;           # 'PerlPerlPe'\nvec($foo, 20,  4) = 2;              # 'PerlPerlPe'   . \"\\x02\"\nvec($foo, 21,  4) = 7;              # 'PerlPerlPer'\n                                    # 'r' is \"\\x72\"\nvec($foo, 45,  2) = 3;              # 'PerlPerlPer'  . \"\\x0c\"\nvec($foo, 93,  1) = 1;              # 'PerlPerlPer'  . \"\\x2c\"\nvec($foo, 94,  1) = 1;              # 'PerlPerlPerl'\n                                    # 'l' is \"\\x6c\" To transform a bit vector into a string or list of 0's and 1's, use these: $bits = unpack(\"b*\", $vector);\n@bits = split(\/\/, unpack(\"b*\", $vector)); If you know the exact length in bits, it can be used in place of the \"*\". Here is an example to illustrate how the bits actually fall in place: #!\/usr\/bin\/perl -wl\n\nprint <<'EOT';\n                                  0         1         2         3\n                   unpack(\"V\",$_) 01234567890123456789012345678901\n------------------------------------------------------------------\nEOT\n\nfor $w (0..3) {\n    $width = 2**$w;\n    for ($shift=0; $shift < $width; ++$shift) {\n        for ($off=0; $off < 32\/$width; ++$off) {\n            $str = pack(\"B*\", \"0\"x32);\n            $bits = (1<<$shift);\n            vec($str, $off, $width) = $bits;\n            $res = unpack(\"b*\",$str);\n            $val = unpack(\"V\", $str);\n            write;\n        }\n    }\n}\n\nformat STDOUT =\nvec($_,@#,@#) = @<< == @######### @>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n$off, $width, $bits, $val, $res\n.\n__END__ Regardless of the machine architecture on which it is run, the above example should print the following table:                                   0         1         2         3\n                   unpack(\"V\",$_) 01234567890123456789012345678901\n------------------------------------------------------------------\nvec($_, 0, 1) = 1   ==          1 10000000000000000000000000000000\nvec($_, 1, 1) = 1   ==          2 01000000000000000000000000000000\nvec($_, 2, 1) = 1   ==          4 00100000000000000000000000000000\nvec($_, 3, 1) = 1   ==          8 00010000000000000000000000000000\nvec($_, 4, 1) = 1   ==         16 00001000000000000000000000000000\nvec($_, 5, 1) = 1   ==         32 00000100000000000000000000000000\nvec($_, 6, 1) = 1   ==         64 00000010000000000000000000000000\nvec($_, 7, 1) = 1   ==        128 00000001000000000000000000000000\nvec($_, 8, 1) = 1   ==        256 00000000100000000000000000000000\nvec($_, 9, 1) = 1   ==        512 00000000010000000000000000000000\nvec($_,10, 1) = 1   ==       1024 00000000001000000000000000000000\nvec($_,11, 1) = 1   ==       2048 00000000000100000000000000000000\nvec($_,12, 1) = 1   ==       4096 00000000000010000000000000000000\nvec($_,13, 1) = 1   ==       8192 00000000000001000000000000000000\nvec($_,14, 1) = 1   ==      16384 00000000000000100000000000000000\nvec($_,15, 1) = 1   ==      32768 00000000000000010000000000000000\nvec($_,16, 1) = 1   ==      65536 00000000000000001000000000000000\nvec($_,17, 1) = 1   ==     131072 00000000000000000100000000000000\nvec($_,18, 1) = 1   ==     262144 00000000000000000010000000000000\nvec($_,19, 1) = 1   ==     524288 00000000000000000001000000000000\nvec($_,20, 1) = 1   ==    1048576 00000000000000000000100000000000\nvec($_,21, 1) = 1   ==    2097152 00000000000000000000010000000000\nvec($_,22, 1) = 1   ==    4194304 00000000000000000000001000000000\nvec($_,23, 1) = 1   ==    8388608 00000000000000000000000100000000\nvec($_,24, 1) = 1   ==   16777216 00000000000000000000000010000000\nvec($_,25, 1) = 1   ==   33554432 00000000000000000000000001000000\nvec($_,26, 1) = 1   ==   67108864 00000000000000000000000000100000\nvec($_,27, 1) = 1   ==  134217728 00000000000000000000000000010000\nvec($_,28, 1) = 1   ==  268435456 00000000000000000000000000001000\nvec($_,29, 1) = 1   ==  536870912 00000000000000000000000000000100\nvec($_,30, 1) = 1   == 1073741824 00000000000000000000000000000010\nvec($_,31, 1) = 1   == 2147483648 00000000000000000000000000000001\nvec($_, 0, 2) = 1   ==          1 10000000000000000000000000000000\nvec($_, 1, 2) = 1   ==          4 00100000000000000000000000000000\nvec($_, 2, 2) = 1   ==         16 00001000000000000000000000000000\nvec($_, 3, 2) = 1   ==         64 00000010000000000000000000000000\nvec($_, 4, 2) = 1   ==        256 00000000100000000000000000000000\nvec($_, 5, 2) = 1   ==       1024 00000000001000000000000000000000\nvec($_, 6, 2) = 1   ==       4096 00000000000010000000000000000000\nvec($_, 7, 2) = 1   ==      16384 00000000000000100000000000000000\nvec($_, 8, 2) = 1   ==      65536 00000000000000001000000000000000\nvec($_, 9, 2) = 1   ==     262144 00000000000000000010000000000000\nvec($_,10, 2) = 1   ==    1048576 00000000000000000000100000000000\nvec($_,11, 2) = 1   ==    4194304 00000000000000000000001000000000\nvec($_,12, 2) = 1   ==   16777216 00000000000000000000000010000000\nvec($_,13, 2) = 1   ==   67108864 00000000000000000000000000100000\nvec($_,14, 2) = 1   ==  268435456 00000000000000000000000000001000\nvec($_,15, 2) = 1   == 1073741824 00000000000000000000000000000010\nvec($_, 0, 2) = 2   ==          2 01000000000000000000000000000000\nvec($_, 1, 2) = 2   ==          8 00010000000000000000000000000000\nvec($_, 2, 2) = 2   ==         32 00000100000000000000000000000000\nvec($_, 3, 2) = 2   ==        128 00000001000000000000000000000000\nvec($_, 4, 2) = 2   ==        512 00000000010000000000000000000000\nvec($_, 5, 2) = 2   ==       2048 00000000000100000000000000000000\nvec($_, 6, 2) = 2   ==       8192 00000000000001000000000000000000\nvec($_, 7, 2) = 2   ==      32768 00000000000000010000000000000000\nvec($_, 8, 2) = 2   ==     131072 00000000000000000100000000000000\nvec($_, 9, 2) = 2   ==     524288 00000000000000000001000000000000\nvec($_,10, 2) = 2   ==    2097152 00000000000000000000010000000000\nvec($_,11, 2) = 2   ==    8388608 00000000000000000000000100000000\nvec($_,12, 2) = 2   ==   33554432 00000000000000000000000001000000\nvec($_,13, 2) = 2   ==  134217728 00000000000000000000000000010000\nvec($_,14, 2) = 2   ==  536870912 00000000000000000000000000000100\nvec($_,15, 2) = 2   == 2147483648 00000000000000000000000000000001\nvec($_, 0, 4) = 1   ==          1 10000000000000000000000000000000\nvec($_, 1, 4) = 1   ==         16 00001000000000000000000000000000\nvec($_, 2, 4) = 1   ==        256 00000000100000000000000000000000\nvec($_, 3, 4) = 1   ==       4096 00000000000010000000000000000000\nvec($_, 4, 4) = 1   ==      65536 00000000000000001000000000000000\nvec($_, 5, 4) = 1   ==    1048576 00000000000000000000100000000000\nvec($_, 6, 4) = 1   ==   16777216 00000000000000000000000010000000\nvec($_, 7, 4) = 1   ==  268435456 00000000000000000000000000001000\nvec($_, 0, 4) = 2   ==          2 01000000000000000000000000000000\nvec($_, 1, 4) = 2   ==         32 00000100000000000000000000000000\nvec($_, 2, 4) = 2   ==        512 00000000010000000000000000000000\nvec($_, 3, 4) = 2   ==       8192 00000000000001000000000000000000\nvec($_, 4, 4) = 2   ==     131072 00000000000000000100000000000000\nvec($_, 5, 4) = 2   ==    2097152 00000000000000000000010000000000\nvec($_, 6, 4) = 2   ==   33554432 00000000000000000000000001000000\nvec($_, 7, 4) = 2   ==  536870912 00000000000000000000000000000100\nvec($_, 0, 4) = 4   ==          4 00100000000000000000000000000000\nvec($_, 1, 4) = 4   ==         64 00000010000000000000000000000000\nvec($_, 2, 4) = 4   ==       1024 00000000001000000000000000000000\nvec($_, 3, 4) = 4   ==      16384 00000000000000100000000000000000\nvec($_, 4, 4) = 4   ==     262144 00000000000000000010000000000000\nvec($_, 5, 4) = 4   ==    4194304 00000000000000000000001000000000\nvec($_, 6, 4) = 4   ==   67108864 00000000000000000000000000100000\nvec($_, 7, 4) = 4   == 1073741824 00000000000000000000000000000010\nvec($_, 0, 4) = 8   ==          8 00010000000000000000000000000000\nvec($_, 1, 4) = 8   ==        128 00000001000000000000000000000000\nvec($_, 2, 4) = 8   ==       2048 00000000000100000000000000000000\nvec($_, 3, 4) = 8   ==      32768 00000000000000010000000000000000\nvec($_, 4, 4) = 8   ==     524288 00000000000000000001000000000000\nvec($_, 5, 4) = 8   ==    8388608 00000000000000000000000100000000\nvec($_, 6, 4) = 8   ==  134217728 00000000000000000000000000010000\nvec($_, 7, 4) = 8   == 2147483648 00000000000000000000000000000001\nvec($_, 0, 8) = 1   ==          1 10000000000000000000000000000000\nvec($_, 1, 8) = 1   ==        256 00000000100000000000000000000000\nvec($_, 2, 8) = 1   ==      65536 00000000000000001000000000000000\nvec($_, 3, 8) = 1   ==   16777216 00000000000000000000000010000000\nvec($_, 0, 8) = 2   ==          2 01000000000000000000000000000000\nvec($_, 1, 8) = 2   ==        512 00000000010000000000000000000000\nvec($_, 2, 8) = 2   ==     131072 00000000000000000100000000000000\nvec($_, 3, 8) = 2   ==   33554432 00000000000000000000000001000000\nvec($_, 0, 8) = 4   ==          4 00100000000000000000000000000000\nvec($_, 1, 8) = 4   ==       1024 00000000001000000000000000000000\nvec($_, 2, 8) = 4   ==     262144 00000000000000000010000000000000\nvec($_, 3, 8) = 4   ==   67108864 00000000000000000000000000100000\nvec($_, 0, 8) = 8   ==          8 00010000000000000000000000000000\nvec($_, 1, 8) = 8   ==       2048 00000000000100000000000000000000\nvec($_, 2, 8) = 8   ==     524288 00000000000000000001000000000000\nvec($_, 3, 8) = 8   ==  134217728 00000000000000000000000000010000\nvec($_, 0, 8) = 16  ==         16 00001000000000000000000000000000\nvec($_, 1, 8) = 16  ==       4096 00000000000010000000000000000000\nvec($_, 2, 8) = 16  ==    1048576 00000000000000000000100000000000\nvec($_, 3, 8) = 16  ==  268435456 00000000000000000000000000001000\nvec($_, 0, 8) = 32  ==         32 00000100000000000000000000000000\nvec($_, 1, 8) = 32  ==       8192 00000000000001000000000000000000\nvec($_, 2, 8) = 32  ==    2097152 00000000000000000000010000000000\nvec($_, 3, 8) = 32  ==  536870912 00000000000000000000000000000100\nvec($_, 0, 8) = 64  ==         64 00000010000000000000000000000000\nvec($_, 1, 8) = 64  ==      16384 00000000000000100000000000000000\nvec($_, 2, 8) = 64  ==    4194304 00000000000000000000001000000000\nvec($_, 3, 8) = 64  == 1073741824 00000000000000000000000000000010\nvec($_, 0, 8) = 128 ==        128 00000001000000000000000000000000\nvec($_, 1, 8) = 128 ==      32768 00000000000000010000000000000000\nvec($_, 2, 8) = 128 ==    8388608 00000000000000000000000100000000\nvec($_, 3, 8) = 128 == 2147483648 00000000000000000000000000000001 wait Behaves like the wait(2) system call on your system: it waits for a child process to terminate and returns the pid of the deceased process, or \"-1\" if there are no child processes. The status is returned in $? and \"${^CHILD_ERROR_NATIVE}\". Note that a return value of \"-1\" could mean that child processes are being automatically reaped, as described in perlipc. waitpid PID ,FLAGS Waits for a particular child process to terminate and returns the pid of the deceased process, or \"-1\" if there is no such child process. On some systems, a value of 0 indicates that there are processes still running. The status is returned in $? and \"${^CHILD_ERROR_NATIVE}\". If you say use POSIX \":sys_wait_h\";\n#...\ndo {\n    $kid = waitpid(-1, WNOHANG);\n} while $kid > 0; then you can do a non-blocking wait for all pending zombie processes. Non-blocking wait is available on machines supporting either the waitpid(2) or wait4(2) system calls. However, waiting for a particular pid with FLAGS of 0 is implemented everywhere. (Perl emulates the system call by remembering the status values of processes that have exited but have not been harvested by the Perl script yet.) Note that on some systems, a return value of \"-1\" could mean that child processes are being automatically reaped. See perlipc for details, and for other examples. wantarray Returns true if the context of the currently executing subroutine or \"eval\" is looking for a list value. Returns false if the context is looking for a scalar. Returns the undefined value if the context is looking for no value (void context). return unless defined wantarray;    # don't bother doing more\nmy @a = complex_calculation();\nreturn wantarray ? @a : \"@a\"; \"wantarray()\"'s result is unspecified in the top level of a file, in a \"BEGIN\", \"UNITCHECK\", \"CHECK\", \"INIT\" or \"END\" block, or in a \"DESTROY\" method. This function should have been named wantlist() instead. warn LIST Prints the value of LIST to STDERR . If the last element of LIST does not end in a newline, it appends the same file\/line number text as \"die\" does. If LIST is empty and $@ already contains a value (typically from a previous eval) that value is used after appending \"\\t...caught\" to $@. This is useful for staying almost, but not entirely similar to \"die\". If $@ is empty then the string \"Warning: Something's wrong\" is used. No message is printed if there is a $SIG{__WARN__} handler installed. It is the handler's responsibility to deal with the message as it sees fit (like, for instance, converting it into a \"die\"). Most handlers must therefore make arrangements to actually display the warnings that they are not prepared to deal with, by calling \"warn\" again in the handler. Note that this is quite safe and will not produce an endless loop, since \"__WARN__\" hooks are not called from inside one. You will find this behavior is slightly different from that of $SIG{__DIE__} handlers (which don't suppress the error text, but can instead call \"die\" again to change it). Using a \"__WARN__\" handler provides a powerful way to silence all warnings (even the so-called mandatory ones). An example: # wipe out *all* compile-time warnings\nBEGIN { $SIG{'__WARN__'} = sub { warn $_[0] if $DOWARN } }\nmy $foo = 10;\nmy $foo = 20;          # no warning about duplicate my $foo,\n                       # but hey, you asked for it!\n# no compile-time or run-time warnings before here\n$DOWARN = 1;\n\n# run-time warnings enabled after here\nwarn \"\\$foo is alive and $foo!\";     # does show up See perlvar for details on setting %SIG entries, and for more examples. See the Carp module for other kinds of warnings using its carp() and cluck() functions. write FILEHANDLE write EXPR write Writes a formatted record (possibly multi-line) to the specified FILEHANDLE , using the format associated with that file. By default the format for a file is the one having the same name as the filehandle, but the format for the current output channel (see the \"select\" function) may be set explicitly by assigning the name of the format to the $~ variable. Top of form processing is handled automatically: if there is insufficient room on the current page for the formatted record, the page is advanced by writing a form feed, a special top-of-page format is used to format the new page header, and then the record is written. By default the top-of-page format is the name of the filehandle with \"_TOP\" appended, but it may be dynamically set to the format of your choice by assigning the name to the $^ variable while the filehandle is selected. The number of lines remaining on the current page is in variable \"$-\", which can be set to 0 to force a new page. If FILEHANDLE is unspecified, output goes to the current default output channel, which starts out as STDOUT but may be changed by the \"select\" operator. If the FILEHANDLE is an EXPR , then the expression is evaluated and the resulting string is used to look up the name of the FILEHANDLE at run time. For more on formats, see perlform. Note that write is not the opposite of \"read\". Unfortunately. y\/\/\/ The transliteration operator. Same as \"tr\/\/\/\". See \"Quote and Quote-like Operators\" in perlop.","Process Name":"perlfunc","Link":"https:\/\/linux.die.net\/man\/1\/perlfunc"}},{"Process":{"Description":"A glossary of terms (technical and otherwise) used in the Perl documentation. Other useful sources include the Free On-Line Dictionary of Computing <http:\/\/foldoc.doc.ic.ac.uk\/foldoc\/index.html>, the Jargon File <http:\/\/catb.org\/~esr\/jargon\/>, and Wikipedia <http:\/\/www.wikipedia.org\/>. A accessor methods A \"method\" used to indirectly inspect or update an \"object\"'s state (its instance variables). actual arguments The scalar values that you supply to a \"function\" or \"subroutine\" when you call it. For instance, when you call \"power(\"puff\")\", the string \"puff\" is the actual argument. See also \"argument\" and \"formal arguments\". address operator Some languages work directly with the memory addresses of values, but this can be like playing with fire. Perl provides a set of asbestos gloves for handling all memory management. The closest to an address operator in Perl is the backslash operator, but it gives you a \"hard reference\", which is much safer than a memory address. algorithm A well-defined sequence of steps, clearly enough explained that even a computer could do them. alias A nickname for something, which behaves in all ways as though you'd used the original name instead of the nickname. Temporary aliases are implicitly created in the loop variable for \"foreach\" loops, in the $_ variable for map or grep operators, in $a and $b during sort's comparison function, and in each element of @_ for the \"actual arguments\" of a subroutine call. Permanent aliases are explicitly created in packages by importing symbols or by assignment to typeglobs. Lexically scoped aliases for package variables are explicitly created by the our declaration. alternatives A list of possible choices from which you may select only one, as in \"Would you like door A, B, or C?\" Alternatives in regular expressions are separated with a single vertical bar: \"|\". Alternatives in normal Perl expressions are separated with a double vertical bar: \"||\". Logical alternatives in \"Boolean\" expressions are separated with either \"||\" or \"or\". anonymous Used to describe a \"referent\" that is not directly accessible through a named \"variable\". Such a referent must be indirectly accessible through at least one \"hard reference\". When the last hard reference goes away, the anonymous referent is destroyed without pity. architecture The kind of computer you're working on, where one \"kind\" of computer means all those computers sharing a compatible machine language. Since Perl programs are (typically) simple text files, not executable images, a Perl program is much less sensitive to the architecture it's running on than programs in other languages, such as C, that are compiled into machine code. See also \"platform\" and \"operating system\". argument A piece of data supplied to a program, \"subroutine\", \"function\", or \"method\" to tell it what it's supposed to do. Also called a \"parameter\". ARGV The name of the array containing the \"argument\" \"vector\" from the command line. If you use the empty \"E<lt>E<gt>\" operator, \" ARGV \" is the name of both the \"filehandle\" used to traverse the arguments and the \"scalar\" containing the name of the current input file. arithmetical operator A \"symbol\" such as \"+\" or \"\/\" that tells Perl to do the arithmetic you were supposed to learn in grade school. array An ordered sequence of values, stored such that you can easily access any of the values using an integer \"subscript\" that specifies the value's \"offset\" in the sequence. array context An archaic expression for what is more correctly referred to as \"list context\". ASCII The American Standard Code for Information Interchange (a 7-bit character set adequate only for poorly representing English text). Often used loosely to describe the lowest 128 values of the various ISO-8859-X character sets, a bunch of mutually incompatible 8-bit codes best described as half ASCII . See also \"Unicode\". assertion A component of a \"regular expression\" that must be true for the pattern to match but does not necessarily match any characters itself. Often used specifically to mean a \"zero width\" assertion. assignment An \"operator\" whose assigned mission in life is to change the value of a \"variable\". assignment operator Either a regular \"assignment\", or a compound \"operator\" composed of an ordinary assignment and some other operator, that changes the value of a variable in place, that is, relative to its old value. For example, \"$a += 2\" adds 2 to $a. associative array See \"hash\". Please. associativity Determines whether you do the left \"operator\" first or the right \"operator\" first when you have \"A \"operator\" B \"operator\" C\" and the two operators are of the same precedence. Operators like \"+\" are left associative, while operators like \"**\" are right associative. See perlop for a list of operators and their associativity. asynchronous Said of events or activities whose relative temporal ordering is indeterminate because too many things are going on at once. Hence, an asynchronous event is one you didn't know when to expect. atom A \"regular expression\" component potentially matching a \"substring\" containing one or more characters and treated as an indivisible syntactic unit by any following \"quantifier\". (Contrast with an \"assertion\" that matches something of \"zero width\" and may not be quantified.) atomic operation When Democritus gave the word \"atom\" to the indivisible bits of matter, he meant literally something that could not be cut: a- (not) + tomos (cuttable). An atomic operation is an action that can't be interrupted, not one forbidden in a nuclear-free zone. attribute A new feature that allows the declaration of variables and subroutines with modifiers as in \"sub foo : locked method\". Also, another name for an \"instance variable\" of an \"object\". autogeneration A feature of \"operator overloading\" of objects, whereby the behavior of certain operators can be reasonably deduced using more fundamental operators. This assumes that the overloaded operators will often have the same relationships as the regular operators. See perlop. autoincrement To add one to something automatically, hence the name of the \"++\" operator. To instead subtract one from something automatically is known as an \"autodecrement\". autoload To load on demand. (Also called \"lazy\" loading.) Specifically, to call an AUTOLOAD subroutine on behalf of an undefined subroutine. autosplit To split a string automatically, as the -a \"switch\" does when running under -p or -n in order to emulate \"awk\". (See also the AutoSplit module, which has nothing to do with the -a switch, but a lot to do with autoloading.) autovivification A Greco-Roman word meaning \"to bring oneself to life\". In Perl, storage locations (lvalues) spontaneously generate themselves as needed, including the creation of any \"hard reference\" values to point to the next level of storage. The assignment \"$a[5][5][5][5][5] = \"quintet\"\" potentially creates five scalar storage locations, plus four references (in the first four scalar locations) pointing to four new anonymous arrays (to hold the last four scalar locations). But the point of autovivification is that you don't have to worry about it. AV Short for \"array value\", which refers to one of Perl's internal data types that holds an \"array\". The \" AV \" type is a subclass of \" SV \". awk Descriptive editing term--short for \"awkward\". Also coincidentally refers to a venerable text-processing language from which Perl derived some of its high-level ideas. B backreference A substring captured by a subpattern within unadorned parentheses in a \"regex\". Backslashed decimal numbers ( \"\\1\", \"\\2\", etc.) later in the same pattern refer back to the corresponding subpattern in the current match. Outside the pattern, the numbered variables ( $1, $2, etc.) continue to refer to these same values, as long as the pattern was the last successful match of the current dynamic scope. backtracking The practice of saying, \"If I had to do it all over, I'd do it differently,\" and then actually going back and doing it all over differently. Mathematically speaking, it's returning from an unsuccessful recursion on a tree of possibilities. Perl backtracks when it attempts to match patterns with a \"regular expression\", and its earlier attempts don't pan out. See \"Backtracking\" in perlre. backward compatibility Means you can still run your old program because we didn't break any of the features or bugs it was relying on. bareword A word sufficiently ambiguous to be deemed illegal under use strict 'subs'. In the absence of that stricture, a bareword is treated as if quotes were around it. base class A generic \"object\" type; that is, a \"class\" from which other, more specific classes are derived genetically by \"inheritance\". Also called a \"superclass\" by people who respect their ancestors. big-endian From Swift: someone who eats eggs big end first. Also used of computers that store the most significant \"byte\" of a word at a lower byte address than the least significant byte. Often considered superior to little-endian machines. See also \"little-endian\". binary Having to do with numbers represented in base 2. That means there's basically two numbers, 0 and 1. Also used to describe a \"non-text file\", presumably because such a file makes full use of all the binary bits in its bytes. With the advent of \"Unicode\", this distinction, already suspect, loses even more of its meaning. binary operator An \"operator\" that takes two operands. bind To assign a specific \"network address\" to a \"socket\". bit An integer in the range from 0 to 1, inclusive. The smallest possible unit of information storage. An eighth of a \"byte\" or of a dollar. (The term \"Pieces of Eight\" comes from being able to split the old Spanish dollar into 8 bits, each of which still counted for money. That's why a 25-cent piece today is still \"two bits\".) bit shift The movement of bits left or right in a computer word, which has the effect of multiplying or dividing by a power of 2. bit string A sequence of bits that is actually being thought of as a sequence of bits, for once. bless In corporate life, to grant official approval to a thing, as in, \"The VP of Engineering has blessed our WebCruncher project.\" Similarly in Perl, to grant official approval to a \"referent\" so that it can function as an \"object\", such as a WebCruncher object. See \"bless\" in perlfunc. block What a \"process\" does when it has to wait for something: \"My process blocked waiting for the disk.\" As an unrelated noun, it refers to a large chunk of data, of a size that the \"operating system\" likes to deal with (normally a power of two such as 512 or 8192). Typically refers to a chunk of data that's coming from or going to a disk file. BLOCK A syntactic construct consisting of a sequence of Perl statements that is delimited by braces. The \"if\" and \"while\" statements are defined in terms of BLOCKs, for instance. Sometimes we also say \"block\" to mean a lexical scope; that is, a sequence of statements that act like a \" BLOCK \", such as within an eval or a file, even though the statements aren't delimited by braces. block buffering A method of making input and output efficient by passing one \"block\" at a time. By default, Perl does block buffering to disk files. See \"buffer\" and \"command buffering\". Boolean A value that is either \"true\" or \"false\". Boolean context A special kind of \"scalar context\" used in conditionals to decide whether the \"scalar value\" returned by an expression is \"true\" or \"false\". Does not evaluate as either a string or a number. See \"context\". breakpoint A spot in your program where you've told the debugger to stop execution so you can poke around and see whether anything is wrong yet. broadcast To send a \"datagram\" to multiple destinations simultaneously. BSD A psychoactive drug, popular in the 80s, probably developed at U. C. Berkeley or thereabouts. Similar in many ways to the prescription-only medication called \"System V\", but infinitely more useful. (Or, at least, more fun.) The full chemical name is \"Berkeley Standard Distribution\". bucket A location in a \"hash table\" containing (potentially) multiple entries whose keys \"hash\" to the same hash value according to its hash function. (As internal policy, you don't have to worry about it, unless you're into internals, or policy.) buffer A temporary holding location for data. Block buffering means that the data is passed on to its destination whenever the buffer is full. Line buffering means that it's passed on whenever a complete line is received. Command buffering means that it's passed every time you do a print command (or equivalent). If your output is unbuffered, the system processes it one byte at a time without the use of a holding area. This can be rather inefficient. built-in A \"function\" that is predefined in the language. Even when hidden by \"overriding\", you can always get at a built-in function by qualifying its name with the \"CORE::\" pseudo-package. bundle A group of related modules on \" CPAN \". (Also, sometimes refers to a group of command-line switches grouped into one \"switch cluster\".) byte A piece of data worth eight bits in most places. bytecode A pidgin-like language spoken among 'droids when they don't wish to reveal their orientation (see \"endian\"). Named after some similar languages spoken (for similar reasons) between compilers and interpreters in the late 20th century. These languages are characterized by representing everything as a non-architecture-dependent sequence of bytes. C C A language beloved by many for its inside-out \"type\" definitions, inscrutable \"precedence\" rules, and heavy \"overloading\" of the function-call mechanism. (Well, actually, people first switched to C because they found lowercase identifiers easier to read than upper.) Perl is written in C, so it's not surprising that Perl borrowed a few ideas from it. C preprocessor The typical C compiler's first pass, which processes lines beginning with \"#\" for conditional compilation and macro definition and does various manipulations of the program text based on the current definitions. Also known as cpp(1). call by reference An \"argument\"-passing mechanism in which the \"formal arguments\" refer directly to the \"actual arguments\", and the \"subroutine\" can change the actual arguments by changing the formal arguments. That is, the formal argument is an \"alias\" for the actual argument. See also \"call by value\". call by value An \"argument\"-passing mechanism in which the \"formal arguments\" refer to a copy of the \"actual arguments\", and the \"subroutine\" cannot change the actual arguments by changing the formal arguments. See also \"call by reference\". callback A \"handler\" that you register with some other part of your program in the hope that the other part of your program will \"trigger\" your handler when some event of interest transpires. canonical Reduced to a standard form to facilitate comparison. capturing The use of parentheses around a \"subpattern\" in a \"regular expression\" to store the matched \"substring\" as a \"backreference\". (Captured strings are also returned as a list in \"list context\".) character A small integer representative of a unit of orthography. Historically, characters were usually stored as fixed-width integers (typically in a byte, or maybe two, depending on the character set), but with the advent of UTF-8 , characters are often stored in a variable number of bytes depending on the size of the integer that represents the character. Perl manages this transparently for you, for the most part. character class A square-bracketed list of characters used in a \"regular expression\" to indicate that any character of the set may occur at a given point. Loosely, any predefined set of characters so used. character property A predefined \"character class\" matchable by the \"\\p\" \"metasymbol\". Many standard properties are defined for \"Unicode\". circumfix operator An \"operator\" that surrounds its \"operand\", like the angle operator, or parentheses, or a hug. class A user-defined \"type\", implemented in Perl via a \"package\" that provides (either directly or by inheritance) methods (that is, subroutines) to handle instances of the class (its objects). See also \"inheritance\". class method A \"method\" whose \"invocant\" is a \"package\" name, not an \"object\" reference. A method associated with the class as a whole. client In networking, a \"process\" that initiates contact with a \"server\" process in order to exchange data and perhaps receive a service. cloister A \"cluster\" used to restrict the scope of a \"regular expression modifier\". closure An \"anonymous\" subroutine that, when a reference to it is generated at run time, keeps track of the identities of externally visible lexical variables even after those lexical variables have supposedly gone out of \"scope\". They're called \"closures\" because this sort of behavior gives mathematicians a sense of closure. cluster A parenthesized \"subpattern\" used to group parts of a \"regular expression\" into a single \"atom\". CODE The word returned by the ref function when you apply it to a reference to a subroutine. See also \" CV \". code generator A system that writes code for you in a low-level language, such as code to implement the backend of a compiler. See \"program generator\". code subpattern A \"regular expression\" subpattern whose real purpose is to execute some Perl code, for example, the \"(?{...})\" and \"(??{...})\" subpatterns. collating sequence The order into which characters sort. This is used by \"string\" comparison routines to decide, for example, where in this glossary to put \"collating sequence\". command In \"shell\" programming, the syntactic combination of a program name and its arguments. More loosely, anything you type to a shell (a command interpreter) that starts it doing something. Even more loosely, a Perl \"statement\", which might start with a \"label\" and typically ends with a semicolon. command buffering A mechanism in Perl that lets you store up the output of each Perl \"command\" and then flush it out as a single request to the \"operating system\". It's enabled by setting the $| ( $AUTOFLUSH) variable to a true value. It's used when you don't want data sitting around not going where it's supposed to, which may happen because the default on a \"file\" or \"pipe\" is to use \"block buffering\". command name The name of the program currently executing, as typed on the command line. In C, the \"command\" name is passed to the program as the first command-line argument. In Perl, it comes in separately as $0. command-line arguments The values you supply along with a program name when you tell a \"shell\" to execute a \"command\". These values are passed to a Perl program through @ARGV. comment A remark that doesn't affect the meaning of the program. In Perl, a comment is introduced by a \"#\" character and continues to the end of the line. compilation unit The \"file\" (or \"string\", in the case of eval) that is currently being compiled. compile phase Any time before Perl starts running your main program. See also \"run phase\". Compile phase is mostly spent in \"compile time\", but may also be spent in \"run time\" when \"BEGIN\" blocks, use declarations, or constant subexpressions are being evaluated. The startup and import code of any use declaration is also run during compile phase. compile time The time when Perl is trying to make sense of your code, as opposed to when it thinks it knows what your code means and is merely trying to do what it thinks your code says to do, which is \"run time\". compiler Strictly speaking, a program that munches up another program and spits out yet another file containing the program in a \"more executable\" form, typically containing native machine instructions. The perl program is not a compiler by this definition, but it does contain a kind of compiler that takes a program and turns it into a more executable form (syntax trees) within the perl process itself, which the \"interpreter\" then interprets. There are, however, extension modules to get Perl to act more like a \"real\" compiler. See O. composer A \"constructor\" for a \"referent\" that isn't really an \"object\", like an anonymous array or a hash (or a sonata, for that matter). For example, a pair of braces acts as a composer for a hash, and a pair of brackets acts as a composer for an array. See \"Making References\" in perlref. concatenation The process of gluing one cat's nose to another cat's tail. Also, a similar operation on two strings. conditional Something \"iffy\". See \"Boolean context\". connection In telephony, the temporary electrical circuit between the caller's and the callee's phone. In networking, the same kind of temporary circuit between a \"client\" and a \"server\". construct As a noun, a piece of syntax made up of smaller pieces. As a transitive verb, to create an \"object\" using a \"constructor\". constructor Any \"class method\", instance \"method\", or \"subroutine\" that composes, initializes, blesses, and returns an \"object\". Sometimes we use the term loosely to mean a \"composer\". context The surroundings, or environment. The context given by the surrounding code determines what kind of data a particular \"expression\" is expected to return. The three primary contexts are \"list context\", \"scalar context\", and \"void context\". Scalar context is sometimes subdivided into \"Boolean context\", \"numeric context\", \"string context\", and \"void context\". There's also a \"don't care\" scalar context (which is dealt with in Programming Perl, Third Edition, Chapter 2, \"Bits and Pieces\" if you care). continuation The treatment of more than one physical \"line\" as a single logical line. \"Makefile\" lines are continued by putting a backslash before the \"newline\". Mail headers as defined by RFC 822 are continued by putting a space or tab after the newline. In general, lines in Perl do not need any form of continuation mark, because \"whitespace\" (including newlines) is gleefully ignored. Usually. core dump The corpse of a \"process\", in the form of a file left in the \"working directory\" of the process, usually as a result of certain kinds of fatal error. CPAN The Comprehensive Perl Archive Network. (See \"What modules and extensions are available for Perl? What is CPAN ? What does CPAN\/src\/... mean?\" in perlfaq2). cracker Someone who breaks security on computer systems. A cracker may be a true \"hacker\" or only a \"script kiddie\". current package The \"package\" in which the current statement is compiled. Scan backwards in the text of your program through the current lexical scope or any enclosing lexical scopes till you find a package declaration. That's your current package name. current working directory See \"working directory\". currently selected output channel The last \"filehandle\" that was designated with select( \"FILEHANDLE\"); \" STDOUT \", if no filehandle has been selected. CV An internal \"code value\" typedef, holding a \"subroutine\". The \" CV \" type is a subclass of \" SV \". D dangling statement A bare, single \"statement\", without any braces, hanging off an \"if\" or \"while\" conditional. C allows them. Perl doesn't. data structure How your various pieces of data relate to each other and what shape they make when you put them all together, as in a rectangular table or a triangular-shaped tree. data type A set of possible values, together with all the operations that know how to deal with those values. For example, a numeric data type has a certain set of numbers that you can work with and various mathematical operations that you can do on the numbers but would make little sense on, say, a string such as \"Kilroy\". Strings have their own operations, such as \"concatenation\". Compound types made of a number of smaller pieces generally have operations to compose and decompose them, and perhaps to rearrange them. Objects that model things in the real world often have operations that correspond to real activities. For instance, if you model an elevator, your elevator object might have an \"open_door()\" \"method\". datagram A packet of data, such as a \" UDP \" message, that (from the viewpoint of the programs involved) can be sent independently over the network. (In fact, all packets are sent independently at the \" IP \" level, but \"stream\" protocols such as \" TCP \" hide this from your program.) DBM Stands for \"Data Base Management\" routines, a set of routines that emulate an \"associative array\" using disk files. The routines use a dynamic hashing scheme to locate any entry with only two disk accesses. DBM files allow a Perl program to keep a persistent \"hash\" across multiple invocations. You can tie your hash variables to various DBM implementations--see AnyDBM_File and DB_File. declaration An \"assertion\" that states something exists and perhaps describes what it's like, without giving any commitment as to how or where you'll use it. A declaration is like the part of your recipe that says, \"two cups flour, one large egg, four or five tadpoles...\" See \"statement\" for its opposite. Note that some declarations also function as statements. Subroutine declarations also act as definitions if a body is supplied. decrement To subtract a value from a variable, as in \"decrement $x\" (meaning to remove 1 from its value) or \"decrement $x by 3\". default A \"value\" chosen for you if you don't supply a value of your own. defined Having a meaning. Perl thinks that some of the things people try to do are devoid of meaning, in particular, making use of variables that have never been given a \"value\" and performing certain operations on data that isn't there. For example, if you try to read data past the end of a file, Perl will hand you back an undefined value. See also \"false\" and \"defined\" in perlfunc. delimiter A \"character\" or \"string\" that sets bounds to an arbitrarily-sized textual object, not to be confused with a \"separator\" or \"terminator\". \"To delimit\" really just means \"to surround\" or \"to enclose\" (like these parentheses are doing). deprecated modules and features Deprecated modules and features are those which were part of a stable release, but later found to be subtly flawed, and which should be avoided. They are subject to removal and\/or bug-incompatible reimplementation in the next major release (but they will be preserved through maintenance releases). Deprecation warnings are issued under -w or \"use diagnostics\", and notices are found in perldeltas, as well as various other PODs. Coding practices that misuse features, such as \"my $foo if 0\", can also be deprecated. dereference A fancy computer science term meaning \"to follow a \"reference\" to what it points to\". The \"de\" part of it refers to the fact that you're taking away one level of \"indirection\". derived class A \"class\" that defines some of its methods in terms of a more generic class, called a \"base class\". Note that classes aren't classified exclusively into base classes or derived classes: a class can function as both a derived class and a base class simultaneously, which is kind of classy. descriptor See \"file descriptor\". destroy To deallocate the memory of a \"referent\" (first triggering its \"DESTROY\" method, if it has one). destructor A special \"method\" that is called when an \"object\" is thinking about destroying itself. A Perl program's \"DESTROY\" method doesn't do the actual destruction; Perl just triggers the method in case the \"class\" wants to do any associated cleanup. device A whiz-bang hardware gizmo (like a disk or tape drive or a modem or a joystick or a mouse) attached to your computer, that the \"operating system\" tries to make look like a \"file\" (or a bunch of files). Under Unix, these fake files tend to live in the \/dev directory. directive A \"pod\" directive. See perlpod. directory A special file that contains other files. Some operating systems call these \"folders\", \"drawers\", or \"catalogs\". directory handle A name that represents a particular instance of opening a directory to read it, until you close it. See the opendir function. dispatch To send something to its correct destination. Often used metaphorically to indicate a transfer of programmatic control to a destination selected algorithmically, often by lookup in a table of function references or, in the case of object methods, by traversing the inheritance tree looking for the most specific definition for the method. distribution A standard, bundled release of a system of software. The default usage implies source code is included. If that is not the case, it will be called a \"binary-only\" distribution. (to be) dropped modules When Perl 5 was first released (see perlhistory), several modules were included, which have now fallen out of common use. It has been suggested that these modules should be removed, since the distribution became rather large, and the common criterion for new module additions is now limited to modules that help to build, test, and extend perl itself. Furthermore, the CPAN (which didn't exist at the time of Perl 5.0) can become the new home of dropped modules. Dropping modules is currently not an option, but further developments may clear the last barriers. dweomer An enchantment, illusion, phantasm, or jugglery. Said when Perl's magical \"dwimmer\" effects don't do what you expect, but rather seem to be the product of arcane dweomercraft, sorcery, or wonder working. [From Old English] dwimmer DWIM is an acronym for \"Do What I Mean\", the principle that something should just do what you want it to do without an undue amount of fuss. A bit of code that does \"dwimming\" is a \"dwimmer\". Dwimming can require a great deal of behind-the-scenes magic, which (if it doesn't stay properly behind the scenes) is called a \"dweomer\" instead. dynamic scoping Dynamic scoping works over a dynamic scope, making variables visible throughout the rest of the \"block\" in which they are first used and in any subroutines that are called by the rest of the block. Dynamically scoped variables can have their values temporarily changed (and implicitly restored later) by a local operator. (Compare \"lexical scoping\".) Used more loosely to mean how a subroutine that is in the middle of calling another subroutine \"contains\" that subroutine at \"run time\". E eclectic Derived from many sources. Some would say too many. element A basic building block. When you're talking about an \"array\", it's one of the items that make up the array. embedding When something is contained in something else, particularly when that might be considered surprising: \"I've embedded a complete Perl interpreter in my editor!\" empty subclass test The notion that an empty \"derived class\" should behave exactly like its \"base class\". en passant When you change a \"value\" as it is being copied. [From French, \"in passing\", as in the exotic pawn-capturing maneuver in chess.] encapsulation The veil of abstraction separating the \"interface\" from the \"implementation\" (whether enforced or not), which mandates that all access to an \"object\"'s state be through methods alone. endian See \"little-endian\" and \"big-endian\". environment The collective set of environment variables your \"process\" inherits from its parent. Accessed via %ENV. environment variable A mechanism by which some high-level agent such as a user can pass its preferences down to its future offspring (child processes, grandchild processes, great-grandchild processes, and so on). Each environment variable is a \"key\"\/\"value\" pair, like one entry in a \"hash\". EOF End of File. Sometimes used metaphorically as the terminating string of a \"here document\". errno The error number returned by a \"syscall\" when it fails. Perl refers to the error by the name $! (or $OS_ERROR if you use the English module). error See \"exception\" or \"fatal error\". escape sequence See \"metasymbol\". exception A fancy term for an error. See \"fatal error\". exception handling The way a program responds to an error. The exception handling mechanism in Perl is the eval operator. exec To throw away the current \"process\"'s program and replace it with another without exiting the process or relinquishing any resources held (apart from the old memory image). executable file A \"file\" that is specially marked to tell the \"operating system\" that it's okay to run this file as a program. Usually shortened to \"executable\". execute To run a program or \"subroutine\". (Has nothing to do with the kill built-in, unless you're trying to run a \"signal handler\".) execute bit The special mark that tells the operating system it can run this program. There are actually three execute bits under Unix, and which bit gets used depends on whether you own the file singularly, collectively, or not at all. exit status See \"status\". export To make symbols from a \"module\" available for \"import\" by other modules. expression Anything you can legally say in a spot where a \"value\" is required. Typically composed of literals, variables, operators, functions, and \"subroutine\" calls, not necessarily in that order. extension A Perl module that also pulls in compiled C or C ++ code. More generally, any experimental option that can be compiled into Perl, such as multithreading. F false In Perl, any value that would look like \"\" or \"0\" if evaluated in a string context. Since undefined values evaluate to \"\", all undefined values are false, but not all false values are undefined. FAQ Frequently Asked Question (although not necessarily frequently answered, especially if the answer appears in the Perl FAQ shipped standard with Perl). fatal error An uncaught \"exception\", which causes termination of the \"process\" after printing a message on your \"standard error\" stream. Errors that happen inside an eval are not fatal. Instead, the eval terminates after placing the exception message in the $@ ( $EVAL_ERROR) variable. You can try to provoke a fatal error with the die operator (known as throwing or raising an exception), but this may be caught by a dynamically enclosing eval. If not caught, the die becomes a fatal error. field A single piece of numeric or string data that is part of a longer \"string\", \"record\", or \"line\". Variable-width fields are usually split up by separators (so use split to extract the fields), while fixed-width fields are usually at fixed positions (so use unpack). Instance variables are also known as fields. FIFO First In, First Out. See also \" LIFO \". Also, a nickname for a \"named pipe\". file A named collection of data, usually stored on disk in a \"directory\" in a \"filesystem\". Roughly like a document, if you're into office metaphors. In modern filesystems, you can actually give a file more than one name. Some files have special properties, like directories and devices. file descriptor The little number the \"operating system\" uses to keep track of which opened \"file\" you're talking about. Perl hides the file descriptor inside a \"standard I\/O\" stream and then attaches the stream to a \"filehandle\". file test operator A built-in unary operator that you use to determine whether something is \"true\" about a file, such as \"-o $filename\" to test whether you're the owner of the file. fileglob A \"wildcard\" match on filenames. See the glob function. filehandle An identifier (not necessarily related to the real name of a file) that represents a particular instance of opening a file until you close it. If you're going to open and close several different files in succession, it's fine to open each of them with the same filehandle, so you don't have to write out separate code to process each file. filename One name for a file. This name is listed in a \"directory\", and you can use it in an open to tell the \"operating system\" exactly which file you want to open, and associate the file with a \"filehandle\" which will carry the subsequent identity of that file in your program, until you close it. filesystem A set of directories and files residing on a partition of the disk. Sometimes known as a \"partition\". You can change the file's name or even move a file around from directory to directory within a filesystem without actually moving the file itself, at least under Unix. filter A program designed to take a \"stream\" of input and transform it into a stream of output. flag We tend to avoid this term because it means so many things. It may mean a command-line \"switch\" that takes no argument itself (such as Perl's -n and -p flags) or, less frequently, a single-bit indicator (such as the \"O_CREAT\" and \"O_EXCL\" flags used in sysopen). floating point A method of storing numbers in \"scientific notation\", such that the precision of the number is independent of its magnitude (the decimal point \"floats\"). Perl does its numeric work with floating-point numbers (sometimes called \"floats\"), when it can't get away with using integers. Floating-point numbers are mere approximations of real numbers. flush The act of emptying a \"buffer\", often before it's full. FMTEYEWTK Far More Than Everything You Ever Wanted To Know. An exhaustive treatise on one narrow topic, something of a super-\" FAQ \". See Tom for far more. fork To create a child \"process\" identical to the parent process at its moment of conception, at least until it gets ideas of its own. A thread with protected memory. formal arguments The generic names by which a \"subroutine\" knows its arguments. In many languages, formal arguments are always given individual names, but in Perl, the formal arguments are just the elements of an array. The formal arguments to a Perl program are $ARGV[0], $ARGV[1], and so on. Similarly, the formal arguments to a Perl subroutine are $_[0], $_[1], and so on. You may give the arguments individual names by assigning the values to a my list. See also \"actual arguments\". format A specification of how many spaces and digits and things to put somewhere so that whatever you're printing comes out nice and pretty. freely available Means you don't have to pay money to get it, but the copyright on it may still belong to someone else (like Larry). freely redistributable Means you're not in legal trouble if you give a bootleg copy of it to your friends and we find out about it. In fact, we'd rather you gave a copy to all your friends. freeware Historically, any software that you give away, particularly if you make the source code available as well. Now often called \"open source software\". Recently there has been a trend to use the term in contradistinction to \"open source software\", to refer only to free software released under the Free Software Foundation's GPL (General Public License), but this is difficult to justify etymologically. function Mathematically, a mapping of each of a set of input values to a particular output value. In computers, refers to a \"subroutine\" or \"operator\" that returns a \"value\". It may or may not have input values (called arguments). funny character Someone like Larry, or one of his peculiar friends. Also refers to the strange prefixes that Perl requires as noun markers on its variables. garbage collection A misnamed feature--it should be called, \"expecting your mother to pick up after you\". Strictly speaking, Perl doesn't do this, but it relies on a reference-counting mechanism to keep things tidy. However, we rarely speak strictly and will often refer to the reference-counting scheme as a form of garbage collection. (If it's any comfort, when your interpreter exits, a \"real\" garbage collector runs to make sure everything is cleaned up if you've been messy with circular references and such.) G GID Group ID--in Unix, the numeric group ID that the \"operating system\" uses to identify you and members of your \"group\". glob Strictly, the shell's \"*\" character, which will match a \"glob\" of characters when you're trying to generate a list of filenames. Loosely, the act of using globs and similar symbols to do pattern matching. See also \"fileglob\" and \"typeglob\". global Something you can see from anywhere, usually used of variables and subroutines that are visible everywhere in your program. In Perl, only certain special variables are truly global--most variables (and all subroutines) exist only in the current \"package\". Global variables can be declared with our. See \"our\" in perlfunc. global destruction The \"garbage collection\" of globals (and the running of any associated object destructors) that takes place when a Perl \"interpreter\" is being shut down. Global destruction should not be confused with the Apocalypse, except perhaps when it should. glue language A language such as Perl that is good at hooking things together that weren't intended to be hooked together. granularity The size of the pieces you're dealing with, mentally speaking. greedy A \"subpattern\" whose \"quantifier\" wants to match as many things as possible. grep Originally from the old Unix editor command for \"Globally search for a Regular Expression and Print it\", now used in the general sense of any kind of search, especially text searches. Perl has a built-in grep function that searches a list for elements matching any given criterion, whereas the grep(1) program searches for lines matching a \"regular expression\" in one or more files. group A set of users of which you are a member. In some operating systems (like Unix), you can give certain file access permissions to other members of your group. GV An internal \"glob value\" typedef, holding a \"typeglob\". The \" GV \" type is a subclass of \" SV \". H hacker Someone who is brilliantly persistent in solving technical problems, whether these involve golfing, fighting orcs, or programming. Hacker is a neutral term, morally speaking. Good hackers are not to be confused with evil crackers or clueless script kiddies. If you confuse them, we will presume that you are either evil or clueless. handler A \"subroutine\" or \"method\" that is called by Perl when your program needs to respond to some internal event, such as a \"signal\", or an encounter with an operator subject to \"operator overloading\". See also \"callback\". hard reference A \"scalar\" \"value\" containing the actual address of a \"referent\", such that the referent's \"reference\" count accounts for it. (Some hard references are held internally, such as the implicit reference from one of a \"typeglob\"'s variable slots to its corresponding referent.) A hard reference is different from a \"symbolic reference\". hash An unordered association of \"key\"\/\"value\" pairs, stored such that you can easily use a string \"key\" to look up its associated data \"value\". This glossary is like a hash, where the word to be defined is the key, and the definition is the value. A hash is also sometimes septisyllabically called an \"associative array\", which is a pretty good reason for simply calling it a \"hash\" instead. hash table A data structure used internally by Perl for implementing associative arrays (hashes) efficiently. See also \"bucket\". header file A file containing certain required definitions that you must include \"ahead\" of the rest of your program to do certain obscure operations. A C header file has a .h extension. Perl doesn't really have header files, though historically Perl has sometimes used translated .h files with a .ph extension. See \"require\" in perlfunc. (Header files have been superseded by the \"module\" mechanism.) here document So called because of a similar construct in shells that pretends that the lines following the \"command\" are a separate \"file\" to be fed to the command, up to some terminating string. In Perl, however, it's just a fancy form of quoting. hexadecimal A number in base 16, \"hex\" for short. The digits for 10 through 16 are customarily represented by the letters \"a\" through \"f\". Hexadecimal constants in Perl start with \"0x\". See also \"hex\" in perlfunc. home directory The directory you are put into when you log in. On a Unix system, the name is often placed into $ENV{HOME} or $ENV{LOGDIR} by login, but you can also find it with \"(getpwuid($<))[7]\". (Some platforms do not have a concept of a home directory.) host The computer on which a program or other data resides. hubris Excessive pride, the sort of thing Zeus zaps you for. Also the quality that makes you write (and maintain) programs that other people won't want to say bad things about. Hence, the third great virtue of a programmer. See also \"laziness\" and \"impatience\". HV Short for a \"hash value\" typedef, which holds Perl's internal representation of a hash. The \" HV \" type is a subclass of \" SV \". I identifier A legally formed name for most anything in which a computer program might be interested. Many languages (including Perl) allow identifiers that start with a letter and contain letters and digits. Perl also counts the underscore character as a valid letter. (Perl also has more complicated names, such as \"qualified\" names.) impatience The anger you feel when the computer is being lazy. This makes you write programs that don't just react to your needs, but actually anticipate them. Or at least that pretend to. Hence, the second great virtue of a programmer. See also \"laziness\" and \"hubris\". implementation How a piece of code actually goes about doing its job. Users of the code should not count on implementation details staying the same unless they are part of the published \"interface\". import To gain access to symbols that are exported from another module. See \"use\" in perlfunc. increment To increase the value of something by 1 (or by some other number, if so specified). indexing In olden days, the act of looking up a \"key\" in an actual index (such as a phone book), but now merely the act of using any kind of key or position to find the corresponding \"value\", even if no index is involved. Things have degenerated to the point that Perl's index function merely locates the position (index) of one string in another. indirect filehandle An \"expression\" that evaluates to something that can be used as a \"filehandle\": a \"string\" (filehandle name), a \"typeglob\", a typeglob \"reference\", or a low-level \" IO \" object. indirect object In English grammar, a short noun phrase between a verb and its direct object indicating the beneficiary or recipient of the action. In Perl, \"print STDOUT \"$foo\\n\";\" can be understood as \"verb indirect-object object\" where \" STDOUT \" is the recipient of the print action, and \"$foo\" is the object being printed. Similarly, when invoking a \"method\", you might place the invocant between the method and its arguments: $gollum = new Pathetic::Creature \"Smeagol\";\ngive $gollum \"Fisssssh!\";\ngive $gollum \"Precious!\"; In modern Perl, calling methods this way is often considered bad practice and to be avoided. indirect object slot The syntactic position falling between a method call and its arguments when using the indirect object invocation syntax. (The slot is distinguished by the absence of a comma between it and the next argument.) \" STDERR \" is in the indirect object slot here: print STDERR \"Awake!  Awake!  Fear, Fire,\n    Foes!  Awake!\\n\"; indirection If something in a program isn't the value you're looking for but indicates where the value is, that's indirection. This can be done with either symbolic references or hard references. infix An \"operator\" that comes in between its operands, such as multiplication in \"24 * 7\". inheritance What you get from your ancestors, genetically or otherwise. If you happen to be a \"class\", your ancestors are called base classes and your descendants are called derived classes. See \"single inheritance\" and \"multiple inheritance\". instance Short for \"an instance of a class\", meaning an \"object\" of that \"class\". instance variable An \"attribute\" of an \"object\"; data stored with the particular object rather than with the class as a whole. integer A number with no fractional (decimal) part. A counting number, like 1, 2, 3, and so on, but including 0 and the negatives. interface The services a piece of code promises to provide forever, in contrast to its \"implementation\", which it should feel free to change whenever it likes. interpolation The insertion of a scalar or list value somewhere in the middle of another value, such that it appears to have been there all along. In Perl, variable interpolation happens in double-quoted strings and patterns, and list interpolation occurs when constructing the list of values to pass to a list operator or other such construct that takes a \" LIST \". interpreter Strictly speaking, a program that reads a second program and does what the second program says directly without turning the program into a different form first, which is what compilers do. Perl is not an interpreter by this definition, because it contains a kind of compiler that takes a program and turns it into a more executable form (syntax trees) within the perl process itself, which the Perl \"run time\" system then interprets. invocant The agent on whose behalf a \"method\" is invoked. In a \"class\" method, the invocant is a package name. In an \"instance\" method, the invocant is an object reference. invocation The act of calling up a deity, daemon, program, method, subroutine, or function to get it do what you think it's supposed to do. We usually \"call\" subroutines but \"invoke\" methods, since it sounds cooler. I\/O Input from, or output to, a \"file\" or \"device\". IO An internal I\/O object. Can also mean \"indirect object\". IP Internet Protocol, or Intellectual Property. IPC Interprocess Communication. is-a A relationship between two objects in which one object is considered to be a more specific version of the other, generic object: \"A camel is a mammal.\" Since the generic object really only exists in a Platonic sense, we usually add a little abstraction to the notion of objects and think of the relationship as being between a generic \"base class\" and a specific \"derived class\". Oddly enough, Platonic classes don't always have Platonic relationships--see \"inheritance\". iteration Doing something repeatedly. iterator A special programming gizmo that keeps track of where you are in something that you're trying to iterate over. The \"foreach\" loop in Perl contains an iterator; so does a hash, allowing you to each through it. IV The integer four, not to be confused with six, Tom's favorite editor. IV also means an internal Integer Value of the type a \"scalar\" can hold, not to be confused with an \" NV \". J JAPH \"Just Another Perl Hacker,\" a clever but cryptic bit of Perl code that when executed, evaluates to that string. Often used to illustrate a particular Perl feature, and something of an ongoing Obfuscated Perl Contest seen in Usenix signatures. K key The string index to a \"hash\", used to look up the \"value\" associated with that key. keyword See \"reserved words\". L label A name you give to a \"statement\" so that you can talk about that statement elsewhere in the program. laziness The quality that makes you go to great effort to reduce overall energy expenditure. It makes you write labor-saving programs that other people will find useful, and document what you wrote so you don't have to answer so many questions about it. Hence, the first great virtue of a programmer. Also hence, this book. See also \"impatience\" and \"hubris\". left shift A \"bit shift\" that multiplies the number by some power of 2. leftmost longest The preference of the \"regular expression\" engine to match the leftmost occurrence of a \"pattern\", then given a position at which a match will occur, the preference for the longest match (presuming the use of a \"greedy\" quantifier). See perlre for much more on this subject. lexeme Fancy term for a \"token\". lexer Fancy term for a \"tokener\". lexical analysis Fancy term for \"tokenizing\". lexical scoping Looking at your Oxford English Dictionary through a microscope. (Also known as \"static scoping\", because dictionaries don't change very fast.) Similarly, looking at variables stored in a private dictionary (namespace) for each scope, which are visible only from their point of declaration down to the end of the lexical scope in which they are declared. --Syn. \"static scoping\". --Ant. \"dynamic scoping\". lexical variable A \"variable\" subject to \"lexical scoping\", declared by my. Often just called a \"lexical\". (The our declaration declares a lexically scoped name for a global variable, which is not itself a lexical variable.) library Generally, a collection of procedures. In ancient days, referred to a collection of subroutines in a .pl file. In modern times, refers more often to the entire collection of Perl modules on your system. LIFO Last In, First Out. See also \" FIFO \". A LIFO is usually called a \"stack\". line In Unix, a sequence of zero or more non-newline characters terminated with a \"newline\" character. On non-Unix machines, this is emulated by the C library even if the underlying \"operating system\" has different ideas. line buffering Used by a \"standard I\/O\" output stream that flushes its \"buffer\" after every \"newline\". Many standard I\/O libraries automatically set up line buffering on output that is going to the terminal. line number The number of lines read previous to this one, plus 1. Perl keeps a separate line number for each source or input file it opens. The current source file's line number is represented by \"__LINE__\". The current input line number (for the file that was most recently read via \"E<lt>FHE<gt>\") is represented by the $. ( $INPUT_LINE_NUMBER) variable. Many error messages report both values, if available. link Used as a noun, a name in a \"directory\", representing a \"file\". A given file can have multiple links to it. It's like having the same phone number listed in the phone directory under different names. As a verb, to resolve a partially compiled file's unresolved symbols into a (nearly) executable image. Linking can generally be static or dynamic, which has nothing to do with static or dynamic scoping. LIST A syntactic construct representing a comma-separated list of expressions, evaluated to produce a \"list value\". Each \"expression\" in a \" LIST \" is evaluated in \"list context\" and interpolated into the list value. list An ordered set of scalar values. list context The situation in which an \"expression\" is expected by its surroundings (the code calling it) to return a list of values rather than a single value. Functions that want a \" LIST \" of arguments tell those arguments that they should produce a list value. See also \"context\". list operator An \"operator\" that does something with a list of values, such as join or grep. Usually used for named built-in operators (such as print, unlink, and system) that do not require parentheses around their \"argument\" list. list value An unnamed list of temporary scalar values that may be passed around within a program from any list-generating function to any function or construct that provides a \"list context\". literal A token in a programming language such as a number or \"string\" that gives you an actual \"value\" instead of merely representing possible values as a \"variable\" does. little-endian From Swift: someone who eats eggs little end first. Also used of computers that store the least significant \"byte\" of a word at a lower byte address than the most significant byte. Often considered superior to big-endian machines. See also \"big-endian\". local Not meaning the same thing everywhere. A global variable in Perl can be localized inside a dynamic scope via the local operator. logical operator Symbols representing the concepts \"and\", \"or\", \"xor\", and \"not\". lookahead An \"assertion\" that peeks at the string to the right of the current match location. lookbehind An \"assertion\" that peeks at the string to the left of the current match location. loop A construct that performs something repeatedly, like a roller coaster. loop control statement Any statement within the body of a loop that can make a loop prematurely stop looping or skip an \"iteration\". Generally you shouldn't try this on roller coasters. loop label A kind of key or name attached to a loop (or roller coaster) so that loop control statements can talk about which loop they want to control. lvaluable Able to serve as an \"lvalue\". lvalue Term used by language lawyers for a storage location you can assign a new \"value\" to, such as a \"variable\" or an element of an \"array\". The \"l\" is short for \"left\", as in the left side of an assignment, a typical place for lvalues. An \"lvaluable\" function or expression is one to which a value may be assigned, as in \"pos($x) = 10\". lvalue modifier An adjectival pseudofunction that warps the meaning of an \"lvalue\" in some declarative fashion. Currently there are three lvalue modifiers: my, our, and local. M magic Technically speaking, any extra semantics attached to a variable such as $!, $0, %ENV, or %SIG, or to any tied variable. Magical things happen when you diddle those variables. magical increment An \"increment\" operator that knows how to bump up alphabetics as well as numbers. magical variables Special variables that have side effects when you access them or assign to them. For example, in Perl, changing elements of the %ENV array also changes the corresponding environment variables that subprocesses will use. Reading the $! variable gives you the current system error number or message. Makefile A file that controls the compilation of a program. Perl programs don't usually need a \"Makefile\" because the Perl compiler has plenty of self-control. man The Unix program that displays online documentation (manual pages) for you. manpage A \"page\" from the manuals, typically accessed via the man(1) command. A manpage contains a SYNOPSIS , a DESCRIPTION , a list of BUGS , and so on, and is typically longer than a page. There are manpages documenting commands, syscalls, \"library\" functions, devices, protocols, files, and such. In this book, we call any piece of standard Perl documentation (like perlop or perldelta) a manpage, no matter what format it's installed in on your system. matching See \"pattern matching\". member data See \"instance variable\". memory This always means your main memory, not your disk. Clouding the issue is the fact that your machine may implement \"virtual\" memory; that is, it will pretend that it has more memory than it really does, and it'll use disk space to hold inactive bits. This can make it seem like you have a little more memory than you really do, but it's not a substitute for real memory. The best thing that can be said about virtual memory is that it lets your performance degrade gradually rather than suddenly when you run out of real memory. But your program can die when you run out of virtual memory too, if you haven't thrashed your disk to death first. metacharacter A \"character\" that is not supposed to be treated normally. Which characters are to be treated specially as metacharacters varies greatly from context to context. Your \"shell\" will have certain metacharacters, double-quoted Perl strings have other metacharacters, and \"regular expression\" patterns have all the double-quote metacharacters plus some extra ones of their own. metasymbol Something we'd call a \"metacharacter\" except that it's a sequence of more than one character. Generally, the first character in the sequence must be a true metacharacter to get the other characters in the metasymbol to misbehave along with it. method A kind of action that an \"object\" can take if you tell it to. See perlobj. minimalism The belief that \"small is beautiful.\" Paradoxically, if you say something in a small language, it turns out big, and if you say it in a big language, it turns out small. Go figure. mode In the context of the stat syscall, refers to the field holding the \"permission bits\" and the type of the \"file\". modifier See \"statement modifier\", \"regular expression modifier\", and \"lvalue modifier\", not necessarily in that order. module A \"file\" that defines a \"package\" of (almost) the same name, which can either \"export\" symbols or function as an \"object\" class. (A module's main .pm file may also load in other files in support of the module.) See the use built-in. modulus An integer divisor when you're interested in the remainder instead of the quotient. monger Short for Perl Monger, a purveyor of Perl. mortal A temporary value scheduled to die when the current statement finishes. multidimensional array An array with multiple subscripts for finding a single element. Perl implements these using references--see perllol and perldsc. multiple inheritance The features you got from your mother and father, mixed together unpredictably. (See also \"inheritance\", and \"single inheritance\".) In computer languages (including Perl), the notion that a given class may have multiple direct ancestors or base classes. N named pipe A \"pipe\" with a name embedded in the \"filesystem\" so that it can be accessed by two unrelated processes. namespace A domain of names. You needn't worry about whether the names in one such domain have been used in another. See \"package\". network address The most important attribute of a socket, like your telephone's telephone number. Typically an IP address. See also \"port\". newline A single character that represents the end of a line, with the ASCII value of 012 octal under Unix (but 015 on a Mac), and represented by \"\\n\" in Perl strings. For Windows machines writing text files, and for certain physical devices like terminals, the single newline gets automatically translated by your C library into a line feed and a carriage return, but normally, no translation is done. NFS Network File System, which allows you to mount a remote filesystem as if it were local. null character A character with the ASCII value of zero. It's used by C to terminate strings, but Perl allows strings to contain a null. null list A \"list value\" with zero elements, represented in Perl by \"()\". null string A \"string\" containing no characters, not to be confused with a string containing a \"null character\", which has a positive length and is \"true\". numeric context The situation in which an expression is expected by its surroundings (the code calling it) to return a number. See also \"context\" and \"string context\". NV Short for Nevada, no part of which will ever be confused with civilization. NV also means an internal floating-point Numeric Value of the type a \"scalar\" can hold, not to be confused with an \" IV \". nybble Half a \"byte\", equivalent to one \"hexadecimal\" digit, and worth four bits. O object An \"instance\" of a \"class\". Something that \"knows\" what user-defined type (class) it is, and what it can do because of what class it is. Your program can request an object to do things, but the object gets to decide whether it wants to do them or not. Some objects are more accommodating than others. octal A number in base 8. Only the digits 0 through 7 are allowed. Octal constants in Perl start with 0, as in 013. See also the oct function. offset How many things you have to skip over when moving from the beginning of a string or array to a specific position within it. Thus, the minimum offset is zero, not one, because you don't skip anything to get to the first item. one-liner An entire computer program crammed into one line of text. open source software Programs for which the source code is freely available and freely redistributable, with no commercial strings attached. For a more detailed definition, see < http:\/\/www.opensource.org\/osd.html>. operand An \"expression\" that yields a \"value\" that an \"operator\" operates on. See also \"precedence\". operating system A special program that runs on the bare machine and hides the gory details of managing processes and devices. Usually used in a looser sense to indicate a particular culture of programming. The loose sense can be used at varying levels of specificity. At one extreme, you might say that all versions of Unix and Unix-lookalikes are the same operating system (upsetting many people, especially lawyers and other advocates). At the other extreme, you could say this particular version of this particular vendor's operating system is different from any other version of this or any other vendor's operating system. Perl is much more portable across operating systems than many other languages. See also \"architecture\" and \"platform\". operator A gizmo that transforms some number of input values to some number of output values, often built into a language with a special syntax or symbol. A given operator may have specific expectations about what types of data you give as its arguments (operands) and what type of data you want back from it. operator overloading A kind of \"overloading\" that you can do on built-in operators to make them work on objects as if the objects were ordinary scalar values, but with the actual semantics supplied by the object class. This is set up with the overload \"pragma\". options See either switches or \"regular expression modifier\". overloading Giving additional meanings to a symbol or construct. Actually, all languages do overloading to one extent or another, since people are good at figuring out things from \"context\". overriding Hiding or invalidating some other definition of the same name. (Not to be confused with \"overloading\", which adds definitions that must be disambiguated some other way.) To confuse the issue further, we use the word with two overloaded definitions: to describe how you can define your own \"subroutine\" to hide a built-in \"function\" of the same name (see \"Overriding Built-in Functions\" in perlsub) and to describe how you can define a replacement \"method\" in a \"derived class\" to hide a \"base class\"'s method of the same name (see perlobj). owner The one user (apart from the superuser) who has absolute control over a \"file\". A file may also have a \"group\" of users who may exercise joint ownership if the real owner permits it. See \"permission bits\". P package A \"namespace\" for global variables, subroutines, and the like, such that they can be kept separate from like-named symbols in other namespaces. In a sense, only the package is global, since the symbols in the package's symbol table are only accessible from code compiled outside the package by naming the package. But in another sense, all package symbols are also globals--they're just well-organized globals. pad Short for \"scratchpad\". parameter See \"argument\". parent class See \"base class\". parse tree See \"syntax tree\". parsing The subtle but sometimes brutal art of attempting to turn your possibly malformed program into a valid \"syntax tree\". patch To fix by applying one, as it were. In the realm of hackerdom, a listing of the differences between two versions of a program as might be applied by the patch(1) program when you want to fix a bug or upgrade your old version. PATH The list of directories the system searches to find a program you want to \"execute\". The list is stored as one of your environment variables, accessible in Perl as $ENV{PATH}. pathname A fully qualified filename such as \/usr\/bin\/perl. Sometimes confused with \" PATH \". pattern A template used in \"pattern matching\". pattern matching Taking a pattern, usually a \"regular expression\", and trying the pattern various ways on a string to see whether there's any way to make it fit. Often used to pick interesting tidbits out of a file. permission bits Bits that the \"owner\" of a file sets or unsets to allow or disallow access to other people. These flag bits are part of the \"mode\" word returned by the stat built-in when you ask about a file. On Unix systems, you can check the ls(1) manpage for more information. Pern What you get when you do \"Perl++\" twice. Doing it only once will curl your hair. You have to increment it eight times to shampoo your hair. Lather, rinse, iterate. pipe A direct \"connection\" that carries the output of one \"process\" to the input of another without an intermediate temporary file. Once the pipe is set up, the two processes in question can read and write as if they were talking to a normal file, with some caveats. pipeline A series of processes all in a row, linked by pipes, where each passes its output stream to the next. platform The entire hardware and software context in which a program runs. A program written in a platform-dependent language might break if you change any of: machine, operating system, libraries, compiler, or system configuration. The perl interpreter has to be compiled differently for each platform because it is implemented in C, but programs written in the Perl language are largely platform-independent. pod The markup used to embed documentation into your Perl code. See perlpod. pointer A \"variable\" in a language like C that contains the exact memory location of some other item. Perl handles pointers internally so you don't have to worry about them. Instead, you just use symbolic pointers in the form of keys and \"variable\" names, or hard references, which aren't pointers (but act like pointers and do in fact contain pointers). polymorphism The notion that you can tell an \"object\" to do something generic, and the object will interpret the command in different ways depending on its type. [<Gk many shapes] port The part of the address of a TCP or UDP socket that directs packets to the correct process after finding the right machine, something like the phone extension you give when you reach the company operator. Also, the result of converting code to run on a different platform than originally intended, or the verb denoting this conversion. portable Once upon a time, C code compilable under both BSD and SysV. In general, code that can be easily converted to run on another \"platform\", where \"easily\" can be defined however you like, and usually is. Anything may be considered portable if you try hard enough. See mobile home or London Bridge. porter Someone who \"carries\" software from one \"platform\" to another. Porting programs written in platform-dependent languages such as C can be difficult work, but porting programs like Perl is very much worth the agony. POSIX The Portable Operating System Interface specification. postfix An \"operator\" that follows its \"operand\", as in \"$x++\". pp An internal shorthand for a \"push-pop\" code, that is, C code implementing Perl's stack machine. pragma A standard module whose practical hints and suggestions are received (and possibly ignored) at compile time. Pragmas are named in all lowercase. precedence The rules of conduct that, in the absence of other guidance, determine what should happen first. For example, in the absence of parentheses, you always do multiplication before addition. prefix An \"operator\" that precedes its \"operand\", as in \"++$x\". preprocessing What some helper \"process\" did to transform the incoming data into a form more suitable for the current process. Often done with an incoming \"pipe\". See also \"C preprocessor\". procedure A \"subroutine\". process An instance of a running program. Under multitasking systems like Unix, two or more separate processes could be running the same program independently at the same time--in fact, the fork function is designed to bring about this happy state of affairs. Under other operating systems, processes are sometimes called \"threads\", \"tasks\", or \"jobs\", often with slight nuances in meaning. program generator A system that algorithmically writes code for you in a high-level language. See also \"code generator\". progressive matching Pattern matching that picks up where it left off before. property See either \"instance variable\" or \"character property\". protocol In networking, an agreed-upon way of sending messages back and forth so that neither correspondent will get too confused. prototype An optional part of a \"subroutine\" declaration telling the Perl compiler how many and what flavor of arguments may be passed as \"actual arguments\", so that you can write subroutine calls that parse much like built-in functions. (Or don't parse, as the case may be.) pseudofunction A construct that sometimes looks like a function but really isn't. Usually reserved for \"lvalue\" modifiers like my, for \"context\" modifiers like scalar, and for the pick-your-own-quotes constructs, \"q\/\/\", \"qq\/\/\", \"qx\/\/\", \"qw\/\/\", \"qr\/\/\", \"m\/\/\", \"s\/\/\/\", \"y\/\/\/\", and \"tr\/\/\/\". pseudohash A reference to an array whose initial element happens to hold a reference to a hash. You can treat a pseudohash reference as either an array reference or a hash reference. pseudoliteral An \"operator\" that looks something like a \"literal\", such as the output-grabbing operator, \"`\" \"command\" \"`\". public domain Something not owned by anybody. Perl is copyrighted and is thus not in the public domain--it's just \"freely available\" and \"freely redistributable\". pumpkin A notional \"baton\" handed around the Perl community indicating who is the lead integrator in some arena of development. pumpking A \"pumpkin\" holder, the person in charge of pumping the pump, or at least priming it. Must be willing to play the part of the Great Pumpkin now and then. PV A \"pointer value\", which is Perl Internals Talk for a \"char*\". Q qualified Possessing a complete name. The symbol $Ent::moot is qualified; $moot is unqualified. A fully qualified filename is specified from the top-level directory. quantifier A component of a \"regular expression\" specifying how many times the foregoing \"atom\" may occur. R readable With respect to files, one that has the proper permission bit set to let you access the file. With respect to computer programs, one that's written well enough that someone has a chance of figuring out what it's trying to do. reaping The last rites performed by a parent \"process\" on behalf of a deceased child process so that it doesn't remain a \"zombie\". See the wait and waitpid function calls. record A set of related data values in a \"file\" or \"stream\", often associated with a unique \"key\" field. In Unix, often commensurate with a \"line\", or a blank-line-terminated set of lines (a \"paragraph\"). Each line of the \/etc\/passwd file is a record, keyed on login name, containing information about that user. recursion The art of defining something (at least partly) in terms of itself, which is a naughty no-no in dictionaries but often works out okay in computer programs if you're careful not to recurse forever, which is like an infinite loop with more spectacular failure modes. reference Where you look to find a pointer to information somewhere else. (See \"indirection\".) References come in two flavors, symbolic references and hard references. referent Whatever a reference refers to, which may or may not have a name. Common types of referents include scalars, arrays, hashes, and subroutines. regex See \"regular expression\". regular expression A single entity with various interpretations, like an elephant. To a computer scientist, it's a grammar for a little language in which some strings are legal and others aren't. To normal people, it's a pattern you can use to find what you're looking for when it varies from case to case. Perl's regular expressions are far from regular in the theoretical sense, but in regular use they work quite well. Here's a regular expression: \"\/Oh s.*t.\/\". This will match strings like \" \"Oh say can you see by the dawn's early light\"\" and \" \"Oh sit!\"\". See perlre. regular expression modifier An option on a pattern or substitution, such as \"\/i\" to render the pattern case insensitive. See also \"cloister\". regular file A \"file\" that's not a \"directory\", a \"device\", a named \"pipe\" or \"socket\", or a \"symbolic link\". Perl uses the \"-f\" file test operator to identify regular files. Sometimes called a \"plain\" file. relational operator An \"operator\" that says whether a particular ordering relationship is \"true\" about a pair of operands. Perl has both numeric and string relational operators. See \"collating sequence\". reserved words A word with a specific, built-in meaning to a \"compiler\", such as \"if\" or delete. In many languages (not Perl), it's illegal to use reserved words to name anything else. (Which is why they're reserved, after all.) In Perl, you just can't use them to name labels or filehandles. Also called \"keywords\". return value The \"value\" produced by a \"subroutine\" or \"expression\" when evaluated. In Perl, a return value may be either a \"list\" or a \"scalar\". RFC Request For Comment, which despite the timid connotations is the name of a series of important standards documents. right shift A \"bit shift\" that divides a number by some power of 2. root The superuser ( UID == 0). Also, the top-level directory of the filesystem. RTFM What you are told when someone thinks you should Read The Fine Manual. run phase Any time after Perl starts running your main program. See also \"compile phase\". Run phase is mostly spent in \"run time\" but may also be spent in \"compile time\" when require, do \"FILE\", or eval \"STRING\" operators are executed or when a substitution uses the \"\/ee\" modifier. run time The time when Perl is actually doing what your code says to do, as opposed to the earlier period of time when it was trying to figure out whether what you said made any sense whatsoever, which is \"compile time\". run-time pattern A pattern that contains one or more variables to be interpolated before parsing the pattern as a \"regular expression\", and that therefore cannot be analyzed at compile time, but must be re-analyzed each time the pattern match operator is evaluated. Run-time patterns are useful but expensive. RV A recreational vehicle, not to be confused with vehicular recreation. RV also means an internal Reference Value of the type a \"scalar\" can hold. See also \" IV \" and \" NV \" if you're not confused yet. rvalue A \"value\" that you might find on the right side of an \"assignment\". See also \"lvalue\". S scalar A simple, singular value; a number, \"string\", or \"reference\". scalar context The situation in which an \"expression\" is expected by its surroundings (the code calling it) to return a single \"value\" rather than a \"list\" of values. See also \"context\" and \"list context\". A scalar context sometimes imposes additional constraints on the return value--see \"string context\" and \"numeric context\". Sometimes we talk about a \"Boolean context\" inside conditionals, but this imposes no additional constraints, since any scalar value, whether numeric or \"string\", is already true or false. scalar literal A number or quoted \"string\"--an actual \"value\" in the text of your program, as opposed to a \"variable\". scalar value A value that happens to be a \"scalar\" as opposed to a \"list\". scalar variable A \"variable\" prefixed with \"$\" that holds a single value. scope How far away you can see a variable from, looking through one. Perl has two visibility mechanisms: it does \"dynamic scoping\" of local variables, meaning that the rest of the \"block\", and any subroutines that are called by the rest of the block, can see the variables that are local to the block. Perl does \"lexical scoping\" of my variables, meaning that the rest of the block can see the variable, but other subroutines called by the block cannot see the variable. scratchpad The area in which a particular invocation of a particular file or subroutine keeps some of its temporary values, including any lexically scoped variables. script A text \"file\" that is a program intended to be executed directly rather than compiled to another form of file before execution. Also, in the context of \"Unicode\", a writing system for a particular language or group of languages, such as Greek, Bengali, or Klingon. script kiddie A \"cracker\" who is not a \"hacker\", but knows just enough to run canned scripts. A cargo-cult programmer. sed A venerable Stream EDitor from which Perl derives some of its ideas. semaphore A fancy kind of interlock that prevents multiple threads or processes from using up the same resources simultaneously. separator A \"character\" or \"string\" that keeps two surrounding strings from being confused with each other. The split function works on separators. Not to be confused with delimiters or terminators. The \"or\" in the previous sentence separated the two alternatives. serialization Putting a fancy \"data structure\" into linear order so that it can be stored as a \"string\" in a disk file or database or sent through a \"pipe\". Also called marshalling. server In networking, a \"process\" that either advertises a \"service\" or just hangs around at a known location and waits for clients who need service to get in touch with it. service Something you do for someone else to make them happy, like giving them the time of day (or of their life). On some machines, well-known services are listed by the getservent function. setgid Same as \"setuid\", only having to do with giving away \"group\" privileges. setuid Said of a program that runs with the privileges of its \"owner\" rather than (as is usually the case) the privileges of whoever is running it. Also describes the bit in the mode word (\"permission bits\") that controls the feature. This bit must be explicitly set by the owner to enable this feature, and the program must be carefully written not to give away more privileges than it ought to. shared memory A piece of \"memory\" accessible by two different processes who otherwise would not see each other's memory. shebang Irish for the whole McGillicuddy. In Perl culture, a portmanteau of \"sharp\" and \"bang\", meaning the \"#!\" sequence that tells the system where to find the interpreter. shell A \"command\"-line \"interpreter\". The program that interactively gives you a prompt, accepts one or more lines of input, and executes the programs you mentioned, feeding each of them their proper arguments and input data. Shells can also execute scripts containing such commands. Under Unix, typical shells include the Bourne shell ( \/bin\/sh), the C shell ( \/bin\/csh), and the Korn shell ( \/bin\/ksh). Perl is not strictly a shell because it's not interactive (although Perl programs can be interactive). side effects Something extra that happens when you evaluate an \"expression\". Nowadays it can refer to almost anything. For example, evaluating a simple assignment statement typically has the \"side effect\" of assigning a value to a variable. (And you thought assigning the value was your primary intent in the first place!) Likewise, assigning a value to the special variable $| ( $AUTOFLUSH) has the side effect of forcing a flush after every write or print on the currently selected filehandle. signal A bolt out of the blue; that is, an event triggered by the \"operating system\", probably when you're least expecting it. signal handler A \"subroutine\" that, instead of being content to be called in the normal fashion, sits around waiting for a bolt out of the blue before it will deign to \"execute\". Under Perl, bolts out of the blue are called signals, and you send them with the kill built-in. See \"%SIG\" in perlvar and \"Signals\" in perlipc. single inheritance The features you got from your mother, if she told you that you don't have a father. (See also \"inheritance\" and \"multiple inheritance\".) In computer languages, the notion that classes reproduce asexually so that a given class can only have one direct ancestor or \"base class\". Perl supplies no such restriction, though you may certainly program Perl that way if you like. slice A selection of any number of elements from a \"list\", \"array\", or \"hash\". slurp To read an entire \"file\" into a \"string\" in one operation. socket An endpoint for network communication among multiple processes that works much like a telephone or a post office box. The most important thing about a socket is its \"network address\" (like a phone number). Different kinds of sockets have different kinds of addresses--some look like filenames, and some don't. soft reference See \"symbolic reference\". source filter A special kind of \"module\" that does \"preprocessing\" on your script just before it gets to the \"tokener\". stack A device you can put things on the top of, and later take them back off in the opposite order in which you put them on. See \" LIFO \". standard Included in the official Perl distribution, as in a standard module, a standard tool, or a standard Perl \"manpage\". standard error The default output \"stream\" for nasty remarks that don't belong in \"standard output\". Represented within a Perl program by the \"filehandle\" \" STDERR \". You can use this stream explicitly, but the die and warn built-ins write to your standard error stream automatically. standard I\/O A standard C library for doing buffered input and output to the \"operating system\". (The \"standard\" of standard I\/O is only marginally related to the \"standard\" of standard input and output.) In general, Perl relies on whatever implementation of standard I\/O a given operating system supplies, so the buffering characteristics of a Perl program on one machine may not exactly match those on another machine. Normally this only influences efficiency, not semantics. If your standard I\/O package is doing block buffering and you want it to \"flush\" the buffer more often, just set the $| variable to a true value. standard input The default input \"stream\" for your program, which if possible shouldn't care where its data is coming from. Represented within a Perl program by the \"filehandle\" \" STDIN \". standard output The default output \"stream\" for your program, which if possible shouldn't care where its data is going. Represented within a Perl program by the \"filehandle\" \" STDOUT \". stat structure A special internal spot in which Perl keeps the information about the last \"file\" on which you requested information. statement A \"command\" to the computer about what to do next, like a step in a recipe: \"Add marmalade to batter and mix until mixed.\" A statement is distinguished from a \"declaration\", which doesn't tell the computer to do anything, but just to learn something. statement modifier A \"conditional\" or \"loop\" that you put after the \"statement\" instead of before, if you know what we mean. static Varying slowly compared to something else. (Unfortunately, everything is relatively stable compared to something else, except for certain elementary particles, and we're not so sure about them.) In computers, where things are supposed to vary rapidly, \"static\" has a derogatory connotation, indicating a slightly dysfunctional \"variable\", \"subroutine\", or \"method\". In Perl culture, the word is politely avoided. static method No such thing. See \"class method\". static scoping No such thing. See \"lexical scoping\". static variable No such thing. Just use a \"lexical variable\" in a scope larger than your \"subroutine\". status The \"value\" returned to the parent \"process\" when one of its child processes dies. This value is placed in the special variable $?. Its upper eight bits are the exit status of the defunct process, and its lower eight bits identify the signal (if any) that the process died from. On Unix systems, this status value is the same as the status word returned by wait(2). See \"system\" in perlfunc. STDERR See \"standard error\". STDIN See \"standard input\". STDIO See \"standard I\/O\". STDOUT See \"standard output\". stream A flow of data into or out of a process as a steady sequence of bytes or characters, without the appearance of being broken up into packets. This is a kind of \"interface\"--the underlying \"implementation\" may well break your data up into separate packets for delivery, but this is hidden from you. string A sequence of characters such as \"He said !@#*&%@#*?!\". A string does not have to be entirely printable. string context The situation in which an expression is expected by its surroundings (the code calling it) to return a \"string\". See also \"context\" and \"numeric context\". stringification The process of producing a \"string\" representation of an abstract object. struct C keyword introducing a structure definition or name. structure See \"data structure\". subclass See \"derived class\". subpattern A component of a \"regular expression\" pattern. subroutine A named or otherwise accessible piece of program that can be invoked from elsewhere in the program in order to accomplish some sub-goal of the program. A subroutine is often parameterized to accomplish different but related things depending on its input arguments. If the subroutine returns a meaningful \"value\", it is also called a \"function\". subscript A \"value\" that indicates the position of a particular \"array\" \"element\" in an array. substitution Changing parts of a string via the \"s\/\/\/\" operator. (We avoid use of this term to mean \"variable interpolation\".) substring A portion of a \"string\", starting at a certain \"character\" position (\"offset\") and proceeding for a certain number of characters. superclass See \"base class\". superuser The person whom the \"operating system\" will let do almost anything. Typically your system administrator or someone pretending to be your system administrator. On Unix systems, the \"root\" user. On Windows systems, usually the Administrator user. SV Short for \"scalar value\". But within the Perl interpreter every \"referent\" is treated as a member of a class derived from SV , in an object-oriented sort of way. Every \"value\" inside Perl is passed around as a C language \"SV*\" pointer. The SV \"struct\" knows its own \"referent type\", and the code is smart enough (we hope) not to try to call a \"hash\" function on a \"subroutine\". switch An option you give on a command line to influence the way your program works, usually introduced with a minus sign. The word is also used as a nickname for a \"switch statement\". switch cluster The combination of multiple command-line switches (e.g., -a -b -c) into one switch (e.g., -abc). Any switch with an additional \"argument\" must be the last switch in a cluster. switch statement A program technique that lets you evaluate an \"expression\" and then, based on the value of the expression, do a multiway branch to the appropriate piece of code for that value. Also called a \"case structure\", named after the similar Pascal construct. Most switch statements in Perl are spelled \"for\". See \"Basic BLOCKs and Switch Statements\" in perlsyn. symbol Generally, any \"token\" or \"metasymbol\". Often used more specifically to mean the sort of name you might find in a \"symbol table\". symbol table Where a \"compiler\" remembers symbols. A program like Perl must somehow remember all the names of all the variables, filehandles, and subroutines you've used. It does this by placing the names in a symbol table, which is implemented in Perl using a \"hash table\". There is a separate symbol table for each \"package\" to give each package its own \"namespace\". symbolic debugger A program that lets you step through the execution of your program, stopping or printing things out here and there to see whether anything has gone wrong, and if so, what. The \"symbolic\" part just means that you can talk to the debugger using the same symbols with which your program is written. symbolic link An alternate filename that points to the real \"filename\", which in turn points to the real \"file\". Whenever the \"operating system\" is trying to parse a \"pathname\" containing a symbolic link, it merely substitutes the new name and continues parsing. symbolic reference A variable whose value is the name of another variable or subroutine. By dereferencing the first variable, you can get at the second one. Symbolic references are illegal under use strict 'refs'. synchronous Programming in which the orderly sequence of events can be determined; that is, when things happen one after the other, not at the same time. syntactic sugar An alternative way of writing something more easily; a shortcut. syntax From Greek, \"with-arrangement\". How things (particularly symbols) are put together with each other. syntax tree An internal representation of your program wherein lower-level constructs dangle off the higher-level constructs enclosing them. syscall A \"function\" call directly to the \"operating system\". Many of the important subroutines and functions you use aren't direct system calls, but are built up in one or more layers above the system call level. In general, Perl programmers don't need to worry about the distinction. However, if you do happen to know which Perl functions are really syscalls, you can predict which of these will set the $! ( $ERRNO) variable on failure. Unfortunately, beginning programmers often confusingly employ the term \"system call\" to mean what happens when you call the Perl system function, which actually involves many syscalls. To avoid any confusion, we nearly always use say \"syscall\" for something you could call indirectly via Perl's syscall function, and never for something you would call with Perl's system function. T tainted Said of data derived from the grubby hands of a user and thus unsafe for a secure program to rely on. Perl does taint checks if you run a \"setuid\" (or \"setgid\") program, or if you use the -T switch. TCP Short for Transmission Control Protocol. A protocol wrapped around the Internet Protocol to make an unreliable packet transmission mechanism appear to the application program to be a reliable \"stream\" of bytes. (Usually.) term Short for a \"terminal\", that is, a leaf node of a \"syntax tree\". A thing that functions grammatically as an \"operand\" for the operators in an expression. terminator A \"character\" or \"string\" that marks the end of another string. The $\/ variable contains the string that terminates a readline operation, which chomp deletes from the end. Not to be confused with delimiters or separators. The period at the end of this sentence is a terminator. ternary An \"operator\" taking three operands. Sometimes pronounced \"trinary\". text A \"string\" or \"file\" containing primarily printable characters. thread Like a forked process, but without \"fork\"'s inherent memory protection. A thread is lighter weight than a full process, in that a process could have multiple threads running around in it, all fighting over the same process's memory space unless steps are taken to protect threads from each other. See threads. tie The bond between a magical variable and its implementation class. See \"tie\" in perlfunc and perltie. TMTOWTDI There's More Than One Way To Do It, the Perl Motto. The notion that there can be more than one valid path to solving a programming problem in context. (This doesn't mean that more ways are always better or that all possible paths are equally desirable--just that there need not be One True Way.) Pronounced TimToady. token A morpheme in a programming language, the smallest unit of text with semantic significance. tokener A module that breaks a program text into a sequence of tokens for later analysis by a parser. tokenizing Splitting up a program text into tokens. Also known as \"lexing\", in which case you get \"lexemes\" instead of tokens. toolbox approach The notion that, with a complete set of simple tools that work well together, you can build almost anything you want. Which is fine if you're assembling a tricycle, but if you're building a defranishizing comboflux regurgalator, you really want your own machine shop in which to build special tools. Perl is sort of a machine shop. transliterate To turn one string representation into another by mapping each character of the source string to its corresponding character in the result string. See \"tr\/SEARCHLIST\/REPLACEMENTLIST\/cds\" in perlop. trigger An event that causes a \"handler\" to be run. trinary Not a stellar system with three stars, but an \"operator\" taking three operands. Sometimes pronounced \"ternary\". troff A venerable typesetting language from which Perl derives the name of its $% variable and which is secretly used in the production of Camel books. true Any scalar value that doesn't evaluate to 0 or \"\". truncating Emptying a file of existing contents, either automatically when opening a file for writing or explicitly via the truncate function. type See \"data type\" and \"class\". type casting Converting data from one type to another. C permits this. Perl does not need it. Nor want it. typed lexical A \"lexical variable\" that is declared with a \"class\" type: \"my Pony $bill\". typedef A type definition in the C language. typeglob Use of a single identifier, prefixed with \"*\". For example, *name stands for any or all of $name, @name, %name, &name, or just \"name\". How you use it determines whether it is interpreted as all or only one of them. See \"Typeglobs and Filehandles\" in perldata. typemap A description of how C types may be transformed to and from Perl types within an \"extension\" module written in \" XS \". U UDP User Datagram Protocol, the typical way to send datagrams over the Internet. UID A user ID . Often used in the context of \"file\" or \"process\" ownership. umask A mask of those \"permission bits\" that should be forced off when creating files or directories, in order to establish a policy of whom you'll ordinarily deny access to. See the umask function. unary operator An operator with only one \"operand\", like \"!\" or chdir. Unary operators are usually prefix operators; that is, they precede their operand. The \"++\" and \"--\" operators can be either prefix or postfix. (Their position does change their meanings.) Unicode A character set comprising all the major character sets of the world, more or less. See < http:\/\/www.unicode.org>. Unix A very large and constantly evolving language with several alternative and largely incompatible syntaxes, in which anyone can define anything any way they choose, and usually do. Speakers of this language think it's easy to learn because it's so easily twisted to one's own ends, but dialectical differences make tribal intercommunication nearly impossible, and travelers are often reduced to a pidgin-like subset of the language. To be universally understood, a Unix shell programmer must spend years of study in the art. Many have abandoned this discipline and now communicate via an Esperanto-like language called Perl. In ancient times, Unix was also used to refer to some code that a couple of people at Bell Labs wrote to make use of a PDP-7 computer that wasn't doing much of anything else at the time. V value An actual piece of data, in contrast to all the variables, references, keys, indexes, operators, and whatnot that you need to access the value. variable A named storage location that can hold any of various kinds of \"value\", as your program sees fit. variable interpolation The \"interpolation\" of a scalar or array variable into a string. variadic Said of a \"function\" that happily receives an indeterminate number of \"actual arguments\". vector Mathematical jargon for a list of scalar values. virtual Providing the appearance of something without the reality, as in: virtual memory is not real memory. (See also \"memory\".) The opposite of \"virtual\" is \"transparent\", which means providing the reality of something without the appearance, as in: Perl handles the variable-length UTF-8 character encoding transparently. void context A form of \"scalar context\" in which an \"expression\" is not expected to return any \"value\" at all and is evaluated for its \"side effects\" alone. v-string A \"version\" or \"vector\" \"string\" specified with a \"v\" followed by a series of decimal integers in dot notation, for instance, \"v1.20.300.4000\". Each number turns into a \"character\" with the specified ordinal value. (The \"v\" is optional when there are at least three integers.) W warning A message printed to the \" STDERR \" stream to the effect that something might be wrong but isn't worth blowing up over. See \"warn\" in perlfunc and the warnings pragma. watch expression An expression which, when its value changes, causes a breakpoint in the Perl debugger. whitespace A \"character\" that moves your cursor but doesn't otherwise put anything on your screen. Typically refers to any of: space, tab, line feed, carriage return, or form feed. word In normal \"computerese\", the piece of data of the size most efficiently handled by your computer, typically 32 bits or so, give or take a few powers of 2. In Perl culture, it more often refers to an alphanumeric \"identifier\" (including underscores), or to a string of nonwhitespace characters bounded by whitespace or string boundaries. working directory Your current \"directory\", from which relative pathnames are interpreted by the \"operating system\". The operating system knows your current directory because you told it with a chdir or because you started out in the place where your parent \"process\" was when you were born. wrapper A program or subroutine that runs some other program or subroutine for you, modifying some of its input or output to better suit your purposes. WYSIWYG What You See Is What You Get. Usually used when something that appears on the screen matches how it will eventually look, like Perl's format declarations. Also used to mean the opposite of magic because everything works exactly as it appears, as in the three-argument form of open. X XS An extraordinarily exported, expeditiously excellent, expressly eXternal Subroutine, executed in existing C or C ++ or in an exciting new extension language called (exasperatingly) XS . Examine perlxs for the exact explanation or perlxstut for an exemplary unexacting one. XSUB An external \"subroutine\" defined in \" XS \". Y yacc Yet Another Compiler Compiler. A parser generator without which Perl probably would not have existed. See the file perly.y in the Perl source distribution. Z zero width A subpattern \"assertion\" matching the \"null string\" between characters. zombie A process that has died (exited) but whose parent has not yet received proper notification of its demise by virtue of having called wait or waitpid. If you fork, you must clean up after your child processes when they exit, or else the process table will fill up and your system administrator will Not Be Happy with you.","Process Name":"perlglossary","Link":"https:\/\/linux.die.net\/man\/1\/perlglossary"}},{"Process":{"Description":"This is \"The GNU General Public License, version 2\". It's here so that modules, programs, etc., that want to declare this as their distribution license, can link to it. It is also one of the two licenses Perl allows itself to be redistributed and\/or modified; for the other one, the Perl Artistic License, see the perlartistic.","Process Name":"perlgpl","Link":"https:\/\/linux.die.net\/man\/1\/perlgpl"}},{"Process":{"Description":"This document attempts to describe how to use the Perl API , as well as to provide some info on the basic workings of the Perl core. It is far from complete and probably contains many errors. Please refer any questions or comments to the author below.","Process Name":"perlguts","Link":"https:\/\/linux.die.net\/man\/1\/perlguts"}},{"Process":{"Description":"This document attempts to explain how Perl development takes place, and ends with some suggestions for people wanting to become bona fide porters. The perl5-porters mailing list is where the Perl standard distribution is maintained and developed. The list can get anywhere from 10 to 150 messages a day, depending on the heatedness of the debate. Most days there are two or three patches, extensions, features, or bugs being discussed at a time. A searchable archive of the list is at either: http:\/\/www.xray.mpe.mpg.de\/mailing-lists\/perl5-porters\/ or http:\/\/archive.develooper.com\/perl5-porters@perl.org\/ List subscribers (the porters themselves) come in several flavours. Some are quiet curious lurkers, who rarely pitch in and instead watch the ongoing development to ensure they're forewarned of new changes or features in Perl. Some are representatives of vendors, who are there to make sure that Perl continues to compile and work on their platforms. Some patch any reported bug that they know how to fix, some are actively patching their pet area (threads, Win32, the regexp engine), while others seem to do nothing but complain. In other words, it's your usual mix of technical people. Over this group of porters presides Larry Wall. He has the final word in what does and does not change in the Perl language. Various releases of Perl are shepherded by a \"pumpking\", a porter responsible for gathering patches, deciding on a patch-by-patch, feature-by-feature basis what will and will not go into the release. For instance, Gurusamy Sarathy was the pumpking for the 5.6 release of Perl, and Jarkko Hietaniemi was the pumpking for the 5.8 release, and Rafael Garcia-Suarez holds the pumpking crown for the 5.10 release. In addition, various people are pumpkings for different things. For instance, Andy Dougherty and Jarkko Hietaniemi did a grand job as the Configure pumpkin up till the 5.8 release. For the 5.10 release H.Merijn Brand took over. Larry sees Perl development along the lines of the US government: there's the Legislature (the porters), the Executive branch (the pumpkings), and the Supreme Court (Larry). The legislature can discuss and submit patches to the executive branch all they like, but the executive branch is free to veto them. Rarely, the Supreme Court will side with the executive branch over the legislature, or the legislature over the executive branch. Mostly, however, the legislature and the executive branch are supposed to get along and work out their differences without impeachment or court cases. You might sometimes see reference to Rule 1 and Rule 2. Larry's power as Supreme Court is expressed in The Rules: 1. Larry is always by definition right about how Perl should behave. This means he has final veto power on the core functionality. 2. Larry is allowed to change his mind about any matter at a later date, regardless of whether he previously invoked Rule 1. Got that? Larry is always right, even when he was wrong. It's rare to see either Rule exercised, but they are often alluded to. New features and extensions to the language are contentious, because the criteria used by the pumpkings, Larry, and other porters to decide which features should be implemented and incorporated are not codified in a few small design goals as with some other languages. Instead, the heuristics are flexible and often difficult to fathom. Here is one person's list, roughly in decreasing order of importance, of heuristics that new features have to be weighed against: Does concept match the general goals of Perl? These haven't been written anywhere in stone, but one approximation is: 1. Keep it fast, simple, and useful.\n2. Keep features\/concepts as orthogonal as possible.\n3. No arbitrary limits (platforms, data sizes, cultures).\n4. Keep it open and exciting to use\/patch\/advocate Perl everywhere.\n5. Either assimilate new technologies, or build bridges to them. Where is the implementation? All the talk in the world is useless without an implementation. In almost every case, the person or people who argue for a new feature will be expected to be the ones who implement it. Porters capable of coding new features have their own agendas, and are not available to implement your (possibly good) idea. Backwards compatibility It's a cardinal sin to break existing Perl programs. New warnings are contentious--some say that a program that emits warnings is not broken, while others say it is. Adding keywords has the potential to break programs, changing the meaning of existing token sequences or functions might break programs. Could it be a module instead? Perl 5 has extension mechanisms, modules and XS , specifically to avoid the need to keep changing the Perl interpreter. You can write modules that export functions, you can give those functions prototypes so they can be called like built-in functions, you can even write XS code to mess with the runtime data structures of the Perl interpreter if you want to implement really complicated things. If it can be done in a module instead of in the core, it's highly unlikely to be added. Is the feature generic enough? Is this something that only the submitter wants added to the language, or would it be broadly useful? Sometimes, instead of adding a feature with a tight focus, the porters might decide to wait until someone implements the more generalized feature. For instance, instead of implementing a \"delayed evaluation\" feature, the porters are waiting for a macro system that would permit delayed evaluation and much more. Does it potentially introduce new bugs? Radical rewrites of large chunks of the Perl interpreter have the potential to introduce new bugs. The smaller and more localized the change, the better. Does it preclude other desirable features? A patch is likely to be rejected if it closes off future avenues of development. For instance, a patch that placed a true and final interpretation on prototypes is likely to be rejected because there are still options for the future of prototypes that haven't been addressed. Is the implementation robust? Good patches (tight code, complete, correct) stand more chance of going in. Sloppy or incorrect patches might be placed on the back burner until the pumpking has time to fix, or might be discarded altogether without further notice. Is the implementation generic enough to be portable? The worst patches make use of a system-specific features. It's highly unlikely that non-portable additions to the Perl language will be accepted. Is the implementation tested? Patches which change behaviour (fixing bugs or introducing new features) must include regression tests to verify that everything works as expected. Without tests provided by the original author, how can anyone else changing perl in the future be sure that they haven't unwittingly broken the behaviour the patch implements? And without tests, how can the patch's author be confident that his\/her hard work put into the patch won't be accidentally thrown away by someone in the future? Is there enough documentation? Patches without documentation are probably ill-thought out or incomplete. Nothing can be added without documentation, so submitting a patch for the appropriate manpages as well as the source code is always a good idea. Is there another way to do it? Larry said \"Although the Perl Slogan is There's More Than One Way to Do It, I hesitate to make 10 ways to do something\". This is a tricky heuristic to navigate, though--one man's essential addition is another man's pointless cruft. Does it create too much work? Work for the pumpking, work for Perl programmers, work for module authors, ... Perl is supposed to be easy. Patches speak louder than words Working code is always preferred to pie-in-the-sky ideas. A patch to add a feature stands a much higher chance of making it to the language than does a random feature request, no matter how fervently argued the request might be. This ties into \"Will it be useful?\", as the fact that someone took the time to make the patch demonstrates a strong desire for the feature. If you're on the list, you might hear the word \"core\" bandied around. It refers to the standard distribution. \"Hacking on the core\" means you're changing the C source code to the Perl interpreter. \"A core module\" is one that ships with Perl. Keeping in sync The source code to the Perl interpreter, in its different versions, is kept in a repository managed by the git revision control system. The pumpkings and a few others have write access to the repository to check in changes. How to clone and use the git perl repository is described in perlrepository. You can also choose to use rsync to get a copy of the current source tree for the bleadperl branch and all maintenance branches : $ rsync -avz rsync:\/\/perl5.git.perl.org\/APC\/perl-current .\n$ rsync -avz rsync:\/\/perl5.git.perl.org\/APC\/perl-5.10.x .\n$ rsync -avz rsync:\/\/perl5.git.perl.org\/APC\/perl-5.8.x .\n$ rsync -avz rsync:\/\/perl5.git.perl.org\/APC\/perl-5.6.x .\n$ rsync -avz rsync:\/\/perl5.git.perl.org\/APC\/perl-5.005xx . (Add the \"--delete\" option to remove leftover files) You may also want to subscribe to the perl5-changes mailing list to receive a copy of each patch that gets submitted to the maintenance and development \"branches\" of the perl repository. See http:\/\/lists.perl.org\/ for subscription information. If you are a member of the perl5-porters mailing list, it is a good thing to keep in touch with the most recent changes. If not only to verify if what you would have posted as a bug report isn't already solved in the most recent available perl development branch, also known as perl-current, bleading edge perl, bleedperl or bleadperl. Needless to say, the source code in perl-current is usually in a perpetual state of evolution. You should expect it to be very buggy. Do not use it for any purpose other than testing and development. Perlbug administration There is a single remote administrative interface for modifying bug status, category, open issues etc. using the RT bugtracker system, maintained by Robert Spier. Become an administrator, and close any bugs you can get your sticky mitts on: http:\/\/bugs.perl.org\/ To email the bug system administrators: \"perlbug-admin\" <perlbug-admin@perl.org> Submitting patches Always submit patches to perl5-porters@perl.org. If you're patching a core module and there's an author listed, send the author a copy (see \"Patching a core module\"). This lets other porters review your patch, which catches a surprising number of errors in patches. Please patch against the latest development version. (e.g., even if you're fixing a bug in the 5.8 track, patch against the \"blead\" branch in the git repository.) If changes are accepted, they are applied to the development branch. Then the maintenance pumpking decides which of those patches is to be backported to the maint branch. Only patches that survive the heat of the development branch get applied to maintenance versions. Your patch should update the documentation and test suite. See \"Writing a test\". If you have added or removed files in the distribution, edit the MANIFEST file accordingly, sort the MANIFEST file using \"make manisort\", and include those changes as part of your patch. Patching documentation also follows the same order: if accepted, a patch is first applied to development, and if relevant then it's backported to maintenance. (With an exception for some patches that document behaviour that only appears in the maintenance branch, but which has changed in the development version.) To report a bug in Perl, use the program perlbug which comes with Perl (if you can't get Perl to work, send mail to the address perlbug@perl.org or perlbug@perl.com). Reporting bugs through perlbug feeds into the automated bug-tracking system, access to which is provided through the web at http:\/\/rt.perl.org\/rt3\/ . It often pays to check the archives of the perl5-porters mailing list to see whether the bug you're reporting has been reported before, and if so whether it was considered a bug. See above for the location of the searchable archives. The CPAN testers ( http:\/\/testers.cpan.org\/ ) are a group of volunteers who test CPAN modules on a variety of platforms. Perl Smokers ( http:\/\/www.nntp.perl.org\/group\/perl.daily-build and http:\/\/www.nntp.perl.org\/group\/perl.daily-build.reports\/ ) automatically test Perl source releases on platforms with various configurations. Both efforts welcome volunteers. In order to get involved in smoke testing of the perl itself visit <http:\/\/search.cpan.org\/dist\/Test-Smoke>. In order to start smoke testing CPAN modules visit <http:\/\/search.cpan.org\/dist\/CPAN-YACSmoke\/> or <http:\/\/search.cpan.org\/dist\/POE-Component-CPAN-YACSmoke\/> or <http:\/\/search.cpan.org\/dist\/CPAN-Reporter\/>. It's a good idea to read and lurk for a while before chipping in. That way you'll get to see the dynamic of the conversations, learn the personalities of the players, and hopefully be better prepared to make a useful contribution when do you speak up. If after all this you still think you want to join the perl5-porters mailing list, send mail to perl5-porters-subscribe@perl.org. To unsubscribe, send mail to perl5-porters-unsubscribe@perl.org. To hack on the Perl guts, you'll need to read the following things: perlguts This is of paramount importance, since it's the documentation of what goes where in the Perl source. Read it over a couple of times and it might start to make sense - don't worry if it doesn't yet, because the best way to study it is to read it in conjunction with poking at Perl source, and we'll do that later on. Gisle Aas's illustrated perlguts (aka: illguts) is wonderful, although a little out of date wrt some size details; the various SV structures have since been reworked for smaller memory footprint. The fundamentals are right however, and the pictures are very helpful. http:\/\/www.perl.org\/tpc\/1998\/Perl_Language_and_Modules\/Perl%20Illustrated\/ perlxstut and perlxs A working knowledge of XSUB programming is incredibly useful for core hacking; XSUBs use techniques drawn from the PP code, the portion of the guts that actually executes a Perl program. It's a lot gentler to learn those techniques from simple examples and explanation than from the core itself. perlapi The documentation for the Perl API explains what some of the internal functions do, as well as the many macros used in the source. Porting\/pumpkin.pod This is a collection of words of wisdom for a Perl porter; some of it is only useful to the pumpkin holder, but most of it applies to anyone wanting to go about Perl development. The perl5-porters FAQ This should be available from http:\/\/dev.perl.org\/perl5\/docs\/p5p-faq.html . It contains hints on reading perl5-porters, information on how perl5-porters works and how Perl development in general works. Finding Your Way Around Perl maintenance can be split into a number of areas, and certain people (pumpkins) will have responsibility for each area. These areas sometimes correspond to files or directories in the source kit. Among the areas are: Core modules Modules shipped as part of the Perl core live in the lib\/ and ext\/ subdirectories: lib\/ is for the pure-Perl modules, and ext\/ contains the core XS modules. Tests There are tests for nearly all the modules, built-ins and major bits of functionality. Test files all have a .t suffix. Module tests live in the lib\/ and ext\/ directories next to the module being tested. Others live in t\/. See \"Writing a test\" Documentation Documentation maintenance includes looking after everything in the pod\/ directory, (as well as contributing new documentation) and the documentation to the modules in core. Configure The configure process is the way we make Perl portable across the myriad of operating systems it supports. Responsibility for the configure, build and installation process, as well as the overall portability of the core code rests with the configure pumpkin - others help out with individual operating systems. The files involved are the operating system directories, (win32\/, os2\/, vms\/ and so on) the shell scripts which generate config.h and Makefile, as well as the metaconfig files which generate Configure. (metaconfig isn't included in the core distribution.) Interpreter And of course, there's the core of the Perl interpreter itself. Let's have a look at that in a little more detail. Before we leave looking at the layout, though, don't forget that MANIFEST contains not only the file names in the Perl distribution, but short descriptions of what's in them, too. For an overview of the important files, try this: perl -lne 'print if \/^[^\\\/]+\\.[ch]\\s+\/' MANIFEST Elements of the interpreter The work of the interpreter has two main stages: compiling the code into the internal representation, or bytecode, and then executing it. \"Compiled code\" in perlguts explains exactly how the compilation stage happens. Here is a short breakdown of perl's operation: Startup The action begins in perlmain.c. (or miniperlmain.c for miniperl) This is very high-level code, enough to fit on a single screen, and it resembles the code found in perlembed; most of the real action takes place in perl.c perlmain.c is generated by writemain from miniperlmain.c at make time, so you should make perl to follow this along. First, perlmain.c allocates some memory and constructs a Perl interpreter, along these lines: 1 PERL_SYS_INIT3(&argc,&argv,&env);\n2\n3 if (!PL_do_undump) {\n4     my_perl = perl_alloc();\n5     if (!my_perl)\n6         exit(1);\n7     perl_construct(my_perl);\n8     PL_perl_destruct_level = 0;\n9 } Line 1 is a macro, and its definition is dependent on your operating system. Line 3 references \"PL_do_undump\", a global variable - all global variables in Perl start with \"PL_\". This tells you whether the current running program was created with the \"-u\" flag to perl and then undump, which means it's going to be false in any sane context. Line 4 calls a function in perl.c to allocate memory for a Perl interpreter. It's quite a simple function, and the guts of it looks like this: my_perl = (PerlInterpreter*)PerlMem_malloc(sizeof(PerlInterpreter)); Here you see an example of Perl's system abstraction, which we'll see later: \"PerlMem_malloc\" is either your system's \"malloc\", or Perl's own \"malloc\" as defined in malloc.c if you selected that option at configure time. Next, in line 7, we construct the interpreter using perl_construct, also in perl.c; this sets up all the special variables that Perl needs, the stacks, and so on. Now we pass Perl the command line options, and tell it to go: exitstatus = perl_parse(my_perl, xs_init, argc, argv, (char **)NULL);\nif (!exitstatus)\n    perl_run(my_perl);\n\nexitstatus = perl_destruct(my_perl);\n\nperl_free(my_perl); \"perl_parse\" is actually a wrapper around \"S_parse_body\", as defined in perl.c, which processes the command line options, sets up any statically linked XS modules, opens the program and calls \"yyparse\" to parse it. Parsing The aim of this stage is to take the Perl source, and turn it into an op tree. We'll see what one of those looks like later. Strictly speaking, there's three things going on here. \"yyparse\", the parser, lives in perly.c, although you're better off reading the original YACC input in perly.y. (Yes, Virginia, there is a YACC grammar for Perl!) The job of the parser is to take your code and \"understand\" it, splitting it into sentences, deciding which operands go with which operators and so on. The parser is nobly assisted by the lexer, which chunks up your input into tokens, and decides what type of thing each token is: a variable name, an operator, a bareword, a subroutine, a core function, and so on. The main point of entry to the lexer is \"yylex\", and that and its associated routines can be found in toke.c. Perl isn't much like other computer languages; it's highly context sensitive at times, it can be tricky to work out what sort of token something is, or where a token ends. As such, there's a lot of interplay between the tokeniser and the parser, which can get pretty frightening if you're not used to it. As the parser understands a Perl program, it builds up a tree of operations for the interpreter to perform during execution. The routines which construct and link together the various operations are to be found in op.c, and will be examined later. Optimization Now the parsing stage is complete, and the finished tree represents the operations that the Perl interpreter needs to perform to execute our program. Next, Perl does a dry run over the tree looking for optimisations: constant expressions such as \"3 + 4\" will be computed now, and the optimizer will also see if any multiple operations can be replaced with a single one. For instance, to fetch the variable $foo, instead of grabbing the glob *foo and looking at the scalar component, the optimizer fiddles the op tree to use a function which directly looks up the scalar in question. The main optimizer is \"peep\" in op.c, and many ops have their own optimizing functions. Running Now we're finally ready to go: we have compiled Perl byte code, and all that's left to do is run it. The actual execution is done by the \"runops_standard\" function in run.c; more specifically, it's done by these three innocent looking lines: while ((PL_op = CALL_FPTR(PL_op->op_ppaddr)(aTHX))) {\n    PERL_ASYNC_CHECK();\n} You may be more comfortable with the Perl version of that: PERL_ASYNC_CHECK() while $Perl::op = &{$Perl::op->{function}}; Well, maybe not. Anyway, each op contains a function pointer, which stipulates the function which will actually carry out the operation. This function will return the next op in the sequence - this allows for things like \"if\" which choose the next op dynamically at run time. The \"PERL_ASYNC_CHECK\" makes sure that things like signals interrupt execution if required. The actual functions called are known as PP code, and they're spread between four files: pp_hot.c contains the \"hot\" code, which is most often used and highly optimized, pp_sys.c contains all the system-specific functions, pp_ctl.c contains the functions which implement control structures (\"if\", \"while\" and the like) and pp.c contains everything else. These are, if you like, the C code for Perl's built-in functions and operators. Note that each \"pp_\" function is expected to return a pointer to the next op. Calls to perl subs (and eval blocks) are handled within the same runops loop, and do not consume extra space on the C stack. For example, \"pp_entersub\" and \"pp_entertry\" just push a \"CxSUB\" or \"CxEVAL\" block struct onto the context stack which contain the address of the op following the sub call or eval. They then return the first op of that sub or eval block, and so execution continues of that sub or block. Later, a \"pp_leavesub\" or \"pp_leavetry\" op pops the \"CxSUB\" or \"CxEVAL\", retrieves the return op from it, and returns it. Exception handing Perl's exception handing (i.e. \"die\" etc.) is built on top of the low-level \"setjmp()\"\/ \"longjmp()\" C-library functions. These basically provide a way to capture the current PC and SP registers and later restore them; i.e. a \"longjmp()\" continues at the point in code where a previous \"setjmp()\" was done, with anything further up on the C stack being lost. This is why code should always save values using \"SAVE_FOO\" rather than in auto variables. The perl core wraps \"setjmp()\" etc in the macros \"JMPENV_PUSH\" and \"JMPENV_JUMP\". The basic rule of perl exceptions is that \"exit\", and \"die\" (in the absence of \"eval\") perform a JMPENV_JUMP(2), while \"die\" within \"eval\" does a JMPENV_JUMP(3). At entry points to perl, such as \"perl_parse()\", \"perl_run()\" and \"call_sv(cv, G_EVAL)\" each does a \"JMPENV_PUSH\", then enter a runops loop or whatever, and handle possible exception returns. For a 2 return, final cleanup is performed, such as popping stacks and calling \"CHECK\" or \"END\" blocks. Amongst other things, this is how scope cleanup still occurs during an \"exit\". If a \"die\" can find a \"CxEVAL\" block on the context stack, then the stack is popped to that level and the return op in that block is assigned to \"PL_restartop\"; then a JMPENV_JUMP(3) is performed. This normally passes control back to the guard. In the case of \"perl_run\" and \"call_sv\", a non-null \"PL_restartop\" triggers re-entry to the runops loop. The is the normal way that \"die\" or \"croak\" is handled within an \"eval\". Sometimes ops are executed within an inner runops loop, such as tie, sort or overload code. In this case, something like sub FETCH { eval { die } } would cause a longjmp right back to the guard in \"perl_run\", popping both runops loops, which is clearly incorrect. One way to avoid this is for the tie code to do a \"JMPENV_PUSH\" before executing \"FETCH\" in the inner runops loop, but for efficiency reasons, perl in fact just sets a flag, using \"CATCH_SET(TRUE)\". The \"pp_require\", \"pp_entereval\" and \"pp_entertry\" ops check this flag, and if true, they call \"docatch\", which does a \"JMPENV_PUSH\" and starts a new runops level to execute the code, rather than doing it on the current loop. As a further optimisation, on exit from the eval block in the \"FETCH\", execution of the code following the block is still carried on in the inner loop. When an exception is raised, \"docatch\" compares the \"JMPENV\" level of the \"CxEVAL\" with \"PL_top_env\" and if they differ, just re-throws the exception. In this way any inner loops get popped. Here's an example. 1: eval { tie @a, 'A' };\n2: sub A::TIEARRAY {\n3:     eval { die };\n4:     die;\n5: } To run this code, \"perl_run\" is called, which does a \"JMPENV_PUSH\" then enters a runops loop. This loop executes the eval and tie ops on line 1, with the eval pushing a \"CxEVAL\" onto the context stack. The \"pp_tie\" does a \"CATCH_SET(TRUE)\", then starts a second runops loop to execute the body of \"TIEARRAY\". When it executes the entertry op on line 3, \"CATCH_GET\" is true, so \"pp_entertry\" calls \"docatch\" which does a \"JMPENV_PUSH\" and starts a third runops loop, which then executes the die op. At this point the C call stack looks like this: Perl_pp_die\nPerl_runops      # third loop\nS_docatch_body\nS_docatch\nPerl_pp_entertry\nPerl_runops      # second loop\nS_call_body\nPerl_call_sv\nPerl_pp_tie\nPerl_runops      # first loop\nS_run_body\nperl_run\nmain and the context and data stacks, as shown by \"-Dstv\", look like: STACK 0: MAIN\n  CX 0: BLOCK  =>\n  CX 1: EVAL   => AV()  PV(\"A\"\\0)\n  retop=leave\nSTACK 1: MAGIC\n  CX 0: SUB    =>\n  retop=(null)\n  CX 1: EVAL   => *\nretop=nextstate The die pops the first \"CxEVAL\" off the context stack, sets \"PL_restartop\" from it, does a JMPENV_JUMP(3), and control returns to the top \"docatch\". This then starts another third-level runops level, which executes the nextstate, pushmark and die ops on line 4. At the point that the second \"pp_die\" is called, the C call stack looks exactly like that above, even though we are no longer within an inner eval; this is because of the optimization mentioned earlier. However, the context stack now looks like this, ie with the top CxEVAL popped: STACK 0: MAIN\n  CX 0: BLOCK  =>\n  CX 1: EVAL   => AV()  PV(\"A\"\\0)\n  retop=leave\nSTACK 1: MAGIC\n  CX 0: SUB    =>\n  retop=(null) The die on line 4 pops the context stack back down to the CxEVAL, leaving it as: STACK 0: MAIN\n  CX 0: BLOCK  => As usual, \"PL_restartop\" is extracted from the \"CxEVAL\", and a JMPENV_JUMP(3) done, which pops the C stack back to the docatch: S_docatch\nPerl_pp_entertry\nPerl_runops      # second loop\nS_call_body\nPerl_call_sv\nPerl_pp_tie\nPerl_runops      # first loop\nS_run_body\nperl_run\nmain In this case, because the \"JMPENV\" level recorded in the \"CxEVAL\" differs from the current one, \"docatch\" just does a JMPENV_JUMP(3) and the C stack unwinds to: perl_run\nmain Because \"PL_restartop\" is non-null, \"run_body\" starts a new runops loop and execution continues. Internal Variable Types You should by now have had a look at perlguts, which tells you about Perl's internal variable types: SVs, HVs, AVs and the rest. If not, do that now. These variables are used not only to represent Perl-space variables, but also any constants in the code, as well as some structures completely internal to Perl. The symbol table, for instance, is an ordinary Perl hash. Your code is represented by an SV as it's read into the parser; any program files you call are opened via ordinary Perl filehandles, and so on. The core Devel::Peek module lets us examine SVs from a Perl program. Let's see, for instance, how Perl treats the constant \"hello\".   % perl -MDevel::Peek -e 'Dump(\"hello\")'\n1 SV = PV(0xa041450) at 0xa04ecbc\n2   REFCNT = 1\n3   FLAGS = (POK,READONLY,pPOK)\n4   PV = 0xa0484e0 \"hello\"\\0\n5   CUR = 5\n6   LEN = 6 Reading \"Devel::Peek\" output takes a bit of practise, so let's go through it line by line. Line 1 tells us we're looking at an SV which lives at 0xa04ecbc in memory. SVs themselves are very simple structures, but they contain a pointer to a more complex structure. In this case, it's a PV , a structure which holds a string value, at location 0xa041450. Line 2 is the reference count; there are no other references to this data, so it's 1. Line 3 are the flags for this SV - it's OK to use it as a PV , it's a read-only SV (because it's a constant) and the data is a PV internally. Next we've got the contents of the string, starting at location 0xa0484e0. Line 5 gives us the current length of the string - note that this does not include the null terminator. Line 6 is not the length of the string, but the length of the currently allocated buffer; as the string grows, Perl automatically extends the available storage via a routine called \"SvGROW\". You can get at any of these quantities from C very easily; just add \"Sv\" to the name of the field shown in the snippet, and you've got a macro which will return the value: \"SvCUR(sv)\" returns the current length of the string, \"SvREFCOUNT(sv)\" returns the reference count, \"SvPV(sv, len)\" returns the string itself with its length, and so on. More macros to manipulate these properties can be found in perlguts. Let's take an example of manipulating a PV , from \"sv_catpvn\", in sv.c  1  void\n 2  Perl_sv_catpvn(pTHX_ register SV *sv, register const char *ptr, register STRLEN len)\n 3  {\n 4      STRLEN tlen;\n 5      char *junk;\n\n 6      junk = SvPV_force(sv, tlen);\n 7      SvGROW(sv, tlen + len + 1);\n 8      if (ptr == junk)\n 9          ptr = SvPVX(sv);\n10      Move(ptr,SvPVX(sv)+tlen,len,char);\n11      SvCUR(sv) += len;\n12      *SvEND(sv) = '\\0';\n13      (void)SvPOK_only_UTF8(sv);          \/* validate pointer *\/\n14      SvTAINT(sv);\n15  } This is a function which adds a string, \"ptr\", of length \"len\" onto the end of the PV stored in \"sv\". The first thing we do in line 6 is make sure that the SV has a valid PV , by calling the \"SvPV_force\" macro to force a PV . As a side effect, \"tlen\" gets set to the current value of the PV , and the PV itself is returned to \"junk\". In line 7, we make sure that the SV will have enough room to accommodate the old string, the new string and the null terminator. If \"LEN\" isn't big enough, \"SvGROW\" will reallocate space for us. Now, if \"junk\" is the same as the string we're trying to add, we can grab the string directly from the SV ; \"SvPVX\" is the address of the PV in the SV . Line 10 does the actual catenation: the \"Move\" macro moves a chunk of memory around: we move the string \"ptr\" to the end of the PV - that's the start of the PV plus its current length. We're moving \"len\" bytes of type \"char\". After doing so, we need to tell Perl we've extended the string, by altering \"CUR\" to reflect the new length. \"SvEND\" is a macro which gives us the end of the string, so that needs to be a \"\\0\". Line 13 manipulates the flags; since we've changed the PV , any IV or NV values will no longer be valid: if we have \"$a=10; $a.=\"6\";\" we don't want to use the old IV of 10. \"SvPOK_only_utf8\" is a special UTF-8-aware version of \"SvPOK_only\", a macro which turns off the IOK and NOK flags and turns on POK . The final \"SvTAINT\" is a macro which launders tainted data if taint mode is turned on. AVs and HVs are more complicated, but SVs are by far the most common variable type being thrown around. Having seen something of how we manipulate these, let's go on and look at how the op tree is constructed. Op Trees First, what is the op tree, anyway? The op tree is the parsed representation of your program, as we saw in our section on parsing, and it's the sequence of operations that Perl goes through to execute your program, as we saw in \"Running\". An op is a fundamental operation that Perl can perform: all the built-in functions and operators are ops, and there are a series of ops which deal with concepts the interpreter needs internally - entering and leaving a block, ending a statement, fetching a variable, and so on. The op tree is connected in two ways: you can imagine that there are two \"routes\" through it, two orders in which you can traverse the tree. First, parse order reflects how the parser understood the code, and secondly, execution order tells perl what order to perform the operations in. The easiest way to examine the op tree is to stop Perl after it has finished parsing, and get it to dump out the tree. This is exactly what the compiler backends B::Terse, B::Concise and B::Debug do. Let's have a look at how Perl sees \"$a = $b + $c\":  % perl -MO=Terse -e '$a=$b+$c'\n 1  LISTOP (0x8179888) leave\n 2      OP (0x81798b0) enter\n 3      COP (0x8179850) nextstate\n 4      BINOP (0x8179828) sassign\n 5          BINOP (0x8179800) add [1]\n 6              UNOP (0x81796e0) null [15]\n 7                  SVOP (0x80fafe0) gvsv  GV (0x80fa4cc) *b\n 8              UNOP (0x81797e0) null [15]\n 9                  SVOP (0x8179700) gvsv  GV (0x80efeb0) *c\n10          UNOP (0x816b4f0) null [15]\n11              SVOP (0x816dcf0) gvsv  GV (0x80fa460) *a Let's start in the middle, at line 4. This is a BINOP , a binary operator, which is at location 0x8179828. The specific operator in question is \"sassign\" - scalar assignment - and you can find the code which implements it in the function \"pp_sassign\" in pp_hot.c. As a binary operator, it has two children: the add operator, providing the result of \"$b+$c\", is uppermost on line 5, and the left hand side is on line 10. Line 10 is the null op: this does exactly nothing. What is that doing there? If you see the null op, it's a sign that something has been optimized away after parsing. As we mentioned in \"Optimization\", the optimization stage sometimes converts two operations into one, for example when fetching a scalar variable. When this happens, instead of rewriting the op tree and cleaning up the dangling pointers, it's easier just to replace the redundant operation with the null op. Originally, the tree would have looked like this: 10          SVOP (0x816b4f0) rv2sv [15]\n11              SVOP (0x816dcf0) gv  GV (0x80fa460) *a That is, fetch the \"a\" entry from the main symbol table, and then look at the scalar component of it: \"gvsv\" ( \"pp_gvsv\" into pp_hot.c) happens to do both these things. The right hand side, starting at line 5 is similar to what we've just seen: we have the \"add\" op (\"pp_add\" also in pp_hot.c) add together two \"gvsv\"s. Now, what's this about? 1  LISTOP (0x8179888) leave\n2      OP (0x81798b0) enter\n3      COP (0x8179850) nextstate \"enter\" and \"leave\" are scoping ops, and their job is to perform any housekeeping every time you enter and leave a block: lexical variables are tidied up, unreferenced variables are destroyed, and so on. Every program will have those first three lines: \"leave\" is a list, and its children are all the statements in the block. Statements are delimited by \"nextstate\", so a block is a collection of \"nextstate\" ops, with the ops to be performed for each statement being the children of \"nextstate\". \"enter\" is a single op which functions as a marker. That's how Perl parsed the program, from top to bottom:  Program\n    |\nStatement\n    |\n    =\n   \/ \\\n  \/   \\\n $a   +\n     \/ \\\n   $b   $c However, it's impossible to perform the operations in this order: you have to find the values of $b and $c before you add them together, for instance. So, the other thread that runs through the op tree is the execution order: each op has a field \"op_next\" which points to the next op to be run, so following these pointers tells us how perl executes the code. We can traverse the tree in this order using the \"exec\" option to \"B::Terse\": % perl -MO=Terse,exec -e '$a=$b+$c'\n1  OP (0x8179928) enter\n2  COP (0x81798c8) nextstate\n3  SVOP (0x81796c8) gvsv  GV (0x80fa4d4) *b\n4  SVOP (0x8179798) gvsv  GV (0x80efeb0) *c\n5  BINOP (0x8179878) add [1]\n6  SVOP (0x816dd38) gvsv  GV (0x80fa468) *a\n7  BINOP (0x81798a0) sassign\n8  LISTOP (0x8179900) leave This probably makes more sense for a human: enter a block, start a statement. Get the values of $b and $c, and add them together. Find $a, and assign one to the other. Then leave. The way Perl builds up these op trees in the parsing process can be unravelled by examining perly.y, the YACC grammar. Let's take the piece we need to construct the tree for \"$a = $b + $c\" 1 term    :   term ASSIGNOP term\n2                { $$ = newASSIGNOP(OPf_STACKED, $1, $2, $3); }\n3         |   term ADDOP term\n4                { $$ = newBINOP($2, 0, scalar($1), scalar($3)); } If you're not used to reading BNF grammars, this is how it works: You're fed certain things by the tokeniser, which generally end up in upper case. Here, \"ADDOP\", is provided when the tokeniser sees \"+\" in your code. \"ASSIGNOP\" is provided when \"=\" is used for assigning. These are \"terminal symbols\", because you can't get any simpler than them. The grammar, lines one and three of the snippet above, tells you how to build up more complex forms. These complex forms, \"non-terminal symbols\" are generally placed in lower case. \"term\" here is a non-terminal symbol, representing a single expression. The grammar gives you the following rule: you can make the thing on the left of the colon if you see all the things on the right in sequence. This is called a \"reduction\", and the aim of parsing is to completely reduce the input. There are several different ways you can perform a reduction, separated by vertical bars: so, \"term\" followed by \"=\" followed by \"term\" makes a \"term\", and \"term\" followed by \"+\" followed by \"term\" can also make a \"term\". So, if you see two terms with an \"=\" or \"+\", between them, you can turn them into a single expression. When you do this, you execute the code in the block on the next line: if you see \"=\", you'll do the code in line 2. If you see \"+\", you'll do the code in line 4. It's this code which contributes to the op tree. |   term ADDOP term\n{ $$ = newBINOP($2, 0, scalar($1), scalar($3)); } What this does is creates a new binary op, and feeds it a number of variables. The variables refer to the tokens: $1 is the first token in the input, $2 the second, and so on - think regular expression backreferences. $$ is the op returned from this reduction. So, we call \"newBINOP\" to create a new binary operator. The first parameter to \"newBINOP\", a function in op.c, is the op type. It's an addition operator, so we want the type to be \"ADDOP\". We could specify this directly, but it's right there as the second token in the input, so we use $2. The second parameter is the op's flags: 0 means \"nothing special\". Then the things to add: the left and right hand side of our expression, in scalar context. Stacks When perl executes something like \"addop\", how does it pass on its results to the next op? The answer is, through the use of stacks. Perl has a number of stacks to store things it's currently working on, and we'll look at the three most important ones here. Argument stack Arguments are passed to PP code and returned from PP code using the argument stack, \"ST\". The typical way to handle arguments is to pop them off the stack, deal with them how you wish, and then push the result back onto the stack. This is how, for instance, the cosine operator works: NV value;\nvalue = POPn;\nvalue = Perl_cos(value);\nXPUSHn(value); We'll see a more tricky example of this when we consider Perl's macros below. \"POPn\" gives you the NV (floating point value) of the top SV on the stack: the $x in \"cos($x)\". Then we compute the cosine, and push the result back as an NV . The \"X\" in \"XPUSHn\" means that the stack should be extended if necessary - it can't be necessary here, because we know there's room for one more item on the stack, since we've just removed one! The \"XPUSH*\" macros at least guarantee safety. Alternatively, you can fiddle with the stack directly: \"SP\" gives you the first element in your portion of the stack, and \"TOP*\" gives you the top SV\/IV\/NV\/etc. on the stack. So, for instance, to do unary negation of an integer: SETi(-TOPi); Just set the integer value of the top stack entry to its negation. Argument stack manipulation in the core is exactly the same as it is in XSUBs - see perlxstut, perlxs and perlguts for a longer description of the macros used in stack manipulation. Mark stack I say \"your portion of the stack\" above because PP code doesn't necessarily get the whole stack to itself: if your function calls another function, you'll only want to expose the arguments aimed for the called function, and not (necessarily) let it get at your own data. The way we do this is to have a \"virtual\" bottom-of-stack, exposed to each function. The mark stack keeps bookmarks to locations in the argument stack usable by each function. For instance, when dealing with a tied variable, (internally, something with \"P\" magic) Perl has to call methods for accesses to the tied variables. However, we need to separate the arguments exposed to the method to the argument exposed to the original function - the store or fetch or whatever it may be. Here's roughly how the tied \"push\" is implemented; see \"av_push\" in av.c: 1  PUSHMARK(SP);\n2  EXTEND(SP,2);\n3  PUSHs(SvTIED_obj((SV*)av, mg));\n4  PUSHs(val);\n5  PUTBACK;\n6  ENTER;\n7  call_method(\"PUSH\", G_SCALAR|G_DISCARD);\n8  LEAVE; Let's examine the whole implementation, for practice: 1  PUSHMARK(SP); Push the current state of the stack pointer onto the mark stack. This is so that when we've finished adding items to the argument stack, Perl knows how many things we've added recently. 2  EXTEND(SP,2);\n3  PUSHs(SvTIED_obj((SV*)av, mg));\n4  PUSHs(val); We're going to add two more items onto the argument stack: when you have a tied array, the \"PUSH\" subroutine receives the object and the value to be pushed, and that's exactly what we have here - the tied object, retrieved with \"SvTIED_obj\", and the value, the SV \"val\". 5  PUTBACK; Next we tell Perl to update the global stack pointer from our internal variable: \"dSP\" only gave us a local copy, not a reference to the global. 6  ENTER;\n7  call_method(\"PUSH\", G_SCALAR|G_DISCARD);\n8  LEAVE; \"ENTER\" and \"LEAVE\" localise a block of code - they make sure that all variables are tidied up, everything that has been localised gets its previous value returned, and so on. Think of them as the \"{\" and \"}\" of a Perl block. To actually do the magic method call, we have to call a subroutine in Perl space: \"call_method\" takes care of that, and it's described in perlcall. We call the \"PUSH\" method in scalar context, and we're going to discard its return value. The call_method() function removes the top element of the mark stack, so there is nothing for the caller to clean up. Save stack C doesn't have a concept of local scope, so perl provides one. We've seen that \"ENTER\" and \"LEAVE\" are used as scoping braces; the save stack implements the C equivalent of, for example: {\n    local $foo = 42;\n    ...\n} See \"Localising Changes\" in perlguts for how to use the save stack. Millions of Macros One thing you'll notice about the Perl source is that it's full of macros. Some have called the pervasive use of macros the hardest thing to understand, others find it adds to clarity. Let's take an example, the code which implements the addition operator: 1  PP(pp_add)\n2  {\n3      dSP; dATARGET; tryAMAGICbin(add,opASSIGN);\n4      {\n5        dPOPTOPnnrl_ul;\n6        SETn( left + right );\n7        RETURN;\n8      }\n9  } Every line here (apart from the braces, of course) contains a macro. The first line sets up the function declaration as Perl expects for PP code; line 3 sets up variable declarations for the argument stack and the target, the return value of the operation. Finally, it tries to see if the addition operation is overloaded; if so, the appropriate subroutine is called. Line 5 is another variable declaration - all variable declarations start with \"d\" - which pops from the top of the argument stack two NVs (hence \"nn\") and puts them into the variables \"right\" and \"left\", hence the \"rl\". These are the two operands to the addition operator. Next, we call \"SETn\" to set the NV of the return value to the result of adding the two values. This done, we return - the \"RETURN\" macro makes sure that our return value is properly handled, and we pass the next operator to run back to the main run loop. Most of these macros are explained in perlapi, and some of the more important ones are explained in perlxs as well. Pay special attention to \"Background and PERL_IMPLICIT_CONTEXT \" in perlguts for information on the \"[pad]THX_?\" macros. The .i Targets You can expand the macros in a foo.c file by saying make foo.i which will expand the macros using cpp. Don't be scared by the results.","Process Name":"perlhack","Link":"https:\/\/linux.die.net\/man\/1\/perlhack"}},{"Process":{"Description":"This file contains instructions how to build Perl for Haiku and lists known problems.","Process Name":"perlhaiku","Link":"https:\/\/linux.die.net\/man\/1\/perlhaiku"}},{"Process":{"Description":"This document aims to record the Perl source code releases.","Process Name":"perlhist","Link":"https:\/\/linux.die.net\/man\/1\/perlhist"}},{"Process":{"Description":"This document describes various features of HP 's Unix operating system (HP-UX) that will affect how Perl version 5 (hereafter just Perl) is compiled and\/or runs. Using perl as shipped with HP-UX Application release September 2001, HP-UX 11.00 is the first to ship with Perl. By the time it was perl-5.6.1 in \/opt\/perl. The first occurrence is on CD 5012-7954 and can be installed using swinstall -s \/cdrom perl assuming you have mounted that CD on \/cdrom. In this version the following modules were installed: ActivePerl::DocTools-0.04   HTML::Parser-3.19   XML::DOM-1.25\nArchive::Tar-0.072          HTML::Tagset-3.03   XML::Parser-2.27\nCompress::Zlib-1.08         MIME::Base64-2.11   XML::Simple-1.05\nConvert::ASN1-0.10          Net-1.07            XML::XPath-1.09\nDigest::MD5-2.11            PPM-2.1.5           XML::XSLT-0.32\nFile::CounterFile-0.12      SOAP::Lite-0.46     libwww-perl-5.51\nFont::AFM-1.18              Storable-1.011      libxml-perl-0.07\nHTML-Tree-3.11              URI-1.11            perl-ldap-0.23 That build was a portable hppa-1.1 multithread build that supports large files compiled with gcc-2.9-hppa-991112. If you perform a new installation, then (a newer) Perl will be installed automatically. Preinstalled HP-UX systems now slao have more recent versions of Perl and the updated modules. The official (threaded) builds from HP , as they are shipped on the Application DVD\/CD 's are available on http:\/\/www.software.hp.com\/cgi-bin\/swdepot_parser.cgi\/cgi\/displayProductInfo.pl?productNumber=PERL for both PA-RISC and IPF (Itanium Processor Family). They are built with the HP ANSI-C compiler by ActiveState. To see what version is included on the DVD (assumed here to be mounted on \/cdrom), issue this command: # swlist -s \/cdrom perl\n# perl           D.5.8.8.B  5.8.8 Perl Programming Language\n  perl.Perl5-32  D.5.8.8.B  32-bit 5.8.8 Perl Programming Language with Extensions\n  perl.Perl5-64  D.5.8.8.B  64-bit 5.8.8 Perl Programming Language with Extensions Using perl from HP 's porting centre HP porting centre tries very hard to keep up with customer demand and release updates from the Open Source community. Having precompiled Perl binaries available is obvious. The HP porting centres are limited in what systems they are allowed to port to and they usually choose the two most recent OS versions available. This means that at the moment of writing, there are only HP-UX 11.11 (pa-risc 2.0) and HP-UX 11.23 (Itanium 2) ports available on the porting centres. HP has asked the porting centre to move Open Source binaries from \/opt to \/usr\/local, so binaries produced since the start of July 2002 are located in \/usr\/local. One of HP porting centres URL 's is http:\/\/hpux.connect.org.uk\/ The port currently available is built with GNU gcc. Compiling Perl 5 on HP-UX When compiling Perl, you must use an ANSI C compiler. The C compiler that ships with all HP-UX systems is a K&R compiler that should only be used to build new kernels. Perl can be compiled with either HP 's ANSI C compiler or with gcc. The former is recommended, as not only can it compile Perl with no difficulty, but also can take advantage of features listed later that require the use of HP compiler-specific command-line flags. If you decide to use gcc, make sure your installation is recent and complete, and be sure to read the Perl INSTALL file for more gcc-specific details. PA-RISC HP 's HP9000 Unix systems run on HP 's own Precision Architecture (PA-RISC) chip. HP-UX used to run on the Motorola MC68000 family of chips, but any machine with this chip in it is quite obsolete and this document will not attempt to address issues for compiling Perl on the Motorola chipset. The version of PA-RISC at the time of this document's last update is 2.0, which is also the last there will be. HP PA-RISC systems are usually refered to with model description \" HP 9000\". The last CPU in this series is the PA-8900 . Support for PA-RISC architectured machines officially ends as shown in the following table:   PA-RISC End-of-Life Roadmap\n+--------+----------------+----------------+-----------------+\n| HP9000 | Superdome      | PA-8700        | Spring 2011     |\n| 4-128  |                | PA-8800\/sx1000 | Summer 2012     |\n| cores  |                | PA-8900\/sx1000 | 2014            |\n|        |                | PA-8900\/sx2000 | 2015            |\n+--------+----------------+----------------+-----------------+\n| HP9000 | rp7410, rp8400 | PA-8700        | Spring 2011     |\n| 2-32   | rp7420, rp8420 | PA-8800\/sx1000 | 2012            |\n| cores  | rp7440, rp8440 | PA-8900\/sx1000 | Autumn 2013     |\n|        |                | PA-8900\/sx2000 | 2015            |\n+--------+----------------+----------------+-----------------+\n| HP9000 | rp44x0         | PA-8700        | Spring 2011     |\n| 1-8    |                | PA-8800\/rp44x0 | 2012            |\n| cores  |                | PA-8900\/rp44x0 | 2014            |\n+--------+----------------+----------------+-----------------+\n| HP9000 | rp34x0         | PA-8700        | Spring 2011     |\n| 1-4    |                | PA-8800\/rp34x0 | 2012            |\n| cores  |                | PA-8900\/rp34x0 | 2014            |\n+--------+----------------+----------------+-----------------+ From http:\/\/www.hp.com\/products1\/evolution\/9000\/eol_announcement.html: The last order date for HP9000 PA-RISC systems is planned for\nDecember 31, 2008 and ship date of April 1, 2009. Operating system\nreleases for HP-UX will continue shipping past the HP9000 systems\nlast order date. A complete list of models at the time the OS was built is in the file \/usr\/sam\/lib\/mo\/sched.models. The first column corresponds to the last part of the output of the \"model\" command. The second column is the PA-RISC version and the third column is the exact chip type used. (Start browsing at the bottom to prevent confusion ;-) # model\n9000\/800\/L1000-44\n# grep L1000-44 \/usr\/sam\/lib\/mo\/sched.models\nL1000-44        2.0     PA8500 Portability Between PA-RISC Versions An executable compiled on a PA-RISC 2.0 platform will not execute on a PA-RISC 1.1 platform, even if they are running the same version of HP-UX. If you are building Perl on a PA-RISC 2.0 platform and want that Perl to also run on a PA-RISC 1.1, the compiler flags +DAportable and +DS32 should be used. It is no longer possible to compile PA-RISC 1.0 executables on either the PA-RISC 1.1 or 2.0 platforms. The command-line flags are accepted, but the resulting executable will not run when transferred to a PA-RISC 1.0 system. PA-RISC 1.0 The original version of PA-RISC, HP no longer sells any system with this chip. The following systems contained PA-RISC 1.0 chips: 600, 635, 645, 808, 815, 822, 825, 832, 834, 835, 840, 842, 845, 850,\n852, 855, 860, 865, 870, 890 PA-RISC 1.1 An upgrade to the PA-RISC design, it shipped for many years in many different system. The following systems contain with PA-RISC 1.1 chips: 705, 710, 712, 715, 720, 722, 725, 728, 730, 735, 742, 743, 744, 745,\n747, 750, 755, 770, 777, 778, 779, 800, 801, 803, 806, 807, 809, 811,\n813, 816, 817, 819, 821, 826, 827, 829, 831, 837, 839, 841, 847, 849,\n851, 856, 857, 859, 867, 869, 877, 887, 891, 892, 897, A180, A180C,\nB115, B120, B132L, B132L+, B160L, B180L, C100, C110, C115, C120,\nC160L, D200, D210, D220, D230, D250, D260, D310, D320, D330, D350,\nD360, D410, DX0, DX5, DXO, E25, E35, E45, E55, F10, F20, F30, G30,\nG40, G50, G60, G70, H20, H30, H40, H50, H60, H70, I30, I40, I50, I60,\nI70, J200, J210, J210XC, K100, K200, K210, K220, K230, K400, K410,\nK420, S700i, S715, S744, S760, T500, T520 PA-RISC 2.0 The most recent upgrade to the PA-RISC design, it added support for 64-bit integer data. As of the date of this document's last update, the following systems contain PA-RISC 2.0 chips: 700, 780, 781, 782, 783, 785, 802, 804, 810, 820, 861, 871, 879, 889,\n893, 895, 896, 898, 899, A400, A500, B1000, B2000, C130, C140, C160,\nC180, C180+, C180-XP, C200+, C400+, C3000, C360, C3600, CB260, D270,\nD280, D370, D380, D390, D650, J220, J2240, J280, J282, J400, J410,\nJ5000, J5500XM, J5600, J7000, J7600, K250, K260, K260-EG, K270, K360,\nK370, K380, K450, K460, K460-EG, K460-XP, K470, K570, K580, L1000,\nL2000, L3000, N4000, R380, R390, SD16000, SD32000, SD64000, T540,\nT600, V2000, V2200, V2250, V2500, V2600 Just before HP took over Compaq, some systems were renamed. the link that contained the explanation is dead, so here's a short summary: HP 9000 A-Class servers, now renamed HP Server rp2400 series.\nHP 9000 L-Class servers, now renamed HP Server rp5400 series.\nHP 9000 N-Class servers, now renamed HP Server rp7400.\n\nrp2400, rp2405, rp2430, rp2450, rp2470, rp3410, rp3440, rp4410,\nrp4440, rp5400, rp5405, rp5430, rp5450, rp5470, rp7400, rp7405,\nrp7410, rp7420, rp7440, rp8400, rp8420, rp8440, Superdome The current naming convention is: aadddd\n||||`+- 00 - 99 relative capacity & newness (upgrades, etc.)\n|||`--- unique number for each architecture to ensure different\n|||     systems do not have the same numbering across\n|||     architectures\n||`---- 1 - 9 identifies family and\/or relative positioning\n||\n|`----- c = ia32 (cisc)\n|       p = pa-risc\n|       x = ia-64 (Itanium & Itanium 2)\n|       h = housing\n`------ t = tower\n        r = rack optimized\n        s = super scalable\n        b = blade\n        sa = appliance Itanium Processor Family ( IPF ) and HP-UX HP-UX also runs on the new Itanium processor. This requires the use of a different version of HP-UX (currently 11.23 or 11i v2), and with the exception of a few differences detailed below and in later sections, Perl should compile with no problems. Although PA-RISC binaries can run on Itanium systems, you should not attempt to use a PA-RISC version of Perl on an Itanium system. This is because shared libraries created on an Itanium system cannot be loaded while running a PA-RISC executable. HP Itanium 2 systems are usually refered to with model description \" HP Integrity\". Itanium, Itanium 2 & Madison 6 HP also ships servers with the 128-bit Itanium processor(s). The cx26x0 is told to have Madison 6. As of the date of this document's last update, the following systems contain Itanium or Itanium 2 chips (this is likely to be out of date): BL60p, BL860c, BL870c, cx2600, cx2620, rx1600, rx1620, rx2600,\nrx2600hptc, rx2620, rx2660, rx3600, rx4610, rx4640, rx5670,\nrx6600, rx7420, rx7620, rx7640, rx8420, rx8620, rx8640, rx9610,\nsx1000, sx2000 To see all about your machine, type # model\nia64 hp server rx2600\n# \/usr\/contrib\/bin\/machinfo HP-UX versions Not all architectures ( PA = PA-RISC, IPF = Itanium Processor Family) support all versions of HP-UX, here is a short list HP-UX version  Kernel  Architecture\n-------------  ------  ------------\n10.20          32 bit  PA\n11.00          32\/64   PA\n11.11  11i v1  32\/64   PA\n11.22  11i v2     64        IPF\n11.23  11i v2     64   PA & IPF\n11.31  11i v3     64   PA & IPF See for the full list of hardware\/OS support and expected end-of-life http:\/\/www.hp.com\/go\/hpuxservermatrix Building Dynamic Extensions on HP-UX HP-UX supports dynamically loadable libraries (shared libraries). Shared libraries end with the suffix .sl. On Itanium systems, they end with the suffix .so. Shared libraries created on a platform using a particular PA-RISC version are not usable on platforms using an earlier PA-RISC version by default. However, this backwards compatibility may be enabled using the same +DAportable compiler flag (with the same PA-RISC 1.0 caveat mentioned above). Shared libraries created on an Itanium platform cannot be loaded on a PA-RISC platform. Shared libraries created on a PA-RISC platform can only be loaded on an Itanium platform if it is a PA-RISC executable that is attempting to load the PA-RISC library. A PA-RISC shared library cannot be loaded into an Itanium executable nor vice-versa. To create a shared library, the following steps must be performed: 1. Compile source modules with +z or +Z flag to create a .o module\n   which contains Position-Independent Code (PIC).  The linker will\n   tell you in the next step if +Z was needed.\n   (For gcc, the appropriate flag is -fpic or -fPIC.)\n\n2. Link the shared library using the -b flag.  If the code calls\n   any functions in other system libraries (e.g., libm), it must\n   be included on this line. (Note that these steps are usually handled automatically by the extension's Makefile). If these dependent libraries are not listed at shared library creation time, you will get fatal \"Unresolved symbol\" errors at run time when the library is loaded. You may create a shared library that refers to another library, which may be either an archive library or a shared library. If this second library is a shared library, this is called a \"dependent library\". The dependent library's name is recorded in the main shared library, but it is not linked into the shared library. Instead, it is loaded when the main shared library is loaded. This can cause problems if you build an extension on one system and move it to another system where the libraries may not be located in the same place as on the first system. If the referred library is an archive library, then it is treated as a simple collection of .o modules (all of which must contain PIC ). These modules are then linked into the shared library. Note that it is okay to create a library which contains a dependent library that is already linked into perl. Some extensions, like DB_File and Compress::Zlib use\/require prebuilt libraries for the perl extensions\/modules to work. If these libraries are built using the default configuration, it might happen that you run into an error like \"invalid loader fixup\" during load phase. HP is aware of this problem. Search the HP-UX cxx-dev forums for discussions about the subject. The short answer is that everything (all libraries, everything) must be compiled with \"+z\" or \"+Z\" to be PIC (position independent code). (For gcc, that would be \"-fpic\" or \"-fPIC\"). In HP-UX 11.00 or newer the linker error message should tell the name of the offending object file. A more general approach is to intervene manually, as with an example for the DB_File module, which requires SleepyCat's libdb.sl: # cd ...\/db-3.2.9\/build_unix\n# vi Makefile\n... add +Z to all cflags to create shared objects\nCFLAGS=         -c $(CPPFLAGS) +Z -Ae +O2 +Onolimit \\\n                -I\/usr\/local\/include -I\/usr\/include\/X11R6\nCXXFLAGS=       -c $(CPPFLAGS) +Z -Ae +O2 +Onolimit \\\n                -I\/usr\/local\/include -I\/usr\/include\/X11R6\n\n# make clean\n# make\n# mkdir tmp\n# cd tmp\n# ar x ..\/libdb.a\n# ld -b -o libdb-3.2.sl *.o\n# mv libdb-3.2.sl \/usr\/local\/lib\n# rm *.o\n# cd \/usr\/local\/lib\n# rm -f libdb.sl\n# ln -s libdb-3.2.sl libdb.sl\n\n# cd ...\/DB_File-1.76\n# make distclean\n# perl Makefile.PL\n# make\n# make test\n# make install As of db-4.2.x it is no longer needed to do this by hand. Sleepycat has changed the configuration process to add +z on HP-UX automatically. # cd ...\/db-4.2.25\/build_unix\n# env CFLAGS=+DD64 LDFLAGS=+DD64 ..\/dist\/configure should work to generate 64bit shared libraries for HP-UX 11.00 and 11i. It is no longer possible to link PA-RISC 1.0 shared libraries (even though the command-line flags are still present). PA-RISC and Itanium object files are not interchangeable. Although you may be able to use ar to create an archive library of PA-RISC object files on an Itanium system, you cannot link against it using an Itanium link editor. The HP ANSI C Compiler When using this compiler to build Perl, you should make sure that the flag -Aa is added to the cpprun and cppstdin variables in the config.sh file (though see the section on 64-bit perl below). If you are using a recent version of the Perl distribution, these flags are set automatically. Even though HP-UX 10.20 and 11.00 are not actively maintained by HP anymore, updates for the HP ANSI C compiler are still available from time to time, and it might be advisable to see if updates are applicable. At the moment of writing, the latests available patches for 11.00 that should be applied are PHSS_35098 , PHSS_35175 , PHSS_35100 , PHSS_33036 , and PHSS_33902 ). If you have a SUM account, you can use it to search for updates\/patches. Enter \" ANSI \" as keyword. The GNU C Compiler When you are going to use the GNU C compiler (gcc), and you don't have gcc yet, you can either build it yourself from the sources (available from e.g. http:\/\/www.gnu.ai.mit.edu\/software\/gcc\/releases.html) or fetch a prebuilt binary from the HP porting center. There are two places where gcc prebuilds can be fetched; the first and best (for HP-UX 11 only) is http:\/\/h21007.www2.hp.com\/dspp\/tech\/tech_TechSoftwareDetailPage_IDX\/1,1703,547,00.html the second is http:\/\/hpux.cs.utah.edu\/hppd\/hpux\/Gnu\/ where you can also find the GNU binutils package. (Browse through the list, because there are often multiple versions of the same package available). Above mentioned distributions are depots. H.Merijn Brand has made prebuilt gcc binaries available on http:\/\/mirrors.develooper.com\/hpux\/ and\/or http:\/\/www.cmve.net\/~merijn\/ for HP-UX 10.20, HP-UX 11.00, HP-UX 11.11 (HP-UX 11i v1), and HP-UX 11.23 (HP-UX 11i v2) in both 32- and 64-bit versions. These are bzipped tar archives that also include recent GNU binutils and GNU gdb. Read the instructions on that page to rebuild gcc using itself. On PA-RISC you need a different compiler for 32-bit applications and for 64-bit applications. On PA-RISC, 32-bit objects and 64-bit objects do not mix. Period. There is no different behaviour for HP C-ANSI-C or GNU gcc. So if you require your perl binary to use 64-bit libraries, like Oracle-64bit, you MUST build a 64-bit perl. Building a 64-bit capable gcc on PA-RISC from source is possible only when you have the HP C-ANSI C compiler or an already working 64-bit binary of gcc available. Best performance for perl is achieved with HP 's native compiler. Using Large Files with Perl on HP-UX Beginning with HP-UX version 10.20, files larger than 2GB (2^31 bytes) may be created and manipulated. Three separate methods of doing this are available. Of these methods, the best method for Perl is to compile using the -Duselargefiles flag to Configure. This causes Perl to be compiled using structures and functions in which these are 64 bits wide, rather than 32 bits wide. (Note that this will only work with HP 's ANSI C compiler. If you want to compile Perl using gcc, you will have to get a version of the compiler that supports 64-bit operations. See above for where to find it.) There are some drawbacks to this approach. One is that any extension which calls any file-manipulating C function will need to be recompiled (just follow the usual \"perl Makefile.PL; make; make test; make install\" procedure). The list of functions that will need to recompiled is: creat, fgetpos, fopen, freopen, fsetpos, fstat, fstatvfs, fstatvfsdev, ftruncate, ftw, lockf, lseek, lstat, mmap, nftw, open, prealloc, stat, statvfs, statvfsdev, tmpfile, truncate, getrlimit, setrlimit Another drawback is only valid for Perl versions before 5.6.0. This drawback is that the seek and tell functions (both the builtin version and POSIX module version) will not perform correctly. It is strongly recommended that you use this flag when you run Configure. If you do not do this, but later answer the question about large files when Configure asks you, you may get a configuration that cannot be compiled, or that does not function as expected. Threaded Perl on HP-UX It is possible to compile a version of threaded Perl on any version of HP-UX before 10.30, but it is strongly suggested that you be running on HP-UX 11.00 at least. To compile Perl with threads, add -Dusethreads to the arguments of Configure. Verify that the -D_POSIX_C_SOURCE=199506L compiler flag is automatically added to the list of flags. Also make sure that -lpthread is listed before -lc in the list of libraries to link Perl with. The hints provided for HP-UX during Configure will try very hard to get this right for you. HP-UX versions before 10.30 require a separate installation of a POSIX threads library package. Two examples are the HP DCE package, available on \"HP-UX Hardware Extensions 3.0, Install and Core OS , Release 10.20, April 1999 (B3920-13941)\" or the Freely available PTH package, available on H.Merijn's site (http:\/\/mirrors.develooper.com\/hpux\/). If you are going to use the HP DCE package, the library used for threading is \/usr\/lib\/libcma.sl, but there have been multiple updates of that library over time. Perl will build with the first version, but it will not pass the test suite. Older Oracle versions might be a compelling reason not to update that library, otherwise please find a newer version in one of the following patches: PHSS_19739 , PHSS_20608 , or PHSS_23672 reformatted output: d3:\/usr\/lib 106 > what libcma-*.1\nlibcma-00000.1:\n   HP DCE\/9000 1.5               Module: libcma.sl (Export)\n                                 Date: Apr 29 1996 22:11:24\nlibcma-19739.1:\n   HP DCE\/9000 1.5 PHSS_19739-40 Module: libcma.sl (Export)\n                                 Date: Sep  4 1999 01:59:07\nlibcma-20608.1:\n   HP DCE\/9000 1.5 PHSS_20608    Module: libcma.1 (Export)\n                                 Date: Dec  8 1999 18:41:23\nlibcma-23672.1:\n   HP DCE\/9000 1.5 PHSS_23672    Module: libcma.1 (Export)\n                                 Date: Apr  9 2001 10:01:06\nd3:\/usr\/lib 107 > If you choose for the PTH package, use swinstall to install pth in the default location (\/opt\/pth), and then make symbolic links to the libraries from \/usr\/lib # cd \/usr\/lib\n# ln -s \/opt\/pth\/lib\/libpth* . For building perl to support Oracle, it needs to be linked with libcl and libpthread. So even if your perl is an unthreaded build, these libraries might be required. See \"Oracle on HP-UX\" below. 64-bit Perl on HP-UX Beginning with HP-UX 11.00, programs compiled under HP-UX can take advantage of the LP64 programming environment ( LP64 means Longs and Pointers are 64 bits wide), in which scalar variables will be able to hold numbers larger than 2^32 with complete precision. Perl has proven to be consistent and reliable in 64bit mode since 5.8.1 on all HP-UX 11.xx. As of the date of this document, Perl is fully 64-bit compliant on HP-UX 11.00 and up for both cc- and gcc builds. If you are about to build a 64-bit perl with GNU gcc, please read the gcc section carefully. Should a user have the need for compiling Perl in the LP64 environment, use the -Duse64bitall flag to Configure. This will force Perl to be compiled in a pure LP64 environment (with the +DD64 flag for HP C-ANSI-C, with no additional options for GNU gcc 64-bit on PA-RISC, and with -mlp64 for GNU gcc on Itanium). If you want to compile Perl using gcc, you will have to get a version of the compiler that supports 64-bit operations.) You can also use the -Duse64bitint flag to Configure. Although there are some minor differences between compiling Perl with this flag versus the -Duse64bitall flag, they should not be noticeable from a Perl user's perspective. When configuring -Duse64bitint using a 64bit gcc on a pa-risc architecture, -Duse64bitint is silently promoted to -Duse64bitall. In both cases, it is strongly recommended that you use these flags when you run Configure. If you do not use do this, but later answer the questions about 64-bit numbers when Configure asks you, you may get a configuration that cannot be compiled, or that does not function as expected. Oracle on HP-UX Using perl to connect to Oracle databases through DBI and DBD::Oracle has caused a lot of people many headaches. Read README .hpux in the DBD::Oracle for much more information. The reason to mention it here is that Oracle requires a perl built with libcl and libpthread, the latter even when perl is build without threads. Building perl using all defaults, but still enabling to build DBD::Oracle later on can be achieved using Configure -A prepend:libswanted='cl pthread ' ... Do not forget the space before the trailing quote. Also note that this does not (yet) work with all configurations, it is known to fail with 64-bit versions of GCC . GDBM and Threads on HP-UX If you attempt to compile Perl with ( POSIX ) threads on an 11.X system and also link in the GDBM library, then Perl will immediately core dump when it starts up. The only workaround at this point is to relink the GDBM library under 11.X, then relink it into Perl. the error might show something like: Pthread internal error: message: __libc_reinit() failed, file: ..\/pthreads\/pthread.c, line: 1096 Return Pointer is 0xc082bf33 sh: 5345 Quit(coredump) and Configure will give up. NFS filesystems and utime(2) on HP-UX If you are compiling Perl on a remotely-mounted NFS filesystem, the test io\/fs.t may fail on test #18. This appears to be a bug in HP-UX and no fix is currently available. perl -P and \/\/ and HP-UX If HP-UX Perl is compiled with flags that will cause problems if the -P flag of Perl (preprocess Perl code with the C preprocessor before perl sees it) is used. The problem is that \"\/\/\", being a C ++ -style until-end-of-line comment, will disappear along with the remainder of the line. This means that common Perl constructs like s\/foo\/\/; will turn into illegal code s\/foo The workaround is to use some other quoting separator than \"\/\", like for example \"!\": s!foo!!; HP-UX Kernel Parameters (maxdsiz) for Compiling Perl By default, HP-UX comes configured with a maximum data segment size of 64MB. This is too small to correctly compile Perl with the maximum optimization levels. You can increase the size of the maxdsiz kernel parameter through the use of SAM . When using the GUI version of SAM , click on the Kernel Configuration icon, then the Configurable Parameters icon. Scroll down and select the maxdsiz line. From the Actions menu, select the Modify Configurable Parameter item. Insert the new formula into the Formula\/Value box. Then follow the instructions to rebuild your kernel and reboot your system. In general, a value of 256MB (or \"256*1024*1024\") is sufficient for Perl to compile at maximum optimization.","Process Name":"perlhpux","Link":"https:\/\/linux.die.net\/man\/1\/perlhpux"}},{"Process":{"Description":"If you want to use Perl on the Hurd, I recommend using the Debian GNU\/Hurd distribution ( see http:\/\/www.debian.org\/ ), even if an official, stable release has not yet been made. The old \"gnu-0.2\" binary distribution will most certainly have additional problems. Known Problems with Perl on Hurd The Perl test suite may still report some errors on the Hurd. The \"lib\/anydbm\" and \"pragma\/warnings\" tests will almost certainly fail. Both failures are not really specific to the Hurd, as indicated by the test suite output. The socket tests may fail if the network is not configured. You have to make \"\/hurd\/pfinet\" the translator for \"\/servers\/socket\/2\", giving it the right arguments. Try \"\/hurd\/pfinet --help\" for more information. Here are the statistics for Perl 5.005_62 on my system: Failed Test  Status Wstat Total Fail  Failed  List of failed\n-------------------------------------------------------------------------\nlib\/anydbm.t                 12    1   8.33%  12\npragma\/warnings             333    1   0.30%  215\n\n8 tests and 24 subtests skipped.\nFailed 2\/229 test scripts, 99.13% okay. 2\/10850 subtests failed, 99.98% okay. There are quite a few systems out there that do worse! However, since I am running a very recent Hurd snapshot, in which a lot of bugs that were exposed by the Perl test suite have been fixed, you may encounter more failures. Likely candidates are: \"op\/stat\", \"lib\/io_pipe\", \"lib\/io_sock\", \"lib\/io_udp\" and \"lib\/time\". In any way, if you're seeing failures beyond those mentioned in this document, please consider upgrading to the latest Hurd before reporting the failure as a bug.","Process Name":"perlhurd","Link":"https:\/\/linux.die.net\/man\/1\/perlhurd"}},{"Process":{"Description":"See HTML::Perlinfo for one.","Process Name":"perlinfo","Link":"https:\/\/linux.die.net\/man\/1\/perlinfo"}},{"Process":{"Description":"This file is the autogenerated documentation of functions in the Perl interpreter that are documented using Perl's internal documentation format but are not marked as part of the Perl API . In other words, they are not for use in extensions!","Process Name":"perlintern","Link":"https:\/\/linux.die.net\/man\/1\/perlintern"}},{"Process":{"Description":"This document is intended to give you a quick overview of the Perl programming language, along with pointers to further documentation. It is intended as a \"bootstrap\" guide for those who are new to the language, and provides just enough information for you to be able to read other peoples' Perl and understand roughly what it's doing, or write your own simple scripts. This introductory document does not aim to be complete. It does not even aim to be entirely accurate. In some cases perfection has been sacrificed in the goal of getting the general idea across. You are strongly advised to follow this introduction with more information from the full Perl manual, the table of contents to which can be found in perltoc. Throughout this document you'll see references to other parts of the Perl documentation. You can read that documentation using the \"perldoc\" command or whatever method you're using to read this document. What is Perl? Perl is a general-purpose programming language originally developed for text manipulation and now used for a wide range of tasks including system administration, web development, network programming, GUI development, and more. The language is intended to be practical (easy to use, efficient, complete) rather than beautiful (tiny, elegant, minimal). Its major features are that it's easy to use, supports both procedural and object-oriented ( OO ) programming, has powerful built-in support for text processing, and has one of the world's most impressive collections of third-party modules. Different definitions of Perl are given in perl, perlfaq1 and no doubt other places. From this we can determine that Perl is different things to different people, but that lots of people think it's at least worth writing about. Running Perl programs To run a Perl program from the Unix command line: perl progname.pl Alternatively, put this as the first line of your script: #!\/usr\/bin\/env perl ... and run the script as \"\/path\/to\/script.pl\". Of course, it'll need to be executable first, so \"chmod 755 script.pl\" (under Unix). (This start line assumes you have the env program. You can also put directly the path to your perl executable, like in \"#!\/usr\/bin\/perl\"). For more information, including instructions for other platforms such as Windows and Mac OS , read perlrun. Safety net Perl by default is very forgiving. In order to make it more robust it is recommended to start every program with the following lines: #!\/usr\/bin\/perl\nuse strict;\nuse warnings; The two additional lines request from perl to catch various common problems in your code. They check different things so you need both. A potential problem caught by \"use strict;\" will cause your code to stop immediately when it is encountered, while \"use warnings;\" will merely give a warning (like the command-line switch -w) and let your code run. To read more about them check their respective manual pages at strict and warnings. Basic syntax overview A Perl script or program consists of one or more statements. These statements are simply written in the script in a straightforward fashion. There is no need to have a \"main()\" function or anything of that kind. Perl statements end in a semi-colon: print \"Hello, world\"; Comments start with a hash symbol and run to the end of the line # This is a comment Whitespace is irrelevant: print\n    \"Hello, world\"\n    ; ... except inside quoted strings: # this would print with a linebreak in the middle\nprint \"Hello\nworld\"; Double quotes or single quotes may be used around literal strings: print \"Hello, world\";\nprint 'Hello, world'; However, only double quotes \"interpolate\" variables and special characters such as newlines ( \"\\n\"): print \"Hello, $name\\n\";     # works fine\nprint 'Hello, $name\\n';     # prints $name\\n literally Numbers don't need quotes around them: print 42; You can use parentheses for functions' arguments or omit them according to your personal taste. They are only required occasionally to clarify issues of precedence. print(\"Hello, world\\n\");\nprint \"Hello, world\\n\"; More detailed information about Perl syntax can be found in perlsyn. Perl variable types Perl has three main variable types: scalars, arrays, and hashes. Scalars A scalar represents a single value: my $animal = \"camel\";\nmy $answer = 42; Scalar values can be strings, integers or floating point numbers, and Perl will automatically convert between them as required. There is no need to pre-declare your variable types, but you have to declare them using the \"my\" keyword the first time you use them. (This is one of the requirements of \"use strict;\".) Scalar values can be used in various ways: print $animal;\nprint \"The animal is $animal\\n\";\nprint \"The square of $answer is \", $answer * $answer, \"\\n\"; There are a number of \"magic\" scalars with names that look like punctuation or line noise. These special variables are used for all kinds of purposes, and are documented in perlvar. The only one you need to know about for now is $_ which is the \"default variable\". It's used as the default argument to a number of functions in Perl, and it's set implicitly by certain looping constructs. print;          # prints contents of $_ by default Arrays An array represents a list of values: my @animals = (\"camel\", \"llama\", \"owl\");\nmy @numbers = (23, 42, 69);\nmy @mixed   = (\"camel\", 42, 1.23); Arrays are zero-indexed. Here's how you get at elements in an array: print $animals[0];              # prints \"camel\"\nprint $animals[1];              # prints \"llama\" The special variable $#array tells you the index of the last element of an array: print $mixed[$#mixed];       # last element, prints 1.23 You might be tempted to use \"$#array + 1\" to tell you how many items there are in an array. Don't bother. As it happens, using @array where Perl expects to find a scalar value (\"in scalar context\") will give you the number of elements in the array: if (@animals < 5) { ... } The elements we're getting from the array start with a \"$\" because we're getting just a single value out of the array -- you ask for a scalar, you get a scalar. To get multiple values from an array: @animals[0,1];                  # gives (\"camel\", \"llama\");\n@animals[0..2];                 # gives (\"camel\", \"llama\", \"owl\");\n@animals[1..$#animals];         # gives all except the first element This is called an \"array slice\". You can do various useful things to lists: my @sorted    = sort @animals;\nmy @backwards = reverse @numbers; There are a couple of special arrays too, such as @ARGV (the command line arguments to your script) and @_ (the arguments passed to a subroutine). These are documented in perlvar. Hashes A hash represents a set of key\/value pairs: my %fruit_color = (\"apple\", \"red\", \"banana\", \"yellow\"); You can use whitespace and the \"=>\" operator to lay them out more nicely: my %fruit_color = (\n    apple  => \"red\",\n    banana => \"yellow\",\n); To get at hash elements: $fruit_color{\"apple\"};           # gives \"red\" You can get at lists of keys and values with \"keys()\" and \"values()\". my @fruits = keys %fruit_colors;\nmy @colors = values %fruit_colors; Hashes have no particular internal order, though you can sort the keys and loop through them. Just like special scalars and arrays, there are also special hashes. The most well known of these is %ENV which contains environment variables. Read all about it (and other special variables) in perlvar. Scalars, arrays and hashes are documented more fully in perldata. More complex data types can be constructed using references, which allow you to build lists and hashes within lists and hashes. A reference is a scalar value and can refer to any other Perl data type. So by storing a reference as the value of an array or hash element, you can easily create lists and hashes within lists and hashes. The following example shows a 2 level hash of hash structure using anonymous hash references. my $variables = {\n    scalar  =>  {\n                 description => \"single item\",\n                 sigil => '$',\n                },\n    array   =>  {\n                 description => \"ordered list of items\",\n                 sigil => '@',\n                },\n    hash    =>  {\n                 description => \"key\/value pairs\",\n                 sigil => '%',\n                },\n};\n\nprint \"Scalars begin with a $variables->{'scalar'}->{'sigil'}\\n\"; Exhaustive information on the topic of references can be found in perlreftut, perllol, perlref and perldsc. Variable scoping Throughout the previous section all the examples have used the syntax: my $var = \"value\"; The \"my\" is actually not required; you could just use: $var = \"value\"; However, the above usage will create global variables throughout your program, which is bad programming practice. \"my\" creates lexically scoped variables instead. The variables are scoped to the block (i.e. a bunch of statements surrounded by curly-braces) in which they are defined. my $x = \"foo\";\nmy $some_condition = 1;\nif ($some_condition) {\n    my $y = \"bar\";\n    print $x;           # prints \"foo\"\n    print $y;           # prints \"bar\"\n}\nprint $x;               # prints \"foo\"\nprint $y;               # prints nothing; $y has fallen out of scope Using \"my\" in combination with a \"use strict;\" at the top of your Perl scripts means that the interpreter will pick up certain common programming errors. For instance, in the example above, the final \"print $y\" would cause a compile-time error and prevent you from running the program. Using \"strict\" is highly recommended. Conditional and looping constructs Perl has most of the usual conditional and looping constructs except for case\/switch (but if you really want it, there is a Switch module in Perl 5.8 and newer, and on CPAN . See the section on modules, below, for more information about modules and CPAN ). The conditions can be any Perl expression. See the list of operators in the next section for information on comparison and boolean logic operators, which are commonly used in conditional statements. if if ( condition ) {\n    ...\n} elsif ( other condition ) {\n    ...\n} else {\n    ...\n} There's also a negated version of it: unless ( condition ) {\n    ...\n} This is provided as a more readable version of \"if (! condition )\". Note that the braces are required in Perl, even if you've only got one line in the block. However, there is a clever way of making your one-line conditional blocks more English like: # the traditional way\nif ($zippy) {\n    print \"Yow!\";\n}\n\n# the Perlish post-condition way\nprint \"Yow!\" if $zippy;\nprint \"We have no bananas\" unless $bananas; while while ( condition ) {\n    ...\n} There's also a negated version, for the same reason we have \"unless\": until ( condition ) {\n    ...\n} You can also use \"while\" in a post-condition: print \"LA LA LA\\n\" while 1;          # loops forever for Exactly like C: for ($i = 0; $i <= $max; $i++) {\n    ...\n} The C style for loop is rarely needed in Perl since Perl provides the more friendly list scanning \"foreach\" loop. foreach foreach (@array) {\n    print \"This element is $_\\n\";\n}\n\nprint $list[$_] foreach 0 .. $max;\n\n# you don't have to use the default $_ either...\nforeach my $key (keys %hash) {\n    print \"The value of $key is $hash{$key}\\n\";\n} For more detail on looping constructs (and some that weren't mentioned in this overview) see perlsyn. Builtin operators and functions Perl comes with a wide selection of builtin functions. Some of the ones we've already seen include \"print\", \"sort\" and \"reverse\". A list of them is given at the start of perlfunc and you can easily read about any given function by using \"perldoc -f functionname \". Perl operators are documented in full in perlop, but here are a few of the most common ones: Arithmetic +   addition\n-   subtraction\n*   multiplication\n\/   division Numeric comparison ==  equality\n!=  inequality\n<   less than\n>   greater than\n<=  less than or equal\n>=  greater than or equal String comparison eq  equality\nne  inequality\nlt  less than\ngt  greater than\nle  less than or equal\nge  greater than or equal (Why do we have separate numeric and string comparisons? Because we don't have special variable types, and Perl needs to know whether to sort numerically (where 99 is less than 100) or alphabetically (where 100 comes before 99). Boolean logic &&  and\n||  or\n!   not ( \"and\", \"or\" and \"not\" aren't just in the above table as descriptions of the operators -- they're also supported as operators in their own right. They're more readable than the C-style operators, but have different precedence to \"&&\" and friends. Check perlop for more detail.) Miscellaneous =   assignment\n.   string concatenation\nx   string multiplication\n..  range operator (creates a list of numbers) Many operators can be combined with a \"=\" as follows: $a += 1;        # same as $a = $a + 1\n$a -= 1;        # same as $a = $a - 1\n$a .= \"\\n\";     # same as $a = $a . \"\\n\"; Files and I\/O You can open a file for input or output using the \"open()\" function. It's documented in extravagant detail in perlfunc and perlopentut, but in short: open(my $in,  \"<\",  \"input.txt\")  or die \"Can't open input.txt: $!\";\nopen(my $out, \">\",  \"output.txt\") or die \"Can't open output.txt: $!\";\nopen(my $log, \">>\", \"my.log\")     or die \"Can't open my.log: $!\"; You can read from an open filehandle using the \"<>\" operator. In scalar context it reads a single line from the filehandle, and in list context it reads the whole file in, assigning each line to an element of the list: my $line  = <$in>;\nmy @lines = <$in>; Reading in the whole file at one time is called slurping. It can be useful but it may be a memory hog. Most text file processing can be done a line at a time with Perl's looping constructs. The \"<>\" operator is most often seen in a \"while\" loop: while (<$in>) {     # assigns each line in turn to $_\n    print \"Just read in this line: $_\";\n} We've already seen how to print to standard output using \"print()\". However, \"print()\" can also take an optional first argument specifying which filehandle to print to: print STDERR \"This is your final warning.\\n\";\nprint $out $record;\nprint $log $logmessage; When you're done with your filehandles, you should \"close()\" them (though to be honest, Perl will clean up after you if you forget): close $in or die \"$in: $!\"; Regular expressions Perl's regular expression support is both broad and deep, and is the subject of lengthy documentation in perlrequick, perlretut, and elsewhere. However, in short: Simple matching if (\/foo\/)       { ... }  # true if $_ contains \"foo\"\nif ($a =~ \/foo\/) { ... }  # true if $a contains \"foo\" The \"\/\/\" matching operator is documented in perlop. It operates on $_ by default, or can be bound to another variable using the \"=~\" binding operator (also documented in perlop). Simple substitution s\/foo\/bar\/;               # replaces foo with bar in $_\n$a =~ s\/foo\/bar\/;         # replaces foo with bar in $a\n$a =~ s\/foo\/bar\/g;        # replaces ALL INSTANCES of foo with bar in $a The \"s\/\/\/\" substitution operator is documented in perlop. More complex regular expressions You don't just have to match on fixed strings. In fact, you can match on just about anything you could dream of by using more complex regular expressions. These are documented at great length in perlre, but for the meantime, here's a quick cheat sheet: .                   a single character\n\\s                  a whitespace character (space, tab, newline, ...)\n\\S                  non-whitespace character\n\\d                  a digit (0-9)\n\\D                  a non-digit\n\\w                  a word character (a-z, A-Z, 0-9, _)\n\\W                  a non-word character\n[aeiou]             matches a single character in the given set\n[^aeiou]            matches a single character outside the given set\n(foo|bar|baz)       matches any of the alternatives specified\n\n^                   start of string\n$                   end of string Quantifiers can be used to specify how many of the previous thing you want to match on, where \"thing\" means either a literal character, one of the metacharacters listed above, or a group of characters or metacharacters in parentheses. *                   zero or more of the previous thing\n+                   one or more of the previous thing\n?                   zero or one of the previous thing\n{3}                 matches exactly 3 of the previous thing\n{3,6}               matches between 3 and 6 of the previous thing\n{3,}                matches 3 or more of the previous thing Some brief examples: \/^\\d+\/              string starts with one or more digits\n\/^$\/                nothing in the string (start and end are adjacent)\n\/(\\d\\s){3}\/         a three digits, each followed by a whitespace\n                    character (eg \"3 4 5 \")\n\/(a.)+\/             matches a string in which every odd-numbered letter\n                    is a (eg \"abacadaf\")\n\n# This loop reads from STDIN, and prints non-blank lines:\nwhile (<>) {\n    next if \/^$\/;\n    print;\n} Parentheses for capturing As well as grouping, parentheses serve a second purpose. They can be used to capture the results of parts of the regexp match for later use. The results end up in $1, $2 and so on. # a cheap and nasty way to break an email address up into parts\n\nif ($email =~ \/([^@]+)@(.+)\/) {\n    print \"Username is $1\\n\";\n    print \"Hostname is $2\\n\";\n} Other regexp features Perl regexps also support backreferences, lookaheads, and all kinds of other complex details. Read all about them in perlrequick, perlretut, and perlre. Writing subroutines Writing subroutines is easy: sub logger {\n    my $logmessage = shift;\n    open my $logfile, \">>\", \"my.log\" or die \"Could not open my.log: $!\";\n    print $logfile $logmessage;\n} Now we can use the subroutine just as any other built-in function: logger(\"We have a logger subroutine!\"); What's that \"shift\"? Well, the arguments to a subroutine are available to us as a special array called @_ (see perlvar for more on that). The default argument to the \"shift\" function just happens to be @_. So \"my $logmessage = shift;\" shifts the first item off the list of arguments and assigns it to $logmessage. We can manipulate @_ in other ways too: my ($logmessage, $priority) = @_;       # common\nmy $logmessage = $_[0];                 # uncommon, and ugly Subroutines can also return values: sub square {\n    my $num = shift;\n    my $result = $num * $num;\n    return $result;\n} Then use it like: $sq = square(8); For more information on writing subroutines, see perlsub. OO Perl OO Perl is relatively simple and is implemented using references which know what sort of object they are based on Perl's concept of packages. However, OO Perl is largely beyond the scope of this document. Read perlboot, perltoot, perltooc and perlobj. As a beginning Perl programmer, your most common use of OO Perl will be in using third-party modules, which are documented below. Using Perl modules Perl modules provide a range of features to help you avoid reinventing the wheel, and can be downloaded from CPAN ( http:\/\/www.cpan.org\/ ). A number of popular modules are included with the Perl distribution itself. Categories of modules range from text manipulation to network protocols to database integration to graphics. A categorized list of modules is also available from CPAN . To learn how to install modules you download from CPAN , read perlmodinstall. To learn how to use a particular module, use \"perldoc Module::Name \". Typically you will want to \"use Module::Name \", which will then give you access to exported functions or an OO interface to the module. perlfaq contains questions and answers related to many common tasks, and often provides suggestions for good CPAN modules to use. perlmod describes Perl modules in general. perlmodlib lists the modules which came with your Perl installation. If you feel the urge to write Perl modules, perlnewmod will give you good advice.","Process Name":"perlintro","Link":"https:\/\/linux.die.net\/man\/1\/perlintro"}},{"Process":{"Description":"This document describes the behavior and implementation of the PerlIO abstraction described in perlapio when \"USE_PERLIO\" is defined (and \"USE_SFIO\" is not). History and Background The PerlIO abstraction was introduced in perl5.003_02 but languished as just an abstraction until perl5.7.0. However during that time a number of perl extensions switched to using it, so the API is mostly fixed to maintain (source) compatibility. The aim of the implementation is to provide the PerlIO API in a flexible and platform neutral manner. It is also a trial of an \"Object Oriented C, with vtables\" approach which may be applied to Perl 6. Basic Structure PerlIO is a stack of layers. The low levels of the stack work with the low-level operating system calls (file descriptors in C) getting bytes in and out, the higher layers of the stack buffer, filter, and otherwise manipulate the I\/O, and return characters (or bytes) to Perl. Terms above and below are used to refer to the relative positioning of the stack layers. A layer contains a \"vtable\", the table of I\/O operations (at C level a table of function pointers), and status flags. The functions in the vtable implement operations like \"open\", \"read\", and \"write\". When I\/O, for example \"read\", is requested, the request goes from Perl first down the stack using \"read\" functions of each layer, then at the bottom the input is requested from the operating system services, then the result is returned up the stack, finally being interpreted as Perl data. The requests do not necessarily go always all the way down to the operating system: that's where PerlIO buffering comes into play. When you do an open() and specify extra PerlIO layers to be deployed, the layers you specify are \"pushed\" on top of the already existing default stack. One way to see it is that \"operating system is on the left\" and \"Perl is on the right\". What exact layers are in this default stack depends on a lot of things: your operating system, Perl version, Perl compile time configuration, and Perl runtime configuration. See PerlIO, \" PERLIO \" in perlrun, and open for more information. binmode() operates similarly to open(): by default the specified layers are pushed on top of the existing stack. However, note that even as the specified layers are \"pushed on top\" for open() and binmode(), this doesn't mean that the effects are limited to the \"top\": PerlIO layers can be very 'active' and inspect and affect layers also deeper in the stack. As an example there is a layer called \"raw\" which repeatedly \"pops\" layers until it reaches the first layer that has declared itself capable of handling binary data. The \"pushed\" layers are processed in left-to-right order. sysopen() operates (unsurprisingly) at a lower level in the stack than open(). For example in UNIX or UNIX-like systems sysopen() operates directly at the level of file descriptors: in the terms of PerlIO layers, it uses only the \"unix\" layer, which is a rather thin wrapper on top of the UNIX file descriptors. Layers vs Disciplines Initial discussion of the ability to modify IO streams behaviour used the term \"discipline\" for the entities which were added. This came (I believe) from the use of the term in \"sfio\", which in turn borrowed it from \"line disciplines\" on Unix terminals. However, this document (and the C code) uses the term \"layer\". This is, I hope, a natural term given the implementation, and should avoid connotations that are inherent in earlier uses of \"discipline\" for things which are rather different. Data Structures The basic data structure is a PerlIOl: typedef struct _PerlIO PerlIOl;\ntypedef struct _PerlIO_funcs PerlIO_funcs;\ntypedef PerlIOl *PerlIO;\n\nstruct _PerlIO\n{\n PerlIOl *      next;       \/* Lower layer *\/\n PerlIO_funcs * tab;        \/* Functions for this layer *\/\n IV             flags;      \/* Various flags for state *\/\n}; A \"PerlIOl *\" is a pointer to the struct, and the application level \"PerlIO *\" is a pointer to a \"PerlIOl *\" - i.e. a pointer to a pointer to the struct. This allows the application level \"PerlIO *\" to remain constant while the actual \"PerlIOl *\" underneath changes. (Compare perl's \"SV *\" which remains constant while its \"sv_any\" field changes as the scalar's type changes.) An IO stream is then in general represented as a pointer to this linked-list of \"layers\". It should be noted that because of the double indirection in a \"PerlIO *\", a \"&(perlio->next)\" \"is\" a \"PerlIO *\", and so to some degree at least one layer can use the \"standard\" API on the next layer down. A \"layer\" is composed of two parts: 1. The functions and attributes of the \"layer class\". 2. The per-instance data for a particular handle. Functions and Attributes The functions and attributes are accessed via the \"tab\" (for table) member of \"PerlIOl\". The functions (methods of the layer \"class\") are fixed, and are defined by the \"PerlIO_funcs\" type. They are broadly the same as the public \"PerlIO_xxxxx\" functions: struct _PerlIO_funcs\n{\n Size_t               fsize;\n char *               name;\n Size_t               size;\n IV           kind;\n IV           (*Pushed)(pTHX_ PerlIO *f,const char *mode,SV *arg, PerlIO_funcs *tab);\n IV           (*Popped)(pTHX_ PerlIO *f);\n PerlIO *     (*Open)(pTHX_ PerlIO_funcs *tab,\n                      PerlIO_list_t *layers, IV n,\n                      const char *mode,\n                      int fd, int imode, int perm,\n                      PerlIO *old,\n                      int narg, SV **args);\n IV           (*Binmode)(pTHX_ PerlIO *f);\n SV *         (*Getarg)(pTHX_ PerlIO *f, CLONE_PARAMS *param, int flags)\n IV           (*Fileno)(pTHX_ PerlIO *f);\n PerlIO *     (*Dup)(pTHX_ PerlIO *f, PerlIO *o, CLONE_PARAMS *param, int flags)\n \/* Unix-like functions - cf sfio line disciplines *\/\n SSize_t      (*Read)(pTHX_ PerlIO *f, void *vbuf, Size_t count);\n SSize_t      (*Unread)(pTHX_ PerlIO *f, const void *vbuf, Size_t count);\n SSize_t      (*Write)(pTHX_ PerlIO *f, const void *vbuf, Size_t count);\n IV           (*Seek)(pTHX_ PerlIO *f, Off_t offset, int whence);\n Off_t        (*Tell)(pTHX_ PerlIO *f);\n IV           (*Close)(pTHX_ PerlIO *f);\n \/* Stdio-like buffered IO functions *\/\n IV           (*Flush)(pTHX_ PerlIO *f);\n IV           (*Fill)(pTHX_ PerlIO *f);\n IV           (*Eof)(pTHX_ PerlIO *f);\n IV           (*Error)(pTHX_ PerlIO *f);\n void         (*Clearerr)(pTHX_ PerlIO *f);\n void         (*Setlinebuf)(pTHX_ PerlIO *f);\n \/* Perl's snooping functions *\/\n STDCHAR *    (*Get_base)(pTHX_ PerlIO *f);\n Size_t       (*Get_bufsiz)(pTHX_ PerlIO *f);\n STDCHAR *    (*Get_ptr)(pTHX_ PerlIO *f);\n SSize_t      (*Get_cnt)(pTHX_ PerlIO *f);\n void         (*Set_ptrcnt)(pTHX_ PerlIO *f,STDCHAR *ptr,SSize_t cnt);\n}; The first few members of the struct give a function table size for compatibility check \"name\" for the layer, the size to \"malloc\" for the per-instance data, and some flags which are attributes of the class as whole (such as whether it is a buffering layer), then follow the functions which fall into four basic groups: 1. Opening and setup functions 2. Basic IO operations 3. Stdio class buffering options. 4. Functions to support Perl's traditional \"fast\" access to the buffer. A layer does not have to implement all the functions, but the whole table has to be present. Unimplemented slots can be NULL (which will result in an error when called) or can be filled in with stubs to \"inherit\" behaviour from a \"base class\". This \"inheritance\" is fixed for all instances of the layer, but as the layer chooses which stubs to populate the table, limited \"multiple inheritance\" is possible. Per-instance Data The per-instance data are held in memory beyond the basic PerlIOl struct, by making a PerlIOl the first member of the layer's struct thus: typedef struct\n{\n struct _PerlIO base;       \/* Base \"class\" info *\/\n STDCHAR *      buf;        \/* Start of buffer *\/\n STDCHAR *      end;        \/* End of valid part of buffer *\/\n STDCHAR *      ptr;        \/* Current position in buffer *\/\n Off_t          posn;       \/* Offset of buf into the file *\/\n Size_t         bufsiz;     \/* Real size of buffer *\/\n IV             oneword;    \/* Emergency buffer *\/\n} PerlIOBuf; In this way (as for perl's scalars) a pointer to a PerlIOBuf can be treated as a pointer to a PerlIOl. Layers in action.              table           perlio          unix\n         |           |\n         +-----------+    +----------+    +--------+\nPerlIO ->|           |--->|  next    |--->|  NULL  |\n         +-----------+    +----------+    +--------+\n         |           |    |  buffer  |    |   fd   |\n         +-----------+    |          |    +--------+\n         |           |    +----------+ The above attempts to show how the layer scheme works in a simple case. The application's \"PerlIO *\" points to an entry in the table(s) representing open (allocated) handles. For example the first three slots in the table correspond to \"stdin\", \"stdout\" and \"stderr\". The table in turn points to the current \"top\" layer for the handle - in this case an instance of the generic buffering layer \"perlio\". That layer in turn points to the next layer down - in this case the low-level \"unix\" layer. The above is roughly equivalent to a \"stdio\" buffered stream, but with much more flexibility: \u2022 If Unix level \"read\"\/ \"write\"\/ \"lseek\" is not appropriate for (say) sockets then the \"unix\" layer can be replaced (at open time or even dynamically) with a \"socket\" layer. \u2022 Different handles can have different buffering schemes. The \"top\" layer could be the \"mmap\" layer if reading disk files was quicker using \"mmap\" than \"read\". An \"unbuffered\" stream can be implemented simply by not having a buffer layer. \u2022 Extra layers can be inserted to process the data as it flows through. This was the driving need for including the scheme in perl 5.7.0+ - we needed a mechanism to allow data to be translated between perl's internal encoding (conceptually at least Unicode as UTF-8 ), and the \"native\" format used by the system. This is provided by the \":encoding(xxxx)\" layer which typically sits above the buffering layer. \u2022 A layer can be added that does \"\\n\" to CRLF translation. This layer can be used on any platform, not just those that normally do such things. Per-instance flag bits The generic flag bits are a hybrid of \"O_XXXXX\" style flags deduced from the mode string passed to \"PerlIO_open()\", and state bits for typical buffer layers. PERLIO_F_EOF End of file. PERLIO_F_CANWRITE Writes are permitted, i.e. opened as \"w\" or \"r+\" or \"a\", etc. PERLIO_F_CANREAD Reads are permitted i.e. opened \"r\" or \"w+\" (or even \"a+\" - ick). PERLIO_F_ERROR An error has occurred (for \"PerlIO_error()\"). PERLIO_F_TRUNCATE Truncate file suggested by open mode. PERLIO_F_APPEND All writes should be appends. PERLIO_F_CRLF Layer is performing Win32-like \"\\n\" mapped to CR ,LF for output and CR ,LF mapped to \"\\n\" for input. Normally the provided \"crlf\" layer is the only layer that need bother about this. \"PerlIO_binmode()\" will mess with this flag rather than add\/remove layers if the \"PERLIO_K_CANCRLF\" bit is set for the layers class. PERLIO_F_UTF8 Data written to this layer should be UTF-8 encoded; data provided by this layer should be considered UTF-8 encoded. Can be set on any layer by \":utf8\" dummy layer. Also set on \":encoding\" layer. PERLIO_F_UNBUF Layer is unbuffered - i.e. write to next layer down should occur for each write to this layer. PERLIO_F_WRBUF The buffer for this layer currently holds data written to it but not sent to next layer. PERLIO_F_RDBUF The buffer for this layer currently holds unconsumed data read from layer below. PERLIO_F_LINEBUF Layer is line buffered. Write data should be passed to next layer down whenever a \"\\n\" is seen. Any data beyond the \"\\n\" should then be processed. PERLIO_F_TEMP File has been \"unlink()\"ed, or should be deleted on \"close()\". PERLIO_F_OPEN Handle is open. PERLIO_F_FASTGETS This instance of this layer supports the \"fast \"gets\"\" interface. Normally set based on \"PERLIO_K_FASTGETS\" for the class and by the existence of the function(s) in the table. However a class that normally provides that interface may need to avoid it on a particular instance. The \"pending\" layer needs to do this when it is pushed above a layer which does not support the interface. (Perl's \"sv_gets()\" does not expect the streams fast \"gets\" behaviour to change during one \"get\".) Methods in Detail fsize Size_t fsize; Size of the function table. This is compared against the value PerlIO code \"knows\" as a compatibility check. Future versions may be able to tolerate layers compiled against an old version of the headers. name char * name; The name of the layer whose open() method Perl should invoke on open(). For example if the layer is called APR , you will call: open $fh, \">:APR\", ... and Perl knows that it has to invoke the PerlIOAPR_open() method implemented by the APR layer. size Size_t size; The size of the per-instance data structure, e.g.: sizeof(PerlIOAPR) If this field is zero then \"PerlIO_pushed\" does not malloc anything and assumes layer's Pushed function will do any required layer stack manipulation - used to avoid malloc\/free overhead for dummy layers. If the field is non-zero it must be at least the size of \"PerlIOl\", \"PerlIO_pushed\" will allocate memory for the layer's data structures and link new layer onto the stream's stack. (If the layer's Pushed method returns an error indication the layer is popped again.) kind IV kind; \u2022 PERLIO_K_BUFFERED The layer is buffered. \u2022 PERLIO_K_RAW The layer is acceptable to have in a binmode( FH ) stack - i.e. it does not (or will configure itself not to) transform bytes passing through it. \u2022 PERLIO_K_CANCRLF Layer can translate between \"\\n\" and CRLF line ends. \u2022 PERLIO_K_FASTGETS Layer allows buffer snooping. \u2022 PERLIO_K_MULTIARG Used when the layer's open() accepts more arguments than usual. The extra arguments should come not before the \"MODE\" argument. When this flag is used it's up to the layer to validate the args. Pushed IV      (*Pushed)(pTHX_ PerlIO *f,const char *mode, SV *arg); The only absolutely mandatory method. Called when the layer is pushed onto the stack. The \"mode\" argument may be NULL if this occurs post-open. The \"arg\" will be non- \"NULL\" if an argument string was passed. In most cases this should call \"PerlIOBase_pushed()\" to convert \"mode\" into the appropriate \"PERLIO_F_XXXXX\" flags in addition to any actions the layer itself takes. If a layer is not expecting an argument it need neither save the one passed to it, nor provide \"Getarg()\" (it could perhaps \"Perl_warn\" that the argument was un-expected). Returns 0 on success. On failure returns -1 and should set errno. Popped IV      (*Popped)(pTHX_ PerlIO *f); Called when the layer is popped from the stack. A layer will normally be popped after \"Close()\" is called. But a layer can be popped without being closed if the program is dynamically managing layers on the stream. In such cases \"Popped()\" should free any resources (buffers, translation tables, ...) not held directly in the layer's struct. It should also \"Unread()\" any unconsumed data that has been read and buffered from the layer below back to that layer, so that it can be re-provided to what ever is now above. Returns 0 on success and failure. If \"Popped()\" returns true then perlio.c assumes that either the layer has popped itself, or the layer is super special and needs to be retained for other reasons. In most cases it should return false. Open PerlIO *        (*Open)(...); The \"Open()\" method has lots of arguments because it combines the functions of perl's \"open\", \"PerlIO_open\", perl's \"sysopen\", \"PerlIO_fdopen\" and \"PerlIO_reopen\". The full prototype is as follows: PerlIO *       (*Open)(pTHX_ PerlIO_funcs *tab,\n                       PerlIO_list_t *layers, IV n,\n                       const char *mode,\n                       int fd, int imode, int perm,\n                       PerlIO *old,\n                       int narg, SV **args); Open should (perhaps indirectly) call \"PerlIO_allocate()\" to allocate a slot in the table and associate it with the layers information for the opened file, by calling \"PerlIO_push\". The layers is an array of all the layers destined for the \"PerlIO *\", and any arguments passed to them, n is the index into that array of the layer being called. The macro \"PerlIOArg\" will return a (possibly \"NULL\") SV * for the argument passed to the layer. The mode string is an \"\"fopen()\"-like\" string which would match the regular expression \"\/^[I#]?[rwa]\\+?[bt]?$\/\". The 'I' prefix is used during creation of \"stdin\"..\"stderr\" via special \"PerlIO_fdopen\" calls; the '#' prefix means that this is \"sysopen\" and that imode and perm should be passed to \"PerlLIO_open3\"; 'r' means read, 'w' means write and 'a' means append. The '+' suffix means that both reading and writing\/appending are permitted. The 'b' suffix means file should be binary, and 't' means it is text. (Almost all layers should do the IO in binary mode, and ignore the b\/t bits. The \":crlf\" layer should be pushed to handle the distinction.) If old is not \"NULL\" then this is a \"PerlIO_reopen\". Perl itself does not use this (yet?) and semantics are a little vague. If fd not negative then it is the numeric file descriptor fd, which will be open in a manner compatible with the supplied mode string, the call is thus equivalent to \"PerlIO_fdopen\". In this case nargs will be zero. If nargs is greater than zero then it gives the number of arguments passed to \"open\", otherwise it will be 1 if for example \"PerlIO_open\" was called. In simple cases SvPV_nolen(*args) is the pathname to open. Having said all that translation-only layers do not need to provide \"Open()\" at all, but rather leave the opening to a lower level layer and wait to be \"pushed\". If a layer does provide \"Open()\" it should normally call the \"Open()\" method of next layer down (if any) and then push itself on top if that succeeds. If \"PerlIO_push\" was performed and open has failed, it must \"PerlIO_pop\" itself, since if it's not, the layer won't be removed and may cause bad problems. Returns \"NULL\" on failure. Binmode IV        (*Binmode)(pTHX_ PerlIO *f); Optional. Used when \":raw\" layer is pushed (explicitly or as a result of binmode( FH )). If not present layer will be popped. If present should configure layer as binary (or pop itself) and return 0. If it returns -1 for error \"binmode\" will fail with layer still on the stack. Getarg SV *      (*Getarg)(pTHX_ PerlIO *f,\n                    CLONE_PARAMS *param, int flags); Optional. If present should return an SV * representing the string argument passed to the layer when it was pushed. e.g. \":encoding(ascii)\" would return an SvPV with value \"ascii\". ( param and flags arguments can be ignored in most cases) \"Dup\" uses \"Getarg\" to retrieve the argument originally passed to \"Pushed\", so you must implement this function if your layer has an extra argument to \"Pushed\" and will ever be \"Dup\"ed. Fileno IV        (*Fileno)(pTHX_ PerlIO *f); Returns the Unix\/Posix numeric file descriptor for the handle. Normally \"PerlIOBase_fileno()\" (which just asks next layer down) will suffice for this. Returns -1 on error, which is considered to include the case where the layer cannot provide such a file descriptor. Dup PerlIO * (*Dup)(pTHX_ PerlIO *f, PerlIO *o,\n                CLONE_PARAMS *param, int flags); XXX: Needs more docs. Used as part of the \"clone\" process when a thread is spawned (in which case param will be non-NULL) and when a stream is being duplicated via '&' in the \"open\". Similar to \"Open\", returns PerlIO* on success, \"NULL\" on failure. Read SSize_t (*Read)(pTHX_ PerlIO *f, void *vbuf, Size_t count); Basic read operation. Typically will call \"Fill\" and manipulate pointers (possibly via the API ). \"PerlIOBuf_read()\" may be suitable for derived classes which provide \"fast gets\" methods. Returns actual bytes read, or -1 on an error. Unread SSize_t (*Unread)(pTHX_ PerlIO *f,\n                  const void *vbuf, Size_t count); A superset of stdio's \"ungetc()\". Should arrange for future reads to see the bytes in \"vbuf\". If there is no obviously better implementation then \"PerlIOBase_unread()\" provides the function by pushing a \"fake\" \"pending\" layer above the calling layer. Returns the number of unread chars. Write SSize_t (*Write)(PerlIO *f, const void *vbuf, Size_t count); Basic write operation. Returns bytes written or -1 on an error. Seek IV      (*Seek)(pTHX_ PerlIO *f, Off_t offset, int whence); Position the file pointer. Should normally call its own \"Flush\" method and then the \"Seek\" method of next layer down. Returns 0 on success, -1 on failure. Tell Off_t   (*Tell)(pTHX_ PerlIO *f); Return the file pointer. May be based on layers cached concept of position to avoid overhead. Returns -1 on failure to get the file pointer. Close IV      (*Close)(pTHX_ PerlIO *f); Close the stream. Should normally call \"PerlIOBase_close()\" to flush itself and close layers below, and then deallocate any data structures (buffers, translation tables, ...) not held directly in the data structure. Returns 0 on success, -1 on failure. Flush IV      (*Flush)(pTHX_ PerlIO *f); Should make stream's state consistent with layers below. That is, any buffered write data should be written, and file position of lower layers adjusted for data read from below but not actually consumed. (Should perhaps \"Unread()\" such data to the lower layer.) Returns 0 on success, -1 on failure. Fill IV      (*Fill)(pTHX_ PerlIO *f); The buffer for this layer should be filled (for read) from layer below. When you \"subclass\" PerlIOBuf layer, you want to use its _read method and to supply your own fill method, which fills the PerlIOBuf's buffer. Returns 0 on success, -1 on failure. Eof IV      (*Eof)(pTHX_ PerlIO *f); Return end-of-file indicator. \"PerlIOBase_eof()\" is normally sufficient. Returns 0 on end-of-file, 1 if not end-of-file, -1 on error. Error IV      (*Error)(pTHX_ PerlIO *f); Return error indicator. \"PerlIOBase_error()\" is normally sufficient. Returns 1 if there is an error (usually when \"PERLIO_F_ERROR\" is set, 0 otherwise. Clearerr void    (*Clearerr)(pTHX_ PerlIO *f); Clear end-of-file and error indicators. Should call \"PerlIOBase_clearerr()\" to set the \"PERLIO_F_XXXXX\" flags, which may suffice. Setlinebuf void    (*Setlinebuf)(pTHX_ PerlIO *f); Mark the stream as line buffered. \"PerlIOBase_setlinebuf()\" sets the PERLIO_F_LINEBUF flag and is normally sufficient. Get_base STDCHAR *       (*Get_base)(pTHX_ PerlIO *f); Allocate (if not already done so) the read buffer for this layer and return pointer to it. Return NULL on failure. Get_bufsiz Size_t  (*Get_bufsiz)(pTHX_ PerlIO *f); Return the number of bytes that last \"Fill()\" put in the buffer. Get_ptr STDCHAR *       (*Get_ptr)(pTHX_ PerlIO *f); Return the current read pointer relative to this layer's buffer. Get_cnt SSize_t (*Get_cnt)(pTHX_ PerlIO *f); Return the number of bytes left to be read in the current buffer. Set_ptrcnt void    (*Set_ptrcnt)(pTHX_ PerlIO *f,\n                      STDCHAR *ptr, SSize_t cnt); Adjust the read pointer and count of bytes to match \"ptr\" and\/or \"cnt\". The application (or layer above) must ensure they are consistent. (Checking is allowed by the paranoid.) Utilities To ask for the next layer down use PerlIONext(PerlIO *f). To check that a PerlIO* is valid use PerlIOValid(PerlIO *f). (All this does is really just to check that the pointer is non-NULL and that the pointer behind that is non-NULL.) PerlIOBase(PerlIO *f) returns the \"Base\" pointer, or in other words, the \"PerlIOl*\" pointer. PerlIOSelf(PerlIO* f, type) return the PerlIOBase cast to a type. Perl_PerlIO_or_Base(PerlIO* f, callback, base, failure, args) either calls the callback from the functions of the layer f (just by the name of the IO function, like \"Read\") with the args, or if there is no such callback, calls the base version of the callback with the same args, or if the f is invalid, set errno to EBADF and return failure. Perl_PerlIO_or_fail(PerlIO* f, callback, failure, args) either calls the callback of the functions of the layer f with the args, or if there is no such callback, set errno to EINVAL . Or if the f is invalid, set errno to EBADF and return failure. Perl_PerlIO_or_Base_void(PerlIO* f, callback, base, args) either calls the callback of the functions of the layer f with the args, or if there is no such callback, calls the base version of the callback with the same args, or if the f is invalid, set errno to EBADF . Perl_PerlIO_or_fail_void(PerlIO* f, callback, args) either calls the callback of the functions of the layer f with the args, or if there is no such callback, set errno to EINVAL . Or if the f is invalid, set errno to EBADF . Implementing PerlIO Layers If you find the implementation document unclear or not sufficient, look at the existing PerlIO layer implementations, which include: \u2022 C implementations The perlio.c and perliol.h in the Perl core implement the \"unix\", \"perlio\", \"stdio\", \"crlf\", \"utf8\", \"byte\", \"raw\", \"pending\" layers, and also the \"mmap\" and \"win32\" layers if applicable. (The \"win32\" is currently unfinished and unused, to see what is used instead in Win32, see \"Querying the layers of filehandles\" in PerlIO .) PerlIO::encoding, PerlIO::scalar, PerlIO::via in the Perl core. PerlIO::gzip and APR::PerlIO (mod_perl 2.0) on CPAN . \u2022 Perl implementations PerlIO::via::QuotedPrint in the Perl core and PerlIO::via::* on CPAN . If you are creating a PerlIO layer, you may want to be lazy, in other words, implement only the methods that interest you. The other methods you can either replace with the \"blank\" methods PerlIOBase_noop_ok\nPerlIOBase_noop_fail (which do nothing, and return zero and -1, respectively) or for certain methods you may assume a default behaviour by using a NULL method. The Open method looks for help in the 'parent' layer. The following table summarizes the behaviour:    method      behaviour with NULL\n\n   Clearerr    PerlIOBase_clearerr\n   Close       PerlIOBase_close\n   Dup         PerlIOBase_dup\n   Eof         PerlIOBase_eof\n   Error       PerlIOBase_error\n   Fileno      PerlIOBase_fileno\n   Fill        FAILURE\n   Flush       SUCCESS\n   Getarg      SUCCESS\n   Get_base    FAILURE\n   Get_bufsiz  FAILURE\n   Get_cnt     FAILURE\n   Get_ptr     FAILURE\n   Open        INHERITED\n   Popped      SUCCESS\n   Pushed      SUCCESS\n   Read        PerlIOBase_read\n   Seek        FAILURE\n   Set_cnt     FAILURE\n   Set_ptrcnt  FAILURE\n   Setlinebuf  PerlIOBase_setlinebuf\n   Tell        FAILURE\n   Unread      PerlIOBase_unread\n   Write       FAILURE\n\nFAILURE        Set errno (to EINVAL in UNIXish, to LIB$_INVARG in VMS) and\n               return -1 (for numeric return values) or NULL (for pointers)\nINHERITED      Inherited from the layer below\nSUCCESS        Return 0 (for numeric return values) or a pointer Core Layers The file \"perlio.c\" provides the following layers: \"unix\" A basic non-buffered layer which calls Unix\/POSIX \"read()\", \"write()\", \"lseek()\", \"close()\". No buffering. Even on platforms that distinguish between O_TEXT and O_BINARY this layer is always O_BINARY. \"perlio\" A very complete generic buffering layer which provides the whole of PerlIO API . It is also intended to be used as a \"base class\" for other layers. (For example its \"Read()\" method is implemented in terms of the \"Get_cnt()\"\/ \"Get_ptr()\"\/ \"Set_ptrcnt()\" methods). \"perlio\" over \"unix\" provides a complete replacement for stdio as seen via PerlIO API . This is the default for USE_PERLIO when system's stdio does not permit perl's \"fast gets\" access, and which do not distinguish between \"O_TEXT\" and \"O_BINARY\". \"stdio\" A layer which provides the PerlIO API via the layer scheme, but implements it by calling system's stdio. This is (currently) the default if system's stdio provides sufficient access to allow perl's \"fast gets\" access and which do not distinguish between \"O_TEXT\" and \"O_BINARY\". \"crlf\" A layer derived using \"perlio\" as a base class. It provides Win32-like \"\\n\" to CR ,LF translation. Can either be applied above \"perlio\" or serve as the buffer layer itself. \"crlf\" over \"unix\" is the default if system distinguishes between \"O_TEXT\" and \"O_BINARY\" opens. (At some point \"unix\" will be replaced by a \"native\" Win32 IO layer on that platform, as Win32's read\/write layer has various drawbacks.) The \"crlf\" layer is a reasonable model for a layer which transforms data in some way. \"mmap\" If Configure detects \"mmap()\" functions this layer is provided (with \"perlio\" as a \"base\") which does \"read\" operations by mmap()ing the file. Performance improvement is marginal on modern systems, so it is mainly there as a proof of concept. It is likely to be unbundled from the core at some point. The \"mmap\" layer is a reasonable model for a minimalist \"derived\" layer. \"pending\" An \"internal\" derivative of \"perlio\" which can be used to provide Unread() function for layers which have no buffer or cannot be bothered. (Basically this layer's \"Fill()\" pops itself off the stack and so resumes reading from layer below.) \"raw\" A dummy layer which never exists on the layer stack. Instead when \"pushed\" it actually pops the stack removing itself, it then calls Binmode function table entry on all the layers in the stack - normally this (via PerlIOBase_binmode) removes any layers which do not have \"PERLIO_K_RAW\" bit set. Layers can modify that behaviour by defining their own Binmode entry. \"utf8\" Another dummy layer. When pushed it pops itself and sets the \"PERLIO_F_UTF8\" flag on the layer which was (and now is once more) the top of the stack. In addition perlio.c also provides a number of \"PerlIOBase_xxxx()\" functions which are intended to be used in the table slots of classes which do not need to do anything special for a particular method. Extension Layers Layers can made available by extension modules. When an unknown layer is encountered the PerlIO code will perform the equivalent of : use PerlIO 'layer'; Where layer is the unknown layer. PerlIO.pm will then attempt to: require PerlIO::layer; If after that process the layer is still not defined then the \"open\" will fail. The following extension layers are bundled with perl: \":encoding\" use Encoding; makes this layer available, although PerlIO.pm \"knows\" where to find it. It is an example of a layer which takes an argument as it is called thus: open( $fh, \"<:encoding(iso-8859-7)\", $pathname ); \":scalar\" Provides support for reading data from and writing data to a scalar. open( $fh, \"+<:scalar\", \\$scalar ); When a handle is so opened, then reads get bytes from the string value of $scalar, and writes change the value. In both cases the position in $scalar starts as zero but can be altered via \"seek\", and determined via \"tell\". Please note that this layer is implied when calling open() thus: open( $fh, \"+<\", \\$scalar ); \":via\" Provided to allow layers to be implemented as Perl code. For instance: use PerlIO::via::StripHTML;\nopen( my $fh, \"<:via(StripHTML)\", \"index.html\" ); See PerlIO::via for details.","Process Name":"perliol","Link":"https:\/\/linux.die.net\/man\/1\/perliol"}},{"Process":{"Description":"The basic IPC facilities of Perl are built out of the good old Unix signals, named pipes, pipe opens, the Berkeley socket routines, and SysV IPC calls. Each is used in slightly different situations.","Process Name":"perlipc","Link":"https:\/\/linux.die.net\/man\/1\/perlipc"}},{"Process":{"Description":"This document describes various features of Irix that will affect how Perl version 5 (hereafter just Perl) is compiled and\/or runs. Building 32-bit Perl in Irix Use sh Configure -Dcc='cc -n32' to compile Perl 32-bit. Don't bother with -n32 unless you have 7.1 or later compilers (use cc -version to check). (Building 'cc -n32' is the default.) Building 64-bit Perl in Irix Use sh Configure -Dcc='cc -64' -Duse64bitint This requires require a 64-bit MIPS CPU (R8000, R10000, ...) You can also use sh Configure -Dcc='cc -64' -Duse64bitall but that makes no difference compared with the -Duse64bitint because of the \"cc -64\". You can also do sh Configure -Dcc='cc -n32' -Duse64bitint to use long longs for the 64-bit integer type, in case you don't have a 64-bit CPU . If you are using gcc, just sh Configure -Dcc=gcc -Duse64bitint should be enough, the Configure should automatically probe for the correct 64-bit settings. About Compiler Versions of Irix Some Irix cc versions, e.g. 7.3.1.1m (try cc -version) have been known to have issues (coredumps) when compiling perl.c. If you've used -OPT:fast_io=ON and this happens, try removing it. If that fails, or you didn't use that, then try adjusting other optimization options (-LNO, -INLINE, -O3 to -O2, etcetera). The compiler bug has been reported to SGI . (Allen Smith < easmith@beatrice.rutgers.edu>) Linker Problems in Irix If you get complaints about so_locations then search in the file hints\/irix_6.sh for \"lddflags\" and do the suggested adjustments. (David Billinghurst < David.Billinghurst@riotinto.com.au>) Malloc in Irix Do not try to use Perl's malloc, this will lead into very mysterious errors (especially with -Duse64bitall). Building with threads in Irix Run Configure with -Duseithreads which will configure Perl with the Perl 5.8.0 \"interpreter threads\", see threads. For Irix 6.2 with perl threads, you have to have the following patches installed: 1404 Irix 6.2 Posix 1003.1b man pages\n1645 Irix 6.2 & 6.3 POSIX header file updates\n2000 Irix 6.2 Posix 1003.1b support modules\n2254 Pthread library fixes\n2401 6.2 all platform kernel rollup IMPORTANT : Without patch 2401, a kernel bug in Irix 6.2 will cause your machine to panic and crash when running threaded perl. Irix 6.3 and later are okay. Thanks to Hannu Napari <Hannu.Napari@hut.fi> for the IRIX\npthreads patches information. Irix 5.3 While running Configure and when building, you are likely to get quite a few of these warnings: ld:\nThe shared object \/usr\/lib\/libm.so did not resolve any symbols.\n      You may want to remove it from your link line. Ignore them: in IRIX 5.3 there is no way to quieten ld about this. During compilation you will see this warning from toke.c: uopt: Warning: Perl_yylex: this procedure not optimized because it\n      exceeds size threshold; to optimize this procedure, use -Olimit option\n      with value >= 4252. Ignore the warning. In IRIX 5.3 and with Perl 5.8.1 (Perl 5.8.0 didn't compile in IRIX 5.3) the following failures are known. Failed Test                  Stat Wstat Total Fail  Failed  List of Failed\n--------------------------------------------------------------------------\n..\/ext\/List\/Util\/t\/shuffle.t    0   139    ??   ??       %  ??\n..\/lib\/Math\/Trig.t            255 65280    29   12  41.38%  24-29\n..\/lib\/sort.t                   0   138   119   72  60.50%  48-119\n56 tests and 474 subtests skipped.\nFailed 3\/811 test scripts, 99.63% okay. 78\/75813 subtests failed, 99.90% okay. They are suspected to be compiler errors (at least the shuffle.t failure is known from some IRIX 6 setups) and math library errors (the Trig.t failure), but since IRIX 5 is long since end-of-lifed, further fixes for the IRIX are unlikely. If you can get gcc for 5.3, you could try that, too, since gcc in IRIX 6 is a known workaround for at least the shuffle.t and sort.t failures.","Process Name":"perlirix","Link":"https:\/\/linux.die.net\/man\/1\/perlirix"}},{"Process":{"Description":"The perlivp program is set up at Perl source code build time to test the Perl version it was built under. It can be used after running: make install (or your platform's equivalent procedure) to verify that perl and its libraries have been installed correctly. A correct installation is verified by output that looks like: ok 1\nok 2 etc.","Process Name":"perlivp","Link":"https:\/\/linux.die.net\/man\/1\/perlivp"}},{"Process":{"Description":"","Process Name":"perljp","Link":"https:\/\/linux.die.net\/man\/1\/perljp"}},{"Process":{"Description":"PerlXXX XXXXXXXX XXXXX XXXXX XXXXXXXXXXXXXX ! PerlXXX 5.8.0XXXXXXXX XXXXXXXXXXX\/ISO 10646XXX XXXXXX XXXXXXXXXX XXXXXXXX XXXXXXXX . XXXXXXXXXXX XXXXXXXX XXXXXXXXXX XXXXXXXXXX XXXXXXX XXXXX XXXXXXXXXX XXXXXXXXXXX XXXXXXXX XXXXX XXXXXXXX XXXXXXX XXXXX XXXXXXX XXXXXX XXXXXXXX XXXXXXXXXX XXXXXXXXXXXXX . XXXXXXXXXXXXXX XXX XXXXXXXXXXX XXXXXXX XXXX XXXXXXX XXXXXX XXXXX XXXX - XXXXXXXX XXXXX XXXXXXXX , XXXX XXXXXXXX , XXXXXX XXXXXXXX , XXXXXXXX XXXXXX XXXXXXXXXXXX XXXXXXX XXXXX XXXXXXXXX , XXXXXX XXXX , XXXXXXX XXXX , XXXXXXXXXX XXXXXX , XXXXXXXXXX XXXXX , XXXXXXXXX XXXXX , XXXX XXXXXXXXXXX XXXXX XXXX XXX-XX XXXXXXXXXXX XXXXX XXXXXX XXXXX XXXXX XXXXXXX XXXXXX XXXXXXX XX XXXXX XX XXXX XXXXX XXXXX XXXXXXX XXXXXXXX XXXX XXXXXX XXXXXXXXXX XXX XXX XXXXXX XXXX XXXXXXXX XXXXXXXXX XXX XXXX XXXXXXXXXX XXXXXXXXXX XXXXX XXXXXX XXXXX XXXXX XXXXXXX XXXXXXXXX XXXXXXXXXXX . PerlXXX XXXXXXXXXXXXX XXXXXXXXXXXXX XXXX XXXXXXXXX XXXXXX XXXXXXXXXXXX . XXXX XXXXXXXXXXX XXXXXXX Perl XXXXXXXXX XXXXXXXXX UTF-8 XXXXXXXXX XXX XXX XXXXX , XXXX XXXXXXXX XXXXXXX ( XXXXX XXXXX , XXXXXXXX , index, substr)XX XXXXXXX XXXXX XXXXXX XXXXXXXXXXX XXXXX XXXXXXX XXXXXXXXXXXXXX . ( XXX XXXXXXXX XXXXX perlunicode XXXXXXXX XXXXXXXXXXXXXXXX .) XXXXXXXXXXXXX XXXXX XXXXXXXXX XXXXXX XXXXX XXXXXXX XXXXXXXX , XXXXXXXX XXXXX XXXXXXX XXXXXX XXXX\/XX XXXXXXX XXXXXXXXXXXX XXXXXXXXXX XXXXX XXXXX XXXXXXXXXXXX XXX XXXXXXXXX XXXXXX XXXXXXX XXXXX XXXXX XXXXX 'Encode' XX XXXXXXXXXXXXX . XXXXXXXX 'Encode' XX XXXXX XXXXXXXX XXXXXXXX XXXXXXX XXXXXXXX XXXXX XXX XXX XXXXXXXXXXX . 'Encode' XXX XXXXXXX XXXXX XXXXXXXX XXXXXXXXXX XXXXXXXXXXXXX . euc-kr US-ASCIIXXX KS X 1001XXX XXXXX XXXXX XXXXXXXXXXXX XXXXXXXX (XXXXXX XXXXXXXXXXXXXXX\nXXXX.) KS X 2901XX RFC 1557 XXXX. cp949 MS-Windows 9x\/MEXXXXXX XXXXXXX XXXXXX XXXXXXXX.  euc-krXXX 8,822XXXXXX\nXXXXX XXXXXXXXX XXXXXX XXXXX.  aliasXXX uhc, windows-949, x-windows-949,\nks_c_5601-1987. XX XXXXXX XXXXXXXX XXXXXXXXXXX XXXXXX XXXXXXXXXXXX, Microsoft\nXXXXXXXXXXXX CP949XXX XXXXXXX XXXXXXX XXXXXX. johab KS X 1001:1998 XXXX 3XXXXXX XXXXXXXX XXXXXX.  XXXX XXXXXXXXXXXX cp949XXX\nXXXXXXXXXX US-ASCIIXXX  KS X 1001XXX 8,822XXXXXX XXXXX XXXXXXXXX XXXXXX XXXXX.\nXXXXXXXX XXXXXXX XXXXXX XXXXX. iso-2022-kr RFC 1557XXXXXX XXXXXXXX XXXXXXXX XXXXXXX XXXXX XXXXXXXX XXXXXXXXXXXX US-ASCIIXXX\nKS X 1001XXX XXXXXXXXXXXX XXXXXX XXXXXXXXX euc-krXX XXXXXX XXXXXXXX XXXXXXX XXXXX.\n1997-8XXX XXXXXX XXXXXXXXXX XXX XXXXX XXXXX XXXXXXXX XXXXXXX XXXXXX. ksc5601-raw KS X 1001(KS C 5601)XXX GL(XX, MSBXX 0XXXXX XXX XXXX) XXX XXXXXXXXX XXXXXX\nXXXXXXXX. US-ASCIIXXX XXXXXXXX XXXXX XXXXXXXXXX XXXXXXX XXXXX X11 XXXXXXXX XXX\nXXXXXXXX (ksc5601.1987-0. '0'XXX GLXXX XXXXXXX.)XXXXX XXXXXXX XXXXX XXXXXXXXXXXXX\nXXXX XXXXXX. KS C 5601XXX 1997XXX KS X 1001XX XXXXXXXX XXXXXXXXX.  1998XXXXXXXXX  XXX\nXXXXX (XXXXXXXX XXXXXXX XXXXX XXXXXX XXXXX)XX XXXXXXXXXXX. XX XXXX XXXXX XXXXXXXX XXXXXXXXX XXXXXXXXXX. XXXXX XXXXX , euc-kr XXXXXXXXXXXX XXX XXXXXXXX UTF-8XX XXXXXXXXXXXX XXXXXX XXXXX XXXXX XXXXXXXX . perl -Mencoding=euc-kr,STDOUT,utf8 -pe1  < file.euckr > file.utf8 XXXXXXXXXXX XXXXXXX XXXXX XXX XXX XXXXXXXXXXX .     perl -Mencoding=utf8,STDOUT,euc-kr -pe1  < file.utf8  > file.euckr\n\n  XXXXX XXXXXXXX XXXXX XXXXXXXXX XXX XXX XXXXXXXX Encode XXXXXXX XXXXX\nXXXXXXXXXXX PerlXXXX XXXXX piconvXX PerlXXX XXXXX XXXXXXXXXXX.\nXX XXXXXXXXXXX XXX XXX XXXXXXXXX piconvXXX UnixXXX XXXXXX iconvX\nXXXXXX XXX XXXXXXXXXXX. XX XXXXXXXXXX XXXXXXXXX XXXXXXXXXX.\n\n   piconv -f euc-kr -t utf8 < file.euckr > file.utf8\n   piconv -f utf8 -t euc-kr < file.utf8 > file.euckr\n\n  XXX, 'PerlIO::encoding' XXXXXXX XXXXX XXXXXXXX XXXXXXXXXX XXXXXXX XXXXX XXXXX\n(XXXXXXX XXXXXXX XXXXXXXXX) XXXXXX XXXXX XXX XXX XXXXXXXXXXX.\n\n  #!\/path\/to\/perl\n\n  use encoding 'euc-kr', STDIN => 'euc-kr',\n                         STDOUT-> 'euc-kr', STDERR=>'euc-kr';\n\n  print length(\"XXXXX\");        # 2  (XXX XXXXXXXXXX XXXXX XXXXX XXXXXX XXXXX)\n  print length('XXXXX');        # 4  (XXXXXX XXXXXXXXXX XXXXXXX XXXXX XXXXXX XXXXX)\n  print index(\"XXXXX, XXXXXXXX\", \"XXX\");   # -1 ('XXX'XXX XXXXXX)\n  print index('XXXXX, XXXXXXXX', 'XXX');   # 7 (8XXXXXX 9XXXX XXXXXXXXX 'XXX'XXX\n                                            XXXXXXXXX XXXXXXXX.) XXX XXXXXXXX XXXXX XXXXXX ...   PerlXXX XXXXXXXXXX  XXXXXXXX XXXXXXXX XXXXXX XXXXX XXXXX XXXX, XXX XXXXXX XXXX\nPerl XXXXX XX XXXXXXXXX XXXXXXXXXXX XXXXX, EncodeXXX XXXXXXX XXXXX XXXXX XXXXX\nXXXX XXX XXXXXXXXXXX.  XXXXX XXX XXXXXXX XXXXXX XXXX XXXXXXXX XXXXX XXXXXXXXXXX. Perl XXXXX XXXXX XXXXXXXXX XXXXXXXX XXXX XXXXXXXX XXXXXXX XXXXX XXXXXXX XXXXXXXXXXX . XXX XXXXXXX XXXX XXXXXXXXX XXXXX XXXXXXXX XXXXX XXXXXXXXXXXX XXXX XXXX XXXXXXXXXXX . < http:\/\/www.perl.com\/> O'ReillyXXX Perl XXX XXXXXXXX < http:\/\/www.cpan.org\/> Comprehensive Perl Archive Network < http:\/\/lists.perl.org\/> Perl XXXXXXX XXXXXX. XXXXX XXXXXX XXXXXX\nperl-unicodeXXXXXX 'Encode'XXX XXXXXX XXXXXXXX. PerlXXX XXX XXXX XXXXXXXXXXXXX XXXXXXXXX XX XXX XXXXXX XXXXXXXX XXXXX XXXXXX < http:\/\/www.perl.or.kr\/> Perl XXXXX XXXXXXX XXXX <news:han.comp.lang.perl\/> XXXXXXXX Perl XXXXX XXX < http:\/\/seoul.pm.org\/> Perl XXXXXX (XXXXXX) < http:\/\/www.perlmania.or.kr\/> Home for Korean Perlmanias < http:\/\/www.oreilly.co.kr\/perl\/> O'ReillyXXXXXX XXXXXX XXXXXXXX Perl XXXXXX XXXX < http:\/\/www.perlschool.net\/> Perl XXXX XXXX XX XXXXXX, XXXX XXXXXX, XXXXX XXXXX XXXXXXX XXXXX < http:\/\/www.perl.co.kr> PerlXXX XXXXXXX CGI, DB, XXXXX XXXXX XXXXXX  XXXXX XX XXXXX XXXX XXXXXXXXXXX XX XXXXXXXX XXXXXXXX XXXXX XXXXX < http:\/\/www.unicode.org\/> XXXXXXXXXXX XXXXXXXXXX. < http:\/\/std.dkuug.dk\/JTC1\/SC2\/WG2> XXXXXXXXXXX UnicodeXXX XXXXX ISO XXXXXXXX ISO\/IEC 10646 UCS (Universal Character Set)XXX XXXXXXXX ISO\/IEC JTC1\/SC2\/WG2XXX XXX XXXXXXXX . < http:\/\/jshin.net\/faq\/qa8.html> XXXXXXXX XXXX XXXXX XX XXXXXXXXXX XXXXXX XXXXXX. < http:\/\/www.cl.cam.ac.uk\/~mgk25\/unicode.html> XXXXXXXXX\/XXXXXXXXXXXX XXXXXXXXXXXXXX UTF-8 XXXXXXX XXXXXX XXXXXX(FAQ) < http:\/\/kldp.org\/Translations\/html\/UTF8-Unicode-KLDP\/UTF8-Unicode-KLDP.html> XXXXXXXXX\/XXXXXXXXXXXX XXXXXXXXXXXXXX UTF-8 XXXXXXX XXXXXX XXXXXX(FAQ)XXX  XXXXXXXX XXXXX","Process Name":"perlko","Link":"https:\/\/linux.die.net\/man\/1\/perlko"}},{"Process":{"Description":"The \"use warnings\" pragma enables to control precisely what warnings are to be enabled in which parts of a Perl program. It's a more flexible alternative for both the command line flag -w and the equivalent Perl variable, $^W. This pragma works just like the \"strict\" pragma. This means that the scope of the warning pragma is limited to the enclosing block. It also means that the pragma setting will not leak across files (via \"use\", \"require\" or \"do\"). This allows authors to independently define the degree of warning checks that will be applied to their module. By default, optional warnings are disabled, so any legacy code that doesn't attempt to control the warnings will work unchanged. All warnings are enabled in a block by either of these: use warnings;\nuse warnings 'all'; Similarly all warnings are disabled in a block by either of these: no warnings;\nno warnings 'all'; For example, consider the code below: use warnings;\nmy @a;\n{\n    no warnings;\n    my $b = @a[0];\n}\nmy $c = @a[0]; The code in the enclosing block has warnings enabled, but the inner block has them disabled. In this case that means the assignment to the scalar $c will trip the \"Scalar value @a[0] better written as $a[0]\" warning, but the assignment to the scalar $b will not. Default Warnings and Optional Warnings Before the introduction of lexical warnings, Perl had two classes of warnings: mandatory and optional. As its name suggests, if your code tripped a mandatory warning, you would get a warning whether you wanted it or not. For example, the code below would always produce an \"isn't numeric\" warning about the \"2:\". my $a = \"2:\" + 3; With the introduction of lexical warnings, mandatory warnings now become default warnings. The difference is that although the previously mandatory warnings are still enabled by default, they can then be subsequently enabled or disabled with the lexical warning pragma. For example, in the code below, an \"isn't numeric\" warning will only be reported for the $a variable. my $a = \"2:\" + 3;\nno warnings;\nmy $b = \"2:\" + 3; Note that neither the -w flag or the $^W can be used to disable\/enable default warnings. They are still mandatory in this case. What's wrong with -w and $^W Although very useful, the big problem with using -w on the command line to enable warnings is that it is all or nothing. Take the typical scenario when you are writing a Perl program. Parts of the code you will write yourself, but it's very likely that you will make use of pre-written Perl modules. If you use the -w flag in this case, you end up enabling warnings in pieces of code that you haven't written. Similarly, using $^W to either disable or enable blocks of code is fundamentally flawed. For a start, say you want to disable warnings in a block of code. You might expect this to be enough to do the trick: {\n    local ($^W) = 0;\n    my $a =+ 2;\n    my $b; chop $b;\n} When this code is run with the -w flag, a warning will be produced for the $a line -- \"Reversed += operator\". The problem is that Perl has both compile-time and run-time warnings. To disable compile-time warnings you need to rewrite the code like this: {\n    BEGIN { $^W = 0 }\n    my $a =+ 2;\n    my $b; chop $b;\n} The other big problem with $^W is the way you can inadvertently change the warning setting in unexpected places in your code. For example, when the code below is run (without the -w flag), the second call to \"doit\" will trip a \"Use of uninitialized value\" warning, whereas the first will not. sub doit\n{\n    my $b; chop $b;\n}\n\ndoit();\n\n{\n    local ($^W) = 1;\n    doit()\n} This is a side-effect of $^W being dynamically scoped. Lexical warnings get around these limitations by allowing finer control over where warnings can or can't be tripped. Controlling Warnings from the Command Line There are three Command Line flags that can be used to control when warnings are (or aren't) produced: -w This is the existing flag. If the lexical warnings pragma is not used in any of you code, or any of the modules that you use, this flag will enable warnings everywhere. See \"Backward Compatibility\" for details of how this flag interacts with lexical warnings. -W If the -W flag is used on the command line, it will enable all warnings throughout the program regardless of whether warnings were disabled locally using \"no warnings\" or \"$^W =0\". This includes all files that get included via \"use\", \"require\" or \"do\". Think of it as the Perl equivalent of the \"lint\" command. -X Does the exact opposite to the -W flag, i.e. it disables all warnings. Backward Compatibility If you are used with working with a version of Perl prior to the introduction of lexically scoped warnings, or have code that uses both lexical warnings and $^W, this section will describe how they interact. How Lexical Warnings interact with -w\/$^W: 1. If none of the three command line flags (-w, -W or -X) that control warnings is used and neither $^W or the \"warnings\" pragma are used, then default warnings will be enabled and optional warnings disabled. This means that legacy code that doesn't attempt to control the warnings will work unchanged. 2. The -w flag just sets the global $^W variable as in 5.005 -- this means that any legacy code that currently relies on manipulating $^W to control warning behavior will still work as is. 3. Apart from now being a boolean, the $^W variable operates in exactly the same horrible uncontrolled global way, except that it cannot disable\/enable default warnings. 4. If a piece of code is under the control of the \"warnings\" pragma, both the $^W variable and the -w flag will be ignored for the scope of the lexical warning. 5. The only way to override a lexical warnings setting is with the -W or -X command line flags. The combined effect of 3 & 4 is that it will allow code which uses the \"warnings\" pragma to control the warning behavior of $^W-type code (using a \"local $^W=0\") if it really wants to, but not vice-versa. Category Hierarchy A hierarchy of \"categories\" have been defined to allow groups of warnings to be enabled\/disabled in isolation. The current hierarchy is: all -+\n     |\n     +- closure\n     |\n     +- deprecated\n     |\n     +- exiting\n     |\n     +- glob\n     |\n     +- io -----------+\n     |                |\n     |                +- closed\n     |                |\n     |                +- exec\n     |                |\n     |                +- layer\n     |                |\n     |                +- newline\n     |                |\n     |                +- pipe\n     |                |\n     |                +- unopened\n     |\n     +- misc\n     |\n     +- numeric\n     |\n     +- once\n     |\n     +- overflow\n     |\n     +- pack\n     |\n     +- portable\n     |\n     +- recursion\n     |\n     +- redefine\n     |\n     +- regexp\n     |\n     +- severe -------+\n     |                |\n     |                +- debugging\n     |                |\n     |                +- inplace\n     |                |\n     |                +- internal\n     |                |\n     |                +- malloc\n     |\n     +- signal\n     |\n     +- substr\n     |\n     +- syntax -------+\n     |                |\n     |                +- ambiguous\n     |                |\n     |                +- bareword\n     |                |\n     |                +- digit\n     |                |\n     |                +- parenthesis\n     |                |\n     |                +- precedence\n     |                |\n     |                +- printf\n     |                |\n     |                +- prototype\n     |                |\n     |                +- qw\n     |                |\n     |                +- reserved\n     |                |\n     |                +- semicolon\n     |\n     +- taint\n     |\n     +- threads\n     |\n     +- uninitialized\n     |\n     +- unpack\n     |\n     +- untie\n     |\n     +- utf8\n     |\n     +- void Just like the \"strict\" pragma any of these categories can be combined use warnings qw(void redefine);\nno warnings qw(io syntax untie); Also like the \"strict\" pragma, if there is more than one instance of the \"warnings\" pragma in a given scope the cumulative effect is additive. use warnings qw(void); # only \"void\" warnings enabled\n...\nuse warnings qw(io);   # only \"void\" & \"io\" warnings enabled\n...\nno warnings qw(void);  # only \"io\" warnings enabled To determine which category a specific warning has been assigned to see perldiag. Note: In Perl 5.6.1, the lexical warnings category \"deprecated\" was a sub-category of the \"syntax\" category. It is now a top-level category in its own right. Fatal Warnings The presence of the word \" FATAL \" in the category list will escalate any warnings detected from the categories specified in the lexical scope into fatal errors. In the code below, the use of \"time\", \"length\" and \"join\" can all produce a \"Useless use of xxx in void context\" warning. use warnings;\n\ntime;\n\n{\n    use warnings FATAL => qw(void);\n    length \"abc\";\n}\n\njoin \"\", 1,2,3;\n\nprint \"done\\n\"; When run it produces this output Useless use of time in void context at fatal line 3.\nUseless use of length in void context at fatal line 7. The scope where \"length\" is used has escalated the \"void\" warnings category into a fatal error, so the program terminates immediately it encounters the warning. To explicitly turn off a \" FATAL \" warning you just disable the warning it is associated with. So, for example, to disable the \"void\" warning in the example above, either of these will do the trick: no warnings qw(void);\nno warnings FATAL => qw(void); If you want to downgrade a warning that has been escalated into a fatal error back to a normal warning, you can use the \" NONFATAL \" keyword. For example, the code below will promote all warnings into fatal errors, except for those in the \"syntax\" category. use warnings FATAL => 'all', NONFATAL => 'syntax'; Reporting Warnings from a Module The \"warnings\" pragma provides a number of functions that are useful for module authors. These are used when you want to report a module-specific warning to a calling module has enabled warnings via the \"warnings\" pragma. Consider the module \"MyMod::Abc\" below. package MyMod::Abc;\n\nuse warnings::register;\n\nsub open {\n    my $path = shift;\n    if ($path !~ m#^\/#) {\n        warnings::warn(\"changing relative path to \/var\/abc\")\n            if warnings::enabled();\n        $path = \"\/var\/abc\/$path\";\n    }\n}\n\n1; The call to \"warnings::register\" will create a new warnings category called \"MyMod::abc\", i.e. the new category name matches the current package name. The \"open\" function in the module will display a warning message if it gets given a relative path as a parameter. This warnings will only be displayed if the code that uses \"MyMod::Abc\" has actually enabled them with the \"warnings\" pragma like below. use MyMod::Abc;\nuse warnings 'MyMod::Abc';\n...\nabc::open(\"..\/fred.txt\"); It is also possible to test whether the pre-defined warnings categories are set in the calling module with the \"warnings::enabled\" function. Consider this snippet of code: package MyMod::Abc;\n\nsub open {\n    warnings::warnif(\"deprecated\",\n                     \"open is deprecated, use new instead\");\n    new(@_);\n}\n\nsub new\n...\n1; The function \"open\" has been deprecated, so code has been included to display a warning message whenever the calling module has (at least) the \"deprecated\" warnings category enabled. Something like this, say. use warnings 'deprecated';\nuse MyMod::Abc;\n...\nMyMod::Abc::open($filename); Either the \"warnings::warn\" or \"warnings::warnif\" function should be used to actually display the warnings message. This is because they can make use of the feature that allows warnings to be escalated into fatal errors. So in this case use MyMod::Abc;\nuse warnings FATAL => 'MyMod::Abc';\n...\nMyMod::Abc::open('..\/fred.txt'); the \"warnings::warnif\" function will detect this and die after displaying the warning message. The three warnings functions, \"warnings::warn\", \"warnings::warnif\" and \"warnings::enabled\" can optionally take an object reference in place of a category name. In this case the functions will use the class name of the object as the warnings category. Consider this example: package Original;\n\nno warnings;\nuse warnings::register;\n\nsub new\n{\n    my $class = shift;\n    bless [], $class;\n}\n\nsub check\n{\n    my $self = shift;\n    my $value = shift;\n\n    if ($value % 2 && warnings::enabled($self))\n      { warnings::warn($self, \"Odd numbers are unsafe\") }\n}\n\nsub doit\n{\n    my $self = shift;\n    my $value = shift;\n    $self->check($value);\n    # ...\n}\n\n1;\n\npackage Derived;\n\nuse warnings::register;\nuse Original;\nour @ISA = qw( Original );\nsub new\n{\n    my $class = shift;\n    bless [], $class;\n}\n\n1; The code below makes use of both modules, but it only enables warnings from \"Derived\". use Original;\nuse Derived;\nuse warnings 'Derived';\nmy $a = Original->new();\n$a->doit(1);\nmy $b = Derived->new();\n$a->doit(1); When this code is run only the \"Derived\" object, $b, will generate a warning. Odd numbers are unsafe at main.pl line 7 Notice also that the warning is reported at the line where the object is first used.","Process Name":"perllexwarn","Link":"https:\/\/linux.die.net\/man\/1\/perllexwarn"}},{"Process":{"Description":"This document describes various features of Linux that will affect how Perl version 5 (hereafter just Perl) is compiled and\/or runs. Experimental Support for Sun Studio Compilers for Linux OS Sun Microsystems has released a port of their Sun Studio compiliers for Linux. As of November 2005, only an alpha version has been released. Until a release of these compilers is made, support for compiling Perl with these compiler experimental. Also, some special instructions for building Perl with Sun Studio on Linux. Following the normal \"Configure\", you have to run make as follows: LDLOADLIBS=-lc make \"LDLOADLIBS\" is an environment variable used by the linker to link modules \"\/ext\" modules to glibc. Currently, that environment variable is not getting populated by a combination of \"Config\" entries and \"ExtUtil::MakeMaker\". While there may be a bug somewhere in Perl's configuration or \"ExtUtil::MakeMaker\" causing the problem, the most likely cause is an incomplete understanding of Sun Studio by this author. Further investigation is needed to get this working better.","Process Name":"perllinux","Link":"https:\/\/linux.die.net\/man\/1\/perllinux"}},{"Process":{"Description":"Perl supports language-specific notions of data such as \"is this a letter\", \"what is the uppercase equivalent of this letter\", and \"which of these letters comes first\". These are important issues, especially for languages other than English--but also for English: it would be naieve to imagine that \"A-Za-z\" defines all the \"letters\" needed to write in English. Perl is also aware that some character other than '.' may be preferred as a decimal point, and that output date representations may be language-specific. The process of making an application take account of its users' preferences in such matters is called internationalization (often abbreviated as i18n); telling such an application about a particular set of preferences is known as localization (l10n). Perl can understand language-specific data via the standardized ( ISO C, XPG4 , POSIX 1.c) method called \"the locale system\". The locale system is controlled per application using one pragma, one function call, and several environment variables. NOTE : This feature is new in Perl 5.004, and does not apply unless an application specifically requests it--see \"Backward compatibility\". The one exception is that write() now always uses the current locale - see \" NOTES \".","Process Name":"perllocale","Link":"https:\/\/linux.die.net\/man\/1\/perllocale"}},{"Process":{"Description":"Declaration and Access of Arrays of Arrays The simplest thing to build is an array of arrays (sometimes imprecisely called a list of lists). It's reasonably easy to understand, and almost everything that applies here will also be applicable later on with the fancier data structures. An array of an array is just a regular old array @AoA that you can get at with two subscripts, like $AoA[3][2]. Here's a declaration of the array:   # assign to our array, an array of array references\n  @AoA = (\n         [ \"fred\", \"barney\" ],\n         [ \"george\", \"jane\", \"elroy\" ],\n         [ \"homer\", \"marge\", \"bart\" ],\n  );\n\n  print $AoA[2][2];\nbart Now you should be very careful that the outer bracket type is a round one, that is, a parenthesis. That's because you're assigning to an @array, so you need parentheses. If you wanted there not to be an @AoA, but rather just a reference to it, you could do something more like this: # assign a reference to array of array references\n$ref_to_AoA = [\n    [ \"fred\", \"barney\", \"pebbles\", \"bambam\", \"dino\", ],\n    [ \"homer\", \"bart\", \"marge\", \"maggie\", ],\n    [ \"george\", \"jane\", \"elroy\", \"judy\", ],\n];\n\nprint $ref_to_AoA->[2][2]; Notice that the outer bracket type has changed, and so our access syntax has also changed. That's because unlike C, in perl you can't freely interchange arrays and references thereto. $ref_to_AoA is a reference to an array, whereas @AoA is an array proper. Likewise, $AoA[2] is not an array, but an array ref. So how come you can write these: $AoA[2][2]\n$ref_to_AoA->[2][2] instead of having to write these: $AoA[2]->[2]\n$ref_to_AoA->[2]->[2] Well, that's because the rule is that on adjacent brackets only (whether square or curly), you are free to omit the pointer dereferencing arrow. But you cannot do so for the very first one if it's a scalar containing a reference, which means that $ref_to_AoA always needs it. Growing Your Own That's all well and good for declaration of a fixed data structure, but what if you wanted to add new elements on the fly, or build it up entirely from scratch? First, let's look at reading it in from a file. This is something like adding a row at a time. We'll assume that there's a flat file in which each line is a row and each word an element. If you're trying to develop an @AoA array containing all these, here's the right way to do that: while (<>) {\n    @tmp = split;\n    push @AoA, [ @tmp ];\n} You might also have loaded that from a function: for $i ( 1 .. 10 ) {\n    $AoA[$i] = [ somefunc($i) ];\n} Or you might have had a temporary variable sitting around with the array in it. for $i ( 1 .. 10 ) {\n    @tmp = somefunc($i);\n    $AoA[$i] = [ @tmp ];\n} It's very important that you make sure to use the \"[]\" array reference constructor. That's because this will be very wrong: $AoA[$i] = @tmp; You see, assigning a named array like that to a scalar just counts the number of elements in @tmp, which probably isn't what you want. If you are running under \"use strict\", you'll have to add some declarations to make it happy: use strict;\nmy(@AoA, @tmp);\nwhile (<>) {\n    @tmp = split;\n    push @AoA, [ @tmp ];\n} Of course, you don't need the temporary array to have a name at all: while (<>) {\n    push @AoA, [ split ];\n} You also don't have to use push(). You could just make a direct assignment if you knew where you wanted to put it: my (@AoA, $i, $line);\nfor $i ( 0 .. 10 ) {\n    $line = <>;\n    $AoA[$i] = [ split ' ', $line ];\n} or even just my (@AoA, $i);\nfor $i ( 0 .. 10 ) {\n    $AoA[$i] = [ split ' ', <> ];\n} You should in general be leery of using functions that could potentially return lists in scalar context without explicitly stating such. This would be clearer to the casual reader: my (@AoA, $i);\nfor $i ( 0 .. 10 ) {\n    $AoA[$i] = [ split ' ', scalar(<>) ];\n} If you wanted to have a $ref_to_AoA variable as a reference to an array, you'd have to do something like this: while (<>) {\n    push @$ref_to_AoA, [ split ];\n} Now you can add new rows. What about adding new columns? If you're dealing with just matrices, it's often easiest to use simple assignment: for $x (1 .. 10) {\n    for $y (1 .. 10) {\n        $AoA[$x][$y] = func($x, $y);\n    }\n}\n\nfor $x ( 3, 7, 9 ) {\n    $AoA[$x][20] += func2($x);\n} It doesn't matter whether those elements are already there or not: it'll gladly create them for you, setting intervening elements to \"undef\" as need be. If you wanted just to append to a row, you'd have to do something a bit funnier looking: # add new columns to an existing row\npush @{ $AoA[0] }, \"wilma\", \"betty\"; Notice that I couldn't say just: push $AoA[0], \"wilma\", \"betty\";  # WRONG! In fact, that wouldn't even compile. How come? Because the argument to push() must be a real array, not just a reference to such. Access and Printing Now it's time to print your data structure out. How are you going to do that? Well, if you want only one of the elements, it's trivial: print $AoA[0][0]; If you want to print the whole thing, though, you can't say print @AoA;         # WRONG because you'll get just references listed, and perl will never automatically dereference things for you. Instead, you have to roll yourself a loop or two. This prints the whole structure, using the shell-style for() construct to loop across the outer set of subscripts. for $aref ( @AoA ) {\n    print \"\\t [ @$aref ],\\n\";\n} If you wanted to keep track of subscripts, you might do this: for $i ( 0 .. $#AoA ) {\n    print \"\\t elt $i is [ @{$AoA[$i]} ],\\n\";\n} or maybe even this. Notice the inner loop. for $i ( 0 .. $#AoA ) {\n    for $j ( 0 .. $#{$AoA[$i]} ) {\n        print \"elt $i $j is $AoA[$i][$j]\\n\";\n    }\n} As you can see, it's getting a bit complicated. That's why sometimes is easier to take a temporary on your way through: for $i ( 0 .. $#AoA ) {\n    $aref = $AoA[$i];\n    for $j ( 0 .. $#{$aref} ) {\n        print \"elt $i $j is $AoA[$i][$j]\\n\";\n    }\n} Hmm... that's still a bit ugly. How about this: for $i ( 0 .. $#AoA ) {\n    $aref = $AoA[$i];\n    $n = @$aref - 1;\n    for $j ( 0 .. $n ) {\n        print \"elt $i $j is $AoA[$i][$j]\\n\";\n    }\n} Slices If you want to get at a slice (part of a row) in a multidimensional array, you're going to have to do some fancy subscripting. That's because while we have a nice synonym for single elements via the pointer arrow for dereferencing, no such convenience exists for slices. (Remember, of course, that you can always write a loop to do a slice operation.) Here's how to do one operation using a loop. We'll assume an @AoA variable as before. @part = ();\n$x = 4;\nfor ($y = 7; $y < 13; $y++) {\n    push @part, $AoA[$x][$y];\n} That same loop could be replaced with a slice operation: @part = @{ $AoA[4] } [ 7..12 ]; but as you might well imagine, this is pretty rough on the reader. Ah, but what if you wanted a two-dimensional slice, such as having $x run from 4..8 and $y run from 7 to 12? Hmm... here's the simple way: @newAoA = ();\nfor ($startx = $x = 4; $x <= 8; $x++) {\n    for ($starty = $y = 7; $y <= 12; $y++) {\n        $newAoA[$x - $startx][$y - $starty] = $AoA[$x][$y];\n    }\n} We can reduce some of the looping through slices for ($x = 4; $x <= 8; $x++) {\n    push @newAoA, [ @{ $AoA[$x] } [ 7..12 ] ];\n} If you were into Schwartzian Transforms, you would probably have selected map for that @newAoA = map { [ @{ $AoA[$_] } [ 7..12 ] ] } 4 .. 8; Although if your manager accused you of seeking job security (or rapid insecurity) through inscrutable code, it would be hard to argue. :-) If I were you, I'd put that in a function: @newAoA = splice_2D( \\@AoA, 4 => 8, 7 => 12 );\nsub splice_2D {\n    my $lrr = shift;        # ref to array of array refs!\n    my ($x_lo, $x_hi,\n        $y_lo, $y_hi) = @_;\n\n    return map {\n        [ @{ $lrr->[$_] } [ $y_lo .. $y_hi ] ]\n    } $x_lo .. $x_hi;\n}","Process Name":"perllol","Link":"https:\/\/linux.die.net\/man\/1\/perllol"}},{"Process":{"Description":"This document describes how to build Perl 5 on Power MachTen systems, and discusses a few wrinkles in the implementation. Perl version 5.8.x and greater not supported Power MachTen is not supported by versions of Perl later than 5.6.x. If you wish to build a version from the 5.6 track, please obtain a source distribution from the archive at < http:\/\/cpan.org\/src\/5.0\/> and follow the instructions in its README .machten file. MachTen is no longer supported by its developers, Tenon Intersystems. A UNIX environment hosted on Mac OS Classic, MachTen has been superseded by Mac OS X and by BSD and Linux implementations for Macintosh hardware. The final version of Power MachTen, 4.1.4, lacks many features found in modern implementations of UNIX , and has a number of bugs. These shortcomings prevent recent versions of Perl from being able to use extensions on MachTen, and cause numerous test suite failures in the perl core. In September 2003, a discussion on the MachTen mailing list determined that there was no interest in making a later version of Perl build successfully on MachTen. Consequently, support for building Perl under MachTen has been suppressed in Perl distributions published after February 2004. The hints file, hints\/machten.sh, remains a part of the distributions for reference purposes. Compiling Perl 5.6.x on MachTen To compile perl 5.6.x under MachTen 4.1.4 (and probably earlier versions): .\/Configure -de\nmake\nmake test\nmake install This builds and installs a statically-linked perl; MachTen's dynamic linking facilities are not adequate to support Perl's use of dynamically linked libraries. (See hints\/machten.sh for more information.) You should have at least 32 megabytes of free memory on your system before running the \"make\" command. For much more information on building perl -- for example, on how to change the default installation directory -- see INSTALL . Failures during \"make test\" on MachTen op\/lexassign.t This test may fail when first run after building perl. It does not fail subsequently. The cause is unknown. pragma\/warnings.t Test 257 fails due to a failure to warn about attempts to read from a filehandle which is a duplicate of stdout when stdout is attached to a pipe. The output of the test contains a block comment which discusses a different failure, not applicable to MachTen. The root of the problem is that Machten does not assign a file type to either end of a pipe (see stat), resulting, among other things in Perl's \"-p\" test failing on file descriptors belonging to pipes. As a result, perl becomes confused, and the test for reading from a write-only file fails. I am reluctant to patch perl to get around this, as it's clearly an OS bug (about which Tenon has been informed), and limited in its effect on practical Perl programs. Building external modules on MachTen To add an external module to perl, build in the normal way, which is documented in ExtUtils::MakeMaker, or which can be driven automatically by the CPAN module (see CPAN ), which is part of the standard distribution. If you want to install a module which contains XS code (C or C ++ source which compiles to object code for linking with perl), you will have to replace your perl binary with a new version containing the new statically-linked object module. The build process tells you how to do this. There is a gotcha, however, which users usually encounter immediately they respond to CPAN 's invitation to \"install Bundle::CPAN\". When installing a bundle -- a group of modules which together achieve some particular purpose, the installation process for later modules in the bundle tends to assume that earlier modules have been fully installed and are available for use. This is not true on a statically-linked system for earlier modules which contain XS code. As a result the installation of the bundle fails. The work-around is not to install the bundle as a one-shot operation, but instead to see what modules it contains, and install these one-at-a-time by hand in the order given.","Process Name":"perlmachten","Link":"https:\/\/linux.die.net\/man\/1\/perlmachten"}},{"Process":{"Description":"The latest perl source itself builds on Mac OS , with some additional pieces. Support for Mac OS is now in the perl core, and MacPerl is kept in close sync with regular perl releases. To build perl for Mac OS (as an MPW tool), you will need the addition of the macos subdirectory, distributed separately. It includes extra source files, config files, and make files. It also includes extra Mac-specific modules. To build the MacPerl application, you will also need the macperl directory, which includes the source files for creating the application itself. All of this is available from the development site, via HTTP (in the MacPerl Installer, which includes all the source and binaries) and anonymous CVS . http:\/\/dev.macperl.org\/ The source is also in the main perl repository in the macperl branch (the 5.6 source is in the maint-5.6\/macperl branch). You will also need compilers and libraries, all of them freely available. These are linked to from the SourceForge site. Go that site for all things having to do with MacPerl development. MacPerl 5.6.1 and later are supported on Mac OS 8.1 and later, for 68040 and PowerPC architectures. The MPW tool may be used on Mac OS 7.5.5 and 68030 computers. MacPerl 5.2.0r4 is also available, on the CPAN and on SourceForge. It is based on perl 5.004, and works with Mac OS 7.5.5 and 68030 computers.","Process Name":"perlmacos","Link":"https:\/\/linux.die.net\/man\/1\/perlmacos"}},{"Process":{"Description":"The latest Perl release (5.8.8 as of this writing) builds without changes under Mac OS X. Under 10.3 \"Panther\" and newer OS versions, all self-tests pass, and all standard features are supported. Earlier Mac OS X releases (10.2 \"Jaguar\" and older) did not include a completely thread-safe libc, so threading is not fully supported. Also, earlier releases included a buggy libdb, so some of the DB_File tests are known to fail on those releases. Installation Prefix The default installation location for this release uses the traditional UNIX directory layout under \/usr\/local. This is the recommended location for most users, and will leave the Apple-supplied Perl and its modules undisturbed. Using an installation prefix of '\/usr' will result in a directory layout that mirrors that of Apple's default Perl, with core modules stored in '\/System\/Library\/Perl\/${version}', CPAN modules stored in '\/Library\/Perl\/${version}', and the addition of '\/Network\/Library\/Perl\/${version}' to @INC for modules that are stored on a file server and used by many Macs. SDK support First, export the path to the SDK into the build environment: export SDK=\/Developer\/SDKs\/MacOSX10.3.9.sdk Use an SDK by exporting some additions to Perl's 'ccflags' and '..flags' config variables: .\/Configure -Accflags=\"-nostdinc -B$SDK\/usr\/include\/gcc \\\n                       -B$SDK\/usr\/lib\/gcc -isystem$SDK\/usr\/include \\\n                       -F$SDK\/System\/Library\/Frameworks\" \\\n            -Aldflags=\"-Wl,-syslibroot,$SDK\" \\\n            -de Universal Binary support To compile perl as a universal binary (built for both ppc and intel), export the SDK variable as above, selecting the 10.4u SDK: export SDK=\/Developer\/SDKs\/MacOSX10.4u.sdk In addition to the compiler flags used to select the SDK , also add the flags for creating a universal binary: .\/Configure -Accflags=\"-arch i686 -arch ppc -nostdinc -B$SDK\/usr\/include\/gcc \\\n                       -B$SDK\/usr\/lib\/gcc -isystem$SDK\/usr\/include \\\n                       -F$SDK\/System\/Library\/Frameworks\" \\\n            -Aldflags=\"-arch i686 -arch ppc -Wl,-syslibroot,$SDK\" \\\n            -de In Leopard (MacOSX 10.5.6 at the time of this writing) you must use the 10.5 SDK: export SDK=\/Developer\/SDKs\/MacOSX10.5.sdk You can use the same compiler flags you would use with the 10.4u SDK . Keep in mind that these compiler and linker settings will also be used when building CPAN modules. For XS modules to be compiled as a universal binary, any libraries it links to must also be universal binaries. The system libraries that Apple includes with the 10.4u SDK are all universal, but user-installed libraries may need to be re-installed as universal binaries. 64-bit PPC support Follow the instructions in INSTALL to build perl with support for 64-bit integers ( \"use64bitint\") or both 64-bit integers and 64-bit addressing ( \"use64bitall\"). In the latter case, the resulting binary will run only on G5-based hosts. Support for 64-bit addressing is experimental: some aspects of Perl may be omitted or buggy. Note the messages output by Configure for further information. Please use \"perlbug\" to submit a problem report in the event that you encounter difficulties. When building 64-bit modules, it is your responsiblity to ensure that linked external libraries and frameworks provide 64-bit support: if they do not, module building may appear to succeed, but attempts to use the module will result in run-time dynamic linking errors, and subsequent test failures. You can use \"file\" to discover the architectures supported by a library: $ file libgdbm.3.0.0.dylib\nlibgdbm.3.0.0.dylib: Mach-O fat file with 2 architectures\nlibgdbm.3.0.0.dylib (for architecture ppc):      Mach-O dynamically linked shared library ppc\nlibgdbm.3.0.0.dylib (for architecture ppc64):    Mach-O 64-bit dynamically linked shared library ppc64 Note that this issue precludes the building of many Macintosh-specific CPAN modules ( \"Mac::*\"), as the required Apple frameworks do not provide PPC64 support. Similarly, downloads from Fink or Darwinports are unlikely to provide 64-bit support; the libraries must be rebuilt from source with the appropriate compiler and linker flags. For further information, see Apple's 64-Bit Transition Guide at < http:\/\/developer.apple.com\/documentation\/Darwin\/Conceptual\/64bitPorting\/index.html>. libperl and Prebinding Mac OS X ships with a dynamically-loaded libperl, but the default for this release is to compile a static libperl. The reason for this is pre-binding. Dynamic libraries can be pre-bound to a specific address in memory in order to decrease load time. To do this, one needs to be aware of the location and size of all previously-loaded libraries. Apple collects this information as part of their overall OS build process, and thus has easy access to it when building Perl, but ordinary users would need to go to a great deal of effort to obtain the information needed for pre-binding. You can override the default and build a shared libperl if you wish (Configure ... -Duseshrlib), but the load time on pre-10.4 OS releases will be greater than either the static library, or Apple's pre-bound dynamic library. With 10.4 \"Tiger\" and newer, Apple has all but eliminated the performance penalty for non-prebound libraries. Updating Apple's Perl In a word - don't, at least without a *very* good reason. Your scripts can just as easily begin with \"#!\/usr\/local\/bin\/perl\" as with \"#!\/usr\/bin\/perl\". Scripts supplied by Apple and other third parties as part of installation packages and such have generally only been tested with the \/usr\/bin\/perl that's installed by Apple. If you find that you do need to update the system Perl, one issue worth keeping in mind is the question of static vs. dynamic libraries. If you upgrade using the default static libperl, you will find that the dynamic libperl supplied by Apple will not be deleted. If both libraries are present when an application that links against libperl is built, ld will link against the dynamic library by default. So, if you need to replace Apple's dynamic libperl with a static libperl, you need to be sure to delete the older dynamic library after you've installed the update. Known problems If you have installed extra libraries such as GDBM through Fink (in other words, you have libraries under \/sw\/lib), or libdlcompat to \/usr\/local\/lib, you may need to be extra careful when running Configure to not to confuse Configure and Perl about which libraries to use. Being confused will show up for example as \"dyld\" errors about symbol problems, for example during \"make test\". The safest bet is to run Configure as Configure ... -Uloclibpth -Dlibpth=\/usr\/lib to make Configure look only into the system libraries. If you have some extra library directories that you really want to use (such as newer Berkeley DB libraries in pre-Panther systems), add those to the libpth: Configure ... -Uloclibpth -Dlibpth='\/usr\/lib \/opt\/lib' The default of building Perl statically may cause problems with complex applications like Tk: in that case consider building shared Perl Configure ... -Duseshrplib but remember that there's a startup cost to pay in that case (see above \"libperl and Prebinding\"). Starting with Tiger (Mac OS X 10.4), Apple shipped broken locale files for the eu_ES locale (Basque-Spain). In previous releases of Perl, this resulted in failures in the \"lib\/locale\" test. These failures have been supressed in the current release of Perl by making the test ignore the broken locale. If you need to use the eu_ES locale, you should contact Apple support. MacPerl Quite a bit has been written about MacPerl, the Perl distribution for \"Classic MacOS\" - that is, versions 9 and earlier of MacOS. Because it runs in environment that's very different from that of UNIX , many things are done differently in MacPerl. Modules are installed using a different procedure, Perl itself is built differently, path names are different, etc. From the perspective of a Perl programmer, Mac OS X is more like a traditional UNIX than Classic MacOS. If you find documentation that refers to a special procedure that's needed for MacOS that's drastically different from the instructions provided for UNIX , the MacOS instructions are quite often intended for MacPerl on Classic MacOS. In that case, the correct procedure on Mac OS X is usually to follow the UNIX instructions, rather than the MacPerl instructions. Carbon MacPerl ships with a number of modules that are used to access the classic MacOS toolbox. Many of these modules have been updated to use Mac OS X's newer \"Carbon\" toolbox, and are available from CPAN in the \"Mac::Carbon\" module. Cocoa There are two ways to use Cocoa from Perl. Apple's PerlObjCBridge module, included with Mac OS X, can be used by standalone scripts to access Foundation (i.e. non-GUI) classes and objects. An alternative is CamelBones, a framework that allows access to both Foundation and AppKit classes and objects, so that full GUI applications can be built in Perl. CamelBones can be found on SourceForge, at <http:\/\/www.sourceforge.net\/projects\/camelbones\/>.","Process Name":"perlmacosx","Link":"https:\/\/linux.die.net\/man\/1\/perlmacosx"}},{"Process":{"Description":"An example of config file: # -*- perl -*-\n# ~\/.perlmine\nuse utf8;\n%Config = (\n    %Config,\n    rows => 10,\n    cols => 10,\n    mines => 10,\n    image_directory => '\/usr\/share\/pixmaps\/gnomine',\n    name => 'aaXXaeXXaaXX',\n); Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"perlmine.pl","Link":"https:\/\/linux.die.net\/man\/1\/perlmine.pl"}},{"Process":{"Description":"There is a binary version of perl available from the FreeMiNT project http:\/\/freemint.de\/ You may wish to use this instead of trying to compile yourself. The following advice is from perl 5.004_02 and is probably rather out of date. If you want to build perl yourself on MiNT (or maybe on an Atari without MiNT) you may want to accept some advice from somebody who already did it... There was a perl port for Atari ST done by ++jrb bammi@cadence.com. This port tried very hard to build on non-MiNT-systems. For the sake of efficiency I've left this way. Yet, I haven't removed bammi's patches but left them intact. Unfortunately some of the files that bammi contributed to the perl distribution seem to have vanished? So, how can you distinguish my patches from bammi's patches? All of bammi's stuff is embedded in \"#ifdef atarist\" preprocessor macros. My MiNT port uses \"#ifdef __MINT__\" instead (and unconditionally undefines \"atarist\". If you want to continue on bammi's port, all you have to do is to swap the \"-D\" and \"-U\" switches for \"__MINT__\" and \"atarist\" in the variable ccflags. However, I think that my version will still run on non-MiNT-systems provided that the user has a Eunuchs-like environment (i.e. the standard envariables like $PATH, $HOME, ... are set, there is a POSIX compliant shell in \/bin\/sh, and...)","Process Name":"perlmint","Link":"https:\/\/linux.die.net\/man\/1\/perlmint"}},{"Process":{"Description":"Packages Perl provides a mechanism for alternative namespaces to protect packages from stomping on each other's variables. In fact, there's really no such thing as a global variable in Perl. The package statement declares the compilation unit as being in the given namespace. The scope of the package declaration is from the declaration itself through the end of the enclosing block, \"eval\", or file, whichever comes first (the same scope as the my() and local() operators). Unqualified dynamic identifiers will be in this namespace, except for those few identifiers that if unqualified, default to the main package instead of the current one as described below. A package statement affects only dynamic variables--including those you've used local() on--but not lexical variables created with my(). Typically it would be the first declaration in a file included by the \"do\", \"require\", or \"use\" operators. You can switch into a package in more than one place; it merely influences which symbol table is used by the compiler for the rest of that block. You can refer to variables and filehandles in other packages by prefixing the identifier with the package name and a double colon: $Package::Variable. If the package name is null, the \"main\" package is assumed. That is, $::sail is equivalent to $main::sail. The old package delimiter was a single quote, but double colon is now the preferred delimiter, in part because it's more readable to humans, and in part because it's more readable to emacs macros. It also makes C ++ programmers feel like they know what's going on--as opposed to using the single quote as separator, which was there to make Ada programmers feel like they knew what was going on. Because the old-fashioned syntax is still supported for backwards compatibility, if you try to use a string like \"This is $owner's house\", you'll be accessing $owner::s; that is, the $s variable in package \"owner\", which is probably not what you meant. Use braces to disambiguate, as in \"This is ${owner}'s house\". Packages may themselves contain package separators, as in $OUTER::INNER::var. This implies nothing about the order of name lookups, however. There are no relative packages: all symbols are either local to the current package, or must be fully qualified from the outer package name down. For instance, there is nowhere within package \"OUTER\" that $INNER::var refers to $OUTER::INNER::var. \"INNER\" refers to a totally separate global package. Only identifiers starting with letters (or underscore) are stored in a package's symbol table. All other symbols are kept in package \"main\", including all punctuation variables, like $_. In addition, when unqualified, the identifiers STDIN , STDOUT , STDERR , ARGV , ARGVOUT , ENV , INC , and SIG are forced to be in package \"main\", even when used for other purposes than their built-in ones. If you have a package called \"m\", \"s\", or \"y\", then you can't use the qualified form of an identifier because it would be instead interpreted as a pattern match, a substitution, or a transliteration. Variables beginning with underscore used to be forced into package main, but we decided it was more useful for package writers to be able to use leading underscore to indicate private variables and method names. However, variables and functions named with a single \"_\", such as $_ and \"sub _\", are still forced into the package \"main\". See also \"Technical Note on the Syntax of Variable Names\" in perlvar. \"eval\"ed strings are compiled in the package in which the eval() was compiled. (Assignments to $SIG{}, however, assume the signal handler specified is in the \"main\" package. Qualify the signal handler name if you wish to have a signal handler in a package.) For an example, examine perldb.pl in the Perl library. It initially switches to the \"DB\" package so that the debugger doesn't interfere with variables in the program you are trying to debug. At various points, however, it temporarily switches back to the \"main\" package to evaluate various expressions in the context of the \"main\" package (or wherever you came from). See perldebug. The special symbol \"__PACKAGE__\" contains the current package, but cannot (easily) be used to construct variable names. See perlsub for other scoping issues related to my() and local(), and perlref regarding closures. Symbol Tables The symbol table for a package happens to be stored in the hash of that name with two colons appended. The main symbol table's name is thus %main::, or %:: for short. Likewise the symbol table for the nested package mentioned earlier is named %OUTER::INNER::. The value in each entry of the hash is what you are referring to when you use the *name typeglob notation. local *main::foo    = *main::bar; You can use this to print out all the variables in a package, for instance. The standard but antiquated dumpvar.pl library and the CPAN module Devel::Symdump make use of this. Assignment to a typeglob performs an aliasing operation, i.e., *dick = *richard; causes variables, subroutines, formats, and file and directory handles accessible via the identifier \"richard\" also to be accessible via the identifier \"dick\". If you want to alias only a particular variable or subroutine, assign a reference instead: *dick = \\$richard; Which makes $richard and $dick the same variable, but leaves @richard and @dick as separate arrays. Tricky, eh? There is one subtle difference between the following statements: *foo = *bar;\n*foo = \\$bar; \"*foo = *bar\" makes the typeglobs themselves synonymous while \"*foo = \\$bar\" makes the SCALAR portions of two distinct typeglobs refer to the same scalar value. This means that the following code: $bar = 1;\n*foo = \\$bar;       # Make $foo an alias for $bar\n\n{\n    local $bar = 2; # Restrict changes to block\n    print $foo;     # Prints '1'!\n} Would print '1', because $foo holds a reference to the original $bar -- the one that was stuffed away by \"local()\" and which will be restored when the block ends. Because variables are accessed through the typeglob, you can use \"*foo = *bar\" to create an alias which can be localized. (But be aware that this means you can't have a separate @foo and @bar, etc.) What makes all of this important is that the Exporter module uses glob aliasing as the import\/export mechanism. Whether or not you can properly localize a variable that has been exported from a module depends on how it was exported: @EXPORT = qw($FOO); # Usual form, can't be localized\n@EXPORT = qw(*FOO); # Can be localized You can work around the first case by using the fully qualified name ( $Package::FOO) where you need a local value, or by overriding it by saying \"*FOO = *Package::FOO\" in your script. The \"*x = \\$y\" mechanism may be used to pass and return cheap references into or from subroutines if you don't want to copy the whole thing. It only works when assigning to dynamic variables, not lexicals. %some_hash = ();                    # can't be my()\n*some_hash = fn( \\%another_hash );\nsub fn {\n    local *hashsym = shift;\n    # now use %hashsym normally, and you\n    # will affect the caller's %another_hash\n    my %nhash = (); # do what you want\n    return \\%nhash;\n} On return, the reference will overwrite the hash slot in the symbol table specified by the *some_hash typeglob. This is a somewhat tricky way of passing around references cheaply when you don't want to have to remember to dereference variables explicitly. Another use of symbol tables is for making \"constant\" scalars. *PI = \\3.14159265358979; Now you cannot alter $PI, which is probably a good thing all in all. This isn't the same as a constant subroutine, which is subject to optimization at compile-time. A constant subroutine is one prototyped to take no arguments and to return a constant expression. See perlsub for details on these. The \"use constant\" pragma is a convenient shorthand for these. You can say *foo{PACKAGE} and *foo{NAME} to find out what name and package the *foo symbol table entry comes from. This may be useful in a subroutine that gets passed typeglobs as arguments: sub identify_typeglob {\n    my $glob = shift;\n    print 'You gave me ', *{$glob}{PACKAGE}, '::', *{$glob}{NAME}, \"\\n\";\n}\nidentify_typeglob *foo;\nidentify_typeglob *bar::baz; This prints You gave me main::foo\nYou gave me bar::baz The *foo{THING} notation can also be used to obtain references to the individual elements of *foo. See perlref. Subroutine definitions (and declarations, for that matter) need not necessarily be situated in the package whose symbol table they occupy. You can define a subroutine outside its package by explicitly qualifying the name of the subroutine: package main;\nsub Some_package::foo { ... }   # &foo defined in Some_package This is just a shorthand for a typeglob assignment at compile time: BEGIN { *Some_package::foo = sub { ... } } and is not the same as writing: {\n    package Some_package;\n    sub foo { ... }\n} In the first two versions, the body of the subroutine is lexically in the main package, not in Some_package. So something like this: package main;\n\n$Some_package::name = \"fred\";\n$main::name = \"barney\";\n\nsub Some_package::foo {\n    print \"in \", __PACKAGE__, \": \\$name is '$name'\\n\";\n}\n\nSome_package::foo(); prints: in main: $name is 'barney' rather than: in Some_package: $name is 'fred' This also has implications for the use of the SUPER:: qualifier (see perlobj). BEGIN , UNITCHECK , CHECK , INIT and END Five specially named code blocks are executed at the beginning and at the end of a running Perl program. These are the \"BEGIN\", \"UNITCHECK\", \"CHECK\", \"INIT\", and \"END\" blocks. These code blocks can be prefixed with \"sub\" to give the appearance of a subroutine (although this is not considered good style). One should note that these code blocks don't really exist as named subroutines (despite their appearance). The thing that gives this away is the fact that you can have more than one of these code blocks in a program, and they will get all executed at the appropriate moment. So you can't execute any of these code blocks by name. A \"BEGIN\" code block is executed as soon as possible, that is, the moment it is completely defined, even before the rest of the containing file (or string) is parsed. You may have multiple \"BEGIN\" blocks within a file (or eval'ed string) -- they will execute in order of definition. Because a \"BEGIN\" code block executes immediately, it can pull in definitions of subroutines and such from other files in time to be visible to the rest of the compile and run time. Once a \"BEGIN\" has run, it is immediately undefined and any code it used is returned to Perl's memory pool. An \"END\" code block is executed as late as possible, that is, after perl has finished running the program and just before the interpreter is being exited, even if it is exiting as a result of a die() function. (But not if it's morphing into another program via \"exec\", or being blown out of the water by a signal--you have to trap that yourself (if you can).) You may have multiple \"END\" blocks within a file--they will execute in reverse order of definition; that is: last in, first out ( LIFO ). \"END\" blocks are not executed when you run perl with the \"-c\" switch, or if compilation fails. Note that \"END\" code blocks are not executed at the end of a string \"eval()\": if any \"END\" code blocks are created in a string \"eval()\", they will be executed just as any other \"END\" code block of that package in LIFO order just before the interpreter is being exited. Inside an \"END\" code block, $? contains the value that the program is going to pass to \"exit()\". You can modify $? to change the exit value of the program. Beware of changing $? by accident (e.g. by running something via \"system\"). \"UNITCHECK\", \"CHECK\" and \"INIT\" code blocks are useful to catch the transition between the compilation phase and the execution phase of the main program. \"UNITCHECK\" blocks are run just after the unit which defined them has been compiled. The main program file and each module it loads are compilation units, as are string \"eval\"s, code compiled using the \"(?{ })\" construct in a regex, calls to \"do FILE\", \"require FILE\", and code after the \"-e\" switch on the command line. \"CHECK\" code blocks are run just after the initial Perl compile phase ends and before the run time begins, in LIFO order. \"CHECK\" code blocks are used in the Perl compiler suite to save the compiled state of the program. \"INIT\" blocks are run just before the Perl runtime begins execution, in \"first in, first out\" ( FIFO ) order. The \"CHECK\" and \"INIT\" code blocks will not be executed inside a string eval(), if that eval() happens after the end of the main compilation phase; that can be a problem in mod_perl and other persistent environments which use \"eval STRING\" to load code at runtime. When you use the -n and -p switches to Perl, \"BEGIN\" and \"END\" work just as they do in awk, as a degenerate case. Both \"BEGIN\" and \"CHECK\" blocks are run when you use the -c switch for a compile-only syntax check, although your main code is not. The begincheck program makes it all clear, eventually: #!\/usr\/bin\/perl\n\n# begincheck\n\nprint         \"10. Ordinary code runs at runtime.\\n\";\n\nEND { print   \"16.   So this is the end of the tale.\\n\" }\nINIT { print  \" 7. INIT blocks run FIFO just before runtime.\\n\" }\nUNITCHECK {\n  print       \" 4.   And therefore before any CHECK blocks.\\n\"\n}\nCHECK { print \" 6.   So this is the sixth line.\\n\" }\n\nprint         \"11.   It runs in order, of course.\\n\";\n\nBEGIN { print \" 1. BEGIN blocks run FIFO during compilation.\\n\" }\nEND { print   \"15.   Read perlmod for the rest of the story.\\n\" }\nCHECK { print \" 5. CHECK blocks run LIFO after all compilation.\\n\" }\nINIT { print  \" 8.   Run this again, using Perl's -c switch.\\n\" }\n\nprint         \"12.   This is anti-obfuscated code.\\n\";\n\nEND { print   \"14. END blocks run LIFO at quitting time.\\n\" }\nBEGIN { print \" 2.   So this line comes out second.\\n\" }\nUNITCHECK {\n print \" 3. UNITCHECK blocks run LIFO after each file is compiled.\\n\"\n}\nINIT { print  \" 9.   You'll see the difference right away.\\n\" }\n\nprint         \"13.   It merely _looks_ like it should be confusing.\\n\";\n\n__END__ Perl Classes There is no special class syntax in Perl, but a package may act as a class if it provides subroutines to act as methods. Such a package may also derive some of its methods from another class (package) by listing the other package name(s) in its global @ISA array (which must be a package global, not a lexical). For more on this, see perltoot and perlobj. Perl Modules A module is just a set of related functions in a library file, i.e., a Perl package with the same name as the file. It is specifically designed to be reusable by other modules or programs. It may do this by providing a mechanism for exporting some of its symbols into the symbol table of any package using it, or it may function as a class definition and make its semantics available implicitly through method calls on the class and its objects, without explicitly exporting anything. Or it can do a little of both. For example, to start a traditional, non-OO module called Some::Module, create a file called Some\/Module.pm and start with this template: package Some::Module;  # assumes Some\/Module.pm\n\nuse strict;\nuse warnings;\n\nBEGIN {\n    use Exporter   ();\n    our ($VERSION, @ISA, @EXPORT, @EXPORT_OK, %EXPORT_TAGS);\n\n    # set the version for version checking\n    $VERSION     = 1.00;\n    # if using RCS\/CVS, this may be preferred\n    $VERSION = sprintf \"%d.%03d\", q$Revision: 1.1 $ =~ \/(\\d+)\/g;\n\n    @ISA         = qw(Exporter);\n    @EXPORT      = qw(&func1 &func2 &func4);\n    %EXPORT_TAGS = ( );     # eg: TAG => [ qw!name1 name2! ],\n\n    # your exported package globals go here,\n    # as well as any optionally exported functions\n    @EXPORT_OK   = qw($Var1 %Hashit &func3);\n}\nour @EXPORT_OK;\n\n# exported package globals go here\nour $Var1;\nour %Hashit;\n\n# non-exported package globals go here\nour @more;\nour $stuff;\n\n# initialize package globals, first exported ones\n$Var1   = '';\n%Hashit = ();\n\n# then the others (which are still accessible as $Some::Module::stuff)\n$stuff  = '';\n@more   = ();\n\n# all file-scoped lexicals must be created before\n# the functions below that use them.\n\n# file-private lexicals go here\nmy $priv_var    = '';\nmy %secret_hash = ();\n\n# here's a file-private function as a closure,\n# callable as &$priv_func;  it cannot be prototyped.\nmy $priv_func = sub {\n    # stuff goes here.\n};\n\n# make all your functions, whether exported or not;\n# remember to put something interesting in the {} stubs\nsub func1      {}    # no prototype\nsub func2()    {}    # proto'd void\nsub func3($$)  {}    # proto'd to 2 scalars\n\n# this one isn't exported, but could be called!\nsub func4(\\%)  {}    # proto'd to 1 hash ref\n\nEND { }       # module clean-up code here (global destructor)\n\n## YOUR CODE GOES HERE\n\n1;  # don't forget to return a true value from the file Then go on to declare and use your variables in functions without any qualifications. See Exporter and the perlmodlib for details on mechanics and style issues in module creation. Perl modules are included into your program by saying use Module; or use Module LIST; This is exactly equivalent to BEGIN { require Module; import Module; } or BEGIN { require Module; import Module LIST; } As a special case use Module (); is exactly equivalent to BEGIN { require Module; } All Perl module files have the extension .pm. The \"use\" operator assumes this so you don't have to spell out \" Module.pm\" in quotes. This also helps to differentiate new modules from old .pl and .ph files. Module names are also capitalized unless they're functioning as pragmas; pragmas are in effect compiler directives, and are sometimes called \"pragmatic modules\" (or even \"pragmata\" if you're a classicist). The two statements: require SomeModule;\nrequire \"SomeModule.pm\"; differ from each other in two ways. In the first case, any double colons in the module name, such as \"Some::Module\", are translated into your system's directory separator, usually \"\/\". The second case does not, and would have to be specified literally. The other difference is that seeing the first \"require\" clues in the compiler that uses of indirect object notation involving \"SomeModule\", as in \"$ob = purge SomeModule\", are method calls, not function calls. (Yes, this really can make a difference.) Because the \"use\" statement implies a \"BEGIN\" block, the importing of semantics happens as soon as the \"use\" statement is compiled, before the rest of the file is compiled. This is how it is able to function as a pragma mechanism, and also how modules are able to declare subroutines that are then visible as list or unary operators for the rest of the current file. This will not work if you use \"require\" instead of \"use\". With \"require\" you can get into this problem: require Cwd;                # make Cwd:: accessible\n$here = Cwd::getcwd();\n\nuse Cwd;                    # import names from Cwd::\n$here = getcwd();\n\nrequire Cwd;                # make Cwd:: accessible\n$here = getcwd();           # oops! no main::getcwd() In general, \"use Module ()\" is recommended over \"require Module\", because it determines module availability at compile time, not in the middle of your program's execution. An exception would be if two modules each tried to \"use\" each other, and each also called a function from that other module. In that case, it's easy to use \"require\" instead. Perl packages may be nested inside other package names, so we can have package names containing \"::\". But if we used that package name directly as a filename it would make for unwieldy or impossible filenames on some systems. Therefore, if a module's name is, say, \"Text::Soundex\", then its definition is actually found in the library file Text\/Soundex.pm. Perl modules always have a .pm file, but there may also be dynamically linked executables (often ending in .so) or autoloaded subroutine definitions (often ending in .al) associated with the module. If so, these will be entirely transparent to the user of the module. It is the responsibility of the .pm file to load (or arrange to autoload) any additional functionality. For example, although the POSIX module happens to do both dynamic loading and autoloading, the user can say just \"use POSIX\" to get it all. Making your module threadsafe Since 5.6.0, Perl has had support for a new type of threads called interpreter threads (ithreads). These threads can be used explicitly and implicitly. Ithreads work by cloning the data tree so that no data is shared between different threads. These threads can be used by using the \"threads\" module or by doing fork() on win32 (fake fork() support). When a thread is cloned all Perl data is cloned, however non-Perl data cannot be cloned automatically. Perl after 5.7.2 has support for the \"CLONE\" special subroutine. In \"CLONE\" you can do whatever you need to do, like for example handle the cloning of non-Perl data, if necessary. \"CLONE\" will be called once as a class method for every package that has it defined (or inherits it). It will be called in the context of the new thread, so all modifications are made in the new area. Currently CLONE is called with no parameters other than the invocant package name, but code should not assume that this will remain unchanged, as it is likely that in future extra parameters will be passed in to give more information about the state of cloning. If you want to CLONE all objects you will need to keep track of them per package. This is simply done using a hash and Scalar::Util::weaken(). Perl after 5.8.7 has support for the \"CLONE_SKIP\" special subroutine. Like \"CLONE\", \"CLONE_SKIP\" is called once per package; however, it is called just before cloning starts, and in the context of the parent thread. If it returns a true value, then no objects of that class will be cloned; or rather, they will be copied as unblessed, undef values. For example: if in the parent there are two references to a single blessed hash, then in the child there will be two references to a single undefined scalar value instead. This provides a simple mechanism for making a module threadsafe; just add \"sub CLONE_SKIP { 1 }\" at the top of the class, and \"DESTROY()\" will be now only be called once per object. Of course, if the child thread needs to make use of the objects, then a more sophisticated approach is needed. Like \"CLONE\", \"CLONE_SKIP\" is currently called with no parameters other than the invocant package name, although that may change. Similarly, to allow for future expansion, the return value should be a single 0 or 1 value.","Process Name":"perlmod","Link":"https:\/\/linux.die.net\/man\/1\/perlmod"}},{"Process":{"Description":"You can think of a module as the fundamental unit of reusable Perl code; see perlmod for details. Whenever anyone creates a chunk of Perl code that they think will be useful to the world, they register as a Perl developer at http:\/\/www.cpan.org\/modules\/04pause.html so that they can then upload their code to the CPAN . The CPAN is the Comprehensive Perl Archive Network and can be accessed at http:\/\/www.cpan.org\/ , and searched at http:\/\/search.cpan.org\/ . This documentation is for people who want to download CPAN modules and install them on their own computer. PREAMBLE First, are you sure that the module isn't already on your system? Try \"perl -MFoo -e 1\". (Replace \"Foo\" with the name of the module; for instance, \"perl -MCGI::Carp -e 1\". If you don't see an error message, you have the module. (If you do see an error message, it's still possible you have the module, but that it's not in your path, which you can display with \"perl -e \"print qq(@INC)\"\".) For the remainder of this document, we'll assume that you really honestly truly lack an installed module, but have found it on the CPAN . So now you have a file ending in .tar.gz (or, less often, .zip). You know there's a tasty module inside. There are four steps you must now take: DECOMPRESS the file UNPACK the file into a directory BUILD the module (sometimes unnecessary) INSTALL the module. Here's how to perform each step for each operating system. This is <not> a substitute for reading the README and INSTALL files that might have come with your module! Also note that these instructions are tailored for installing the module into your system's repository of Perl modules -- but you can install modules into any directory you wish. For instance, where I say \"perl Makefile.PL\", you can substitute \"perl Makefile.PL PREFIX=\/my\/perl_directory\" to install the modules into \"\/my\/perl_directory\". Then you can use the modules from your Perl programs with \"use lib \"\/my\/perl_directory\/lib\/site_perl\";\" or sometimes just \"use \"\/my\/perl_directory\";\". If you're on a system that requires superuser\/root access to install modules into the directories you see when you type \"perl -e \"print qq(@INC)\"\", you'll want to install them into a local directory (such as your home directory) and use this approach. \u2022 If you're on a Unix or Unix-like system, You can use Andreas Koenig's CPAN module ( http:\/\/www.cpan.org\/modules\/by-module\/CPAN ) to automate the following steps, from DECOMPRESS through INSTALL . A. DECOMPRESS Decompress the file with \"gzip -d yourmodule.tar.gz\" You can get gzip from ftp:\/\/prep.ai.mit.edu\/pub\/gnu\/ Or, you can combine this step with the next to save disk space: gzip -dc yourmodule.tar.gz | tar -xof - B. UNPACK Unpack the result with \"tar -xof yourmodule.tar\" C. BUILD Go into the newly-created directory and type: perl Makefile.PL\nmake test or perl Makefile.PL PREFIX=\/my\/perl_directory to install it locally. (Remember that if you do this, you'll have to put \"use lib \"\/my\/perl_directory\";\" near the top of the program that is to use this module. D. INSTALL While still in that directory, type: make install Make sure you have the appropriate permissions to install the module in your Perl 5 library directory. Often, you'll need to be root. That's all you need to do on Unix systems with dynamic linking. Most Unix systems have dynamic linking -- if yours doesn't, or if for another reason you have a statically-linked perl, and the module requires compilation, you'll need to build a new Perl binary that includes the module. Again, you'll probably need to be root. \u2022 If you're running ActivePerl (Win95\/98\/2K\/NT\/XP, Linux, Solaris) First, type \"ppm\" from a shell and see whether ActiveState's PPM repository has your module. If so, you can install it with \"ppm\" and you won't have to bother with any of the other steps here. You might be able to use the CPAN instructions from the \"Unix or Linux\" section above as well; give it a try. Otherwise, you'll have to follow the steps below. A. DECOMPRESS You can use the shareware Winzip ( http:\/\/www.winzip.com ) to decompress and unpack modules. B. UNPACK If you used WinZip, this was already done for you. C. BUILD You'll need the \"nmake\" utility, available at http:\/\/download.microsoft.com\/download\/vc15\/Patch\/1.52\/W95\/EN-US\/nmake15.exe or dmake, available on CPAN . http:\/\/search.cpan.org\/dist\/dmake\/ Does the module require compilation (i.e. does it have files that end in .xs, .c, .h, .y, .cc, .cxx, or .C)? If it does, life is now officially tough for you, because you have to compile the module yourself -- no easy feat on Windows. You'll need a compiler such as Visual C ++ . Alternatively, you can download a pre-built PPM package from ActiveState. http:\/\/aspn.activestate.com\/ASPN\/Downloads\/ActivePerl\/PPM\/ Go into the newly-created directory and type:    perl Makefile.PL\n   nmake test\n\nD. INSTALL While still in that directory, type: nmake install \u2022 If you're using a Macintosh with \"Classic\" MacOS and MacPerl, A. DECOMPRESS First, make sure you have the latest cpan-mac distribution ( http:\/\/www.cpan.org\/authors\/id\/CNANDOR\/ ), which has utilities for doing all of the steps. Read the cpan-mac directions carefully and install it. If you choose not to use cpan-mac for some reason, there are alternatives listed here. After installing cpan-mac, drop the module archive on the untarzipme droplet, which will decompress and unpack for you. Or, you can either use the shareware StuffIt Expander program ( http:\/\/www.aladdinsys.com\/expander\/ ) in combination with DropStuff with Expander Enhancer ( http:\/\/www.aladdinsys.com\/dropstuff\/ ) or the freeware MacGzip program ( http:\/\/persephone.cps.unizar.es\/general\/gente\/spd\/gzip\/gzip.html ). B. UNPACK If you're using untarzipme or StuffIt, the archive should be extracted now. Or, you can use the freeware suntar or Tar ( http:\/\/hyperarchive.lcs.mit.edu\/HyperArchive\/Archive\/cmp\/ ). C. BUILD Check the contents of the distribution. Read the module's documentation, looking for reasons why you might have trouble using it with MacPerl. Look for .xs and .c files, which normally denote that the distribution must be compiled, and you cannot install it \"out of the box.\" (See \" PORTABILITY \".) If a module does not work on MacPerl but should, or needs to be compiled, see if the module exists already as a port on the MacPerl Module Porters site ( http:\/\/pudge.net\/mmp\/ ). For more information on doing XS with MacPerl yourself, see Arved Sandstrom's XS tutorial ( http:\/\/macperl.com\/depts\/Tutorials\/ ), and then consider uploading your binary to the CPAN and registering it on the MMP site. D. INSTALL If you are using cpan-mac, just drop the folder on the installme droplet, and use the module. Or, if you aren't using cpan-mac, do some manual labor. Make sure the newlines for the modules are in Mac format, not Unix format. If they are not then you might have decompressed them incorrectly. Check your decompression and unpacking utilities settings to make sure they are translating text files properly. As a last resort, you can use the perl one-liner: perl -i.bak -pe 's\/(?:\\015)?\\012\/\\015\/g' <filenames> on the source files. Then move the files (probably just the .pm files, though there may be some additional ones, too; check the module documentation) to their final destination: This will most likely be in \"$ENV{MACPERL}site_lib:\" (i.e., \"HD:MacPerl folder:site_lib:\"). You can add new paths to the default @INC in the Preferences menu item in the MacPerl application (\"$ENV{MACPERL}site_lib:\" is added automagically). Create whatever directory structures are required (i.e., for \"Some::Module\", create \"$ENV{MACPERL}site_lib:Some:\" and put \"Module.pm\" in that directory). Then run the following script (or something like it): #!perl -w\nuse AutoSplit;\nmy $dir = \"${MACPERL}site_perl\";\nautosplit(\"$dir:Some:Module.pm\", \"$dir:auto\", 0, 1, 1); \u2022 If you're on the DJGPP port of DOS , A. DECOMPRESS djtarx ( ftp:\/\/ftp.simtel.net\/pub\/simtelnet\/gnu\/djgpp\/v2\/ ) will both uncompress and unpack. B. UNPACK See above. C. BUILD Go into the newly-created directory and type: perl Makefile.PL\nmake test You will need the packages mentioned in README .dos in the Perl distribution. D. INSTALL While still in that directory, type: make install You will need the packages mentioned in README .dos in the Perl distribution. \u2022 If you're on OS\/2 , Get the EMX development suite and gzip\/tar, from either Hobbes ( http:\/\/hobbes.nmsu.edu ) or Leo ( http:\/\/www.leo.org ), and then follow the instructions for Unix. \u2022 If you're on VMS , When downloading from CPAN , save your file with a \".tgz\" extension instead of \".tar.gz\". All other periods in the filename should be replaced with underscores. For example, \"Your-Module-1.33.tar.gz\" should be downloaded as \"Your-Module-1_33.tgz\". A. DECOMPRESS Type gzip -d Your-Module.tgz or, for zipped modules, type unzip Your-Module.zip Executables for gzip, zip, and VMStar: http:\/\/www.openvms.digital.com\/freeware\/\nhttp:\/\/www.crinoid.com\/utils\/ and their source code: http:\/\/www.fsf.org\/order\/ftp.html Note that GNU 's gzip\/gunzip is not the same as Info-ZIP's zip\/unzip package. The former is a simple compression tool; the latter permits creation of multi-file archives. B. UNPACK If you're using VMStar: VMStar xf Your-Module.tar Or, if you're fond of VMS command syntax: tar\/extract\/verbose Your_Module.tar C. BUILD Make sure you have MMS (from Digital) or the freeware MMK ( available from MadGoat at http:\/\/www.madgoat.com ). Then type this to create the DESCRIP .MMS for the module: perl Makefile.PL Now you're ready to build: mms test Substitute \"mmk\" for \"mms\" above if you're using MMK . D. INSTALL Type mms install Substitute \"mmk\" for \"mms\" above if you're using MMK . \u2022 If you're on MVS , Introduce the .tar.gz file into an HFS as binary; don't translate from ASCII to EBCDIC . A. DECOMPRESS Decompress the file with \"gzip -d yourmodule.tar.gz\" You can get gzip from http:\/\/www.s390.ibm.com\/products\/oe\/bpxqp1.html B. UNPACK Unpack the result with pax -o to=IBM-1047,from=ISO8859-1 -r < yourmodule.tar The BUILD and INSTALL steps are identical to those for Unix. Some modules generate Makefiles that work better with GNU make, which is available from http:\/\/www.mks.com\/s390\/gnu\/","Process Name":"perlmodinstall","Link":"https:\/\/linux.die.net\/man\/1\/perlmodinstall"}},{"Process":{"Description":"","Process Name":"perlmodlib","Link":"https:\/\/linux.die.net\/man\/1\/perlmodlib"}},{"Process":{"Description":"","Process Name":"perlmodstyle","Link":"https:\/\/linux.die.net\/man\/1\/perlmodstyle"}},{"Process":{"Description":"","Process Name":"perlmpeix","Link":"https:\/\/linux.die.net\/man\/1\/perlmpeix"}},{"Process":{"Description":"As of Perl 5.10.1 there is a new interface for plugging and using method resolution orders other than the default (linear depth first search). The C3 method resolution order added in 5.10.0 has been re-implemented as a plugin, without changing its Perl-space interface. Each plugin should register itself with \"Perl_mro_register\" by providing the following structure struct mro_alg {\n    AV *(*resolve)(pTHX_ HV *stash, U32 level);\n    const char *name;\n    U16 length;\n    U16 kflags;\n    U32 hash;\n}; resolve Pointer to the linearisation function, described below. name Name of the MRO , either in ISO-8859-1 or UTF-8 . length Length of the name. kflags If the name is given in UTF-8 , set this to \"HVhek_UTF8\". The value is passed direct as the parameter kflags to \"hv_common()\". hash A precomputed hash value for the MRO 's name, or 0.","Process Name":"perlmroapi","Link":"https:\/\/linux.die.net\/man\/1\/perlmroapi"}},{"Process":{"Description":"This file gives instructions for building Perl 5.7 and above, and also Perl modules for NetWare. Before you start, you may want to read the README file found in the top level directory into which the Perl source code distribution was extracted. Make sure you read and understand the terms under which the software is being distributed.","Process Name":"perlnetware","Link":"https:\/\/linux.die.net\/man\/1\/perlnetware"}},{"Process":{"Description":"This document gives you some suggestions about how to go about writing Perl modules, preparing them for distribution, and making them available via CPAN . One of the things that makes Perl really powerful is the fact that Perl hackers tend to want to share the solutions to problems they've faced, so you and I don't have to battle with the same problem again. The main way they do this is by abstracting the solution into a Perl module. If you don't know what one of these is, the rest of this document isn't going to be much use to you. You're also missing out on an awful lot of useful code; consider having a look at perlmod, perlmodlib and perlmodinstall before coming back here. When you've found that there isn't a module available for what you're trying to do, and you've had to write the code yourself, consider packaging up the solution into a module and uploading it to CPAN so that others can benefit. Warning We're going to primarily concentrate on Perl-only modules here, rather than XS modules. XS modules serve a rather different purpose, and you should consider different things before distributing them - the popularity of the library you are gluing, the portability to other operating systems, and so on. However, the notes on preparing the Perl side of the module and packaging and distributing it will apply equally well to an XS module as a pure-Perl one. What should I make into a module? You should make a module out of any code that you think is going to be useful to others. Anything that's likely to fill a hole in the communal library and which someone else can slot directly into their program. Any part of your code which you can isolate and extract and plug into something else is a likely candidate. Let's take an example. Suppose you're reading in data from a local format into a hash-of-hashes in Perl, turning that into a tree, walking the tree and then piping each node to an Acme Transmogrifier Server. Now, quite a few people have the Acme Transmogrifier, and you've had to write something to talk the protocol from scratch - you'd almost certainly want to make that into a module. The level at which you pitch it is up to you: you might want protocol-level modules analogous to Net::SMTP which then talk to higher level modules analogous to Mail::Send. The choice is yours, but you do want to get a module out for that server protocol. Nobody else on the planet is going to talk your local data format, so we can ignore that. But what about the thing in the middle? Building tree structures from Perl variables and then traversing them is a nice, general problem, and if nobody's already written a module that does that, you might want to modularise that code too. So hopefully you've now got a few ideas about what's good to modularise. Let's now see how it's done. Step-by-step: Preparing the ground Before we even start scraping out the code, there are a few things we'll want to do in advance. Look around Dig into a bunch of modules to see how they're written. I'd suggest starting with Text::Tabs, since it's in the standard library and is nice and simple, and then looking at something a little more complex like File::Copy. For object oriented code, \"WWW::Mechanize\" or the \"Email::*\" modules provide some good examples. These should give you an overall feel for how modules are laid out and written. Check it's new There are a lot of modules on CPAN , and it's easy to miss one that's similar to what you're planning on contributing. Have a good plough through the < http:\/\/search.cpan.org> and make sure you're not the one reinventing the wheel! Discuss the need You might love it. You might feel that everyone else needs it. But there might not actually be any real demand for it out there. If you're unsure about the demand your module will have, consider sending out feelers on the \"comp.lang.perl.modules\" newsgroup, or as a last resort, ask the modules list at \"modules@perl.org\". Remember that this is a closed list with a very long turn-around time - be prepared to wait a good while for a response from them. Choose a name Perl modules included on CPAN have a naming hierarchy you should try to fit in with. See perlmodlib for more details on how this works, and browse around CPAN and the modules list to get a feel of it. At the very least, remember this: modules should be title capitalised, (This::Thing) fit in with a category, and explain their purpose succinctly. Check again While you're doing that, make really sure you haven't missed a module similar to the one you're about to write. When you've got your name sorted out and you're sure that your module is wanted and not currently available, it's time to start coding. Step-by-step: Making the module Start with module-starter or h2xs The module-starter utility is distributed as part of the Module::Starter CPAN package. It creates a directory with stubs of all the necessary files to start a new module, according to recent \"best practice\" for module development, and is invoked from the command line, thus: module-starter --module=Foo::Bar \\\n   --author=\"Your Name\" --email=yourname@cpan.org If you do not wish to install the Module::Starter package from CPAN , h2xs is an older tool, originally intended for the development of XS modules, which comes packaged with the Perl distribution. A typical invocation of h2xs for a pure Perl module is: h2xs -AX --skip-exporter --use-new-tests -n Foo::Bar The \"-A\" omits the Autoloader code, \"-X\" omits XS elements, \"--skip-exporter\" omits the Exporter code, \"--use-new-tests\" sets up a modern testing environment, and \"-n\" specifies the name of the module. Use strict and warnings A module's code has to be warning and strict-clean, since you can't guarantee the conditions that it'll be used under. Besides, you wouldn't want to distribute code that wasn't warning or strict-clean anyway, right? Use Carp The Carp module allows you to present your error messages from the caller's perspective; this gives you a way to signal a problem with the caller and not your module. For instance, if you say this: warn \"No hostname given\"; the user will see something like this: No hostname given at \/usr\/local\/lib\/perl5\/site_perl\/5.6.0\/Net\/Acme.pm\nline 123. which looks like your module is doing something wrong. Instead, you want to put the blame on the user, and say this: No hostname given at bad_code, line 10. You do this by using Carp and replacing your \"warn\"s with \"carp\"s. If you need to \"die\", say \"croak\" instead. However, keep \"warn\" and \"die\" in place for your sanity checks - where it really is your module at fault. Use Exporter - wisely! Exporter gives you a standard way of exporting symbols and subroutines from your module into the caller's namespace. For instance, saying \"use Net::Acme qw(&frob)\" would import the \"frob\" subroutine. The package variable @EXPORT will determine which symbols will get exported when the caller simply says \"use Net::Acme\" - you will hardly ever want to put anything in there. @EXPORT_OK, on the other hand, specifies which symbols you're willing to export. If you do want to export a bunch of symbols, use the %EXPORT_TAGS and define a standard export set - look at Exporter for more details. Use plain old documentation The work isn't over until the paperwork is done, and you're going to need to put in some time writing some documentation for your module. \"module-starter\" or \"h2xs\" will provide a stub for you to fill in; if you're not sure about the format, look at perlpod for an introduction. Provide a good synopsis of how your module is used in code, a description, and then notes on the syntax and function of the individual subroutines or methods. Use Perl comments for developer notes and POD for end-user notes. Write tests You're encouraged to create self-tests for your module to ensure it's working as intended on the myriad platforms Perl supports; if you upload your module to CPAN , a host of testers will build your module and send you the results of the tests. Again, \"module-starter\" and \"h2xs\" provide a test framework which you can extend - you should do something more than just checking your module will compile. Test::Simple and Test::More are good places to start when writing a test suite. Write the README If you're uploading to CPAN , the automated gremlins will extract the README file and place that in your CPAN directory. It'll also appear in the main by-module and by-category directories if you make it onto the modules list. It's a good idea to put here what the module actually does in detail, and the user-visible changes since the last release. Step-by-step: Distributing your module Get a CPAN user ID Every developer publishing modules on CPAN needs a CPAN ID . Visit \"http:\/\/pause.perl.org\/\", select \"Request PAUSE Account\", and wait for your request to be approved by the PAUSE administrators. \"perl Makefile.PL; make test; make dist\" Once again, \"module-starter\" or \"h2xs\" has done all the work for you. They produce the standard \"Makefile.PL\" you see when you download and install modules, and this produces a Makefile with a \"dist\" target. Once you've ensured that your module passes its own tests - always a good thing to make sure - you can \"make dist\", and the Makefile will hopefully produce you a nice tarball of your module, ready for upload. Upload the tarball The email you got when you received your CPAN ID will tell you how to log in to PAUSE , the Perl Authors Upload SErver. From the menus there, you can upload your module to CPAN . Announce to the modules list Once uploaded, it'll sit unnoticed in your author directory. If you want it connected to the rest of the CPAN , you'll need to go to \"Register Namespace\" on PAUSE . Once registered, your module will appear in the by-module and by-category listings on CPAN . Announce to clpa If you have a burning desire to tell the world about your release, post an announcement to the moderated \"comp.lang.perl.announce\" newsgroup. Fix bugs! Once you start accumulating users, they'll send you bug reports. If you're lucky, they'll even send you patches. Welcome to the joys of maintaining a software project...","Process Name":"perlnewmod","Link":"https:\/\/linux.die.net\/man\/1\/perlnewmod"}},{"Process":{"Description":"This document describes how Perl internally handles numeric values. Perl's operator overloading facility is completely ignored here. Operator overloading allows user-defined behaviors for numbers, such as operations over arbitrarily large integers, floating points numbers with arbitrary precision, operations over \"exotic\" numbers such as modular arithmetic or p-adic arithmetic, and so on. See overload for details.","Process Name":"perlnumber","Link":"https:\/\/linux.die.net\/man\/1\/perlnumber"}},{"Process":{"Description":"First you need to understand what references are in Perl. See perlref for that. Second, if you still find the following reference work too complicated, a tutorial on object-oriented programming in Perl can be found in perltoot and perltooc. If you're still with us, then here are three very simple definitions that you should find reassuring. 1. An object is simply a reference that happens to know which class it belongs to. 2. A class is simply a package that happens to provide methods to deal with object references. 3. A method is simply a subroutine that expects an object reference (or a package name, for class methods) as the first argument. We'll cover these points now in more depth. An Object is Simply a Reference Unlike say C ++ , Perl doesn't provide any special syntax for constructors. A constructor is merely a subroutine that returns a reference to something \"blessed\" into a class, generally the class that the subroutine is defined in. Here is a typical constructor: package Critter;\nsub new { bless {} } That word \"new\" isn't special. You could have written a construct this way, too: package Critter;\nsub spawn { bless {} } This might even be preferable, because the C ++ programmers won't be tricked into thinking that \"new\" works in Perl as it does in C ++ . It doesn't. We recommend that you name your constructors whatever makes sense in the context of the problem you're solving. For example, constructors in the Tk extension to Perl are named after the widgets they create. One thing that's different about Perl constructors compared with those in C ++ is that in Perl, they have to allocate their own memory. (The other things is that they don't automatically call overridden base-class constructors.) The \"{}\" allocates an anonymous hash containing no key\/value pairs, and returns it The bless() takes that reference and tells the object it references that it's now a Critter, and returns the reference. This is for convenience, because the referenced object itself knows that it has been blessed, and the reference to it could have been returned directly, like this: sub new {\n    my $self = {};\n    bless $self;\n    return $self;\n} You often see such a thing in more complicated constructors that wish to call methods in the class as part of the construction: sub new {\n    my $self = {};\n    bless $self;\n    $self->initialize();\n    return $self;\n} If you care about inheritance (and you should; see \"Modules: Creation, Use, and Abuse\" in perlmodlib), then you want to use the two-arg form of bless so that your constructors may be inherited: sub new {\n    my $class = shift;\n    my $self = {};\n    bless $self, $class;\n    $self->initialize();\n    return $self;\n} Or if you expect people to call not just \"CLASS->new()\" but also \"$obj->new()\", then use something like the following. (Note that using this to call new() on an instance does not automatically perform any copying. If you want a shallow or deep copy of an object, you'll have to specifically allow for that.) The initialize() method used will be of whatever $class we blessed the object into: sub new {\n    my $this = shift;\n    my $class = ref($this) || $this;\n    my $self = {};\n    bless $self, $class;\n    $self->initialize();\n    return $self;\n} Within the class package, the methods will typically deal with the reference as an ordinary reference. Outside the class package, the reference is generally treated as an opaque value that may be accessed only through the class's methods. Although a constructor can in theory re-bless a referenced object currently belonging to another class, this is almost certainly going to get you into trouble. The new class is responsible for all cleanup later. The previous blessing is forgotten, as an object may belong to only one class at a time. (Although of course it's free to inherit methods from many classes.) If you find yourself having to do this, the parent class is probably misbehaving, though. A clarification: Perl objects are blessed. References are not. Objects know which package they belong to. References do not. The bless() function uses the reference to find the object. Consider the following example: $a = {};\n$b = $a;\nbless $a, BLAH;\nprint \"\\$b is a \", ref($b), \"\\n\"; This reports $b as being a BLAH , so obviously bless() operated on the object and not on the reference. A Class is Simply a Package Unlike say C ++ , Perl doesn't provide any special syntax for class definitions. You use a package as a class by putting method definitions into the class. There is a special array within each package called @ISA, which says where else to look for a method if you can't find it in the current package. This is how Perl implements inheritance. Each element of the @ISA array is just the name of another package that happens to be a class package. The classes are searched for missing methods in depth-first, left-to-right order by default (see mro for alternative search order and other in-depth information). The classes accessible through @ISA are known as base classes of the current class. All classes implicitly inherit from class \"UNIVERSAL\" as their last base class. Several commonly used methods are automatically supplied in the UNIVERSAL class; see \"Default UNIVERSAL methods\" or UNIVERSAL for more details. If a missing method is found in a base class, it is cached in the current class for efficiency. Changing @ISA or defining new subroutines invalidates the cache and causes Perl to do the lookup again. If neither the current class, its named base classes, nor the UNIVERSAL class contains the requested method, these three places are searched all over again, this time looking for a method named AUTOLOAD (). If an AUTOLOAD is found, this method is called on behalf of the missing method, setting the package global $AUTOLOAD to be the fully qualified name of the method that was intended to be called. If none of that works, Perl finally gives up and complains. If you want to stop the AUTOLOAD inheritance say simply sub AUTOLOAD; and the call will die using the name of the sub being called. Perl classes do method inheritance only. Data inheritance is left up to the class itself. By and large, this is not a problem in Perl, because most classes model the attributes of their object using an anonymous hash, which serves as its own little namespace to be carved up by the various classes that might want to do something with the object. The only problem with this is that you can't sure that you aren't using a piece of the hash that isn't already used. A reasonable workaround is to prepend your fieldname in the hash with the package name. sub bump {\n    my $self = shift;\n    $self->{ __PACKAGE__ . \".count\"}++;\n} A Method is Simply a Subroutine Unlike say C ++ , Perl doesn't provide any special syntax for method definition. (It does provide a little syntax for method invocation though. More on that later.) A method expects its first argument to be the object (reference) or package (string) it is being invoked on. There are two ways of calling methods, which we'll call class methods and instance methods. A class method expects a class name as the first argument. It provides functionality for the class as a whole, not for any individual object belonging to the class. Constructors are often class methods, but see perltoot and perltooc for alternatives. Many class methods simply ignore their first argument, because they already know what package they're in and don't care what package they were invoked via. (These aren't necessarily the same, because class methods follow the inheritance tree just like ordinary instance methods.) Another typical use for class methods is to look up an object by name: sub find {\n    my ($class, $name) = @_;\n    $objtable{$name};\n} An instance method expects an object reference as its first argument. Typically it shifts the first argument into a \"self\" or \"this\" variable, and then uses that as an ordinary reference. sub display {\n    my $self = shift;\n    my @keys = @_ ? @_ : sort keys %$self;\n    foreach $key (@keys) {\n        print \"\\t$key => $self->{$key}\\n\";\n    }\n} Method Invocation For various historical and other reasons, Perl offers two equivalent ways to write a method call. The simpler and more common way is to use the arrow notation: my $fred = Critter->find(\"Fred\");\n$fred->display(\"Height\", \"Weight\"); You should already be familiar with the use of the \"->\" operator with references. In fact, since $fred above is a reference to an object, you could think of the method call as just another form of dereferencing. Whatever is on the left side of the arrow, whether a reference or a class name, is passed to the method subroutine as its first argument. So the above code is mostly equivalent to: my $fred = Critter::find(\"Critter\", \"Fred\");\nCritter::display($fred, \"Height\", \"Weight\"); How does Perl know which package the subroutine is in? By looking at the left side of the arrow, which must be either a package name or a reference to an object, i.e. something that has been blessed to a package. Either way, that's the package where Perl starts looking. If that package has no subroutine with that name, Perl starts looking for it in any base classes of that package, and so on. If you need to, you can force Perl to start looking in some other package: my $barney = MyCritter->Critter::find(\"Barney\");\n$barney->Critter::display(\"Height\", \"Weight\"); Here \"MyCritter\" is presumably a subclass of \"Critter\" that defines its own versions of find() and display(). We haven't specified what those methods do, but that doesn't matter above since we've forced Perl to start looking for the subroutines in \"Critter\". As a special case of the above, you may use the \"SUPER\" pseudo-class to tell Perl to start looking for the method in the packages named in the current class's @ISA list. package MyCritter;\nuse base 'Critter';    # sets @MyCritter::ISA = ('Critter');\n\nsub display {\n    my ($self, @args) = @_;\n    $self->SUPER::display(\"Name\", @args);\n} It is important to note that \"SUPER\" refers to the superclass(es) of the current package and not to the superclass(es) of the object. Also, the \"SUPER\" pseudo-class can only currently be used as a modifier to a method name, but not in any of the other ways that class names are normally used, eg: something->SUPER::method(...);      # OK\nSUPER::method(...);                 # WRONG\nSUPER->method(...);                 # WRONG Instead of a class name or an object reference, you can also use any expression that returns either of those on the left side of the arrow. So the following statement is valid: Critter->find(\"Fred\")->display(\"Height\", \"Weight\"); and so is the following: my $fred = (reverse \"rettirC\")->find(reverse \"derF\"); The right side of the arrow typically is the method name, but a simple scalar variable containing either the method name or a subroutine reference can also be used. If the right side of the arrow is a scalar containing a reference to a subroutine, then this is equivalent to calling the referenced subroutine directly with the class name or object on the left side of the arrow as its first argument. No lookup is done and there is no requirement that the subroutine be defined in any package related to the class name or object on the left side of the arrow. For example, the following calls to $display are equivalent: my $display = sub { my $self = shift; ... };\n$fred->$display(\"Height\", \"Weight\");\n$display->($fred, \"Height\", \"Weight\"); Indirect Object Syntax The other way to invoke a method is by using the so-called \"indirect object\" notation. This syntax was available in Perl 4 long before objects were introduced, and is still used with filehandles like this: print STDERR \"help!!!\\n\"; The same syntax can be used to call either object or class methods. my $fred = find Critter \"Fred\";\ndisplay $fred \"Height\", \"Weight\"; Notice that there is no comma between the object or class name and the parameters. This is how Perl can tell you want an indirect method call instead of an ordinary subroutine call. But what if there are no arguments? In that case, Perl must guess what you want. Even worse, it must make that guess at compile time. Usually Perl gets it right, but when it doesn't you get a function call compiled as a method, or vice versa. This can introduce subtle bugs that are hard to detect. For example, a call to a method \"new\" in indirect notation -- as C ++ programmers are wont to make -- can be miscompiled into a subroutine call if there's already a \"new\" function in scope. You'd end up calling the current package's \"new\" as a subroutine, rather than the desired class's method. The compiler tries to cheat by remembering bareword \"require\"s, but the grief when it messes up just isn't worth the years of debugging it will take you to track down such subtle bugs. There is another problem with this syntax: the indirect object is limited to a name, a scalar variable, or a block, because it would have to do too much lookahead otherwise, just like any other postfix dereference in the language. (These are the same quirky rules as are used for the filehandle slot in functions like \"print\" and \"printf\".) This can lead to horribly confusing precedence problems, as in these next two lines: move $obj->{FIELD};                 # probably wrong!\nmove $ary[$i];                      # probably wrong! Those actually parse as the very surprising: $obj->move->{FIELD};                # Well, lookee here\n$ary->move([$i]);                   # Didn't expect this one, eh? Rather than what you might have expected: $obj->{FIELD}->move();              # You should be so lucky.\n$ary[$i]->move;                     # Yeah, sure. To get the correct behavior with indirect object syntax, you would have to use a block around the indirect object: move {$obj->{FIELD}};\nmove {$ary[$i]}; Even then, you still have the same potential problem if there happens to be a function named \"move\" in the current package. The \"->\" notation suffers from neither of these disturbing ambiguities, so we recommend you use it exclusively. However, you may still end up having to read code using the indirect object notation, so it's important to be familiar with it. Default UNIVERSAL methods The \"UNIVERSAL\" package automatically contains the following methods that are inherited by all other classes: isa( CLASS ) \"isa\" returns true if its object is blessed into a subclass of \"CLASS\" DOES ( ROLE ) \"DOES\" returns true if its object claims to perform the role \"ROLE\". By default, this is equivalent to \"isa\". can( METHOD ) \"can\" checks to see if its object has a method called \"METHOD\", if it does then a reference to the sub is returned, if it does not then \"undef\" is returned. VERSION ( [ NEED ] ) \"VERSION\" returns the version number of the class (package). If the NEED argument is given then it will check that the current version (as defined by the $VERSION variable in the given package) not less than NEED ; it will die if this is not the case. This method is called automatically by the \"VERSION\" form of \"use\". use Package 1.2 qw(some imported subs);\n# implies:\nPackage->VERSION(1.2); Destructors When the last reference to an object goes away, the object is automatically destroyed. (This may even be after you exit, if you've stored references in global variables.) If you want to capture control just before the object is freed, you may define a DESTROY method in your class. It will automatically be called at the appropriate moment, and you can do any extra cleanup you need to do. Perl passes a reference to the object under destruction as the first (and only) argument. Beware that the reference is a read-only value, and cannot be modified by manipulating $_[0] within the destructor. The object itself (i.e. the thingy the reference points to, namely \"${$_[0]}\", \"@{$_[0]}\", \"%{$_[0]}\" etc.) is not similarly constrained. Since DESTROY methods can be called at unpredictable times, it is important that you localise any global variables that the method may update. In particular, localise $@ if you use \"eval {}\" and localise $? if you use \"system\" or backticks. If you arrange to re-bless the reference before the destructor returns, perl will again call the DESTROY method for the re-blessed object after the current one returns. This can be used for clean delegation of object destruction, or for ensuring that destructors in the base classes of your choosing get called. Explicitly calling DESTROY is also possible, but is usually never needed. Do not confuse the previous discussion with how objects CONTAINED in the current one are destroyed. Such objects will be freed and destroyed automatically when the current object is freed, provided no other references to them exist elsewhere. Summary That's about all there is to it. Now you need just to go off and buy a book about object-oriented design methodology, and bang your forehead with it for the next six months or so. Two-Phased Garbage Collection For most purposes, Perl uses a fast and simple, reference-based garbage collection system. That means there's an extra dereference going on at some level, so if you haven't built your Perl executable using your C compiler's \"-O\" flag, performance will suffer. If you have built Perl with \"cc -O\", then this probably won't matter. A more serious concern is that unreachable memory with a non-zero reference count will not normally get freed. Therefore, this is a bad idea: {\n    my $a;\n    $a = \\$a;\n} Even thought $a should go away, it can't. When building recursive data structures, you'll have to break the self-reference yourself explicitly if you don't care to leak. For example, here's a self-referential node such as one might use in a sophisticated tree structure: sub new_node {\n    my $class = shift;\n    my $node  = {};\n    $node->{LEFT} = $node->{RIGHT} = $node;\n    $node->{DATA} = [ @_ ];\n    return bless $node => $class;\n} If you create nodes like that, they (currently) won't go away unless you break their self reference yourself. (In other words, this is not to be construed as a feature, and you shouldn't depend on it.) Almost. When an interpreter thread finally shuts down (usually when your program exits), then a rather costly but complete mark-and-sweep style of garbage collection is performed, and everything allocated by that thread gets destroyed. This is essential to support Perl as an embedded or a multithreadable language. For example, this program demonstrates Perl's two-phased garbage collection: #!\/usr\/bin\/perl\npackage Subtle;\n\nsub new {\n    my $test;\n    $test = \\$test;\n    warn \"CREATING \" . \\$test;\n    return bless \\$test;\n}\n\nsub DESTROY {\n    my $self = shift;\n    warn \"DESTROYING $self\";\n}\n\npackage main;\n\nwarn \"starting program\";\n{\n    my $a = Subtle->new;\n    my $b = Subtle->new;\n    $$a = 0;  # break selfref\n    warn \"leaving block\";\n}\n\nwarn \"just exited block\";\nwarn \"time to die...\";\nexit; When run as \/foo\/test, the following output is produced: starting program at \/foo\/test line 18.\nCREATING SCALAR(0x8e5b8) at \/foo\/test line 7.\nCREATING SCALAR(0x8e57c) at \/foo\/test line 7.\nleaving block at \/foo\/test line 23.\nDESTROYING Subtle=SCALAR(0x8e5b8) at \/foo\/test line 13.\njust exited block at \/foo\/test line 26.\ntime to die... at \/foo\/test line 27.\nDESTROYING Subtle=SCALAR(0x8e57c) during global destruction. Notice that \"global destruction\" bit there? That's the thread garbage collector reaching the unreachable. Objects are always destructed, even when regular refs aren't. Objects are destructed in a separate pass before ordinary refs just to prevent object destructors from using refs that have been themselves destructed. Plain refs are only garbage-collected if the destruct level is greater than 0. You can test the higher levels of global destruction by setting the PERL_DESTRUCT_LEVEL environment variable, presuming \"-DDEBUGGING\" was enabled during perl build time. See \" PERL_DESTRUCT_LEVEL \" in perlhack for more information. A more complete garbage collection strategy will be implemented at a future date. In the meantime, the best solution is to create a non-recursive container class that holds a pointer to the self-referential data structure. Define a DESTROY method for the containing object's class that manually breaks the circularities in the self-referential structure.","Process Name":"perlobj","Link":"https:\/\/linux.die.net\/man\/1\/perlobj"}},{"Process":{"Description":"Operator Precedence and Associativity Operator precedence and associativity work in Perl more or less like they do in mathematics. Operator precedence means some operators are evaluated before others. For example, in \"2 + 4 * 5\", the multiplication has higher precedence so \"4 * 5\" is evaluated first yielding \"2 + 20 == 22\" and not \"6 * 5 == 30\". Operator associativity defines what happens if a sequence of the same operators is used one after another: whether the evaluator will evaluate the left operations first or the right. For example, in \"8 - 4 - 2\", subtraction is left associative so Perl evaluates the expression left to right. \"8 - 4\" is evaluated first making the expression \"4 - 2 == 2\" and not \"8 - 2 == 6\". Perl operators have the following associativity and precedence, listed from highest precedence to lowest. Operators borrowed from C keep the same precedence relationship with each other, even where C's precedence is slightly screwy. (This makes learning Perl easier for C folks.) With very few exceptions, these all operate on scalar values only, not array values. left        terms and list operators (leftward)\nleft        ->\nnonassoc    ++ --\nright       **\nright       ! ~ \\ and unary + and -\nleft        =~ !~\nleft        * \/ % x\nleft        + - .\nleft        << >>\nnonassoc    named unary operators\nnonassoc    < > <= >= lt gt le ge\nnonassoc    == != <=> eq ne cmp ~~\nleft        &\nleft        | ^\nleft        &&\nleft        || \/\/\nnonassoc    ..  ...\nright       ?:\nright       = += -= *= etc.\nleft        , =>\nnonassoc    list operators (rightward)\nright       not\nleft        and\nleft        or xor In the following sections, these operators are covered in precedence order. Many operators can be overloaded for objects. See overload. Terms and List Operators (Leftward) A TERM has the highest precedence in Perl. They include variables, quote and quote-like operators, any expression in parentheses, and any function whose arguments are parenthesized. Actually, there aren't really functions in this sense, just list operators and unary operators behaving as functions because you put parentheses around the arguments. These are all documented in perlfunc. If any list operator (print(), etc.) or any unary operator (chdir(), etc.) is followed by a left parenthesis as the next token, the operator and arguments within parentheses are taken to be of highest precedence, just like a normal function call. In the absence of parentheses, the precedence of list operators such as \"print\", \"sort\", or \"chmod\" is either very high or very low depending on whether you are looking at the left side or the right side of the operator. For example, in @ary = (1, 3, sort 4, 2);\nprint @ary;         # prints 1324 the commas on the right of the sort are evaluated before the sort, but the commas on the left are evaluated after. In other words, list operators tend to gobble up all arguments that follow, and then act like a simple TERM with regard to the preceding expression. Be careful with parentheses: # These evaluate exit before doing the print:\nprint($foo, exit);  # Obviously not what you want.\nprint $foo, exit;   # Nor is this.\n\n# These do the print before evaluating exit:\n(print $foo), exit; # This is what you want.\nprint($foo), exit;  # Or this.\nprint ($foo), exit; # Or even this. Also note that print ($foo & 255) + 1, \"\\n\"; probably doesn't do what you expect at first glance. The parentheses enclose the argument list for \"print\" which is evaluated (printing the result of \"$foo & 255\"). Then one is added to the return value of \"print\" (usually 1). The result is something like this: 1 + 1, \"\\n\";    # Obviously not what you meant. To do what you meant properly, you must write: print(($foo & 255) + 1, \"\\n\"); See \"Named Unary Operators\" for more discussion of this. Also parsed as terms are the \"do {}\" and \"eval {}\" constructs, as well as subroutine and method calls, and the anonymous constructors \"[]\" and \"{}\". See also \"Quote and Quote-like Operators\" toward the end of this section, as well as \"I\/O Operators\". The Arrow Operator \" \"->\"\" is an infix dereference operator, just as it is in C and C ++ . If the right side is either a \"[...]\", \"{...}\", or a \"(...)\" subscript, then the left side must be either a hard or symbolic reference to an array, a hash, or a subroutine respectively. (Or technically speaking, a location capable of holding a hard reference, if it's an array or hash reference being used for assignment.) See perlreftut and perlref. Otherwise, the right side is a method name or a simple scalar variable containing either the method name or a subroutine reference, and the left side must be either an object (a blessed reference) or a class name (that is, a package name). See perlobj. Auto-increment and Auto-decrement \"++\" and \"--\" work as in C. That is, if placed before a variable, they increment or decrement the variable by one before returning the value, and if placed after, increment or decrement after returning the value. $i = 0;  $j = 0;\nprint $i++;  # prints 0\nprint ++$j;  # prints 1 Note that just as in C, Perl doesn't define when the variable is incremented or decremented. You just know it will be done sometime before or after the value is returned. This also means that modifying a variable twice in the same statement will lead to undefined behaviour. Avoid statements like: $i = $i ++;\nprint ++ $i + $i ++; Perl will not guarantee what the result of the above statements is. The auto-increment operator has a little extra builtin magic to it. If you increment a variable that is numeric, or that has ever been used in a numeric context, you get a normal increment. If, however, the variable has been used in only string contexts since it was set, and has a value that is not the empty string and matches the pattern \"\/^[a-zA-Z]*[0-9]*\\z\/\", the increment is done as a string, preserving each character within its range, with carry: print ++($foo = '99');      # prints '100'\nprint ++($foo = 'a0');      # prints 'a1'\nprint ++($foo = 'Az');      # prints 'Ba'\nprint ++($foo = 'zz');      # prints 'aaa' \"undef\" is always treated as numeric, and in particular is changed to 0 before incrementing (so that a post-increment of an undef value will return 0 rather than \"undef\"). The auto-decrement operator is not magical. Exponentiation Binary \"**\" is the exponentiation operator. It binds even more tightly than unary minus, so -2**4 is -(2**4), not (-2)**4. (This is implemented using C's pow(3) function, which actually works on doubles internally.) Symbolic Unary Operators Unary \"!\" performs logical negation, i.e., \"not\". See also \"not\" for a lower precedence version of this. Unary \"-\" performs arithmetic negation if the operand is numeric. If the operand is an identifier, a string consisting of a minus sign concatenated with the identifier is returned. Otherwise, if the string starts with a plus or minus, a string starting with the opposite sign is returned. One effect of these rules is that -bareword is equivalent to the string \"-bareword\". If, however, the string begins with a non-alphabetic character (excluding \"+\" or \"-\"), Perl will attempt to convert the string to a numeric and the arithmetic negation is performed. If the string cannot be cleanly converted to a numeric, Perl will give the warning Argument \"the string\" isn't numeric in negation (-) at .... Unary \"~\" performs bitwise negation, i.e., 1's complement. For example, \"0666 & ~027\" is 0640. (See also \"Integer Arithmetic\" and \"Bitwise String Operators\".) Note that the width of the result is platform-dependent: ~0 is 32 bits wide on a 32-bit platform, but 64 bits wide on a 64-bit platform, so if you are expecting a certain bit width, remember to use the & operator to mask off the excess bits. Unary \"+\" has no effect whatsoever, even on strings. It is useful syntactically for separating a function name from a parenthesized expression that would otherwise be interpreted as the complete list of function arguments. (See examples above under \"Terms and List Operators (Leftward)\".) Unary \"\\\" creates a reference to whatever follows it. See perlreftut and perlref. Do not confuse this behavior with the behavior of backslash within a string, although both forms do convey the notion of protecting the next thing from interpolation. Binding Operators Binary \"=~\" binds a scalar expression to a pattern match. Certain operations search or modify the string $_ by default. This operator makes that kind of operation work on some other string. The right argument is a search pattern, substitution, or transliteration. The left argument is what is supposed to be searched, substituted, or transliterated instead of the default $_. When used in scalar context, the return value generally indicates the success of the operation. Behavior in list context depends on the particular operator. See \"Regexp Quote-Like Operators\" for details and perlretut for examples using these operators. If the right argument is an expression rather than a search pattern, substitution, or transliteration, it is interpreted as a search pattern at run time. Note that this means that its contents will be interpolated twice, so '\\\\' =~ q'\\\\'; is not ok, as the regex engine will end up trying to compile the pattern \"\\\", which it will consider a syntax error. Binary \"!~\" is just like \"=~\" except the return value is negated in the logical sense. Multiplicative Operators Binary \"*\" multiplies two numbers. Binary \"\/\" divides two numbers. Binary \"%\" is the modulo operator, which computes the division remainder of its first argument with respect to its second argument. Given integer operands $a and $b: If $b is positive, then \"$a % $b\" is $a minus the largest multiple of $b less than or equal to $a. If $b is negative, then \"$a % $b\" is $a minus the smallest multiple of $b that is not less than $a (i.e. the result will be less than or equal to zero). If the operands $a and $b are floating point values and the absolute value of $b (that is \"abs($b)\") is less than \"(UV_MAX + 1)\", only the integer portion of $a and $b will be used in the operation (Note: here \"UV_MAX\" means the maximum of the unsigned integer type). If the absolute value of the right operand (\"abs($b)\") is greater than or equal to \"(UV_MAX + 1)\", \"%\" computes the floating-point remainder $r in the equation \"($r = $a - $i*$b)\" where $i is a certain integer that makes $r have the same sign as the right operand $b (not as the left operand $a like C function \"fmod()\") and the absolute value less than that of $b. Note that when \"use integer\" is in scope, \"%\" gives you direct access to the modulo operator as implemented by your C compiler. This operator is not as well defined for negative operands, but it will execute faster. Binary \"x\" is the repetition operator. In scalar context or if the left operand is not enclosed in parentheses, it returns a string consisting of the left operand repeated the number of times specified by the right operand. In list context, if the left operand is enclosed in parentheses or is a list formed by \"qw\/STRING\/\", it repeats the list. If the right operand is zero or negative, it returns an empty string or an empty list, depending on the context. print '-' x 80;             # print row of dashes\n\nprint \"\\t\" x ($tab\/8), ' ' x ($tab%8);      # tab over\n\n@ones = (1) x 80;           # a list of 80 1's\n@ones = (5) x @ones;        # set all elements to 5 Additive Operators Binary \"+\" returns the sum of two numbers. Binary \"-\" returns the difference of two numbers. Binary \".\" concatenates two strings. Shift Operators Binary \"<<\" returns the value of its left argument shifted left by the number of bits specified by the right argument. Arguments should be integers. (See also \"Integer Arithmetic\".) Binary \">>\" returns the value of its left argument shifted right by the number of bits specified by the right argument. Arguments should be integers. (See also \"Integer Arithmetic\".) Note that both \"<<\" and \">>\" in Perl are implemented directly using \"<<\" and \">>\" in C. If \"use integer\" (see \"Integer Arithmetic\") is in force then signed C integers are used, else unsigned C integers are used. Either way, the implementation isn't going to generate results larger than the size of the integer type Perl was built with (32 bits or 64 bits). The result of overflowing the range of the integers is undefined because it is undefined also in C. In other words, using 32-bit integers, \"1 << 32\" is undefined. Shifting by a negative number of bits is also undefined. Named Unary Operators The various named unary operators are treated as functions with one argument, with optional parentheses. If any list operator (print(), etc.) or any unary operator (chdir(), etc.) is followed by a left parenthesis as the next token, the operator and arguments within parentheses are taken to be of highest precedence, just like a normal function call. For example, because named unary operators are higher precedence than ||: chdir $foo    || die;       # (chdir $foo) || die\nchdir($foo)   || die;       # (chdir $foo) || die\nchdir ($foo)  || die;       # (chdir $foo) || die\nchdir +($foo) || die;       # (chdir $foo) || die but, because * is higher precedence than named operators: chdir $foo * 20;    # chdir ($foo * 20)\nchdir($foo) * 20;   # (chdir $foo) * 20\nchdir ($foo) * 20;  # (chdir $foo) * 20\nchdir +($foo) * 20; # chdir ($foo * 20)\n\nrand 10 * 20;       # rand (10 * 20)\nrand(10) * 20;      # (rand 10) * 20\nrand (10) * 20;     # (rand 10) * 20\nrand +(10) * 20;    # rand (10 * 20) Regarding precedence, the filetest operators, like \"-f\", \"-M\", etc. are treated like named unary operators, but they don't follow this functional parenthesis rule. That means, for example, that \"-f($file).\".bak\"\" is equivalent to \"-f \"$file.bak\"\". See also \"Terms and List Operators (Leftward)\". Relational Operators Binary \"<\" returns true if the left argument is numerically less than the right argument. Binary \">\" returns true if the left argument is numerically greater than the right argument. Binary \"<=\" returns true if the left argument is numerically less than or equal to the right argument. Binary \">=\" returns true if the left argument is numerically greater than or equal to the right argument. Binary \"lt\" returns true if the left argument is stringwise less than the right argument. Binary \"gt\" returns true if the left argument is stringwise greater than the right argument. Binary \"le\" returns true if the left argument is stringwise less than or equal to the right argument. Binary \"ge\" returns true if the left argument is stringwise greater than or equal to the right argument. Equality Operators Binary \"==\" returns true if the left argument is numerically equal to the right argument. Binary \"!=\" returns true if the left argument is numerically not equal to the right argument. Binary \"<=>\" returns -1, 0, or 1 depending on whether the left argument is numerically less than, equal to, or greater than the right argument. If your platform supports NaNs (not-a-numbers) as numeric values, using them with \"<=>\" returns undef. NaN is not \"<\", \"==\", \">\", \"<=\" or \">=\" anything (even NaN), so those 5 return false. NaN != NaN returns true, as does NaN != anything else. If your platform doesn't support NaNs then NaN is just a string with numeric value 0. perl -le '$a = \"NaN\"; print \"No NaN support here\" if $a == $a'\nperl -le '$a = \"NaN\"; print \"NaN support here\" if $a != $a' Binary \"eq\" returns true if the left argument is stringwise equal to the right argument. Binary \"ne\" returns true if the left argument is stringwise not equal to the right argument. Binary \"cmp\" returns -1, 0, or 1 depending on whether the left argument is stringwise less than, equal to, or greater than the right argument. Binary \"~~\" does a smart match between its arguments. Smart matching is described in \"Smart matching in detail\" in perlsyn. \"lt\", \"le\", \"ge\", \"gt\" and \"cmp\" use the collation (sort) order specified by the current locale if \"use locale\" is in effect. See perllocale. Bitwise And Binary \"&\" returns its operands ANDed together bit by bit. (See also \"Integer Arithmetic\" and \"Bitwise String Operators\".) Note that \"&\" has lower priority than relational operators, so for example the brackets are essential in a test like print \"Even\\n\" if ($x & 1) == 0; Bitwise Or and Exclusive Or Binary \"|\" returns its operands ORed together bit by bit. (See also \"Integer Arithmetic\" and \"Bitwise String Operators\".) Binary \"^\" returns its operands XORed together bit by bit. (See also \"Integer Arithmetic\" and \"Bitwise String Operators\".) Note that \"|\" and \"^\" have lower priority than relational operators, so for example the brackets are essential in a test like print \"false\\n\" if (8 | 2) != 10; C-style Logical And Binary \"&&\" performs a short-circuit logical AND operation. That is, if the left operand is false, the right operand is not even evaluated. Scalar or list context propagates down to the right operand if it is evaluated. C-style Logical Or Binary \"||\" performs a short-circuit logical OR operation. That is, if the left operand is true, the right operand is not even evaluated. Scalar or list context propagates down to the right operand if it is evaluated. C-style Logical Defined-Or Although it has no direct equivalent in C, Perl's \"\/\/\" operator is related to its C-style or. In fact, it's exactly the same as \"||\", except that it tests the left hand side's definedness instead of its truth. Thus, \"$a \/\/ $b\" is similar to \"defined($a) || $b\" (except that it returns the value of $a rather than the value of \"defined($a)\") and is exactly equivalent to \"defined($a) ? $a : $b\". This is very useful for providing default values for variables. If you actually want to test if at least one of $a and $b is defined, use \"defined($a \/\/ $b)\". The \"||\", \"\/\/\" and \"&&\" operators return the last value evaluated (unlike C's \"||\" and \"&&\", which return 0 or 1). Thus, a reasonably portable way to find out the home directory might be: $home = $ENV{'HOME'} \/\/ $ENV{'LOGDIR'} \/\/\n    (getpwuid($<))[7] \/\/ die \"You're homeless!\\n\"; In particular, this means that you shouldn't use this for selecting between two aggregates for assignment: @a = @b || @c;              # this is wrong\n@a = scalar(@b) || @c;      # really meant this\n@a = @b ? @b : @c;          # this works fine, though As more readable alternatives to \"&&\" and \"||\" when used for control flow, Perl provides the \"and\" and \"or\" operators (see below). The short-circuit behavior is identical. The precedence of \"and\" and \"or\" is much lower, however, so that you can safely use them after a list operator without the need for parentheses: unlink \"alpha\", \"beta\", \"gamma\"\n        or gripe(), next LINE; With the C-style operators that would have been written like this: unlink(\"alpha\", \"beta\", \"gamma\")\n        || (gripe(), next LINE); Using \"or\" for assignment is unlikely to do what you want; see below. Range Operators Binary \"..\" is the range operator, which is really two different operators depending on the context. In list context, it returns a list of values counting (up by ones) from the left value to the right value. If the left value is greater than the right value then it returns the empty list. The range operator is useful for writing \"foreach (1..10)\" loops and for doing slice operations on arrays. In the current implementation, no temporary array is created when the range operator is used as the expression in \"foreach\" loops, but older versions of Perl might burn a lot of memory when you write something like this: for (1 .. 1_000_000) {\n    # code\n} The range operator also works on strings, using the magical auto-increment, see below. In scalar context, \"..\" returns a boolean value. The operator is bistable, like a flip-flop, and emulates the line-range (comma) operator of sed, awk, and various editors. Each \"..\" operator maintains its own boolean state. It is false as long as its left operand is false. Once the left operand is true, the range operator stays true until the right operand is true, AFTER which the range operator becomes false again. It doesn't become false till the next time the range operator is evaluated. It can test the right operand and become false on the same evaluation it became true (as in awk), but it still returns true once. If you don't want it to test the right operand till the next evaluation, as in sed, just use three dots (\"...\") instead of two. In all other regards, \"...\" behaves just like \"..\" does. The right operand is not evaluated while the operator is in the \"false\" state, and the left operand is not evaluated while the operator is in the \"true\" state. The precedence is a little lower than || and &&. The value returned is either the empty string for false, or a sequence number (beginning with 1) for true. The sequence number is reset for each range encountered. The final sequence number in a range has the string \"E0\" appended to it, which doesn't affect its numeric value, but gives you something to search for if you want to exclude the endpoint. You can exclude the beginning point by waiting for the sequence number to be greater than 1. If either operand of scalar \"..\" is a constant expression, that operand is considered true if it is equal (\"==\") to the current input line number (the $. variable). To be pedantic, the comparison is actually \"int(EXPR) == int(EXPR)\", but that is only an issue if you use a floating point expression; when implicitly using $. as described in the previous paragraph, the comparison is \"int(EXPR) == int($.)\" which is only an issue when $. is set to a floating point value and you are not reading from a file. Furthermore, \"span\" .. \"spat\" or \"2.18 .. 3.14\" will not do what you want in scalar context because each of the operands are evaluated using their integer representation. Examples: As a scalar operator: if (101 .. 200) { print; } # print 2nd hundred lines, short for\n                           #   if ($. == 101 .. $. == 200) { print; }\n\nnext LINE if (1 .. \/^$\/);  # skip header lines, short for\n                           #   next LINE if ($. == 1 .. \/^$\/);\n                           # (typically in a loop labeled LINE)\n\ns\/^\/> \/ if (\/^$\/ .. eof());  # quote body\n\n# parse mail messages\nwhile (<>) {\n    $in_header =   1  .. \/^$\/;\n    $in_body   = \/^$\/ .. eof;\n    if ($in_header) {\n        # do something\n    } else { # in body\n        # do something else\n    }\n} continue {\n    close ARGV if eof;             # reset $. each file\n} Here's a simple example to illustrate the difference between the two range operators: @lines = (\"   - Foo\",\n          \"01 - Bar\",\n          \"1  - Baz\",\n          \"   - Quux\");\n\nforeach (@lines) {\n    if (\/0\/ .. \/1\/) {\n        print \"$_\\n\";\n    }\n} This program will print only the line containing \"Bar\". If the range operator is changed to \"...\", it will also print the \"Baz\" line. And now some examples as a list operator: for (101 .. 200) { print; } # print $_ 100 times\n@foo = @foo[0 .. $#foo];    # an expensive no-op\n@foo = @foo[$#foo-4 .. $#foo];      # slice last 5 items The range operator (in list context) makes use of the magical auto-increment algorithm if the operands are strings. You can say @alphabet = ('A' .. 'Z'); to get all normal letters of the English alphabet, or $hexdigit = (0 .. 9, 'a' .. 'f')[$num & 15]; to get a hexadecimal digit, or @z2 = ('01' .. '31');  print $z2[$mday]; to get dates with leading zeros. If the final value specified is not in the sequence that the magical increment would produce, the sequence goes until the next value would be longer than the final value specified. If the initial value specified isn't part of a magical increment sequence (that is, a non-empty string matching \"\/^[a-zA-Z]*[0-9]*\\z\/\"), only the initial value will be returned. So the following will only return an alpha: use charnames 'greek';\nmy @greek_small =  (\"\\N{alpha}\" .. \"\\N{omega}\"); To get lower-case greek letters, use this instead: my @greek_small =  map { chr } ( ord(\"\\N{alpha}\") .. ord(\"\\N{omega}\") ); Because each operand is evaluated in integer form, \"2.18 .. 3.14\" will return two elements in list context. @list = (2.18 .. 3.14); # same as @list = (2 .. 3); Conditional Operator Ternary \"?:\" is the conditional operator, just as in C. It works much like an if-then-else. If the argument before the ? is true, the argument before the : is returned, otherwise the argument after the : is returned. For example: printf \"I have %d dog%s.\\n\", $n,\n        ($n == 1) ? '' : \"s\"; Scalar or list context propagates downward into the 2nd or 3rd argument, whichever is selected. $a = $ok ? $b : $c;  # get a scalar\n@a = $ok ? @b : @c;  # get an array\n$a = $ok ? @b : @c;  # oops, that's just a count! The operator may be assigned to if both the 2nd and 3rd arguments are legal lvalues (meaning that you can assign to them): ($a_or_b ? $a : $b) = $c; Because this operator produces an assignable result, using assignments without parentheses will get you in trouble. For example, this: $a % 2 ? $a += 10 : $a += 2 Really means this: (($a % 2) ? ($a += 10) : $a) += 2 Rather than this: ($a % 2) ? ($a += 10) : ($a += 2) That should probably be written more simply as: $a += ($a % 2) ? 10 : 2; Assignment Operators \"=\" is the ordinary assignment operator. Assignment operators work as in C. That is, $a += 2; is equivalent to $a = $a + 2; although without duplicating any side effects that dereferencing the lvalue might trigger, such as from tie(). Other assignment operators work similarly. The following are recognized: **=    +=    *=    &=    <<=    &&=\n       -=    \/=    |=    >>=    ||=\n       .=    %=    ^=           \/\/=\n             x= Although these are grouped by family, they all have the precedence of assignment. Unlike in C, the scalar assignment operator produces a valid lvalue. Modifying an assignment is equivalent to doing the assignment and then modifying the variable that was assigned to. This is useful for modifying a copy of something, like this: ($tmp = $global) =~ tr [A-Z] [a-z]; Likewise, ($a += 2) *= 3; is equivalent to $a += 2;\n$a *= 3; Similarly, a list assignment in list context produces the list of lvalues assigned to, and a list assignment in scalar context returns the number of elements produced by the expression on the right hand side of the assignment. Comma Operator Binary \",\" is the comma operator. In scalar context it evaluates its left argument, throws that value away, then evaluates its right argument and returns that value. This is just like C's comma operator. In list context, it's just the list argument separator, and inserts both its arguments into the list. These arguments are also evaluated from left to right. The \"=>\" operator is a synonym for the comma except that it causes its left operand to be interpreted as a string if it begins with a letter or underscore and is composed only of letters, digits and underscores. This includes operands that might otherwise be interpreted as operators, constants, single number v-strings or function calls. If in doubt about this behaviour, the left operand can be quoted explicitly. Otherwise, the \"=>\" operator behaves exactly as the comma operator or list argument separator, according to context. For example: use constant FOO => \"something\";\n\nmy %h = ( FOO => 23 ); is equivalent to: my %h = (\"FOO\", 23); It is NOT : my %h = (\"something\", 23); The \"=>\" operator is helpful in documenting the correspondence between keys and values in hashes, and other paired elements in lists. %hash = ( $key => $value );\nlogin( $username => $password ); List Operators (Rightward) On the right side of a list operator, it has very low precedence, such that it controls all comma-separated expressions found there. The only operators with lower precedence are the logical operators \"and\", \"or\", and \"not\", which may be used to evaluate calls to list operators without the need for extra parentheses: open HANDLE, \"filename\"\n    or die \"Can't open: $!\\n\"; See also discussion of list operators in \"Terms and List Operators (Leftward)\". Logical Not Unary \"not\" returns the logical negation of the expression to its right. It's the equivalent of \"!\" except for the very low precedence. Logical And Binary \"and\" returns the logical conjunction of the two surrounding expressions. It's equivalent to && except for the very low precedence. This means that it short-circuits: i.e., the right expression is evaluated only if the left expression is true. Logical or, Defined or, and Exclusive Or Binary \"or\" returns the logical disjunction of the two surrounding expressions. It's equivalent to || except for the very low precedence. This makes it useful for control flow print FH $data              or die \"Can't write to FH: $!\"; This means that it short-circuits: i.e., the right expression is evaluated only if the left expression is false. Due to its precedence, you should probably avoid using this for assignment, only for control flow. $a = $b or $c;              # bug: this is wrong\n($a = $b) or $c;            # really means this\n$a = $b || $c;              # better written this way However, when it's a list-context assignment and you're trying to use \"||\" for control flow, you probably need \"or\" so that the assignment takes higher precedence. @info = stat($file) || die;     # oops, scalar sense of stat!\n@info = stat($file) or die;     # better, now @info gets its due Then again, you could always use parentheses. Binary \"xor\" returns the exclusive-OR of the two surrounding expressions. It cannot short circuit, of course. C Operators Missing From Perl Here is what C has that Perl doesn't: unary & Address-of operator. (But see the \"\\\" operator for taking a reference.) unary * Dereference-address operator. (Perl's prefix dereferencing operators are typed: $, @, %, and &.) ( TYPE ) Type-casting operator. Quote and Quote-like Operators While we usually think of quotes as literal values, in Perl they function as operators, providing various kinds of interpolating and pattern matching capabilities. Perl provides customary quote characters for these behaviors, but also provides a way for you to choose your quote character for any of them. In the following table, a \"{}\" represents any pair of delimiters you choose. Customary  Generic        Meaning        Interpolates\n    ''       q{}          Literal             no\n    \"\"      qq{}          Literal             yes\n    ``      qx{}          Command             yes*\n            qw{}         Word list            no\n    \/\/       m{}       Pattern match          yes*\n            qr{}          Pattern             yes*\n             s{}{}      Substitution          yes*\n            tr{}{}    Transliteration         no (but see below)\n    <<EOF                 here-doc            yes*\n\n    * unless the delimiter is ''. Non-bracketing delimiters use the same character fore and aft, but the four sorts of brackets (round, angle, square, curly) will all nest, which means that q{foo{bar}baz} is the same as 'foo{bar}baz' Note, however, that this does not always work for quoting Perl code: $s = q{ if($a eq \"}\") ... }; # WRONG is a syntax error. The \"Text::Balanced\" module (from CPAN , and starting from Perl 5.8 part of the standard distribution) is able to do this properly. There can be whitespace between the operator and the quoting characters, except when \"#\" is being used as the quoting character. \"q#foo#\" is parsed as the string \"foo\", while \"q #foo#\" is the operator \"q\" followed by a comment. Its argument will be taken from the next line. This allows you to write: s {foo}  # Replace foo\n  {bar}  # with bar. The following escape sequences are available in constructs that interpolate and in transliterations. \\t          tab             (HT, TAB)\n\\n          newline         (NL)\n\\r          return          (CR)\n\\f          form feed       (FF)\n\\b          backspace       (BS)\n\\a          alarm (bell)    (BEL)\n\\e          escape          (ESC)\n\\033        octal char      (example: ESC)\n\\x1b        hex char        (example: ESC)\n\\x{263a}    wide hex char   (example: SMILEY)\n\\c[         control char    (example: ESC)\n\\N{name}    named Unicode character The character following \"\\c\" is mapped to some other character by converting letters to upper case and then (on ASCII systems) by inverting the 7th bit (0x40). The most interesting range is from '@' to '_' (0x40 through 0x5F), resulting in a control character from 0x00 through 0x1F. A '?' maps to the DEL character. On EBCDIC systems only '@', the letters, '[', '\\', ']', '^', '_' and '?' will work, resulting in 0x00 through 0x1F and 0x7F. NOTE : Unlike C and other languages, Perl has no \\v escape sequence for the vertical tab ( VT - ASCII 11), but you may use \"\\ck\" or \"\\x0b\". The following escape sequences are available in constructs that interpolate but not in transliterations. \\l          lowercase next char\n\\u          uppercase next char\n\\L          lowercase till \\E\n\\U          uppercase till \\E\n\\E          end case modification\n\\Q          quote non-word characters till \\E If \"use locale\" is in effect, the case map used by \"\\l\", \"\\L\", \"\\u\" and \"\\U\" is taken from the current locale. See perllocale. If Unicode (for example, \"\\N{}\" or wide hex characters of 0x100 or beyond) is being used, the case map used by \"\\l\", \"\\L\", \"\\u\" and \"\\U\" is as defined by Unicode. For documentation of \"\\N{name}\", see charnames. All systems use the virtual \"\\n\" to represent a line terminator, called a \"newline\". There is no such thing as an unvarying, physical newline character. It is only an illusion that the operating system, device drivers, C libraries, and Perl all conspire to preserve. Not all systems read \"\\r\" as ASCII CR and \"\\n\" as ASCII LF . For example, on a Mac, these are reversed, and on systems without line terminator, printing \"\\n\" may emit no actual data. In general, use \"\\n\" when you mean a \"newline\" for your system, but use the literal ASCII when you need an exact character. For example, most networking protocols expect and prefer a CR+LF (\"\\015\\012\" or \"\\cM\\cJ\") for line terminators, and although they often accept just \"\\012\", they seldom tolerate just \"\\015\". If you get in the habit of using \"\\n\" for networking, you may be burned some day. For constructs that do interpolate, variables beginning with \"\"$\"\" or \"\"@\"\" are interpolated. Subscripted variables such as $a[3] or \"$href->{key}[0]\" are also interpolated, as are array and hash slices. But method calls such as \"$obj->meth\" are not. Interpolating an array or slice interpolates the elements in order, separated by the value of $\", so is equivalent to interpolating \"join $\", @array\". \"Punctuation\" arrays such as \"@*\" are only interpolated if the name is enclosed in braces \"@{*}\", but special arrays @_, \"@+\", and \"@-\" are interpolated, even without braces. You cannot include a literal \"$\" or \"@\" within a \"\\Q\" sequence. An unescaped \"$\" or \"@\" interpolates the corresponding variable, while escaping will cause the literal string \"\\$\" to be inserted. You'll need to write something like \"m\/\\Quser\\E\\@\\Qhost\/\". Patterns are subject to an additional level of interpretation as a regular expression. This is done as a second pass, after variables are interpolated, so that regular expressions may be incorporated into the pattern from the variables. If this is not what you want, use \"\\Q\" to interpolate a variable literally. Apart from the behavior described above, Perl does not expand multiple levels of interpolation. In particular, contrary to the expectations of shell programmers, back-quotes do NOT interpolate within double quotes, nor do single quotes impede evaluation of variables when used within double quotes. Regexp Quote-Like Operators Here are the quote-like operators that apply to pattern matching and related activities. qr\/STRING\/msixpo This operator quotes (and possibly compiles) its STRING as a regular expression. STRING is interpolated the same way as PATTERN in \"m\/PATTERN\/\". If \"'\" is used as the delimiter, no interpolation is done. Returns a Perl value which may be used instead of the corresponding \"\/STRING\/msixpo\" expression. The returned value is a normalized version of the original pattern. It magically differs from a string containing the same characters: \"ref(qr\/x\/)\" returns \"Regexp\", even though dereferencing the result returns undef. For example, $rex = qr\/my.STRING\/is;\nprint $rex;                 # prints (?si-xm:my.STRING)\ns\/$rex\/foo\/; is equivalent to s\/my.STRING\/foo\/is; The result may be used as a subpattern in a match: $re = qr\/$pattern\/;\n$string =~ \/foo${re}bar\/;   # can be interpolated in other patterns\n$string =~ $re;             # or used standalone\n$string =~ \/$re\/;           # or this way Since Perl may compile the pattern at the moment of execution of qr() operator, using qr() may have speed advantages in some situations, notably if the result of qr() is used standalone: sub match {\n    my $patterns = shift;\n    my @compiled = map qr\/$_\/i, @$patterns;\n    grep {\n        my $success = 0;\n        foreach my $pat (@compiled) {\n            $success = 1, last if \/$pat\/;\n        }\n        $success;\n    } @_;\n} Precompilation of the pattern into an internal representation at the moment of qr() avoids a need to recompile the pattern every time a match \"\/$pat\/\" is attempted. (Perl has many other internal optimizations, but none would be triggered in the above example if we did not use qr() operator.) Options are: m   Treat string as multiple lines.\ns   Treat string as single line. (Make . match a newline)\ni   Do case-insensitive pattern matching.\nx   Use extended regular expressions.\np   When matching preserve a copy of the matched string so\n    that ${^PREMATCH}, ${^MATCH}, ${^POSTMATCH} will be defined.\no   Compile pattern only once. If a precompiled pattern is embedded in a larger pattern then the effect of 'msixp' will be propagated appropriately. The effect of the 'o' modifier has is not propagated, being restricted to those patterns explicitly using it. See perlre for additional information on valid syntax for STRING , and for a detailed look at the semantics of regular expressions. m\/PATTERN\/msixpogc \/PATTERN\/msixpogc Searches a string for a pattern match, and in scalar context returns true if it succeeds, false if it fails. If no string is specified via the \"=~\" or \"!~\" operator, the $_ string is searched. (The string specified with \"=~\" need not be an lvalue--it may be the result of an expression evaluation, but remember the \"=~\" binds rather tightly.) See also perlre. See perllocale for discussion of additional considerations that apply when \"use locale\" is in effect. Options are as described in \"qr\/\/\"; in addition, the following match process modifiers are available: g   Match globally, i.e., find all occurrences.\nc   Do not reset search position on a failed match when \/g is in effect. If \"\/\" is the delimiter then the initial \"m\" is optional. With the \"m\" you can use any pair of non-alphanumeric, non-whitespace characters as delimiters. This is particularly useful for matching path names that contain \"\/\", to avoid LTS (leaning toothpick syndrome). If \"?\" is the delimiter, then the match-only-once rule of \"?PATTERN?\" applies. If \"'\" is the delimiter, no interpolation is performed on the PATTERN . PATTERN may contain variables, which will be interpolated (and the pattern recompiled) every time the pattern search is evaluated, except for when the delimiter is a single quote. (Note that $(, $), and $| are not interpolated because they look like end-of-string tests.) If you want such a pattern to be compiled only once, add a \"\/o\" after the trailing delimiter. This avoids expensive run-time recompilations, and is useful when the value you are interpolating won't change over the life of the script. However, mentioning \"\/o\" constitutes a promise that you won't change the variables in the pattern. If you change them, Perl won't even notice. See also \"STRING\/msixpo\"\" in \"qr. The empty pattern \/\/ If the PATTERN evaluates to the empty string, the last successfully matched regular expression is used instead. In this case, only the \"g\" and \"c\" flags on the empty pattern is honoured - the other flags are taken from the original pattern. If no match has previously succeeded, this will (silently) act instead as a genuine empty pattern (which will always match). Note that it's possible to confuse Perl into thinking \"\/\/\" (the empty regex) is really \"\/\/\" (the defined-or operator). Perl is usually pretty good about this, but some pathological cases might trigger this, such as \"$a\/\/\/\" (is that \"($a) \/ (\/\/)\" or \"$a \/\/ \/\"?) and \"print $fh \/\/\" (\"print $fh(\/\/\" or \"print($fh \/\/\"?). In all of these examples, Perl will assume you meant defined-or. If you meant the empty regex, just use parentheses or spaces to disambiguate, or even prefix the empty regex with an \"m\" (so \"\/\/\" becomes \"m\/\/\"). Matching in list context If the \"\/g\" option is not used, \"m\/\/\" in list context returns a list consisting of the subexpressions matched by the parentheses in the pattern, i.e., ( $1, $2, $3...). (Note that here $1 etc. are also set, and that this differs from Perl 4's behavior.) When there are no parentheses in the pattern, the return value is the list \"(1)\" for success. With or without parentheses, an empty list is returned upon failure. Examples: open(TTY, '\/dev\/tty');\n<TTY> =~ \/^y\/i && foo();    # do foo if desired\n\nif (\/Version: *([0-9.]*)\/) { $version = $1; }\n\nnext if m#^\/usr\/spool\/uucp#;\n\n# poor man's grep\n$arg = shift;\nwhile (<>) {\n    print if \/$arg\/o;       # compile only once\n}\n\nif (($F1, $F2, $Etc) = ($foo =~ \/^(\\S+)\\s+(\\S+)\\s*(.*)\/)) This last example splits $foo into the first two words and the remainder of the line, and assigns those three fields to $F1, $F2, and $Etc. The conditional is true if any variables were assigned, i.e., if the pattern matched. The \"\/g\" modifier specifies global pattern matching--that is, matching as many times as possible within the string. How it behaves depends on the context. In list context, it returns a list of the substrings matched by any capturing parentheses in the regular expression. If there are no parentheses, it returns a list of all the matched strings, as if there were parentheses around the whole pattern. In scalar context, each execution of \"m\/\/g\" finds the next match, returning true if it matches, and false if there is no further match. The position after the last match can be read or set using the pos() function; see \"pos\" in perlfunc. A failed match normally resets the search position to the beginning of the string, but you can avoid that by adding the \"\/c\" modifier (e.g. \"m\/\/gc\"). Modifying the target string also resets the search position. \\G assertion You can intermix \"m\/\/g\" matches with \"m\/\\G...\/g\", where \"\\G\" is a zero-width assertion that matches the exact position where the previous \"m\/\/g\", if any, left off. Without the \"\/g\" modifier, the \"\\G\" assertion still anchors at pos(), but the match is of course only attempted once. Using \"\\G\" without \"\/g\" on a target string that has not previously had a \"\/g\" match applied to it is the same as using the \"\\A\" assertion to match the beginning of the string. Note also that, currently, \"\\G\" is only properly supported when anchored at the very beginning of the pattern. Examples: # list context\n($one,$five,$fifteen) = (`uptime` =~ \/(\\d+\\.\\d+)\/g);\n\n# scalar context\n$\/ = \"\";\nwhile (defined($paragraph = <>)) {\n    while ($paragraph =~ \/[a-z]['\")]*[.!?]+['\")]*\\s\/g) {\n        $sentences++;\n    }\n}\nprint \"$sentences\\n\";\n\n# using m\/\/gc with \\G\n$_ = \"ppooqppqq\";\nwhile ($i++ < 2) {\n    print \"1: '\";\n    print $1 while \/(o)\/gc; print \"', pos=\", pos, \"\\n\";\n    print \"2: '\";\n    print $1 if \/\\G(q)\/gc;  print \"', pos=\", pos, \"\\n\";\n    print \"3: '\";\n    print $1 while \/(p)\/gc; print \"', pos=\", pos, \"\\n\";\n}\nprint \"Final: '$1', pos=\",pos,\"\\n\" if \/\\G(.)\/; The last example should print: 1: 'oo', pos=4\n2: 'q', pos=5\n3: 'pp', pos=7\n1: '', pos=7\n2: 'q', pos=8\n3: '', pos=8\nFinal: 'q', pos=8 Notice that the final match matched \"q\" instead of \"p\", which a match without the \"\\G\" anchor would have done. Also note that the final match did not update \"pos\" -- \"pos\" is only updated on a \"\/g\" match. If the final match did indeed match \"p\", it's a good bet that you're running an older (pre-5.6.0) Perl. A useful idiom for \"lex\"-like scanners is \"\/\\G...\/gc\". You can combine several regexps like this to process a string part-by-part, doing different actions depending on which regexp matched. Each regexp tries to match where the previous one leaves off. $_ = <<'EOL';\n     $url = URI::URL->new( \"http:\/\/www\/\" );   die if $url eq \"xXx\";\nEOL\nLOOP:\n   {\n     print(\" digits\"),         redo LOOP if \/\\G\\d+\\b[,.;]?\\s*\/gc;\n     print(\" lowercase\"),      redo LOOP if \/\\G[a-z]+\\b[,.;]?\\s*\/gc;\n     print(\" UPPERCASE\"),      redo LOOP if \/\\G[A-Z]+\\b[,.;]?\\s*\/gc;\n     print(\" Capitalized\"),    redo LOOP if \/\\G[A-Z][a-z]+\\b[,.;]?\\s*\/gc;\n     print(\" MiXeD\"),          redo LOOP if \/\\G[A-Za-z]+\\b[,.;]?\\s*\/gc;\n     print(\" alphanumeric\"),   redo LOOP if \/\\G[A-Za-z0-9]+\\b[,.;]?\\s*\/gc;\n     print(\" line-noise\"),     redo LOOP if \/\\G[^A-Za-z0-9]+\/gc;\n     print \". That's all!\\n\";\n   } Here is the output (split into several lines): line-noise lowercase line-noise lowercase UPPERCASE line-noise\nUPPERCASE line-noise lowercase line-noise lowercase line-noise\nlowercase lowercase line-noise lowercase lowercase line-noise\nMiXeD line-noise. That's all! ?PATTERN? This is just like the \"\/pattern\/\" search, except that it matches only once between calls to the reset() operator. This is a useful optimization when you want to see only the first occurrence of something in each file of a set of files, for instance. Only \"??\" patterns local to the current package are reset. while (<>) {\n    if (?^$?) {\n                        # blank line between header and body\n    }\n} continue {\n    reset if eof;       # clear ?? status for next file\n} This usage is vaguely deprecated, which means it just might possibly be removed in some distant future version of Perl, perhaps somewhere around the year 2168. s\/PATTERN\/REPLACEMENT\/msixpogce Searches a string for a pattern, and if found, replaces that pattern with the replacement text and returns the number of substitutions made. Otherwise it returns false (specifically, the empty string). If no string is specified via the \"=~\" or \"!~\" operator, the $_ variable is searched and modified. (The string specified with \"=~\" must be scalar variable, an array element, a hash element, or an assignment to one of those, i.e., an lvalue.) If the delimiter chosen is a single quote, no interpolation is done on either the PATTERN or the REPLACEMENT . Otherwise, if the PATTERN contains a $ that looks like a variable rather than an end-of-string test, the variable will be interpolated into the pattern at run-time. If you want the pattern compiled only once the first time the variable is interpolated, use the \"\/o\" option. If the pattern evaluates to the empty string, the last successfully executed regular expression is used instead. See perlre for further explanation on these. See perllocale for discussion of additional considerations that apply when \"use locale\" is in effect. Options are as with m\/\/ with the addition of the following replacement specific options: e   Evaluate the right side as an expression.\nee  Evaluate the right side as a string then eval the result Any non-alphanumeric, non-whitespace delimiter may replace the slashes. If single quotes are used, no interpretation is done on the replacement string (the \"\/e\" modifier overrides this, however). Unlike Perl 4, Perl 5 treats backticks as normal delimiters; the replacement text is not evaluated as a command. If the PATTERN is delimited by bracketing quotes, the REPLACEMENT has its own pair of quotes, which may or may not be bracketing quotes, e.g., \"s(foo)(bar)\" or \"s<foo>\/bar\/\". A \"\/e\" will cause the replacement portion to be treated as a full-fledged Perl expression and evaluated right then and there. It is, however, syntax checked at compile-time. A second \"e\" modifier will cause the replacement portion to be \"eval\"ed before being run as a Perl expression. Examples: s\/\\bgreen\\b\/mauve\/g;                # don't change wintergreen\n\n$path =~ s|\/usr\/bin|\/usr\/local\/bin|;\n\ns\/Login: $foo\/Login: $bar\/; # run-time pattern\n\n($foo = $bar) =~ s\/this\/that\/;      # copy first, then change\n\n$count = ($paragraph =~ s\/Mister\\b\/Mr.\/g);  # get change-count\n\n$_ = 'abc123xyz';\ns\/\\d+\/$&*2\/e;               # yields 'abc246xyz'\ns\/\\d+\/sprintf(\"%5d\",$&)\/e;  # yields 'abc  246xyz'\ns\/\\w\/$& x 2\/eg;             # yields 'aabbcc  224466xxyyzz'\n\ns\/%(.)\/$percent{$1}\/g;      # change percent escapes; no \/e\ns\/%(.)\/$percent{$1} || $&\/ge;       # expr now, so \/e\ns\/^=(\\w+)\/pod($1)\/ge;       # use function call\n\n# expand variables in $_, but dynamics only, using\n# symbolic dereferencing\ns\/\\$(\\w+)\/${$1}\/g;\n\n# Add one to the value of any numbers in the string\ns\/(\\d+)\/1 + $1\/eg;\n\n# This will expand any embedded scalar variable\n# (including lexicals) in $_ : First $1 is interpolated\n# to the variable name, and then evaluated\ns\/(\\$\\w+)\/$1\/eeg;\n\n# Delete (most) C comments.\n$program =~ s {\n    \/\\*     # Match the opening delimiter.\n    .*?     # Match a minimal number of characters.\n    \\*\/     # Match the closing delimiter.\n} []gsx;\n\ns\/^\\s*(.*?)\\s*$\/$1\/;        # trim whitespace in $_, expensively\n\nfor ($variable) {           # trim whitespace in $variable, cheap\n    s\/^\\s+\/\/;\n    s\/\\s+$\/\/;\n}\n\ns\/([^ ]*) *([^ ]*)\/$2 $1\/;  # reverse 1st two fields Note the use of $ instead of \\ in the last example. Unlike sed, we use the \\< digit> form in only the left hand side. Anywhere else it's $< digit>. Occasionally, you can't use just a \"\/g\" to get all the changes to occur that you might want. Here are two common cases: # put commas in the right places in an integer\n1 while s\/(\\d)(\\d\\d\\d)(?!\\d)\/$1,$2\/g;\n\n# expand tabs to 8-column spacing\n1 while s\/\\t+\/' ' x (length($&)*8 - length($`)%8)\/e; Quote-Like Operators q\/STRING\/ ' STRING ' A single-quoted, literal string. A backslash represents a backslash unless followed by the delimiter or another backslash, in which case the delimiter or backslash is interpolated. $foo = q!I said, \"You said, 'She said it.'\"!;\n$bar = q('This is it.');\n$baz = '\\n';                # a two-character string qq\/STRING\/ \" STRING \" A double-quoted, interpolated string. $_ .= qq\n (*** The previous line contains the naughty word \"$1\".\\n)\n            if \/\\b(tcl|java|python)\\b\/i;      # :-)\n$baz = \"\\n\";                # a one-character string qx\/STRING\/ 'STRING' A string which is (possibly) interpolated and then executed as a system command with \"\/bin\/sh\" or its equivalent. Shell wildcards, pipes, and redirections will be honored. The collected standard output of the command is returned; standard error is unaffected. In scalar context, it comes back as a single (potentially multi-line) string, or undef if the command failed. In list context, returns a list of lines (however you've defined lines with $\/ or $INPUT_RECORD_SEPARATOR), or an empty list if the command failed. Because backticks do not affect standard error, use shell file descriptor syntax (assuming the shell supports this) if you care to address this. To capture a command's STDERR and STDOUT together: $output = `cmd 2>&1`; To capture a command's STDOUT but discard its STDERR: $output = `cmd 2>\/dev\/null`; To capture a command's STDERR but discard its STDOUT (ordering is important here): $output = `cmd 2>&1 1>\/dev\/null`; To exchange a command's STDOUT and STDERR in order to capture the STDERR but leave its STDOUT to come out the old STDERR: $output = `cmd 3>&1 1>&2 2>&3 3>&-`; To read both a command's STDOUT and its STDERR separately, it's easiest to redirect them separately to files, and then read from those files when the program is done: system(\"program args 1>program.stdout 2>program.stderr\"); The STDIN filehandle used by the command is inherited from Perl's STDIN . For example: open BLAM, \"blam\" || die \"Can't open: $!\";\nopen STDIN, \"<&BLAM\";\nprint `sort`; will print the sorted contents of the file \"blam\". Using single-quote as a delimiter protects the command from Perl's double-quote interpolation, passing it on to the shell instead: $perl_info  = qx(ps $$);            # that's Perl's $$\n$shell_info = qx'ps $$';            # that's the new shell's $$ How that string gets evaluated is entirely subject to the command interpreter on your system. On most platforms, you will have to protect shell metacharacters if you want them treated literally. This is in practice difficult to do, as it's unclear how to escape which characters. See perlsec for a clean and safe example of a manual fork() and exec() to emulate backticks safely. On some platforms (notably DOS-like ones), the shell may not be capable of dealing with multiline commands, so putting newlines in the string may not get you what you want. You may be able to evaluate multiple commands in a single line by separating them with the command separator character, if your shell supports that (e.g. \";\" on many Unix shells; \"&\" on the Windows NT \"cmd\" shell). Beginning with v5.6.0, Perl will attempt to flush all files opened for output before starting the child process, but this may not be supported on some platforms (see perlport). To be safe, you may need to set $| ($AUTOFLUSH in English) or call the \"autoflush()\" method of \"IO::Handle\" on any open handles. Beware that some command shells may place restrictions on the length of the command line. You must ensure your strings don't exceed this limit after any necessary interpolations. See the platform-specific release notes for more details about your particular environment. Using this operator can lead to programs that are difficult to port, because the shell commands called vary between systems, and may in fact not be present at all. As one example, the \"type\" command under the POSIX shell is very different from the \"type\" command under DOS . That doesn't mean you should go out of your way to avoid backticks when they're the right way to get something done. Perl was made to be a glue language, and one of the things it glues together is commands. Just understand what you're getting yourself into. See \"I\/O Operators\" for more discussion. qw\/STRING\/ Evaluates to a list of the words extracted out of STRING , using embedded whitespace as the word delimiters. It can be understood as being roughly equivalent to: split(' ', q\/STRING\/); the differences being that it generates a real list at compile time, and in scalar context it returns the last element in the list. So this expression: qw(foo bar baz) is semantically equivalent to the list: 'foo', 'bar', 'baz' Some frequently seen examples: use POSIX qw( setlocale localeconv )\n@EXPORT = qw( foo bar baz ); A common mistake is to try to separate the words with comma or to put comments into a multi-line \"qw\"-string. For this reason, the \"use warnings\" pragma and the -w switch (that is, the $^W variable) produces warnings if the STRING contains the \",\" or the \"#\" character. tr\/SEARCHLIST\/REPLACEMENTLIST\/cds y\/SEARCHLIST\/REPLACEMENTLIST\/cds Transliterates all occurrences of the characters found in the search list with the corresponding character in the replacement list. It returns the number of characters replaced or deleted. If no string is specified via the =~ or !~ operator, the $_ string is transliterated. (The string specified with =~ must be a scalar variable, an array element, a hash element, or an assignment to one of those, i.e., an lvalue.) A character range may be specified with a hyphen, so \"tr\/A-J\/0-9\/\" does the same replacement as \"tr\/ACEGIBDFHJ\/0246813579\/\". For sed devotees, \"y\" is provided as a synonym for \"tr\". If the SEARCHLIST is delimited by bracketing quotes, the REPLACEMENTLIST has its own pair of quotes, which may or may not be bracketing quotes, e.g., \"tr[A-Z][a-z]\" or \"tr(+\\-*\/)\/ABCD\/\". Note that \"tr\" does not do regular expression character classes such as \"\\d\" or \"[:lower:]\". The \"tr\" operator is not equivalent to the tr(1) utility. If you want to map strings between lower\/upper cases, see \"lc\" in perlfunc and \"uc\" in perlfunc, and in general consider using the \"s\" operator if you need regular expressions. Note also that the whole range idea is rather unportable between character sets--and even within character sets they may cause results you probably didn't expect. A sound principle is to use only ranges that begin from and end at either alphabets of equal case (a-e, A-E), or digits (0-4). Anything else is unsafe. If in doubt, spell out the character sets in full. Options: c   Complement the SEARCHLIST.\nd   Delete found but unreplaced characters.\ns   Squash duplicate replaced characters. If the \"\/c\" modifier is specified, the SEARCHLIST character set is complemented. If the \"\/d\" modifier is specified, any characters specified by SEARCHLIST not found in REPLACEMENTLIST are deleted. (Note that this is slightly more flexible than the behavior of some tr programs, which delete anything they find in the SEARCHLIST , period.) If the \"\/s\" modifier is specified, sequences of characters that were transliterated to the same character are squashed down to a single instance of the character. If the \"\/d\" modifier is used, the REPLACEMENTLIST is always interpreted exactly as specified. Otherwise, if the REPLACEMENTLIST is shorter than the SEARCHLIST , the final character is replicated till it is long enough. If the REPLACEMENTLIST is empty, the SEARCHLIST is replicated. This latter is useful for counting characters in a class or for squashing character sequences in a class. Examples: $ARGV[1] =~ tr\/A-Z\/a-z\/;    # canonicalize to lower case\n\n$cnt = tr\/*\/*\/;             # count the stars in $_\n\n$cnt = $sky =~ tr\/*\/*\/;     # count the stars in $sky\n\n$cnt = tr\/0-9\/\/;            # count the digits in $_\n\ntr\/a-zA-Z\/\/s;               # bookkeeper -> bokeper\n\n($HOST = $host) =~ tr\/a-z\/A-Z\/;\n\ntr\/a-zA-Z\/ \/cs;             # change non-alphas to single space\n\ntr [\\200-\\377]\n   [\\000-\\177];             # delete 8th bit If multiple transliterations are given for a character, only the first one is used: tr\/AAA\/XYZ\/ will transliterate any A to X. Because the transliteration table is built at compile time, neither the SEARCHLIST nor the REPLACEMENTLIST are subjected to double quote interpolation. That means that if you want to use variables, you must use an eval(): eval \"tr\/$oldlist\/$newlist\/\";\ndie $@ if $@;\n\neval \"tr\/$oldlist\/$newlist\/, 1\" or die $@; << EOF A line-oriented form of quoting is based on the shell \"here-document\" syntax. Following a \"<<\" you specify a string to terminate the quoted material, and all lines following the current line down to the terminating string are the value of the item. The terminating string may be either an identifier (a word), or some quoted text. An unquoted identifier works like double quotes. There may not be a space between the \"<<\" and the identifier, unless the identifier is explicitly quoted. (If you put a space it will be treated as a null identifier, which is valid, and matches the first empty line.) The terminating string must appear by itself (unquoted and with no surrounding whitespace) on the terminating line. If the terminating string is quoted, the type of quotes used determine the treatment of the text. Double Quotes Double quotes indicate that the text will be interpolated using exactly the same rules as normal double quoted strings.    print <<EOF;\nThe price is $Price.\nEOF\n\n   print << \"EOF\"; # same as above\nThe price is $Price.\nEOF Single Quotes Single quotes indicate the text is to be treated literally with no interpolation of its content. This is similar to single quoted strings except that backslashes have no special meaning, with \"\\\\\" being treated as two backslashes and not one as they would in every other quoting construct. This is the only form of quoting in perl where there is no need to worry about escaping content, something that code generators can and do make good use of. Backticks The content of the here doc is treated just as it would be if the string were embedded in backticks. Thus the content is interpolated as though it were double quoted and then executed via the shell, with the results of the execution returned.    print << `EOC`; # execute command and get results\necho hi there\nEOC It is possible to stack multiple here-docs in a row:    print <<\"foo\", <<\"bar\"; # you can stack them\nI said foo.\nfoo\nI said bar.\nbar\n\n   myfunc(<< \"THIS\", 23, <<'THAT');\nHere's a line\nor two.\nTHIS\nand here's another.\nTHAT Just don't forget that you have to put a semicolon on the end to finish the statement, as Perl doesn't know you're not going to try to do this:    print <<ABC\n179231\nABC\n   + 20; If you want to remove the line terminator from your here-docs, use \"chomp()\". chomp($string = <<'END');\nThis is a string.\nEND If you want your here-docs to be indented with the rest of the code, you'll need to remove leading whitespace from each line manually: ($quote = <<'FINIS') =~ s\/^\\s+\/\/gm;\n   The Road goes ever on and on,\n   down from the door where it began.\nFINIS If you use a here-doc within a delimited construct, such as in \"s\/\/\/eg\", the quoted material must come on the lines following the final delimiter. So instead of s\/this\/<<E . 'that'\nthe other\nE\n . 'more '\/eg; you have to write s\/this\/<<E . 'that'\n . 'more '\/eg;\nthe other\nE If the terminating identifier is on the last line of the program, you must be sure there is a newline after it; otherwise, Perl will give the warning Can't find string terminator \" END \" anywhere before EOF .... Additionally, the quoting rules for the end of string identifier are not related to Perl's quoting rules -- \"q()\", \"qq()\", and the like are not supported in place of '' and \"\", and the only interpolation is for backslashing the quoting character: print << \"abc\\\"def\";\ntesting...\nabc\"def Finally, quoted strings cannot span multiple lines. The general rule is that the identifier must be a string literal. Stick with that, and you should be safe. Gory details of parsing quoted constructs When presented with something that might have several different interpretations, Perl uses the DWIM (that's \"Do What I Mean\") principle to pick the most probable interpretation. This strategy is so successful that Perl programmers often do not suspect the ambivalence of what they write. But from time to time, Perl's notions differ substantially from what the author honestly meant. This section hopes to clarify how Perl handles quoted constructs. Although the most common reason to learn this is to unravel labyrinthine regular expressions, because the initial steps of parsing are the same for all quoting operators, they are all discussed together. The most important Perl parsing rule is the first one discussed below: when processing a quoted construct, Perl first finds the end of that construct, then interprets its contents. If you understand this rule, you may skip the rest of this section on the first reading. The other rules are likely to contradict the user's expectations much less frequently than this first one. Some passes discussed below are performed concurrently, but because their results are the same, we consider them individually. For different quoting constructs, Perl performs different numbers of passes, from one to four, but these passes are always performed in the same order. Finding the end The first pass is finding the end of the quoted construct, where the information about the delimiters is used in parsing. During this search, text between the starting and ending delimiters is copied to a safe location. The text copied gets delimiter-independent. If the construct is a here-doc, the ending delimiter is a line that has a terminating string as the content. Therefore \"<<EOF\" is terminated by \"EOF\" immediately followed by \"\\n\" and starting from the first column of the terminating line. When searching for the terminating line of a here-doc, nothing is skipped. In other words, lines after the here-doc syntax are compared with the terminating string line by line. For the constructs except here-docs, single characters are used as starting and ending delimiters. If the starting delimiter is an opening punctuation (that is \"(\", \"[\", \"{\", or \"<\"), the ending delimiter is the corresponding closing punctuation (that is \")\", \"]\", \"}\", or \">\"). If the starting delimiter is an unpaired character like \"\/\" or a closing punctuation, the ending delimiter is same as the starting delimiter. Therefore a \"\/\" terminates a \"qq\/\/\" construct, while a \"]\" terminates \"qq[]\" and \"qq]]\" constructs. When searching for single-character delimiters, escaped delimiters and \"\\\\\" are skipped. For example, while searching for terminating \"\/\", combinations of \"\\\\\" and \"\\\/\" are skipped. If the delimiters are bracketing, nested pairs are also skipped. For example, while searching for closing \"]\" paired with the opening \"[\", combinations of \"\\\\\", \"\\]\", and \"\\[\" are all skipped, and nested \"[\" and \"]\" are skipped as well. However, when backslashes are used as the delimiters (like \"qq\\\\\" and \"tr\\\\\\\"), nothing is skipped. During the search for the end, backslashes that escape delimiters are removed (exactly speaking, they are not copied to the safe location). For constructs with three-part delimiters (\"s\/\/\/\", \"y\/\/\/\", and \"tr\/\/\/\"), the search is repeated once more. If the first delimiter is not an opening punctuation, three delimiters must be same such as \"s!!!\" and \"tr)))\", in which case the second delimiter terminates the left part and starts the right part at once. If the left part is delimited by bracketing punctuations (that is \"()\", \"[]\", \"{}\", or \"<>\"), the right part needs another pair of delimiters such as \"s(){}\" and \"tr[]\/\/\". In these cases, whitespaces and comments are allowed between both parts, though the comment must follow at least one whitespace; otherwise a character expected as the start of the comment may be regarded as the starting delimiter of the right part. During this search no attention is paid to the semantics of the construct. Thus: \"$hash{\"$foo\/$bar\"}\" or: m\/\n  bar       # NOT a comment, this slash \/ terminated m\/\/!\n \/x do not form legal quoted expressions. The quoted part ends on the first \"\"\" and \"\/\", and the rest happens to be a syntax error. Because the slash that terminated \"m\/\/\" was followed by a \"SPACE\", the example above is not \"m\/\/x\", but rather \"m\/\/\" with no \"\/x\" modifier. So the embedded \"#\" is interpreted as a literal \"#\". Also no attention is paid to \"\\c\\\" (multichar control char syntax) during this search. Thus the second \"\\\" in \"qq\/\\c\\\/\" is interpreted as a part of \"\\\/\", and the following \"\/\" is not recognized as a delimiter. Instead, use \"\\034\" or \"\\x1c\" at the end of quoted constructs. Interpolation The next step is interpolation in the text obtained, which is now delimiter-independent. There are multiple cases. \"<<'EOF'\" No interpolation is performed. Note that the combination \"\\\\\" is left intact, since escaped delimiters are not available for here-docs. \"m''\", the pattern of \"s'''\" No interpolation is performed at this stage. Any backslashed sequences including \"\\\\\" are treated at the stage to \"parsing regular expressions\". '', \"q\/\/\", \"tr'''\", \"y'''\", the replacement of \"s'''\" The only interpolation is removal of \"\\\" from pairs of \"\\\\\". Therefore \"-\" in \"tr'''\" and \"y'''\" is treated literally as a hyphen and no character range is available. \"\\1\" in the replacement of \"s'''\" does not work as $1. \"tr\/\/\/\", \"y\/\/\/\" No variable interpolation occurs. String modifying combinations for case and quoting such as \"\\Q\", \"\\U\", and \"\\E\" are not recognized. The other escape sequences such as \"\\200\" and \"\\t\" and backslashed characters such as \"\\\\\" and \"\\-\" are converted to appropriate literals. The character \"-\" is treated specially and therefore \"\\-\" is treated as a literal \"-\". \"\", \"``\", \"qq\/\/\", \"qx\/\/\", \"<file*glob>\", \"<<\"EOF\"\" \"\\Q\", \"\\U\", \"\\u\", \"\\L\", \"\\l\" (possibly paired with \"\\E\") are converted to corresponding Perl constructs. Thus, \"$foo\\Qbaz$bar\" is converted to \"$foo . (quotemeta(\"baz\" . $bar))\" internally. The other escape sequences such as \"\\200\" and \"\\t\" and backslashed characters such as \"\\\\\" and \"\\-\" are replaced with appropriate expansions. Let it be stressed that whatever falls between \"\\Q\" and \"\\E\" is interpolated in the usual way. Something like \"\\Q\\\\E\" has no \"\\E\" inside. instead, it has \"\\Q\", \"\\\\\", and \"E\", so the result is the same as for \"\\\\\\\\E\". As a general rule, backslashes between \"\\Q\" and \"\\E\" may lead to counterintuitive results. So, \"\\Q\\t\\E\" is converted to \"quotemeta(\"\\t\")\", which is the same as \"\\\\\\t\" (since TAB is not alphanumeric). Note also that: $str = '\\t';\nreturn \"\\Q$str\"; may be closer to the conjectural intention of the writer of \"\\Q\\t\\E\". Interpolated scalars and arrays are converted internally to the \"join\" and \".\" catenation operations. Thus, \"$foo XXX '@arr'\" becomes: $foo . \" XXX '\" . (join $\", @arr) . \"'\"; All operations above are performed simultaneously, left to right. Because the result of \"\\Q STRING \\E\" has all metacharacters quoted, there is no way to insert a literal \"$\" or \"@\" inside a \"\\Q\\E\" pair. If protected by \"\\\", \"$\" will be quoted to became \"\\\\\\$\"; if not, it is interpreted as the start of an interpolated scalar. Note also that the interpolation code needs to make a decision on where the interpolated scalar ends. For instance, whether \"a $b -> {c}\" really means: \"a \" . $b . \" -> {c}\"; or: \"a \" . $b -> {c}; Most of the time, the longest possible text that does not include spaces between components and which contains matching braces or brackets. because the outcome may be determined by voting based on heuristic estimators, the result is not strictly predictable. Fortunately, it's usually correct for ambiguous cases. the replacement of \"s\/\/\/\" Processing of \"\\Q\", \"\\U\", \"\\u\", \"\\L\", \"\\l\", and interpolation happens as with \"qq\/\/\" constructs. It is at this step that \"\\1\" is begrudgingly converted to $1 in the replacement text of \"s\/\/\/\", in order to correct the incorrigible sed hackers who haven't picked up the saner idiom yet. A warning is emitted if the \"use warnings\" pragma or the -w command-line flag (that is, the $^W variable) was set. \"RE\" in \"?RE?\", \"\/RE\/\", \"m\/RE\/\", \"s\/RE\/foo\/\", Processing of \"\\Q\", \"\\U\", \"\\u\", \"\\L\", \"\\l\", \"\\E\", and interpolation happens (almost) as with \"qq\/\/\" constructs. However any other combinations of \"\\\" followed by a character are not substituted but only skipped, in order to parse them as regular expressions at the following step. As \"\\c\" is skipped at this step, \"@\" of \"\\c@\" in RE is possibly treated as an array symbol (for example @foo), even though the same text in \"qq\/\/\" gives interpolation of \"\\c@\". Moreover, inside \"(?{BLOCK})\", \"(?# comment )\", and a \"#\"-comment in a \"\/\/x\"-regular expression, no processing is performed whatsoever. This is the first step at which the presence of the \"\/\/x\" modifier is relevant. Interpolation in patterns has several quirks: $|, $(, $), \"@+\" and \"@-\" are not interpolated, and constructs $var[SOMETHING] are voted (by several different estimators) to be either an array element or $var followed by an RE alternative. This is where the notation \"${arr[$bar]}\" comes handy: \"\/${arr[0-9]}\/\" is interpreted as array element \"-9\", not as a regular expression from the variable $arr followed by a digit, which would be the interpretation of \"\/$arr[0-9]\/\". Since voting among different estimators may occur, the result is not predictable. The lack of processing of \"\\\\\" creates specific restrictions on the post-processed text. If the delimiter is \"\/\", one cannot get the combination \"\\\/\" into the result of this step. \"\/\" will finish the regular expression, \"\\\/\" will be stripped to \"\/\" on the previous step, and \"\\\\\/\" will be left as is. Because \"\/\" is equivalent to \"\\\/\" inside a regular expression, this does not matter unless the delimiter happens to be character special to the RE engine, such as in \"s*foo*bar*\", \"m[foo]\", or \"?foo?\"; or an alphanumeric char, as in: m m ^ a \\s* b mmx; In the RE above, which is intentionally obfuscated for illustration, the delimiter is \"m\", the modifier is \"mx\", and after delimiter-removal the RE is the same as for \"m\/ ^ a \\s* b \/mx\". There's more than one reason you're encouraged to restrict your delimiters to non-alphanumeric, non-whitespace choices. This step is the last one for all constructs except regular expressions, which are processed further. parsing regular expressions Previous steps were performed during the compilation of Perl code, but this one happens at run time--although it may be optimized to be calculated at compile time if appropriate. After preprocessing described above, and possibly after evaluation if concatenation, joining, casing translation, or metaquoting are involved, the resulting string is passed to the RE engine for compilation. Whatever happens in the RE engine might be better discussed in perlre, but for the sake of continuity, we shall do so here. This is another step where the presence of the \"\/\/x\" modifier is relevant. The RE engine scans the string from left to right and converts it to a finite automaton. Backslashed characters are either replaced with corresponding literal strings (as with \"\\{\"), or else they generate special nodes in the finite automaton (as with \"\\b\"). Characters special to the RE engine (such as \"|\") generate corresponding nodes or groups of nodes. \"(?#...)\" comments are ignored. All the rest is either converted to literal strings to match, or else is ignored (as is whitespace and \"#\"-style comments if \"\/\/x\" is present). Parsing of the bracketed character class construct, \"[...]\", is rather different than the rule used for the rest of the pattern. The terminator of this construct is found using the same rules as for finding the terminator of a \"{}\"-delimited construct, the only exception being that \"]\" immediately following \"[\" is treated as though preceded by a backslash. Similarly, the terminator of \"(?{...})\" is found using the same rules as for finding the terminator of a \"{}\"-delimited construct. It is possible to inspect both the string given to RE engine and the resulting finite automaton. See the arguments \"debug\"\/\"debugcolor\" in the \"use re\" pragma, as well as Perl's -Dr command-line switch documented in \"Command Switches\" in perlrun. Optimization of regular expressions This step is listed for completeness only. Since it does not change semantics, details of this step are not documented and are subject to change without notice. This step is performed over the finite automaton that was generated during the previous pass. It is at this stage that \"split()\" silently optimizes \"\/^\/\" to mean \"\/^\/m\". I\/O Operators There are several I\/O operators you should know about. A string enclosed by backticks (grave accents) first undergoes double-quote interpolation. It is then interpreted as an external command, and the output of that command is the value of the backtick string, like in a shell. In scalar context, a single string consisting of all output is returned. In list context, a list of values is returned, one per line of output. (You can set $\/ to use a different line terminator.) The command is executed each time the pseudo-literal is evaluated. The status value of the command is returned in $? (see perlvar for the interpretation of $?). Unlike in csh, no translation is done on the return data--newlines remain newlines. Unlike in any of the shells, single quotes do not hide variable names in the command from interpretation. To pass a literal dollar-sign through to the shell you need to hide it with a backslash. The generalized form of backticks is \"qx\/\/\". (Because backticks always undergo shell expansion as well, see perlsec for security concerns.) In scalar context, evaluating a filehandle in angle brackets yields the next line from that file (the newline, if any, included), or \"undef\" at end-of-file or on error. When $\/ is set to \"undef\" (sometimes known as file-slurp mode) and the file is empty, it returns '' the first time, followed by \"undef\" subsequently. Ordinarily you must assign the returned value to a variable, but there is one situation where an automatic assignment happens. If and only if the input symbol is the only thing inside the conditional of a \"while\" statement (even if disguised as a \"for(;;)\" loop), the value is automatically assigned to the global variable $_, destroying whatever was there previously. (This may seem like an odd thing to you, but you'll use the construct in almost every Perl script you write.) The $_ variable is not implicitly localized. You'll have to put a \"local $_;\" before the loop if you want that to happen. The following lines are equivalent: while (defined($_ = <STDIN>)) { print; }\nwhile ($_ = <STDIN>) { print; }\nwhile (<STDIN>) { print; }\nfor (;<STDIN>;) { print; }\nprint while defined($_ = <STDIN>);\nprint while ($_ = <STDIN>);\nprint while <STDIN>; This also behaves similarly, but avoids $_ : while (my $line = <STDIN>) { print $line } In these loop constructs, the assigned value (whether assignment is automatic or explicit) is then tested to see whether it is defined. The defined test avoids problems where line has a string value that would be treated as false by Perl, for example a \"\" or a \"0\" with no trailing newline. If you really mean for such values to terminate the loop, they should be tested for explicitly: while (($_ = <STDIN>) ne '0') { ... }\nwhile (<STDIN>) { last unless $_; ... } In other boolean contexts, \"<I<filehandle>>\" without an explicit \"defined\" test or comparison elicit a warning if the \"use warnings\" pragma or the -w command-line switch (the $^W variable) is in effect. The filehandles STDIN , STDOUT , and STDERR are predefined. (The filehandles \"stdin\", \"stdout\", and \"stderr\" will also work except in packages, where they would be interpreted as local identifiers rather than global.) Additional filehandles may be created with the open() function, amongst others. See perlopentut and \"open\" in perlfunc for details on this. If a < FILEHANDLE > is used in a context that is looking for a list, a list comprising all input lines is returned, one line per list element. It's easy to grow to a rather large data space this way, so use with care. < FILEHANDLE > may also be spelled \"readline(*FILEHANDLE)\". See \"readline\" in perlfunc. The null filehandle <> is special: it can be used to emulate the behavior of sed and awk. Input from <> comes either from standard input, or from each file listed on the command line. Here's how it works: the first time <> is evaluated, the @ARGV array is checked, and if it is empty, $ARGV[0] is set to \"-\", which when opened gives you standard input. The @ARGV array is then processed as a list of filenames. The loop while (<>) {\n    ...                     # code for each line\n} is equivalent to the following Perl-like pseudo code: unshift(@ARGV, '-') unless @ARGV;\nwhile ($ARGV = shift) {\n    open(ARGV, $ARGV);\n    while (<ARGV>) {\n        ...         # code for each line\n    }\n} except that it isn't so cumbersome to say, and will actually work. It really does shift the @ARGV array and put the current filename into the $ARGV variable. It also uses filehandle ARGV internally--<> is just a synonym for < ARGV >, which is magical. (The pseudo code above doesn't work because it treats < ARGV > as non-magical.) Since the null filehandle uses the two argument form of \"open\" in perlfunc it interprets special characters, so if you have a script like this: while (<>) {\n    print;\n} and call it with \"perl dangerous.pl 'rm -rfv *|'\", it actually opens a pipe, executes the \"rm\" command and reads \"rm\"'s output from that pipe. If you want all items in @ARGV to be interpreted as file names, you can use the module \"ARGV::readonly\" from CPAN . You can modify @ARGV before the first <> as long as the array ends up containing the list of filenames you really want. Line numbers ($.) continue as though the input were one big happy file. See the example in \"eof\" in perlfunc for how to reset line numbers on each file. If you want to set @ARGV to your own list of files, go right ahead. This sets @ARGV to all plain text files if no @ARGV was given: @ARGV = grep { -f && -T } glob('*') unless @ARGV; You can even set them to pipe commands. For example, this automatically filters compressed arguments through gzip: @ARGV = map { \/\\.(gz|Z)$\/ ? \"gzip -dc < $_ |\" : $_ } @ARGV; If you want to pass switches into your script, you can use one of the Getopts modules or put a loop on the front like this: while ($_ = $ARGV[0], \/^-\/) {\n    shift;\n    last if \/^--$\/;\n    if (\/^-D(.*)\/) { $debug = $1 }\n    if (\/^-v\/)     { $verbose++  }\n    # ...           # other switches\n}\n\nwhile (<>) {\n    # ...           # code for each line\n} The <> symbol will return \"undef\" for end-of-file only once. If you call it again after this, it will assume you are processing another @ARGV list, and if you haven't set @ARGV, will read input from STDIN . If what the angle brackets contain is a simple scalar variable (e.g., <$foo>), then that variable contains the name of the filehandle to input from, or its typeglob, or a reference to the same. For example: $fh = \\*STDIN;\n$line = <$fh>; If what's within the angle brackets is neither a filehandle nor a simple scalar variable containing a filehandle name, typeglob, or typeglob reference, it is interpreted as a filename pattern to be globbed, and either a list of filenames or the next filename in the list is returned, depending on context. This distinction is determined on syntactic grounds alone. That means \"<$x>\" is always a readline() from an indirect handle, but \"<$hash{key}>\" is always a glob(). That's because $x is a simple scalar variable, but $hash{key} is not--it's a hash element. Even \"<$x >\" (note the extra space) is treated as \"glob(\"$x \")\", not \"readline($x)\". One level of double-quote interpretation is done first, but you can't say \"<$foo>\" because that's an indirect filehandle as explained in the previous paragraph. (In older versions of Perl, programmers would insert curly brackets to force interpretation as a filename glob: \"<${foo}>\". These days, it's considered cleaner to call the internal function directly as \"glob($foo)\", which is probably the right way to have done it in the first place.) For example: while (<*.c>) {\n    chmod 0644, $_;\n} is roughly equivalent to: open(FOO, \"echo *.c | tr -s ' \\t\\r\\f' '\\\\012\\\\012\\\\012\\\\012'|\");\nwhile (<FOO>) {\n    chomp;\n    chmod 0644, $_;\n} except that the globbing is actually done internally using the standard \"File::Glob\" extension. Of course, the shortest way to do the above is: chmod 0644, <*.c>; A (file)glob evaluates its (embedded) argument only when it is starting a new list. All values must be read before it will start over. In list context, this isn't important because you automatically get them all anyway. However, in scalar context the operator returns the next value each time it's called, or \"undef\" when the list has run out. As with filehandle reads, an automatic \"defined\" is generated when the glob occurs in the test part of a \"while\", because legal glob returns (e.g. a file called 0) would otherwise terminate the loop. Again, \"undef\" is returned only once. So if you're expecting a single value from a glob, it is much better to say ($file) = <blurch*>; than $file = <blurch*>; because the latter will alternate between returning a filename and returning false. If you're trying to do variable interpolation, it's definitely better to use the glob() function, because the older notation can cause people to become confused with the indirect filehandle notation. @files = glob(\"$dir\/*.[ch]\");\n@files = glob($files[$i]); Constant Folding Like C, Perl does a certain amount of expression evaluation at compile time whenever it determines that all arguments to an operator are static and have no side effects. In particular, string concatenation happens at compile time between literals that don't do variable substitution. Backslash interpolation also happens at compile time. You can say 'Now is the time for all' . \"\\n\" .\n    'good men to come to.' and this all reduces to one string internally. Likewise, if you say foreach $file (@filenames) {\n    if (-s $file > 5 + 100 * 2**16) {  }\n} the compiler will precompute the number which that expression represents so that the interpreter won't have to. No-ops Perl doesn't officially have a no-op operator, but the bare constants 0 and 1 are special-cased to not produce a warning in a void context, so you can for example safely do 1 while foo(); Bitwise String Operators Bitstrings of any size may be manipulated by the bitwise operators ( \"~ | & ^\"). If the operands to a binary bitwise op are strings of different sizes, | and ^ ops act as though the shorter operand had additional zero bits on the right, while the & op acts as though the longer operand were truncated to the length of the shorter. The granularity for such extension or truncation is one or more bytes. # ASCII-based examples\nprint \"j p \\n\" ^ \" a h\";            # prints \"JAPH\\n\"\nprint \"JA\" | \"  ph\\n\";              # prints \"japh\\n\"\nprint \"japh\\nJunk\" & '_____';       # prints \"JAPH\\n\";\nprint 'p N$' ^ \" E<H\\n\";            # prints \"Perl\\n\"; If you are intending to manipulate bitstrings, be certain that you're supplying bitstrings: If an operand is a number, that will imply a numeric bitwise operation. You may explicitly show which type of operation you intend by using \"\" or \"0+\", as in the examples below. $foo =  150  |  105;        # yields 255  (0x96 | 0x69 is 0xFF)\n$foo = '150' |  105;        # yields 255\n$foo =  150  | '105';       # yields 255\n$foo = '150' | '105';       # yields string '155' (under ASCII)\n\n$baz = 0+$foo & 0+$bar;     # both ops explicitly numeric\n$biz = \"$foo\" ^ \"$bar\";     # both ops explicitly stringy See \"vec\" in perlfunc for information on how to manipulate individual bits in a bit vector. Integer Arithmetic By default, Perl assumes that it must do most of its arithmetic in floating point. But by saying use integer; you may tell the compiler that it's okay to use integer operations (if it feels like it) from here to the end of the enclosing BLOCK . An inner BLOCK may countermand this by saying no integer; which lasts until the end of that BLOCK . Note that this doesn't mean everything is only an integer, merely that Perl may use integer operations if it is so inclined. For example, even under \"use integer\", if you take the sqrt(2), you'll still get 1.4142135623731 or so. Used on numbers, the bitwise operators (\"&\", \"|\", \"^\", \"~\", \"<<\", and \">>\") always produce integral results. (But see also \"Bitwise String Operators\".) However, \"use integer\" still has meaning for them. By default, their results are interpreted as unsigned integers, but if \"use integer\" is in effect, their results are interpreted as signed integers. For example, \"~0\" usually evaluates to a large integral value. However, \"use integer; ~0\" is \"-1\" on two's-complement machines. Floating-point Arithmetic While \"use integer\" provides integer-only arithmetic, there is no analogous mechanism to provide automatic rounding or truncation to a certain number of decimal places. For rounding to a certain number of digits, sprintf() or printf() is usually the easiest route. See perlfaq4. Floating-point numbers are only approximations to what a mathematician would call real numbers. There are infinitely more reals than floats, so some corners must be cut. For example: printf \"%.20g\\n\", 123456789123456789;\n#        produces 123456789123456784 Testing for exact equality of floating-point equality or inequality is not a good idea. Here's a (relatively expensive) work-around to compare whether two floating-point numbers are equal to a particular number of decimal places. See Knuth, volume II , for a more robust treatment of this topic. sub fp_equal {\n    my ($X, $Y, $POINTS) = @_;\n    my ($tX, $tY);\n    $tX = sprintf(\"%.${POINTS}g\", $X);\n    $tY = sprintf(\"%.${POINTS}g\", $Y);\n    return $tX eq $tY;\n} The POSIX module (part of the standard perl distribution) implements ceil(), floor(), and other mathematical and trigonometric functions. The Math::Complex module (part of the standard perl distribution) defines mathematical functions that work on both the reals and the imaginary numbers. Math::Complex not as efficient as POSIX , but POSIX can't work with complex numbers. Rounding in financial applications can have serious implications, and the rounding method used should be specified precisely. In these cases, it probably pays not to trust whichever system rounding is being used by Perl, but to instead implement the rounding function you need yourself. Bigger Numbers The standard Math::BigInt and Math::BigFloat modules provide variable-precision arithmetic and overloaded operators, although they're currently pretty slow. At the cost of some space and considerable speed, they avoid the normal pitfalls associated with limited-precision representations. use Math::BigInt;\n$x = Math::BigInt->new('123456789123456789');\nprint $x * $x;\n\n# prints +15241578780673678515622620750190521 There are several modules that let you calculate with (bound only by memory and cpu-time) unlimited or fixed precision. There are also some non-standard modules that provide faster implementations via external C libraries. Here is a short, but incomplete summary: Math::Fraction          big, unlimited fractions like 9973 \/ 12967\nMath::String            treat string sequences like numbers\nMath::FixedPrecision    calculate with a fixed precision\nMath::Currency          for currency calculations\nBit::Vector             manipulate bit vectors fast (uses C)\nMath::BigIntFast        Bit::Vector wrapper for big numbers\nMath::Pari              provides access to the Pari C library\nMath::BigInteger        uses an external C library\nMath::Cephes            uses external Cephes C library (no big numbers)\nMath::Cephes::Fraction  fractions via the Cephes library\nMath::GMP               another one using an external C library Choose wisely. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"perlop","Link":"https:\/\/linux.die.net\/man\/1\/perlop"}},{"Process":{"Description":"This document describes various features of OpenBSD that will affect how Perl version 5 (hereafter just Perl) is compiled and\/or runs. OpenBSD core dumps from getprotobyname_r and getservbyname_r with ithreads When Perl is configured to use ithreads, it will use re-entrant library calls in preference to non-re-entrant versions. There is an incompatability in OpenBSD's \"getprotobyname_r\" and \"getservbyname_r\" function in versions 3.7 and later that will cause a SEGV when called without doing a \"bzero\" on their return structs prior to calling these functions. Current Perl's should handle this problem correctly. Older threaded Perls (5.8.6 or earlier) will run into this problem. If you want to run a threaded Perl on OpenBSD 3.7 or higher, you will need to upgrade to at least Perl 5.8.7.","Process Name":"perlopenbsd","Link":"https:\/\/linux.die.net\/man\/1\/perlopenbsd"}},{"Process":{"Description":"Perl has two simple, built-in ways to open files: the shell way for convenience, and the C way for precision. The shell way also has 2- and 3-argument forms, which have different semantics for handling the filename. The choice is yours.","Process Name":"perlopentut","Link":"https:\/\/linux.die.net\/man\/1\/perlopentut"}},{"Process":{"Description":"Target The target is to make OS\/2 one of the best supported platform for using\/building\/developing Perl and Perl applications, as well as make Perl the best language to use under OS\/2 . The secondary target is to try to make this work under DOS and Win* as well (but not too hard). The current state is quite close to this target. Known limitations: \u2022 Some *nix programs use fork() a lot; with the mostly useful flavors of perl for OS\/2 (there are several built simultaneously) this is supported; but some flavors do not support this (e.g., when Perl is called from inside REXX ). Using fork() after useing dynamically loading extensions would not work with very old versions of EMX . \u2022 You need a separate perl executable perl__.exe (see perl__.exe) if you want to use PM code in your application (as Perl\/Tk or OpenGL Perl modules do) without having a text-mode window present. While using the standard perl.exe from a text-mode window is possible too, I have seen cases when this causes degradation of the system stability. Using perl__.exe avoids such a degradation. \u2022 There is no simple way to access WPS objects. The only way I know is via \"OS2::REXX\" and \"SOM\" extensions (see OS2::REXX , Som). However, we do not have access to convenience methods of Object-REXX. (Is it possible at all? I know of no Object-REXX API .) The \"SOM\" extension (currently in alpha-text) may eventually remove this shortcoming; however, due to the fact that DII is not supported by the \"SOM\" module, using \"SOM\" is not as convenient as one would like it. Please keep this list up-to-date by informing me about other items. Other OSes Since OS\/2 port of perl uses a remarkable EMX environment, it can run (and build extensions, and - possibly - be built itself) under any environment which can run EMX . The current list is DOS , DOS-inside-OS\/2, Win0.3*, Win0.95 and WinNT. Out of many perl flavors, only one works, see \"perl_.exe\". Note that not all features of Perl are available under these environments. This depends on the features the extender - most probably RSX - decided to implement. Cf. Prerequisites. Prerequisites EMX EMX runtime is required (may be substituted by RSX ). Note that it is possible to make perl_.exe to run under DOS without any external support by binding emx.exe\/rsx.exe to it, see emxbind. Note that under DOS for best results one should use RSX runtime, which has much more functions working (like \"fork\", \"popen\" and so on). In fact RSX is required if there is no VCPI present. Note the RSX requires DPMI . Many implementations of DPMI are known to be very buggy, beware! Only the latest runtime is supported, currently \"0.9d fix 03\". Perl may run under earlier versions of EMX , but this is not tested. One can get different parts of EMX from, say http:\/\/www.leo.org\/pub\/comp\/os\/os2\/leo\/gnu\/emx+gcc\/\nhttp:\/\/powerusersbbs.com\/pub\/os2\/dev\/   [EMX+GCC Development]\nhttp:\/\/hobbes.nmsu.edu\/pub\/os2\/dev\/emx\/v0.9d\/ The runtime component should have the name emxrt.zip. NOTE . When using emx.exe\/rsx.exe, it is enough to have them on your path. One does not need to specify them explicitly (though this emx perl_.exe -de 0 will work as well.) RSX To run Perl on DPMI platforms one needs RSX runtime. This is needed under DOS-inside-OS\/2, Win0.3*, Win0.95 and WinNT (see \"Other OSes\"). RSX would not work with VCPI only, as EMX would, it requires DMPI . Having RSX and the latest sh.exe one gets a fully functional *nix-ish environment under DOS , say, \"fork\", \"``\" and pipe- \"open\" work. In fact, MakeMaker works (for static build), so one can have Perl development environment under DOS . One can get RSX from, say ftp:\/\/ftp.cdrom.com\/pub\/os2\/emx09c\/contrib\nftp:\/\/ftp.uni-bielefeld.de\/pub\/systems\/msdos\/misc\nftp:\/\/ftp.leo.org\/pub\/comp\/os\/os2\/leo\/devtools\/emx+gcc\/contrib Contact the author on \"rainer@mathematik.uni-bielefeld.de\". The latest sh.exe with DOS hooks is available in http:\/\/www.ilyaz.org\/software\/os2\/ as sh_dos.zip or under similar names starting with \"sh\", \"pdksh\" etc. HPFS Perl does not care about file systems, but the perl library contains many files with long names, so to install it intact one needs a file system which supports long file names. Note that if you do not plan to build the perl itself, it may be possible to fool EMX to truncate file names. This is not supported, read EMX docs to see how to do it. pdksh To start external programs with complicated command lines (like with pipes in between, and\/or quoting of arguments), Perl uses an external shell. With EMX port such shell should be named sh.exe, and located either in the wired-in-during-compile locations (usually F:\/bin), or in configurable location (see \" PERL_SH_DIR \"). For best results use EMX pdksh. The standard binary (5.2.14 or later) runs under DOS (with RSX ) as well, see http:\/\/www.ilyaz.org\/software\/os2\/ Starting Perl programs under OS\/2 (and DOS and...) Start your Perl program foo.pl with arguments \"arg1 arg2 arg3\" the same way as on any other platform, by perl foo.pl arg1 arg2 arg3 If you want to specify perl options \"-my_opts\" to the perl itself (as opposed to your program), use perl -my_opts foo.pl arg1 arg2 arg3 Alternately, if you use OS\/2-ish shell, like CMD or 4os2, put the following at the start of your perl script: extproc perl -S -my_opts rename your program to foo.cmd, and start it by typing foo arg1 arg2 arg3 Note that because of stupid OS\/2 limitations the full path of the perl script is not available when you use \"extproc\", thus you are forced to use \"-S\" perl switch, and your script should be on the \"PATH\". As a plus side, if you know a full path to your script, you may still start it with perl ..\/..\/blah\/foo.cmd arg1 arg2 arg3 (note that the argument \"-my_opts\" is taken care of by the \"extproc\" line in your script, see \" \"extproc\" on the first line\"). To understand what the above magic does, read perl docs about \"-S\" switch - see perlrun, and cmdref about \"extproc\": view perl perlrun\nman perlrun\nview cmdref extproc\nhelp extproc or whatever method you prefer. There are also endless possibilities to use executable extensions of 4os2, associations of WPS and so on... However, if you use *nixish shell (like sh.exe supplied in the binary distribution), you need to follow the syntax specified in \"Switches\" in perlrun. Note that -S switch supports scripts with additional extensions .cmd, .btm, .bat, .pl as well. Starting OS\/2 (and DOS ) programs under Perl This is what system() (see \"system\" in perlfunc), \"``\" (see \"I\/O Operators\" in perlop), and open pipe (see \"open\" in perlfunc) are for. (Avoid exec() (see \"exec\" in perlfunc) unless you know what you do). Note however that to use some of these operators you need to have a sh-syntax shell installed (see \"Pdksh\", \"Frequently asked questions\"), and perl should be able to find it (see \" PERL_SH_DIR \"). The cases when the shell is used are: 1. One-argument system() (see \"system\" in perlfunc), exec() (see \"exec\" in perlfunc) with redirection or shell meta-characters; 2. Pipe-open (see \"open\" in perlfunc) with the command which contains redirection or shell meta-characters; 3. Backticks \"``\" (see \"I\/O Operators\" in perlop) with the command which contains redirection or shell meta-characters; 4. If the executable called by system()\/exec()\/pipe-open()\/\"``\" is a script with the \"magic\" \"#!\" line or \"extproc\" line which specifies shell; 5. If the executable called by system()\/exec()\/pipe-open()\/\"``\" is a script without \"magic\" line, and $ENV{EXECSHELL} is set to shell; 6. If the executable called by system()\/exec()\/pipe-open()\/\"``\" is not found (is not this remark obsolete?); 7. For globbing (see \"glob\" in perlfunc, \"I\/O Operators\" in perlop) (obsolete? Perl uses builtin globbing nowadays...). For the sake of speed for a common case, in the above algorithms backslashes in the command name are not considered as shell metacharacters. Perl starts scripts which begin with cookies \"extproc\" or \"#!\" directly, without an intervention of shell. Perl uses the same algorithm to find the executable as pdksh: if the path on \"#!\" line does not work, and contains \"\/\", then the directory part of the executable is ignored, and the executable is searched in . and on \"PATH\". To find arguments for these scripts Perl uses a different algorithm than pdksh: up to 3 arguments are recognized, and trailing whitespace is stripped. If a script does not contain such a cooky, then to avoid calling sh.exe, Perl uses the same algorithm as pdksh: if $ENV{EXECSHELL} is set, the script is given as the first argument to this command, if not set, then \"$ENV{COMSPEC} \/c\" is used (or a hardwired guess if $ENV{COMSPEC} is not set). When starting scripts directly, Perl uses exactly the same algorithm as for the search of script given by -S command-line option: it will look in the current directory, then on components of $ENV{PATH} using the following order of appended extensions: no extension, .cmd, .btm, .bat, .pl. Note that Perl will start to look for scripts only if OS\/2 cannot start the specified application, thus \"system 'blah'\" will not look for a script if there is an executable file blah.exe anywhere on \"PATH\". In other words, \"PATH\" is essentially searched twice: once by the OS for an executable, then by Perl for scripts. Note also that executable files on OS\/2 can have an arbitrary extension, but .exe will be automatically appended if no dot is present in the name. The workaround is as simple as that: since blah. and blah denote the same file (at list on FAT and HPFS file systems), to start an executable residing in file n:\/bin\/blah (no extension) give an argument \"n:\/bin\/blah.\" (dot appended) to system(). Perl will start PM programs from VIO (=text-mode) Perl process in a separate PM session; the opposite is not true: when you start a non-PM program from a PM Perl process, Perl would not run it in a separate session. If a separate session is desired, either ensure that shell will be used, as in \"system 'cmd \/c myprog'\", or start it using optional arguments to system() documented in \"OS2::Process\" module. This is considered to be a feature.","Process Name":"perlos2","Link":"https:\/\/linux.die.net\/man\/1\/perlos2"}},{"Process":{"Description":"This is a fully ported Perl for OS\/390 Version 2 Release 3, 5, 6, 7, 8, and 9. It may work on other versions or releases, but those are the ones we've tested it on. You may need to carry out some system configuration tasks before running the Configure script for Perl. Tools The z\/OS Unix Tools and Toys list may prove helpful and contains links to ports of much of the software helpful for building Perl. http:\/\/www-1.ibm.com\/servers\/eserver\/zseries\/zos\/unix\/bpxa1toy.html Unpacking Perl distribution on OS\/390 If using ftp remember to transfer the distribution in binary format. Gunzip\/gzip for OS\/390 is discussed at: http:\/\/www-1.ibm.com\/servers\/eserver\/zseries\/zos\/unix\/faq\/bpxqp1.html to extract an ASCII tar archive on OS\/390 , try this: pax -o to=IBM-1047,from=ISO8859-1 -r < latest.tar or zcat latest.tar.Z | pax -o to=IBM-1047,from=ISO8859-1 -r If you get lots of errors of the form tar: FSUM7171 ...: cannot set uid\/gid: EDC5139I Operation not permitted. you didn't read the above and tried to use tar instead of pax, you'll first have to remove the (now corrupt) perl directory rm -rf perl-... and then use pax. Setup and utilities for Perl on OS\/390 Be sure that your yacc installation is in place including any necessary parser template files. If you have not already done so then be sure to: cp \/samples\/yyparse.c \/etc This may also be a good time to ensure that your \/etc\/protocol file and either your \/etc\/resolv.conf or \/etc\/hosts files are in place. The IBM document that described such USS system setup issues was SC28-1890-07 \" OS\/390 UNIX System Services Planning\", in particular Chapter 6 on customizing the OE shell. GNU make for OS\/390 , which is recommended for the build of perl (as well as building CPAN modules and extensions), is available from the \"Tools\". Some people have reported encountering \"Out of memory!\" errors while trying to build Perl using GNU make binaries. If you encounter such trouble then try to download the source code kit and build GNU make from source to eliminate any such trouble. You might also find GNU make (as well as Perl and Apache) in the red-piece\/book \"Open Source Software for OS\/390 UNIX \", SG24-5944-00 from IBM . If instead of the recommended GNU make you would like to use the system supplied make program then be sure to install the default rules file properly via the shell command: cp \/samples\/startup.mk \/etc and be sure to also set the environment variable _C89_CCMODE=1 (exporting _C89_CCMODE=1 is also a good idea for users of GNU make). You might also want to have GNU groff for OS\/390 installed before running the \"make install\" step for Perl. There is a syntax error in the \/usr\/include\/sys\/socket.h header file that IBM supplies with USS V2R7, V2R8, and possibly V2R9. The problem with the header file is that near the definition of the SO_REUSEPORT constant there is a spurious extra '\/' character outside of a comment like so: #define SO_REUSEPORT    0x0200    \/* allow local address & port\n                                     reuse *\/                    \/ You could edit that header yourself to remove that last '\/', or you might note that Language Environment ( LE ) APAR PQ39997 describes the problem and PTF 's UQ46272 and UQ46271 are the (R8 at least) fixes and apply them. If left unattended that syntax error will turn up as an inability for Perl to build its \"Socket\" extension. For successful testing you may need to turn on the sticky bit for your world readable \/tmp directory if you have not already done so (see man chmod). Configure Perl on OS\/390 Once you've unpacked the distribution, run \"sh Configure\" (see INSTALL for a full discussion of the Configure options). There is a \"hints\" file for os390 that specifies the correct values for most things. Some things to watch out for include: \u2022 A message of the form: (I see you are using the Korn shell.  Some ksh's blow up on Configure,\nmainly on older exotic systems.  If yours does, try the Bourne shell instead.) is nothing to worry about at all. \u2022 Some of the parser default template files in \/samples are needed in \/etc. In particular be sure that you at least copy \/samples\/yyparse.c to \/etc before running Perl's Configure. This step ensures successful extraction of EBCDIC versions of parser files such as perly.c, perly.h, and x2p\/a2p.c. This has to be done before running Configure the first time. If you failed to do so then the easiest way to re-Configure Perl is to delete your misconfigured build root and re-extract the source from the tar ball. Then you must ensure that \/etc\/yyparse.c is properly in place before attempting to re-run Configure. \u2022 This port will support dynamic loading, but it is not selected by default. If you would like to experiment with dynamic loading then be sure to specify -Dusedl in the arguments to the Configure script. See the comments in hints\/os390.sh for more information on dynamic loading. If you build with dynamic loading then you will need to add the $archlibexp\/CORE directory to your LIBPATH environment variable in order for perl to work. See the config.sh file for the value of $archlibexp. If in trying to use Perl you see an error message similar to: CEE3501S The module libperl.dll was not found.\n        From entry point __dllstaticinit at compile unit offset +00000194 at then your LIBPATH does not have the location of libperl.x and either libperl.dll or libperl.so in it. Add that directory to your LIBPATH and proceed. \u2022 Do not turn on the compiler optimization flag \"-O\". There is a bug in either the optimizer or perl that causes perl to not work correctly when the optimizer is on. \u2022 Some of the configuration files in \/etc used by the networking APIs are either missing or have the wrong names. In particular, make sure that there's either an \/etc\/resolv.conf or an \/etc\/hosts, so that gethostbyname() works, and make sure that the file \/etc\/proto has been renamed to \/etc\/protocol ( NOT \/etc\/protocols, as used by other Unix systems). You may have to look for things like HOSTNAME and DOMAINORIGIN in the \"\/\/' SYS1 .TCPPARMS( TCPDATA )'\" PDS member in order to properly set up your \/etc networking files. Build, Test, Install Perl on OS\/390 Simply put: sh Configure\nmake\nmake test if everything looks ok (see the next section for test\/IVP diagnosis) then: make install this last step may or may not require UID=0 privileges depending on how you answered the questions that Configure asked and whether or not you have write access to the directories you specified. Build Anomalies with Perl on OS\/390 \"Out of memory!\" messages during the build of Perl are most often fixed by re building the GNU make utility for OS\/390 from a source code kit. Another memory limiting item to check is your MAXASSIZE parameter in your ' SYS1 .PARMLIB(BPXPRMxx)' data set (note too that as of V2R8 address space limits can be set on a per user ID basis in the USS segment of a RACF profile). People have reported successful builds of Perl with MAXASSIZE parameters as small as 503316480 (and it may be possible to build Perl with a MAXASSIZE smaller than that). Within USS your \/etc\/profile or $HOME\/.profile may limit your ulimit settings. Check that the following command returns reasonable values: ulimit -a To conserve memory you should have your compiler modules loaded into the Link Pack Area ( LPA\/ELPA ) rather than in a link list or step lib. If the c89 compiler complains of syntax errors during the build of the Socket extension then be sure to fix the syntax error in the system header \/usr\/include\/sys\/socket.h. Testing Anomalies with Perl on OS\/390 The \"make test\" step runs a Perl Verification Procedure, usually before installation. You might encounter STDERR messages even during a successful run of \"make test\". Here is a guide to some of the more commonly seen anomalies: \u2022 A message of the form: comp\/cpp.............ERROR CBC3191 .\/.301989890.c:1     The character $ is not a\n valid C source character.\nFSUM3065 The COMPILE step ended with return code 12.\nFSUM3017 Could not compile .301989890.c. Correct the errors and try again.\nok indicates that the t\/comp\/cpp.t test of Perl's -P command line switch has passed but that the particular invocation of c89 -E in the cpp script does not suppress the C compiler check of source code validity. \u2022 A message of the form: io\/openpid...........CEE5210S The signal SIGHUP was received.\nCEE5210S The signal SIGHUP was received.\nCEE5210S The signal SIGHUP was received.\nok indicates that the t\/io\/openpid.t test of Perl has passed but done so with extraneous messages on stderr from CEE . \u2022 A message of the form: lib\/ftmp-security....File::Temp::_gettemp: Parent directory (\/tmp\/) is not safe\n(sticky bit not set when world writable?) at lib\/ftmp-security.t line 100\nFile::Temp::_gettemp: Parent directory (\/tmp\/) is not safe (sticky bit not\nset when world writable?) at lib\/ftmp-security.t line 100\nok indicates a problem with the permissions on your \/tmp directory within the HFS . To correct that problem issue the command: chmod a+t \/tmp from an account with write access to the directory entry for \/tmp. \u2022 Out of Memory! Recent perl test suite is quite memory hunrgy. In addition to the comments above on memory limitations it is also worth checking for _CEE_RUNOPTS in your environment. Perl now has (in miniperlmain.c) a C #pragma to set CEE run options, but the environment variable wins. The C code asks for: #pragma runopts(HEAP(2M,500K,ANYWHERE,KEEP,8K,4K) STACK(,,ANY,) ALL31(ON)) The important parts of that are the second argument (the increment) to HEAP , and allowing the stack to be \"Above the (16M) line\". If the heap increment is too small then when perl (for example loading unicode\/Name.pl) tries to create a \"big\" (400K+) string it cannot fit in a single segment and you get \"Out of Memory!\" - even if there is still plenty of memory available. A related issue is use with perl's malloc. Perl's malloc uses \"sbrk()\" to get memory, and \"sbrk()\" is limited to the first allocation so in this case something like: HEAP(8M,500K,ANYWHERE,KEEP,8K,4K) is needed to get through the test suite. Installation Anomalies with Perl on OS\/390 The installman script will try to run on OS\/390 . There will be fewer errors if you have a roff utility installed. You can obtain GNU groff from the Redbook SG24-5944-00 ftp site. Usage Hints for Perl on OS\/390 When using perl on OS\/390 please keep in mind that the EBCDIC and ASCII character sets are different. See perlebcdic.pod for more on such character set issues. Perl builtin functions that may behave differently under EBCDIC are also mentioned in the perlport.pod document. Open Edition ( UNIX System Services) from V2R8 onward does support #!\/path\/to\/perl script invocation. There is a PTF available from IBM for V2R7 that will allow shell\/kernel support for #!. USS releases prior to V2R7 did not support the #! means of script invocation. If you are running V2R6 or earlier then see: head `whence perldoc` for an example of how to use the \"eval exec\" trick to ask the shell to have Perl run your scripts on those older releases of Unix System Services. If you are having trouble with square brackets then consider switching your rlogin or telnet client. Try to avoid older 3270 emulators and ISHELL for working with Perl on USS . Floating Point Anomalies with Perl on OS\/390 There appears to be a bug in the floating point implementation on S\/390 systems such that calling int() on the product of a number and a small magnitude number is not the same as calling int() on the quotient of that number and a large magnitude number. For example, in the following Perl code: my $x = 100000.0;\nmy $y = int($x * 1e-5) * 1e5; # '0'\nmy $z = int($x \/ 1e+5) * 1e5;  # '100000'\nprint \"\\$y is $y and \\$z is $z\\n\"; # $y is 0 and $z is 100000 Although one would expect the quantities $y and $z to be the same and equal to 100000 they will differ and instead will be 0 and 100000 respectively. The problem can be further examined in a roughly equivalent C program: #include <stdio.h>\n#include <math.h>\nmain()\n{\ndouble r1,r2;\ndouble x = 100000.0;\ndouble y = 0.0;\ndouble z = 0.0;\nx = 100000.0 * 1e-5;\nr1 = modf (x,&y);\nx = 100000.0 \/ 1e+5;\nr2 = modf (x,&z);\nprintf(\"y is %e and z is %e\\n\",y*1e5,z*1e5);\n\/* y is 0.000000e+00 and z is 1.000000e+05 (with c89) *\/\n} Modules and Extensions for Perl on OS\/390 Pure pure (that is non xs) modules may be installed via the usual: perl Makefile.PL\nmake\nmake test\nmake install If you built perl with dynamic loading capability then that would also be the way to build xs based extensions. However, if you built perl with the default static linking you can still build xs based extensions for OS\/390 but you will need to follow the instructions in ExtUtils::MakeMaker for building statically linked perl binaries. In the simplest configurations building a static perl + xs extension boils down to: perl Makefile.PL\nmake\nmake perl\nmake test\nmake install\nmake -f Makefile.aperl inst_perl MAP_TARGET=perl In most cases people have reported better results with GNU make rather than the system's \/bin\/make program, whether for plain modules or for xs based extensions. If the make process encounters trouble with either compilation or linking then try setting the _C89_CCMODE to 1. Assuming sh is your login shell then run: export _C89_CCMODE=1 If tcsh is your login shell then use the setenv command.","Process Name":"perlos390","Link":"https:\/\/linux.die.net\/man\/1\/perlos390"}},{"Process":{"Description":"This document describes various features of IBM 's OS\/400 operating system that will affect how Perl version 5 (hereafter just Perl) is compiled and\/or runs. By far the easiest way to build Perl for OS\/400 is to use the PASE (Portable Application Solutions Environment), for more information see http:\/\/www.iseries.ibm.com\/developer\/factory\/pase\/index.html This environment allows one to use AIX APIs while programming, and it provides a runtime that allows AIX binaries to execute directly on the PowerPC iSeries. Compiling Perl for OS\/400 PASE The recommended way to build Perl for the OS\/400 PASE is to build the Perl 5 source code (release 5.8.1 or later) under AIX . The trick is to give a special parameter to the Configure shell script when running it on AIX: sh Configure -DPASE ... The default installation directory of Perl under PASE is \/QOpenSys\/perl. This can be modified if needed with Configure parameter -Dprefix=\/some\/dir. Starting from OS\/400 V5R2 the IBM Visual Age compiler is supported on OS\/400 PASE , so it is possible to build Perl natively on OS\/400 . The easier way, however, is to compile in AIX , as just described. If you don't want to install the compiled Perl in AIX into \/QOpenSys (for packaging it before copying it to PASE ), you can use a Configure parameter: -Dinstallprefix=\/tmp\/QOpenSys\/perl. This will cause the \"make install\" to install everything into that directory, while the installed files still think they are (will be) in \/QOpenSys\/perl. If building natively on PASE , please do the build under the \/QOpenSys directory, since Perl is happier when built on a case sensitive filesystem. Installing Perl in OS\/400 PASE If you are compiling on AIX , simply do a \"make install\" on the AIX box. Once the install finishes, tar up the \/QOpenSys\/perl directory. Transfer the tarball to the OS\/400 using FTP with the following commands: > binary\n> site namefmt 1\n> put perl.tar \/QOpenSys Once you have it on, simply bring up a PASE shell and extract the tarball. If you are compiling in PASE , then \"make install\" is the only thing you will need to do. The default path for perl binary is \/QOpenSys\/perl\/bin\/perl. You'll want to symlink \/QOpenSys\/usr\/bin\/perl to this file so you don't have to modify your path. Using Perl in OS\/400 PASE Perl in PASE may be used in the same manner as you would use Perl on AIX . Scripts starting with #!\/usr\/bin\/perl should work if you have \/QOpenSys\/usr\/bin\/perl symlinked to your perl binary. This will not work if you've done a setuid\/setgid or have environment variable PASE_EXEC_QOPENSYS=\"N\". If you have V5R1, you'll need to get the latest PTFs to have this feature. Scripts starting with #!\/QOpenSys\/perl\/bin\/perl should always work. Known Problems When compiling in PASE , there is no \"oslevel\" command. Therefore, you may want to create a script called \"oslevel\" that echoes the level of AIX that your version of PASE runtime supports. If you're unsure, consult your documentation or use \"4.3.3.0\". If you have test cases that fail, check for the existence of spool files. The test case may be trying to use a syscall that is not implemented in PASE . To avoid the SIGILL , try setting the PASE_SYSCALL_NOSIGILL environment variable or have a handler for the SIGILL . If you can compile programs for PASE , run the config script and edit config.sh when it gives you the option. If you want to remove fchdir(), which isn't implement in V5R1, simply change the line that says: d_fchdir='define' to d_fchdir='undef' and then compile Perl. The places where fchdir() is used have alternatives for systems that do not have fchdir() available. Perl on ILE There exists a port of Perl to the ILE environment. This port, however, is based quite an old release of Perl, Perl 5.00502 (August 1998). (As of July 2002 the latest release of Perl is 5.8.0, and even 5.6.1 has been out since April 2001.) If you need to run Perl on ILE , though, you may need this older port: http:\/\/www.cpan.org\/ports\/#os400 Note that any Perl release later than 5.00502 has not been ported to ILE . If you need to use Perl in the ILE environment, you may want to consider using Qp2RunPase() to call the PASE version of Perl.","Process Name":"perlos400","Link":"https:\/\/linux.die.net\/man\/1\/perlos400"}},{"Process":{"Description":"WARNING : This tutorial describes the old-style thread model that was introduced in release 5.005. This model is deprecated, and has been removed for version 5.10. The interfaces described here were considered experimental, and are likely to be buggy. For information about the new interpreter threads (\"ithreads\") model, see the perlthrtut tutorial, and the threads and threads::shared modules. You are strongly encouraged to migrate any existing threads code to the new model as soon as possible.","Process Name":"perlothrtut","Link":"https:\/\/linux.die.net\/man\/1\/perlothrtut"}},{"Process":{"Description":"\"pack\" and \"unpack\" are two functions for transforming data according to a user-defined template, between the guarded way Perl stores values and some well-defined representation as might be required in the environment of a Perl program. Unfortunately, they're also two of the most misunderstood and most often overlooked functions that Perl provides. This tutorial will demystify them for you.","Process Name":"perlpacktut","Link":"https:\/\/linux.die.net\/man\/1\/perlpacktut"}},{"Process":{"Description":"This is an introduction to the use of performance and optimization techniques which can be used with particular reference to perl programs. While many perl developers have come from other languages, and can use their prior knowledge where appropriate, there are many other people who might benefit from a few perl specific pointers. If you want the condensed version, perhaps the best advice comes from the renowned Japanese Samurai, Miyamoto Musashi, who said: \"Do Not Engage in Useless Activity\" in 1645.","Process Name":"perlperf","Link":"https:\/\/linux.die.net\/man\/1\/perlperf"}},{"Process":{"Description":"These are a few notes describing features peculiar to Plan 9 Perl. As such, it is not intended to be a replacement for the rest of the Perl 5 documentation (which is both copious and excellent). If you have any questions to which you can't find answers in these man pages, contact Luther Huffman at lutherh@stratcom.com and we'll try to answer them. Invoking Perl Perl is invoked from the command line as described in perl. Most perl scripts, however, do have a first line such as \"#!\/usr\/local\/bin\/perl\". This is known as a shebang (shell-bang) statement and tells the OS shell where to find the perl interpreter. In Plan 9 Perl this statement should be \"#!\/bin\/perl\" if you wish to be able to directly invoke the script by its name. Alternatively, you may invoke perl with the command \"Perl\" instead of \"perl\". This will produce Acme-friendly error messages of the form \"filename:18\". Some scripts, usually identified with a *.PL extension, are self-configuring and are able to correctly create their own shebang path from config information located in Plan 9 Perl. These you won't need to be worried about. What's in Plan 9 Perl Although Plan 9 Perl currently only provides static loading, it is built with a number of useful extensions. These include Opcode, FileHandle, Fcntl, and POSIX . Expect to see others (and DynaLoading!) in the future. What's not in Plan 9 Perl As mentioned previously, dynamic loading isn't currently available nor is MakeMaker. Both are high-priority items. Perl5 Functions not currently supported in Plan 9 Perl Some, such as \"chown\" and \"umask\" aren't provided because the concept does not exist within Plan 9. Others, such as some of the socket-related functions, simply haven't been written yet. Many in the latter category may be supported in the future. The functions not currently implemented include: chown, chroot, dbmclose, dbmopen, getsockopt,\nsetsockopt, recvmsg, sendmsg, getnetbyname,\ngetnetbyaddr, getnetent, getprotoent, getservent,\nsethostent, setnetent, setprotoent, setservent,\nendservent, endnetent, endprotoent, umask There may be several other functions that have undefined behavior so this list shouldn't be considered complete. Signals in Plan 9 Perl For compatibility with perl scripts written for the Unix environment, Plan 9 Perl uses the POSIX signal emulation provided in Plan 9's ANSI POSIX Environment ( APE ). Signal stacking isn't supported. The signals provided are: SIGHUP, SIGINT, SIGQUIT, SIGILL, SIGABRT,\nSIGFPE, SIGKILL, SIGSEGV, SIGPIPE, SIGPIPE, SIGALRM,\nSIGTERM, SIGUSR1, SIGUSR2, SIGCHLD, SIGCONT,\nSIGSTOP, SIGTSTP, SIGTTIN, SIGTTOU","Process Name":"perlplan9","Link":"https:\/\/linux.die.net\/man\/1\/perlplan9"}},{"Process":{"Description":"Pod is a simple-to-use markup language used for writing documentation for Perl, Perl programs, and Perl modules. Translators are available for converting Pod to various formats like plain text, HTML , man pages, and more. Pod markup consists of three basic kinds of paragraphs: ordinary, verbatim, and command. Ordinary Paragraph Most paragraphs in your documentation will be ordinary blocks of text, like this one. You can simply type in your text without any markup whatsoever, and with just a blank line before and after. When it gets formatted, it will undergo minimal formatting, like being rewrapped, probably put into a proportionally spaced font, and maybe even justified. You can use formatting codes in ordinary paragraphs, for bold, italic, \"code-style\", hyperlinks, and more. Such codes are explained in the \"Formatting Codes\" section, below. Verbatim Paragraph Verbatim paragraphs are usually used for presenting a codeblock or other text which does not require any special parsing or formatting, and which shouldn't be wrapped. A verbatim paragraph is distinguished by having its first character be a space or a tab. (And commonly, all its lines begin with spaces and\/or tabs.) It should be reproduced exactly, with tabs assumed to be on 8-column boundaries. There are no special formatting codes, so you can't italicize or anything like that. A \\ means \\, and nothing else. Command Paragraph A command paragraph is used for special treatment of whole chunks of text, usually as headings or parts of lists. All command paragraphs (which are typically only one line long) start with \"=\", followed by an identifier, followed by arbitrary text that the command can use however it pleases. Currently recognized commands are =pod\n=head1 Heading Text\n=head2 Heading Text\n=head3 Heading Text\n=head4 Heading Text\n=over indentlevel\n=item stuff\n=back\n=begin format\n=end format\n=for format text...\n=encoding type\n=cut To explain them each in detail: \"=head1 Heading Text \" \"=head2 Heading Text \" \"=head3 Heading Text \" \"=head4 Heading Text \" Head1 through head4 produce headings, head1 being the highest level. The text in the rest of this paragraph is the content of the heading. For example: =head2 Object Attributes The text \"Object Attributes\" comprises the heading there. (Note that head3 and head4 are recent additions, not supported in older Pod translators.) The text in these heading commands can use formatting codes, as seen here: =head2 Possible Values for C<$\/> Such commands are explained in the \"Formatting Codes\" section, below. \"=over indentlevel \" \"=item stuff... \" \"=back\" Item, over, and back require a little more explanation: \"=over\" starts a region specifically for the generation of a list using \"=item\" commands, or for indenting (groups of) normal paragraphs. At the end of your list, use \"=back\" to end it. The indentlevel option to \"=over\" indicates how far over to indent, generally in ems (where one em is the width of an \"M\" in the document's base font) or roughly comparable units; if there is no indentlevel option, it defaults to four. (And some formatters may just ignore whatever indentlevel you provide.) In the stuff in \"=item stuff... \", you may use formatting codes, as seen here: =item Using C<$|> to Control Buffering Such commands are explained in the \"Formatting Codes\" section, below. Note also that there are some basic rules to using \"=over\" ... \"=back\" regions: \u2022 Don't use \"=item\"s outside of an \"=over\" ... \"=back\" region. \u2022 The first thing after the \"=over\" command should be an \"=item\", unless there aren't going to be any items at all in this \"=over\" ... \"=back\" region. \u2022 Don't put \"=headn\" commands inside an \"=over\" ... \"=back\" region. \u2022 And perhaps most importantly, keep the items consistent: either use \"=item *\" for all of them, to produce bullets; or use \"=item 1.\", \"=item 2.\", etc., to produce numbered lists; or use \"=item foo\", \"=item bar\", etc. -- namely, things that look nothing like bullets or numbers. If you start with bullets or numbers, stick with them, as formatters use the first \"=item\" type to decide how to format the list. \"=cut\" To end a Pod block, use a blank line, then a line beginning with \"=cut\", and a blank line after it. This lets Perl (and the Pod formatter) know that this is where Perl code is resuming. (The blank line before the \"=cut\" is not technically necessary, but many older Pod processors require it.) \"=pod\" The \"=pod\" command by itself doesn't do much of anything, but it signals to Perl (and Pod formatters) that a Pod block starts here. A Pod block starts with any command paragraph, so a \"=pod\" command is usually used just when you want to start a Pod block with an ordinary paragraph or a verbatim paragraph. For example: =item stuff()\n\nThis function does stuff.\n\n=cut\n\nsub stuff {\n  ...\n}\n\n=pod\n\nRemember to check its return value, as in:\n\n  stuff() || die \"Couldn't do stuff!\";\n\n=cut \"=begin formatname \" \"=end formatname \" \"=for formatname text... \" For, begin, and end will let you have regions of text\/code\/data that are not generally interpreted as normal Pod text, but are passed directly to particular formatters, or are otherwise special. A formatter that can use that format will use the region, otherwise it will be completely ignored. A command \"=begin formatname\", some paragraphs, and a command \"=end formatname\", mean that the text\/data in between is meant for formatters that understand the special format called formatname. For example, =begin html\n\n<hr> <img src=\"thang.png\">\n<p> This is a raw HTML paragraph <\/p>\n\n=end html The command \"=for formatname text...\" specifies that the remainder of just this paragraph (starting right after formatname) is in that special format. =for html <hr> <img src=\"thang.png\">\n<p> This is a raw HTML paragraph <\/p> This means the same thing as the above \"=begin html\" ... \"=end html\" region. That is, with \"=for\", you can have only one paragraph's worth of text (i.e., the text in \"=foo targetname text...\"), but with \"=begin targetname\" ... \"=end targetname\", you can have any amount of stuff inbetween. (Note that there still must be a blank line after the \"=begin\" command and a blank line before the \"=end\" command. Here are some examples of how to use these: =begin html\n\n<br>Figure 1.<br><IMG SRC=\"figure1.png\"><br>\n\n=end html\n\n=begin text\n\n  ---------------\n  |  foo        |\n  |        bar  |\n  ---------------\n\n^^^^ Figure 1. ^^^^\n\n=end text Some format names that formatters currently are known to accept include \"roff\", \"man\", \"latex\", \"tex\", \"text\", and \"html\". (Some formatters will treat some of these as synonyms.) A format name of \"comment\" is common for just making notes (presumably to yourself) that won't appear in any formatted version of the Pod document: =for comment\nMake sure that all the available options are documented! Some formatnames will require a leading colon (as in \"=for :formatname\", or \"=begin :formatname\" ... \"=end :formatname\"), to signal that the text is not raw data, but instead is Pod text (i.e., possibly containing formatting codes) that's just not for normal formatting (e.g., may not be a normal-use paragraph, but might be for formatting as a footnote). \"=encoding encodingname \" This command is used for declaring the encoding of a document. Most users won't need this; but if your encoding isn't US-ASCII or Latin-1, then put a \"=encoding encodingname \" command early in the document so that pod formatters will know how to decode the document. For encodingname, use a name recognized by the Encode::Supported module. Examples: =encoding utf8\n\n=encoding koi8-r\n\n=encoding ShiftJIS\n\n=encoding big5 \"=encoding\" affects the whole document, and must occur only once. And don't forget, when using any other command, that the command lasts up until the end of its paragraph, not its line. So in the examples below, you can see that every command needs the blank line after it, to end its paragraph. Some examples of lists include: =over\n\n=item *\n\nFirst item\n\n=item *\n\nSecond item\n\n=back\n\n=over\n\n=item Foo()\n\nDescription of Foo function\n\n=item Bar()\n\nDescription of Bar function\n\n=back Formatting Codes In ordinary paragraphs and in some command paragraphs, various formatting codes (a.k.a. \"interior sequences\") can be used: \"I<text>\" -- italic text Used for emphasis (\" \"be I<careful!>\"\") and parameters (\" \"redo I<LABEL>\"\") \"B<text>\" -- bold text Used for switches (\" \"perl's B<-n> switch\"\"), programs (\" \"some systems provide a B<chfn> for that\"\"), emphasis (\" \"be B<careful!>\"\"), and so on (\" \"and that feature is known as B<autovivification>\"\"). \"C<code>\" -- code text Renders code in a typewriter font, or gives some other indication that this represents program text (\" \"C<gmtime($^T)>\"\") or some other form of computerese (\" \"C<drwxr-xr-x>\"\"). \"L<name>\" -- a hyperlink There are various syntaxes, listed below. In the syntaxes given, \"text\", \"name\", and \"section\" cannot contain the characters '\/' and '|'; and any '<' or '>' should be matched. \u2022 \"L<name>\" Link to a Perl manual page (e.g., \"L<Net::Ping>\"). Note that \"name\" should not contain spaces. This syntax is also occasionally used for references to UNIX man pages, as in \"L<crontab(5)>\". \u2022 \"L<name\/\"sec\">\" or \"L<name\/sec>\" Link to a section in other manual page. E.g., \"L<perlsyn\/\"For Loops\">\" \u2022 \"L<\/\"sec\">\" or \"L<\/sec>\" Link to a section in this manual page. E.g., \"L<\/\"Object Methods\">\" A section is started by the named heading or item. For example, \"L<perlvar\/$.>\" or \"L<perlvar\/\"$.\">\" both link to the section started by \" \"=item $.\"\" in perlvar. And \"L<perlsyn\/For Loops>\" or \"L<perlsyn\/\"For Loops\">\" both link to the section started by \" \"=head2 For Loops\"\" in perlsyn. To control what text is used for display, you use \"\"L<text|...>\"\", as in: \u2022 \"L<text|name>\" Link this text to that manual page. E.g., \"L<Perl Error Messages|perldiag>\" \u2022 \"L<text|name\/\"sec\">\" or \"L<text|name\/sec>\" Link this text to that section in that manual page. E.g., \"L<postfix \"if\"|perlsyn\/\"Statement Modifiers\">\" \u2022 \"L<text|\/\"sec\">\" or \"L<text|\/sec>\" or \"L<text|\"sec\">\" Link this text to that section in this manual page. E.g., \"L<the various attributes|\/\"Member Data\">\" Or you can link to a web page: \u2022 \"L<scheme:...>\" \"L<text|scheme:...>\" Links to an absolute URL . For example, \"L<http:\/\/www.perl.org\/>\" or \"L<The Perl Home Page|http:\/\/www.perl.org\/>\". \"E<escape>\" -- a character escape Very similar to HTML\/XML \"& foo ;\" \"entity references\": \u2022 \"E<lt>\" -- a literal < (less than) \u2022 \"E<gt>\" -- a literal > (greater than) \u2022 \"E<verbar>\" -- a literal | (vertical bar) \u2022 \"E<sol>\" = a literal \/ (solidus) The above four are optional except in other formatting codes, notably \"L<...>\", and when preceded by a capital letter. \u2022 \"E<htmlname>\" Some non-numeric HTML entity name, such as \"E<eacute>\", meaning the same thing as \"&eacute;\" in HTML -- i.e., a lowercase e with an acute (\/-shaped) accent. \u2022 \"E<number>\" The ASCII\/Latin-1\/Unicode character with that number. A leading \"0x\" means that number is hex, as in \"E<0x201E>\". A leading \"0\" means that number is octal, as in \"E<075>\". Otherwise number is interpreted as being in decimal, as in \"E<181>\". Note that older Pod formatters might not recognize octal or hex numeric escapes, and that many formatters cannot reliably render characters above 255. (Some formatters may even have to use compromised renderings of Latin-1 characters, like rendering \"E<eacute>\" as just a plain \"e\".) \"F<filename>\" -- used for filenames Typically displayed in italics. Example: \" \"F<.cshrc>\"\" \"S<text>\" -- text contains non-breaking spaces This means that the words in text should not be broken across lines. Example: \"S<$x ? $y : $z>\". \"X<topic name>\" -- an index entry This is ignored by most formatters, but some may use it for building indexes. It always renders as empty-string. Example: \"X<absolutizing relative URLs>\" \"Z<>\" -- a null (zero-effect) formatting code This is rarely used. It's one way to get around using an E<...> code sometimes. For example, instead of \" \"NE<lt>3\"\" (for \"N<3\") you could write \" \"NZ<><3\"\" (the \"Z<>\" breaks up the \"N\" and the \"<\" so they can't be considered the part of a (fictitious) \"N<...>\" code. Most of the time, you will need only a single set of angle brackets to delimit the beginning and end of formatting codes. However, sometimes you will want to put a real right angle bracket (a greater-than sign, '>') inside of a formatting code. This is particularly common when using a formatting code to provide a different font-type for a snippet of code. As with all things in Perl, there is more than one way to do it. One way is to simply escape the closing bracket using an \"E\" code: C<$a E<lt>=E<gt> $b> This will produce: \" \"$a <=> $b\"\" A more readable, and perhaps more \"plain\" way is to use an alternate set of delimiters that doesn't require a single \">\" to be escaped. With the Pod formatters that are standard starting with perl5.5.660, doubled angle brackets (\"<<\" and \">>\") may be used if and only if there is whitespace right after the opening delimiter and whitespace right before the closing delimiter! For example, the following will do the trick: C<< $a <=> $b >> In fact, you can use as many repeated angle-brackets as you like so long as you have the same number of them in the opening and closing delimiters, and make sure that whitespace immediately follows the last '<' of the opening delimiter, and immediately precedes the first '>' of the closing delimiter. (The whitespace is ignored.) So the following will also work: C<<< $a <=> $b >>>\nC<<<<  $a <=> $b     >>>> And they all mean exactly the same as this: C<$a E<lt>=E<gt> $b> As a further example, this means that if you wanted to put these bits of code in \"C\" (code) style: open(X, \">>thing.dat\") || die $!\n$foo->bar(); you could do it like so: C<<< open(X, \">>thing.dat\") || die $! >>>\nC<< $foo->bar(); >> which is presumably easier to read than the old way: C<open(X, \"E<gt>E<gt>thing.dat\") || die $!>\nC<$foo-E<gt>bar();> This is currently supported by pod2text (Pod::Text), pod2man (Pod::Man), and any other pod2xxx or Pod::Xxxx translators that use Pod::Parser 1.093 or later, or Pod::Tree 1.02 or later. The Intent The intent is simplicity of use, not power of expression. Paragraphs look like paragraphs (block format), so that they stand out visually, and so that I could run them through \"fmt\" easily to reformat them (that's F7 in my version of vi, or Esc Q in my version of emacs). I wanted the translator to always leave the \"'\" and \"`\" and \"\"\" quotes alone, in verbatim mode, so I could slurp in a working program, shift it over four spaces, and have it print out, er, verbatim. And presumably in a monospace font. The Pod format is not necessarily sufficient for writing a book. Pod is just meant to be an idiot-proof common source for nroff, HTML , TeX, and other markup languages, as used for online documentation. Translators exist for pod2text, pod2html, pod2man (that's for nroff(1) and troff(1)), pod2latex, and pod2fm. Various others are available in CPAN . Embedding Pods in Perl Modules You can embed Pod documentation in your Perl modules and scripts. Start your documentation with an empty line, a \"=head1\" command at the beginning, and end it with a \"=cut\" command and an empty line. Perl will ignore the Pod text. See any of the supplied library modules for examples. If you're going to put your Pod at the end of the file, and you're using an __END__ or __DATA__ cut mark, make sure to put an empty line there before the first Pod command. __END__\n\n=head1 NAME\n\nTime::Local - efficiently compute time from local and GMT time Without that empty line before the \"=head1\", many translators wouldn't have recognized the \"=head1\" as starting a Pod block. Hints for Writing Pod \u2022 The podchecker command is provided for checking Pod syntax for errors and warnings. For example, it checks for completely blank lines in Pod blocks and for unknown commands and formatting codes. You should still also pass your document through one or more translators and proofread the result, or print out the result and proofread that. Some of the problems found may be bugs in the translators, which you may or may not wish to work around. \u2022 If you're more familiar with writing in HTML than with writing in Pod, you can try your hand at writing documentation in simple HTML , and converting it to Pod with the experimental Pod::HTML2Pod module, (available in CPAN ), and looking at the resulting code. The experimental Pod::PXML module in CPAN might also be useful. \u2022 Many older Pod translators require the lines before every Pod command and after every Pod command (including \"=cut\"!) to be a blank line. Having something like this: # - - - - - - - - - - - -\n=item $firecracker->boom()\n\nThis noisily detonates the firecracker object.\n=cut\nsub boom {\n... ...will make such Pod translators completely fail to see the Pod block at all. Instead, have it like this: # - - - - - - - - - - - -\n\n=item $firecracker->boom()\n\nThis noisily detonates the firecracker object.\n\n=cut\n\nsub boom {\n... \u2022 Some older Pod translators require paragraphs (including command paragraphs like \"=head2 Functions\") to be separated by completely empty lines. If you have an apparently empty line with some spaces on it, this might not count as a separator for those translators, and that could cause odd formatting. \u2022 Older translators might add wording around an L<> link, so that \"L<Foo::Bar>\" may become \"the Foo::Bar manpage\", for example. So you shouldn't write things like \"the L<foo> documentation\", if you want the translated document to read sensibly -- instead write \"the L<Foo::Bar|Foo::Bar> documentation\" or \"L<the Foo::Bar documentation|Foo::Bar>\", to control how the link comes out. \u2022 Going past the 70th column in a verbatim block might be ungracefully wrapped by some formatters.","Process Name":"perlpod","Link":"https:\/\/linux.die.net\/man\/1\/perlpod"}},{"Process":{"Description":"This document is detailed notes on the Pod markup language. Most people will only have to read perlpod to know how to write in Pod, but this document may answer some incidental questions to do with parsing and rendering Pod. In this document, \"must\" \/ \"must not\", \"should\" \/ \"should not\", and \"may\" have their conventional (cf. RFC 2119) meanings: \"X must do Y\" means that if X doesn't do Y, it's against this specification, and should really be fixed. \"X should do Y\" means that it's recommended, but X may fail to do Y, if there's a good reason. \"X may do Y\" is merely a note that X can do Y at will (although it is up to the reader to detect any connotation of \"and I think it would be nice if X did Y\" versus \"it wouldn't really bother me if X did Y\"). Notably, when I say \"the parser should do Y\", the parser may fail to do Y, if the calling application explicitly requests that the parser not do Y. I often phrase this as \"the parser should, by default, do Y.\" This doesn't require the parser to provide an option for turning off whatever feature Y is (like expanding tabs in verbatim paragraphs), although it implicates that such an option may be provided.","Process Name":"perlpodspec","Link":"https:\/\/linux.die.net\/man\/1\/perlpodspec"}},{"Process":{"Description":"Perl runs on numerous operating systems. While most of them share much in common, they also have their own unique features. This document is meant to help you to find out what constitutes portable Perl code. That way once you make a decision to write portably, you know where the lines are drawn, and you can stay within them. There is a tradeoff between taking full advantage of one particular type of computer and taking advantage of a full range of them. Naturally, as you broaden your range and become more diverse, the common factors drop, and you are left with an increasingly smaller area of common ground in which you can operate to accomplish a particular task. Thus, when you begin attacking a problem, it is important to consider under which part of the tradeoff curve you want to operate. Specifically, you must decide whether it is important that the task that you are coding have the full generality of being portable, or whether to just get the job done right now. This is the hardest choice to be made. The rest is easy, because Perl provides many choices, whichever way you want to approach your problem. Looking at it another way, writing portable code is usually about willfully limiting your available choices. Naturally, it takes discipline and sacrifice to do that. The product of portability and convenience may be a constant. You have been warned. Be aware of two important points: Not all Perl programs have to be portable There is no reason you should not use Perl as a language to glue Unix tools together, or to prototype a Macintosh application, or to manage the Windows registry. If it makes no sense to aim for portability for one reason or another in a given program, then don't bother. Nearly all of Perl already is portable Don't be fooled into thinking that it is hard to create portable Perl code. It isn't. Perl tries its level-best to bridge the gaps between what's available on different platforms, and all the means available to use those features. Thus almost all Perl code runs on any machine without modification. But there are some significant issues in writing portable code, and this document is entirely about those issues. Here's the general rule: When you approach a task commonly done using a whole range of platforms, think about writing portable code. That way, you don't sacrifice much by way of the implementation choices you can avail yourself of, and at the same time you can give your users lots of platform choices. On the other hand, when you have to take advantage of some unique feature of a particular platform, as is often the case with systems programming (whether for Unix, Windows, Mac OS , VMS , etc.), consider writing platform-specific code. When the code will run on only two or three operating systems, you may need to consider only the differences of those particular systems. The important thing is to decide where the code will run and to be deliberate in your decision. The material below is separated into three main sections: main issues of portability (\" ISSUES \"), platform-specific issues (\" PLATFORMS \"), and built-in perl functions that behave differently on various ports (\" FUNCTION IMPLEMENTATIONS \"). This information should not be considered complete; it includes possibly transient information about idiosyncrasies of some of the ports, almost all of which are in a state of constant evolution. Thus, this material should be considered a perpetual work in progress (\"<IMG SRC=\"yellow_sign.gif\" ALT=\"Under Construction\">\").","Process Name":"perlport","Link":"https:\/\/linux.die.net\/man\/1\/perlport"}},{"Process":{"Description":"A pragma is a module which influences some aspect of the compile time or run time behaviour of Perl, such as \"strict\" or \"warnings\". With Perl 5.10 you are no longer limited to the built in pragmata; you can now create user pragmata that modify the behaviour of user functions within a lexical scope.","Process Name":"perlpragma","Link":"https:\/\/linux.die.net\/man\/1\/perlpragma"}},{"Process":{"Description":"As of perl5.7.2 all tests pass under: QNX 4.24G\nWatcom 10.6 with Beta\/970211.wcc.update.tar.F\nsocket3r.lib Nov21 1996. As of perl5.8.1 there is at least one test still failing. Some tests may complain under known circumstances. See below and hints\/qnx.sh for more information. Under QNX 6.2.0 there are still a few tests which fail. See below and hints\/qnx.sh for more information. Required Software for Compiling Perl on QNX4 As with many unix ports, this one depends on a few \"standard\" unix utilities which are not necessarily standard for QNX4 . \/bin\/sh This is used heavily by Configure and then by perl itself. QNX4 's version is fine, but Configure will choke on the 16-bit version, so if you are running QNX 4.22, link \/bin\/sh to \/bin32\/ksh ar This is the standard unix library builder. We use wlib. With Watcom 10.6, when wlib is linked as \"ar\", it behaves like ar and all is fine. Under 9.5, a cover is required. One is included in ..\/qnx nm This is used (optionally) by configure to list the contents of libraries. I will generate a cover function on the fly in the UU directory. cpp Configure and perl need a way to invoke a C preprocessor. I have created a simple cover for cc which does the right thing. Without this, Configure will create its own wrapper which works, but it doesn't handle some of the command line arguments that perl will throw at it. make You really need GNU make to compile this. GNU make ships by default with QNX 4.23, but you can get it from quics for earlier versions. Outstanding Issues with Perl on QNX4 There is no support for dynamically linked libraries in QNX4 . If you wish to compile with the Socket extension, you need to have the TCP\/IP toolkit, and you need to make sure that -lsocket locates the correct copy of socket3r.lib. Beware that the Watcom compiler ships with a stub version of socket3r.lib which has very little functionality. Also beware the order in which wlink searches directories for libraries. You may have \/usr\/lib\/socket3r.lib pointing to the correct library, but wlink may pick up \/usr\/watcom\/10.6\/usr\/lib\/socket3r.lib instead. Make sure they both point to the correct library, that is, \/usr\/tcptk\/current\/usr\/lib\/socket3r.lib. The following tests may report errors under QNX4: ext\/Cwd\/Cwd.t will complain if 'pwd' and cwd don't give the same results. cwd calls 'fullpath -t', so if you cd 'fullpath -t' before running the test, it will pass. lib\/File\/Find\/taint.t will complain if '.' is in your PATH . The PATH test is triggered because cwd calls 'fullpath -t'. ext\/IO\/lib\/IO\/t\/io_sock.t: Subtests 14 and 22 are skipped due to the fact that the functionality to read back the non-blocking status of a socket is not implemented in QNX 's TCP\/IP . This has been reported to QNX and it may work with later versions of TCP\/IP . t\/io\/tell.t: Subtest 27 is failing. We are still investigating. QNX auxiliary files The files in the \"qnx\" directory are: qnx\/ar A script that emulates the standard unix archive (aka library) utility. Under Watcom 10.6, ar is linked to wlib and provides the expected interface. With Watcom 9.5, a cover function is required. This one is fairly crude but has proved adequate for compiling perl. qnx\/cpp A script that provides C preprocessing functionality. Configure can generate a similar cover, but it doesn't handle all the command-line options that perl throws at it. This might be reasonably placed in \/usr\/local\/bin. Outstanding issues with perl under QNX6 The following tests are still failing for Perl 5.8.1 under QNX 6.2.0: op\/sprintf.........................FAILED at test 91\nlib\/Benchmark......................FAILED at test 26 This is due to a bug in the C library's printf routine. printf(\"'%e'\", 0. ) produces '0.000000e+0', but ANSI requires '0.000000e+00'. QNX has acknowledged the bug.","Process Name":"perlqnx","Link":"https:\/\/linux.die.net\/man\/1\/perlqnx"}},{"Process":{"Description":"This page describes the syntax of regular expressions in Perl. If you haven't used regular expressions before, a quick-start introduction is available in perlrequick, and a longer tutorial introduction is available in perlretut. For reference on how regular expressions are used in matching operations, plus various examples of the same, see discussions of \"m\/\/\", \"s\/\/\/\", \"qr\/\/\" and \"??\" in \"Regexp Quote-Like Operators\" in perlop. Modifiers Matching operations can have various modifiers. Modifiers that relate to the interpretation of the regular expression inside are listed below. Modifiers that alter the way a regular expression is used by Perl are detailed in \"Regexp Quote-Like Operators\" in perlop and \"Gory details of parsing quoted constructs\" in perlop. m Treat string as multiple lines. That is, change \"^\" and \"$\" from matching the start or end of the string to matching the start or end of any line anywhere within the string. s Treat string as single line. That is, change \".\" to match any character whatsoever, even a newline, which normally it would not match. Used together, as \/ms, they let the \".\" match any character whatsoever, while still allowing \"^\" and \"$\" to match, respectively, just after and just before newlines within the string. i Do case-insensitive pattern matching. If \"use locale\" is in effect, the case map is taken from the current locale. See perllocale. x Extend your pattern's legibility by permitting whitespace and comments. p Preserve the string matched such that ${^PREMATCH}, {$^MATCH}, and ${^POSTMATCH} are available for use after matching. g and c Global matching, and keep the Current position after failed matching. Unlike i, m, s and x, these two flags affect the way the regex is used rather than the regex itself. See \"Using regular expressions in Perl\" in perlretut for further explanation of the g and c modifiers. These are usually written as \"the \"\/x\" modifier\", even though the delimiter in question might not really be a slash. Any of these modifiers may also be embedded within the regular expression itself using the \"(?...)\" construct. See below. The \"\/x\" modifier itself needs a little more explanation. It tells the regular expression parser to ignore whitespace that is neither backslashed nor within a character class. You can use this to break up your regular expression into (slightly) more readable parts. The \"#\" character is also treated as a metacharacter introducing a comment, just as in ordinary Perl code. This also means that if you want real whitespace or \"#\" characters in the pattern (outside a character class, where they are unaffected by \"\/x\"), then you'll either have to escape them (using backslashes or \"\\Q...\\E\") or encode them using octal or hex escapes. Taken together, these features go a long way towards making Perl's regular expressions more readable. Note that you have to be careful not to include the pattern delimiter in the comment--perl has no way of knowing you did not intend to close the pattern early. See the C-comment deletion code in perlop. Also note that anything inside a \"\\Q...\\E\" stays unaffected by \"\/x\". Regular Expressions Metacharacters The patterns used in Perl pattern matching evolved from those supplied in the Version 8 regex routines. (The routines are derived (distantly) from Henry Spencer's freely redistributable reimplementation of the V8 routines.) See \"Version 8 Regular Expressions\" for details. In particular the following metacharacters have their standard egrep-ish meanings: \\   Quote the next metacharacter\n^   Match the beginning of the line\n.   Match any character (except newline)\n$   Match the end of the line (or before newline at the end)\n|   Alternation\n()  Grouping\n[]  Character class By default, the \"^\" character is guaranteed to match only the beginning of the string, the \"$\" character only the end (or before the newline at the end), and Perl does certain optimizations with the assumption that the string contains only one line. Embedded newlines will not be matched by \"^\" or \"$\". You may, however, wish to treat a string as a multi-line buffer, such that the \"^\" will match after any newline within the string (except if the newline is the last character in the string), and \"$\" will match before any newline. At the cost of a little more overhead, you can do this by using the \/m modifier on the pattern match operator. (Older programs did this by setting $*, but this practice has been removed in perl 5.9.) To simplify multi-line substitutions, the \".\" character never matches a newline unless you use the \"\/s\" modifier, which in effect tells Perl to pretend the string is a single line--even if it isn't. Quantifiers The following standard quantifiers are recognized: *      Match 0 or more times\n+      Match 1 or more times\n?      Match 1 or 0 times\n{n}    Match exactly n times\n{n,}   Match at least n times\n{n,m}  Match at least n but not more than m times (If a curly bracket occurs in any other context, it is treated as a regular character. In particular, the lower bound is not optional.) The \"*\" quantifier is equivalent to \"{0,}\", the \"+\" quantifier to \"{1,}\", and the \"?\" quantifier to \"{0,1}\". n and m are limited to integral values less than a preset limit defined when perl is built. This is usually 32766 on the most common platforms. The actual limit can be seen in the error message generated by code such as this: $_ **= $_ , \/ {$_} \/ for 2 .. 42; By default, a quantified subpattern is \"greedy\", that is, it will match as many times as possible (given a particular starting location) while still allowing the rest of the pattern to match. If you want it to match the minimum number of times possible, follow the quantifier with a \"?\". Note that the meanings don't change, just the \"greediness\": *?     Match 0 or more times, not greedily\n+?     Match 1 or more times, not greedily\n??     Match 0 or 1 time, not greedily\n{n}?   Match exactly n times, not greedily\n{n,}?  Match at least n times, not greedily\n{n,m}? Match at least n but not more than m times, not greedily By default, when a quantified subpattern does not allow the rest of the overall pattern to match, Perl will backtrack. However, this behaviour is sometimes undesirable. Thus Perl provides the \"possessive\" quantifier form as well. *+     Match 0 or more times and give nothing back\n++     Match 1 or more times and give nothing back\n?+     Match 0 or 1 time and give nothing back\n{n}+   Match exactly n times and give nothing back (redundant)\n{n,}+  Match at least n times and give nothing back\n{n,m}+ Match at least n but not more than m times and give nothing back For instance, 'aaaa' =~ \/a++a\/ will never match, as the \"a++\" will gobble up all the \"a\"'s in the string and won't leave any for the remaining part of the pattern. This feature can be extremely useful to give perl hints about where it shouldn't backtrack. For instance, the typical \"match a double-quoted string\" problem can be most efficiently performed when written as: \/\"(?:[^\"\\\\]++|\\\\.)*+\"\/ as we know that if the final quote does not match, backtracking will not help. See the independent subexpression \"(?>...)\" for more details; possessive quantifiers are just syntactic sugar for that construct. For instance the above example could also be written as follows: \/\"(?>(?:(?>[^\"\\\\]+)|\\\\.)*)\"\/ Escape sequences Because patterns are processed as double quoted strings, the following also work: \\t          tab                   (HT, TAB)\n\\n          newline               (LF, NL)\n\\r          return                (CR)\n\\f          form feed             (FF)\n\\a          alarm (bell)          (BEL)\n\\e          escape (think troff)  (ESC)\n\\033        octal char            (example: ESC)\n\\x1B        hex char              (example: ESC)\n\\x{263a}    long hex char         (example: Unicode SMILEY)\n\\cK         control char          (example: VT)\n\\N{name}    named Unicode character\n\\l          lowercase next char (think vi)\n\\u          uppercase next char (think vi)\n\\L          lowercase till \\E (think vi)\n\\U          uppercase till \\E (think vi)\n\\E          end case modification (think vi)\n\\Q          quote (disable) pattern metacharacters till \\E If \"use locale\" is in effect, the case map used by \"\\l\", \"\\L\", \"\\u\" and \"\\U\" is taken from the current locale. See perllocale. For documentation of \"\\N{name}\", see charnames. You cannot include a literal \"$\" or \"@\" within a \"\\Q\" sequence. An unescaped \"$\" or \"@\" interpolates the corresponding variable, while escaping will cause the literal string \"\\$\" to be matched. You'll need to write something like \"m\/\\Quser\\E\\@\\Qhost\/\". Character Classes and other Special Escapes In addition, Perl defines the following: \\w       Match a \"word\" character (alphanumeric plus \"_\")\n\\W       Match a non-\"word\" character\n\\s       Match a whitespace character\n\\S       Match a non-whitespace character\n\\d       Match a digit character\n\\D       Match a non-digit character\n\\pP      Match P, named property.  Use \\p{Prop} for longer names.\n\\PP      Match non-P\n\\X       Match eXtended Unicode \"combining character sequence\",\n         equivalent to (?>\\PM\\pM*)\n\\C       Match a single C char (octet) even under Unicode.\n         NOTE: breaks up characters into their UTF-8 bytes,\n         so you may end up with malformed pieces of UTF-8.\n         Unsupported in lookbehind.\n\\1       Backreference to a specific group.\n         '1' may actually be any positive integer.\n\\g1      Backreference to a specific or previous group,\n\\g{-1}   number may be negative indicating a previous buffer and may\n         optionally be wrapped in curly brackets for safer parsing.\n\\g{name} Named backreference\n\\k<name> Named backreference\n\\K       Keep the stuff left of the \\K, don't include it in $&\n\\v       Vertical whitespace\n\\V       Not vertical whitespace\n\\h       Horizontal whitespace\n\\H       Not horizontal whitespace\n\\R       Linebreak A \"\\w\" matches a single alphanumeric character (an alphabetic character, or a decimal digit) or \"_\", not a whole word. Use \"\\w+\" to match a string of Perl-identifier characters (which isn't the same as matching an English word). If \"use locale\" is in effect, the list of alphabetic characters generated by \"\\w\" is taken from the current locale. See perllocale. You may use \"\\w\", \"\\W\", \"\\s\", \"\\S\", \"\\d\", and \"\\D\" within character classes, but they aren't usable as either end of a range. If any of them precedes or follows a \"-\", the \"-\" is understood literally. If Unicode is in effect, \"\\s\" matches also \"\\x{85}\", \"\\x{2028}\", and \"\\x{2029}\". See perlunicode for more details about \"\\pP\", \"\\PP\", \"\\X\" and the possibility of defining your own \"\\p\" and \"\\P\" properties, and perluniintro about Unicode in general. \"\\R\" will atomically match a linebreak, including the network line-ending \"\\x0D\\x0A\". Specifically, is exactly equivalent to (?>\\x0D\\x0A?|[\\x0A-\\x0C\\x85\\x{2028}\\x{2029}]) Note: \"\\R\" has no special meaning inside of a character class; use \"\\v\" instead (vertical whitespace). The POSIX character class syntax [:class:] is also available. Note that the \"[\" and \"]\" brackets are literal; they must always be used within a character class expression. # this is correct:\n$string =~ \/[[:alpha:]]\/;\n\n# this is not, and will generate a warning:\n$string =~ \/[:alpha:]\/; The available classes and their backslash equivalents (if available) are as follows: alpha\nalnum\nascii\nblank               [1]\ncntrl\ndigit       \\d\ngraph\nlower\nprint\npunct\nspace       \\s      [2]\nupper\nword        \\w      [3]\nxdigit [1] A GNU extension equivalent to \"[ \\t]\", \"all horizontal whitespace\". [2] Not exactly equivalent to \"\\s\" since the \"[[:space:]]\" includes also the (very rare) \"vertical tabulator\", \"\\cK\" or chr(11) in ASCII . [3] A Perl extension, see above. For example use \"[:upper:]\" to match all the uppercase characters. Note that the \"[]\" are part of the \"[::]\" construct, not part of the whole character class. For example: [01[:alpha:]%] matches zero, one, any alphabetic character, and the percent sign. The following equivalences to Unicode \\p{} constructs and equivalent backslash character classes (if available), will hold: [[:...:]]   \\p{...}         backslash\n\nalpha       IsAlpha\nalnum       IsAlnum\nascii       IsASCII\nblank\ncntrl       IsCntrl\ndigit       IsDigit        \\d\ngraph       IsGraph\nlower       IsLower\nprint       IsPrint         (but see [2] below)\npunct       IsPunct         (but see [3] below)\nspace       IsSpace\n            IsSpacePerl    \\s\nupper       IsUpper\nword        IsWord         \\w\nxdigit      IsXDigit For example \"[[:lower:]]\" and \"\\p{IsLower}\" are equivalent. However, the equivalence between \"[[:xxxxx:]]\" and \"\\p{IsXxxxx}\" is not exact. [1] If the \"utf8\" pragma is not used but the \"locale\" pragma is, the classes correlate with the usual isalpha(3) interface (except for \"word\" and \"blank\"). But if the \"locale\" or \"encoding\" pragmas are not used and the string is not \"utf8\", then \"[[:xxxxx:]]\" (and \"\\w\", etc.) will not match characters 0x80-0xff; whereas \"\\p{IsXxxxx}\" will force the string to \"utf8\" and can match these characters (as Unicode). [2] \"\\p{IsPrint}\" matches characters 0x09-0x0d but \"[[:print:]]\" does not. [3] \"[[:punct::]]\" matches the following but \"\\p{IsPunct}\" does not, because they are classed as symbols (not punctuation) in Unicode. \"$\" Currency symbol \"+\" \"<\" \"=\" \">\" \"|\" \"~\" Mathematical symbols \"^\" \"`\" Modifier symbols (accents) The other named classes are: cntrl Any control character. Usually characters that don't produce output as such but instead control the terminal somehow: for example newline and backspace are control characters. All characters with ord() less than 32 are usually classified as control characters (assuming ASCII , the ISO Latin character sets, and Unicode), as is the character with the ord() value of 127 ( \"DEL\"). graph Any alphanumeric or punctuation (special) character. print Any alphanumeric or punctuation (special) character or the space character. punct Any punctuation (special) character. xdigit Any hexadecimal digit. Though this may feel silly ([0-9A-Fa-f] would work just fine) it is included for completeness. You can negate the [::] character classes by prefixing the class name with a '^'. This is a Perl extension. For example: POSIX         traditional  Unicode\n\n[[:^digit:]]    \\D         \\P{IsDigit}\n[[:^space:]]    \\S         \\P{IsSpace}\n[[:^word:]]     \\W         \\P{IsWord} Perl respects the POSIX standard in that POSIX character classes are only supported within a character class. The POSIX character classes [.cc.] and [=cc=] are recognized but not supported and trying to use them will cause an error. Assertions Perl defines the following zero-width assertions: \\b  Match a word boundary\n\\B  Match except at a word boundary\n\\A  Match only at beginning of string\n\\Z  Match only at end of string, or before newline at the end\n\\z  Match only at end of string\n\\G  Match only at pos() (e.g. at the end-of-match position\n    of prior m\/\/g) A word boundary ( \"\\b\") is a spot between two characters that has a \"\\w\" on one side of it and a \"\\W\" on the other side of it (in either order), counting the imaginary characters off the beginning and end of the string as matching a \"\\W\". (Within character classes \"\\b\" represents backspace rather than a word boundary, just as it normally does in any double-quoted string.) The \"\\A\" and \"\\Z\" are just like \"^\" and \"$\", except that they won't match multiple times when the \"\/m\" modifier is used, while \"^\" and \"$\" will match at every internal line boundary. To match the actual end of the string and not ignore an optional trailing newline, use \"\\z\". The \"\\G\" assertion can be used to chain global matches (using \"m\/\/g\"), as described in \"Regexp Quote-Like Operators\" in perlop. It is also useful when writing \"lex\"-like scanners, when you have several patterns that you want to match against consequent substrings of your string, see the previous reference. The actual location where \"\\G\" will match can also be influenced by using \"pos()\" as an lvalue: see \"pos\" in perlfunc. Note that the rule for zero-length matches is modified somewhat, in that contents to the left of \"\\G\" is not counted when determining the length of the match. Thus the following will not match forever: $str = 'ABC';\npos($str) = 1;\nwhile (\/.\\G\/g) {\n    print $&;\n} It will print 'A' and then terminate, as it considers the match to be zero-width, and thus will not match at the same position twice in a row. It is worth noting that \"\\G\" improperly used can result in an infinite loop. Take care when using patterns that include \"\\G\" in an alternation. Capture buffers The bracketing construct \"( ... )\" creates capture buffers. To refer to the current contents of a buffer later on, within the same pattern, use \\1 for the first, \\2 for the second, and so on. Outside the match use \"$\" instead of \"\\\". (The \\<digit> notation works in certain circumstances outside the match. See the warning below about \\1 vs $1 for details.) Referring back to another part of the match is called a backreference. There is no limit to the number of captured substrings that you may use. However Perl also uses \\10, \\11, etc. as aliases for \\010, \\011, etc. (Recall that 0 means octal, so \\011 is the character at number 9 in your coded character set; which would be the 10th character, a horizontal tab under ASCII .) Perl resolves this ambiguity by interpreting \\10 as a backreference only if at least 10 left parentheses have opened before it. Likewise \\11 is a backreference only if at least 11 left parentheses have opened before it. And so on. \\1 through \\9 are always interpreted as backreferences. In order to provide a safer and easier way to construct patterns using backreferences, Perl provides the \"\\g{N}\" notation (starting with perl 5.10.0). The curly brackets are optional, however omitting them is less safe as the meaning of the pattern can be changed by text (such as digits) following it. When N is a positive integer the \"\\g{N}\" notation is exactly equivalent to using normal backreferences. When N is a negative integer then it is a relative backreference referring to the previous N'th capturing group. When the bracket form is used and N is not an integer, it is treated as a reference to a named buffer. Thus \"\\g{-1}\" refers to the last buffer, \"\\g{-2}\" refers to the buffer before that. For example: \/\n (Y)            # buffer 1\n (              # buffer 2\n    (X)         # buffer 3\n    \\g{-1}      # backref to buffer 3\n    \\g{-3}      # backref to buffer 1\n )\n\/x and would match the same as \"\/(Y) ( (X) \\3 \\1 )\/x\". Additionally, as of Perl 5.10.0 you may use named capture buffers and named backreferences. The notation is \"(?<name>...)\" to declare and \"\\k<name>\" to reference. You may also use apostrophes instead of angle brackets to delimit the name; and you may use the bracketed \"\\g{name}\" backreference syntax. It's possible to refer to a named capture buffer by absolute and relative number as well. Outside the pattern, a named capture buffer is available via the \"%+\" hash. When different buffers within the same pattern have the same name, $+{name} and \"\\k<name>\" refer to the leftmost defined group. (Thus it's possible to do things with named capture buffers that would otherwise require \"(??{})\" code to accomplish.) Examples: s\/^([^ ]*) *([^ ]*)\/$2 $1\/;     # swap first two words\n\n\/(.)\\1\/                         # find first doubled char\n     and print \"'$1' is the first doubled character\\n\";\n\n\/(?<char>.)\\k<char>\/            # ... a different way\n     and print \"'$+{char}' is the first doubled character\\n\";\n\n\/(?'char'.)\\1\/                  # ... mix and match\n     and print \"'$1' is the first doubled character\\n\";\n\nif (\/Time: (..):(..):(..)\/) {   # parse out values\n    $hours = $1;\n    $minutes = $2;\n    $seconds = $3;\n} Several special variables also refer back to portions of the previous match. $+ returns whatever the last bracket match matched. $& returns the entire matched string. (At one point $0 did also, but now it returns the name of the program.) \"$`\" returns everything before the matched string. \"$'\" returns everything after the matched string. And $^N contains whatever was matched by the most-recently closed group (submatch). $^N can be used in extended patterns (see below), for example to assign a submatch to a variable. The numbered match variables ($1, $2, $3, etc.) and the related punctuation set ($+, $&, \"$`\", \"$'\", and $^N) are all dynamically scoped until the end of the enclosing block or until the next successful match, whichever comes first. (See \"Compound Statements\" in perlsyn.) NOTE : Failed matches in Perl do not reset the match variables, which makes it easier to write code that tests for a series of more specific cases and remembers the best match. WARNING : Once Perl sees that you need one of $&, \"$`\", or \"$'\" anywhere in the program, it has to provide them for every pattern match. This may substantially slow your program. Perl uses the same mechanism to produce $1, $2, etc, so you also pay a price for each pattern that contains capturing parentheses. (To avoid this cost while retaining the grouping behaviour, use the extended regular expression \"(?: ... )\" instead.) But if you never use $&, \"$`\" or \"$'\", then patterns without capturing parentheses will not be penalized. So avoid $&, \"$'\", and \"$`\" if you can, but if you can't (and some algorithms really appreciate them), once you've used them once, use them at will, because you've already paid the price. As of 5.005, $& is not so costly as the other two. As a workaround for this problem, Perl 5.10.0 introduces \"${^PREMATCH}\", \"${^MATCH}\" and \"${^POSTMATCH}\", which are equivalent to \"$`\", $& and \"$'\", except that they are only guaranteed to be defined after a successful match that was executed with the \"\/p\" (preserve) modifier. The use of these variables incurs no global performance penalty, unlike their punctuation char equivalents, however at the trade-off that you have to tell perl when you want to use them. Backslashed metacharacters in Perl are alphanumeric, such as \"\\b\", \"\\w\", \"\\n\". Unlike some other regular expression languages, there are no backslashed symbols that aren't alphanumeric. So anything that looks like \\\\, \\(, \\), \\<, \\>, \\{, or \\} is always interpreted as a literal character, not a metacharacter. This was once used in a common idiom to disable or quote the special meanings of regular expression metacharacters in a string that you want to use for a pattern. Simply quote all non-\"word\" characters: $pattern =~ s\/(\\W)\/\\\\$1\/g; (If \"use locale\" is set, then this depends on the current locale.) Today it is more common to use the quotemeta() function or the \"\\Q\" metaquoting escape sequence to disable all metacharacters' special meanings like this: \/$unquoted\\Q$quoted\\E$unquoted\/ Beware that if you put literal backslashes (those not inside interpolated variables) between \"\\Q\" and \"\\E\", double-quotish backslash interpolation may lead to confusing results. If you need to use literal backslashes within \"\\Q...\\E\", consult \"Gory details of parsing quoted constructs\" in perlop. Extended Patterns Perl also defines a consistent extension syntax for features not found in standard tools like awk and lex. The syntax is a pair of parentheses with a question mark as the first thing within the parentheses. The character after the question mark indicates the extension. The stability of these extensions varies widely. Some have been part of the core language for many years. Others are experimental and may change without warning or be completely removed. Check the documentation on an individual feature to verify its current status. A question mark was chosen for this and for the minimal-matching construct because 1) question marks are rare in older regular expressions, and 2) whenever you see one, you should stop and \"question\" exactly what is going on. That's psychology... \"(?#text)\" A comment. The text is ignored. If the \"\/x\" modifier enables whitespace formatting, a simple \"#\" will suffice. Note that Perl closes the comment as soon as it sees a \")\", so there is no way to put a literal \")\" in the comment. \"(?pimsx-imsx)\" One or more embedded pattern-match modifiers, to be turned on (or turned off, if preceded by \"-\") for the remainder of the pattern or the remainder of the enclosing pattern group (if any). This is particularly useful for dynamic patterns, such as those read in from a configuration file, taken from an argument, or specified in a table somewhere. Consider the case where some patterns want to be case sensitive and some do not: The case insensitive ones merely need to include \"(?i)\" at the front of the pattern. For example: $pattern = \"foobar\";\nif ( \/$pattern\/i ) { }\n\n# more flexible:\n\n$pattern = \"(?i)foobar\";\nif ( \/$pattern\/ ) { } These modifiers are restored at the end of the enclosing group. For example, ( (?i) blah ) \\s+ \\1 will match \"blah\" in any case, some spaces, and an exact ( including the case!) repetition of the previous word, assuming the \"\/x\" modifier, and no \"\/i\" modifier outside this group. Note that the \"p\" modifier is special in that it can only be enabled, not disabled, and that its presence anywhere in a pattern has a global effect. Thus \"(?-p)\" and \"(?-p:...)\" are meaningless and will warn when executed under \"use warnings\". \"(?:pattern)\" \"(?imsx-imsx:pattern)\" This is for clustering, not capturing; it groups subexpressions like \"()\", but doesn't make backreferences as \"()\" does. So @fields = split(\/\\b(?:a|b|c)\\b\/) is like @fields = split(\/\\b(a|b|c)\\b\/) but doesn't spit out extra fields. It's also cheaper not to capture characters if you don't need to. Any letters between \"?\" and \":\" act as flags modifiers as with \"(?imsx-imsx)\". For example, \/(?s-i:more.*than).*million\/i is equivalent to the more verbose \/(?:(?s-i)more.*than).*million\/i \"(?|pattern)\" This is the \"branch reset\" pattern, which has the special property that the capture buffers are numbered from the same starting point in each alternation branch. It is available starting from perl 5.10.0. Capture buffers are numbered from left to right, but inside this construct the numbering is restarted for each branch. The numbering within each branch will be as normal, and any buffers following this construct will be numbered as though the construct contained only one branch, that being the one with the most capture buffers in it. This construct will be useful when you want to capture one of a number of alternative matches. Consider the following pattern. The numbers underneath show in which buffer the captured content will be stored. # before  ---------------branch-reset----------- after\n\/ ( a )  (?| x ( y ) z | (p (q) r) | (t) u (v) ) ( z ) \/x\n# 1            2         2  3        2     3     4 Note: as of Perl 5.10.0, branch resets interfere with the contents of the \"%+\" hash, that holds named captures. Consider using \"%-\" instead. Look-Around Assertions Look-around assertions are zero width patterns which match a specific pattern without including it in $&. Positive assertions match when their subpattern matches, negative assertions match when their subpattern fails. Look-behind matches text up to the current match position, look-ahead matches text following the current match position. \"(?=pattern)\" A zero-width positive look-ahead assertion. For example, \"\/\\w+(?=\\t)\/\" matches a word followed by a tab, without including the tab in $&. \"(?!pattern)\" A zero-width negative look-ahead assertion. For example \"\/foo(?!bar)\/\" matches any occurrence of \"foo\" that isn't followed by \"bar\". Note however that look-ahead and look-behind are NOT the same thing. You cannot use this for look-behind. If you are looking for a \"bar\" that isn't preceded by a \"foo\", \"\/(?!foo)bar\/\" will not do what you want. That's because the \"(?!foo)\" is just saying that the next thing cannot be \"foo\"--and it's not, it's a \"bar\", so \"foobar\" will match. You would have to do something like \"\/(?!foo)...bar\/\" for that. We say \"like\" because there's the case of your \"bar\" not having three characters before it. You could cover that this way: \"\/(?:(?!foo)...|^.{0,2})bar\/\". Sometimes it's still easier just to say: if (\/bar\/ && $` !~ \/foo$\/) For look-behind see below. \"(?<=pattern)\" \"\\K\" A zero-width positive look-behind assertion. For example, \"\/(?<=\\t)\\w+\/\" matches a word that follows a tab, without including the tab in $&. Works only for fixed-width look-behind. There is a special form of this construct, called \"\\K\", which causes the regex engine to \"keep\" everything it had matched prior to the \"\\K\" and not include it in $&. This effectively provides variable length look-behind. The use of \"\\K\" inside of another look-around assertion is allowed, but the behaviour is currently not well defined. For various reasons \"\\K\" may be significantly more efficient than the equivalent \"(?<=...)\" construct, and it is especially useful in situations where you want to efficiently remove something following something else in a string. For instance s\/(foo)bar\/$1\/g; can be rewritten as the much more efficient s\/foo\\Kbar\/\/g; \"(?<!pattern)\" A zero-width negative look-behind assertion. For example \"\/(?<!bar)foo\/\" matches any occurrence of \"foo\" that does not follow \"bar\". Works only for fixed-width look-behind. \"(?'NAME'pattern)\" \"(?<NAME>pattern)\" A named capture buffer. Identical in every respect to normal capturing parentheses \"()\" but for the additional fact that \"%+\" or \"%-\" may be used after a successful match to refer to a named buffer. See \"perlvar\" for more details on the \"%+\" and \"%-\" hashes. If multiple distinct capture buffers have the same name then the $+{ NAME } will refer to the leftmost defined buffer in the match. The forms \"(?'NAME'pattern)\" and \"(?<NAME>pattern)\" are equivalent. NOTE: While the notation of this construct is the same as the similar function in .NET regexes, the behavior is not. In Perl the buffers are numbered sequentially regardless of being named or not. Thus in the pattern \/(x)(?<foo>y)(z)\/ $+{foo} will be the same as $2, and $3 will contain 'z' instead of the opposite which is what a .NET regex hacker might expect. Currently NAME is restricted to simple identifiers only. In other words, it must match \"\/^[_A-Za-z][_A-Za-z0-9]*\\z\/\" or its Unicode extension (see utf8), though it isn't extended by the locale (see perllocale). NOTE: In order to make things easier for programmers with experience with the Python or PCRE regex engines, the pattern \"(?PE<lt>NAMEE<gt>pattern)\" may be used instead of \"(?<NAME>pattern)\"; however this form does not support the use of single quotes as a delimiter for the name. \"\\k<NAME>\" \"\\k'NAME'\" Named backreference. Similar to numeric backreferences, except that the group is designated by name and not number. If multiple groups have the same name then it refers to the leftmost defined group in the current match. It is an error to refer to a name not defined by a \"(?<NAME>)\" earlier in the pattern. Both forms are equivalent. NOTE: In order to make things easier for programmers with experience with the Python or PCRE regex engines, the pattern \"(?P=NAME)\" may be used instead of \"\\k<NAME>\". \"(?{ code })\" WARNING : This extended regular expression feature is considered experimental, and may be changed without notice. Code executed that has side effects may not perform identically from version to version due to the effect of future optimisations in the regex engine. This zero-width assertion evaluates any embedded Perl code. It always succeeds, and its \"code\" is not interpolated. Currently, the rules to determine where the \"code\" ends are somewhat convoluted. This feature can be used together with the special variable $^N to capture the results of submatches in variables without having to keep track of the number of nested parentheses. For example: $_ = \"The brown fox jumps over the lazy dog\";\n\/the (\\S+)(?{ $color = $^N }) (\\S+)(?{ $animal = $^N })\/i;\nprint \"color = $color, animal = $animal\\n\"; Inside the \"(?{...})\" block, $_ refers to the string the regular expression is matching against. You can also use \"pos()\" to know what is the current position of matching within this string. The \"code\" is properly scoped in the following sense: If the assertion is backtracked (compare \"Backtracking\"), all changes introduced after \"local\"ization are undone, so that $_ = 'a' x 8;\nm<\n   (?{ $cnt = 0 })                    # Initialize $cnt.\n   (\n     a\n     (?{\n         local $cnt = $cnt + 1;       # Update $cnt, backtracking-safe.\n     })\n   )*\n   aaaa\n   (?{ $res = $cnt })                 # On success copy to non-localized\n                                      # location.\n >x; will set \"$res = 4\". Note that after the match, $cnt returns to the globally introduced value, because the scopes that restrict \"local\" operators are unwound. This assertion may be used as a \"(?(condition)yes-pattern|no-pattern)\" switch. If not used in this way, the result of evaluation of \"code\" is put into the special variable $^R. This happens immediately, so $^R can be used from other \"(?{ code })\" assertions inside the same regular expression. The assignment to $^R above is properly localized, so the old value of $^R is restored if the assertion is backtracked; compare \"Backtracking\". Due to an unfortunate implementation issue, the Perl code contained in these blocks is treated as a compile time closure that can have seemingly bizarre consequences when used with lexically scoped variables inside of subroutines or loops. There are various workarounds for this, including simply using global variables instead. If you are using this construct and strange results occur then check for the use of lexically scoped variables. For reasons of security, this construct is forbidden if the regular expression involves run-time interpolation of variables, unless the perilous \"use re 'eval'\" pragma has been used (see re), or the variables contain results of \"qr\/\/\" operator (see \"qr\/STRING\/imosx\" in perlop). This restriction is due to the wide-spread and remarkably convenient custom of using run-time determined strings as patterns. For example: $re = <>;\nchomp $re;\n$string =~ \/$re\/; Before Perl knew how to execute interpolated code within a pattern, this operation was completely safe from a security point of view, although it could raise an exception from an illegal pattern. If you turn on the \"use re 'eval'\", though, it is no longer secure, so you should only do so if you are also using taint checking. Better yet, use the carefully constrained evaluation within a Safe compartment. See perlsec for details about both these mechanisms. Because Perl's regex engine is currently not re-entrant, interpolated code may not invoke the regex engine either directly with \"m\/\/\" or \"s\/\/\/\"), or indirectly with functions such as \"split\". \"(??{ code })\" WARNING : This extended regular expression feature is considered experimental, and may be changed without notice. Code executed that has side effects may not perform identically from version to version due to the effect of future optimisations in the regex engine. This is a \"postponed\" regular subexpression. The \"code\" is evaluated at run time, at the moment this subexpression may match. The result of evaluation is considered as a regular expression and matched as if it were inserted instead of this construct. Note that this means that the contents of capture buffers defined inside an eval'ed pattern are not available outside of the pattern, and vice versa, there is no way for the inner pattern to refer to a capture buffer defined outside. Thus, ('a' x 100)=~\/(??{'(.)' x 100})\/ will match, it will not set $1. The \"code\" is not interpolated. As before, the rules to determine where the \"code\" ends are currently somewhat convoluted. The following pattern matches a parenthesized group: $re = qr{\n           \\(\n           (?:\n              (?> [^()]+ )    # Non-parens without backtracking\n            |\n              (??{ $re })     # Group with matching parens\n           )*\n           \\)\n        }x; See also \"(?PARNO)\" for a different, more efficient way to accomplish the same task. Because perl's regex engine is not currently re-entrant, delayed code may not invoke the regex engine either directly with \"m\/\/\" or \"s\/\/\/\"), or indirectly with functions such as \"split\". Recursing deeper than 50 times without consuming any input string will result in a fatal error. The maximum depth is compiled into perl, so changing it requires a custom build. \"(?PARNO)\" \"(?-PARNO)\" \"(?+PARNO)\" \"(?R)\" \"(?0)\" Similar to \"(??{ code })\" except it does not involve compiling any code, instead it treats the contents of a capture buffer as an independent pattern that must match at the current position. Capture buffers contained by the pattern will have the value as determined by the outermost recursion. PARNO is a sequence of digits (not starting with 0) whose value reflects the paren-number of the capture buffer to recurse to. \"(?R)\" recurses to the beginning of the whole pattern. \"(?0)\" is an alternate syntax for \"(?R)\". If PARNO is preceded by a plus or minus sign then it is assumed to be relative, with negative numbers indicating preceding capture buffers and positive ones following. Thus \"(?-1)\" refers to the most recently declared buffer, and \"(?+1)\" indicates the next buffer to be declared. Note that the counting for relative recursion differs from that of relative backreferences, in that with recursion unclosed buffers are included. The following pattern matches a function foo() which may contain balanced parentheses as the argument. $re = qr{ (                    # paren group 1 (full function)\n            foo\n            (                  # paren group 2 (parens)\n              \\(\n                (              # paren group 3 (contents of parens)\n                (?:\n                 (?> [^()]+ )  # Non-parens without backtracking\n                |\n                 (?2)          # Recurse to start of paren group 2\n                )*\n                )\n              \\)\n            )\n          )\n        }x; If the pattern was used as follows 'foo(bar(baz)+baz(bop))'=~\/$re\/\n    and print \"\\$1 = $1\\n\",\n              \"\\$2 = $2\\n\",\n              \"\\$3 = $3\\n\"; the output produced should be the following: $1 = foo(bar(baz)+baz(bop))\n$2 = (bar(baz)+baz(bop))\n$3 = bar(baz)+baz(bop) If there is no corresponding capture buffer defined, then it is a fatal error. Recursing deeper than 50 times without consuming any input string will also result in a fatal error. The maximum depth is compiled into perl, so changing it requires a custom build. The following shows how using negative indexing can make it easier to embed recursive patterns inside of a \"qr\/\/\" construct for later use: my $parens = qr\/(\\((?:[^()]++|(?-1))*+\\))\/;\nif (\/foo $parens \\s+ + \\s+ bar $parens\/x) {\n   # do something here...\n} Note that this pattern does not behave the same way as the equivalent PCRE or Python construct of the same form. In Perl you can backtrack into a recursed group, in PCRE and Python the recursed into group is treated as atomic. Also, modifiers are resolved at compile time, so constructs like (?i:(?1)) or (?:(?i)(?1)) do not affect how the sub-pattern will be processed. \"(?&NAME)\" Recurse to a named subpattern. Identical to \"(?PARNO)\" except that the parenthesis to recurse to is determined by name. If multiple parentheses have the same name, then it recurses to the leftmost. It is an error to refer to a name that is not declared somewhere in the pattern. NOTE: In order to make things easier for programmers with experience with the Python or PCRE regex engines the pattern \"(?P>NAME)\" may be used instead of \"(?&NAME)\". \"(?(condition)yes-pattern|no-pattern)\" \"(?(condition)yes-pattern)\" Conditional expression. \"(condition)\" should be either an integer in parentheses (which is valid if the corresponding pair of parentheses matched), a look-ahead\/look-behind\/evaluate zero-width assertion, a name in angle brackets or single quotes (which is valid if a buffer with the given name matched), or the special symbol (R) (true when evaluated inside of recursion or eval). Additionally the R may be followed by a number, (which will be true when evaluated when recursing inside of the appropriate group), or by &NAME, in which case it will be true only when evaluated during recursion in the named group. Here's a summary of the possible predicates: (1) (2) ... Checks if the numbered capturing buffer has matched something. (< NAME >) (' NAME ') Checks if a buffer with the given name has matched something. (?{ CODE }) Treats the code block as the condition. (R) Checks if the expression has been evaluated inside of recursion. (R1) (R2) ... Checks if the expression has been evaluated while executing directly inside of the n-th capture group. This check is the regex equivalent of if ((caller(0))[3] eq 'subname') { ... } In other words, it does not check the full recursion stack. (R&NAME) Similar to \"(R1)\", this predicate checks to see if we're executing directly inside of the leftmost group with a given name (this is the same logic used by \"(?&NAME)\" to disambiguate). It does not check the full stack, but only the name of the innermost active recursion. ( DEFINE ) In this case, the yes-pattern is never directly executed, and no no-pattern is allowed. Similar in spirit to \"(?{0})\" but more efficient. See below for details. For example: m{ ( \\( )?\n   [^()]+\n   (?(1) \\) )\n }x matches a chunk of non-parentheses, possibly included in parentheses themselves. A special form is the \"(DEFINE)\" predicate, which never executes directly its yes-pattern, and does not allow a no-pattern. This allows to define subpatterns which will be executed only by using the recursion mechanism. This way, you can define a set of regular expression rules that can be bundled into any pattern you choose. It is recommended that for this usage you put the DEFINE block at the end of the pattern, and that you name any subpatterns defined within it. Also, it's worth noting that patterns defined this way probably will not be as efficient, as the optimiser is not very clever about handling them. An example of how this might be used is as follows: \/(?<NAME>(?&NAME_PAT))(?<ADDR>(?&ADDRESS_PAT))\n (?(DEFINE)\n   (?<NAME_PAT>....)\n   (?<ADRESS_PAT>....)\n )\/x Note that capture buffers matched inside of recursion are not accessible after the recursion returns, so the extra layer of capturing buffers is necessary. Thus $+{NAME_PAT} would not be defined even though $+{NAME} would be. \"(?>pattern)\" An \"independent\" subexpression, one which matches the substring that a standalone \"pattern\" would match if anchored at the given position, and it matches nothing other than this substring. This construct is useful for optimizations of what would otherwise be \"eternal\" matches, because it will not backtrack (see \"Backtracking\"). It may also be useful in places where the \"grab all you can, and do not give anything back\" semantic is desirable. For example: \"^(?>a*)ab\" will never match, since \"(?>a*)\" (anchored at the beginning of string, as above) will match all characters \"a\" at the beginning of string, leaving no \"a\" for \"ab\" to match. In contrast, \"a*ab\" will match the same as \"a+b\", since the match of the subgroup \"a*\" is influenced by the following group \"ab\" (see \"Backtracking\"). In particular, \"a*\" inside \"a*ab\" will match fewer characters than a standalone \"a*\", since this makes the tail match. An effect similar to \"(?>pattern)\" may be achieved by writing \"(?=(pattern))\\1\". This matches the same substring as a standalone \"a+\", and the following \"\\1\" eats the matched string; it therefore makes a zero-length assertion into an analogue of \"(?>...)\". (The difference between these two constructs is that the second one uses a capturing group, thus shifting ordinals of backreferences in the rest of a regular expression.) Consider this pattern: m{ \\(\n      (\n        [^()]+              # x+\n      |\n        \\( [^()]* \\)\n      )+\n   \\)\n }x That will efficiently match a nonempty group with matching parentheses two levels deep or less. However, if there is no such group, it will take virtually forever on a long string. That's because there are so many different ways to split a long string into several substrings. This is what \"(.+)+\" is doing, and \"(.+)+\" is similar to a subpattern of the above pattern. Consider how the pattern above detects no-match on \"((()aaaaaaaaaaaaaaaaaa\" in several seconds, but that each extra letter doubles this time. This exponential performance will make it appear that your program has hung. However, a tiny change to this pattern m{ \\(\n      (\n        (?> [^()]+ )        # change x+ above to (?> x+ )\n      |\n        \\( [^()]* \\)\n      )+\n   \\)\n }x which uses \"(?>...)\" matches exactly when the one above does (verifying this yourself would be a productive exercise), but finishes in a fourth the time when used on a similar string with 1000000 \"a\"s. Be aware, however, that this pattern currently triggers a warning message under the \"use warnings\" pragma or -w switch saying it \"matches null string many times in regex\". On simple groups, such as the pattern \"(?> [^()]+ )\", a comparable effect may be achieved by negative look-ahead, as in \"[^()]+ (?! [^()] )\". This was only 4 times slower on a string with 1000000 \"a\"s. The \"grab all you can, and do not give anything back\" semantic is desirable in many situations where on the first sight a simple \"()*\" looks like the correct solution. Suppose we parse text with comments being delimited by \"#\" followed by some optional (horizontal) whitespace. Contrary to its appearance, \"#[ \\t]*\" is not the correct subexpression to match the comment delimiter, because it may \"give up\" some whitespace if the remainder of the pattern can be made to match that way. The correct answer is either one of these: (?>#[ \\t]*)\n#[ \\t]*(?![ \\t]) For example, to grab non-empty comments into $1, one should use either one of these: \/ (?> \\# [ \\t]* ) (        .+ ) \/x;\n\/     \\# [ \\t]*   ( [^ \\t] .* ) \/x; Which one you pick depends on which of these expressions better reflects the above specification of comments. In some literature this construct is called \"atomic matching\" or \"possessive matching\". Possessive quantifiers are equivalent to putting the item they are applied to inside of one of these constructs. The following equivalences apply: Quantifier Form     Bracketing Form\n---------------     ---------------\nPAT*+               (?>PAT*)\nPAT++               (?>PAT+)\nPAT?+               (?>PAT?)\nPAT{min,max}+       (?>PAT{min,max}) Special Backtracking Control Verbs WARNING: These patterns are experimental and subject to change or removal in a future version of Perl. Their usage in production code should be noted to avoid problems during upgrades. These special patterns are generally of the form \"(*VERB:ARG)\". Unless otherwise stated the ARG argument is optional; in some cases, it is forbidden. Any pattern containing a special backtracking verb that allows an argument has the special behaviour that when executed it sets the current packages' $REGERROR and $REGMARK variables. When doing so the following rules apply: On failure, the $REGERROR variable will be set to the ARG value of the verb pattern, if the verb was involved in the failure of the match. If the ARG part of the pattern was omitted, then $REGERROR will be set to the name of the last \"(*MARK:NAME)\" pattern executed, or to TRUE if there was none. Also, the $REGMARK variable will be set to FALSE . On a successful match, the $REGERROR variable will be set to FALSE , and the $REGMARK variable will be set to the name of the last \"(*MARK:NAME)\" pattern executed. See the explanation for the \"(*MARK:NAME)\" verb below for more details. NOTE: $REGERROR and $REGMARK are not magic variables like $1 and most other regex related variables. They are not local to a scope, nor readonly, but instead are volatile package variables similar to $AUTOLOAD. Use \"local\" to localize changes to them to a specific scope if necessary. If a pattern does not contain a special backtracking verb that allows an argument, then $REGERROR and $REGMARK are not touched at all. Verbs that take an argument \"(*PRUNE)\" \"(*PRUNE:NAME)\" This zero-width pattern prunes the backtracking tree at the current point when backtracked into on failure. Consider the pattern \"A (*PRUNE) B\", where A and B are complex patterns. Until the \"(*PRUNE)\" verb is reached, A may backtrack as necessary to match. Once it is reached, matching continues in B, which may also backtrack as necessary; however, should B not match, then no further backtracking will take place, and the pattern will fail outright at the current starting position. The following example counts all the possible matching strings in a pattern (without actually matching any of them). 'aaab' =~ \/a+b?(?{print \"$&\\n\"; $count++})(*FAIL)\/;\nprint \"Count=$count\\n\"; which produces: aaab\naaa\naa\na\naab\naa\na\nab\na\nCount=9 If we add a \"(*PRUNE)\" before the count like the following 'aaab' =~ \/a+b?(*PRUNE)(?{print \"$&\\n\"; $count++})(*FAIL)\/;\nprint \"Count=$count\\n\"; we prevent backtracking and find the count of the longest matching at each matching starting point like so: aaab\naab\nab\nCount=3 Any number of \"(*PRUNE)\" assertions may be used in a pattern. See also \"(?>pattern)\" and possessive quantifiers for other ways to control backtracking. In some cases, the use of \"(*PRUNE)\" can be replaced with a \"(?>pattern)\" with no functional difference; however, \"(*PRUNE)\" can be used to handle cases that cannot be expressed using a \"(?>pattern)\" alone. \"(*SKIP)\" \"(*SKIP:NAME)\" This zero-width pattern is similar to \"(*PRUNE)\", except that on failure it also signifies that whatever text that was matched leading up to the \"(*SKIP)\" pattern being executed cannot be part of any match of this pattern. This effectively means that the regex engine \"skips\" forward to this position on failure and tries to match again, (assuming that there is sufficient room to match). The name of the \"(*SKIP:NAME)\" pattern has special significance. If a \"(*MARK:NAME)\" was encountered while matching, then it is that position which is used as the \"skip point\". If no \"(*MARK)\" of that name was encountered, then the \"(*SKIP)\" operator has no effect. When used without a name the \"skip point\" is where the match point was when executing the (*SKIP) pattern. Compare the following to the examples in \"(*PRUNE)\", note the string is twice as long: 'aaabaaab' =~ \/a+b?(*SKIP)(?{print \"$&\\n\"; $count++})(*FAIL)\/;\nprint \"Count=$count\\n\"; outputs aaab\naaab\nCount=2 Once the 'aaab' at the start of the string has matched, and the \"(*SKIP)\" executed, the next starting point will be where the cursor was when the \"(*SKIP)\" was executed. \"(*MARK:NAME)\" \"(*:NAME)\" \"(*MARK:NAME)\" \"(*:NAME)\" This zero-width pattern can be used to mark the point reached in a string when a certain part of the pattern has been successfully matched. This mark may be given a name. A later \"(*SKIP)\" pattern will then skip forward to that point if backtracked into on failure. Any number of \"(*MARK)\" patterns are allowed, and the NAME portion is optional and may be duplicated. In addition to interacting with the \"(*SKIP)\" pattern, \"(*MARK:NAME)\" can be used to \"label\" a pattern branch, so that after matching, the program can determine which branches of the pattern were involved in the match. When a match is successful, the $REGMARK variable will be set to the name of the most recently executed \"(*MARK:NAME)\" that was involved in the match. This can be used to determine which branch of a pattern was matched without using a separate capture buffer for each branch, which in turn can result in a performance improvement, as perl cannot optimize \"\/(?:(x)|(y)|(z))\/\" as efficiently as something like \"\/(?:x(*MARK:x)|y(*MARK:y)|z(*MARK:z))\/\". When a match has failed, and unless another verb has been involved in failing the match and has provided its own name to use, the $REGERROR variable will be set to the name of the most recently executed \"(*MARK:NAME)\". See \"(*SKIP)\" for more details. As a shortcut \"(*MARK:NAME)\" can be written \"(*:NAME)\". \"(*THEN)\" \"(*THEN:NAME)\" This is similar to the \"cut group\" operator \"::\" from Perl 6. Like \"(*PRUNE)\", this verb always matches, and when backtracked into on failure, it causes the regex engine to try the next alternation in the innermost enclosing group (capturing or otherwise). Its name comes from the observation that this operation combined with the alternation operator (\"|\") can be used to create what is essentially a pattern-based if\/then\/else block: ( COND (*THEN) FOO | COND2 (*THEN) BAR | COND3 (*THEN) BAZ ) Note that if this operator is used and NOT inside of an alternation then it acts exactly like the \"(*PRUNE)\" operator. \/ A (*PRUNE) B \/ is the same as \/ A (*THEN) B \/ but \/ ( A (*THEN) B | C (*THEN) D ) \/ is not the same as \/ ( A (*PRUNE) B | C (*PRUNE) D ) \/ as after matching the A but failing on the B the \"(*THEN)\" verb will backtrack and try C; but the \"(*PRUNE)\" verb will simply fail. \"(*COMMIT)\" This is the Perl 6 \"commit pattern\" \"<commit>\" or \":::\". It's a zero-width pattern similar to \"(*SKIP)\", except that when backtracked into on failure it causes the match to fail outright. No further attempts to find a valid match by advancing the start pointer will occur again. For example, 'aaabaaab' =~ \/a+b?(*COMMIT)(?{print \"$&\\n\"; $count++})(*FAIL)\/;\nprint \"Count=$count\\n\"; outputs aaab\nCount=1 In other words, once the \"(*COMMIT)\" has been entered, and if the pattern does not match, the regex engine will not try any further matching on the rest of the string. Verbs without an argument \"(*FAIL)\" \"(*F)\" This pattern matches nothing and always fails. It can be used to force the engine to backtrack. It is equivalent to \"(?!)\", but easier to read. In fact, \"(?!)\" gets optimised into \"(*FAIL)\" internally. It is probably useful only when combined with \"(?{})\" or \"(??{})\". \"(*ACCEPT)\" WARNING: This feature is highly experimental. It is not recommended for production code. This pattern matches nothing and causes the end of successful matching at the point at which the \"(*ACCEPT)\" pattern was encountered, regardless of whether there is actually more to match in the string. When inside of a nested pattern, such as recursion, or in a subpattern dynamically generated via \"(??{})\", only the innermost pattern is ended immediately. If the \"(*ACCEPT)\" is inside of capturing buffers then the buffers are marked as ended at the point at which the \"(*ACCEPT)\" was encountered. For instance: 'AB' =~ \/(A (A|B(*ACCEPT)|C) D)(E)\/x; will match, and $1 will be \"AB\" and $2 will be \"B\", $3 will not be set. If another branch in the inner parentheses were matched, such as in the string ' ACDE ', then the \"D\" and \"E\" would have to be matched as well. Backtracking NOTE: This section presents an abstract approximation of regular expression behavior. For a more rigorous (and complicated) view of the rules involved in selecting a match among possible alternatives, see \"Combining RE Pieces\". A fundamental feature of regular expression matching involves the notion called backtracking, which is currently used (when needed) by all regular non-possessive expression quantifiers, namely \"*\", \"*?\", \"+\", \"+?\", \"{n,m}\", and \"{n,m}?\". Backtracking is often optimized internally, but the general principle outlined here is valid. For a regular expression to match, the entire regular expression must match, not just part of it. So if the beginning of a pattern containing a quantifier succeeds in a way that causes later parts in the pattern to fail, the matching engine backs up and recalculates the beginning part--that's why it's called backtracking. Here is an example of backtracking: Let's say you want to find the word following \"foo\" in the string \"Food is on the foo table.\": $_ = \"Food is on the foo table.\";\nif ( \/\\b(foo)\\s+(\\w+)\/i ) {\n    print \"$2 follows $1.\\n\";\n} When the match runs, the first part of the regular expression ( \"\\b(foo)\") finds a possible match right at the beginning of the string, and loads up $1 with \"Foo\". However, as soon as the matching engine sees that there's no whitespace following the \"Foo\" that it had saved in $1, it realizes its mistake and starts over again one character after where it had the tentative match. This time it goes all the way until the next occurrence of \"foo\". The complete regular expression matches this time, and you get the expected output of \"table follows foo.\" Sometimes minimal matching can help a lot. Imagine you'd like to match everything between \"foo\" and \"bar\". Initially, you write something like this: $_ =  \"The food is under the bar in the barn.\";\nif ( \/foo(.*)bar\/ ) {\n    print \"got <$1>\\n\";\n} Which perhaps unexpectedly yields: got <d is under the bar in the > That's because \".*\" was greedy, so you get everything between the first \"foo\" and the last \"bar\". Here it's more effective to use minimal matching to make sure you get the text between a \"foo\" and the first \"bar\" thereafter.   if ( \/foo(.*?)bar\/ ) { print \"got <$1>\\n\" }\ngot <d is under the > Here's another example. Let's say you'd like to match a number at the end of a string, and you also want to keep the preceding part of the match. So you write this: $_ = \"I have 2 numbers: 53147\";\nif ( \/(.*)(\\d*)\/ ) {                                # Wrong!\n    print \"Beginning is <$1>, number is <$2>.\\n\";\n} That won't work at all, because \".*\" was greedy and gobbled up the whole string. As \"\\d*\" can match on an empty string the complete regular expression matched successfully. Beginning is <I have 2 numbers: 53147>, number is <>. Here are some variants, most of which don't work: $_ = \"I have 2 numbers: 53147\";\n@pats = qw{\n    (.*)(\\d*)\n    (.*)(\\d+)\n    (.*?)(\\d*)\n    (.*?)(\\d+)\n    (.*)(\\d+)$\n    (.*?)(\\d+)$\n    (.*)\\b(\\d+)$\n    (.*\\D)(\\d+)$\n};\n\nfor $pat (@pats) {\n    printf \"%-12s \", $pat;\n    if ( \/$pat\/ ) {\n        print \"<$1> <$2>\\n\";\n    } else {\n        print \"FAIL\\n\";\n    }\n} That will print out: (.*)(\\d*)    <I have 2 numbers: 53147> <>\n(.*)(\\d+)    <I have 2 numbers: 5314> <7>\n(.*?)(\\d*)   <> <>\n(.*?)(\\d+)   <I have > <2>\n(.*)(\\d+)$   <I have 2 numbers: 5314> <7>\n(.*?)(\\d+)$  <I have 2 numbers: > <53147>\n(.*)\\b(\\d+)$ <I have 2 numbers: > <53147>\n(.*\\D)(\\d+)$ <I have 2 numbers: > <53147> As you see, this can be a bit tricky. It's important to realize that a regular expression is merely a set of assertions that gives a definition of success. There may be 0, 1, or several different ways that the definition might succeed against a particular string. And if there are multiple ways it might succeed, you need to understand backtracking to know which variety of success you will achieve. When using look-ahead assertions and negations, this can all get even trickier. Imagine you'd like to find a sequence of non-digits not followed by \"123\". You might try to write that as $_ = \"ABC123\";\nif ( \/^\\D*(?!123)\/ ) {              # Wrong!\n    print \"Yup, no 123 in $_\\n\";\n} But that isn't going to match; at least, not the way you're hoping. It claims that there is no 123 in the string. Here's a clearer picture of why that pattern matches, contrary to popular expectations: $x = 'ABC123';\n$y = 'ABC445';\n\nprint \"1: got $1\\n\" if $x =~ \/^(ABC)(?!123)\/;\nprint \"2: got $1\\n\" if $y =~ \/^(ABC)(?!123)\/;\n\nprint \"3: got $1\\n\" if $x =~ \/^(\\D*)(?!123)\/;\nprint \"4: got $1\\n\" if $y =~ \/^(\\D*)(?!123)\/; This prints 2: got ABC\n3: got AB\n4: got ABC You might have expected test 3 to fail because it seems to a more general purpose version of test 1. The important difference between them is that test 3 contains a quantifier ( \"\\D*\") and so can use backtracking, whereas test 1 will not. What's happening is that you've asked \"Is it true that at the start of $x, following 0 or more non-digits, you have something that's not 123?\" If the pattern matcher had let \"\\D*\" expand to \" ABC \", this would have caused the whole pattern to fail. The search engine will initially match \"\\D*\" with \" ABC \". Then it will try to match \"(?!123\" with \"123\", which fails. But because a quantifier (\"\\D*\") has been used in the regular expression, the search engine can backtrack and retry the match differently in the hope of matching the complete regular expression. The pattern really, really wants to succeed, so it uses the standard pattern back-off-and-retry and lets \"\\D*\" expand to just \" AB \" this time. Now there's indeed something following \" AB \" that is not \"123\". It's \"C123\", which suffices. We can deal with this by using both an assertion and a negation. We'll say that the first part in $1 must be followed both by a digit and by something that's not \"123\". Remember that the look-aheads are zero-width expressions--they only look, but don't consume any of the string in their match. So rewriting this way produces what you'd expect; that is, case 5 will fail, but case 6 succeeds: print \"5: got $1\\n\" if $x =~ \/^(\\D*)(?=\\d)(?!123)\/;\nprint \"6: got $1\\n\" if $y =~ \/^(\\D*)(?=\\d)(?!123)\/;\n\n6: got ABC In other words, the two zero-width assertions next to each other work as though they're ANDed together, just as you'd use any built-in assertions: \"\/^$\/\" matches only if you're at the beginning of the line AND the end of the line simultaneously. The deeper underlying truth is that juxtaposition in regular expressions always means AND , except when you write an explicit OR using the vertical bar. \"\/ab\/\" means match \"a\" AND (then) match \"b\", although the attempted matches are made at different positions because \"a\" is not a zero-width assertion, but a one-width assertion. WARNING : Particularly complicated regular expressions can take exponential time to solve because of the immense number of possible ways they can use backtracking to try for a match. For example, without internal optimizations done by the regular expression engine, this will take a painfully long time to run: 'aaaaaaaaaaaa' =~ \/((a{0,5}){0,5})*[c]\/ And if you used \"*\"'s in the internal groups instead of limiting them to 0 through 5 matches, then it would take forever--or until you ran out of stack space. Moreover, these internal optimizations are not always applicable. For example, if you put \"{0,5}\" instead of \"*\" on the external group, no current optimization is applicable, and the match takes a long time to finish. A powerful tool for optimizing such beasts is what is known as an \"independent group\", which does not backtrack (see \"(?>pattern)\"). Note also that zero-length look-ahead\/look-behind assertions will not backtrack to make the tail match, since they are in \"logical\" context: only whether they match is considered relevant. For an example where side-effects of look-ahead might have influenced the following match, see \"(?>pattern)\". Version 8 Regular Expressions In case you're not familiar with the \"regular\" Version 8 regex routines, here are the pattern-matching rules not described above. Any single character matches itself, unless it is a metacharacter with a special meaning described here or above. You can cause characters that normally function as metacharacters to be interpreted literally by prefixing them with a \"\\\" (e.g., \"\\.\" matches a \".\", not any character; \"\\\\\" matches a \"\\\"). This escape mechanism is also required for the character used as the pattern delimiter. A series of characters matches that series of characters in the target string, so the pattern \"blurfl\" would match \"blurfl\" in the target string. You can specify a character class, by enclosing a list of characters in \"[]\", which will match any character from the list. If the first character after the \"[\" is \"^\", the class matches any character not in the list. Within a list, the \"-\" character specifies a range, so that \"a-z\" represents all characters between \"a\" and \"z\", inclusive. If you want either \"-\" or \"]\" itself to be a member of a class, put it at the start of the list (possibly after a \"^\"), or escape it with a backslash. \"-\" is also taken literally when it is at the end of the list, just before the closing \"]\". (The following all specify the same class of three characters: \"[-az]\", \"[az-]\", and \"[a\\-z]\". All are different from \"[a-z]\", which specifies a class containing twenty-six characters, even on EBCDIC-based character sets.) Also, if you try to use the character classes \"\\w\", \"\\W\", \"\\s\", \"\\S\", \"\\d\", or \"\\D\" as endpoints of a range, the \"-\" is understood literally. Note also that the whole range idea is rather unportable between character sets--and even within character sets they may cause results you probably didn't expect. A sound principle is to use only ranges that begin from and end at either alphabetics of equal case ([a-e], [A-E]), or digits ([0-9]). Anything else is unsafe. If in doubt, spell out the character sets in full. Characters may be specified using a metacharacter syntax much like that used in C: \"\\n\" matches a newline, \"\\t\" a tab, \"\\r\" a carriage return, \"\\f\" a form feed, etc. More generally, \\nnn, where nnn is a string of octal digits, matches the character whose coded character set value is nnn. Similarly, \\xnn, where nn are hexadecimal digits, matches the character whose numeric value is nn. The expression \\cx matches the character control-x. Finally, the \".\" metacharacter matches any character except \"\\n\" (unless you use \"\/s\"). You can specify a series of alternatives for a pattern using \"|\" to separate them, so that \"fee|fie|foe\" will match any of \"fee\", \"fie\", or \"foe\" in the target string (as would \"f(e|i|o)e\"). The first alternative includes everything from the last pattern delimiter (\"(\", \"[\", or the beginning of the pattern) up to the first \"|\", and the last alternative contains everything from the last \"|\" to the next pattern delimiter. That's why it's common practice to include alternatives in parentheses: to minimize confusion about where they start and end. Alternatives are tried from left to right, so the first alternative found for which the entire expression matches, is the one that is chosen. This means that alternatives are not necessarily greedy. For example: when matching \"foo|foot\" against \"barefoot\", only the \"foo\" part will match, as that is the first alternative tried, and it successfully matches the target string. (This might not seem important, but it is important when you are capturing matched text using parentheses.) Also remember that \"|\" is interpreted as a literal within square brackets, so if you write \"[fee|fie|foe]\" you're really only matching \"[feio|]\". Within a pattern, you may designate subpatterns for later reference by enclosing them in parentheses, and you may refer back to the nth subpattern later in the pattern using the metacharacter \\n. Subpatterns are numbered based on the left to right order of their opening parenthesis. A backreference matches whatever actually matched the subpattern in the string being examined, not the rules for that subpattern. Therefore, \"(0|0x)\\d*\\s\\1\\d*\" will match \"0x1234 0x4321\", but not \"0x1234 01234\", because subpattern 1 matched \"0x\", even though the rule \"0|0x\" could potentially match the leading 0 in the second number. Warning on \\1 Instead of $1 Some people get too used to writing things like: $pattern =~ s\/(\\W)\/\\\\\\1\/g; This is grandfathered for the RHS of a substitute to avoid shocking the sed addicts, but it's a dirty habit to get into. That's because in PerlThink, the righthand side of an \"s\/\/\/\" is a double-quoted string. \"\\1\" in the usual double-quoted string means a control-A. The customary Unix meaning of \"\\1\" is kludged in for \"s\/\/\/\". However, if you get into the habit of doing that, you get yourself into trouble if you then add an \"\/e\" modifier. s\/(\\d+)\/ \\1 + 1 \/eg;        # causes warning under -w Or if you try to do s\/(\\d+)\/\\1000\/; You can't disambiguate that by saying \"\\{1}000\", whereas you can fix it with \"${1}000\". The operation of interpolation should not be confused with the operation of matching a backreference. Certainly they mean two different things on the left side of the \"s\/\/\/\". Repeated Patterns Matching a Zero-length Substring WARNING : Difficult material (and prose) ahead. This section needs a rewrite. Regular expressions provide a terse and powerful programming language. As with most other power tools, power comes together with the ability to wreak havoc. A common abuse of this power stems from the ability to make infinite loops using regular expressions, with something as innocuous as: 'foo' =~ m{ ( o? )* }x; The \"o?\" matches at the beginning of 'foo', and since the position in the string is not moved by the match, \"o?\" would match again and again because of the \"*\" quantifier. Another common way to create a similar cycle is with the looping modifier \"\/\/g\": @matches = ( 'foo' =~ m{ o? }xg ); or print \"match: <$&>\\n\" while 'foo' =~ m{ o? }xg; or the loop implied by split(). However, long experience has shown that many programming tasks may be significantly simplified by using repeated subexpressions that may match zero-length substrings. Here's a simple example being: @chars = split \/\/, $string;           # \/\/ is not magic in split\n($whitewashed = $string) =~ s\/()\/ \/g; # parens avoid magic s\/\/ \/ Thus Perl allows such constructs, by forcefully breaking the infinite loop. The rules for this are different for lower-level loops given by the greedy quantifiers \"*+{}\", and for higher-level ones like the \"\/g\" modifier or split() operator. The lower-level loops are interrupted (that is, the loop is broken) when Perl detects that a repeated expression matched a zero-length substring. Thus m{ (?: NON_ZERO_LENGTH | ZERO_LENGTH )* }x; is made equivalent to m{   (?: NON_ZERO_LENGTH )*\n   |\n     (?: ZERO_LENGTH )?\n }x; The higher level-loops preserve an additional state between iterations: whether the last match was zero-length. To break the loop, the following match after a zero-length match is prohibited to have a length of zero. This prohibition interacts with backtracking (see \"Backtracking\"), and so the second best match is chosen if the best match is of zero length. For example: $_ = 'bar';\ns\/\\w??\/<$&>\/g; results in \"<><b><><a><><r><>\". At each position of the string the best match given by non-greedy \"??\" is the zero-length match, and the second best match is what is matched by \"\\w\". Thus zero-length matches alternate with one-character-long matches. Similarly, for repeated \"m\/()\/g\" the second-best match is the match at the position one notch further in the string. The additional state of being matched with zero-length is associated with the matched string, and is reset by each assignment to pos(). Zero-length matches at the end of the previous match are ignored during \"split\". Combining RE Pieces Each of the elementary pieces of regular expressions which were described before (such as \"ab\" or \"\\Z\") could match at most one substring at the given position of the input string. However, in a typical regular expression these elementary pieces are combined into more complicated patterns using combining operators \"ST\", \"S|T\", \"S*\" etc (in these examples \"S\" and \"T\" are regular subexpressions). Such combinations can include alternatives, leading to a problem of choice: if we match a regular expression \"a|ab\" against \"abc\", will it match substring \"a\" or \"ab\"? One way to describe which substring is actually matched is the concept of backtracking (see \"Backtracking\"). However, this description is too low-level and makes you think in terms of a particular implementation. Another description starts with notions of \"better\"\/\"worse\". All the substrings which may be matched by the given regular expression can be sorted from the \"best\" match to the \"worst\" match, and it is the \"best\" match which is chosen. This substitutes the question of \"what is chosen?\" by the question of \"which matches are better, and which are worse?\". Again, for elementary pieces there is no such question, since at most one match at a given position is possible. This section describes the notion of better\/worse for combining operators. In the description below \"S\" and \"T\" are regular subexpressions. \"ST\" Consider two possible matches, \"AB\" and \"A'B'\", \"A\" and \"A'\" are substrings which can be matched by \"S\", \"B\" and \"B'\" are substrings which can be matched by \"T\". If \"A\" is better match for \"S\" than \"A'\", \"AB\" is a better match than \"A'B'\". If \"A\" and \"A'\" coincide: \"AB\" is a better match than \"AB'\" if \"B\" is better match for \"T\" than \"B'\". \"S|T\" When \"S\" can match, it is a better match than when only \"T\" can match. Ordering of two matches for \"S\" is the same as for \"S\". Similar for two matches for \"T\". \"S{REPEAT_COUNT}\" Matches as \"SSS...S\" (repeated as many times as necessary). \"S{min,max}\" Matches as \"S{max}|S{max-1}|...|S{min+1}|S{min}\". \"S{min,max}?\" Matches as \"S{min}|S{min+1}|...|S{max-1}|S{max}\". \"S?\", \"S*\", \"S+\" Same as \"S{0,1}\", \"S{0,BIG_NUMBER}\", \"S{1,BIG_NUMBER}\" respectively. \"S??\", \"S*?\", \"S+?\" Same as \"S{0,1}?\", \"S{0,BIG_NUMBER}?\", \"S{1,BIG_NUMBER}?\" respectively. \"(?>S)\" Matches the best match for \"S\" and only that. \"(?=S)\", \"(?<=S)\" Only the best match for \"S\" is considered. (This is important only if \"S\" has capturing parentheses, and backreferences are used somewhere else in the whole regular expression.) \"(?!S)\", \"(?<!S)\" For this grouping operator there is no need to describe the ordering, since only whether or not \"S\" can match is important. \"(??{ EXPR })\", \"(?PARNO)\" The ordering is the same as for the regular expression which is the result of EXPR , or the pattern contained by capture buffer PARNO . \"(?(condition)yes-pattern|no-pattern)\" Recall that which of \"yes-pattern\" or \"no-pattern\" actually matches is already determined. The ordering of the matches is the same as for the chosen subexpression. The above recipes describe the ordering of matches at a given position. One more rule is needed to understand how a match is determined for the whole regular expression: a match at an earlier position is always better than a match at a later position. Creating Custom RE Engines Overloaded constants (see overload) provide a simple way to extend the functionality of the RE engine. Suppose that we want to enable a new RE escape-sequence \"\\Y|\" which matches at a boundary between whitespace characters and non-whitespace characters. Note that \"(?=\\S)(?<!\\S)|(?!\\S)(?<=\\S)\" matches exactly at these positions, so we want to have each \"\\Y|\" in the place of the more complicated version. We can create a module \"customre\" to do this: package customre;\nuse overload;\n\nsub import {\n  shift;\n  die \"No argument to customre::import allowed\" if @_;\n  overload::constant 'qr' => \\&convert;\n}\n\nsub invalid { die \"\/$_[0]\/: invalid escape '\\\\$_[1]'\"}\n\n# We must also take care of not escaping the legitimate \\\\Y|\n# sequence, hence the presence of '\\\\' in the conversion rules.\nmy %rules = ( '\\\\' => '\\\\\\\\',\n              'Y|' => qr\/(?=\\S)(?<!\\S)|(?!\\S)(?<=\\S)\/ );\nsub convert {\n  my $re = shift;\n  $re =~ s{\n            \\\\ ( \\\\ | Y . )\n          }\n          { $rules{$1} or invalid($re,$1) }sgex;\n  return $re;\n} Now \"use customre\" enables the new escape in constant regular expressions, i.e., those without any runtime variable interpolations. As documented in overload, this conversion will work only over literal parts of regular expressions. For \"\\Y|$re\\Y|\" the variable part of this regular expression needs to be converted explicitly (but only if the special meaning of \"\\Y|\" should be enabled inside $re): use customre;\n$re = <>;\nchomp $re;\n$re = customre::convert $re;\n\/\\Y|$re\\Y|\/;","Process Name":"perlre","Link":"https:\/\/linux.die.net\/man\/1\/perlre"}},{"Process":{"Description":"As of Perl 5.9.5 there is a new interface for plugging and using other regular expression engines than the default one. Each engine is supposed to provide access to a constant structure of the following format: typedef struct regexp_engine {\n    REGEXP* (*comp) (pTHX_ const SV * const pattern, const U32 flags);\n    I32     (*exec) (pTHX_ REGEXP * const rx, char* stringarg, char* strend,\n                     char* strbeg, I32 minend, SV* screamer,\n                     void* data, U32 flags);\n    char*   (*intuit) (pTHX_ REGEXP * const rx, SV *sv, char *strpos,\n                       char *strend, U32 flags,\n                       struct re_scream_pos_data_s *data);\n    SV*     (*checkstr) (pTHX_ REGEXP * const rx);\n    void    (*free) (pTHX_ REGEXP * const rx);\n    void    (*numbered_buff_FETCH) (pTHX_ REGEXP * const rx, const I32 paren,\n                             SV * const sv);\n    void    (*numbered_buff_STORE) (pTHX_ REGEXP * const rx, const I32 paren,\n                                   SV const * const value);\n    I32     (*numbered_buff_LENGTH) (pTHX_ REGEXP * const rx, const SV * const sv,\n                                    const I32 paren);\n    SV*     (*named_buff) (pTHX_ REGEXP * const rx, SV * const key,\n                           SV * const value, U32 flags);\n    SV*     (*named_buff_iter) (pTHX_ REGEXP * const rx, const SV * const lastkey,\n                                const U32 flags);\n    SV*     (*qr_package)(pTHX_ REGEXP * const rx);\n#ifdef USE_ITHREADS\n    void*   (*dupe) (pTHX_ REGEXP * const rx, CLONE_PARAMS *param);\n#endif When a regexp is compiled, its \"engine\" field is then set to point at the appropriate structure, so that when it needs to be used Perl can find the right routines to do so. In order to install a new regexp handler, $^H{regcomp} is set to an integer which (when casted appropriately) resolves to one of these structures. When compiling, the \"comp\" method is executed, and the resulting regexp structure's engine field is expected to point back at the same structure. The pTHX_ symbol in the definition is a macro used by perl under threading to provide an extra argument to the routine holding a pointer back to the interpreter that is executing the regexp. So under threading all routines get an extra argument.","Process Name":"perlreapi","Link":"https:\/\/linux.die.net\/man\/1\/perlreapi"}},{"Process":{"Description":"The top level documentation about Perl regular expressions is found in perlre. This document describes all backslash and escape sequences. After explaining the role of the backslash, it lists all the sequences that have a special meaning in Perl regular expressions (in alphabetical order), then describes each of them. Most sequences are described in detail in different documents; the primary purpose of this document is to have a quick reference guide describing all backslash and escape sequences. The backslash In a regular expression, the backslash can perform one of two tasks: it either takes away the special meaning of the character following it (for instance, \"\\|\" matches a vertical bar, it's not an alternation), or it is the start of a backslash or escape sequence. The rules determining what it is are quite simple: if the character following the backslash is a punctuation (non-word) character (that is, anything that is not a letter, digit or underscore), then the backslash just takes away the special meaning (if any) of the character following it. If the character following the backslash is a letter or a digit, then the sequence may be special; if so, it's listed below. A few letters have not been used yet, and escaping them with a backslash is safe for now, but a future version of Perl may assign a special meaning to it. However, if you have warnings turned on, Perl will issue a warning if you use such a sequence. [1]. It is however guaranteed that backslash or escape sequences never have a punctuation character following the backslash, not now, and not in a future version of Perl 5. So it is safe to put a backslash in front of a non-word character. Note that the backslash itself is special; if you want to match a backslash, you have to escape the backslash with a backslash: \"\/\\\\\/\" matches a single backslash. [1] There is one exception. If you use an alphanumerical character as the delimiter of your pattern (which you probably shouldn't do for readability reasons), you will have to escape the delimiter if you want to match it. Perl won't warn then. See also \"Gory details of parsing quoted constructs\" in perlop. All the sequences and escapes \\000              Octal escape sequence.\n\\1                Absolute backreference.\n\\a                Alarm or bell.\n\\A                Beginning of string.\n\\b                Word\/non-word boundary. (Backspace in a char class).\n\\B                Not a word\/non-word boundary.\n\\cX               Control-X (X can be any ASCII character).\n\\C                Single octet, even under UTF-8.\n\\d                Character class for digits.\n\\D                Character class for non-digits.\n\\e                Escape character.\n\\E                Turn off \\Q, \\L and \\U processing.\n\\f                Form feed.\n\\g{}, \\g1         Named, absolute or relative backreference.\n\\G                Pos assertion.\n\\h                Character class for horizontal white space.\n\\H                Character class for non horizontal white space.\n\\k{}, \\k<>, \\k''  Named backreference.\n\\K                Keep the stuff left of \\K.\n\\l                Lowercase next character.\n\\L                Lowercase till \\E.\n\\n                (Logical) newline character.\n\\N{}              Named (Unicode) character.\n\\p{}, \\pP         Character with a Unicode property.\n\\P{}, \\PP         Character without a Unicode property.\n\\Q                Quotemeta till \\E.\n\\r                Return character.\n\\R                Generic new line.\n\\s                Character class for white space.\n\\S                Character class for non white space.\n\\t                Tab character.\n\\u                Titlecase next character.\n\\U                Uppercase till \\E.\n\\v                Character class for vertical white space.\n\\V                Character class for non vertical white space.\n\\w                Character class for word characters.\n\\W                Character class for non-word characters.\n\\x{}, \\x00        Hexadecimal escape sequence.\n\\X                Extended Unicode \"combining character sequence\".\n\\z                End of string.\n\\Z                End of string. Character Escapes Fixed characters A handful of characters have a dedicated character escape. The following table shows them, along with their code points (in decimal and hex), their ASCII name, the control escape (see below) and a short description. Seq.  Code Point  ASCII   Cntr    Description.\n      Dec    Hex\n \\a     7     07    BEL    \\cG    alarm or bell\n \\b     8     08     BS    \\cH    backspace [1]\n \\e    27     1B    ESC    \\c[    escape character\n \\f    12     0C     FF    \\cL    form feed\n \\n    10     0A     LF    \\cJ    line feed [2]\n \\r    13     0D     CR    \\cM    carriage return\n \\t     9     09    TAB    \\cI    tab [1] \"\\b\" is only the backspace character inside a character class. Outside a character class, \"\\b\" is a word\/non-word boundary. [2] \"\\n\" matches a logical newline. Perl will convert between \"\\n\" and your OSses native newline character when reading from or writing to text files. Example $str =~ \/\\t\/;   # Matches if $str contains a (horizontal) tab. Control characters \"\\c\" is used to denote a control character; the character following \"\\c\" is the name of the control character. For instance, \"\/\\cM\/\" matches the character control-M (a carriage return, code point 13). The case of the character following \"\\c\" doesn't matter: \"\\cM\" and \"\\cm\" match the same character. Mnemonic: control character. Example $str =~ \/\\cK\/;  # Matches if $str contains a vertical tab (control-K). Named characters All Unicode characters have a Unicode name, and characters in various scripts have names as well. It is even possible to give your own names to characters. You can use a character by name by using the \"\\N{}\" construct; the name of the character goes between the curly braces. You do have to \"use charnames\" to load the names of the characters, otherwise Perl will complain you use a name it doesn't know about. For more details, see charnames. Mnemonic: Named character. Example use charnames ':full';               # Loads the Unicode names.\n$str =~ \/\\N{THAI CHARACTER SO SO}\/;  # Matches the Thai SO SO character\n\nuse charnames 'Cyrillic';            # Loads Cyrillic names.\n$str =~ \/\\N{ZHE}\\N{KA}\/;             # Match \"ZHE\" followed by \"KA\". Octal escapes Octal escapes consist of a backslash followed by two or three octal digits matching the code point of the character you want to use. This allows for 512 characters (\"\\00\" up to \"\\777\") that can be expressed this way. Enough in pre-Unicode days, but most Unicode characters cannot be escaped this way. Note that a character that is expressed as an octal escape is considered as a character without special meaning by the regex engine, and will match \"as is\". Examples $str = \"Perl\";\n$str =~ \/\\120\/;    # Match, \"\\120\" is \"P\".\n$str =~ \/\\120+\/;   # Match, \"\\120\" is \"P\", it is repeated at least once.\n$str =~ \/P\\053\/;   # No match, \"\\053\" is \"+\" and taken literally. Caveat Octal escapes potentially clash with backreferences. They both consist of a backslash followed by numbers. So Perl has to use heuristics to determine whether it is a backreference or an octal escape. Perl uses the following rules: 1. If the backslash is followed by a single digit, it's a backreference. 2. If the first digit following the backslash is a 0, it's an octal escape. 3. If the number following the backslash is N (decimal), and Perl already has seen N capture groups, Perl will consider this to be a backreference. Otherwise, it will consider it to be an octal escape. Note that if N > 999, Perl only takes the first three digits for the octal escape; the rest is matched as is. my $pat  = \"(\" x 999;\n   $pat .= \"a\";\n   $pat .= \")\" x 999;\n\/^($pat)\\1000$\/;   #  Matches 'aa'; there are 1000 capture groups.\n\/^$pat\\1000$\/;     #  Matches 'a@0'; there are 999 capture groups\n                   #    and \\1000 is seen as \\100 (a '@') and a '0'. Hexadecimal escapes Hexadecimal escapes start with \"\\x\" and are then either followed by two digit hexadecimal number, or a hexadecimal number of arbitrary length surrounded by curly braces. The hexadecimal number is the code point of the character you want to express. Note that a character that is expressed as a hexadecimal escape is considered as a character without special meaning by the regex engine, and will match \"as is\". Mnemonic: hexadecimal. Examples $str = \"Perl\";\n$str =~ \/\\x50\/;    # Match, \"\\x50\" is \"P\".\n$str =~ \/\\x50+\/;   # Match, \"\\x50\" is \"P\", it is repeated at least once.\n$str =~ \/P\\x2B\/;   # No match, \"\\x2B\" is \"+\" and taken literally.\n\n\/\\x{2603}\\x{2602}\/ # Snowman with an umbrella.\n                   # The Unicode character 2603 is a snowman,\n                   # the Unicode character 2602 is an umbrella.\n\/\\x{263B}\/         # Black smiling face.\n\/\\x{263b}\/         # Same, the hex digits A - F are case insensitive. Modifiers A number of backslash sequences have to do with changing the character, or characters following them. \"\\l\" will lowercase the character following it, while \"\\u\" will uppercase (or, more accurately, titlecase) the character following it. (They perform similar functionality as the functions \"lcfirst\" and \"ucfirst\"). To uppercase or lowercase several characters, one might want to use \"\\L\" or \"\\U\", which will lowercase\/uppercase all characters following them, until either the end of the pattern, or the next occurrence of \"\\E\", whatever comes first. They perform similar functionality as the functions \"lc\" and \"uc\" do. \"\\Q\" is used to escape all characters following, up to the next \"\\E\" or the end of the pattern. \"\\Q\" adds a backslash to any character that isn't a letter, digit or underscore. This will ensure that any character between \"\\Q\" and \"\\E\" is matched literally, and will not be interpreted by the regexp engine. Mnemonic: Lowercase, Uppercase, Quotemeta, End. Examples $sid     = \"sid\";\n$greg    = \"GrEg\";\n$miranda = \"(Miranda)\";\n$str     =~ \/\\u$sid\/;        # Matches 'Sid'\n$str     =~ \/\\L$greg\/;       # Matches 'greg'\n$str     =~ \/\\Q$miranda\\E\/;  # Matches '(Miranda)', as if the pattern\n                             #   had been written as \/\\(Miranda\\)\/ Character classes Perl regular expressions have a large range of character classes. Some of the character classes are written as a backslash sequence. We will briefly discuss those here; full details of character classes can be found in perlrecharclass. \"\\w\" is a character class that matches any word character (letters, digits, underscore). \"\\d\" is a character class that matches any digit, while the character class \"\\s\" matches any white space character. New in perl 5.10.0 are the classes \"\\h\" and \"\\v\" which match horizontal and vertical white space characters. The uppercase variants (\"\\W\", \"\\D\", \"\\S\", \"\\H\", and \"\\V\") are character classes that match any character that isn't a word character, digit, white space, horizontal white space or vertical white space. Mnemonics: word, digit, space, horizontal, vertical. Unicode classes \"\\pP\" (where \"P\" is a single letter) and \"\\p{Property}\" are used to match a character that matches the given Unicode property; properties include things like \"letter\", or \"thai character\". Capitalizing the sequence to \"\\PP\" and \"\\P{Property}\" make the sequence match a character that doesn't match the given Unicode property. For more details, see \"Backslashed sequences\" in perlrecharclass and \"Unicode Character Properties\" in perlunicode. Mnemonic: property. Referencing If capturing parenthesis are used in a regular expression, we can refer to the part of the source string that was matched, and match exactly the same thing. There are three ways of referring to such backreference: absolutely, relatively, and by name. Absolute referencing A backslash sequence that starts with a backslash and is followed by a number is an absolute reference (but be aware of the caveat mentioned above). If the number is N, it refers to the Nth set of parenthesis - whatever has been matched by that set of parenthesis has to be matched by the \"\\N\" as well. Examples \/(\\w+) \\1\/;    # Finds a duplicated word, (e.g. \"cat cat\").\n\/(.)(.)\\2\\1\/;  # Match a four letter palindrome (e.g. \"ABBA\"). Relative referencing New in perl 5.10.0 is a different way of referring to capture buffers: \"\\g\". \"\\g\" takes a number as argument, with the number in curly braces (the braces are optional). If the number (N) does not have a sign, it's a reference to the Nth capture group (so \"\\g{2}\" is equivalent to \"\\2\" - except that \"\\g\" always refers to a capture group and will never be seen as an octal escape). If the number is negative, the reference is relative, referring to the Nth group before the \"\\g{-N}\". The big advantage of \"\\g{-N}\" is that it makes it much easier to write patterns with references that can be interpolated in larger patterns, even if the larger pattern also contains capture groups. Mnemonic: group. Examples \/(A)        # Buffer 1\n (          # Buffer 2\n   (B)      # Buffer 3\n   \\g{-1}   # Refers to buffer 3 (B)\n   \\g{-3}   # Refers to buffer 1 (A)\n )\n\/x;         # Matches \"ABBA\".\n\nmy $qr = qr \/(.)(.)\\g{-2}\\g{-1}\/;  # Matches 'abab', 'cdcd', etc.\n\/$qr$qr\/                           # Matches 'ababcdcd'. Named referencing Also new in perl 5.10.0 is the use of named capture buffers, which can be referred to by name. This is done with \"\\g{name}\", which is a backreference to the capture buffer with the name name. To be compatible with .Net regular expressions, \"\\g{name}\" may also be written as \"\\k{name}\", \"\\k<name>\" or \"\\k'name'\". Note that \"\\g{}\" has the potential to be ambiguous, as it could be a named reference, or an absolute or relative reference (if its argument is numeric). However, names are not allowed to start with digits, nor are allowed to contain a hyphen, so there is no ambiguity. Examples \/(?<word>\\w+) \\g{word}\/ # Finds duplicated word, (e.g. \"cat cat\")\n\/(?<word>\\w+) \\k{word}\/ # Same.\n\/(?<word>\\w+) \\k<word>\/ # Same.\n\/(?<letter1>.)(?<letter2>.)\\g{letter2}\\g{letter1}\/\n                        # Match a four letter palindrome (e.g. \"ABBA\") Assertions Assertions are conditions that have to be true -- they don't actually match parts of the substring. There are six assertions that are written as backslash sequences. \\A \"\\A\" only matches at the beginning of the string. If the \"\/m\" modifier isn't used, then \"\/\\A\/\" is equivalent with \"\/^\/\". However, if the \"\/m\" modifier is used, then \"\/^\/\" matches internal newlines, but the meaning of \"\/\\A\/\" isn't changed by the \"\/m\" modifier. \"\\A\" matches at the beginning of the string regardless whether the \"\/m\" modifier is used. \\z, \\Z \"\\z\" and \"\\Z\" match at the end of the string. If the \"\/m\" modifier isn't used, then \"\/\\Z\/\" is equivalent with \"\/$\/\", that is, it matches at the end of the string, or before the newline at the end of the string. If the \"\/m\" modifier is used, then \"\/$\/\" matches at internal newlines, but the meaning of \"\/\\Z\/\" isn't changed by the \"\/m\" modifier. \"\\Z\" matches at the end of the string (or just before a trailing newline) regardless whether the \"\/m\" modifier is used. \"\\z\" is just like \"\\Z\", except that it will not match before a trailing newline. \"\\z\" will only match at the end of the string - regardless of the modifiers used, and not before a newline. \\G \"\\G\" is usually only used in combination with the \"\/g\" modifier. If the \"\/g\" modifier is used (and the match is done in scalar context), Perl will remember where in the source string the last match ended, and the next time, it will start the match from where it ended the previous time. \"\\G\" matches the point where the previous match ended, or the beginning of the string if there was no previous match. Mnemonic: Global. \\b, \\B \"\\b\" matches at any place between a word and a non-word character; \"\\B\" matches at any place between characters where \"\\b\" doesn't match. \"\\b\" and \"\\B\" assume there's a non-word character before the beginning and after the end of the source string; so \"\\b\" will match at the beginning (or end) of the source string if the source string begins (or ends) with a word character. Otherwise, \"\\B\" will match. Mnemonic: boundary. Examples \"cat\"   =~ \/\\Acat\/;     # Match.\n\"cat\"   =~ \/cat\\Z\/;     # Match.\n\"cat\\n\" =~ \/cat\\Z\/;     # Match.\n\"cat\\n\" =~ \/cat\\z\/;     # No match.\n\n\"cat\"   =~ \/\\bcat\\b\/;   # Matches.\n\"cats\"  =~ \/\\bcat\\b\/;   # No match.\n\"cat\"   =~ \/\\bcat\\B\/;   # No match.\n\"cats\"  =~ \/\\bcat\\B\/;   # Match.\n\nwhile (\"cat dog\" =~ \/(\\w+)\/g) {\n    print $1;           # Prints 'catdog'\n}\nwhile (\"cat dog\" =~ \/\\G(\\w+)\/g) {\n    print $1;           # Prints 'cat'\n} Misc Here we document the backslash sequences that don't fall in one of the categories above. They are: \\C \"\\C\" always matches a single octet, even if the source string is encoded in UTF-8 format, and the character to be matched is a multi-octet character. \"\\C\" was introduced in perl 5.6. Mnemonic: o Ctet. \\K This is new in perl 5.10.0. Anything that is matched left of \"\\K\" is not included in $& - and will not be replaced if the pattern is used in a substitution. This will allow you to write \"s\/PAT1 \\K PAT2\/REPL\/x\" instead of \"s\/(PAT1) PAT2\/${1}REPL\/x\" or \"s\/(?<=PAT1) PAT2\/REPL\/x\". Mnemonic: Keep. \\R \"\\R\" matches a generic newline, that is, anything that is considered a newline by Unicode. This includes all characters matched by \"\\v\" (vertical white space), and the multi character sequence \"\\x0D\\x0A\" (carriage return followed by a line feed, aka the network newline, or the newline used in Windows text files). \"\\R\" is equivalent with \"(?>\\x0D\\x0A)|\\v)\". Since \"\\R\" can match a more than one character, it cannot be put inside a bracketed character class; \"\/[\\R]\/\" is an error. \"\\R\" was introduced in perl 5.10.0. Mnemonic: none really. \"\\R\" was picked because PCRE already uses \"\\R\", and more importantly because Unicode recommends such a regular expression metacharacter, and suggests \"\\R\" as the notation. \\X This matches an extended Unicode combining character sequence, and is equivalent to \"(?>\\PM\\pM*)\". \"\\PM\" matches any character that is not considered a Unicode mark character, while \"\\pM\" matches any character that is considered a Unicode mark character; so \"\\X\" matches any non mark character followed by zero or more mark characters. Mark characters include (but are not restricted to) combining characters and vowel signs. \"\\X\" matches quite well what normal (non-Unicode-programmer) usage would consider a single character: for example a base character (the \"\\PM\" above), for example a letter, followed by zero or more diacritics, which are combining characters (the \"\\pM*\" above). Mnemonic: eXtended Unicode character. Examples \"\\x{256}\" =~ \/^\\C\\C$\/;    # Match as chr (256) takes 2 octets in UTF-8.\n\n$str =~ s\/foo\\Kbar\/baz\/g; # Change any 'bar' following a 'foo' to 'baz'.\n$str =~ s\/(.)\\K\\1\/\/g;     # Delete duplicated characters.\n\n\"\\n\"   =~ \/^\\R$\/;         # Match, \\n   is a generic newline.\n\"\\r\"   =~ \/^\\R$\/;         # Match, \\r   is a generic newline.\n\"\\r\\n\" =~ \/^\\R$\/;         # Match, \\r\\n is a generic newline.\n\n\"P\\x{0307}\" =~ \/^\\X$\/     # \\X matches a P with a dot above. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"perlrebackslash","Link":"https:\/\/linux.die.net\/man\/1\/perlrebackslash"}},{"Process":{"Description":"The top level documentation about Perl regular expressions is found in perlre. This manual page discusses the syntax and use of character classes in Perl Regular Expressions. A character class is a way of denoting a set of characters, in such a way that one character of the set is matched. It's important to remember that matching a character class consumes exactly one character in the source string. (The source string is the string the regular expression is matched against.) There are three types of character classes in Perl regular expressions: the dot, backslashed sequences, and the bracketed form. The dot The dot (or period), \".\" is probably the most used, and certainly the most well-known character class. By default, a dot matches any character, except for the newline. The default can be changed to add matching the newline with the single line modifier: either for the entire regular expression using the \"\/s\" modifier, or locally using \"(?s)\". Here are some examples: \"a\"  =~  \/.\/       # Match\n\".\"  =~  \/.\/       # Match\n\"\"   =~  \/.\/       # No match (dot has to match a character)\n\"\\n\" =~  \/.\/       # No match (dot does not match a newline)\n\"\\n\" =~  \/.\/s      # Match (global 'single line' modifier)\n\"\\n\" =~  \/(?s:.)\/  # Match (local 'single line' modifier)\n\"ab\" =~  \/^.$\/     # No match (dot matches one character) Backslashed sequences Perl regular expressions contain many backslashed sequences that constitute a character class. That is, they will match a single character, if that character belongs to a specific set of characters (defined by the sequence). A backslashed sequence is a sequence of characters starting with a backslash. Not all backslashed sequences are character class; for a full list, see perlrebackslash. Here's a list of the backslashed sequences, which are discussed in more detail below. \\d             Match a digit character.\n\\D             Match a non-digit character.\n\\w             Match a \"word\" character.\n\\W             Match a non-\"word\" character.\n\\s             Match a white space character.\n\\S             Match a non-white space character.\n\\h             Match a horizontal white space character.\n\\H             Match a character that isn't horizontal white space.\n\\v             Match a vertical white space character.\n\\V             Match a character that isn't vertical white space.\n\\pP, \\p{Prop}  Match a character matching a Unicode property.\n\\PP, \\P{Prop}  Match a character that doesn't match a Unicode property. Digits \"\\d\" matches a single character that is considered to be a digit. What is considered a digit depends on the internal encoding of the source string. If the source string is in UTF-8 format, \"\\d\" not only matches the digits '0' - '9', but also Arabic, Devanagari and digits from other languages. Otherwise, if there is a locale in effect, it will match whatever characters the locale considers digits. Without a locale, \"\\d\" matches the digits '0' to '9'. See \"Locale, Unicode and UTF-8 \". Any character that isn't matched by \"\\d\" will be matched by \"\\D\". Word characters \"\\w\" matches a single word character: an alphanumeric character (that is, an alphabetic character, or a digit), or the underscore (\"_\"). What is considered a word character depends on the internal encoding of the string. If it's in UTF-8 format, \"\\w\" matches those characters that are considered word characters in the Unicode database. That is, it not only matches ASCII letters, but also Thai letters, Greek letters, etc. If the source string isn't in UTF-8 format, \"\\w\" matches those characters that are considered word characters by the current locale. Without a locale in effect, \"\\w\" matches the ASCII letters, digits and the underscore. Any character that isn't matched by \"\\w\" will be matched by \"\\W\". White space \"\\s\" matches any single character that is consider white space. In the ASCII range, \"\\s\" matches the horizontal tab (\"\\t\"), the new line (\"\\n\"), the form feed (\"\\f\"), the carriage return (\"\\r\"), and the space (the vertical tab, \"\\cK\" is not matched by \"\\s\"). The exact set of characters matched by \"\\s\" depends on whether the source string is in UTF-8 format. If it is, \"\\s\" matches what is considered white space in the Unicode database. Otherwise, if there is a locale in effect, \"\\s\" matches whatever is considered white space by the current locale. Without a locale, \"\\s\" matches the five characters mentioned in the beginning of this paragraph. Perhaps the most notable difference is that \"\\s\" matches a non-breaking space only if the non-breaking space is in a UTF-8 encoded string. Any character that isn't matched by \"\\s\" will be matched by \"\\S\". \"\\h\" will match any character that is considered horizontal white space; this includes the space and the tab characters. \"\\H\" will match any character that is not considered horizontal white space. \"\\v\" will match any character that is considered vertical white space; this includes the carriage return and line feed characters (newline). \"\\V\" will match any character that is not considered vertical white space. \"\\R\" matches anything that can be considered a newline under Unicode rules. It's not a character class, as it can match a multi-character sequence. Therefore, it cannot be used inside a bracketed character class. Details are discussed in perlrebackslash. \"\\h\", \"\\H\", \"\\v\", \"\\V\", and \"\\R\" are new in perl 5.10.0. Note that unlike \"\\s\", \"\\d\" and \"\\w\", \"\\h\" and \"\\v\" always match the same characters, regardless whether the source string is in UTF-8 format or not. The set of characters they match is also not influenced by locale. One might think that \"\\s\" is equivalent with \"[\\h\\v]\". This is not true. The vertical tab (\"\\x0b\") is not matched by \"\\s\", it is however considered vertical white space. Furthermore, if the source string is not in UTF-8 format, the next line (\"\\x85\") and the no-break space (\"\\xA0\") are not matched by \"\\s\", but are by \"\\v\" and \"\\h\" respectively. If the source string is in UTF-8 format, both the next line and the no-break space are matched by \"\\s\". The following table is a complete listing of characters matched by \"\\s\", \"\\h\" and \"\\v\". The first column gives the code point of the character (in hex format), the second column gives the (Unicode) name. The third column indicates by which class(es) the character is matched. 0x00009        CHARACTER TABULATION   h s\n0x0000a              LINE FEED (LF)    vs\n0x0000b             LINE TABULATION    v\n0x0000c              FORM FEED (FF)    vs\n0x0000d        CARRIAGE RETURN (CR)    vs\n0x00020                       SPACE   h s\n0x00085             NEXT LINE (NEL)    vs  [1]\n0x000a0              NO-BREAK SPACE   h s  [1]\n0x01680            OGHAM SPACE MARK   h s\n0x0180e   MONGOLIAN VOWEL SEPARATOR   h s\n0x02000                     EN QUAD   h s\n0x02001                     EM QUAD   h s\n0x02002                    EN SPACE   h s\n0x02003                    EM SPACE   h s\n0x02004          THREE-PER-EM SPACE   h s\n0x02005           FOUR-PER-EM SPACE   h s\n0x02006            SIX-PER-EM SPACE   h s\n0x02007                FIGURE SPACE   h s\n0x02008           PUNCTUATION SPACE   h s\n0x02009                  THIN SPACE   h s\n0x0200a                  HAIR SPACE   h s\n0x02028              LINE SEPARATOR    vs\n0x02029         PARAGRAPH SEPARATOR    vs\n0x0202f       NARROW NO-BREAK SPACE   h s\n0x0205f   MEDIUM MATHEMATICAL SPACE   h s\n0x03000           IDEOGRAPHIC SPACE   h s [1] NEXT LINE and NO-BREAK SPACE only match \"\\s\" if the source string is in UTF-8 format. It is worth noting that \"\\d\", \"\\w\", etc, match single characters, not complete numbers or words. To match a number (that consists of integers), use \"\\d+\"; to match a word, use \"\\w+\". Unicode Properties \"\\pP\" and \"\\p{Prop}\" are character classes to match characters that fit given Unicode classes. One letter classes can be used in the \"\\pP\" form, with the class name following the \"\\p\", otherwise, the property name is enclosed in braces, and follows the \"\\p\". For instance, a match for a number can be written as \"\/\\pN\/\" or as \"\/\\p{Number}\/\". Lowercase letters are matched by the property LowercaseLetter which has as short form Ll. They have to be written as \"\/\\p{Ll}\/\" or \"\/\\p{LowercaseLetter}\/\". \"\/\\pLl\/\" is valid, but means something different. It matches a two character string: a letter (Unicode property \"\\pL\"), followed by a lowercase \"l\". For a list of possible properties, see \"Unicode Character Properties\" in perlunicode. It is also possible to defined your own properties. This is discussed in \"User-Defined Character Properties\" in perlunicode. Examples \"a\"  =~  \/\\w\/      # Match, \"a\" is a 'word' character.\n\"7\"  =~  \/\\w\/      # Match, \"7\" is a 'word' character as well.\n\"a\"  =~  \/\\d\/      # No match, \"a\" isn't a digit.\n\"7\"  =~  \/\\d\/      # Match, \"7\" is a digit.\n\" \"  =~  \/\\s\/      # Match, a space is white space.\n\"a\"  =~  \/\\D\/      # Match, \"a\" is a non-digit.\n\"7\"  =~  \/\\D\/      # No match, \"7\" is not a non-digit.\n\" \"  =~  \/\\S\/      # No match, a space is not non-white space.\n\n\" \"  =~  \/\\h\/      # Match, space is horizontal white space.\n\" \"  =~  \/\\v\/      # No match, space is not vertical white space.\n\"\\r\" =~  \/\\v\/      # Match, a return is vertical white space.\n\n\"a\"  =~  \/\\pL\/     # Match, \"a\" is a letter.\n\"a\"  =~  \/\\p{Lu}\/  # No match, \/\\p{Lu}\/ matches upper case letters.\n\n\"\\x{0e0b}\" =~ \/\\p{Thai}\/  # Match, \\x{0e0b} is the character\n                          # 'THAI CHARACTER SO SO', and that's in\n                          # Thai Unicode class.\n\"a\"  =~  \/\\P{Lao}\/ # Match, as \"a\" is not a Laoian character. Bracketed Character Classes The third form of character class you can use in Perl regular expressions is the bracketed form. In its simplest form, it lists the characters that may be matched inside square brackets, like this: \"[aeiou]\". This matches one of \"a\", \"e\", \"i\", \"o\" or \"u\". Just as the other character classes, exactly one character will be matched. To match a longer string consisting of characters mentioned in the characters class, follow the character class with a quantifier. For instance, \"[aeiou]+\" matches a string of one or more lowercase ASCII vowels. Repeating a character in a character class has no effect; it's considered to be in the set only once. Examples: \"e\"  =~  \/[aeiou]\/        # Match, as \"e\" is listed in the class.\n\"p\"  =~  \/[aeiou]\/        # No match, \"p\" is not listed in the class.\n\"ae\" =~  \/^[aeiou]$\/      # No match, a character class only matches\n                          # a single character.\n\"ae\" =~  \/^[aeiou]+$\/     # Match, due to the quantifier. Special Characters Inside a Bracketed Character Class Most characters that are meta characters in regular expressions (that is, characters that carry a special meaning like \"*\" or \"(\") lose their special meaning and can be used inside a character class without the need to escape them. For instance, \"[()]\" matches either an opening parenthesis, or a closing parenthesis, and the parens inside the character class don't group or capture. Characters that may carry a special meaning inside a character class are: \"\\\", \"^\", \"-\", \"[\" and \"]\", and are discussed below. They can be escaped with a backslash, although this is sometimes not needed, in which case the backslash may be omitted. The sequence \"\\b\" is special inside a bracketed character class. While outside the character class \"\\b\" is an assertion indicating a point that does not have either two word characters or two non-word characters on either side, inside a bracketed character class, \"\\b\" matches a backspace character. A \"[\" is not special inside a character class, unless it's the start of a POSIX character class (see below). It normally does not need escaping. A \"]\" is either the end of a POSIX character class (see below), or it signals the end of the bracketed character class. Normally it needs escaping if you want to include a \"]\" in the set of characters. However, if the \"]\" is the first (or the second if the first character is a caret) character of a bracketed character class, it does not denote the end of the class (as you cannot have an empty class) and is considered part of the set of characters that can be matched without escaping. Examples: \"+\"   =~ \/[+?*]\/     #  Match, \"+\" in a character class is not special.\n\"\\cH\" =~ \/[\\b]\/      #  Match, \\b inside in a character class\n                     #  is equivalent with a backspace.\n\"]\"   =~ \/[][]\/      #  Match, as the character class contains.\n                     #  both [ and ].\n\"[]\"  =~ \/[[]]\/      #  Match, the pattern contains a character class\n                     #  containing just ], and the character class is\n                     #  followed by a ]. Character Ranges It is not uncommon to want to match a range of characters. Luckily, instead of listing all the characters in the range, one may use the hyphen (\"-\"). If inside a bracketed character class you have two characters separated by a hyphen, it's treated as if all the characters between the two are in the class. For instance, \"[0-9]\" matches any ASCII digit, and \"[a-m]\" matches any lowercase letter from the first half of the ASCII alphabet. Note that the two characters on either side of the hyphen are not necessary both letters or both digits. Any character is possible, although not advisable. \"['-?]\" contains a range of characters, but most people will not know which characters that will be. Furthermore, such ranges may lead to portability problems if the code has to run on a platform that uses a different character set, such as EBCDIC . If a hyphen in a character class cannot be part of a range, for instance because it is the first or the last character of the character class, or if it immediately follows a range, the hyphen isn't special, and will be considered a character that may be matched. You have to escape the hyphen with a backslash if you want to have a hyphen in your set of characters to be matched, and its position in the class is such that it can be considered part of a range. Examples: [a-z]       #  Matches a character that is a lower case ASCII letter.\n[a-fz]      #  Matches any letter between 'a' and 'f' (inclusive) or the\n            #  letter 'z'.\n[-z]        #  Matches either a hyphen ('-') or the letter 'z'.\n[a-f-m]     #  Matches any letter between 'a' and 'f' (inclusive), the\n            #  hyphen ('-'), or the letter 'm'.\n['-?]       #  Matches any of the characters  '()*+,-.\/0123456789:;<=>?\n            #  (But not on an EBCDIC platform). Negation It is also possible to instead list the characters you do not want to match. You can do so by using a caret (\"^\") as the first character in the character class. For instance, \"[^a-z]\" matches a character that is not a lowercase ASCII letter. This syntax make the caret a special character inside a bracketed character class, but only if it is the first character of the class. So if you want to have the caret as one of the characters you want to match, you either have to escape the caret, or not list it first. Examples: \"e\"  =~  \/[^aeiou]\/   #  No match, the 'e' is listed.\n\"x\"  =~  \/[^aeiou]\/   #  Match, as 'x' isn't a lowercase vowel.\n\"^\"  =~  \/[^^]\/       #  No match, matches anything that isn't a caret.\n\"^\"  =~  \/[x^]\/       #  Match, caret is not special here. Backslash Sequences You can put a backslash sequence character class inside a bracketed character class, and it will act just as if you put all the characters matched by the backslash sequence inside the character class. For instance, \"[a-f\\d]\" will match any digit, or any of the lowercase letters between 'a' and 'f' inclusive. Examples: \/[\\p{Thai}\\d]\/     # Matches a character that is either a Thai\n                   # character, or a digit.\n\/[^\\p{Arabic}()]\/  # Matches a character that is neither an Arabic\n                   # character, nor a parenthesis. Backslash sequence character classes cannot form one of the endpoints of a range. Posix Character Classes Posix character classes have the form \"[:class:]\", where class is name, and the \"[:\" and \":]\" delimiters. Posix character classes appear inside bracketed character classes, and are a convenient and descriptive way of listing a group of characters. Be careful about the syntax, # Correct:\n$string =~ \/[[:alpha:]]\/\n\n# Incorrect (will warn):\n$string =~ \/[:alpha:]\/ The latter pattern would be a character class consisting of a colon, and the letters \"a\", \"l\", \"p\" and \"h\". Perl recognizes the following POSIX character classes: alpha  Any alphabetical character.\nalnum  Any alphanumerical character.\nascii  Any ASCII character.\nblank  A GNU extension, equal to a space or a horizontal tab (\"\\t\").\ncntrl  Any control character.\ndigit  Any digit, equivalent to \"\\d\".\ngraph  Any printable character, excluding a space.\nlower  Any lowercase character.\nprint  Any printable character, including a space.\npunct  Any punctuation character.\nspace  Any white space character. \"\\s\" plus the vertical tab (\"\\cK\").\nupper  Any uppercase character.\nword   Any \"word\" character, equivalent to \"\\w\".\nxdigit Any hexadecimal digit, '0' - '9', 'a' - 'f', 'A' - 'F'. The exact set of characters matched depends on whether the source string is internally in UTF-8 format or not. See \"Locale, Unicode and UTF-8 \". Most POSIX character classes have \"\\p\" counterparts. The difference is that the \"\\p\" classes will always match according to the Unicode properties, regardless whether the string is in UTF-8 format or not. The following table shows the relation between POSIX character classes and the Unicode properties: [[:...:]]   \\p{...}      backslash\n\nalpha       IsAlpha\nalnum       IsAlnum\nascii       IsASCII\nblank\ncntrl       IsCntrl\ndigit       IsDigit      \\d\ngraph       IsGraph\nlower       IsLower\nprint       IsPrint\npunct       IsPunct\nspace       IsSpace\n            IsSpacePerl  \\s\nupper       IsUpper\nword        IsWord\nxdigit      IsXDigit Some character classes may have a non-obvious name: cntrl Any control character. Usually, control characters don't produce output as such, but instead control the terminal somehow: for example newline and backspace are control characters. All characters with \"ord()\" less than 32 are usually classified as control characters (in ASCII , the ISO Latin character sets, and Unicode), as is the character \"ord()\" value of 127 ( \"DEL\"). graph Any character that is graphical, that is, visible. This class consists of all the alphanumerical characters and all punctuation characters. print All printable characters, which is the set of all the graphical characters plus the space. punct Any punctuation (special) character. Negation A Perl extension to the POSIX character class is the ability to negate it. This is done by prefixing the class name with a caret (\"^\"). Some examples: POSIX         Unicode       Backslash\n[[:^digit:]]  \\P{IsDigit}   \\D\n[[:^space:]]  \\P{IsSpace}   \\S\n[[:^word:]]   \\P{IsWord}    \\W [= =] and [. .] Perl will recognize the POSIX character classes \"[=class=]\", and \"[.class.]\", but does not (yet?) support this construct. Use of such a construct will lead to an error. Examples \/[[:digit:]]\/            # Matches a character that is a digit.\n\/[01[:lower:]]\/          # Matches a character that is either a\n                         # lowercase letter, or '0' or '1'.\n\/[[:digit:][:^xdigit:]]\/ # Matches a character that can be anything,\n                         # but the letters 'a' to 'f' in either case.\n                         # This is because the character class contains\n                         # all digits, and anything that isn't a\n                         # hex digit, resulting in a class containing\n                         # all characters, but the letters 'a' to 'f'\n                         # and 'A' to 'F'. Locale, Unicode and UTF-8 Some of the character classes have a somewhat different behaviour depending on the internal encoding of the source string, and the locale that is in effect. \"\\w\", \"\\d\", \"\\s\" and the POSIX character classes (and their negations, including \"\\W\", \"\\D\", \"\\S\") suffer from this behaviour. The rule is that if the source string is in UTF-8 format, the character classes match according to the Unicode properties. If the source string isn't, then the character classes match according to whatever locale is in effect. If there is no locale, they match the ASCII defaults (52 letters, 10 digits and underscore for \"\\w\", 0 to 9 for \"\\d\", etc). This usually means that if you are matching against characters whose \"ord()\" values are between 128 and 255 inclusive, your character class may match or not depending on the current locale, and whether the source string is in UTF-8 format. The string will be in UTF-8 format if it contains characters whose \"ord()\" value exceeds 255. But a string may be in UTF-8 format without it having such characters. For portability reasons, it may be better to not use \"\\w\", \"\\d\", \"\\s\" or the POSIX character classes, and use the Unicode properties instead. Examples $str =  \"\\xDF\";      # $str is not in UTF-8 format.\n$str =~ \/^\\w\/;       # No match, as $str isn't in UTF-8 format.\n$str .= \"\\x{0e0b}\";  # Now $str is in UTF-8 format.\n$str =~ \/^\\w\/;       # Match! $str is now in UTF-8 format.\nchop $str;\n$str =~ \/^\\w\/;       # Still a match! $str remains in UTF-8 format. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"perlrecharclass","Link":"https:\/\/linux.die.net\/man\/1\/perlrecharclass"}},{"Process":{"Description":"Before release 5 of Perl it was difficult to represent complex data structures, because all references had to be symbolic--and even then it was difficult to refer to a variable instead of a symbol table entry. Perl now not only makes it easier to use symbolic references to variables, but also lets you have \"hard\" references to any piece of data or code. Any scalar may hold a hard reference. Because arrays and hashes contain scalars, you can now easily build arrays of arrays, arrays of hashes, hashes of arrays, arrays of hashes of functions, and so on. Hard references are smart--they keep track of reference counts for you, automatically freeing the thing referred to when its reference count goes to zero. (Reference counts for values in self-referential or cyclic data structures may not go to zero without a little help; see \"Two-Phased Garbage Collection\" in perlobj for a detailed explanation.) If that thing happens to be an object, the object is destructed. See perlobj for more about objects. (In a sense, everything in Perl is an object, but we usually reserve the word for references to objects that have been officially \"blessed\" into a class package.) Symbolic references are names of variables or other objects, just as a symbolic link in a Unix filesystem contains merely the name of a file. The *glob notation is something of a symbolic reference. (Symbolic references are sometimes called \"soft references\", but please don't call them that; references are confusing enough without useless synonyms.) In contrast, hard references are more like hard links in a Unix file system: They are used to access an underlying object without concern for what its (other) name is. When the word \"reference\" is used without an adjective, as in the following paragraph, it is usually talking about a hard reference. References are easy to use in Perl. There is just one overriding principle: Perl does no implicit referencing or dereferencing. When a scalar is holding a reference, it always behaves as a simple scalar. It doesn't magically start being an array or hash or subroutine; you have to tell it explicitly to do so, by dereferencing it. Making References References can be created in several ways. 1. By using the backslash operator on a variable, subroutine, or value. (This works much like the & (address-of) operator in C.) This typically creates another reference to a variable, because there's already a reference to the variable in the symbol table. But the symbol table reference might go away, and you'll still have the reference that the backslash returned. Here are some examples: $scalarref = \\$foo;\n$arrayref  = \\@ARGV;\n$hashref   = \\%ENV;\n$coderef   = \\&handler;\n$globref   = \\*foo; It isn't possible to create a true reference to an IO handle (filehandle or dirhandle) using the backslash operator. The most you can get is a reference to a typeglob, which is actually a complete symbol table entry. But see the explanation of the *foo{THING} syntax below. However, you can still use type globs and globrefs as though they were IO handles. 2. A reference to an anonymous array can be created using square brackets: $arrayref = [1, 2, ['a', 'b', 'c']]; Here we've created a reference to an anonymous array of three elements whose final element is itself a reference to another anonymous array of three elements. (The multidimensional syntax described later can be used to access this. For example, after the above, \"$arrayref->[2][1]\" would have the value \"b\".) Taking a reference to an enumerated list is not the same as using square brackets--instead it's the same as creating a list of references! @list = (\\$a, \\@b, \\%c);\n@list = \\($a, @b, %c);      # same thing! As a special case, \"\\(@foo)\" returns a list of references to the contents of @foo, not a reference to @foo itself. Likewise for %foo, except that the key references are to copies (since the keys are just strings rather than full-fledged scalars). 3. A reference to an anonymous hash can be created using curly brackets: $hashref = {\n    'Adam'  => 'Eve',\n    'Clyde' => 'Bonnie',\n}; Anonymous hash and array composers like these can be intermixed freely to produce as complicated a structure as you want. The multidimensional syntax described below works for these too. The values above are literals, but variables and expressions would work just as well, because assignment operators in Perl (even within local() or my()) are executable statements, not compile-time declarations. Because curly brackets (braces) are used for several other things including BLOCKs, you may occasionally have to disambiguate braces at the beginning of a statement by putting a \"+\" or a \"return\" in front so that Perl realizes the opening brace isn't starting a BLOCK . The economy and mnemonic value of using curlies is deemed worth this occasional extra hassle. For example, if you wanted a function to make a new hash and return a reference to it, you have these options: sub hashem {        { @_ } }   # silently wrong\nsub hashem {       +{ @_ } }   # ok\nsub hashem { return { @_ } }   # ok On the other hand, if you want the other meaning, you can do this: sub showem {        { @_ } }   # ambiguous (currently ok, but may change)\nsub showem {       {; @_ } }   # ok\nsub showem { { return @_ } }   # ok The leading \"+{\" and \"{;\" always serve to disambiguate the expression to mean either the HASH reference, or the BLOCK . 4. A reference to an anonymous subroutine can be created by using \"sub\" without a subname: $coderef = sub { print \"Boink!\\n\" }; Note the semicolon. Except for the code inside not being immediately executed, a \"sub {}\" is not so much a declaration as it is an operator, like \"do{}\" or \"eval{}\". (However, no matter how many times you execute that particular line (unless you're in an \"eval(\"...\")\"), $coderef will still have a reference to the same anonymous subroutine.) Anonymous subroutines act as closures with respect to my() variables, that is, variables lexically visible within the current scope. Closure is a notion out of the Lisp world that says if you define an anonymous function in a particular lexical context, it pretends to run in that context even when it's called outside the context. In human terms, it's a funny way of passing arguments to a subroutine when you define it as well as when you call it. It's useful for setting up little bits of code to run later, such as callbacks. You can even do object-oriented stuff with it, though Perl already provides a different mechanism to do that--see perlobj. You might also think of closure as a way to write a subroutine template without using eval(). Here's a small example of how closures work: sub newprint {\n    my $x = shift;\n    return sub { my $y = shift; print \"$x, $y!\\n\"; };\n}\n$h = newprint(\"Howdy\");\n$g = newprint(\"Greetings\");\n\n# Time passes...\n\n&$h(\"world\");\n&$g(\"earthlings\"); This prints Howdy, world!\nGreetings, earthlings! Note particularly that $x continues to refer to the value passed into newprint() despite \"my $x\" having gone out of scope by the time the anonymous subroutine runs. That's what a closure is all about. This applies only to lexical variables, by the way. Dynamic variables continue to work as they have always worked. Closure is not something that most Perl programmers need trouble themselves about to begin with. 5. References are often returned by special subroutines called constructors. Perl objects are just references to a special type of object that happens to know which package it's associated with. Constructors are just special subroutines that know how to create that association. They do so by starting with an ordinary reference, and it remains an ordinary reference even while it's also being an object. Constructors are often named \"new()\". You can call them indirectly: $objref = new Doggie( Tail => 'short', Ears => 'long' ); But that can produce ambiguous syntax in certain cases, so it's often better to use the direct method invocation approach: $objref   = Doggie->new(Tail => 'short', Ears => 'long');\n\nuse Term::Cap;\n$terminal = Term::Cap->Tgetent( { OSPEED => 9600 });\n\nuse Tk;\n$main    = MainWindow->new();\n$menubar = $main->Frame(-relief              => \"raised\",\n                        -borderwidth         => 2) 6. References of the appropriate type can spring into existence if you dereference them in a context that assumes they exist. Because we haven't talked about dereferencing yet, we can't show you any examples yet. 7. A reference can be created by using a special syntax, lovingly known as the *foo{ THING } syntax. *foo{ THING } returns a reference to the THING slot in *foo (which is the symbol table entry which holds everything known as foo). $scalarref = *foo{SCALAR};\n$arrayref  = *ARGV{ARRAY};\n$hashref   = *ENV{HASH};\n$coderef   = *handler{CODE};\n$ioref     = *STDIN{IO};\n$globref   = *foo{GLOB};\n$formatref = *foo{FORMAT}; All of these are self-explanatory except for *foo{IO}. It returns the IO handle, used for file handles (\"open\" in perlfunc), sockets (\"socket\" in perlfunc and \"socketpair\" in perlfunc), and directory handles (\"opendir\" in perlfunc). For compatibility with previous versions of Perl, *foo{FILEHANDLE} is a synonym for *foo{IO}, though it is deprecated as of 5.8.0. If deprecation warnings are in effect, it will warn of its use. *foo{THING} returns undef if that particular THING hasn't been used yet, except in the case of scalars. *foo{SCALAR} returns a reference to an anonymous scalar if $foo hasn't been used yet. This might change in a future release. *foo{IO} is an alternative to the *HANDLE mechanism given in \"Typeglobs and Filehandles\" in perldata for passing filehandles into or out of subroutines, or storing into larger data structures. Its disadvantage is that it won't create a new filehandle for you. Its advantage is that you have less risk of clobbering more than you want to with a typeglob assignment. (It still conflates file and directory handles, though.) However, if you assign the incoming value to a scalar instead of a typeglob as we do in the examples below, there's no risk of that happening. splutter(*STDOUT);          # pass the whole glob\nsplutter(*STDOUT{IO});      # pass both file and dir handles\n\nsub splutter {\n    my $fh = shift;\n    print $fh \"her um well a hmmm\\n\";\n}\n\n$rec = get_rec(*STDIN);     # pass the whole glob\n$rec = get_rec(*STDIN{IO}); # pass both file and dir handles\n\nsub get_rec {\n    my $fh = shift;\n    return scalar <$fh>;\n} Using References That's it for creating references. By now you're probably dying to know how to use references to get back to your long-lost data. There are several basic methods. 1. Anywhere you'd put an identifier (or chain of identifiers) as part of a variable or subroutine name, you can replace the identifier with a simple scalar variable containing a reference of the correct type: $bar = $$scalarref;\npush(@$arrayref, $filename);\n$$arrayref[0] = \"January\";\n$$hashref{\"KEY\"} = \"VALUE\";\n&$coderef(1,2,3);\nprint $globref \"output\\n\"; It's important to understand that we are specifically not dereferencing $arrayref[0] or $hashref{\"KEY\"} there. The dereference of the scalar variable happens before it does any key lookups. Anything more complicated than a simple scalar variable must use methods 2 or 3 below. However, a \"simple scalar\" includes an identifier that itself uses method 1 recursively. Therefore, the following prints \"howdy\". $refrefref = \\\\\\\"howdy\";\nprint $$$$refrefref; 2. Anywhere you'd put an identifier (or chain of identifiers) as part of a variable or subroutine name, you can replace the identifier with a BLOCK returning a reference of the correct type. In other words, the previous examples could be written like this: $bar = ${$scalarref};\npush(@{$arrayref}, $filename);\n${$arrayref}[0] = \"January\";\n${$hashref}{\"KEY\"} = \"VALUE\";\n&{$coderef}(1,2,3);\n$globref->print(\"output\\n\");  # iff IO::Handle is loaded Admittedly, it's a little silly to use the curlies in this case, but the BLOCK can contain any arbitrary expression, in particular, subscripted expressions: &{ $dispatch{$index} }(1,2,3);      # call correct routine Because of being able to omit the curlies for the simple case of $$x, people often make the mistake of viewing the dereferencing symbols as proper operators, and wonder about their precedence. If they were, though, you could use parentheses instead of braces. That's not the case. Consider the difference below; case 0 is a short-hand version of case 1, not case 2: $$hashref{\"KEY\"}   = \"VALUE\";       # CASE 0\n${$hashref}{\"KEY\"} = \"VALUE\";       # CASE 1\n${$hashref{\"KEY\"}} = \"VALUE\";       # CASE 2\n${$hashref->{\"KEY\"}} = \"VALUE\";     # CASE 3 Case 2 is also deceptive in that you're accessing a variable called %hashref, not dereferencing through $hashref to the hash it's presumably referencing. That would be case 3. 3. Subroutine calls and lookups of individual array elements arise often enough that it gets cumbersome to use method 2. As a form of syntactic sugar, the examples for method 2 may be written: $arrayref->[0] = \"January\";   # Array element\n$hashref->{\"KEY\"} = \"VALUE\";  # Hash element\n$coderef->(1,2,3);            # Subroutine call The left side of the arrow can be any expression returning a reference, including a previous dereference. Note that $array[$x] is not the same thing as \"$array->[$x]\" here: $array[$x]->{\"foo\"}->[0] = \"January\"; This is one of the cases we mentioned earlier in which references could spring into existence when in an lvalue context. Before this statement, $array[$x] may have been undefined. If so, it's automatically defined with a hash reference so that we can look up \"{\"foo\"}\" in it. Likewise \"$array[$x]->{\"foo\"}\" will automatically get defined with an array reference so that we can look up \"[0]\" in it. This process is called autovivification. One more thing here. The arrow is optional between brackets subscripts, so you can shrink the above down to $array[$x]{\"foo\"}[0] = \"January\"; Which, in the degenerate case of using only ordinary arrays, gives you multidimensional arrays just like C's: $score[$x][$y][$z] += 42; Well, okay, not entirely like C's arrays, actually. C doesn't know how to grow its arrays on demand. Perl does. 4. If a reference happens to be a reference to an object, then there are probably methods to access the things referred to, and you should probably stick to those methods unless you're in the class package that defines the object's methods. In other words, be nice, and don't violate the object's encapsulation without a very good reason. Perl does not enforce encapsulation. We are not totalitarians here. We do expect some basic civility though. Using a string or number as a reference produces a symbolic reference, as explained above. Using a reference as a number produces an integer representing its storage location in memory. The only useful thing to be done with this is to compare two references numerically to see whether they refer to the same location. if ($ref1 == $ref2) {  # cheap numeric compare of references\n    print \"refs 1 and 2 refer to the same thing\\n\";\n} Using a reference as a string produces both its referent's type, including any package blessing as described in perlobj, as well as the numeric address expressed in hex. The ref() operator returns just the type of thing the reference is pointing to, without the address. See \"ref\" in perlfunc for details and examples of its use. The bless() operator may be used to associate the object a reference points to with a package functioning as an object class. See perlobj. A typeglob may be dereferenced the same way a reference can, because the dereference syntax always indicates the type of reference desired. So \"${*foo}\" and \"${\\$foo}\" both indicate the same scalar variable. Here's a trick for interpolating a subroutine call into a string: print \"My sub returned @{[mysub(1,2,3)]} that time.\\n\"; The way it works is that when the \"@{...}\" is seen in the double-quoted string, it's evaluated as a block. The block creates a reference to an anonymous array containing the results of the call to \"mysub(1,2,3)\". So the whole block returns a reference to an array, which is then dereferenced by \"@{...}\" and stuck into the double-quoted string. This chicanery is also useful for arbitrary expressions: print \"That yields @{[$n + 5]} widgets\\n\"; Similarly, an expression that returns a reference to a scalar can be dereferenced via \"${...}\". Thus, the above expression may be written as: print \"That yields ${\\($n + 5)} widgets\\n\"; Symbolic references We said that references spring into existence as necessary if they are undefined, but we didn't say what happens if a value used as a reference is already defined, but isn't a hard reference. If you use it as a reference, it'll be treated as a symbolic reference. That is, the value of the scalar is taken to be the name of a variable, rather than a direct link to a (possibly) anonymous value. People frequently expect it to work like this. So it does. $name = \"foo\";\n$$name = 1;                 # Sets $foo\n${$name} = 2;               # Sets $foo\n${$name x 2} = 3;           # Sets $foofoo\n$name->[0] = 4;             # Sets $foo[0]\n@$name = ();                # Clears @foo\n&$name();                   # Calls &foo() (as in Perl 4)\n$pack = \"THAT\";\n${\"${pack}::$name\"} = 5;    # Sets $THAT::foo without eval This is powerful, and slightly dangerous, in that it's possible to intend (with the utmost sincerity) to use a hard reference, and accidentally use a symbolic reference instead. To protect against that, you can say use strict 'refs'; and then only hard references will be allowed for the rest of the enclosing block. An inner block may countermand that with no strict 'refs'; Only package variables (globals, even if localized) are visible to symbolic references. Lexical variables (declared with my()) aren't in a symbol table, and thus are invisible to this mechanism. For example: local $value = 10;\n$ref = \"value\";\n{\n    my $value = 20;\n    print $$ref;\n} This will still print 10, not 20. Remember that local() affects package variables, which are all \"global\" to the package. Not-so-symbolic references A new feature contributing to readability in perl version 5.001 is that the brackets around a symbolic reference behave more like quotes, just as they always have within a string. That is, $push = \"pop on \";\nprint \"${push}over\"; has always meant to print \"pop on over\", even though push is a reserved word. This has been generalized to work the same outside of quotes, so that print ${push} . \"over\"; and even print ${ push } . \"over\"; will have the same effect. (This would have been a syntax error in Perl 5.000, though Perl 4 allowed it in the spaceless form.) This construct is not considered to be a symbolic reference when you're using strict refs: use strict 'refs';\n${ bareword };      # Okay, means $bareword.\n${ \"bareword\" };    # Error, symbolic reference. Similarly, because of all the subscripting that is done using single words, we've applied the same rule to any bareword that is used for subscripting a hash. So now, instead of writing $array{ \"aaa\" }{ \"bbb\" }{ \"ccc\" } you can write just $array{ aaa }{ bbb }{ ccc } and not worry about whether the subscripts are reserved words. In the rare event that you do wish to do something like $array{ shift } you can force interpretation as a reserved word by adding anything that makes it more than a bareword: $array{ shift() }\n$array{ +shift }\n$array{ shift @_ } The \"use warnings\" pragma or the -w switch will warn you if it interprets a reserved word as a string. But it will no longer warn you about using lowercase words, because the string is effectively quoted. Pseudo-hashes: Using an array as a hash Pseudo-hashes have been removed from Perl. The 'fields' pragma remains available. Function Templates As explained above, an anonymous function with access to the lexical variables visible when that function was compiled, creates a closure. It retains access to those variables even though it doesn't get run until later, such as in a signal handler or a Tk callback. Using a closure as a function template allows us to generate many functions that act similarly. Suppose you wanted functions named after the colors that generated HTML font changes for the various colors: print \"Be \", red(\"careful\"), \"with that \", green(\"light\"); The red() and green() functions would be similar. To create these, we'll assign a closure to a typeglob of the name of the function we're trying to build. @colors = qw(red blue green yellow orange purple violet);\nfor my $name (@colors) {\n    no strict 'refs';       # allow symbol table manipulation\n    *$name = *{uc $name} = sub { \"<FONT COLOR='$name'>@_<\/FONT>\" };\n} Now all those different functions appear to exist independently. You can call red(), RED (), blue(), BLUE (), green(), etc. This technique saves on both compile time and memory use, and is less error-prone as well, since syntax checks happen at compile time. It's critical that any variables in the anonymous subroutine be lexicals in order to create a proper closure. That's the reasons for the \"my\" on the loop iteration variable. This is one of the only places where giving a prototype to a closure makes much sense. If you wanted to impose scalar context on the arguments of these functions (probably not a wise idea for this particular example), you could have written it this way instead: *$name = sub ($) { \"<FONT COLOR='$name'>$_[0]<\/FONT>\" }; However, since prototype checking happens at compile time, the assignment above happens too late to be of much use. You could address this by putting the whole loop of assignments within a BEGIN block, forcing it to occur during compilation. Access to lexicals that change over time--like those in the \"for\" loop above, basically aliases to elements from the surrounding lexical scopes-- only works with anonymous subs, not with named subroutines. Generally said, named subroutines do not nest properly and should only be declared in the main package scope. This is because named subroutines are created at compile time so their lexical variables get assigned to the parent lexicals from the first execution of the parent block. If a parent scope is entered a second time, its lexicals are created again, while the nested subs still reference the old ones. Anonymous subroutines get to capture each time you execute the \"sub\" operator, as they are created on the fly. If you are accustomed to using nested subroutines in other programming languages with their own private variables, you'll have to work at it a bit in Perl. The intuitive coding of this type of thing incurs mysterious warnings about \"will not stay shared\" due to the reasons explained above. For example, this won't work: sub outer {\n    my $x = $_[0] + 35;\n    sub inner { return $x * 19 }   # WRONG\n    return $x + inner();\n} A work-around is the following: sub outer {\n    my $x = $_[0] + 35;\n    local *inner = sub { return $x * 19 };\n    return $x + inner();\n} Now inner() can only be called from within outer(), because of the temporary assignments of the anonymous subroutine. But when it does, it has normal access to the lexical variable $x from the scope of outer() at the time outer is invoked. This has the interesting effect of creating a function local to another function, something not normally supported in Perl.","Process Name":"perlref","Link":"https:\/\/linux.die.net\/man\/1\/perlref"}},{"Process":{"Description":"One of the most important new features in Perl 5 was the capability to manage complicated data structures like multidimensional arrays and nested hashes. To enable these, Perl 5 introduced a feature called 'references', and using references is the key to managing complicated, structured data in Perl. Unfortunately, there's a lot of funny syntax to learn, and the main manual page can be hard to follow. The manual is quite complete, and sometimes people find that a problem, because it can be hard to tell what is important and what isn't. Fortunately, you only need to know 10% of what's in the main page to get 90% of the benefit. This page will show you that 10%.","Process Name":"perlreftut","Link":"https:\/\/linux.die.net\/man\/1\/perlreftut"}},{"Process":{"Description":"This document is an attempt to shine some light on the guts of the regex engine and how it works. The regex engine represents a significant chunk of the perl codebase, but is relatively poorly understood. This document is a meagre attempt at addressing this situation. It is derived from the author's experience, comments in the source code, other papers on the regex engine, feedback on the perl5-porters mail list, and no doubt other places as well. NOTICE ! It should be clearly understood that the behavior and structures discussed in this represents the state of the engine as the author understood it at the time of writing. It is NOT an API definition, it is purely an internals guide for those who want to hack the regex engine, or understand how the regex engine works. Readers of this document are expected to understand perl's regex syntax and its usage in detail. If you want to learn about the basics of Perl's regular expressions, see perlre. And if you want to replace the regex engine with your own see see perlreapi.","Process Name":"perlreguts","Link":"https:\/\/linux.die.net\/man\/1\/perlreguts"}},{"Process":{"Description":"","Process Name":"perlrepository","Link":"https:\/\/linux.die.net\/man\/1\/perlrepository"}},{"Process":{"Description":"This page covers the very basics of understanding, creating and using regular expressions ('regexes') in Perl.","Process Name":"perlrequick","Link":"https:\/\/linux.die.net\/man\/1\/perlrequick"}},{"Process":{"Description":"This is a quick reference to Perl's regular expressions. For full information see perlre and perlop, as well as the \" SEE ALSO \" section in this document. OPERATORS \"=~\" determines to which variable the regex is applied. In its absence, $_ is used. $var =~ \/foo\/; \"!~\" determines to which variable the regex is applied, and negates the result of the match; it returns false if the match succeeds, and true if it fails. $var !~ \/foo\/; \"m\/pattern\/msixpogc\" searches a string for a pattern match, applying the given options. m  Multiline mode - ^ and $ match internal lines\ns  match as a Single line - . matches \\n\ni  case-Insensitive\nx  eXtended legibility - free whitespace and comments\np  Preserve a copy of the matched string -\n   ${^PREMATCH}, ${^MATCH}, ${^POSTMATCH} will be defined.\no  compile pattern Once\ng  Global - all occurrences\nc  don't reset pos on failed matches when using \/g If 'pattern' is an empty string, the last successfully matched regex is used. Delimiters other than '\/' may be used for both this operator and the following ones. The leading \"m\" can be omitted if the delimiter is '\/'. \"qr\/pattern\/msixpo\" lets you store a regex in a variable, or pass one around. Modifiers as for \"m\/\/\", and are stored within the regex. \"s\/pattern\/replacement\/msixpogce\" substitutes matches of 'pattern' with 'replacement'. Modifiers as for \"m\/\/\", with one addition: e  Evaluate 'replacement' as an expression 'e' may be specified multiple times. 'replacement' is interpreted as a double quoted string unless a single-quote ( \"'\") is the delimiter. \"?pattern?\" is like \"m\/pattern\/\" but matches only once. No alternate delimiters can be used. Must be reset with reset(). SYNTAX \\       Escapes the character immediately following it\n.       Matches any single character except a newline (unless \/s is used)\n^       Matches at the beginning of the string (or line, if \/m is used)\n$       Matches at the end of the string (or line, if \/m is used)\n*       Matches the preceding element 0 or more times\n+       Matches the preceding element 1 or more times\n?       Matches the preceding element 0 or 1 times\n{...}   Specifies a range of occurrences for the element preceding it\n[...]   Matches any one of the characters contained within the brackets\n(...)   Groups subexpressions for capturing to $1, $2...\n(?:...) Groups subexpressions without capturing (cluster)\n|       Matches either the subexpression preceding or following it\n\\1, \\2, \\3 ...           Matches the text from the Nth group\n\\g1 or \\g{1}, \\g2 ...    Matches the text from the Nth group\n\\g-1 or \\g{-1}, \\g-2 ... Matches the text from the Nth previous group\n\\g{name}     Named backreference\n\\k<name>     Named backreference\n\\k'name'     Named backreference\n(?P=name)    Named backreference (python syntax) ESCAPE SEQUENCES These work as in normal strings. \\a       Alarm (beep)\n\\e       Escape\n\\f       Formfeed\n\\n       Newline\n\\r       Carriage return\n\\t       Tab\n\\037     Any octal ASCII value\n\\x7f     Any hexadecimal ASCII value\n\\x{263a} A wide hexadecimal value\n\\cx      Control-x\n\\N{name} A named character\n\n\\l  Lowercase next character\n\\u  Titlecase next character\n\\L  Lowercase until \\E\n\\U  Uppercase until \\E\n\\Q  Disable pattern metacharacters until \\E\n\\E  End modification For Titlecase, see \"Titlecase\". This one works differently from normal strings: \\b  An assertion, not backspace, except in a character class CHARACTER CLASSES [amy]    Match 'a', 'm' or 'y'\n[f-j]    Dash specifies \"range\"\n[f-j-]   Dash escaped or at start or end means 'dash'\n[^f-j]   Caret indicates \"match any character _except_ these\" The following sequences work within or without a character class. The first six are locale aware, all are Unicode aware. See perllocale and perlunicode for details. \\d      A digit\n\\D      A nondigit\n\\w      A word character\n\\W      A non-word character\n\\s      A whitespace character\n\\S      A non-whitespace character\n\\h      An horizontal white space\n\\H      A non horizontal white space\n\\v      A vertical white space\n\\V      A non vertical white space\n\\R      A generic newline           (?>\\v|\\x0D\\x0A)\n\n\\C      Match a byte (with Unicode, '.' matches a character)\n\\pP     Match P-named (Unicode) property\n\\p{...} Match Unicode property with long name\n\\PP     Match non-P\n\\P{...} Match lack of Unicode property with long name\n\\X      Match extended Unicode combining character sequence POSIX character classes and their Unicode and Perl equivalents: alnum   IsAlnum              Alphanumeric\nalpha   IsAlpha              Alphabetic\nascii   IsASCII              Any ASCII char\nblank   IsSpace  [ \\t]       Horizontal whitespace (GNU extension)\ncntrl   IsCntrl              Control characters\ndigit   IsDigit  \\d          Digits\ngraph   IsGraph              Alphanumeric and punctuation\nlower   IsLower              Lowercase chars (locale and Unicode aware)\nprint   IsPrint              Alphanumeric, punct, and space\npunct   IsPunct              Punctuation\nspace   IsSpace  [\\s\\ck]     Whitespace\n        IsSpacePerl   \\s     Perl's whitespace definition\nupper   IsUpper              Uppercase chars (locale and Unicode aware)\nword    IsWord   \\w          Alphanumeric plus _ (Perl extension)\nxdigit  IsXDigit [0-9A-Fa-f] Hexadecimal digit Within a character class: POSIX       traditional   Unicode\n[:digit:]       \\d        \\p{IsDigit}\n[:^digit:]      \\D        \\P{IsDigit} ANCHORS All are zero-width assertions. ^  Match string start (or line, if \/m is used)\n$  Match string end (or line, if \/m is used) or before newline\n\\b Match word boundary (between \\w and \\W)\n\\B Match except at word boundary (between \\w and \\w or \\W and \\W)\n\\A Match string start (regardless of \/m)\n\\Z Match string end (before optional newline)\n\\z Match absolute string end\n\\G Match where previous m\/\/g left off\n\n\\K Keep the stuff left of the \\K, don't include it in $& QUANTIFIERS Quantifiers are greedy by default -- match the longest leftmost. Maximal Minimal Possessive Allowed range\n------- ------- ---------- -------------\n{n,m}   {n,m}?  {n,m}+     Must occur at least n times\n                           but no more than m times\n{n,}    {n,}?   {n,}+      Must occur at least n times\n{n}     {n}?    {n}+       Must occur exactly n times\n*       *?      *+         0 or more times (same as {0,})\n+       +?      ++         1 or more times (same as {1,})\n?       ??      ?+         0 or 1 time (same as {0,1}) The possessive forms (new in Perl 5.10) prevent backtracking: what gets matched by a pattern with a possessive quantifier will not be backtracked into, even if that causes the whole match to fail. There is no quantifier {,n} -- that gets understood as a literal string. EXTENDED CONSTRUCTS (?#text)          A comment\n(?:...)           Groups subexpressions without capturing (cluster)\n(?pimsx-imsx:...) Enable\/disable option (as per m\/\/ modifiers)\n(?=...)           Zero-width positive lookahead assertion\n(?!...)           Zero-width negative lookahead assertion\n(?<=...)          Zero-width positive lookbehind assertion\n(?<!...)          Zero-width negative lookbehind assertion\n(?>...)           Grab what we can, prohibit backtracking\n(?|...)           Branch reset\n(?<name>...)      Named capture\n(?'name'...)      Named capture\n(?P<name>...)     Named capture (python syntax)\n(?{ code })       Embedded code, return value becomes $^R\n(??{ code })      Dynamic regex, return value used as regex\n(?N)              Recurse into subpattern number N\n(?-N), (?+N)      Recurse into Nth previous\/next subpattern\n(?R), (?0)        Recurse at the beginning of the whole pattern\n(?&name)          Recurse into a named subpattern\n(?P>name)         Recurse into a named subpattern (python syntax)\n(?(cond)yes|no)\n(?(cond)yes)      Conditional expression, where \"cond\" can be:\n                  (N)       subpattern N has matched something\n                  (<name>)  named subpattern has matched something\n                  ('name')  named subpattern has matched something\n                  (?{code}) code condition\n                  (R)       true if recursing\n                  (RN)      true if recursing into Nth subpattern\n                  (R&name)  true if recursing into named subpattern\n                  (DEFINE)  always false, no no-pattern allowed VARIABLES $_    Default variable for operators to use\n\n$`    Everything prior to matched string\n$&    Entire matched string\n$'    Everything after to matched string\n\n${^PREMATCH}   Everything prior to matched string\n${^MATCH}      Entire matched string\n${^POSTMATCH}  Everything after to matched string The use of \"$`\", $& or \"$'\" will slow down all regex use within your program. Consult perlvar for \"@-\" to see equivalent expressions that won't cause slow down. See also Devel::SawAmpersand. Starting with Perl 5.10, you can also use the equivalent variables \"${^PREMATCH}\", \"${^MATCH}\" and \"${^POSTMATCH}\", but for them to be defined, you have to specify the \"\/p\" (preserve) modifier on your regular expression. $1, $2 ...  hold the Xth captured expr\n$+    Last parenthesized pattern match\n$^N   Holds the most recently closed capture\n$^R   Holds the result of the last (?{...}) expr\n@-    Offsets of starts of groups. $-[0] holds start of whole match\n@+    Offsets of ends of groups. $+[0] holds end of whole match\n%+    Named capture buffers\n%-    Named capture buffers, as array refs Captured groups are numbered according to their opening paren. FUNCTIONS lc          Lowercase a string\nlcfirst     Lowercase first char of a string\nuc          Uppercase a string\nucfirst     Titlecase first char of a string\n\npos         Return or set current match position\nquotemeta   Quote metacharacters\nreset       Reset ?pattern? status\nstudy       Analyze string for optimizing matching\n\nsplit       Use a regex to split a string into parts The first four of these are like the escape sequences \"\\L\", \"\\l\", \"\\U\", and \"\\u\". For Titlecase, see \"Titlecase\". TERMINOLOGY Titlecase Unicode concept which most often is equal to uppercase, but for certain characters like the German \"sharp s\" there is a difference.","Process Name":"perlreref","Link":"https:\/\/linux.die.net\/man\/1\/perlreref"}},{"Process":{"Description":"This page provides a basic tutorial on understanding, creating and using regular expressions in Perl. It serves as a complement to the reference page on regular expressions perlre. Regular expressions are an integral part of the \"m\/\/\", \"s\/\/\/\", \"qr\/\/\" and \"split\" operators and so this tutorial also overlaps with \"Regexp Quote-Like Operators\" in perlop and \"split\" in perlfunc. Perl is widely renowned for excellence in text processing, and regular expressions are one of the big factors behind this fame. Perl regular expressions display an efficiency and flexibility unknown in most other computer languages. Mastering even the basics of regular expressions will allow you to manipulate text with surprising ease. What is a regular expression? A regular expression is simply a string that describes a pattern. Patterns are in common use these days; examples are the patterns typed into a search engine to find web pages and the patterns used to list files in a directory, e.g., \"ls *.txt\" or \"dir *.*\". In Perl, the patterns described by regular expressions are used to search strings, extract desired parts of strings, and to do search and replace operations. Regular expressions have the undeserved reputation of being abstract and difficult to understand. Regular expressions are constructed using simple concepts like conditionals and loops and are no more difficult to understand than the corresponding \"if\" conditionals and \"while\" loops in the Perl language itself. In fact, the main challenge in learning regular expressions is just getting used to the terse notation used to express these concepts. This tutorial flattens the learning curve by discussing regular expression concepts, along with their notation, one at a time and with many examples. The first part of the tutorial will progress from the simplest word searches to the basic regular expression concepts. If you master the first part, you will have all the tools needed to solve about 98% of your needs. The second part of the tutorial is for those comfortable with the basics and hungry for more power tools. It discusses the more advanced regular expression operators and introduces the latest cutting edge innovations in 5.6.0. A note: to save time, 'regular expression' is often abbreviated as regexp or regex. Regexp is a more natural abbreviation than regex, but is harder to pronounce. The Perl pod documentation is evenly split on regexp vs regex; in Perl, there is more than one way to abbreviate it. We'll use regexp in this tutorial.","Process Name":"perlretut","Link":"https:\/\/linux.die.net\/man\/1\/perlretut"}},{"Process":{"Description":"This document gives instructions for building Perl for RISC OS . It is complicated by the need to cross compile. There is a binary version of perl available from <http:\/\/www.cp15.org\/perl\/> which you may wish to use instead of trying to compile it yourself.","Process Name":"perlriscos","Link":"https:\/\/linux.die.net\/man\/1\/perlriscos"}},{"Process":{"Description":"The normal way to run a Perl program is by making it directly executable, or else by passing the name of the source file as an argument on the command line. (An interactive Perl environment is also possible--see perldebug for details on how to do that.) Upon startup, Perl looks for your program in one of the following places: 1. Specified line by line via -e or -E switches on the command line. 2. Contained in the file specified by the first filename on the command line. (Note that systems supporting the #! notation invoke interpreters this way. See \"Location of Perl\".) 3. Passed in implicitly via standard input. This works only if there are no filename arguments--to pass arguments to a STDIN-read program you must explicitly specify a \"-\" for the program name. With methods 2 and 3, Perl starts parsing the input file from the beginning, unless you've specified a -x switch, in which case it scans for the first line starting with #! and containing the word \"perl\", and starts there instead. This is useful for running a program embedded in a larger message. (In this case you would indicate the end of the program using the \"__END__\" token.) The #! line is always examined for switches as the line is being parsed. Thus, if you're on a machine that allows only one argument with the #! line, or worse, doesn't even recognize the #! line, you still can get consistent switch behavior regardless of how Perl was invoked, even if -x was used to find the beginning of the program. Because historically some operating systems silently chopped off kernel interpretation of the #! line after 32 characters, some switches may be passed in on the command line, and some may not; you could even get a \"-\" without its letter, if you're not careful. You probably want to make sure that all your switches fall either before or after that 32-character boundary. Most switches don't actually care if they're processed redundantly, but getting a \"-\" instead of a complete switch could cause Perl to try to execute standard input instead of your program. And a partial -I switch could also cause odd results. Some switches do care if they are processed twice, for instance combinations of -l and -0. Either put all the switches after the 32-character boundary (if applicable), or replace the use of -0digits by \"BEGIN{ $\/ = \"\\0digits\"; }\". Parsing of the #! switches starts wherever \"perl\" is mentioned in the line. The sequences \"-*\" and \"- \" are specifically ignored so that you could, if you were so inclined, say #!\/bin\/sh\n#! -*-perl-*-\neval 'exec perl -x -wS $0 ${1+\"$@\"}'\n    if 0; to let Perl see the -p switch. A similar trick involves the env program, if you have it. #!\/usr\/bin\/env perl The examples above use a relative path to the perl interpreter, getting whatever version is first in the user's path. If you want a specific version of Perl, say, perl5.005_57, you should place that directly in the #! line's path. If the #! line does not contain the word \"perl\", the program named after the #! is executed instead of the Perl interpreter. This is slightly bizarre, but it helps people on machines that don't do #!, because they can tell a program that their SHELL is \/usr\/bin\/perl, and Perl will then dispatch the program to the correct interpreter for them. After locating your program, Perl compiles the entire program to an internal form. If there are any compilation errors, execution of the program is not attempted. (This is unlike the typical shell script, which might run part-way through before finding a syntax error.) If the program is syntactically correct, it is executed. If the program runs off the end without hitting an exit() or die() operator, an implicit exit(0) is provided to indicate successful completion. #! and quoting on non-Unix systems Unix's #! technique can be simulated on other systems: OS\/2 Put extproc perl -S -your_switches as the first line in \"*.cmd\" file ( -S due to a bug in cmd.exe's 'extproc' handling). MS-DOS Create a batch file to run your program, and codify it in \"ALTERNATE_SHEBANG\" (see the dosish.h file in the source distribution for more information). Win95\/NT The Win95\/NT installation, when using the ActiveState installer for Perl, will modify the Registry to associate the .pl extension with the perl interpreter. If you install Perl by other means (including building from the sources), you may have to modify the Registry yourself. Note that this means you can no longer tell the difference between an executable Perl program and a Perl library file. Macintosh Under \"Classic\" MacOS, a perl program will have the appropriate Creator and Type, so that double-clicking them will invoke the MacPerl application. Under Mac OS X, clickable apps can be made from any \"#!\" script using Wil Sanchez' DropScript utility: http:\/\/www.wsanchez.net\/software\/ . VMS Put $ perl -mysw 'f$env(\"procedure\")' 'p1' 'p2' 'p3' 'p4' 'p5' 'p6' 'p7' 'p8' !\n$ exit++ + ++$status != 0 and $exit = $status = undef; at the top of your program, where -mysw are any command line switches you want to pass to Perl. You can now invoke the program directly, by saying \"perl program\", or as a DCL procedure, by saying @program (or implicitly via DCL$PATH by just using the name of the program). This incantation is a bit much to remember, but Perl will display it for you if you say \"perl \"-V:startperl\"\". Command-interpreters on non-Unix systems have rather different ideas on quoting than Unix shells. You'll need to learn the special characters in your command-interpreter ( \"*\", \"\\\" and \"\"\" are common) and how to protect whitespace and these characters to run one-liners (see -e below). On some systems, you may have to change single-quotes to double ones, which you must not do on Unix or Plan 9 systems. You might also have to change a single % to a %%. For example: # Unix\nperl -e 'print \"Hello world\\n\"'\n\n# MS-DOS, etc.\nperl -e \"print \\\"Hello world\\n\\\"\"\n\n# Macintosh\nprint \"Hello world\\n\"\n (then Run \"Myscript\" or Shift-Command-R)\n\n# VMS\nperl -e \"print \"\"Hello world\\n\"\"\" The problem is that none of this is reliable: it depends on the command and it is entirely possible neither works. If 4DOS were the command shell, this would probably work better: perl -e \"print <Ctrl-x>\"Hello world\\n<Ctrl-x>\"\" CMD .EXE in Windows NT slipped a lot of standard Unix functionality in when nobody was looking, but just try to find documentation for its quoting rules. Under the Macintosh, it depends which environment you are using. The MacPerl shell, or MPW , is much like Unix shells in its support for several quoting variants, except that it makes free use of the Macintosh's non-ASCII characters as control characters. There is no general solution to all of this. It's just a mess. Location of Perl It may seem obvious to say, but Perl is useful only when users can easily find it. When possible, it's good for both \/usr\/bin\/perl and \/usr\/local\/bin\/perl to be symlinks to the actual binary. If that can't be done, system administrators are strongly encouraged to put (symlinks to) perl and its accompanying utilities into a directory typically found along a user's PATH , or in some other obvious and convenient place. In this documentation, \"#!\/usr\/bin\/perl\" on the first line of the program will stand in for whatever method works on your system. You are advised to use a specific path if you care about a specific version. #!\/usr\/local\/bin\/perl5.00554 or if you just want to be running at least version, place a statement like this at the top of your program: use 5.005_54; Command Switches As with all standard commands, a single-character switch may be clustered with the following switch, if any. #!\/usr\/bin\/perl -spi.orig   # same as -s -p -i.orig Switches include: -0[ octal\/hexadecimal] specifies the input record separator ( $\/) as an octal or hexadecimal number. If there are no digits, the null character is the separator. Other switches may precede or follow the digits. For example, if you have a version of find which can print filenames terminated by the null character, you can say this: find . -name '*.orig' -print0 | perl -n0e unlink The special value 00 will cause Perl to slurp files in paragraph mode. The value 0777 will cause Perl to slurp files whole because there is no legal byte with that value. If you want to specify any Unicode character, use the hexadecimal format: \"-0xHHH...\", where the \"H\" are valid hexadecimal digits. (This means that you cannot use the \"-x\" with a directory name that consists of hexadecimal digits.) -a turns on autosplit mode when used with a -n or -p. An implicit split command to the @F array is done as the first thing inside the implicit while loop produced by the -n or -p. perl -ane 'print pop(@F), \"\\n\";' is equivalent to while (<>) {\n    @F = split(' ');\n    print pop(@F), \"\\n\";\n} An alternate delimiter may be specified using -F. -C [number\/list] The \"-C\" flag controls some of the Perl Unicode features. As of 5.8.1, the \"-C\" can be followed either by a number or a list of option letters. The letters, their numeric values, and effects are as follows; listing the letters is equal to summing the numbers. I     1   STDIN is assumed to be in UTF-8\nO     2   STDOUT will be in UTF-8\nE     4   STDERR will be in UTF-8\nS     7   I + O + E\ni     8   UTF-8 is the default PerlIO layer for input streams\no    16   UTF-8 is the default PerlIO layer for output streams\nD    24   i + o\nA    32   the @ARGV elements are expected to be strings encoded\n          in UTF-8\nL    64   normally the \"IOEioA\" are unconditional,\n          the L makes them conditional on the locale environment\n          variables (the LC_ALL, LC_TYPE, and LANG, in the order\n          of decreasing precedence) -- if the variables indicate\n          UTF-8, then the selected \"IOEioA\" are in effect\na   256   Set ${^UTF8CACHE} to -1, to run the UTF-8 caching code in\n          debugging mode. For example, \"-COE\" and \"-C6\" will both turn on UTF-8-ness on both STDOUT and STDERR . Repeating letters is just redundant, not cumulative nor toggling. The \"io\" options mean that any subsequent open() (or similar I\/O operations) will have the \":utf8\" PerlIO layer implicitly applied to them, in other words, UTF-8 is expected from any input stream, and UTF-8 is produced to any output stream. This is just the default, with explicit layers in open() and with binmode() one can manipulate streams as usual. \"-C\" on its own (not followed by any number or option list), or the empty string \"\" for the \"PERL_UNICODE\" environment variable, has the same effect as \"-CSDL\". In other words, the standard I\/O handles and the default \"open()\" layer are UTF-8-fied but only if the locale environment variables indicate a UTF-8 locale. This behaviour follows the implicit (and problematic) UTF-8 behaviour of Perl 5.8.0. You can use \"-C0\" (or \"0\" for \"PERL_UNICODE\") to explicitly disable all the above Unicode features. The read-only magic variable \"${^UNICODE}\" reflects the numeric value of this setting. This is variable is set during Perl startup and is thereafter read-only. If you want runtime effects, use the three-arg open() (see \"open\" in perlfunc), the two-arg binmode() (see \"binmode\" in perlfunc), and the \"open\" pragma (see open). (In Perls earlier than 5.8.1 the \"-C\" switch was a Win32-only switch that enabled the use of Unicode-aware \"wide system call\" Win32 APIs. This feature was practically unused, however, and the command line switch was therefore \"recycled\".) Note: Since perl 5.10.1, if the -C option is used on the #! line, it must be specified on the command line as well, since the standard streams are already set up at this point in the execution of the perl interpreter. You can also use binmode() to set the encoding of an I\/O stream. -c causes Perl to check the syntax of the program and then exit without executing it. Actually, it will execute \"BEGIN\", \"UNITCHECK\", \"CHECK\", and \"use\" blocks, because these are considered as occurring outside the execution of your program. \"INIT\" and \"END\" blocks, however, will be skipped. -d -dt runs the program under the Perl debugger. See perldebug. If t is specified, it indicates to the debugger that threads will be used in the code being debugged. -d: foo[=bar,baz] -dt: foo[=bar,baz] runs the program under the control of a debugging, profiling, or tracing module installed as Devel::foo. E.g., -d:DProf executes the program using the Devel::DProf profiler. As with the -M flag, options may be passed to the Devel::foo package where they will be received and interpreted by the Devel::foo::import routine. The comma-separated list of options must follow a \"=\" character. If t is specified, it indicates to the debugger that threads will be used in the code being debugged. See perldebug. -D letters -D number sets debugging flags. To watch how it executes your program, use -Dtls. (This works only if debugging is compiled into your Perl.) Another nice value is -Dx, which lists your compiled syntax tree. And -Dr displays compiled regular expressions; the format of the output is explained in perldebguts. As an alternative, specify a number instead of list of letters (e.g., -D14 is equivalent to -Dtls):       1  p  Tokenizing and parsing (with v, displays parse stack)\n      2  s  Stack snapshots (with v, displays all stacks)\n      4  l  Context (loop) stack processing\n      8  t  Trace execution\n     16  o  Method and overloading resolution\n     32  c  String\/numeric conversions\n     64  P  Print profiling info, preprocessor command for -P, source file input state\n    128  m  Memory and SV allocation\n    256  f  Format processing\n    512  r  Regular expression parsing and execution\n   1024  x  Syntax tree dump\n   2048  u  Tainting checks\n   4096  U  Unofficial, User hacking (reserved for private, unreleased use)\n   8192  H  Hash dump -- usurps values()\n  16384  X  Scratchpad allocation\n  32768  D  Cleaning up\n  65536  S  Thread synchronization\n 131072  T  Tokenising\n 262144  R  Include reference counts of dumped variables (eg when using -Ds)\n 524288  J  Do not s,t,P-debug (Jump over) opcodes within package DB\n1048576  v  Verbose: use in conjunction with other flags\n2097152  C  Copy On Write\n4194304  A  Consistency checks on internal structures\n8388608  q  quiet - currently only suppresses the \"EXECUTING\" message All these flags require -DDEBUGGING when you compile the Perl executable (but see Devel::Peek, re which may change this). See the INSTALL file in the Perl source distribution for how to do this. This flag is automatically set if you include -g option when \"Configure\" asks you about optimizer\/debugger flags. If you're just trying to get a print out of each line of Perl code as it executes, the way that \"sh -x\" provides for shell scripts, you can't use Perl's -D switch. Instead do this # If you have \"env\" utility\nenv PERLDB_OPTS=\"NonStop=1 AutoTrace=1 frame=2\" perl -dS program\n\n# Bourne shell syntax\n$ PERLDB_OPTS=\"NonStop=1 AutoTrace=1 frame=2\" perl -dS program\n\n# csh syntax\n% (setenv PERLDB_OPTS \"NonStop=1 AutoTrace=1 frame=2\"; perl -dS program) See perldebug for details and variations. -e commandline may be used to enter one line of program. If -e is given, Perl will not look for a filename in the argument list. Multiple -e commands may be given to build up a multi-line script. Make sure to use semicolons where you would in a normal program. -E commandline behaves just like -e, except that it implicitly enables all optional features (in the main compilation unit). See feature. -f Disable executing $Config{sitelib}\/sitecustomize.pl at startup. Perl can be built so that it by default will try to execute $Config {sitelib}\/sitecustomize.pl at startup (in a BEGIN block). This is a hook that allows the sysadmin to customize how perl behaves. It can for instance be used to add entries to the @INC array to make perl find modules in non-standard locations. -F pattern specifies the pattern to split on if -a is also in effect. The pattern may be surrounded by \"\/\/\", \"\", or '', otherwise it will be put in single quotes. You can't use literal whitespace in the pattern. -h prints a summary of the options. -i[ extension] specifies that files processed by the \"<>\" construct are to be edited in-place. It does this by renaming the input file, opening the output file by the original name, and selecting that output file as the default for print() statements. The extension, if supplied, is used to modify the name of the old file to make a backup copy, following these rules: If no extension is supplied, no backup is made and the current file is overwritten. If the extension doesn't contain a \"*\", then it is appended to the end of the current filename as a suffix. If the extension does contain one or more \"*\" characters, then each \"*\" is replaced with the current filename. In Perl terms, you could think of this as: ($backup = $extension) =~ s\/\\*\/$file_name\/g; This allows you to add a prefix to the backup file, instead of (or in addition to) a suffix: $ perl -pi'orig_*' -e 's\/bar\/baz\/' fileA    # backup to 'orig_fileA' Or even to place backup copies of the original files into another directory (provided the directory already exists): $ perl -pi'old\/*.orig' -e 's\/bar\/baz\/' fileA # backup to 'old\/fileA.orig' These sets of one-liners are equivalent: $ perl -pi -e 's\/bar\/baz\/' fileA            # overwrite current file\n$ perl -pi'*' -e 's\/bar\/baz\/' fileA         # overwrite current file\n\n$ perl -pi'.orig' -e 's\/bar\/baz\/' fileA     # backup to 'fileA.orig'\n$ perl -pi'*.orig' -e 's\/bar\/baz\/' fileA    # backup to 'fileA.orig' From the shell, saying $ perl -p -i.orig -e \"s\/foo\/bar\/; ... \" is the same as using the program: #!\/usr\/bin\/perl -pi.orig\ns\/foo\/bar\/; which is equivalent to #!\/usr\/bin\/perl\n$extension = '.orig';\nLINE: while (<>) {\n    if ($ARGV ne $oldargv) {\n        if ($extension !~ \/\\*\/) {\n            $backup = $ARGV . $extension;\n        }\n        else {\n            ($backup = $extension) =~ s\/\\*\/$ARGV\/g;\n        }\n        rename($ARGV, $backup);\n        open(ARGVOUT, \">$ARGV\");\n        select(ARGVOUT);\n        $oldargv = $ARGV;\n    }\n    s\/foo\/bar\/;\n}\ncontinue {\n    print;  # this prints to original filename\n}\nselect(STDOUT); except that the -i form doesn't need to compare $ARGV to $oldargv to know when the filename has changed. It does, however, use ARGVOUT for the selected filehandle. Note that STDOUT is restored as the default output filehandle after the loop. As shown above, Perl creates the backup file whether or not any output is actually changed. So this is just a fancy way to copy files:     $ perl -p -i'\/some\/file\/path\/*' -e 1 file1 file2 file3...\nor\n    $ perl -p -i'.orig' -e 1 file1 file2 file3... You can use \"eof\" without parentheses to locate the end of each input file, in case you want to append to each file, or reset line numbering (see example in \"eof\" in perlfunc). If, for a given file, Perl is unable to create the backup file as specified in the extension then it will skip that file and continue on with the next one (if it exists). For a discussion of issues surrounding file permissions and -i, see \"Why does Perl let me delete read-only files? Why does -i clobber protected files? Isn't this a bug in Perl?\" in perlfaq5. You cannot use -i to create directories or to strip extensions from files. Perl does not expand \"~\" in filenames, which is good, since some folks use it for their backup files: $ perl -pi~ -e 's\/foo\/bar\/' file1 file2 file3... Note that because -i renames or deletes the original file before creating a new file of the same name, UNIX-style soft and hard links will not be preserved. Finally, the -i switch does not impede execution when no files are given on the command line. In this case, no backup is made (the original file cannot, of course, be determined) and processing proceeds from STDIN to STDOUT as might be expected. -I directory Directories specified by -I are prepended to the search path for modules ( @INC), and also tells the C preprocessor where to search for include files. The C preprocessor is invoked with -P; by default it searches \/usr\/include and \/usr\/lib\/perl. -l[ octnum] enables automatic line-ending processing. It has two separate effects. First, it automatically chomps $\/ (the input record separator) when used with -n or -p. Second, it assigns \"$\\\" (the output record separator) to have the value of octnum so that any print statements will have that separator added back on. If octnum is omitted, sets \"$\\\" to the current value of $\/. For instance, to trim lines to 80 columns: perl -lpe 'substr($_, 80) = \"\"' Note that the assignment \"$\\ = $\/\" is done when the switch is processed, so the input record separator can be different than the output record separator if the -l switch is followed by a -0 switch: gnufind \/ -print0 | perl -ln0e 'print \"found $_\" if -p' This sets \"$\\\" to newline and then sets $\/ to the null character. -m[ -] module -M[ -] module -M[ -] 'module ...' -[mM][ -] module=arg[,arg]... -m module executes \"use\" module \"();\" before executing your program. -Mmodule executes \"use\" module \";\" before executing your program. You can use quotes to add extra code after the module name, e.g., '-Mmodule qw(foo bar)'. If the first character after the -M or -m is a dash (\"-\") then the 'use' is replaced with 'no'. A little builtin syntactic sugar means you can also say -mmodule=foo,bar or -Mmodule=foo,bar as a shortcut for '-Mmodule qw(foo bar)'. This avoids the need to use quotes when importing symbols. The actual code generated by -Mmodule=foo,bar is \"use module split(\/,\/,q{foo,bar})\". Note that the \"=\" form removes the distinction between -m and -M. A consequence of this is that -MFoo=number never does a version check (unless \"Foo::import()\" itself is set up to do a version check, which could happen for example if Foo inherits from Exporter.) -n causes Perl to assume the following loop around your program, which makes it iterate over filename arguments somewhat like sed -n or awk: LINE:\n  while (<>) {\n      ...             # your program goes here\n  } Note that the lines are not printed by default. See -p to have lines printed. If a file named by an argument cannot be opened for some reason, Perl warns you about it and moves on to the next file. Also note that \"<>\" passes command line arguments to \"open\" in perlfunc, which doesn't necessarily interpret them as file names. See perlop for possible security implications. Here is an efficient way to delete all files that haven't been modified for at least a week: find . -mtime +7 -print | perl -nle unlink This is faster than using the -exec switch of find because you don't have to start a process on every filename found. It does suffer from the bug of mishandling newlines in pathnames, which you can fix if you follow the example under -0. \"BEGIN\" and \"END\" blocks may be used to capture control before or after the implicit program loop, just as in awk. -p causes Perl to assume the following loop around your program, which makes it iterate over filename arguments somewhat like sed: LINE:\n  while (<>) {\n      ...             # your program goes here\n  } continue {\n      print or die \"-p destination: $!\\n\";\n  } If a file named by an argument cannot be opened for some reason, Perl warns you about it, and moves on to the next file. Note that the lines are printed automatically. An error occurring during printing is treated as fatal. To suppress printing use the -n switch. A -p overrides a -n switch. \"BEGIN\" and \"END\" blocks may be used to capture control before or after the implicit loop, just as in awk. -P NOTE: Use of -P is strongly discouraged because of its inherent problems, including poor portability. It is deprecated and will be removed in a future version of Perl. This option causes your program to be run through the C preprocessor before compilation by Perl. Because both comments and cpp directives begin with the # character, you should avoid starting comments with any words recognized by the C preprocessor such as \"if\", \"else\", or \"define\". If you're considering using \"-P\", you might also want to look at the Filter::cpp module from CPAN . The problems of -P include, but are not limited to: \u2022 The \"#!\" line is stripped, so any switches there don't apply. \u2022 A \"-P\" on a \"#!\" line doesn't work. \u2022 All lines that begin with (whitespace and) a \"#\" but do not look like cpp commands, are stripped, including anything inside Perl strings, regular expressions, and here-docs . \u2022 In some platforms the C preprocessor knows too much: it knows about the C ++ -style until-end-of-line comments starting with \"\/\/\". This will cause problems with common Perl constructs like s\/foo\/\/; because after -P this will became illegal code s\/foo The workaround is to use some other quoting separator than \"\/\", like for example \"!\": s!foo!!; \u2022 It requires not only a working C preprocessor but also a working sed. If not on UNIX , you are probably out of luck on this. \u2022 Script line numbers are not preserved. \u2022 The \"-x\" does not work with \"-P\". -s enables rudimentary switch parsing for switches on the command line after the program name but before any filename arguments (or before an argument of --). Any switch found there is removed from @ARGV and sets the corresponding variable in the Perl program. The following program prints \"1\" if the program is invoked with a -xyz switch, and \"abc\" if it is invoked with -xyz=abc. #!\/usr\/bin\/perl -s\nif ($xyz) { print \"$xyz\\n\" } Do note that a switch like --help creates the variable ${-help}, which is not compliant with \"strict refs\". Also, when using this option on a script with warnings enabled you may get a lot of spurious \"used only once\" warnings. -S makes Perl use the PATH environment variable to search for the program (unless the name of the program contains directory separators). On some platforms, this also makes Perl append suffixes to the filename while searching for it. For example, on Win32 platforms, the \".bat\" and \".cmd\" suffixes are appended if a lookup for the original name fails, and if the name does not already end in one of those suffixes. If your Perl was compiled with DEBUGGING turned on, using the -Dp switch to Perl shows how the search progresses. Typically this is used to emulate #! startup on platforms that don't support #!. Its also convenient when debugging a script that uses #!, and is thus normally found by the shell's $PATH search mechanism. This example works on many platforms that have a shell compatible with Bourne shell: #!\/usr\/bin\/perl\neval 'exec \/usr\/bin\/perl -wS $0 ${1+\"$@\"}'\n        if $running_under_some_shell; The system ignores the first line and feeds the program to \/bin\/sh, which proceeds to try to execute the Perl program as a shell script. The shell executes the second line as a normal shell command, and thus starts up the Perl interpreter. On some systems $0 doesn't always contain the full pathname, so the -S tells Perl to search for the program if necessary. After Perl locates the program, it parses the lines and ignores them because the variable $running_under_some_shell is never true. If the program will be interpreted by csh, you will need to replace \"${1+\"$@\"}\" with $*, even though that doesn't understand embedded spaces (and such) in the argument list. To start up sh rather than csh, some systems may have to replace the #! line with a line containing just a colon, which will be politely ignored by Perl. Other systems can't control that, and need a totally devious construct that will work under any of csh, sh, or Perl, such as the following: eval '(exit $?0)' && eval 'exec perl -wS $0 ${1+\"$@\"}'\n& eval 'exec \/usr\/bin\/perl -wS $0 $argv:q'\n        if $running_under_some_shell; If the filename supplied contains directory separators (i.e., is an absolute or relative pathname), and if that file is not found, platforms that append file extensions will do so and try to look for the file with those extensions added, one by one. On DOS-like platforms, if the program does not contain directory separators, it will first be searched for in the current directory before being searched for on the PATH . On Unix platforms, the program will be searched for strictly on the PATH . -t Like -T, but taint checks will issue warnings rather than fatal errors. These warnings can be controlled normally with \"no warnings qw(taint)\". NOTE: this is not a substitute for -T. This is meant only to be used as a temporary development aid while securing legacy code: for real production code and for new secure code written from scratch always use the real -T. -T forces \"taint\" checks to be turned on so you can test them. Ordinarily these checks are done only when running setuid or setgid. It's a good idea to turn them on explicitly for programs that run on behalf of someone else whom you might not necessarily trust, such as CGI programs or any internet servers you might write in Perl. See perlsec for details. For security reasons, this option must be seen by Perl quite early; usually this means it must appear early on the command line or in the #! line for systems which support that construct. -u This obsolete switch causes Perl to dump core after compiling your program. You can then in theory take this core dump and turn it into an executable file by using the undump program (not supplied). This speeds startup at the expense of some disk space (which you can minimize by stripping the executable). (Still, a \"hello world\" executable comes out to about 200K on my machine.) If you want to execute a portion of your program before dumping, use the dump() operator instead. Note: availability of undump is platform specific and may not be available for a specific port of Perl. -U allows Perl to do unsafe operations. Currently the only \"unsafe\" operations are attempting to unlink directories while running as superuser, and running setuid programs with fatal taint checks turned into warnings. Note that the -w switch (or the $^W variable) must be used along with this option to actually generate the taint-check warnings. -v prints the version and patchlevel of your perl executable. -V prints summary of the major perl configuration values and the current values of @INC. -V: configvar Prints to STDOUT the value of the named configuration variable(s), with multiples when your configvar argument looks like a regex (has non-letters). For example: $ perl -V:libc\n    libc='\/lib\/libc-2.2.4.so';\n$ perl -V:lib.\n    libs='-lnsl -lgdbm -ldb -ldl -lm -lcrypt -lutil -lc';\n    libc='\/lib\/libc-2.2.4.so';\n$ perl -V:lib.*\n    libpth='\/usr\/local\/lib \/lib \/usr\/lib';\n    libs='-lnsl -lgdbm -ldb -ldl -lm -lcrypt -lutil -lc';\n    lib_ext='.a';\n    libc='\/lib\/libc-2.2.4.so';\n    libperl='libperl.a';\n    .... Additionally, extra colons can be used to control formatting. A trailing colon suppresses the linefeed and terminator ';', allowing you to embed queries into shell commands. (mnemonic: PATH separator ':'.) $ echo \"compression-vars: \" `perl -V:z.*: ` \" are here !\"\ncompression-vars:  zcat='' zip='zip'  are here ! A leading colon removes the 'name=' part of the response, this allows you to map to the name you need. (mnemonic: empty label) $ echo \"goodvfork=\"`.\/perl -Ilib -V::usevfork`\ngoodvfork=false; Leading and trailing colons can be used together if you need positional parameter values without the names. Note that in the case below, the PERL_API params are returned in alphabetical order. $ echo building_on `perl -V::osname: -V::PERL_API_.*:` now\nbuilding_on 'linux' '5' '1' '9' now -w prints warnings about dubious constructs, such as variable names that are mentioned only once and scalar variables that are used before being set, redefined subroutines, references to undefined filehandles or filehandles opened read-only that you are attempting to write on, values used as a number that don't look like numbers, using an array as though it were a scalar, if your subroutines recurse more than 100 deep, and innumerable other things. This switch really just enables the internal $^W variable. You can disable or promote into fatal errors specific warnings using \"__WARN__\" hooks, as described in perlvar and \"warn\" in perlfunc. See also perldiag and perltrap. A new, fine-grained warning facility is also available if you want to manipulate entire classes of warnings; see warnings or perllexwarn. -W Enables all warnings regardless of \"no warnings\" or $^W. See perllexwarn. -X Disables all warnings regardless of \"use warnings\" or $^W. See perllexwarn. -x -x directory tells Perl that the program is embedded in a larger chunk of unrelated ASCII text, such as in a mail message. Leading garbage will be discarded until the first line that starts with #! and contains the string \"perl\". Any meaningful switches on that line will be applied. All references to line numbers by the program (warnings, errors, ...) will treat the #! line as the first line. Thus a warning on the 2nd line of the program (which is on the 100th line in the file) will be reported as line 2, and not as line 100. This can be overridden by using the #line directive. (See \"Plain-Old-Comments-(Not!)\" in perlsyn) If a directory name is specified, Perl will switch to that directory before running the program. The -x switch controls only the disposal of leading garbage. The program must be terminated with \"__END__\" if there is trailing garbage to be ignored (the program can process any or all of the trailing garbage via the DATA filehandle if desired). The directory, if specified, must appear immediately following the -x with no intervening whitespace.","Process Name":"perlrun","Link":"https:\/\/linux.die.net\/man\/1\/perlrun"}},{"Process":{"Description":"Perl is designed to make it easy to program securely even when running with extra privileges, like setuid or setgid programs. Unlike most command line shells, which are based on multiple substitution passes on each line of the script, Perl uses a more conventional evaluation scheme with fewer hidden snags. Additionally, because the language has more builtin functionality, it can rely less upon external (and possibly untrustworthy) programs to accomplish its purposes.","Process Name":"perlsec","Link":"https:\/\/linux.die.net\/man\/1\/perlsec"}},{"Process":{"Description":"This document describes various features of Sun's Solaris operating system that will affect how Perl version 5 (hereafter just perl) is compiled and\/or runs. Some issues relating to the older SunOS 4.x are also discussed, though they may be out of date. For the most part, everything should just work. Starting with Solaris 8, perl5.00503 (or higher) is supplied with the operating system, so you might not even need to build a newer version of perl at all. The Sun-supplied version is installed in \/usr\/perl5 with \/usr\/bin\/perl pointing to \/usr\/perl5\/bin\/perl. Do not disturb that installation unless you really know what you are doing. If you remove the perl supplied with the OS , you will render some bits of your system inoperable. If you wish to install a newer version of perl, install it under a different prefix from \/usr\/perl5. Common prefixes to use are \/usr\/local and \/opt\/perl. You may wish to put your version of perl in the PATH of all users by changing the link \/usr\/bin\/perl. This is probably OK , as most perl scripts shipped with Solaris use an explicit path. (There are a few exceptions, such as \/usr\/bin\/rpm2cpio and \/etc\/rcm\/scripts\/README, but these are also sufficiently generic that the actual version of perl probably doesn't matter too much.) Solaris ships with a range of Solaris-specific modules. If you choose to install your own version of perl you will find the source of many of these modules is available on CPAN under the Sun::Solaris:: namespace. Solaris may include two versions of perl, e.g. Solaris 9 includes both 5.005_03 and 5.6.1. This is to provide stability across Solaris releases, in cases where a later perl version has incompatibilities with the version included in the preceeding Solaris release. The default perl version will always be the most recent, and in general the old version will only be retained for one Solaris release. Note also that the default perl will NOT be configured to search for modules in the older version, again due to compatibility\/stability concerns. As a consequence if you upgrade Solaris, you will have to rebuild\/reinstall any additional CPAN modules that you installed for the previous Solaris version. See the CPAN manpage under 'autobundle' for a quick way of doing this. As an interim measure, you may either change the #! line of your scripts to specifically refer to the old perl version, e.g. on Solaris 9 use #!\/usr\/perl5\/5.00503\/bin\/perl to use the perl version that was the default for Solaris 8, or if you have a large number of scripts it may be more convenient to make the old version of perl the default on your system. You can do this by changing the appropriate symlinks under \/usr\/perl5 as follows (example for Solaris 9): # cd \/usr\/perl5\n# rm bin man pod\n# ln -s .\/5.00503\/bin\n# ln -s .\/5.00503\/man\n# ln -s .\/5.00503\/lib\/pod\n# rm \/usr\/bin\/perl\n# ln -s ..\/perl5\/5.00503\/bin\/perl \/usr\/bin\/perl In both cases this should only be considered to be a temporary measure - you should upgrade to the later version of perl as soon as is practicable. Note also that the perl command-line utilities (e.g. perldoc) and any that are added by modules that you install will be under \/usr\/perl5\/bin, so that directory should be added to your PATH . Solaris Version Numbers. For consistency with common usage, perl's Configure script performs some minor manipulations on the operating system name and version number as reported by uname. Here's a partial translation table:          Sun:                      perl's Configure:\nuname    uname -r   Name           osname     osvers\nSunOS    4.1.3     Solaris 1.1     sunos      4.1.3\nSunOS    5.6       Solaris 2.6     solaris    2.6\nSunOS    5.8       Solaris 8       solaris    2.8\nSunOS    5.9       Solaris 9       solaris    2.9\nSunOS    5.10      Solaris 10      solaris    2.10 The complete table can be found in the Sun Managers' FAQ < ftp:\/\/ftp.cs.toronto.edu\/pub\/jdd\/sunmanagers\/faq> under \"9.1) Which Sun models run which versions of SunOS?\".","Process Name":"perlsolaris","Link":"https:\/\/linux.die.net\/man\/1\/perlsolaris"}},{"Process":{"Description":"Each programmer will, of course, have his or her own preferences in regards to formatting, but there are some general guidelines that will make your programs easier to read, understand, and maintain. The most important thing is to run your programs under the -w flag at all times. You may turn it off explicitly for particular portions of code via the \"no warnings\" pragma or the $^W variable if you must. You should also always run under \"use strict\" or know the reason why not. The \"use sigtrap\" and even \"use diagnostics\" pragmas may also prove useful. Regarding aesthetics of code lay out, about the only thing Larry cares strongly about is that the closing curly bracket of a multi-line BLOCK should line up with the keyword that started the construct. Beyond that, he has other preferences that aren't so strong: \u2022 4-column indent. \u2022 Opening curly on same line as keyword, if possible, otherwise line up. \u2022 Space before the opening curly of a multi-line BLOCK . \u2022 One-line BLOCK may be put on one line, including curlies. \u2022 No space before the semicolon. \u2022 Semicolon omitted in \"short\" one-line BLOCK . \u2022 Space around most operators. \u2022 Space around a \"complex\" subscript (inside brackets). \u2022 Blank lines between chunks that do different things. \u2022 Uncuddled elses. \u2022 No space between function name and its opening parenthesis. \u2022 Space after each comma. \u2022 Long lines broken after an operator (except \"and\" and \"or\"). \u2022 Space after last parenthesis matching on current line. \u2022 Line up corresponding items vertically. \u2022 Omit redundant punctuation as long as clarity doesn't suffer. Larry has his reasons for each of these things, but he doesn't claim that everyone else's mind works the same as his does. Here are some other more substantive style issues to think about: \u2022 Just because you CAN do something a particular way doesn't mean that you SHOULD do it that way. Perl is designed to give you several ways to do anything, so consider picking the most readable one. For instance open(FOO,$foo) || die \"Can't open $foo: $!\"; is better than die \"Can't open $foo: $!\" unless open(FOO,$foo); because the second way hides the main point of the statement in a modifier. On the other hand print \"Starting analysis\\n\" if $verbose; is better than $verbose && print \"Starting analysis\\n\"; because the main point isn't whether the user typed -v or not. Similarly, just because an operator lets you assume default arguments doesn't mean that you have to make use of the defaults. The defaults are there for lazy systems programmers writing one-shot programs. If you want your program to be readable, consider supplying the argument. Along the same lines, just because you CAN omit parentheses in many places doesn't mean that you ought to: return print reverse sort num values %array;\nreturn print(reverse(sort num (values(%array)))); When in doubt, parenthesize. At the very least it will let some poor schmuck bounce on the % key in vi. Even if you aren't in doubt, consider the mental welfare of the person who has to maintain the code after you, and who will probably put parentheses in the wrong place. \u2022 Don't go through silly contortions to exit a loop at the top or the bottom, when Perl provides the \"last\" operator so you can exit in the middle. Just \"outdent\" it a little to make it more visible: LINE:\n    for (;;) {\n        statements;\n      last LINE if $foo;\n        next LINE if \/^#\/;\n        statements;\n    } \u2022 Don't be afraid to use loop labels--they're there to enhance readability as well as to allow multilevel loop breaks. See the previous example. \u2022 Avoid using \"grep()\" (or \"map()\") or 'backticks' in a void context, that is, when you just throw away their return values. Those functions all have return values, so use them. Otherwise use a \"foreach()\" loop or the \"system()\" function instead. \u2022 For portability, when using features that may not be implemented on every machine, test the construct in an eval to see if it fails. If you know what version or patchlevel a particular feature was implemented, you can test $] ($PERL_VERSION in \"English\") to see if it will be there. The \"Config\" module will also let you interrogate values determined by the Configure program when Perl was installed. \u2022 Choose mnemonic identifiers. If you can't remember what mnemonic means, you've got a problem. \u2022 While short identifiers like $gotit are probably ok, use underscores to separate words in longer identifiers. It is generally easier to read $var_names_like_this than $VarNamesLikeThis, especially for non-native speakers of English. It's also a simple rule that works consistently with \"VAR_NAMES_LIKE_THIS\". Package names are sometimes an exception to this rule. Perl informally reserves lowercase module names for \"pragma\" modules like \"integer\" and \"strict\". Other modules should begin with a capital letter and use mixed case, but probably without underscores due to limitations in primitive file systems' representations of module names as files that must fit into a few sparse bytes. \u2022 You may find it helpful to use letter case to indicate the scope or nature of a variable. For example: $ALL_CAPS_HERE   constants only (beware clashes with perl vars!)\n$Some_Caps_Here  package-wide global\/static\n$no_caps_here    function scope my() or local() variables Function and method names seem to work best as all lowercase. E.g., \"$obj->as_string()\". You can use a leading underscore to indicate that a variable or function should not be used outside the package that defined it. \u2022 If you have a really hairy regular expression, use the \"\/x\" modifier and put in some whitespace to make it look a little less like line noise. Don't use slash as a delimiter when your regexp has slashes or backslashes. \u2022 Use the new \"and\" and \"or\" operators to avoid having to parenthesize list operators so much, and to reduce the incidence of punctuation operators like \"&&\" and \"||\". Call your subroutines as if they were functions or list operators to avoid excessive ampersands and parentheses. \u2022 Use here documents instead of repeated \"print()\" statements. \u2022 Line up corresponding things vertically, especially if it'd be too long to fit on one line anyway. $IDX = $ST_MTIME;\n$IDX = $ST_ATIME       if $opt_u;\n$IDX = $ST_CTIME       if $opt_c;\n$IDX = $ST_SIZE        if $opt_s;\n\nmkdir $tmpdir, 0700 or die \"can't mkdir $tmpdir: $!\";\nchdir($tmpdir)      or die \"can't chdir $tmpdir: $!\";\nmkdir 'tmp',   0777 or die \"can't mkdir $tmpdir\/tmp: $!\"; \u2022 Always check the return codes of system calls. Good error messages should go to \"STDERR\", include which program caused the problem, what the failed system call and arguments were, and ( VERY IMPORTANT ) should contain the standard system error message for what went wrong. Here's a simple but sufficient example: opendir(D, $dir)     or die \"can't opendir $dir: $!\"; \u2022 Line up your transliterations when it makes sense: tr [abc]\n   [xyz]; \u2022 Think about reusability. Why waste brainpower on a one-shot when you might want to do something like it again? Consider generalizing your code. Consider writing a module or object class. Consider making your code run cleanly with \"use strict\" and \"use warnings\" (or -w) in effect. Consider giving away your code. Consider changing your whole world view. Consider... oh, never mind. \u2022 Try to document your code and use Pod formatting in a consistent way. Here are commonly expected conventions: \u2022 use \"C<>\" for function, variable and module names (and more generally anything that can be considered part of code, like filehandles or specific values). Note that function names are considered more readable with parentheses after their name, that is \"function()\". \u2022 use \"B<>\" for commands names like cat or grep. \u2022 use \"F<>\" or \"C<>\" for file names. \"F<>\" should be the only Pod code for file names, but as most Pod formatters render it as italic, Unix and Windows paths with their slashes and backslashes may be less readable, and better rendered with \"C<>\". \u2022 Be consistent. \u2022 Be nice.","Process Name":"perlstyle","Link":"https:\/\/linux.die.net\/man\/1\/perlstyle"}},{"Process":{"Description":"Like many languages, Perl provides for user-defined subroutines. These may be located anywhere in the main program, loaded in from other files via the \"do\", \"require\", or \"use\" keywords, or generated on the fly using \"eval\" or anonymous subroutines. You can even call a function indirectly using a variable containing its name or a CODE reference. The Perl model for function call and return values is simple: all functions are passed as parameters one single flat list of scalars, and all functions likewise return to their caller one single flat list of scalars. Any arrays or hashes in these call and return lists will collapse, losing their identities--but you may always use pass-by-reference instead to avoid this. Both call and return lists may contain as many or as few scalar elements as you'd like. (Often a function without an explicit return statement is called a subroutine, but there's really no difference from Perl's perspective.) Any arguments passed in show up in the array @_. Therefore, if you called a function with two arguments, those would be stored in $_[0] and $_[1]. The array @_ is a local array, but its elements are aliases for the actual scalar parameters. In particular, if an element $_[0] is updated, the corresponding argument is updated (or an error occurs if it is not updatable). If an argument is an array or hash element which did not exist when the function was called, that element is created only when (and if) it is modified or a reference to it is taken. (Some earlier versions of Perl created the element whether or not the element was assigned to.) Assigning to the whole array @_ removes that aliasing, and does not update any arguments. A \"return\" statement may be used to exit a subroutine, optionally specifying the returned value, which will be evaluated in the appropriate context (list, scalar, or void) depending on the context of the subroutine call. If you specify no return value, the subroutine returns an empty list in list context, the undefined value in scalar context, or nothing in void context. If you return one or more aggregates (arrays and hashes), these will be flattened together into one large indistinguishable list. If no \"return\" is found and if the last statement is an expression, its value is returned. If the last statement is a loop control structure like a \"foreach\" or a \"while\", the returned value is unspecified. The empty sub returns the empty list. Perl does not have named formal parameters. In practice all you do is assign to a \"my()\" list of these. Variables that aren't declared to be private are global variables. For gory details on creating private variables, see \"Private Variables via my()\" and \"Temporary Values via local()\". To create protected environments for a set of functions in a separate package (and probably a separate file), see \"Packages\" in perlmod. Example: sub max {\n    my $max = shift(@_);\n    foreach $foo (@_) {\n        $max = $foo if $max < $foo;\n    }\n    return $max;\n}\n$bestday = max($mon,$tue,$wed,$thu,$fri); Example: # get a line, combining continuation lines\n#  that start with whitespace\n\nsub get_line {\n    $thisline = $lookahead;  # global variables!\n    LINE: while (defined($lookahead = <STDIN>)) {\n        if ($lookahead =~ \/^[ \\t]\/) {\n            $thisline .= $lookahead;\n        }\n        else {\n            last LINE;\n        }\n    }\n    return $thisline;\n}\n\n$lookahead = <STDIN>;       # get first line\nwhile (defined($line = get_line())) {\n    ...\n} Assigning to a list of private variables to name your arguments: sub maybeset {\n    my($key, $value) = @_;\n    $Foo{$key} = $value unless $Foo{$key};\n} Because the assignment copies the values, this also has the effect of turning call-by-reference into call-by-value. Otherwise a function is free to do in-place modifications of @_ and change its caller's values. upcase_in($v1, $v2);  # this changes $v1 and $v2\nsub upcase_in {\n    for (@_) { tr\/a-z\/A-Z\/ }\n} You aren't allowed to modify constants in this way, of course. If an argument were actually literal and you tried to change it, you'd take a (presumably fatal) exception. For example, this won't work: upcase_in(\"frederick\"); It would be much safer if the \"upcase_in()\" function were written to return a copy of its parameters instead of changing them in place: ($v3, $v4) = upcase($v1, $v2);  # this doesn't change $v1 and $v2\nsub upcase {\n    return unless defined wantarray;  # void context, do nothing\n    my @parms = @_;\n    for (@parms) { tr\/a-z\/A-Z\/ }\n    return wantarray ? @parms : $parms[0];\n} Notice how this (unprototyped) function doesn't care whether it was passed real scalars or arrays. Perl sees all arguments as one big, long, flat parameter list in @_. This is one area where Perl's simple argument-passing style shines. The \"upcase()\" function would work perfectly well without changing the \"upcase()\" definition even if we fed it things like this: @newlist   = upcase(@list1, @list2);\n@newlist   = upcase( split \/:\/, $var ); Do not, however, be tempted to do this: (@a, @b)   = upcase(@list1, @list2); Like the flattened incoming parameter list, the return list is also flattened on return. So all you have managed to do here is stored everything in @a and made @b empty. See \"Pass by Reference\" for alternatives. A subroutine may be called using an explicit \"&\" prefix. The \"&\" is optional in modern Perl, as are parentheses if the subroutine has been predeclared. The \"&\" is not optional when just naming the subroutine, such as when it's used as an argument to defined() or undef(). Nor is it optional when you want to do an indirect subroutine call with a subroutine name or reference using the \"&$subref()\" or \"&{$subref}()\" constructs, although the \"$subref->()\" notation solves that problem. See perlref for more about all that. Subroutines may be called recursively. If a subroutine is called using the \"&\" form, the argument list is optional, and if omitted, no @_ array is set up for the subroutine: the @_ array at the time of the call is visible to subroutine instead. This is an efficiency mechanism that new users may wish to avoid. &foo(1,2,3);        # pass three arguments\nfoo(1,2,3);         # the same\n\nfoo();              # pass a null list\n&foo();             # the same\n\n&foo;               # foo() get current args, like foo(@_) !!\nfoo;                # like foo() IFF sub foo predeclared, else \"foo\" Not only does the \"&\" form make the argument list optional, it also disables any prototype checking on arguments you do provide. This is partly for historical reasons, and partly for having a convenient way to cheat if you know what you're doing. See Prototypes below. Subroutines whose names are in all upper case are reserved to the Perl core, as are modules whose names are in all lower case. A subroutine in all capitals is a loosely-held convention meaning it will be called indirectly by the run-time system itself, usually due to a triggered event. Subroutines that do special, pre-defined things include \"AUTOLOAD\", \"CLONE\", \"DESTROY\" plus all functions mentioned in perltie and PerlIO::via. The \"BEGIN\", \"UNITCHECK\", \"CHECK\", \"INIT\" and \"END\" subroutines are not so much subroutines as named special code blocks, of which you can have more than one in a package, and which you can not call explicitly. See \" BEGIN , UNITCHECK , CHECK , INIT and END \" in perlmod Private Variables via my() Synopsis: my $foo;            # declare $foo lexically local\nmy (@wid, %get);    # declare list of variables local\nmy $foo = \"flurp\";  # declare $foo lexical, and init it\nmy @oof = @bar;     # declare @oof lexical, and init it\nmy $x : Foo = $y;   # similar, with an attribute applied WARNING : The use of attribute lists on \"my\" declarations is still evolving. The current semantics and interface are subject to change. See attributes and Attribute::Handlers. The \"my\" operator declares the listed variables to be lexically confined to the enclosing block, conditional (\"if\/unless\/elsif\/else\"), loop (\"for\/foreach\/while\/until\/continue\"), subroutine, \"eval\", or \"do\/require\/use\"'d file. If more than one value is listed, the list must be placed in parentheses. All listed elements must be legal lvalues. Only alphanumeric identifiers may be lexically scoped--magical built-ins like $\/ must currently be \"local\"ized with \"local\" instead. Unlike dynamic variables created by the \"local\" operator, lexical variables declared with \"my\" are totally hidden from the outside world, including any called subroutines. This is true if it's the same subroutine called from itself or elsewhere--every call gets its own copy. This doesn't mean that a \"my\" variable declared in a statically enclosing lexical scope would be invisible. Only dynamic scopes are cut off. For example, the \"bumpx()\" function below has access to the lexical $x variable because both the \"my\" and the \"sub\" occurred at the same scope, presumably file scope. my $x = 10;\nsub bumpx { $x++ } An \"eval()\", however, can see lexical variables of the scope it is being evaluated in, so long as the names aren't hidden by declarations within the \"eval()\" itself. See perlref. The parameter list to my() may be assigned to if desired, which allows you to initialize your variables. (If no initializer is given for a particular variable, it is created with the undefined value.) Commonly this is used to name input parameters to a subroutine. Examples:    $arg = \"fred\";        # \"global\" variable\n   $n = cube_root(27);\n   print \"$arg thinks the root is $n\\n\";\nfred thinks the root is 3\n\n   sub cube_root {\n       my $arg = shift;  # name doesn't matter\n       $arg **= 1\/3;\n       return $arg;\n   } The \"my\" is simply a modifier on something you might assign to. So when you do assign to variables in its argument list, \"my\" doesn't change whether those variables are viewed as a scalar or an array. So my ($foo) = <STDIN>;                # WRONG?\nmy @FOO = <STDIN>; both supply a list context to the right-hand side, while my $foo = <STDIN>; supplies a scalar context. But the following declares only one variable: my $foo, $bar = 1;                  # WRONG That has the same effect as my $foo;\n$bar = 1; The declared variable is not introduced (is not visible) until after the current statement. Thus, my $x = $x; can be used to initialize a new $x with the value of the old $x, and the expression my $x = 123 and $x == 123 is false unless the old $x happened to have the value 123. Lexical scopes of control structures are not bounded precisely by the braces that delimit their controlled blocks; control expressions are part of that scope, too. Thus in the loop while (my $line = <>) {\n    $line = lc $line;\n} continue {\n    print $line;\n} the scope of $line extends from its declaration throughout the rest of the loop construct (including the \"continue\" clause), but not beyond it. Similarly, in the conditional if ((my $answer = <STDIN>) =~ \/^yes$\/i) {\n    user_agrees();\n} elsif ($answer =~ \/^no$\/i) {\n    user_disagrees();\n} else {\n    chomp $answer;\n    die \"'$answer' is neither 'yes' nor 'no'\";\n} the scope of $answer extends from its declaration through the rest of that conditional, including any \"elsif\" and \"else\" clauses, but not beyond it. See \"Simple statements\" in perlsyn for information on the scope of variables in statements with modifiers. The \"foreach\" loop defaults to scoping its index variable dynamically in the manner of \"local\". However, if the index variable is prefixed with the keyword \"my\", or if there is already a lexical by that name in scope, then a new lexical is created instead. Thus in the loop for my $i (1, 2, 3) {\n    some_function();\n} the scope of $i extends to the end of the loop, but not beyond it, rendering the value of $i inaccessible within \"some_function()\". Some users may wish to encourage the use of lexically scoped variables. As an aid to catching implicit uses to package variables, which are always global, if you say use strict 'vars'; then any variable mentioned from there to the end of the enclosing block must either refer to a lexical variable, be predeclared via \"our\" or \"use vars\", or else must be fully qualified with the package name. A compilation error results otherwise. An inner block may countermand this with \"no strict 'vars'\". A \"my\" has both a compile-time and a run-time effect. At compile time, the compiler takes notice of it. The principal usefulness of this is to quiet \"use strict 'vars'\", but it is also essential for generation of closures as detailed in perlref. Actual initialization is delayed until run time, though, so it gets executed at the appropriate time, such as each time through a loop, for example. Variables declared with \"my\" are not part of any package and are therefore never fully qualified with the package name. In particular, you're not allowed to try to make a package variable (or other global) lexical: my $pack::var;      # ERROR!  Illegal syntax In fact, a dynamic variable (also known as package or global variables) are still accessible using the fully qualified \"::\" notation even while a lexical of the same name is also visible: package main;\nlocal $x = 10;\nmy    $x = 20;\nprint \"$x and $::x\\n\"; That will print out 20 and 10. You may declare \"my\" variables at the outermost scope of a file to hide any such identifiers from the world outside that file. This is similar in spirit to C's static variables when they are used at the file level. To do this with a subroutine requires the use of a closure (an anonymous function that accesses enclosing lexicals). If you want to create a private subroutine that cannot be called from outside that block, it can declare a lexical variable containing an anonymous sub reference: my $secret_version = '1.001-beta';\nmy $secret_sub = sub { print $secret_version };\n&$secret_sub(); As long as the reference is never returned by any function within the module, no outside module can see the subroutine, because its name is not in any package's symbol table. Remember that it's not REALLY called $some_pack::secret_version or anything; it's just $secret_version, unqualified and unqualifiable. This does not work with object methods, however; all object methods have to be in the symbol table of some package to be found. See \"Function Templates\" in perlref for something of a work-around to this. Persistent Private Variables There are two ways to build persistent private variables in Perl 5.10. First, you can simply use the \"state\" feature. Or, you can use closures, if you want to stay compatible with releases older than 5.10. Persistent variables via state() Beginning with perl 5.9.4, you can declare variables with the \"state\" keyword in place of \"my\". For that to work, though, you must have enabled that feature beforehand, either by using the \"feature\" pragma, or by using \"-E\" on one-liners. (see feature) For example, the following code maintains a private counter, incremented each time the gimme_another() function is called: use feature 'state';\nsub gimme_another { state $x; return ++$x } Also, since $x is lexical, it can't be reached or modified by any Perl code outside. When combined with variable declaration, simple scalar assignment to \"state\" variables (as in \"state $x = 42\") is executed only the first time. When such statements are evaluated subsequent times, the assignment is ignored. The behavior of this sort of assignment to non-scalar variables is undefined. Persistent variables with closures Just because a lexical variable is lexically (also called statically) scoped to its enclosing block, \"eval\", or \"do\" FILE , this doesn't mean that within a function it works like a C static. It normally works more like a C auto, but with implicit garbage collection. Unlike local variables in C or C ++ , Perl's lexical variables don't necessarily get recycled just because their scope has exited. If something more permanent is still aware of the lexical, it will stick around. So long as something else references a lexical, that lexical won't be freed--which is as it should be. You wouldn't want memory being free until you were done using it, or kept around once you were done. Automatic garbage collection takes care of this for you. This means that you can pass back or save away references to lexical variables, whereas to return a pointer to a C auto is a grave error. It also gives us a way to simulate C's function statics. Here's a mechanism for giving a function private variables with both lexical scoping and a static lifetime. If you do want to create something like C's static variables, just enclose the whole function in an extra block, and put the static variable outside the function but in the block. {\n    my $secret_val = 0;\n    sub gimme_another {\n        return ++$secret_val;\n    }\n}\n# $secret_val now becomes unreachable by the outside\n# world, but retains its value between calls to gimme_another If this function is being sourced in from a separate file via \"require\" or \"use\", then this is probably just fine. If it's all in the main program, you'll need to arrange for the \"my\" to be executed early, either by putting the whole block above your main program, or more likely, placing merely a \"BEGIN\" code block around it to make sure it gets executed before your program starts to run: BEGIN {\n    my $secret_val = 0;\n    sub gimme_another {\n        return ++$secret_val;\n    }\n} See \" BEGIN , UNITCHECK , CHECK , INIT and END \" in perlmod about the special triggered code blocks, \"BEGIN\", \"UNITCHECK\", \"CHECK\", \"INIT\" and \"END\". If declared at the outermost scope (the file scope), then lexicals work somewhat like C's file statics. They are available to all functions in that same file declared below them, but are inaccessible from outside that file. This strategy is sometimes used in modules to create private variables that the whole module can see. Temporary Values via local() WARNING : In general, you should be using \"my\" instead of \"local\", because it's faster and safer. Exceptions to this include the global punctuation variables, global filehandles and formats, and direct manipulation of the Perl symbol table itself. \"local\" is mostly used when the current value of a variable must be visible to called subroutines. Synopsis: # localization of values\n\nlocal $foo;                 # make $foo dynamically local\nlocal (@wid, %get);         # make list of variables local\nlocal $foo = \"flurp\";       # make $foo dynamic, and init it\nlocal @oof = @bar;          # make @oof dynamic, and init it\n\nlocal $hash{key} = \"val\";   # sets a local value for this hash entry\nlocal ($cond ? $v1 : $v2);  # several types of lvalues support\n                            # localization\n\n# localization of symbols\n\nlocal *FH;                  # localize $FH, @FH, %FH, &FH  ...\nlocal *merlyn = *randal;    # now $merlyn is really $randal, plus\n                            #     @merlyn is really @randal, etc\nlocal *merlyn = 'randal';   # SAME THING: promote 'randal' to *randal\nlocal *merlyn = \\$randal;   # just alias $merlyn, not @merlyn etc A \"local\" modifies its listed variables to be \"local\" to the enclosing block, \"eval\", or \"do FILE\"--and to any subroutine called from within that block. A \"local\" just gives temporary values to global (meaning package) variables. It does not create a local variable. This is known as dynamic scoping. Lexical scoping is done with \"my\", which works more like C's auto declarations. Some types of lvalues can be localized as well : hash and array elements and slices, conditionals (provided that their result is always localizable), and symbolic references. As for simple variables, this creates new, dynamically scoped values. If more than one variable or expression is given to \"local\", they must be placed in parentheses. This operator works by saving the current values of those variables in its argument list on a hidden stack and restoring them upon exiting the block, subroutine, or eval. This means that called subroutines can also reference the local variable, but not the global one. The argument list may be assigned to if desired, which allows you to initialize your local variables. (If no initializer is given for a particular variable, it is created with an undefined value.) Because \"local\" is a run-time operator, it gets executed each time through a loop. Consequently, it's more efficient to localize your variables outside the loop. Grammatical note on local() A \"local\" is simply a modifier on an lvalue expression. When you assign to a \"local\"ized variable, the \"local\" doesn't change whether its list is viewed as a scalar or an array. So local($foo) = <STDIN>;\nlocal @FOO = <STDIN>; both supply a list context to the right-hand side, while local $foo = <STDIN>; supplies a scalar context. Localization of special variables If you localize a special variable, you'll be giving a new value to it, but its magic won't go away. That means that all side-effects related to this magic still work with the localized value. This feature allows code like this to work : # Read the whole contents of FILE in $slurp\n{ local $\/ = undef; $slurp = <FILE>; } Note, however, that this restricts localization of some values ; for example, the following statement dies, as of perl 5.9.0, with an error Modification of a read-only value attempted, because the $1 variable is magical and read-only : local $1 = 2; Similarly, but in a way more difficult to spot, the following snippet will die in perl 5.9.0 : sub f { local $_ = \"foo\"; print }\nfor ($1) {\n    # now $_ is aliased to $1, thus is magic and readonly\n    f();\n} See next section for an alternative to this situation. WARNING : Localization of tied arrays and hashes does not currently work as described. This will be fixed in a future release of Perl; in the meantime, avoid code that relies on any particular behaviour of localising tied arrays or hashes (localising individual elements is still okay). See \"Localising Tied Arrays and Hashes Is Broken\" in perl58delta for more details. Localization of globs The construct local *name; creates a whole new symbol table entry for the glob \"name\" in the current package. That means that all variables in its glob slot ($name, @name, %name, &name, and the \"name\" filehandle) are dynamically reset. This implies, among other things, that any magic eventually carried by those variables is locally lost. In other words, saying \"local *\/\" will not have any effect on the internal value of the input record separator. Notably, if you want to work with a brand new value of the default scalar $_, and avoid the potential problem listed above about $_ previously carrying a magic value, you should use \"local *_\" instead of \"local $_\". As of perl 5.9.1, you can also use the lexical form of $_ (declaring it with \"my $_\"), which avoids completely this problem. Localization of elements of composite types It's also worth taking a moment to explain what happens when you \"local\"ize a member of a composite type (i.e. an array or hash element). In this case, the element is \"local\"ized by name. This means that when the scope of the \"local()\" ends, the saved value will be restored to the hash element whose key was named in the \"local()\", or the array element whose index was named in the \"local()\". If that element was deleted while the \"local()\" was in effect (e.g. by a \"delete()\" from a hash or a \"shift()\" of an array), it will spring back into existence, possibly extending an array and filling in the skipped elements with \"undef\". For instance, if you say %hash = ( 'This' => 'is', 'a' => 'test' );\n@ary  = ( 0..5 );\n{\n     local($ary[5]) = 6;\n     local($hash{'a'}) = 'drill';\n     while (my $e = pop(@ary)) {\n         print \"$e . . .\\n\";\n         last unless $e > 3;\n     }\n     if (@ary) {\n         $hash{'only a'} = 'test';\n         delete $hash{'a'};\n     }\n}\nprint join(' ', map { \"$_ $hash{$_}\" } sort keys %hash),\".\\n\";\nprint \"The array has \",scalar(@ary),\" elements: \",\n      join(', ', map { defined $_ ? $_ : 'undef' } @ary),\"\\n\"; Perl will print 6 . . .\n4 . . .\n3 . . .\nThis is a test only a test.\nThe array has 6 elements: 0, 1, 2, undef, undef, 5 The behavior of local() on non-existent members of composite types is subject to change in future. Lvalue subroutines WARNING : Lvalue subroutines are still experimental and the implementation may change in future versions of Perl. It is possible to return a modifiable value from a subroutine. To do this, you have to declare the subroutine to return an lvalue. my $val;\nsub canmod : lvalue {\n    # return $val; this doesn't work, don't say \"return\"\n    $val;\n}\nsub nomod {\n    $val;\n}\n\ncanmod() = 5;   # assigns to $val\nnomod()  = 5;   # ERROR The scalar\/list context for the subroutine and for the right-hand side of assignment is determined as if the subroutine call is replaced by a scalar. For example, consider: data(2,3) = get_data(3,4); Both subroutines here are called in a scalar context, while in: (data(2,3)) = get_data(3,4); and in: (data(2),data(3)) = get_data(3,4); all the subroutines are called in a list context. Lvalue subroutines are EXPERIMENTAL They appear to be convenient, but there are several reasons to be circumspect. You can't use the return keyword, you must pass out the value before falling out of subroutine scope. (see comment in example above). This is usually not a problem, but it disallows an explicit return out of a deeply nested loop, which is sometimes a nice way out. They violate encapsulation. A normal mutator can check the supplied argument before setting the attribute it is protecting, an lvalue subroutine never gets that chance. Consider; my $some_array_ref = [];    # protected by mutators ??\n\nsub set_arr {               # normal mutator\n    my $val = shift;\n    die(\"expected array, you supplied \", ref $val)\n       unless ref $val eq 'ARRAY';\n    $some_array_ref = $val;\n}\nsub set_arr_lv : lvalue {   # lvalue mutator\n    $some_array_ref;\n}\n\n# set_arr_lv cannot stop this !\nset_arr_lv() = { a => 1 }; Passing Symbol Table Entries (typeglobs) WARNING : The mechanism described in this section was originally the only way to simulate pass-by-reference in older versions of Perl. While it still works fine in modern versions, the new reference mechanism is generally easier to work with. See below. Sometimes you don't want to pass the value of an array to a subroutine but rather the name of it, so that the subroutine can modify the global copy of it rather than working with a local copy. In perl you can refer to all objects of a particular name by prefixing the name with a star: *foo. This is often known as a \"typeglob\", because the star on the front can be thought of as a wildcard match for all the funny prefix characters on variables and subroutines and such. When evaluated, the typeglob produces a scalar value that represents all the objects of that name, including any filehandle, format, or subroutine. When assigned to, it causes the name mentioned to refer to whatever \"*\" value was assigned to it. Example: sub doubleary {\n    local(*someary) = @_;\n    foreach $elem (@someary) {\n        $elem *= 2;\n    }\n}\ndoubleary(*foo);\ndoubleary(*bar); Scalars are already passed by reference, so you can modify scalar arguments without using this mechanism by referring explicitly to $_[0] etc. You can modify all the elements of an array by passing all the elements as scalars, but you have to use the \"*\" mechanism (or the equivalent reference mechanism) to \"push\", \"pop\", or change the size of an array. It will certainly be faster to pass the typeglob (or reference). Even if you don't want to modify an array, this mechanism is useful for passing multiple arrays in a single LIST , because normally the LIST mechanism will merge all the array values so that you can't extract out the individual arrays. For more on typeglobs, see \"Typeglobs and Filehandles\" in perldata. When to Still Use local() Despite the existence of \"my\", there are still three places where the \"local\" operator still shines. In fact, in these three places, you must use \"local\" instead of \"my\". 1. You need to give a global variable a temporary value, especially $_. The global variables, like @ARGV or the punctuation variables, must be \"local\"ized with \"local()\". This block reads in \/etc\/motd, and splits it up into chunks separated by lines of equal signs, which are placed in @Fields. {\n    local @ARGV = (\"\/etc\/motd\");\n    local $\/ = undef;\n    local $_ = <>;\n    @Fields = split \/^\\s*=+\\s*$\/;\n} It particular, it's important to \"local\"ize $_ in any routine that assigns to it. Look out for implicit assignments in \"while\" conditionals. 2. You need to create a local file or directory handle or a local function. A function that needs a filehandle of its own must use \"local()\" on a complete typeglob. This can be used to create new symbol table entries: sub ioqueue {\n    local  (*READER, *WRITER);    # not my!\n    pipe    (READER,  WRITER)     or die \"pipe: $!\";\n    return (*READER, *WRITER);\n}\n($head, $tail) = ioqueue(); See the Symbol module for a way to create anonymous symbol table entries. Because assignment of a reference to a typeglob creates an alias, this can be used to create what is effectively a local function, or at least, a local alias. {\n    local *grow = \\&shrink; # only until this block exists\n    grow();                 # really calls shrink()\n    move();                 # if move() grow()s, it shrink()s too\n}\ngrow();                     # get the real grow() again See \"Function Templates\" in perlref for more about manipulating functions by name in this way. 3. You want to temporarily change just one element of an array or hash. You can \"local\"ize just one element of an aggregate. Usually this is done on dynamics: {\n    local $SIG{INT} = 'IGNORE';\n    funct();                            # uninterruptible\n}\n# interruptibility automatically restored here But it also works on lexically declared aggregates. Prior to 5.005, this operation could on occasion misbehave. Pass by Reference If you want to pass more than one array or hash into a function--or return them from it--and have them maintain their integrity, then you're going to have to use an explicit pass-by-reference. Before you do that, you need to understand references as detailed in perlref. This section may not make much sense to you otherwise. Here are a few simple examples. First, let's pass in several arrays to a function and have it \"pop\" all of then, returning a new list of all their former last elements: @tailings = popmany ( \\@a, \\@b, \\@c, \\@d );\n\nsub popmany {\n    my $aref;\n    my @retlist = ();\n    foreach $aref ( @_ ) {\n        push @retlist, pop @$aref;\n    }\n    return @retlist;\n} Here's how you might write a function that returns a list of keys occurring in all the hashes passed to it: @common = inter( \\%foo, \\%bar, \\%joe );\nsub inter {\n    my ($k, $href, %seen); # locals\n    foreach $href (@_) {\n        while ( $k = each %$href ) {\n            $seen{$k}++;\n        }\n    }\n    return grep { $seen{$_} == @_ } keys %seen;\n} So far, we're using just the normal list return mechanism. What happens if you want to pass or return a hash? Well, if you're using only one of them, or you don't mind them concatenating, then the normal calling convention is ok, although a little expensive. Where people get into trouble is here:     (@a, @b) = func(@c, @d);\nor\n    (%a, %b) = func(%c, %d); That syntax simply won't work. It sets just @a or %a and clears the @b or %b. Plus the function didn't get passed into two separate arrays or hashes: it got one long list in @_, as always. If you can arrange for everyone to deal with this through references, it's cleaner code, although not so nice to look at. Here's a function that takes two array references as arguments, returning the two array elements in order of how many elements they have in them: ($aref, $bref) = func(\\@c, \\@d);\nprint \"@$aref has more than @$bref\\n\";\nsub func {\n    my ($cref, $dref) = @_;\n    if (@$cref > @$dref) {\n        return ($cref, $dref);\n    } else {\n        return ($dref, $cref);\n    }\n} It turns out that you can actually do this also: (*a, *b) = func(\\@c, \\@d);\nprint \"@a has more than @b\\n\";\nsub func {\n    local (*c, *d) = @_;\n    if (@c > @d) {\n        return (\\@c, \\@d);\n    } else {\n        return (\\@d, \\@c);\n    }\n} Here we're using the typeglobs to do symbol table aliasing. It's a tad subtle, though, and also won't work if you're using \"my\" variables, because only globals (even in disguise as \"local\"s) are in the symbol table. If you're passing around filehandles, you could usually just use the bare typeglob, like *STDOUT, but typeglobs references work, too. For example: splutter(\\*STDOUT);\nsub splutter {\n    my $fh = shift;\n    print $fh \"her um well a hmmm\\n\";\n}\n\n$rec = get_rec(\\*STDIN);\nsub get_rec {\n    my $fh = shift;\n    return scalar <$fh>;\n} If you're planning on generating new filehandles, you could do this. Notice to pass back just the bare *FH, not its reference. sub openit {\n    my $path = shift;\n    local *FH;\n    return open (FH, $path) ? *FH : undef;\n} Prototypes Perl supports a very limited kind of compile-time argument checking using function prototyping. If you declare sub mypush (\\@@) then \"mypush()\" takes arguments exactly like \"push()\" does. The function declaration must be visible at compile time. The prototype affects only interpretation of new-style calls to the function, where new-style is defined as not using the \"&\" character. In other words, if you call it like a built-in function, then it behaves like a built-in function. If you call it like an old-fashioned subroutine, then it behaves like an old-fashioned subroutine. It naturally falls out from this rule that prototypes have no influence on subroutine references like \"\\&foo\" or on indirect subroutine calls like \"&{$subref}\" or \"$subref->()\". Method calls are not influenced by prototypes either, because the function to be called is indeterminate at compile time, since the exact code called depends on inheritance. Because the intent of this feature is primarily to let you define subroutines that work like built-in functions, here are prototypes for some other functions that parse almost exactly like the corresponding built-in. Declared as                 Called as\n\nsub mylink ($$)          mylink $old, $new\nsub myvec ($$$)          myvec $var, $offset, 1\nsub myindex ($$;$)       myindex &getstring, \"substr\"\nsub mysyswrite ($$$;$)   mysyswrite $buf, 0, length($buf) - $off, $off\nsub myreverse (@)        myreverse $a, $b, $c\nsub myjoin ($@)          myjoin \":\", $a, $b, $c\nsub mypop (\\@)           mypop @array\nsub mysplice (\\@$$@)     mysplice @array, 0, 2, @pushme\nsub mykeys (\\%)          mykeys %{$hashref}\nsub myopen (*;$)         myopen HANDLE, $name\nsub mypipe (**)          mypipe READHANDLE, WRITEHANDLE\nsub mygrep (&@)          mygrep { \/foo\/ } $a, $b, $c\nsub myrand (;$)          myrand 42\nsub mytime ()            mytime Any backslashed prototype character represents an actual argument that absolutely must start with that character. The value passed as part of @_ will be a reference to the actual argument given in the subroutine call, obtained by applying \"\\\" to that argument. You can also backslash several argument types simultaneously by using the \"\\[]\" notation: sub myref (\\[$@%&*]) will allow calling myref() as myref $var\nmyref @array\nmyref %hash\nmyref &sub\nmyref *glob and the first argument of myref() will be a reference to a scalar, an array, a hash, a code, or a glob. Unbackslashed prototype characters have special meanings. Any unbackslashed \"@\" or \"%\" eats all remaining arguments, and forces list context. An argument represented by \"$\" forces scalar context. An \"&\" requires an anonymous subroutine, which, if passed as the first argument, does not require the \"sub\" keyword or a subsequent comma. A \"*\" allows the subroutine to accept a bareword, constant, scalar expression, typeglob, or a reference to a typeglob in that slot. The value will be available to the subroutine either as a simple scalar, or (in the latter two cases) as a reference to the typeglob. If you wish to always convert such arguments to a typeglob reference, use Symbol::qualify_to_ref() as follows: use Symbol 'qualify_to_ref';\n\nsub foo (*) {\n    my $fh = qualify_to_ref(shift, caller);\n    ...\n} A semicolon ( \";\") separates mandatory arguments from optional arguments. It is redundant before \"@\" or \"%\", which gobble up everything else. As the last character of a prototype, or just before a semicolon, you can use \"_\" in place of \"$\": if this argument is not provided, $_ will be used instead. Note how the last three examples in the table above are treated specially by the parser. \"mygrep()\" is parsed as a true list operator, \"myrand()\" is parsed as a true unary operator with unary precedence the same as \"rand()\", and \"mytime()\" is truly without arguments, just like \"time()\". That is, if you say mytime +2; you'll get \"mytime() + 2\", not mytime(2), which is how it would be parsed without a prototype. The interesting thing about \"&\" is that you can generate new syntax with it, provided it's in the initial position: sub try (&@) {\n    my($try,$catch) = @_;\n    eval { &$try };\n    if ($@) {\n        local $_ = $@;\n        &$catch;\n    }\n}\nsub catch (&) { $_[0] }\n\ntry {\n    die \"phooey\";\n} catch {\n    \/phooey\/ and print \"unphooey\\n\";\n}; That prints \"unphooey\". (Yes, there are still unresolved issues having to do with visibility of @_. I'm ignoring that question for the moment. (But note that if we make @_ lexically scoped, those anonymous subroutines can act like closures... (Gee, is this sounding a little Lispish? (Never mind.)))) And here's a reimplementation of the Perl \"grep\" operator: sub mygrep (&@) {\n    my $code = shift;\n    my @result;\n    foreach $_ (@_) {\n        push(@result, $_) if &$code;\n    }\n    @result;\n} Some folks would prefer full alphanumeric prototypes. Alphanumerics have been intentionally left out of prototypes for the express purpose of someday in the future adding named, formal parameters. The current mechanism's main goal is to let module writers provide better diagnostics for module users. Larry feels the notation quite understandable to Perl programmers, and that it will not intrude greatly upon the meat of the module, nor make it harder to read. The line noise is visually encapsulated into a small pill that's easy to swallow. If you try to use an alphanumeric sequence in a prototype you will generate an optional warning - \"Illegal character in prototype...\". Unfortunately earlier versions of Perl allowed the prototype to be used as long as its prefix was a valid prototype. The warning may be upgraded to a fatal error in a future version of Perl once the majority of offending code is fixed. It's probably best to prototype new functions, not retrofit prototyping into older ones. That's because you must be especially careful about silent impositions of differing list versus scalar contexts. For example, if you decide that a function should take just one parameter, like this: sub func ($) {\n    my $n = shift;\n    print \"you gave me $n\\n\";\n} and someone has been calling it with an array or expression returning a list: func(@foo);\nfunc( split \/:\/ ); Then you've just supplied an automatic \"scalar\" in front of their argument, which can be more than a bit surprising. The old @foo which used to hold one thing doesn't get passed in. Instead, \"func()\" now gets passed in a 1; that is, the number of elements in @foo. And the \"split\" gets called in scalar context so it starts scribbling on your @_ parameter list. Ouch! This is all very powerful, of course, and should be used only in moderation to make the world a better place. Constant Functions Functions with a prototype of \"()\" are potential candidates for inlining. If the result after optimization and constant folding is either a constant or a lexically-scoped scalar which has no other references, then it will be used in place of function calls made without \"&\". Calls made using \"&\" are never inlined. (See constant.pm for an easy way to declare most constants.) The following functions would all be inlined: sub pi ()           { 3.14159 }             # Not exact, but close.\nsub PI ()           { 4 * atan2 1, 1 }      # As good as it gets,\n                                            # and it's inlined, too!\nsub ST_DEV ()       { 0 }\nsub ST_INO ()       { 1 }\n\nsub FLAG_FOO ()     { 1 << 8 }\nsub FLAG_BAR ()     { 1 << 9 }\nsub FLAG_MASK ()    { FLAG_FOO | FLAG_BAR }\n\nsub OPT_BAZ ()      { not (0x1B58 & FLAG_MASK) }\n\nsub N () { int(OPT_BAZ) \/ 3 }\n\nsub FOO_SET () { 1 if FLAG_MASK & FLAG_FOO } Be aware that these will not be inlined; as they contain inner scopes, the constant folding doesn't reduce them to a single constant: sub foo_set () { if (FLAG_MASK & FLAG_FOO) { 1 } }\n\nsub baz_val () {\n    if (OPT_BAZ) {\n        return 23;\n    }\n    else {\n        return 42;\n    }\n} If you redefine a subroutine that was eligible for inlining, you'll get a mandatory warning. (You can use this warning to tell whether or not a particular subroutine is considered constant.) The warning is considered severe enough not to be optional because previously compiled invocations of the function will still be using the old value of the function. If you need to be able to redefine the subroutine, you need to ensure that it isn't inlined, either by dropping the \"()\" prototype (which changes calling semantics, so beware) or by thwarting the inlining mechanism in some other way, such as sub not_inlined () {\n    23 if $];\n} Overriding Built-in Functions Many built-in functions may be overridden, though this should be tried only occasionally and for good reason. Typically this might be done by a package attempting to emulate missing built-in functionality on a non-Unix system. Overriding may be done only by importing the name from a module at compile time--ordinary predeclaration isn't good enough. However, the \"use subs\" pragma lets you, in effect, predeclare subs via the import syntax, and these names may then override built-in ones: use subs 'chdir', 'chroot', 'chmod', 'chown';\nchdir $somewhere;\nsub chdir { ... } To unambiguously refer to the built-in form, precede the built-in name with the special package qualifier \"CORE::\". For example, saying \"CORE::open()\" always refers to the built-in \"open()\", even if the current package has imported some other subroutine called \"&open()\" from elsewhere. Even though it looks like a regular function call, it isn't: you can't take a reference to it, such as the incorrect \"\\&CORE::open\" might appear to produce. Library modules should not in general export built-in names like \"open\" or \"chdir\" as part of their default @EXPORT list, because these may sneak into someone else's namespace and change the semantics unexpectedly. Instead, if the module adds that name to @EXPORT_OK, then it's possible for a user to import the name explicitly, but not implicitly. That is, they could say use Module 'open'; and it would import the \"open\" override. But if they said use Module; they would get the default imports without overrides. The foregoing mechanism for overriding built-in is restricted, quite deliberately, to the package that requests the import. There is a second method that is sometimes applicable when you wish to override a built-in everywhere, without regard to namespace boundaries. This is achieved by importing a sub into the special namespace \"CORE::GLOBAL::\". Here is an example that quite brazenly replaces the \"glob\" operator with something that understands regular expressions. package REGlob;\nrequire Exporter;\n@ISA = 'Exporter';\n@EXPORT_OK = 'glob';\n\nsub import {\n    my $pkg = shift;\n    return unless @_;\n    my $sym = shift;\n    my $where = ($sym =~ s\/^GLOBAL_\/\/ ? 'CORE::GLOBAL' : caller(0));\n    $pkg->export($where, $sym, @_);\n}\n\nsub glob {\n    my $pat = shift;\n    my @got;\n    if (opendir my $d, '.') {\n        @got = grep \/$pat\/, readdir $d;\n        closedir $d;\n    }\n    return @got;\n}\n1; And here's how it could be (ab)used: #use REGlob 'GLOBAL_glob';      # override glob() in ALL namespaces\npackage Foo;\nuse REGlob 'glob';              # override glob() in Foo:: only\nprint for <^[a-z_]+\\.pm\\$>;     # show all pragmatic modules The initial comment shows a contrived, even dangerous example. By overriding \"glob\" globally, you would be forcing the new (and subversive) behavior for the \"glob\" operator for every namespace, without the complete cognizance or cooperation of the modules that own those namespaces. Naturally, this should be done with extreme caution--if it must be done at all. The \"REGlob\" example above does not implement all the support needed to cleanly override perl's \"glob\" operator. The built-in \"glob\" has different behaviors depending on whether it appears in a scalar or list context, but our \"REGlob\" doesn't. Indeed, many perl built-in have such context sensitive behaviors, and these must be adequately supported by a properly written override. For a fully functional example of overriding \"glob\", study the implementation of \"File::DosGlob\" in the standard library. When you override a built-in, your replacement should be consistent (if possible) with the built-in native syntax. You can achieve this by using a suitable prototype. To get the prototype of an overridable built-in, use the \"prototype\" function with an argument of \"CORE::builtin_name\" (see \"prototype\" in perlfunc). Note however that some built-ins can't have their syntax expressed by a prototype (such as \"system\" or \"chomp\"). If you override them you won't be able to fully mimic their original syntax. The built-ins \"do\", \"require\" and \"glob\" can also be overridden, but due to special magic, their original syntax is preserved, and you don't have to define a prototype for their replacements. (You can't override the \"do BLOCK\" syntax, though). \"require\" has special additional dark magic: if you invoke your \"require\" replacement as \"require Foo::Bar\", it will actually receive the argument \"Foo\/Bar.pm\" in @_. See \"require\" in perlfunc. And, as you'll have noticed from the previous example, if you override \"glob\", the \"<*>\" glob operator is overridden as well. In a similar fashion, overriding the \"readline\" function also overrides the equivalent I\/O operator \"<FILEHANDLE>\". Also, overriding \"readpipe\" also overrides the operators \"``\" and \"qx\/\/\". Finally, some built-ins (e.g. \"exists\" or \"grep\") can't be overridden. Autoloading If you call a subroutine that is undefined, you would ordinarily get an immediate, fatal error complaining that the subroutine doesn't exist. (Likewise for subroutines being used as methods, when the method doesn't exist in any base class of the class's package.) However, if an \"AUTOLOAD\" subroutine is defined in the package or packages used to locate the original subroutine, then that \"AUTOLOAD\" subroutine is called with the arguments that would have been passed to the original subroutine. The fully qualified name of the original subroutine magically appears in the global $AUTOLOAD variable of the same package as the \"AUTOLOAD\" routine. The name is not passed as an ordinary argument because, er, well, just because, that's why. (As an exception, a method call to a nonexistent \"import\" or \"unimport\" method is just skipped instead.) Many \"AUTOLOAD\" routines load in a definition for the requested subroutine using eval(), then execute that subroutine using a special form of goto() that erases the stack frame of the \"AUTOLOAD\" routine without a trace. (See the source to the standard module documented in AutoLoader, for example.) But an \"AUTOLOAD\" routine can also just emulate the routine and never define it. For example, let's pretend that a function that wasn't defined should just invoke \"system\" with those arguments. All you'd do is: sub AUTOLOAD {\n    my $program = $AUTOLOAD;\n    $program =~ s\/.*::\/\/;\n    system($program, @_);\n}\ndate();\nwho('am', 'i');\nls('-l'); In fact, if you predeclare functions you want to call that way, you don't even need parentheses: use subs qw(date who ls);\ndate;\nwho \"am\", \"i\";\nls '-l'; A more complete example of this is the standard Shell module, which can treat undefined subroutine calls as calls to external programs. Mechanisms are available to help modules writers split their modules into autoloadable files. See the standard AutoLoader module described in AutoLoader and in AutoSplit, the standard SelfLoader modules in SelfLoader, and the document on adding C functions to Perl code in perlxs. Subroutine Attributes A subroutine declaration or definition may have a list of attributes associated with it. If such an attribute list is present, it is broken up at space or colon boundaries and treated as though a \"use attributes\" had been seen. See attributes for details about what attributes are currently supported. Unlike the limitation with the obsolescent \"use attrs\", the \"sub : ATTRLIST\" syntax works to associate the attributes with a pre-declaration, and not just with a subroutine definition. The attributes must be valid as simple identifier names (without any punctuation other than the '_' character). They may have a parameter list appended, which is only checked for whether its parentheses ('(',')') nest properly. Examples of valid syntax (even though the attributes are unknown): sub fnord (&\\%) : switch(10,foo(7,3))  :  expensive;\nsub plugh () : Ugly('\\(\") :Bad;\nsub xyzzy : _5x5 { ... } Examples of invalid syntax: sub fnord : switch(10,foo(); # ()-string not balanced\nsub snoid : Ugly('(');        # ()-string not balanced\nsub xyzzy : 5x5;              # \"5x5\" not a valid identifier\nsub plugh : Y2::north;        # \"Y2::north\" not a simple identifier\nsub snurt : foo + bar;        # \"+\" not a colon or space The attribute list is passed as a list of constant strings to the code which associates them with the subroutine. In particular, the second example of valid syntax above currently looks like this in terms of how it's parsed and invoked: use attributes __PACKAGE__, \\&plugh, q[Ugly('\\(\")], 'Bad'; For further details on attribute lists and their manipulation, see attributes and Attribute::Handlers.","Process Name":"perlsub","Link":"https:\/\/linux.die.net\/man\/1\/perlsub"}},{"Process":{"Description":"This document describes various features of the Symbian operating system that will affect how Perl version 5 (hereafter just Perl) is compiled and\/or runs. NOTE: this port (as of 0.4.1) does not compile into a Symbian OS GUI application, but instead it results in a Symbian DLL . The DLL includes a C ++ class called CPerlBase, which one can then (derive from and) use to embed Perl into applications, see symbian\/README. The base port of Perl to Symbian only implements the basic POSIX-like functionality; it does not implement any further Symbian or Series 60, Series 80, or UIQ bindings for Perl. It is also possible to generate Symbian executables for \"miniperl\" and \"perl\", but since there is no standard command line interface for Symbian (nor full keyboards in the devices), these are useful mainly as demonstrations. Compiling Perl on Symbian (0) You need to have the appropriate Symbian SDK installed. These instructions have been tested under various Nokia Series 60\nSymbian SDKs (1.2 to 2.6, 2.8 should also work, 1.2 compiles but\ndoes not work), Series 80 2.0, and Nokia 7710 (Series 90) SDK.\nYou can get the SDKs from Forum Nokia (http:\/\/www.forum.nokia.com\/).\nA very rough port (\"it compiles\") to UIQ 2.1 has also been made.\n\nA prerequisite for any of the SDKs is to install ActivePerl\nfrom ActiveState, http:\/\/www.activestate.com\/Products\/ActivePerl\/\n\nHaving the SDK installed also means that you need to have either\nthe Metrowerks CodeWarrior installed (2.8 and 3.0 were used in testing)\nor the Microsoft Visual C++ 6.0 installed (SP3 minimum, SP5 recommended).\n\nNote that for example the Series 60 2.0 VC SDK installation talks\nabout ActivePerl build 518, which does no more (as of mid-2005) exist\nat the ActiveState website.  The ActivePerl 5.8.4 build 810 was\nused successfully for compiling Perl on Symbian.  The 5.6.x ActivePerls\ndo not work.\n\nOther SDKs or compilers like Visual.NET, command-line-only\nVisual.NET, Borland, GnuPoc, or sdk2unix have not been tried.\n\nThese instructions almost certainly won't work with older Symbian\nreleases or other SDKs.  Patches to get this port running in other\nreleases, SDKs, compilers, platforms, or devices are naturally welcome. (1) Get a Perl source code distribution (for example the file perl-5.9.2.tar.gz is fine) from http:\/\/www.cpan.org\/src\/ and unpack it in your the C:\/Symbian directory of your Windows system. (2) Change to the perl source directory. cd c:\\Symbian\\perl-5.x.x (3) Run the following script using the perl coming with the SDK     perl symbian\\config.pl\n\nYou must use the cmd.exe, the Cygwin shell will not work.\nThe PATH must include the SDK tools, including a Perl,\nwhich should be the case under cmd.exe.  If you do not\nhave that, see the end of symbian\\sdk.pl for notes of\nhow your environment should be set up for Symbian compiles. (4) Build the project, either by     make all\n\nin cmd.exe or by using either the Metrowerks CodeWarrior\nor the Visual C++ 6.0, or the Visual Studio 8 (the Visual C++\n2005 Express Edition works fine).\n\nIf you use the VC IDE, you will have to run F<symbian\\config.pl>\nfirst using the cmd.exe, and then run 'make win.mf vc6.mf' to generate\nthe VC6 makefiles and workspaces.  \"make vc6\" will compile for the VC6,\nand \"make cw\" for the CodeWarrior.\n\nThe following SDK and compiler configurations and Nokia phones were\ntested at some point in time (+ = compiled and PerlApp run, - = not),\nboth for Perl 5.8.x and 5.9.x:\n\n    SDK     | VC | CW |\n    --------+----+----+---\n    S60 1.2 | +  | +  | 3650 (*)\n    S60 2.0 | +  | +  | 6600\n    S60 2.1 | -  | +  | 6670\n    S60 2.6 | +  | +  | 6630\n    S60 2.8 | +  | +  | (not tested in a device)\n    S80 2.6 | -  | +  | 9300\n    S90 1.1 | +  | -  | 7710\n    UIQ 2.1 | -  | +  | (not tested in a device)\n\n(*) Compiles but does not work, unfortunately, a problem with Symbian.\n\nIf you are using the 'make' directly, it is the GNU make from the SDKs,\nand it will invoke the right make commands for the Windows emulator\nbuild and the Arm target builds ('thumb' by default) as necessary.\n\nThe build scripts assume the 'absolute style' SDK installs under C:,\nthe 'subst style' will not work.\n\nIf using the VC IDE, to build use for example the File->Open Workspace->\nC:\\Symbian\\8.0a\\S60_2nd_FP2\\epoc32\\build\\symbian\\perl\\perl\\wins\\perl.dsw\nThe emulator binaries will appear in the same directory.\n\nIf using the VC IDE, you will a lot of warnings in the beginning of\nthe build because a lot of headers mentioned by the source cannot\nbe found, but this is not serious since those headers are not used.\n\nThe Metrowerks will give a lot of warnings about unused variables and\nempty declarations, you can ignore those.\n\nWhen the Windows and Arm DLLs are built do not be scared by a very long\nmessages whizzing by: it is the \"export freeze\" phase where the whole\n(rather large) API of Perl is listed.\n\nOnce the build is completed you need to create the DLL SIS file by\n\n    make perldll.sis\n\nwhich will create the file perlXYZ.sis (the XYZ being the Perl version)\nwhich you can then install into your Symbian device: an easy way\nto do this is to send them via Bluetooth or infrared and just open\nthe messages.\n\nSince the total size of all Perl SIS files once installed is\nover 2 MB, it is recommended to do the installation into a\nmemory card (drive E:) instead of the C: drive.\n\nThe size of the perlXYZ.SIS is about 370 kB but once it is in the\ndevice it is about one 750 kB (according to the application manager).\n\nThe perlXYZ.sis includes only the Perl DLL: to create an additional\nSIS file which includes some of the standard (pure) Perl libraries,\nissue the command\n\n    make perllib.sis\n\nSome of the standard Perl libraries are included, but not all:\nsee L<\/HISTORY> or F<symbian\\install.cfg> for more details\n(250 kB -> 700 kB).\n\nSome of the standard Perl XS extensions (see L<\/HISTORY> are\nalso available:\n\n    make perlext.sis\n\nwhich will create perlXYZext.sis (290 kB -> 770 kB).\n\nTo compile the demonstration application PerlApp you need first to\ninstall the Perl headers under the SDK.\n\nTo install the Perl headers and the class CPerlBase documentation\nso that you no more need the Perl sources around to compile Perl\napplications using the SDK:\n\n    make sdkinstall\n\nThe destination directory is C:\\Symbian\\perl\\X.Y.Z.  For more\ndetails, see F<symbian\\PerlBase.pod>.\n\nOnce the headers have been installed, you can create a SIS for\nthe PerlApp:\n\n    make perlapp.sis\n\nThe perlapp.sis (11 kB -> 16 kB) will be built in the symbian\nsubdirectory, but a copy will also be made to the main directory.\n\nIf you want to package the Perl DLLs (one for WINS, one for ARMI),\nthe headers, and the documentation:\n\n    make perlsdk.zip\n\nwhich will create perlXYZsdk.zip that can be used in another\nWindows system with the SDK, without having to compile Perl in\nthat system.\n\nIf you want to package the PerlApp sources:\n\n    make perlapp.zip\n\nIf you want to package the perl.exe and miniperl.exe, you\ncan use the perlexe.sis and miniperlexe.sis make targets.\nYou also probably want the perllib.sis for the libraries\nand maybe even the perlapp.sis for the recognizer.\n\nThe make target 'allsis' combines all the above SIS targets.\n\nTo clean up after compilation you can use either of\n\n    make clean\n    make distclean\n\ndepending on how clean you want to be. Compilation problems If you see right after \"make\" this cat makefile.sh >makefile\n'cat' is not recognized as an internal or external command,\noperable program or batch file. it means you need to (re)run the symbian\\config.pl. If you get the error 'perl' is not recognized as an internal or external command,\noperable program or batch file. you may need to reinstall the ActivePerl. If you see this ren makedef.pl nomakedef.pl\nThe system cannot find the file specified.\nC:\\Symbian\\...\\make.exe: [rename_makedef] Error 1 (ignored) please ignore it since it is nothing serious (the build process of renames the Perl makedef.pl as nomakedef.pl to avoid confusing it with a makedef.pl of the SDK ). PerlApp The PerlApp application demonstrates how to embed Perl interpreters to a Symbian application. The \"Time\" menu item runs the following Perl code: \"print \"Running in \", $^O, \"\\n\", scalar localtime\", the \"Oneliner\" allows one to type in Perl code, and the \"Run\" opens a file chooser for selecting a Perl file to run. The PerlApp also is started when the \"Perl recognizer\" (also included and installed) detects a Perl file being activated througg the GUI , and offers either to install it under \\Perl (if the Perl file is in the inbox of the messaging application) or to run it (if the Perl file is under \\Perl). sisify.pl In the symbian subdirectory there is sisify.pl utility which can be used to package Perl scripts and\/or Perl library directories into SIS files, which can be installed to the device. To run the sisify.pl utility, you will need to have the 'makesis' and 'uidcrc' utilities already installed. If you don't have the Win32 SDKs, you may try for example http:\/\/gnupoc.sourceforge.net\/ or http:\/\/symbianos.org\/~andreh\/. Using Perl in Symbian First of all note that you have full access to the Symbian device when using Perl: you can do a lot of damage to your device (like removing system files) unless you are careful. Please do take backups before doing anything. The Perl port has been done for the most part using the Symbian standard POSIX-ish STDLIB library. It is a reasonably complete library, but certain corners of such emulation libraries that tend to be left unimplemented on non-UNIX platforms have been left unimplemented also this time: fork(), signals(), user\/group ids, select() working for sockets, non-blocking sockets, and so forth. See the file symbian\/config.sh and look for 'undef' to find the unsupported APIs (or from Perl use Config). The filesystem of Symbian devices uses DOSish syntax, \"drives\" separated from paths by a colon, and backslashes for the path. The exact assignment of the drives probably varies between platforms, but for example in Series 60 you might see C: as the (flash) main memory, D: as the RAM drive, E: as the memory card ( MMC ), Z: as the ROM . In Series 80 D: is the memory card. As far the devices go the NUL: is the bit bucket, the COMx: are the serial lines, IRCOMx: are the IR ports, TMP: might be C:\\System\\Temp. Remember to double those backslashes in doublequoted strings. The Perl DLL is installed in \\System\\Libs\\. The Perl libraries and extension DLLs are installed in \\System\\Libs\\Perl\\X.Y.Z\\. The PerlApp is installed in \\System\\Apps\\, and the SIS also installs a couple of demo scripts in \\Perl\\ (C:\\Mydocs\\Perl\\ on Nokia 7710). Note that the Symbian filesystem is very picky: it strongly prefers the \\ instead of the \/. When doing XS \/ Symbian C ++ programming include first the Symbian headers, then any standard C\/POSIX headers, then Perl headers, and finally any application headers. New() and Copy() are unfortunately used by both Symbian and Perl code so you'll have to play cpp games if you need them. PerlBase.h undefines the Perl definitions and redefines them as PerlNew() and PerlCopy().","Process Name":"perlsymbian","Link":"https:\/\/linux.die.net\/man\/1\/perlsymbian"}},{"Process":{"Description":"A Perl program consists of a sequence of declarations and statements which run from the top to the bottom. Loops, subroutines and other control structures allow you to jump around within the code. Perl is a free-form language, you can format and indent it however you like. Whitespace mostly serves to separate tokens, unlike languages like Python where it is an important part of the syntax. Many of Perl's syntactic elements are optional. Rather than requiring you to put parentheses around every function call and declare every variable, you can often leave such explicit elements off and Perl will figure out what you meant. This is known as Do What I Mean, abbreviated DWIM . It allows programmers to be lazy and to code in a style with which they are comfortable. Perl borrows syntax and concepts from many languages: awk, sed, C, Bourne Shell, Smalltalk, Lisp and even English. Other languages have borrowed syntax from Perl, particularly its regular expression extensions. So if you have programmed in another language you will see familiar pieces in Perl. They often work the same, but see perltrap for information about how they differ. Declarations The only things you need to declare in Perl are report formats and subroutines (and sometimes not even subroutines). A variable holds the undefined value ( \"undef\") until it has been assigned a defined value, which is anything other than \"undef\". When used as a number, \"undef\" is treated as 0; when used as a string, it is treated as the empty string, \"\"; and when used as a reference that isn't being assigned to, it is treated as an error. If you enable warnings, you'll be notified of an uninitialized value whenever you treat \"undef\" as a string or a number. Well, usually. Boolean contexts, such as: my $a;\nif ($a) {} are exempt from warnings (because they care about truth rather than definedness). Operators such as \"++\", \"--\", \"+=\", \"-=\", and \".=\", that operate on undefined left values such as: my $a;\n$a++; are also always exempt from such warnings. A declaration can be put anywhere a statement can, but has no effect on the execution of the primary sequence of statements--declarations all take effect at compile time. Typically all the declarations are put at the beginning or the end of the script. However, if you're using lexically-scoped private variables created with \"my()\", you'll have to make sure your format or subroutine definition is within the same block scope as the my if you expect to be able to access those private variables. Declaring a subroutine allows a subroutine name to be used as if it were a list operator from that point forward in the program. You can declare a subroutine without defining it by saying \"sub name\", thus: sub myname;\n$me = myname $0             or die \"can't get myname\"; Note that myname() functions as a list operator, not as a unary operator; so be careful to use \"or\" instead of \"||\" in this case. However, if you were to declare the subroutine as \"sub myname ($)\", then \"myname\" would function as a unary operator, so either \"or\" or \"||\" would work. Subroutines declarations can also be loaded up with the \"require\" statement or both loaded and imported into your namespace with a \"use\" statement. See perlmod for details on this. A statement sequence may contain declarations of lexically-scoped variables, but apart from declaring a variable name, the declaration acts like an ordinary statement, and is elaborated within the sequence of statements as if it were an ordinary statement. That means it actually has both compile-time and run-time effects. Comments Text from a \"#\" character until the end of the line is a comment, and is ignored. Exceptions include \"#\" inside a string or regular expression. Simple Statements The only kind of simple statement is an expression evaluated for its side effects. Every simple statement must be terminated with a semicolon, unless it is the final statement in a block, in which case the semicolon is optional. (A semicolon is still encouraged if the block takes up more than one line, because you may eventually add another line.) Note that there are some operators like \"eval {}\" and \"do {}\" that look like compound statements, but aren't (they're just TERMs in an expression), and thus need an explicit termination if used as the last item in a statement. Truth and Falsehood The number 0, the strings '0' and '', the empty list \"()\", and \"undef\" are all false in a boolean context. All other values are true. Negation of a true value by \"!\" or \"not\" returns a special false value. When evaluated as a string it is treated as '', but as a number, it is treated as 0. Statement Modifiers Any simple statement may optionally be followed by a SINGLE modifier, just before the terminating semicolon (or block ending). The possible modifiers are: if EXPR\nunless EXPR\nwhile EXPR\nuntil EXPR\nforeach LIST The \"EXPR\" following the modifier is referred to as the \"condition\". Its truth or falsehood determines how the modifier will behave. \"if\" executes the statement once if and only if the condition is true. \"unless\" is the opposite, it executes the statement unless the condition is true (i.e., if the condition is false). print \"Basset hounds got long ears\" if length $ear >= 10;\ngo_outside() and play() unless $is_raining; The \"foreach\" modifier is an iterator: it executes the statement once for each item in the LIST (with $_ aliased to each item in turn). print \"Hello $_!\\n\" foreach qw(world Dolly nurse); \"while\" repeats the statement while the condition is true. \"until\" does the opposite, it repeats the statement until the condition is true (or while the condition is false): # Both of these count from 0 to 10.\nprint $i++ while $i <= 10;\nprint $j++ until $j >  10; The \"while\" and \"until\" modifiers have the usual \" \"while\" loop\" semantics (conditional evaluated first), except when applied to a \"do\"-BLOCK (or to the deprecated \"do\"-SUBROUTINE statement), in which case the block executes once before the conditional is evaluated. This is so that you can write loops like: do {\n    $line = <STDIN>;\n    ...\n} until $line  eq \".\\n\"; See \"do\" in perlfunc. Note also that the loop control statements described later will NOT work in this construct, because modifiers don't take loop labels. Sorry. You can always put another block inside of it (for \"next\") or around it (for \"last\") to do that sort of thing. For \"next\", just double the braces: do {{\n    next if $x == $y;\n    # do something here\n}} until $x++ > $z; For \"last\", you have to be more elaborate: LOOP: {\n        do {\n            last if $x = $y**2;\n            # do something here\n        } while $x++ <= $z;\n} NOTE: The behaviour of a \"my\" statement modified with a statement modifier conditional or loop construct (e.g. \"my $x if ...\") is undefined. The value of the \"my\" variable may be \"undef\", any previously assigned value, or possibly anything else. Don't rely on it. Future versions of perl might do something different from the version of perl you try it out on. Here be dragons. Compound Statements In Perl, a sequence of statements that defines a scope is called a block. Sometimes a block is delimited by the file containing it (in the case of a required file, or the program as a whole), and sometimes a block is delimited by the extent of a string (in the case of an eval). But generally, a block is delimited by curly brackets, also known as braces. We will call this syntactic construct a BLOCK . The following compound statements may be used to control flow: if (EXPR) BLOCK\nif (EXPR) BLOCK else BLOCK\nif (EXPR) BLOCK elsif (EXPR) BLOCK ... else BLOCK\nLABEL while (EXPR) BLOCK\nLABEL while (EXPR) BLOCK continue BLOCK\nLABEL until (EXPR) BLOCK\nLABEL until (EXPR) BLOCK continue BLOCK\nLABEL for (EXPR; EXPR; EXPR) BLOCK\nLABEL foreach VAR (LIST) BLOCK\nLABEL foreach VAR (LIST) BLOCK continue BLOCK\nLABEL BLOCK continue BLOCK Note that, unlike C and Pascal, these are defined in terms of BLOCKs, not statements. This means that the curly brackets are required--no dangling statements allowed. If you want to write conditionals without curly brackets there are several other ways to do it. The following all do the same thing: if (!open(FOO)) { die \"Can't open $FOO: $!\"; }\ndie \"Can't open $FOO: $!\" unless open(FOO);\nopen(FOO) or die \"Can't open $FOO: $!\";     # FOO or bust!\nopen(FOO) ? 'hi mom' : die \"Can't open $FOO: $!\";\n                    # a bit exotic, that last one The \"if\" statement is straightforward. Because BLOCKs are always bounded by curly brackets, there is never any ambiguity about which \"if\" an \"else\" goes with. If you use \"unless\" in place of \"if\", the sense of the test is reversed. The \"while\" statement executes the block as long as the expression is true. The \"until\" statement executes the block as long as the expression is false. The LABEL is optional, and if present, consists of an identifier followed by a colon. The LABEL identifies the loop for the loop control statements \"next\", \"last\", and \"redo\". If the LABEL is omitted, the loop control statement refers to the innermost enclosing loop. This may include dynamically looking back your call-stack at run time to find the LABEL . Such desperate behavior triggers a warning if you use the \"use warnings\" pragma or the -w flag. If there is a \"continue\" BLOCK , it is always executed just before the conditional is about to be evaluated again. Thus it can be used to increment a loop variable, even when the loop has been continued via the \"next\" statement. Loop Control The \"next\" command starts the next iteration of the loop: LINE: while (<STDIN>) {\n    next LINE if \/^#\/;      # discard comments\n    ...\n} The \"last\" command immediately exits the loop in question. The \"continue\" block, if any, is not executed: LINE: while (<STDIN>) {\n    last LINE if \/^$\/;      # exit when done with header\n    ...\n} The \"redo\" command restarts the loop block without evaluating the conditional again. The \"continue\" block, if any, is not executed. This command is normally used by programs that want to lie to themselves about what was just input. For example, when processing a file like \/etc\/termcap. If your input lines might end in backslashes to indicate continuation, you want to skip ahead and get the next record. while (<>) {\n    chomp;\n    if (s\/\\\\$\/\/) {\n        $_ .= <>;\n        redo unless eof();\n    }\n    # now process $_\n} which is Perl short-hand for the more explicitly written version: LINE: while (defined($line = <ARGV>)) {\n    chomp($line);\n    if ($line =~ s\/\\\\$\/\/) {\n        $line .= <ARGV>;\n        redo LINE unless eof(); # not eof(ARGV)!\n    }\n    # now process $line\n} Note that if there were a \"continue\" block on the above code, it would get executed only on lines discarded by the regex (since redo skips the continue block). A continue block is often used to reset line counters or \"?pat?\" one-time matches: # inspired by :1,$g\/fred\/s\/\/WILMA\/\nwhile (<>) {\n    ?(fred)?    && s\/\/WILMA $1 WILMA\/;\n    ?(barney)?  && s\/\/BETTY $1 BETTY\/;\n    ?(homer)?   && s\/\/MARGE $1 MARGE\/;\n} continue {\n    print \"$ARGV $.: $_\";\n    close ARGV  if eof();           # reset $.\n    reset       if eof();           # reset ?pat?\n} If the word \"while\" is replaced by the word \"until\", the sense of the test is reversed, but the conditional is still tested before the first iteration. The loop control statements don't work in an \"if\" or \"unless\", since they aren't loops. You can double the braces to make them such, though. if (\/pattern\/) {{\n    last if \/fred\/;\n    next if \/barney\/; # same effect as \"last\", but doesn't document as well\n    # do something here\n}} This is caused by the fact that a block by itself acts as a loop that executes once, see \"Basic BLOCKs\". The form \"while\/if BLOCK BLOCK\", available in Perl 4, is no longer available. Replace any occurrence of \"if BLOCK\" by \"if (do BLOCK)\". For Loops Perl's C-style \"for\" loop works like the corresponding \"while\" loop; that means that this: for ($i = 1; $i < 10; $i++) {\n    ...\n} is the same as this: $i = 1;\nwhile ($i < 10) {\n    ...\n} continue {\n    $i++;\n} There is one minor difference: if variables are declared with \"my\" in the initialization section of the \"for\", the lexical scope of those variables is exactly the \"for\" loop (the body of the loop and the control sections). Besides the normal array index looping, \"for\" can lend itself to many other interesting applications. Here's one that avoids the problem you get into if you explicitly test for end-of-file on an interactive file descriptor causing your program to appear to hang. $on_a_tty = -t STDIN && -t STDOUT;\nsub prompt { print \"yes? \" if $on_a_tty }\nfor ( prompt(); <STDIN>; prompt() ) {\n    # do something\n} Using \"readline\" (or the operator form, \"<EXPR>\") as the conditional of a \"for\" loop is shorthand for the following. This behaviour is the same as a \"while\" loop conditional. for ( prompt(); defined( $_ = <STDIN> ); prompt() ) {\n    # do something\n} Foreach Loops The \"foreach\" loop iterates over a normal list value and sets the variable VAR to be each element of the list in turn. If the variable is preceded with the keyword \"my\", then it is lexically scoped, and is therefore visible only within the loop. Otherwise, the variable is implicitly local to the loop and regains its former value upon exiting the loop. If the variable was previously declared with \"my\", it uses that variable instead of the global one, but it's still localized to the loop. This implicit localisation occurs only in a \"foreach\" loop. The \"foreach\" keyword is actually a synonym for the \"for\" keyword, so you can use \"foreach\" for readability or \"for\" for brevity. (Or because the Bourne shell is more familiar to you than csh, so writing \"for\" comes more naturally.) If VAR is omitted, $_ is set to each value. If any element of LIST is an lvalue, you can modify it by modifying VAR inside the loop. Conversely, if any element of LIST is NOT an lvalue, any attempt to modify that element will fail. In other words, the \"foreach\" loop index variable is an implicit alias for each item in the list that you're looping over. If any part of LIST is an array, \"foreach\" will get very confused if you add or remove elements within the loop body, for example with \"splice\". So don't do that. \"foreach\" probably won't do what you expect if VAR is a tied or other special variable. Don't do that either. Examples: for (@ary) { s\/foo\/bar\/ }\n\nfor my $elem (@elements) {\n    $elem *= 2;\n}\n\nfor $count (10,9,8,7,6,5,4,3,2,1,'BOOM') {\n    print $count, \"\\n\"; sleep(1);\n}\n\nfor (1..15) { print \"Merry Christmas\\n\"; }\n\nforeach $item (split(\/:[\\\\\\n:]*\/, $ENV{TERMCAP})) {\n    print \"Item: $item\\n\";\n} Here's how a C programmer might code up a particular algorithm in Perl: for (my $i = 0; $i < @ary1; $i++) {\n    for (my $j = 0; $j < @ary2; $j++) {\n        if ($ary1[$i] > $ary2[$j]) {\n            last; # can't go to outer :-(\n        }\n        $ary1[$i] += $ary2[$j];\n    }\n    # this is where that last takes me\n} Whereas here's how a Perl programmer more comfortable with the idiom might do it: OUTER: for my $wid (@ary1) {\nINNER:   for my $jet (@ary2) {\n            next OUTER if $wid > $jet;\n            $wid += $jet;\n         }\n      } See how much easier this is? It's cleaner, safer, and faster. It's cleaner because it's less noisy. It's safer because if code gets added between the inner and outer loops later on, the new code won't be accidentally executed. The \"next\" explicitly iterates the other loop rather than merely terminating the inner one. And it's faster because Perl executes a \"foreach\" statement more rapidly than it would the equivalent \"for\" loop. Basic BLOCKs A BLOCK by itself (labeled or not) is semantically equivalent to a loop that executes once. Thus you can use any of the loop control statements in it to leave or restart the block. (Note that this is NOT true in \"eval{}\", \"sub{}\", or contrary to popular belief \"do{}\" blocks, which do NOT count as loops.) The \"continue\" block is optional. The BLOCK construct can be used to emulate case structures. SWITCH: {\n    if (\/^abc\/) { $abc = 1; last SWITCH; }\n    if (\/^def\/) { $def = 1; last SWITCH; }\n    if (\/^xyz\/) { $xyz = 1; last SWITCH; }\n    $nothing = 1;\n} Such constructs are quite frequently used, because older versions of Perl had no official \"switch\" statement. Switch statements Starting from Perl 5.10, you can say use feature \"switch\"; which enables a switch feature that is closely based on the Perl 6 proposal. The keywords \"given\" and \"when\" are analogous to \"switch\" and \"case\" in other languages, so the code above could be written as given($_) {\n    when (\/^abc\/) { $abc = 1; }\n    when (\/^def\/) { $def = 1; }\n    when (\/^xyz\/) { $xyz = 1; }\n    default { $nothing = 1; }\n} This construct is very flexible and powerful. For example: use feature \":5.10\";\ngiven($foo) {\n    when (undef) {\n        say '$foo is undefined';\n    }\n    when (\"foo\") {\n        say '$foo is the string \"foo\"';\n    }\n    when ([1,3,5,7,9]) {\n        say '$foo is an odd digit';\n        continue; # Fall through\n    }\n    when ($_ < 100) {\n        say '$foo is numerically less than 100';\n    }\n    when (\\&complicated_check) {\n        say 'a complicated check for $foo is true';\n    }\n    default {\n        die q(I don't know what to do with $foo);\n    }\n} \"given(EXPR)\" will assign the value of EXPR to $_ within the lexical scope of the block, so it's similar to do { my $_ = EXPR; ... } except that the block is automatically broken out of by a successful \"when\" or an explicit \"break\". Most of the power comes from implicit smart matching: when($foo) is exactly equivalent to when($_ ~~ $foo) Most of the time, \"when(EXPR)\" is treated as an implicit smart match of $_, i.e. \"$_ ~~ EXPR\". (See \"Smart matching in detail\" for more information on smart matching.) But when EXPR is one of the below exceptional cases, it is used directly as a boolean: \u2022 a subroutine or method call \u2022 a regular expression match, i.e. \"\/REGEX\/\" or \"$foo =~ \/REGEX\/\", or a negated regular expression match (\"!\/REGEX\/\" or \"$foo !~ \/REGEX\/\"). \u2022 a comparison such as \"$_ < 10\" or \"$x eq \"abc\"\" (or of course \"$_ ~~ $c\") \u2022 \"defined(...)\", \"exists(...)\", or \"eof(...)\" \u2022 a negated expression \"!(...)\" or \"not (...)\", or a logical exclusive-or \"(...) xor (...)\". \u2022 a filetest operator, with the exception of \"-s\", \"-M\", \"-A\", and \"-C\", that return numerical values, not boolean ones. \u2022 the \"..\" and \"...\" flip-flop operators. In those cases the value of EXPR is used directly as a boolean. Furthermore: \u2022 If EXPR is \"... && ...\" or \"... and ...\", the test is applied recursively to both arguments. If both arguments pass the test, then the argument is treated as boolean. \u2022 If EXPR is \"... || ...\", \"... \/\/ ...\" or \"... or ...\", the test is applied recursively to the first argument. These rules look complicated, but usually they will do what you want. For example you could write: when (\/^\\d+$\/ && $_ < 75) { ... } Another useful shortcut is that, if you use a literal array or hash as the argument to \"given\", it is turned into a reference. So \"given(@foo)\" is the same as \"given(\\@foo)\", for example. \"default\" behaves exactly like \"when(1 == 1)\", which is to say that it always matches. Breaking out You can use the \"break\" keyword to break out of the enclosing \"given\" block. Every \"when\" block is implicitly ended with a \"break\". Fall-through You can use the \"continue\" keyword to fall through from one case to the next: given($foo) {\n    when (\/x\/) { say '$foo contains an x'; continue }\n    when (\/y\/) { say '$foo contains a y' }\n    default    { say '$foo does not contain a y' }\n} Switching in a loop Instead of using \"given()\", you can use a \"foreach()\" loop. For example, here's one way to count how many times a particular string occurs in an array: my $count = 0;\nfor (@array) {\n    when (\"foo\") { ++$count }\n}\nprint \"\\@array contains $count copies of 'foo'\\n\"; On exit from the \"when\" block, there is an implicit \"next\". You can override that with an explicit \"last\" if you're only interested in the first match. This doesn't work if you explicitly specify a loop variable, as in \"for $item (@array)\". You have to use the default variable $_. (You can use \"for my $_ (@array)\".) Smart matching in detail The behaviour of a smart match depends on what type of thing its arguments are. The behaviour is determined by the following table: the first row that applies determines the match behaviour (which is thus mostly determined by the type of the right operand). Note that the smart match implicitly dereferences any non-blessed hash or array ref, so the \"Hash\" and \"Array\" entries apply in those cases. (For blessed references, the \"Object\" entries apply.) Note that the \"Matching Code\" column is not always an exact rendition. For example, the smart match operator short-circuits whenever possible, but \"grep\" does not.    $a      $b        Type of Match Implied    Matching Code\n   ======  =====     =====================    =============\n   Any     undef     undefined                !defined $a\n\n   Any     Object    invokes ~~ overloading on $object, or dies\n\n   Hash    CodeRef   sub truth for each key[1] !grep { !$b->($_) } keys %$a\n   Array   CodeRef   sub truth for each elt[1] !grep { !$b->($_) } @$a\n   Any     CodeRef   scalar sub truth          $b->($a)\n\n   Hash    Hash      hash keys identical (every key is found in both hashes)\n   Array   Hash      hash slice existence     grep { exists $b->{$_} } @$a\n   Regex   Hash      hash key grep            grep \/$a\/, keys %$b\n   undef   Hash      always false (undef can't be a key)\n   Any     Hash      hash entry existence     exists $b->{$a}\n\n   Hash    Array     hash slice existence     grep { exists $a->{$_} } @$b\n   Array   Array     arrays are comparable[2]\n   Regex   Array     array grep               grep \/$a\/, @$b\n   undef   Array     array contains undef     grep !defined, @$b\n   Any     Array     match against an array element[3]\n                                              grep $a ~~ $_, @$b\n\n   Hash    Regex     hash key grep            grep \/$b\/, keys %$a\n   Array   Regex     array grep               grep \/$b\/, @$a\n   Any     Regex     pattern match            $a =~ \/$b\/\n\n   Object  Any       invokes ~~ overloading on $object, or falls back:\n   Any     Num       numeric equality         $a == $b\n   Num     numish[4] numeric equality         $a == $b\n   undef   Any       undefined                !defined($b)\n   Any     Any       string equality          $a eq $b\n\n1 - empty hashes or arrays will match.\n2 - that is, each element smart-matches the element of same index in the\n    other array. [3]\n3 - If a circular reference is found, we fall back to referential equality.\n4 - either a real number, or a string that looks like a number Custom matching via overloading You can change the way that an object is matched by overloading the \"~~\" operator. This may alter the usual smart match semantics. It should be noted that \"~~\" will refuse to work on objects that don't overload it (in order to avoid relying on the object's underlying structure). Note also that smart match's matching rules take precedence over overloading, so if $obj has smart match overloading, then $obj ~~ X will not automatically invoke the overload method with X as an argument; instead the table above is consulted as normal, and based in the type of X, overloading may or may not be invoked. See overload. Differences from Perl 6 The Perl 5 smart match and \"given\"\/\"when\" constructs are not absolutely identical to their Perl 6 analogues. The most visible difference is that, in Perl 5, parentheses are required around the argument to \"given()\" and \"when()\". Parentheses in Perl 6 are always optional in a control construct such as \"if()\", \"while()\", or \"when()\"; they can't be made optional in Perl 5 without a great deal of potential confusion, because Perl 5 would parse the expression given $foo {\n  ...\n} as though the argument to \"given\" were an element of the hash %foo, interpreting the braces as hash-element syntax. The table of smart matches is not identical to that proposed by the Perl 6 specification, mainly due to the differences between Perl 6's and Perl 5's data models. In Perl 6, \"when()\" will always do an implicit smart match with its argument, whilst it is convenient in Perl 5 to suppress this implicit smart match in certain situations, as documented above. (The difference is largely because Perl 5 does not, even internally, have a boolean type.) Goto Although not for the faint of heart, Perl does support a \"goto\" statement. There are three forms: \"goto\"-LABEL, \"goto\"-EXPR, and \"goto\"-&NAME. A loop's LABEL is not actually a valid target for a \"goto\"; it's just the name of the loop. The \"goto\"-LABEL form finds the statement labeled with LABEL and resumes execution there. It may not be used to go into any construct that requires initialization, such as a subroutine or a \"foreach\" loop. It also can't be used to go into a construct that is optimized away. It can be used to go almost anywhere else within the dynamic scope, including out of subroutines, but it's usually better to use some other construct such as \"last\" or \"die\". The author of Perl has never felt the need to use this form of \"goto\" (in Perl, that is--C is another matter). The \"goto\"-EXPR form expects a label name, whose scope will be resolved dynamically. This allows for computed \"goto\"s per FORTRAN , but isn't necessarily recommended if you're optimizing for maintainability: goto((\"FOO\", \"BAR\", \"GLARCH\")[$i]); The \"goto\"-&NAME form is highly magical, and substitutes a call to the named subroutine for the currently running subroutine. This is used by \"AUTOLOAD()\" subroutines that wish to load another subroutine and then pretend that the other subroutine had been called in the first place (except that any modifications to @_ in the current subroutine are propagated to the other subroutine.) After the \"goto\", not even \"caller()\" will be able to tell that this routine was called first. In almost all cases like this, it's usually a far, far better idea to use the structured control flow mechanisms of \"next\", \"last\", or \"redo\" instead of resorting to a \"goto\". For certain applications, the catch and throw pair of \"eval{}\" and die() for exception processing can also be a prudent approach. PODs: Embedded Documentation Perl has a mechanism for intermixing documentation with source code. While it's expecting the beginning of a new statement, if the compiler encounters a line that begins with an equal sign and a word, like this =head1 Here There Be Pods! Then that text and all remaining text up through and including a line beginning with \"=cut\" will be ignored. The format of the intervening text is described in perlpod. This allows you to intermix your source code and your documentation text freely, as in =item snazzle($)\n\nThe snazzle() function will behave in the most spectacular\nform that you can possibly imagine, not even excepting\ncybernetic pyrotechnics.\n\n=cut back to the compiler, nuff of this pod stuff!\n\nsub snazzle($) {\n    my $thingie = shift;\n    .........\n} Note that pod translators should look at only paragraphs beginning with a pod directive (it makes parsing easier), whereas the compiler actually knows to look for pod escapes even in the middle of a paragraph. This means that the following secret stuff will be ignored by both the compiler and the translators. $a=3;\n=secret stuff\n warn \"Neither POD nor CODE!?\"\n=cut back\nprint \"got $a\\n\"; You probably shouldn't rely upon the \"warn()\" being podded out forever. Not all pod translators are well-behaved in this regard, and perhaps the compiler will become pickier. One may also use pod directives to quickly comment out a section of code. Plain Old Comments (Not!) Perl can process line directives, much like the C preprocessor. Using this, one can control Perl's idea of filenames and line numbers in error or warning messages (especially for strings that are processed with \"eval()\"). The syntax for this mechanism is the same as for most C preprocessors: it matches the regular expression # example: '# line 42 \"new_filename.plx\"'\n\/^\\#   \\s*\n  line \\s+ (\\d+)   \\s*\n  (?:\\s(\"?)([^\"]+)\\2)? \\s*\n $\/x with $1 being the line number for the next line, and $3 being the optional filename (specified with or without quotes). There is a fairly obvious gotcha included with the line directive: Debuggers and profilers will only show the last source line to appear at a particular line number in a given file. Care should be taken not to cause line number collisions in code you'd like to debug later. Here are some examples that you should be able to type into your command shell: % perl\n# line 200 \"bzzzt\"\n# the `#' on the previous line must be the first char on line\ndie 'foo';\n__END__\nfoo at bzzzt line 201.\n\n% perl\n# line 200 \"bzzzt\"\neval qq[\\n#line 2001 \"\"\\ndie 'foo']; print $@;\n__END__\nfoo at - line 2001.\n\n% perl\neval qq[\\n#line 200 \"foo bar\"\\ndie 'foo']; print $@;\n__END__\nfoo at foo bar line 200.\n\n% perl\n# line 345 \"goop\"\neval \"\\n#line \" . __LINE__ . ' \"' . __FILE__ .\"\\\"\\ndie 'foo'\";\nprint $@;\n__END__\nfoo at goop line 345. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"perlsyn","Link":"https:\/\/linux.die.net\/man\/1\/perlsyn"}},{"Process":{"Description":"","Process Name":"perltetris.pl","Link":"https:\/\/linux.die.net\/man\/1\/perltetris.pl"}},{"Process":{"Description":"This program is designed to help you generate and send bug reports (and thank-you notes) about perl5 and the modules which ship with it. In most cases, you can just run it interactively from a command line without any special arguments and follow the prompts. If you have found a bug with a non-standard port (one that was not part of the standard distribution), a binary distribution, or a non-core module (such as Tk, DBI , etc), then please see the documentation that came with that distribution to determine the correct place to report bugs. If you are unable to send your report using perlbug (most likely because your system doesn't have a way to send mail that perlbug recognizes), you may be able to use this tool to compose your report and save it to a file which you can then send to perlbug@perl.org using your regular mail client. In extreme cases, perlbug may not work well enough on your system to guide you through composing a bug report. In those cases, you may be able to use perlbug -d to get system configuration information to include in a manually composed bug report to perlbug@perl.org. When reporting a bug, please run through this checklist: What version of Perl you are running? Type \"perl -v\" at the command line to find out. Are you running the latest released version of perl? Look at http:\/\/www.perl.org\/ to find out. If you are not using the latest released version, please try to replicate your bug on the latest stable release. Note that reports about bugs in old versions of Perl, especially those which indicate you haven't also tested the current stable release of Perl, are likely to receive less attention from the volunteers who build and maintain Perl than reports about bugs in the current release. This tool isn't apropriate for reporting bugs in any version prior to Perl 5.0. Are you sure what you have is a bug? A significant number of the bug reports we get turn out to be documented features in Perl. Make sure the issue you've run into isn't intentional by glancing through the documentation that comes with the Perl distribution. Given the sheer volume of Perl documentation, this isn't a trivial undertaking, but if you can point to documentation that suggests the behaviour you're seeing is wrong, your issue is likely to receive more attention. You may want to start with perldoc perltrap for pointers to common traps that new (and experienced) Perl programmers run into. If you're unsure of the meaning of an error message you've run across, perldoc perldiag for an explanation. If the message isn't in perldiag, it probably isn't generated by Perl. You may have luck consulting your operating system documentation instead. If you are on a non-UNIX platform perldoc perlport, as some features may be unimplemented or work differently. You may be able to figure out what's going wrong using the Perl debugger. For information about how to use the debugger perldoc perldebug. Do you have a proper test case? The easier it is to reproduce your bug, the more likely it will be fixed -- if nobody can duplicate your problem, it probably won't be addressed. A good test case has most of these attributes: short, simple code; few dependencies on external commands, modules, or libraries; no platform-dependent code (unless it's a platform-specific bug); clear, simple documentation. A good test case is almost always a good candidate to be included in Perl's test suite. If you have the time, consider writing your test case so that it can be easily included into the standard test suite. Have you included all relevant information? Be sure to include the exact error messages, if any. \"Perl gave an error\" is not an exact error message. If you get a core dump (or equivalent), you may use a debugger (dbx, gdb, etc) to produce a stack trace to include in the bug report. NOTE: unless your Perl has been compiled with debug info (often -g), the stack trace is likely to be somewhat hard to use because it will most probably contain only the function names and not their arguments. If possible, recompile your Perl with debug info and reproduce the crash and the stack trace. Can you describe the bug in plain English? The easier it is to understand a reproducible bug, the more likely it will be fixed. Any insight you can provide into the problem will help a great deal. In other words, try to analyze the problem (to the extent you can) and report your discoveries. Can you fix the bug yourself? A bug report which includes a patch to fix it will almost definitely be fixed. When sending a patch, please use the \"diff\" program with the \"-u\" option to generate \"unified\" diff files. Bug reports with patches are likely to receive significantly more attention and interest than those without patches. Your patch may be returned with requests for changes, or requests for more detailed explanations about your fix. Here are a few hints for creating high-quality patches: Make sure the patch is not reversed (the first argument to diff is typically the original file, the second argument your changed file). Make sure you test your patch by applying it with the \"patch\" program before you send it on its way. Try to follow the same style as the code you are trying to patch. Make sure your patch really does work (\"make test\", if the thing you're patching is covered by Perl's test suite). Can you use \"perlbug\" to submit the report? perlbug will, amongst other things, ensure your report includes crucial information about your version of perl. If \"perlbug\" is unable to mail your report after you have typed it in, you may have to compose the message yourself, add the output produced by \"perlbug -d\" and email it to perlbug@perl.org. If, for some reason, you cannot run \"perlbug\" at all on your system, be sure to include the entire output produced by running \"perl -V\" (note the uppercase V). Whether you use \"perlbug\" or send the email manually, please make your Subject line informative. \"a bug\" is not informative. Neither is \"perl crashes\" nor is \" HELP !!!\". These don't help. A compact description of what's wrong is fine. Can you use \"perlbug\" to submit a thank-you note? Yes, you can do this by either using the \"-T\" option, or by invoking the program as \"perlthanks\". Thank-you notes are good. It makes people smile. Having done your bit, please be prepared to wait, to be told the bug is in your code, or possibly to get no reply at all. The volunteers who maintain Perl are busy folks, so if your problem is an obvious bug in your own code, is difficult to understand or is a duplicate of an existing report, you may not receive a personal reply. If it is important to you that your bug be fixed, do monitor the perl5-porters@perl.org mailing list and the commit logs to development versions of Perl, and encourage the maintainers with kind words or offers of frosty beverages. (Please do be kind to the maintainers. Harassing or flaming them is likely to have the opposite effect of the one you want.) Feel free to update the ticket about your bug on http:\/\/rt.perl.org if a new version of Perl is released and your bug is still present.","Process Name":"perlthanks","Link":"https:\/\/linux.die.net\/man\/1\/perlthanks"}},{"Process":{"Description":"This tutorial describes the use of Perl interpreter threads (sometimes referred to as ithreads) that was first introduced in Perl 5.6.0. In this model, each thread runs in its own Perl interpreter, and any data sharing between threads must be explicit. The user-level interface for ithreads uses the threads class. NOTE : There was another older Perl threading flavor called the 5.005 model that used the Threads class. This old model was known to have problems, is deprecated, and was removed for release 5.10. You are strongly encouraged to migrate any existing 5.005 threads code to the new model as soon as possible. You can see which (or neither) threading flavour you have by running \"perl -V\" and looking at the \"Platform\" section. If you have \"useithreads=define\" you have ithreads, if you have \"use5005threads=define\" you have 5.005 threads. If you have neither, you don't have any thread support built in. If you have both, you are in trouble. The threads and threads::shared modules are included in the core Perl distribution. Additionally, they are maintained as a separate modules on CPAN , so you can check there for any updates.","Process Name":"perlthrtut","Link":"https:\/\/linux.die.net\/man\/1\/perlthrtut"}},{"Process":{"Description":"Perltidy reads a perl script and writes an indented, reformatted script. Many users will find enough information in \" EXAMPLES \" to get started. New users may benefit from the short tutorial which can be found at http:\/\/perltidy.sourceforge.net\/tutorial.html A convenient aid to systematically defining a set of style parameters can be found at http:\/\/perltidy.sourceforge.net\/stylekey.html Perltidy can produce output on either of two modes, depending on the existence of an -html flag. Without this flag, the output is passed through a formatter. The default formatting tries to follow the recommendations in perlstyle(1), but it can be controlled in detail with numerous input parameters, which are described in \" FORMATTING OPTIONS \". When the -html flag is given, the output is passed through an HTML formatter which is described in \" HTML OPTIONS \".","Process Name":"perltidy","Link":"https:\/\/linux.die.net\/man\/1\/perltidy"}},{"Process":{"Description":"Prior to release 5.0 of Perl, a programmer could use dbmopen() to connect an on-disk database in the standard Unix dbm(3x) format magically to a %HASH in their program. However, their Perl was either built with one particular dbm library or another, but not both, and you couldn't extend this mechanism to other packages or types of variables. Now you can. The tie() function binds a variable to a class (package) that will provide the implementation for access methods for that variable. Once this magic has been performed, accessing a tied variable automatically triggers method calls in the proper class. The complexity of the class is hidden behind magic methods calls. The method names are in ALL CAPS , which is a convention that Perl uses to indicate that they're called implicitly rather than explicitly--just like the BEGIN () and END () functions. In the tie() call, \"VARIABLE\" is the name of the variable to be enchanted. \"CLASSNAME\" is the name of a class implementing objects of the correct type. Any additional arguments in the \"LIST\" are passed to the appropriate constructor method for that class--meaning TIESCALAR (), TIEARRAY (), TIEHASH (), or TIEHANDLE (). (Typically these are arguments such as might be passed to the dbminit() function of C.) The object returned by the \"new\" method is also returned by the tie() function, which would be useful if you wanted to access other methods in \"CLASSNAME\". (You don't actually have to return a reference to a right \"type\" (e.g., HASH or \"CLASSNAME\") so long as it's a properly blessed object.) You can also retrieve a reference to the underlying object using the tied() function. Unlike dbmopen(), the tie() function will not \"use\" or \"require\" a module for you--you need to do that explicitly yourself. Tying Scalars A class implementing a tied scalar should define the following methods: TIESCALAR , FETCH , STORE , and possibly UNTIE and\/or DESTROY . Let's look at each in turn, using as an example a tie class for scalars that allows the user to do something like: tie $his_speed, 'Nice', getppid();\ntie $my_speed,  'Nice', $$; And now whenever either of those variables is accessed, its current system priority is retrieved and returned. If those variables are set, then the process's priority is changed! We'll use Jarkko Hietaniemi <jhi@iki.fi>'s BSD::Resource class (not included) to access the PRIO_PROCESS , PRIO_MIN , and PRIO_MAX constants from your system, as well as the getpriority() and setpriority() system calls. Here's the preamble of the class. package Nice;\nuse Carp;\nuse BSD::Resource;\nuse strict;\n$Nice::DEBUG = 0 unless defined $Nice::DEBUG; TIESCALAR classname, LIST This is the constructor for the class. That means it is expected to return a blessed reference to a new scalar (probably anonymous) that it's creating. For example: sub TIESCALAR {\n    my $class = shift;\n    my $pid = shift || $$; # 0 means me\n\n    if ($pid !~ \/^\\d+$\/) {\n        carp \"Nice::Tie::Scalar got non-numeric pid $pid\" if $^W;\n        return undef;\n    }\n\n    unless (kill 0, $pid) { # EPERM or ERSCH, no doubt\n        carp \"Nice::Tie::Scalar got bad pid $pid: $!\" if $^W;\n        return undef;\n    }\n\n    return bless \\$pid, $class;\n} This tie class has chosen to return an error rather than raising an exception if its constructor should fail. While this is how dbmopen() works, other classes may well not wish to be so forgiving. It checks the global variable $^W to see whether to emit a bit of noise anyway. FETCH this This method will be triggered every time the tied variable is accessed (read). It takes no arguments beyond its self reference, which is the object representing the scalar we're dealing with. Because in this case we're using just a SCALAR ref for the tied scalar object, a simple $$self allows the method to get at the real value stored there. In our example below, that real value is the process ID to which we've tied our variable. sub FETCH {\n    my $self = shift;\n    confess \"wrong type\" unless ref $self;\n    croak \"usage error\" if @_;\n    my $nicety;\n    local($!) = 0;\n    $nicety = getpriority(PRIO_PROCESS, $$self);\n    if ($!) { croak \"getpriority failed: $!\" }\n    return $nicety;\n} This time we've decided to blow up (raise an exception) if the renice fails--there's no place for us to return an error otherwise, and it's probably the right thing to do. STORE this, value This method will be triggered every time the tied variable is set (assigned). Beyond its self reference, it also expects one (and only one) argument--the new value the user is trying to assign. Don't worry about returning a value from STORE -- the semantic of assignment returning the assigned value is implemented with FETCH . sub STORE {\n    my $self = shift;\n    confess \"wrong type\" unless ref $self;\n    my $new_nicety = shift;\n    croak \"usage error\" if @_;\n\n    if ($new_nicety < PRIO_MIN) {\n        carp sprintf\n          \"WARNING: priority %d less than minimum system priority %d\",\n              $new_nicety, PRIO_MIN if $^W;\n        $new_nicety = PRIO_MIN;\n    }\n\n    if ($new_nicety > PRIO_MAX) {\n        carp sprintf\n          \"WARNING: priority %d greater than maximum system priority %d\",\n              $new_nicety, PRIO_MAX if $^W;\n        $new_nicety = PRIO_MAX;\n    }\n\n    unless (defined setpriority(PRIO_PROCESS, $$self, $new_nicety)) {\n        confess \"setpriority failed: $!\";\n    }\n} UNTIE this This method will be triggered when the \"untie\" occurs. This can be useful if the class needs to know when no further calls will be made. (Except DESTROY of course.) See \"The \"untie\" Gotcha\" below for more details. DESTROY this This method will be triggered when the tied variable needs to be destructed. As with other object classes, such a method is seldom necessary, because Perl deallocates its moribund object's memory for you automatically--this isn't C ++ , you know. We'll use a DESTROY method here for debugging purposes only. sub DESTROY {\n    my $self = shift;\n    confess \"wrong type\" unless ref $self;\n    carp \"[ Nice::DESTROY pid $$self ]\" if $Nice::DEBUG;\n} That's about all there is to it. Actually, it's more than all there is to it, because we've done a few nice things here for the sake of completeness, robustness, and general aesthetics. Simpler TIESCALAR classes are certainly possible. Tying Arrays A class implementing a tied ordinary array should define the following methods: TIEARRAY , FETCH , STORE , FETCHSIZE , STORESIZE and perhaps UNTIE and\/or DESTROY . FETCHSIZE and STORESIZE are used to provide $#array and equivalent \"scalar(@array)\" access. The methods POP , PUSH , SHIFT , UNSHIFT , SPLICE , DELETE , and EXISTS are required if the perl operator with the corresponding (but lowercase) name is to operate on the tied array. The Tie::Array class can be used as a base class to implement the first five of these in terms of the basic methods above. The default implementations of DELETE and EXISTS in Tie::Array simply \"croak\". In addition EXTEND will be called when perl would have pre-extended allocation in a real array. For this discussion, we'll implement an array whose elements are a fixed size at creation. If you try to create an element larger than the fixed size, you'll take an exception. For example: use FixedElem_Array;\ntie @array, 'FixedElem_Array', 3;\n$array[0] = 'cat';  # ok.\n$array[1] = 'dogs'; # exception, length('dogs') > 3. The preamble code for the class is as follows: package FixedElem_Array;\nuse Carp;\nuse strict; TIEARRAY classname, LIST This is the constructor for the class. That means it is expected to return a blessed reference through which the new array (probably an anonymous ARRAY ref) will be accessed. In our example, just to show you that you don't really have to return an ARRAY reference, we'll choose a HASH reference to represent our object. A HASH works out well as a generic record type: the \"{ELEMSIZE}\" field will store the maximum element size allowed, and the \"{ARRAY}\" field will hold the true ARRAY ref. If someone outside the class tries to dereference the object returned (doubtless thinking it an ARRAY ref), they'll blow up. This just goes to show you that you should respect an object's privacy. sub TIEARRAY {\n  my $class    = shift;\n  my $elemsize = shift;\n  if ( @_ || $elemsize =~ \/\\D\/ ) {\n    croak \"usage: tie ARRAY, '\" . __PACKAGE__ . \"', elem_size\";\n  }\n  return bless {\n    ELEMSIZE => $elemsize,\n    ARRAY    => [],\n  }, $class;\n} FETCH this, index This method will be triggered every time an individual element the tied array is accessed (read). It takes one argument beyond its self reference: the index whose value we're trying to fetch. sub FETCH {\n  my $self  = shift;\n  my $index = shift;\n  return $self->{ARRAY}->[$index];\n} If a negative array index is used to read from an array, the index will be translated to a positive one internally by calling FETCHSIZE before being passed to FETCH . You may disable this feature by assigning a true value to the variable $NEGATIVE_INDICES in the tied array class. As you may have noticed, the name of the FETCH method (et al.) is the same for all accesses, even though the constructors differ in names ( TIESCALAR vs TIEARRAY ). While in theory you could have the same class servicing several tied types, in practice this becomes cumbersome, and it's easiest to keep them at simply one tie type per class. STORE this, index, value This method will be triggered every time an element in the tied array is set (written). It takes two arguments beyond its self reference: the index at which we're trying to store something and the value we're trying to put there. In our example, \"undef\" is really \"$self->{ELEMSIZE}\" number of spaces so we have a little more work to do here: sub STORE {\n  my $self = shift;\n  my( $index, $value ) = @_;\n  if ( length $value > $self->{ELEMSIZE} ) {\n    croak \"length of $value is greater than $self->{ELEMSIZE}\";\n  }\n  # fill in the blanks\n  $self->EXTEND( $index ) if $index > $self->FETCHSIZE();\n  # right justify to keep element size for smaller elements\n  $self->{ARRAY}->[$index] = sprintf \"%$self->{ELEMSIZE}s\", $value;\n} Negative indexes are treated the same as with FETCH . FETCHSIZE this Returns the total number of items in the tied array associated with object this. (Equivalent to \"scalar(@array)\"). For example: sub FETCHSIZE {\n  my $self = shift;\n  return scalar @{$self->{ARRAY}};\n} STORESIZE this, count Sets the total number of items in the tied array associated with object this to be count. If this makes the array larger then class's mapping of \"undef\" should be returned for new positions. If the array becomes smaller then entries beyond count should be deleted. In our example, 'undef' is really an element containing \"$self->{ELEMSIZE}\" number of spaces. Observe: sub STORESIZE {\n  my $self  = shift;\n  my $count = shift;\n  if ( $count > $self->FETCHSIZE() ) {\n    foreach ( $count - $self->FETCHSIZE() .. $count ) {\n      $self->STORE( $_, '' );\n    }\n  } elsif ( $count < $self->FETCHSIZE() ) {\n    foreach ( 0 .. $self->FETCHSIZE() - $count - 2 ) {\n      $self->POP();\n    }\n  }\n} EXTEND this, count Informative call that array is likely to grow to have count entries. Can be used to optimize allocation. This method need do nothing. In our example, we want to make sure there are no blank (\"undef\") entries, so \"EXTEND\" will make use of \"STORESIZE\" to fill elements as needed: sub EXTEND {\n  my $self  = shift;\n  my $count = shift;\n  $self->STORESIZE( $count );\n} EXISTS this, key Verify that the element at index key exists in the tied array this. In our example, we will determine that if an element consists of \"$self->{ELEMSIZE}\" spaces only, it does not exist: sub EXISTS {\n  my $self  = shift;\n  my $index = shift;\n  return 0 if ! defined $self->{ARRAY}->[$index] ||\n              $self->{ARRAY}->[$index] eq ' ' x $self->{ELEMSIZE};\n  return 1;\n} DELETE this, key Delete the element at index key from the tied array this. In our example, a deleted item is \"$self->{ELEMSIZE}\" spaces: sub DELETE {\n  my $self  = shift;\n  my $index = shift;\n  return $self->STORE( $index, '' );\n} CLEAR this Clear (remove, delete, ...) all values from the tied array associated with object this. For example: sub CLEAR {\n  my $self = shift;\n  return $self->{ARRAY} = [];\n} PUSH this, LIST Append elements of LIST to the array. For example: sub PUSH {\n  my $self = shift;\n  my @list = @_;\n  my $last = $self->FETCHSIZE();\n  $self->STORE( $last + $_, $list[$_] ) foreach 0 .. $#list;\n  return $self->FETCHSIZE();\n} POP this Remove last element of the array and return it. For example: sub POP {\n  my $self = shift;\n  return pop @{$self->{ARRAY}};\n} SHIFT this Remove the first element of the array (shifting other elements down) and return it. For example: sub SHIFT {\n  my $self = shift;\n  return shift @{$self->{ARRAY}};\n} UNSHIFT this, LIST Insert LIST elements at the beginning of the array, moving existing elements up to make room. For example: sub UNSHIFT {\n  my $self = shift;\n  my @list = @_;\n  my $size = scalar( @list );\n  # make room for our list\n  @{$self->{ARRAY}}[ $size .. $#{$self->{ARRAY}} + $size ]\n   = @{$self->{ARRAY}};\n  $self->STORE( $_, $list[$_] ) foreach 0 .. $#list;\n} SPLICE this, offset, length, LIST Perform the equivalent of \"splice\" on the array. offset is optional and defaults to zero, negative values count back from the end of the array. length is optional and defaults to rest of the array. LIST may be empty. Returns a list of the original length elements at offset. In our example, we'll use a little shortcut if there is a LIST : sub SPLICE {\n  my $self   = shift;\n  my $offset = shift || 0;\n  my $length = shift || $self->FETCHSIZE() - $offset;\n  my @list   = ();\n  if ( @_ ) {\n    tie @list, __PACKAGE__, $self->{ELEMSIZE};\n    @list   = @_;\n  }\n  return splice @{$self->{ARRAY}}, $offset, $length, @list;\n} UNTIE this Will be called when \"untie\" happens. (See \"The \"untie\" Gotcha\" below.) DESTROY this This method will be triggered when the tied variable needs to be destructed. As with the scalar tie class, this is almost never needed in a language that does its own garbage collection, so this time we'll just leave it out. Tying Hashes Hashes were the first Perl data type to be tied (see dbmopen()). A class implementing a tied hash should define the following methods: TIEHASH is the constructor. FETCH and STORE access the key and value pairs. EXISTS reports whether a key is present in the hash, and DELETE deletes one. CLEAR empties the hash by deleting all the key and value pairs. FIRSTKEY and NEXTKEY implement the keys() and each() functions to iterate over all the keys. SCALAR is triggered when the tied hash is evaluated in scalar context. UNTIE is called when \"untie\" happens, and DESTROY is called when the tied variable is garbage collected. If this seems like a lot, then feel free to inherit from merely the standard Tie::StdHash module for most of your methods, redefining only the interesting ones. See Tie::Hash for details. Remember that Perl distinguishes between a key not existing in the hash, and the key existing in the hash but having a corresponding value of \"undef\". The two possibilities can be tested with the \"exists()\" and \"defined()\" functions. Here's an example of a somewhat interesting tied hash class: it gives you a hash representing a particular user's dot files. You index into the hash with the name of the file (minus the dot) and you get back that dot file's contents. For example: use DotFiles;\ntie %dot, 'DotFiles';\nif ( $dot{profile} =~ \/MANPATH\/ ||\n     $dot{login}   =~ \/MANPATH\/ ||\n     $dot{cshrc}   =~ \/MANPATH\/    )\n{\n    print \"you seem to set your MANPATH\\n\";\n} Or here's another sample of using our tied class: tie %him, 'DotFiles', 'daemon';\nforeach $f ( keys %him ) {\n    printf \"daemon dot file %s is size %d\\n\",\n        $f, length $him{$f};\n} In our tied hash DotFiles example, we use a regular hash for the object containing several important fields, of which only the \"{LIST}\" field will be what the user thinks of as the real hash. USER whose dot files this object represents HOME where those dot files live CLOBBER whether we should try to change or remove those dot files LIST the hash of dot file names and content mappings Here's the start of Dotfiles.pm: package DotFiles;\nuse Carp;\nsub whowasi { (caller(1))[3] . '()' }\nmy $DEBUG = 0;\nsub debug { $DEBUG = @_ ? shift : 1 } For our example, we want to be able to emit debugging info to help in tracing during development. We keep also one convenience function around internally to help print out warnings; whowasi() returns the function name that calls it. Here are the methods for the DotFiles tied hash. TIEHASH classname, LIST This is the constructor for the class. That means it is expected to return a blessed reference through which the new object (probably but not necessarily an anonymous hash) will be accessed. Here's the constructor: sub TIEHASH {\n    my $self = shift;\n    my $user = shift || $>;\n    my $dotdir = shift || '';\n    croak \"usage: @{[&whowasi]} [USER [DOTDIR]]\" if @_;\n    $user = getpwuid($user) if $user =~ \/^\\d+$\/;\n    my $dir = (getpwnam($user))[7]\n            || croak \"@{[&whowasi]}: no user $user\";\n    $dir .= \"\/$dotdir\" if $dotdir;\n\n    my $node = {\n        USER    => $user,\n        HOME    => $dir,\n        LIST    => {},\n        CLOBBER => 0,\n    };\n\n    opendir(DIR, $dir)\n            || croak \"@{[&whowasi]}: can't opendir $dir: $!\";\n    foreach $dot ( grep \/^\\.\/ && -f \"$dir\/$_\", readdir(DIR)) {\n        $dot =~ s\/^\\.\/\/;\n        $node->{LIST}{$dot} = undef;\n    }\n    closedir DIR;\n    return bless $node, $self;\n} It's probably worth mentioning that if you're going to filetest the return values out of a readdir, you'd better prepend the directory in question. Otherwise, because we didn't chdir() there, it would have been testing the wrong file. FETCH this, key This method will be triggered every time an element in the tied hash is accessed (read). It takes one argument beyond its self reference: the key whose value we're trying to fetch. Here's the fetch for our DotFiles example. sub FETCH {\n    carp &whowasi if $DEBUG;\n    my $self = shift;\n    my $dot = shift;\n    my $dir = $self->{HOME};\n    my $file = \"$dir\/.$dot\";\n\n    unless (exists $self->{LIST}->{$dot} || -f $file) {\n        carp \"@{[&whowasi]}: no $dot file\" if $DEBUG;\n        return undef;\n    }\n\n    if (defined $self->{LIST}->{$dot}) {\n        return $self->{LIST}->{$dot};\n    } else {\n        return $self->{LIST}->{$dot} = `cat $dir\/.$dot`;\n    }\n} It was easy to write by having it call the Unix cat(1) command, but it would probably be more portable to open the file manually (and somewhat more efficient). Of course, because dot files are a Unixy concept, we're not that concerned. STORE this, key, value This method will be triggered every time an element in the tied hash is set (written). It takes two arguments beyond its self reference: the index at which we're trying to store something, and the value we're trying to put there. Here in our DotFiles example, we'll be careful not to let them try to overwrite the file unless they've called the clobber() method on the original object reference returned by tie(). sub STORE {\n    carp &whowasi if $DEBUG;\n    my $self = shift;\n    my $dot = shift;\n    my $value = shift;\n    my $file = $self->{HOME} . \"\/.$dot\";\n    my $user = $self->{USER};\n\n    croak \"@{[&whowasi]}: $file not clobberable\"\n        unless $self->{CLOBBER};\n\n    open(F, \"> $file\") || croak \"can't open $file: $!\";\n    print F $value;\n    close(F);\n} If they wanted to clobber something, they might say: $ob = tie %daemon_dots, 'daemon';\n$ob->clobber(1);\n$daemon_dots{signature} = \"A true daemon\\n\"; Another way to lay hands on a reference to the underlying object is to use the tied() function, so they might alternately have set clobber using: tie %daemon_dots, 'daemon';\ntied(%daemon_dots)->clobber(1); The clobber method is simply: sub clobber {\n    my $self = shift;\n    $self->{CLOBBER} = @_ ? shift : 1;\n} DELETE this, key This method is triggered when we remove an element from the hash, typically by using the delete() function. Again, we'll be careful to check whether they really want to clobber files. sub DELETE   {\n    carp &whowasi if $DEBUG;\n\n    my $self = shift;\n    my $dot = shift;\n    my $file = $self->{HOME} . \"\/.$dot\";\n    croak \"@{[&whowasi]}: won't remove file $file\"\n        unless $self->{CLOBBER};\n    delete $self->{LIST}->{$dot};\n    my $success = unlink($file);\n    carp \"@{[&whowasi]}: can't unlink $file: $!\" unless $success;\n    $success;\n} The value returned by DELETE becomes the return value of the call to delete(). If you want to emulate the normal behavior of delete(), you should return whatever FETCH would have returned for this key. In this example, we have chosen instead to return a value which tells the caller whether the file was successfully deleted. CLEAR this This method is triggered when the whole hash is to be cleared, usually by assigning the empty list to it. In our example, that would remove all the user's dot files! It's such a dangerous thing that they'll have to set CLOBBER to something higher than 1 to make it happen. sub CLEAR    {\n    carp &whowasi if $DEBUG;\n    my $self = shift;\n    croak \"@{[&whowasi]}: won't remove all dot files for $self->{USER}\"\n        unless $self->{CLOBBER} > 1;\n    my $dot;\n    foreach $dot ( keys %{$self->{LIST}}) {\n        $self->DELETE($dot);\n    }\n} EXISTS this, key This method is triggered when the user uses the exists() function on a particular hash. In our example, we'll look at the \"{LIST}\" hash element for this: sub EXISTS   {\n    carp &whowasi if $DEBUG;\n    my $self = shift;\n    my $dot = shift;\n    return exists $self->{LIST}->{$dot};\n} FIRSTKEY this This method will be triggered when the user is going to iterate through the hash, such as via a keys() or each() call. sub FIRSTKEY {\n    carp &whowasi if $DEBUG;\n    my $self = shift;\n    my $a = keys %{$self->{LIST}};          # reset each() iterator\n    each %{$self->{LIST}}\n} NEXTKEY this, lastkey This method gets triggered during a keys() or each() iteration. It has a second argument which is the last key that had been accessed. This is useful if you're carrying about ordering or calling the iterator from more than one sequence, or not really storing things in a hash anywhere. For our example, we're using a real hash so we'll do just the simple thing, but we'll have to go through the LIST field indirectly. sub NEXTKEY  {\n    carp &whowasi if $DEBUG;\n    my $self = shift;\n    return each %{ $self->{LIST} }\n} SCALAR this This is called when the hash is evaluated in scalar context. In order to mimic the behaviour of untied hashes, this method should return a false value when the tied hash is considered empty. If this method does not exist, perl will make some educated guesses and return true when the hash is inside an iteration. If this isn't the case, FIRSTKEY is called, and the result will be a false value if FIRSTKEY returns the empty list, true otherwise. However, you should not blindly rely on perl always doing the right thing. Particularly, perl will mistakenly return true when you clear the hash by repeatedly calling DELETE until it is empty. You are therefore advised to supply your own SCALAR method when you want to be absolutely sure that your hash behaves nicely in scalar context. In our example we can just call \"scalar\" on the underlying hash referenced by \"$self->{LIST}\": sub SCALAR {\n    carp &whowasi if $DEBUG;\n    my $self = shift;\n    return scalar %{ $self->{LIST} }\n} UNTIE this This is called when \"untie\" occurs. See \"The \"untie\" Gotcha\" below. DESTROY this This method is triggered when a tied hash is about to go out of scope. You don't really need it unless you're trying to add debugging or have auxiliary state to clean up. Here's a very simple function: sub DESTROY  {\n    carp &whowasi if $DEBUG;\n} Note that functions such as keys() and values() may return huge lists when used on large objects, like DBM files. You may prefer to use the each() function to iterate over such. Example: # print out history file offsets\nuse NDBM_File;\ntie(%HIST, 'NDBM_File', '\/usr\/lib\/news\/history', 1, 0);\nwhile (($key,$val) = each %HIST) {\n    print $key, ' = ', unpack('L',$val), \"\\n\";\n}\nuntie(%HIST); Tying FileHandles This is partially implemented now. A class implementing a tied filehandle should define the following methods: TIEHANDLE , at least one of PRINT , PRINTF , WRITE , READLINE , GETC , READ , and possibly CLOSE , UNTIE and DESTROY . The class can also provide: BINMODE , OPEN , EOF , FILENO , SEEK , TELL - if the corresponding perl operators are used on the handle. When STDERR is tied, its PRINT method will be called to issue warnings and error messages. This feature is temporarily disabled during the call, which means you can use \"warn()\" inside PRINT without starting a recursive loop. And just like \"__WARN__\" and \"__DIE__\" handlers, STDERR 's PRINT method may be called to report parser errors, so the caveats mentioned under \"%SIG\" in perlvar apply. All of this is especially useful when perl is embedded in some other program, where output to STDOUT and STDERR may have to be redirected in some special way. See nvi and the Apache module for examples. In our example we're going to create a shouting handle. package Shout; TIEHANDLE classname, LIST This is the constructor for the class. That means it is expected to return a blessed reference of some sort. The reference can be used to hold some internal information. sub TIEHANDLE { print \"<shout>\\n\"; my $i; bless \\$i, shift } WRITE this, LIST This method will be called when the handle is written to via the \"syswrite\" function. sub WRITE {\n    $r = shift;\n    my($buf,$len,$offset) = @_;\n    print \"WRITE called, \\$buf=$buf, \\$len=$len, \\$offset=$offset\";\n} PRINT this, LIST This method will be triggered every time the tied handle is printed to with the \"print()\" or \"say()\" functions. Beyond its self reference it also expects the list that was passed to the print function. sub PRINT { $r = shift; $$r++; print join($,,map(uc($_),@_)),$\\ } \"say()\" acts just like \"print()\" except $\\ will be localized to \"\\n\" so you need do nothing special to handle \"say()\" in \"PRINT()\". PRINTF this, LIST This method will be triggered every time the tied handle is printed to with the \"printf()\" function. Beyond its self reference it also expects the format and list that was passed to the printf function. sub PRINTF {\n    shift;\n    my $fmt = shift;\n    print sprintf($fmt, @_);\n} READ this, LIST This method will be called when the handle is read from via the \"read\" or \"sysread\" functions. sub READ {\n    my $self = shift;\n    my $bufref = \\$_[0];\n    my(undef,$len,$offset) = @_;\n    print \"READ called, \\$buf=$bufref, \\$len=$len, \\$offset=$offset\";\n    # add to $$bufref, set $len to number of characters read\n    $len;\n} READLINE this This method will be called when the handle is read from via < HANDLE >. The method should return undef when there is no more data. sub READLINE { $r = shift; \"READLINE called $$r times\\n\"; } GETC this This method will be called when the \"getc\" function is called. sub GETC { print \"Don't GETC, Get Perl\"; return \"a\"; } CLOSE this This method will be called when the handle is closed via the \"close\" function. sub CLOSE { print \"CLOSE called.\\n\" } UNTIE this As with the other types of ties, this method will be called when \"untie\" happens. It may be appropriate to \"auto CLOSE \" when this occurs. See \"The \"untie\" Gotcha\" below. DESTROY this As with the other types of ties, this method will be called when the tied handle is about to be destroyed. This is useful for debugging and possibly cleaning up. sub DESTROY { print \"<\/shout>\\n\" } Here's how to use our little example: tie(*FOO,'Shout');\nprint FOO \"hello\\n\";\n$a = 4; $b = 6;\nprint FOO $a, \" plus \", $b, \" equals \", $a + $b, \"\\n\";\nprint <FOO>; UNTIE this You can define for all tie types an UNTIE method that will be called at untie(). See \"The \"untie\" Gotcha\" below. The \"untie\" Gotcha If you intend making use of the object returned from either tie() or tied(), and if the tie's target class defines a destructor, there is a subtle gotcha you must guard against. As setup, consider this (admittedly rather contrived) example of a tie; all it does is use a file to keep a log of the values assigned to a scalar. package Remember;\n\nuse strict;\nuse warnings;\nuse IO::File;\n\nsub TIESCALAR {\n    my $class = shift;\n    my $filename = shift;\n    my $handle = IO::File->new( \"> $filename\" )\n                     or die \"Cannot open $filename: $!\\n\";\n\n    print $handle \"The Start\\n\";\n    bless {FH => $handle, Value => 0}, $class;\n}\n\nsub FETCH {\n    my $self = shift;\n    return $self->{Value};\n}\n\nsub STORE {\n    my $self = shift;\n    my $value = shift;\n    my $handle = $self->{FH};\n    print $handle \"$value\\n\";\n    $self->{Value} = $value;\n}\n\nsub DESTROY {\n    my $self = shift;\n    my $handle = $self->{FH};\n    print $handle \"The End\\n\";\n    close $handle;\n}\n\n1; Here is an example that makes use of this tie: use strict;\nuse Remember;\n\nmy $fred;\ntie $fred, 'Remember', 'myfile.txt';\n$fred = 1;\n$fred = 4;\n$fred = 5;\nuntie $fred;\nsystem \"cat myfile.txt\"; This is the output when it is executed: The Start\n1\n4\n5\nThe End So far so good. Those of you who have been paying attention will have spotted that the tied object hasn't been used so far. So lets add an extra method to the Remember class to allow comments to be included in the file -- say, something like this: sub comment {\n    my $self = shift;\n    my $text = shift;\n    my $handle = $self->{FH};\n    print $handle $text, \"\\n\";\n} And here is the previous example modified to use the \"comment\" method (which requires the tied object): use strict;\nuse Remember;\n\nmy ($fred, $x);\n$x = tie $fred, 'Remember', 'myfile.txt';\n$fred = 1;\n$fred = 4;\ncomment $x \"changing...\";\n$fred = 5;\nuntie $fred;\nsystem \"cat myfile.txt\"; When this code is executed there is no output. Here's why: When a variable is tied, it is associated with the object which is the return value of the TIESCALAR , TIEARRAY , or TIEHASH function. This object normally has only one reference, namely, the implicit reference from the tied variable. When untie() is called, that reference is destroyed. Then, as in the first example above, the object's destructor ( DESTROY ) is called, which is normal for objects that have no more valid references; and thus the file is closed. In the second example, however, we have stored another reference to the tied object in $x. That means that when untie() gets called there will still be a valid reference to the object in existence, so the destructor is not called at that time, and thus the file is not closed. The reason there is no output is because the file buffers have not been flushed to disk. Now that you know what the problem is, what can you do to avoid it? Prior to the introduction of the optional UNTIE method the only way was the good old \"-w\" flag. Which will spot any instances where you call untie() and there are still valid references to the tied object. If the second script above this near the top \"use warnings 'untie'\" or was run with the \"-w\" flag, Perl prints this warning message: untie attempted while 1 inner references still exist To get the script to work properly and silence the warning make sure there are no valid references to the tied object before untie() is called: undef $x;\nuntie $fred; Now that UNTIE exists the class designer can decide which parts of the class functionality are really associated with \"untie\" and which with the object being destroyed. What makes sense for a given class depends on whether the inner references are being kept so that non-tie-related methods can be called on the object. But in most cases it probably makes sense to move the functionality that would have been in DESTROY to the UNTIE method. If the UNTIE method exists then the warning above does not occur. Instead the UNTIE method is passed the count of \"extra\" references and can issue its own warning if appropriate. e.g. to replicate the no UNTIE case this method can be used: sub UNTIE\n{\n my ($obj,$count) = @_;\n carp \"untie attempted while $count inner references still exist\" if $count;\n}","Process Name":"perltie","Link":"https:\/\/linux.die.net\/man\/1\/perltie"}},{"Process":{"Description":"This page provides a brief table of contents for the rest of the Perl documentation set. It is meant to be scanned quickly or grepped through to locate the proper section you're looking for.","Process Name":"perltoc","Link":"https:\/\/linux.die.net\/man\/1\/perltoc"}},{"Process":{"Description":"This is a list of wishes for Perl. The most up to date version of this file is at http:\/\/perl5.git.perl.org\/perl.git\/blob_plain\/HEAD:\/pod\/perltodo.pod The tasks we think are smaller or easier are listed first. Anyone is welcome to work on any of these, but it's a good idea to first contact perl5-porters@perl.org to avoid duplication of effort, and to learn from any previous attempts. By all means contact a pumpking privately first if you prefer. Whilst patches to make the list shorter are most welcome, ideas to add to the list are also encouraged. Check the perl5-porters archives for past ideas, and any discussion about them. One set of archives may be found at: http:\/\/www.xray.mpe.mpg.de\/mailing-lists\/perl5-porters\/ What can we offer you in return? Fame, fortune, and everlasting glory? Maybe not, but if your patch is incorporated, then we'll add your name to the AUTHORS file, which ships in the official distribution. How many other programming languages offer you 1 line of immortality?","Process Name":"perltodo","Link":"https:\/\/linux.die.net\/man\/1\/perltodo"}},{"Process":{"Description":"When designing an object class, you are sometimes faced with the situation of wanting common state shared by all objects of that class. Such class attributes act somewhat like global variables for the entire class, but unlike program-wide globals, class attributes have meaning only to the class itself. Here are a few examples where class attributes might come in handy: \u2022 to keep a count of the objects you've created, or how many are still extant. \u2022 to extract the name or file descriptor for a logfile used by a debugging method. \u2022 to access collective data, like the total amount of cash dispensed by all ATMs in a network in a given day. \u2022 to access the last object created by a class, or the most accessed object, or to retrieve a list of all objects. Unlike a true global, class attributes should not be accessed directly. Instead, their state should be inspected, and perhaps altered, only through the mediated access of class methods. These class attributes accessor methods are similar in spirit and function to accessors used to manipulate the state of instance attributes on an object. They provide a clear firewall between interface and implementation. You should allow access to class attributes through either the class name or any object of that class. If we assume that $an_object is of type Some_Class, and the &Some_Class::population_count method accesses class attributes, then these two invocations should both be possible, and almost certainly equivalent. Some_Class->population_count()\n$an_object->population_count() The question is, where do you store the state which that method accesses? Unlike more restrictive languages like C ++ , where these are called static data members, Perl provides no syntactic mechanism to declare class attributes, any more than it provides a syntactic mechanism to declare instance attributes. Perl provides the developer with a broad set of powerful but flexible features that can be uniquely crafted to the particular demands of the situation. A class in Perl is typically implemented in a module. A module consists of two complementary feature sets: a package for interfacing with the outside world, and a lexical file scope for privacy. Either of these two mechanisms can be used to implement class attributes. That means you get to decide whether to put your class attributes in package variables or to put them in lexical variables. And those aren't the only decisions to make. If you choose to use package variables, you can make your class attribute accessor methods either ignorant of inheritance or sensitive to it. If you choose lexical variables, you can elect to permit access to them from anywhere in the entire file scope, or you can limit direct data access exclusively to the methods implementing those attributes.","Process Name":"perltooc","Link":"https:\/\/linux.die.net\/man\/1\/perltooc"}},{"Process":{"Description":"Object-oriented programming is a big seller these days. Some managers would rather have objects than sliced bread. Why is that? What's so special about an object? Just what is an object anyway? An object is nothing but a way of tucking away complex behaviours into a neat little easy-to-use bundle. (This is what professors call abstraction.) Smart people who have nothing to do but sit around for weeks on end figuring out really hard problems make these nifty objects that even regular people can use. (This is what professors call software reuse.) Users (well, programmers) can play with this little bundle all they want, but they aren't to open it up and mess with the insides. Just like an expensive piece of hardware, the contract says that you void the warranty if you muck with the cover. So don't do that. The heart of objects is the class, a protected little private namespace full of data and functions. A class is a set of related routines that addresses some problem area. You can think of it as a user-defined type. The Perl package mechanism, also used for more traditional modules, is used for class modules as well. Objects \"live\" in a class, meaning that they belong to some package. More often than not, the class provides the user with little bundles. These bundles are objects. They know whose class they belong to, and how to behave. Users ask the class to do something, like \"give me an object.\" Or they can ask one of these objects to do something. Asking a class to do something for you is calling a class method. Asking an object to do something for you is calling an object method. Asking either a class (usually) or an object (sometimes) to give you back an object is calling a constructor, which is just a kind of method. That's all well and good, but how is an object different from any other Perl data type? Just what is an object really; that is, what's its fundamental type? The answer to the first question is easy. An object is different from any other data type in Perl in one and only one way: you may dereference it using not merely string or numeric subscripts as with simple arrays and hashes, but with named subroutine calls. In a word, with methods. The answer to the second question is that it's a reference, and not just any reference, mind you, but one whose referent has been bless()ed into a particular class (read: package). What kind of reference? Well, the answer to that one is a bit less concrete. That's because in Perl the designer of the class can employ any sort of reference they'd like as the underlying intrinsic data type. It could be a scalar, an array, or a hash reference. It could even be a code reference. But because of its inherent flexibility, an object is usually a hash reference.","Process Name":"perltoot","Link":"https:\/\/linux.die.net\/man\/1\/perltoot"}},{"Process":{"Description":"The biggest trap of all is forgetting to \"use warnings\" or use the -w switch; see perllexwarn and perlrun. The second biggest trap is not making your entire program runnable under \"use strict\". The third biggest trap is not reading the list of changes in this version of Perl; see perldelta. Awk Traps Accustomed awk users should take special note of the following: \u2022 A Perl program executes only once, not once for each input line. You can do an implicit loop with \"-n\" or \"-p\". \u2022 The English module, loaded via use English; allows you to refer to special variables (like $\/) with names (like $RS), as though they were in awk; see perlvar for details. \u2022 Semicolons are required after all simple statements in Perl (except at the end of a block). Newline is not a statement delimiter. \u2022 Curly brackets are required on \"if\"s and \"while\"s. \u2022 Variables begin with \"$\", \"@\" or \"%\" in Perl. \u2022 Arrays index from 0. Likewise string positions in substr() and index(). \u2022 You have to decide whether your array has numeric or string indices. \u2022 Hash values do not spring into existence upon mere reference. \u2022 You have to decide whether you want to use string or numeric comparisons. \u2022 Reading an input line does not split it for you. You get to split it to an array yourself. And the split() operator has different arguments than awk's. \u2022 The current input line is normally in $_, not $0. It generally does not have the newline stripped. ($0 is the name of the program executed.) See perlvar. \u2022 $<digit> does not refer to fields--it refers to substrings matched by the last match pattern. \u2022 The print() statement does not add field and record separators unless you set $, and \"$\\\". You can set $OFS and $ORS if you're using the English module. \u2022 You must open your files before you print to them. \u2022 The range operator is \"..\", not comma. The comma operator works as in C. \u2022 The match operator is \"=~\", not \"~\". (\"~\" is the one's complement operator, as in C.) \u2022 The exponentiation operator is \"**\", not \"^\". \"^\" is the XOR operator, as in C. (You know, one could get the feeling that awk is basically incompatible with C.) \u2022 The concatenation operator is \".\", not the null string. (Using the null string would render \"\/pat\/ \/pat\/\" unparsable, because the third slash would be interpreted as a division operator--the tokenizer is in fact slightly context sensitive for operators like \"\/\", \"?\", and \">\". And in fact, \".\" itself can be the beginning of a number.) \u2022 The \"next\", \"exit\", and \"continue\" keywords work differently. \u2022 The following variables work differently: Awk       Perl\nARGC      scalar @ARGV (compare with $#ARGV)\nARGV[0]   $0\nFILENAME  $ARGV\nFNR       $. - something\nFS        (whatever you like)\nNF        $#Fld, or some such\nNR        $.\nOFMT      $#\nOFS       $,\nORS       $\\\nRLENGTH   length($&)\nRS        $\/\nRSTART    length($`)\nSUBSEP    $; \u2022 You cannot set $RS to a pattern, only a string. \u2022 When in doubt, run the awk construct through a2p and see what it gives you. C\/C ++ Traps Cerebral C and C ++ programmers should take note of the following: \u2022 Curly brackets are required on \"if\"'s and \"while\"'s. \u2022 You must use \"elsif\" rather than \"else if\". \u2022 The \"break\" and \"continue\" keywords from C become in Perl \"last\" and \"next\", respectively. Unlike in C, these do not work within a \"do { } while\" construct. See \"Loop Control\" in perlsyn. \u2022 The switch statement is called \"given\/when\" and only available in perl 5.10 or newer. See \"Switch statements\" in perlsyn. \u2022 Variables begin with \"$\", \"@\" or \"%\" in Perl. \u2022 Comments begin with \"#\", not \"\/*\" or \"\/\/\". Perl may interpret C\/C ++ comments as division operators, unterminated regular expressions or the defined-or operator. \u2022 You can't take the address of anything, although a similar operator in Perl is the backslash, which creates a reference. \u2022 \"ARGV\" must be capitalized. $ARGV[0] is C's \"argv[1]\", and \"argv[0]\" ends up in $0. \u2022 System calls such as link(), unlink(), rename(), etc. return nonzero for success, not 0. (system(), however, returns zero for success.) \u2022 Signal handlers deal with signal names, not numbers. Use \"kill -l\" to find their names on your system. Sed Traps Seasoned sed programmers should take note of the following: \u2022 A Perl program executes only once, not once for each input line. You can do an implicit loop with \"-n\" or \"-p\". \u2022 Backreferences in substitutions use \"$\" rather than \"\\\". \u2022 The pattern matching metacharacters \"(\", \")\", and \"|\" do not have backslashes in front. \u2022 The range operator is \"...\", rather than comma. Shell Traps Sharp shell programmers should take note of the following: \u2022 The backtick operator does variable interpolation without regard to the presence of single quotes in the command. \u2022 The backtick operator does no translation of the return value, unlike csh. \u2022 Shells (especially csh) do several levels of substitution on each command line. Perl does substitution in only certain constructs such as double quotes, backticks, angle brackets, and search patterns. \u2022 Shells interpret scripts a little bit at a time. Perl compiles the entire program before executing it (except for \"BEGIN\" blocks, which execute at compile time). \u2022 The arguments are available via @ARGV, not $1, $2, etc. \u2022 The environment is not automatically made available as separate scalar variables. \u2022 The shell's \"test\" uses \"=\", \"!=\", \"<\" etc for string comparisons and \"-eq\", \"-ne\", \"-lt\" etc for numeric comparisons. This is the reverse of Perl, which uses \"eq\", \"ne\", \"lt\" for string comparisons, and \"==\", \"!=\" \"<\" etc for numeric comparisons. Perl Traps Practicing Perl Programmers should take note of the following: \u2022 Remember that many operations behave differently in a list context than they do in a scalar one. See perldata for details. \u2022 Avoid barewords if you can, especially all lowercase ones. You can't tell by just looking at it whether a bareword is a function or a string. By using quotes on strings and parentheses on function calls, you won't ever get them confused. \u2022 You cannot discern from mere inspection which builtins are unary operators (like chop() and chdir()) and which are list operators (like print() and unlink()). (Unless prototyped, user-defined subroutines can only be list operators, never unary ones.) See perlop and perlsub. \u2022 People have a hard time remembering that some functions default to $_, or @ARGV, or whatever, but that others which you might expect to do not. \u2022 The < FH > construct is not the name of the filehandle, it is a readline operation on that handle. The data read is assigned to $_ only if the file read is the sole condition in a while loop: while (<FH>)      { }\nwhile (defined($_ = <FH>)) { }..\n<FH>;  # data discarded! \u2022 Remember not to use \"=\" when you need \"=~\"; these two constructs are quite different: $x =  \/foo\/;\n$x =~ \/foo\/; \u2022 The \"do {}\" construct isn't a real loop that you can use loop control on. \u2022 Use \"my()\" for local variables whenever you can get away with it (but see perlform for where you can't). Using \"local()\" actually gives a local value to a global variable, which leaves you open to unforeseen side-effects of dynamic scoping. \u2022 If you localize an exported variable in a module, its exported value will not change. The local name becomes an alias to a new value but the external name is still an alias for the original. Perl4 to Perl5 Traps Practicing Perl4 Programmers should take note of the following Perl4-to-Perl5 specific traps. They're crudely ordered according to the following list: Discontinuance, Deprecation, and BugFix traps Anything that's been fixed as a perl4 bug, removed as a perl4 feature or deprecated as a perl4 feature with the intent to encourage usage of some other perl5 feature. Parsing Traps Traps that appear to stem from the new parser. Numerical Traps Traps having to do with numerical or mathematical operators. General data type traps Traps involving perl standard data types. Context Traps - scalar, list contexts Traps related to context within lists, scalar statements\/declarations. Precedence Traps Traps related to the precedence of parsing, evaluation, and execution of code. General Regular Expression Traps using s\/\/\/, etc. Traps related to the use of pattern matching. Subroutine, Signal, Sorting Traps Traps related to the use of signals and signal handlers, general subroutines, and sorting, along with sorting subroutines. OS Traps OS-specific traps. DBM Traps Traps specific to the use of \"dbmopen()\", and specific dbm implementations. Unclassified Traps Everything else. If you find an example of a conversion trap that is not listed here, please submit it to < perlbug@perl.org> for inclusion. Also note that at least some of these can be caught with the \"use warnings\" pragma or the -w switch. Discontinuance, Deprecation, and BugFix traps Anything that has been discontinued, deprecated, or fixed as a bug from perl4. \u2022 Symbols starting with \"_\" no longer forced into main Symbols starting with \"_\" are no longer forced into package main, except for $_ itself (and @_, etc.). package test;\n$_legacy = 1;\n\npackage main;\nprint \"\\$_legacy is \",$_legacy,\"\\n\";\n\n# perl4 prints: $_legacy is 1\n# perl5 prints: $_legacy is \u2022 Double-colon valid package separator in variable name Double-colon is now a valid package separator in a variable name. Thus these behave differently in perl4 vs. perl5, because the packages don't exist. $a=1;$b=2;$c=3;$var=4;\nprint \"$a::$b::$c \";\nprint \"$var::abc::xyz\\n\";\n\n# perl4 prints: 1::2::3 4::abc::xyz\n# perl5 prints: 3 Given that \"::\" is now the preferred package delimiter, it is debatable whether this should be classed as a bug or not. (The older package delimiter, ' ,is used here) $x = 10;\nprint \"x=${'x}\\n\";\n\n# perl4 prints: x=10\n# perl5 prints: Can't find string terminator \"'\" anywhere before EOF You can avoid this problem, and remain compatible with perl4, if you always explicitly include the package name: $x = 10;\nprint \"x=${main'x}\\n\"; Also see precedence traps, for parsing $:. \u2022 2nd and 3rd args to \"splice()\" are now in scalar context The second and third arguments of \"splice()\" are now evaluated in scalar context (as the Camel says) rather than list context. sub sub1{return(0,2) }          # return a 2-element list\nsub sub2{ return(1,2,3)}        # return a 3-element list\n@a1 = (\"a\",\"b\",\"c\",\"d\",\"e\");\n@a2 = splice(@a1,&sub1,&sub2);\nprint join(' ',@a2),\"\\n\";\n\n# perl4 prints: a b\n# perl5 prints: c d e \u2022 Can't do \"goto\" into a block that is optimized away You can't do a \"goto\" into a block that is optimized away. Darn. goto marker1;\n\nfor(1){\nmarker1:\n    print \"Here I is!\\n\";\n}\n\n# perl4 prints: Here I is!\n# perl5 errors: Can't \"goto\" into the middle of a foreach loop \u2022 Can't use whitespace as variable name or quote delimiter It is no longer syntactically legal to use whitespace as the name of a variable, or as a delimiter for any kind of quote construct. Double darn. $a = (\"foo bar\");\n$b = q baz;\nprint \"a is $a, b is $b\\n\";\n\n# perl4 prints: a is foo bar, b is baz\n# perl5 errors: Bareword found where operator expected \u2022 \"while\/if BLOCK BLOCK\" gone The archaic while\/if BLOCK BLOCK syntax is no longer supported. if { 1 } {\n    print \"True!\";\n}\nelse {\n    print \"False!\";\n}\n\n# perl4 prints: True!\n# perl5 errors: syntax error at test.pl line 1, near \"if {\" \u2022 \"**\" binds tighter than unary minus The \"**\" operator now binds more tightly than unary minus. It was documented to work this way before, but didn't. print -4**2,\"\\n\";\n\n# perl4 prints: 16\n# perl5 prints: -16 \u2022 \"foreach\" changed when iterating over a list The meaning of \"foreach{}\" has changed slightly when it is iterating over a list which is not an array. This used to assign the list to a temporary array, but no longer does so (for efficiency). This means that you'll now be iterating over the actual values, not over copies of the values. Modifications to the loop variable can change the original values. @list = ('ab','abc','bcd','def');\nforeach $var (grep(\/ab\/,@list)){\n    $var = 1;\n}\nprint (join(':',@list));\n\n# perl4 prints: ab:abc:bcd:def\n# perl5 prints: 1:1:bcd:def To retain Perl4 semantics you need to assign your list explicitly to a temporary array and then iterate over that. For example, you might need to change foreach $var (grep(\/ab\/,@list)){ to foreach $var (@tmp = grep(\/ab\/,@list)){ Otherwise changing $var will clobber the values of @list. (This most often happens when you use $_ for the loop variable, and call subroutines in the loop that don't properly localize $_.) \u2022 \"split\" with no args behavior changed \"split\" with no arguments now behaves like \"split ' '\" (which doesn't return an initial null field if $_ starts with whitespace), it used to behave like \"split \/\\s+\/\" (which does). $_ = ' hi mom';\nprint join(':', split);\n\n# perl4 prints: :hi:mom\n# perl5 prints: hi:mom \u2022 -e behavior fixed Perl 4 would ignore any text which was attached to an -e switch, always taking the code snippet from the following arg. Additionally, it would silently accept an -e switch without a following arg. Both of these behaviors have been fixed. perl -e'print \"attached to -e\"' 'print \"separate arg\"'\n\n# perl4 prints: separate arg\n# perl5 prints: attached to -e\n\nperl -e\n\n# perl4 prints:\n# perl5 dies: No code specified for -e. \u2022 \"push\" returns number of elements in resulting list In Perl 4 the return value of \"push\" was undocumented, but it was actually the last value being pushed onto the target list. In Perl 5 the return value of \"push\" is documented, but has changed, it is the number of elements in the resulting list. @x = ('existing');\nprint push(@x, 'first new', 'second new');\n\n# perl4 prints: second new\n# perl5 prints: 3 \u2022 Some error messages differ Some error messages will be different. \u2022 \"split()\" honors subroutine args In Perl 4, if in list context the delimiters to the first argument of \"split()\" were \"??\", the result would be placed in @_ as well as being returned. Perl 5 has more respect for your subroutine arguments. \u2022 Bugs removed Some bugs may have been inadvertently removed. :-) Parsing Traps Perl4-to-Perl5 traps from having to do with parsing. \u2022 Space between . and = triggers syntax error Note the space between . and = $string . = \"more string\";\nprint $string;\n\n# perl4 prints: more string\n# perl5 prints: syntax error at - line 1, near \". =\" \u2022 Better parsing in perl 5 Better parsing in perl 5 sub foo {}\n&foo\nprint(\"hello, world\\n\");\n\n# perl4 prints: hello, world\n# perl5 prints: syntax error \u2022 Function parsing \"if it looks like a function, it is a function\" rule. print\n  ($foo == 1) ? \"is one\\n\" : \"is zero\\n\";\n\n  # perl4 prints: is zero\n  # perl5 warns: \"Useless use of a constant in void context\" if using -w \u2022 String interpolation of $#array differs String interpolation of the $#array construct differs when braces are to used around the name. @a = (1..3);\nprint \"${#a}\";\n\n# perl4 prints: 2\n# perl5 fails with syntax error\n\n@ = (1..3);\nprint \"$#{a}\";\n\n# perl4 prints: {a}\n# perl5 prints: 2 \u2022 Perl guesses on \"map\", \"grep\" followed by \"{\" if it starts BLOCK or hash ref When perl sees \"map {\" (or \"grep {\"), it has to guess whether the \"{\" starts a BLOCK or a hash reference. If it guesses wrong, it will report a syntax error near the \"}\" and the missing (or unexpected) comma. Use unary \"+\" before \"{\" on a hash reference, and unary \"+\" applied to the first thing in a BLOCK (after \"{\"), for perl to guess right all the time. (See \"map\" in perlfunc.) Numerical Traps Perl4-to-Perl5 traps having to do with numerical operators, operands, or output from same. \u2022 Formatted output and significant digits Formatted output and significant digits. In general, Perl 5 tries to be more precise. For example, on a Solaris Sparc: print 7.373504 - 0, \"\\n\";\nprintf \"%20.18f\\n\", 7.373504 - 0;\n\n# Perl4 prints:\n7.3750399999999996141\n7.375039999999999614\n\n# Perl5 prints:\n7.373504\n7.375039999999999614 Notice how the first result looks better in Perl 5. Your results may vary, since your floating point formatting routines and even floating point format may be slightly different. \u2022 Auto-increment operator over signed int limit deleted This specific item has been deleted. It demonstrated how the auto-increment operator would not catch when a number went over the signed int limit. Fixed in version 5.003_04. But always be wary when using large integers. If in doubt: use Math::BigInt; \u2022 Assignment of return values from numeric equality tests doesn't work Assignment of return values from numeric equality tests does not work in perl5 when the test evaluates to false (0). Logical tests now return a null, instead of 0 $p = ($test == 1);\nprint $p,\"\\n\";\n\n# perl4 prints: 0\n# perl5 prints: Also see \"\/\/, etc.\"\" in \"General Regular Expression Traps using s for another example of this new feature... \u2022 Bitwise string ops When bitwise operators which can operate upon either numbers or strings ( \"& | ^ ~\") are given only strings as arguments, perl4 would treat the operands as bitstrings so long as the program contained a call to the \"vec()\" function. perl5 treats the string operands as bitstrings. (See \"Bitwise String Operators\" in perlop for more details.) $fred = \"10\";\n$barney = \"12\";\n$betty = $fred & $barney;\nprint \"$betty\\n\";\n# Uncomment the next line to change perl4's behavior\n# ($dummy) = vec(\"dummy\", 0, 0);\n\n# Perl4 prints:\n8\n\n# Perl5 prints:\n10\n\n# If vec() is used anywhere in the program, both print:\n10 General data type traps Perl4-to-Perl5 traps involving most data-types, and their usage within certain expressions and\/or context. \u2022 Negative array subscripts now count from the end of array Negative array subscripts now count from the end of the array. @a = (1, 2, 3, 4, 5);\nprint \"The third element of the array is $a[3] also expressed as $a[-2] \\n\";\n\n# perl4 prints: The third element of the array is 4 also expressed as\n# perl5 prints: The third element of the array is 4 also expressed as 4 \u2022 Setting $#array lower now discards array elements Setting $#array lower now discards array elements, and makes them impossible to recover. @a = (a,b,c,d,e);\nprint \"Before: \",join('',@a);\n$#a =1;\nprint \", After: \",join('',@a);\n$#a =3;\nprint \", Recovered: \",join('',@a),\"\\n\";\n\n# perl4 prints: Before: abcde, After: ab, Recovered: abcd\n# perl5 prints: Before: abcde, After: ab, Recovered: ab \u2022 Hashes get defined before use Hashes get defined before use local($s,@a,%h);\ndie \"scalar \\$s defined\" if defined($s);\ndie \"array \\@a defined\" if defined(@a);\ndie \"hash \\%h defined\" if defined(%h);\n\n# perl4 prints:\n# perl5 dies: hash %h defined Perl will now generate a warning when it sees defined(@a) and defined(%h). \u2022 Glob assignment from localized variable to variable glob assignment from variable to variable will fail if the assigned variable is localized subsequent to the assignment @a = (\"This is Perl 4\");\n*b = *a;\nlocal(@a);\nprint @b,\"\\n\";\n\n# perl4 prints: This is Perl 4\n# perl5 prints: \u2022 Assigning \"undef\" to glob Assigning \"undef\" to a glob has no effect in Perl 5. In Perl 4 it undefines the associated scalar (but may have other side effects including SEGVs). Perl 5 will also warn if \"undef\" is assigned to a typeglob. (Note that assigning \"undef\" to a typeglob is different than calling the \"undef\" function on a typeglob ( \"undef *foo\"), which has quite a few effects. $foo = \"bar\";\n*foo = undef;\nprint $foo;\n\n# perl4 prints:\n# perl4 warns: \"Use of uninitialized variable\" if using -w\n# perl5 prints: bar\n# perl5 warns: \"Undefined value assigned to typeglob\" if using -w \u2022 Changes in unary negation (of strings) Changes in unary negation (of strings) This change effects both the return value and what it does to auto(magic)increment. $x = \"aaa\";\nprint ++$x,\" : \";\nprint -$x,\" : \";\nprint ++$x,\"\\n\";\n\n# perl4 prints: aab : -0 : 1\n# perl5 prints: aab : -aab : aac \u2022 Modifying of constants prohibited perl 4 lets you modify constants: $foo = \"x\";\n&mod($foo);\nfor ($x = 0; $x < 3; $x++) {\n    &mod(\"a\");\n}\nsub mod {\n    print \"before: $_[0]\";\n    $_[0] = \"m\";\n    print \"  after: $_[0]\\n\";\n}\n\n# perl4:\n# before: x  after: m\n# before: a  after: m\n# before: m  after: m\n# before: m  after: m\n\n# Perl5:\n# before: x  after: m\n# Modification of a read-only value attempted at foo.pl line 12.\n# before: a \u2022 \"defined $var\" behavior changed The behavior is slightly different for: print \"$x\", defined $x\n\n# perl 4: 1\n# perl 5: <no output, $x is not called into existence> \u2022 Variable Suicide Variable suicide behavior is more consistent under Perl 5. Perl5 exhibits the same behavior for hashes and scalars, that perl4 exhibits for only scalars. $aGlobal{ \"aKey\" } = \"global value\";\nprint \"MAIN:\", $aGlobal{\"aKey\"}, \"\\n\";\n$GlobalLevel = 0;\n&test( *aGlobal );\n\nsub test {\n    local( *theArgument ) = @_;\n    local( %aNewLocal ); # perl 4 != 5.001l,m\n    $aNewLocal{\"aKey\"} = \"this should never appear\";\n    print \"SUB: \", $theArgument{\"aKey\"}, \"\\n\";\n    $aNewLocal{\"aKey\"} = \"level $GlobalLevel\";   # what should print\n    $GlobalLevel++;\n    if( $GlobalLevel<4 ) {\n        &test( *aNewLocal );\n    }\n}\n\n# Perl4:\n# MAIN:global value\n# SUB: global value\n# SUB: level 0\n# SUB: level 1\n# SUB: level 2\n\n# Perl5:\n# MAIN:global value\n# SUB: global value\n# SUB: this should never appear\n# SUB: this should never appear\n# SUB: this should never appear Context Traps - scalar, list contexts \u2022 Elements of argument lists for formats evaluated in list context The elements of argument lists for formats are now evaluated in list context. This means you can interpolate list values now. @fmt = (\"foo\",\"bar\",\"baz\");\nformat STDOUT=\n@<<<<< @||||| @>>>>>\n@fmt;\n.\nwrite;\n\n# perl4 errors:  Please use commas to separate fields in file\n# perl5 prints: foo     bar      baz \u2022 \"caller()\" returns false value in scalar context if no caller present The \"caller()\" function now returns a false value in a scalar context if there is no caller. This lets library files determine if they're being required. caller() ? (print \"You rang?\\n\") : (print \"Got a 0\\n\");\n\n# perl4 errors: There is no caller\n# perl5 prints: Got a 0 \u2022 Comma operator in scalar context gives scalar context to args The comma operator in a scalar context is now guaranteed to give a scalar context to its arguments. @y= ('a','b','c');\n$x = (1, 2, @y);\nprint \"x = $x\\n\";\n\n# Perl4 prints:  x = c   # Thinks list context interpolates list\n# Perl5 prints:  x = 3   # Knows scalar uses length of list \u2022 \"sprintf()\" prototyped as \"($;@)\" \"sprintf()\" is prototyped as ($;@), so its first argument is given scalar context. Thus, if passed an array, it will probably not do what you want, unlike Perl 4: @z = ('%s%s', 'foo', 'bar');\n$x = sprintf(@z);\nprint $x;\n\n# perl4 prints: foobar\n# perl5 prints: 3 \"printf()\" works the same as it did in Perl 4, though: @z = ('%s%s', 'foo', 'bar');\nprintf STDOUT (@z);\n\n# perl4 prints: foobar\n# perl5 prints: foobar Precedence Traps Perl4-to-Perl5 traps involving precedence order. Perl 4 has almost the same precedence rules as Perl 5 for the operators that they both have. Perl 4 however, seems to have had some inconsistencies that made the behavior differ from what was documented. \u2022 LHS vs. RHS of any assignment operator LHS vs. RHS of any assignment operator. LHS is evaluated first in perl4, second in perl5; this can affect the relationship between side-effects in sub-expressions. @arr = ( 'left', 'right' );\n$a{shift @arr} = shift @arr;\nprint join( ' ', keys %a );\n\n# perl4 prints: left\n# perl5 prints: right \u2022 Semantic errors introduced due to precedence These are now semantic errors because of precedence: @list = (1,2,3,4,5);\n%map = (\"a\",1,\"b\",2,\"c\",3,\"d\",4);\n$n = shift @list + 2;   # first item in list plus 2\nprint \"n is $n, \";\n$m = keys %map + 2;     # number of items in hash plus 2\nprint \"m is $m\\n\";\n\n# perl4 prints: n is 3, m is 6\n# perl5 errors and fails to compile \u2022 Precedence of assignment operators same as the precedence of assignment The precedence of assignment operators is now the same as the precedence of assignment. Perl 4 mistakenly gave them the precedence of the associated operator. So you now must parenthesize them in expressions like \/foo\/ ? ($a += 2) : ($a -= 2); Otherwise \/foo\/ ? $a += 2 : $a -= 2 would be erroneously parsed as (\/foo\/ ? $a += 2 : $a) -= 2; On the other hand, $a += \/foo\/ ? 1 : 2; now works as a C programmer would expect. \u2022 \"open\" requires parentheses around filehandle open FOO || die; is now incorrect. You need parentheses around the filehandle. Otherwise, perl5 leaves the statement as its default precedence: open(FOO || die);\n\n# perl4 opens or dies\n# perl5 opens FOO, dying only if 'FOO' is false, i.e. never \u2022 $: precedence over $:: gone perl4 gives the special variable, $: precedence, where perl5 treats $:: as main \"package\" $a = \"x\"; print \"$::a\"; # perl 4 prints: -:a # perl 5 prints: x \u2022 Precedence of file test operators documented perl4 had buggy precedence for the file test operators vis-a-vis the assignment operators. Thus, although the precedence table for perl4 leads one to believe \"-e $foo .= \"q\"\" should parse as \"((-e $foo) .= \"q\")\", it actually parses as \"(-e ($foo .= \"q\"))\". In perl5, the precedence is as documented. -e $foo .= \"q\"\n\n# perl4 prints: no output\n# perl5 prints: Can't modify -e in concatenation \u2022 \"keys\", \"each\", \"values\" are regular named unary operators In perl4, keys(), each() and values() were special high-precedence operators that operated on a single hash, but in perl5, they are regular named unary operators. As documented, named unary operators have lower precedence than the arithmetic and concatenation operators \"+ - .\", but the perl4 variants of these operators actually bind tighter than \"+ - .\". Thus, for: %foo = 1..10;\nprint keys %foo - 1\n\n# perl4 prints: 4\n# perl5 prints: Type of arg 1 to keys must be hash (not subtraction) The perl4 behavior was probably more useful, if less consistent. General Regular Expression Traps using s\/\/\/, etc. All types of RE traps. \u2022 \"s'$lhs'$rhs'\" interpolates on either side \"s'$lhs'$rhs'\" now does no interpolation on either side. It used to interpolate $lhs but not $rhs. (And still does not match a literal '$' in string) $a=1;$b=2;\n$string = '1 2 $a $b';\n$string =~ s'$a'$b';\nprint $string,\"\\n\";\n\n# perl4 prints: $b 2 $a $b\n# perl5 prints: 1 2 $a $b \u2022 \"m\/\/g\" attaches its state to the searched string \"m\/\/g\" now attaches its state to the searched string rather than the regular expression. (Once the scope of a block is left for the sub, the state of the searched string is lost) $_ = \"ababab\";\nwhile(m\/ab\/g){\n    &doit(\"blah\");\n}\nsub doit{local($_) = shift; print \"Got $_ \"}\n\n# perl4 prints: Got blah Got blah Got blah Got blah\n# perl5 prints: infinite loop blah... \u2022 \"m\/\/o\" used within an anonymous sub Currently, if you use the \"m\/\/o\" qualifier on a regular expression within an anonymous sub, all closures generated from that anonymous sub will use the regular expression as it was compiled when it was used the very first time in any such closure. For instance, if you say sub build_match {\n    my($left,$right) = @_;\n    return sub { $_[0] =~ \/$left stuff $right\/o; };\n}\n$good = build_match('foo','bar');\n$bad = build_match('baz','blarch');\nprint $good->('foo stuff bar') ? \"ok\\n\" : \"not ok\\n\";\nprint $bad->('baz stuff blarch') ? \"ok\\n\" : \"not ok\\n\";\nprint $bad->('foo stuff bar') ? \"not ok\\n\" : \"ok\\n\"; For most builds of Perl5, this will print: ok not ok not ok build_match() will always return a sub which matches the contents of $left and $right as they were the first time that build_match() was called, not as they are in the current call. \u2022 $+ isn't set to whole match If no parentheses are used in a match, Perl4 sets $+ to the whole match, just like $&. Perl5 does not. \"abcdef\" =~ \/b.*e\/;\nprint \"\\$+ = $+\\n\";\n\n# perl4 prints: bcde\n# perl5 prints: \u2022 Substitution now returns null string if it fails substitution now returns the null string if it fails $string = \"test\";\n$value = ($string =~ s\/foo\/\/);\nprint $value, \"\\n\";\n\n# perl4 prints: 0\n# perl5 prints: Also see \"Numerical Traps\" for another example of this new feature. \u2022 \"s`lhs`rhs`\" is now a normal substitution \"s`lhs`rhs`\" (using backticks) is now a normal substitution, with no backtick expansion $string = \"\";\n$string =~ s`^`hostname`;\nprint $string, \"\\n\";\n\n# perl4 prints: <the local hostname>\n# perl5 prints: hostname \u2022 Stricter parsing of variables in regular expressions Stricter parsing of variables used in regular expressions s\/^([^$grpc]*$grpc[$opt$plus$rep]?)\/\/o;\n\n# perl4: compiles w\/o error\n# perl5: with Scalar found where operator expected ..., near \"$opt$plus\" an added component of this example, apparently from the same script, is the actual value of the s'd string after the substitution. \"[$opt]\" is a character class in perl4 and an array subscript in perl5 $grpc = 'a';\n$opt  = 'r';\n$_ = 'bar';\ns\/^([^$grpc]*$grpc[$opt]?)\/foo\/;\nprint;\n\n# perl4 prints: foo\n# perl5 prints: foobar \u2022 \"m?x?\" matches only once Under perl5, \"m?x?\" matches only once, like \"?x?\". Under perl4, it matched repeatedly, like \"\/x\/\" or \"m!x!\". $test = \"once\";\nsub match { $test =~ m?once?; }\n&match();\nif( &match() ) {\n    # m?x? matches more then once\n    print \"perl4\\n\";\n} else {\n    # m?x? matches only once\n    print \"perl5\\n\";\n}\n\n# perl4 prints: perl4\n# perl5 prints: perl5 \u2022 Failed matches don't reset the match variables Unlike in Ruby, failed matches in Perl do not reset the match variables ($1, $2, ..., \"$`\", ...). Subroutine, Signal, Sorting Traps The general group of Perl4-to-Perl5 traps having to do with Signals, Sorting, and their related subroutines, as well as general subroutine traps. Includes some OS-Specific traps. \u2022 Barewords that used to look like strings look like subroutine calls Barewords that used to look like strings to Perl will now look like subroutine calls if a subroutine by that name is defined before the compiler sees them. sub SeeYa { warn\"Hasta la vista, baby!\" }\n$SIG{'TERM'} = SeeYa;\nprint \"SIGTERM is now $SIG{'TERM'}\\n\";\n\n# perl4 prints: SIGTERM is now main'SeeYa\n# perl5 prints: SIGTERM is now main::1 (and warns \"Hasta la vista, baby!\") Use -w to catch this one \u2022 Reverse is no longer allowed as the name of a sort subroutine reverse is no longer allowed as the name of a sort subroutine. sub reverse{ print \"yup \"; $a <=> $b }\nprint sort reverse (2,1,3);\n\n# perl4 prints: yup yup 123\n# perl5 prints: 123\n# perl5 warns (if using -w): Ambiguous call resolved as CORE::reverse() \u2022 \"warn()\" won't let you specify a filehandle. Although it _always_ printed to STDERR , warn() would let you specify a filehandle in perl4. With perl5 it does not. warn STDERR \"Foo!\";\n\n# perl4 prints: Foo!\n# perl5 prints: String found where operator expected OS Traps \u2022 SysV resets signal handler correctly Under HPUX , and some other SysV OSes, one had to reset any signal handler, within the signal handler function, each time a signal was handled with perl4. With perl5, the reset is now done correctly. Any code relying on the handler _not_ being reset will have to be reworked. Since version 5.002, Perl uses sigaction() under SysV. sub gotit {\n    print \"Got @_... \";\n}\n$SIG{'INT'} = 'gotit';\n\n$| = 1;\n$pid = fork;\nif ($pid) {\n    kill('INT', $pid);\n    sleep(1);\n    kill('INT', $pid);\n} else {\n    while (1) {sleep(10);}\n}\n\n# perl4 (HPUX) prints: Got INT...\n# perl5 (HPUX) prints: Got INT... Got INT... \u2022 SysV \"seek()\" appends correctly Under SysV OSes, \"seek()\" on a file opened to append \">>\" now does the right thing w.r.t. the fopen() manpage. e.g., - When a file is opened for append, it is impossible to overwrite information already in the file. open(TEST,\">>seek.test\");\n$start = tell TEST;\nforeach(1 .. 9){\n    print TEST \"$_ \";\n}\n$end = tell TEST;\nseek(TEST,$start,0);\nprint TEST \"18 characters here\";\n\n# perl4 (solaris) seek.test has: 18 characters here\n# perl5 (solaris) seek.test has: 1 2 3 4 5 6 7 8 9 18 characters here Interpolation Traps Perl4-to-Perl5 traps having to do with how things get interpolated within certain expressions, statements, contexts, or whatever. \u2022 \"@\" always interpolates an array in double-quotish strings @ now always interpolates an array in double-quotish strings. print \"To: someone@somewhere.com\\n\";\n\n# perl4 prints: To:someone@somewhere.com\n# perl < 5.6.1, error : In string, @somewhere now must be written as \\@somewhere\n# perl >= 5.6.1, warning : Possible unintended interpolation of @somewhere in string \u2022 Double-quoted strings may no longer end with an unescaped $ Double-quoted strings may no longer end with an unescaped $. $foo = \"foo$\";\nprint \"foo is $foo\\n\";\n\n# perl4 prints: foo is foo$\n# perl5 errors: Final $ should be \\$ or $name Note: perl5 DOES NOT error on the terminating @ in $bar \u2022 Arbitrary expressions are evaluated inside braces within double quotes Perl now sometimes evaluates arbitrary expressions inside braces that occur within double quotes (usually when the opening brace is preceded by \"$\" or \"@\"). @www = \"buz\";\n$foo = \"foo\";\n$bar = \"bar\";\nsub foo { return \"bar\" };\nprint \"|@{w.w.w}|${main'foo}|\";\n\n# perl4 prints: |@{w.w.w}|foo|\n# perl5 prints: |buz|bar| Note that you can \"use strict;\" to ward off such trappiness under perl5. \u2022 $$x now tries to dereference $x The construct \"this is $$x\" used to interpolate the pid at that point, but now tries to dereference $x. $$ by itself still works fine, however. $s = \"a reference\";\n$x = *s;\nprint \"this is $$x\\n\";\n\n# perl4 prints: this is XXXx   (XXX is the current pid)\n# perl5 prints: this is a reference \u2022 Creation of hashes on the fly with \"eval \"EXPR\"\" requires protection Creation of hashes on the fly with \"eval \"EXPR\"\" now requires either both \"$\"'s to be protected in the specification of the hash name, or both curlies to be protected. If both curlies are protected, the result will be compatible with perl4 and perl5. This is a very common practice, and should be changed to use the block form of \"eval{}\" if possible. $hashname = \"foobar\";\n$key = \"baz\";\n$value = 1234;\neval \"\\$$hashname{'$key'} = q|$value|\";\n(defined($foobar{'baz'})) ?  (print \"Yup\") : (print \"Nope\");\n\n# perl4 prints: Yup\n# perl5 prints: Nope Changing eval \"\\$$hashname{'$key'} = q|$value|\"; to eval \"\\$\\$hashname{'$key'} = q|$value|\"; causes the following result: # perl4 prints: Nope\n# perl5 prints: Yup or, changing to eval \"\\$$hashname\\{'$key'\\} = q|$value|\"; causes the following result: # perl4 prints: Yup\n# perl5 prints: Yup\n# and is compatible for both versions \u2022 Bugs in earlier perl versions perl4 programs which unconsciously rely on the bugs in earlier perl versions. perl -e '$bar=q\/not\/; print \"This is $foo{$bar} perl5\"'\n\n# perl4 prints: This is not perl5\n# perl5 prints: This is perl5 \u2022 Array and hash brackets during interpolation You also have to be careful about array and hash brackets during interpolation. print \"$foo[\"\n\nperl 4 prints: [\nperl 5 prints: syntax error\n\nprint \"$foo{\"\n\nperl 4 prints: {\nperl 5 prints: syntax error Perl 5 is expecting to find an index or key name following the respective brackets, as well as an ending bracket of the appropriate type. In order to mimic the behavior of Perl 4, you must escape the bracket like so. print \"$foo\\[\";\nprint \"$foo\\{\"; \u2022 Interpolation of \"\\$$foo{bar}\" Similarly, watch out for: \"\\$$foo{bar}\" $foo = \"baz\"; print \"\\$$foo{bar}\\n\"; # perl4 prints: $baz{bar} # perl5 prints: $ Perl 5 is looking for $foo{bar} which doesn't exist, but perl 4 is happy just to expand $foo to \"baz\" by itself. Watch out for this especially in \"eval\"'s. \u2022 \"qq()\" string passed to \"eval\" will not find string terminator \"qq()\" string passed to \"eval\" eval qq( foreach \\$y (keys %\\$x\\) { \\$count++; } ); # perl4 runs this ok # perl5 prints: Can't find string terminator \")\" DBM Traps General DBM traps. \u2022 Perl5 must have been linked with same dbm\/ndbm as the default for \"dbmopen()\" Existing dbm databases created under perl4 (or any other dbm\/ndbm tool) may cause the same script, run under perl5, to fail. The build of perl5 must have been linked with the same dbm\/ndbm as the default for \"dbmopen()\" to function properly without \"tie\"'ing to an extension dbm implementation. dbmopen (%dbm, \"file\", undef);\nprint \"ok\\n\";\n\n# perl4 prints: ok\n# perl5 prints: ok (IFF linked with -ldbm or -lndbm) \u2022 DBM exceeding limit on the key\/value size will cause perl5 to exit immediately Existing dbm databases created under perl4 (or any other dbm\/ndbm tool) may cause the same script, run under perl5, to fail. The error generated when exceeding the limit on the key\/value size will cause perl5 to exit immediately. dbmopen(DB, \"testdb\",0600) || die \"couldn't open db! $!\";\n$DB{'trap'} = \"x\" x 1024;  # value too large for most dbm\/ndbm\nprint \"YUP\\n\";\n\n# perl4 prints:\ndbm store returned -1, errno 28, key \"trap\" at - line 3.\nYUP\n\n# perl5 prints:\ndbm store returned -1, errno 28, key \"trap\" at - line 3. Unclassified Traps Everything else. \u2022 \"require\"\/ \"do\" trap using returned value If the file doit.pl has: sub foo {\n    $rc = do \".\/do.pl\";\n    return 8;\n}\nprint &foo, \"\\n\"; And the do.pl file has the following single line: return 3; Running doit.pl gives the following: # perl 4 prints: 3 (aborts the subroutine early)\n# perl 5 prints: 8 Same behavior if you replace \"do\" with \"require\". \u2022 \"split\" on empty string with LIMIT specified $string = '';\n@list = split(\/foo\/, $string, 2) Perl4 returns a one element list containing the empty string but Perl5 returns an empty list. As always, if any of these are ever officially declared as bugs, they'll be fixed and removed.","Process Name":"perltrap","Link":"https:\/\/linux.die.net\/man\/1\/perltrap"}},{"Process":{"Description":"This document describes various features of HP 's (formerly Compaq's, formerly Digital's) Unix operating system (Tru64) that will affect how Perl version 5 (hereafter just Perl) is configured, compiled and\/or runs. Compiling Perl 5 on Tru64 The recommended compiler to use in Tru64 is the native C compiler. The native compiler produces much faster code (the speed difference is noticeable: several dozen percentages) and also more correct code: if you are considering using the GNU C compiler you should use at the very least the release of 2.95.3 since all older gcc releases are known to produce broken code when compiling Perl. One manifestation of this brokenness is the lib\/sdbm test dumping core; another is many of the op\/regexp and op\/pat, or ext\/Storable tests dumping core (the exact pattern of failures depending on the GCC release and optimization flags). gcc 3.2.1 is known to work okay with Perl 5.8.0. However, when optimizing the toke.c gcc likes to have a lot of memory, 256 megabytes seems to be enough. The default setting of the process data section in Tru64 should be one gigabyte, but some sites\/setups might have lowered that. The configuration process of Perl checks for too low process limits, and lowers the optimization for the toke.c if necessary, and also gives advice on how to raise the process limits. Also, Configure might abort with Build a threading Perl? [n]\nConfigure[2437]: Syntax error at line 1 : `config.sh' is not expected. This indicates that Configure is being run with a broken Korn shell (even though you think you are using a Bourne shell by using \"sh Configure\" or \".\/Configure\"). The Korn shell bug has been reported to Compaq as of February 1999 but in the meanwhile, the reason ksh is being used is that you have the environment variable BIN_SH set to 'xpg4'. This causes \/bin\/sh to delegate its duties to \/bin\/posix\/sh (a ksh). Unset the environment variable and rerun Configure. Using Large Files with Perl on Tru64 In Tru64 Perl is automatically able to use large files, that is, files larger than 2 gigabytes, there is no need to use the Configure -Duselargefiles option as described in INSTALL (though using the option is harmless). Threaded Perl on Tru64 If you want to use threads, you should primarily use the Perl 5.8.0 threads model by running Configure with -Duseithreads. Perl threading is going to work only in Tru64 4.0 and newer releases, older operating releases like 3.2 aren't probably going to work properly with threads. In Tru64 V5 (at least V5.1A, V5.1B) you cannot build threaded Perl with gcc because the system header <pthread.h> explicitly checks for supported C compilers, gcc (at least 3.2.2) not being one of them. But the system C compiler should work just fine. Long Doubles on Tru64 You cannot Configure Perl to use long doubles unless you have at least Tru64 V5.0, the long double support simply wasn't functional enough before that. Perl's Configure will override attempts to use the long doubles (you can notice this by Configure finding out that the modfl() function does not work as it should). At the time of this writing (June 2002), there is a known bug in the Tru64 libc printing of long doubles when not using \"e\" notation. The values are correct and usable, but you only get a limited number of digits displayed unless you force the issue by using \"printf \"%.33e\",$num\" or the like. For Tru64 versions V5.0A through V5.1A, a patch is expected sometime after perl 5.8.0 is released. If your libc has not yet been patched, you'll get a warning from Configure when selecting long doubles. DB_File tests failing on Tru64 The DB_File tests (db-btree.t, db-hash.t, db-recno.t) may fail you have installed a newer version of Berkeley DB into the system and the -I and -L compiler and linker flags introduce version conflicts with the DB 1.85 headers and libraries that came with the Tru64. For example, mixing a DB v2 library with the DB v1 headers is a bad idea. Watch out for Configure options -Dlocincpth and -Dloclibpth, and check your \/usr\/local\/include and \/usr\/local\/lib since they are included by default. The second option is to explicitly instruct Configure to detect the newer Berkeley DB installation, by supplying the right directories with \"-Dlocincpth=\/some\/include\" and \"-Dloclibpth=\/some\/lib\" and before running \"make test\" setting your LD_LIBRARY_PATH to \/some\/lib. The third option is to work around the problem by disabling the DB_File completely when build Perl by specifying -Ui_db to Configure, and then using the BerkeleyDB module from CPAN instead of DB_File. The BerkeleyDB works with Berkeley DB versions 2.* or greater. The Berkeley DB 4.1.25 has been tested with Tru64 V5.1A and found to work. The latest Berkeley DB can be found from http:\/\/www.sleepycat.com. 64-bit Perl on Tru64 In Tru64 Perl's integers are automatically 64-bit wide, there is no need to use the Configure -Duse64bitint option as described in INSTALL . Similarly, there is no need for -Duse64bitall since pointers are automatically 64-bit wide. Warnings about floating-point overflow when compiling Perl on Tru64 When compiling Perl in Tru64 you may (depending on the compiler release) see two warnings like this cc: Warning: numeric.c, line 104: In this statement, floating-point overflow occurs in evaluating the expression \"1.8e308\". (floatoverfl)\n    return HUGE_VAL;\n-----------^ and when compiling the POSIX extension cc: Warning: const-c.inc, line 2007: In this statement, floating-point overflow occurs in evaluating the expression \"1.8e308\". (floatoverfl)\n            return HUGE_VAL;\n-------------------^ The exact line numbers may vary between Perl releases. The warnings are benign and can be ignored: in later C compiler releases the warnings should be gone. When the file pp_sys.c is being compiled you may (depending on the operating system release) see an additional compiler flag being used: \"-DNO_EFF_ONLY_OK\". This is normal and refers to a feature that is relevant only if you use the \"filetest\" pragma. In older releases of the operating system the feature was broken and the NO_EFF_ONLY_OK instructs Perl not to use the feature.","Process Name":"perltru64","Link":"https:\/\/linux.die.net\/man\/1\/perltru64"}},{"Process":{"Description":"XXXXXXXXX Perl XXXXXXX ! XX 5.8.0 XXXXXXXX , Perl XXXXXXXXXXXXXXX Unicode ( XXXXXXX ) XXXXX , XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX ; CJK ( XXXXXX ) XXXXXXXXXXXXXXXX . Unicode XXXXXXXXXXXXXXXXX , XXXXXXXXXXXXXXXXXXXXXXXXXXXX: XXXXXXXXX , XXXXXXXXXX , XXXXXXXXXXXXXXXXXXXX ( XXXXXXXX , XXXXXXXXXXX , XXXXXXXXX , XXXXXXXXX , XXXXXXX , XXXXXXXXXX , XXXX ). XXXXXXXXXXXXXXXXXXXXXXXXXXX ( XX PC XXXXXXXXX ). Perl XXXXXX Unicode XXXXXXXXXX . XXXXXX Perl XXXXXXXXXXXXXXXXXXXXX Unicode XXX ; Perl XXXXXXXXXXXXXXX ( XXXXXXXXXXXXXXXXX ) XXXXXXX Unicode XXXXXXXXXX . XXXXXXXXXXXXXXX , XXXXXXXXXXXXX Unicode XXXXXXXXXXXXXXXXXXXXXXXXXXXXX , Perl XXXXXXX Encode XXXXXXXXXX , XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX . Encode XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX ('big5' XXX 'big5-eten'): big5-eten   Big5 XXX (XXXXXXXXXXXXXX)\nbig5-hkscs  Big5 + XXXXXXXXXXX, 2001 XXXX\ncp950       XXXXXX 950 (Big5 + XXXXXXXXXXXXXXX) XXXXXXXXX , XX Big5 XXXXXXXXXXXXXXX Unicode, XXXXXXXXXXXXXXXXXXXX: perl -Mencoding=big5,STDOUT,utf8 -pe1 < file.big5 > file.utf8 Perl XXXXXXXXX \"piconv\", XXXXXXXXXXX Perl XXXXXXXXXXXXXXXXXXXXXXXX , XXXXXXXXX: piconv -f big5 -t utf8 < file.big5 > file.utf8\npiconv -f utf8 -t big5 < file.utf8 > file.big5 XXXXX , XXXXX encoding XXXX , XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX , XXXXXXXXX: #!\/usr\/bin\/env perl\n# XXXXXX big5 XXXXXXXX; XXXXXXXXXXXXXXXXXXXXXXXXXXX big5 XXX\nuse encoding 'big5', STDIN => 'big5', STDOUT => 'big5';\nprint length(\"XXXX\");            #  2 (XXXXXXXXXXXXXXX)\nprint length('XXXX');            #  4 (XXXXXXXXXXXXXXXXXX)\nprint index(\"XXXXXXXXX\", \"XXXX\"); # -1 (XXXXXXXXXXXXXXX)\nprint index('XXXXXXXXX', 'XXXX'); #  1 (XXXXXXXXXXXXXXXXXXXXX) XXXXXXXXXXXXXXXXXX , \" XX \" XXXXXXXXXXXXXXXXXXXX \" XX \" XXXXXXXXXXXXXXXXXXXXXXXXX Big5 XXXX \" XX \"; \" XX \" XXXXXXXXXXXXXXXXXXXXXXX \" XXX \" XXXXXXXXXXXXXXXXXXXXXXXXX \" XX \". XXXXXXXXXXXXX Big5 XXXXXXXXXXXXXXXXXXXXXXXXXX . XXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXX , XXXXXX CPAN (< http:\/\/www.cpan.org\/>) XXXX Encode::HanExtra XXXX . XXXXXXXXXXXXXXXXXXXXXXXXX: cccii       1980 XXXXXXXXXXXXXXXXXXXXXXXX\neuc-tw      Unix XXXXXXXXX, XXXXXX CNS11643 XXXX 1-7\nbig5plus    XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Big5+\nbig5ext     XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Big5e XXXXX , Encode::HanConvert XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX: big5-simp   Big5 XXXXXXXXXXX Unicode XXXXXXXXXXXX\ngbk-trad    GBK XXXXXXXXXXX Unicode XXXXXXXXXXXX XXXXXXX GBK XXX Big5 XXXXXXXXX , XXXXXXXXXXXXXXXXXXXXX b2g.pl XXX g2b.pl XXXXXXXXX , XXXXXXXXXXXXXXXXXXXXXXXXXX: use Encode::HanConvert;\n$euc_cn = big5_to_gb($big5); # XX Big5 XXXXX GBK\n$big5 = gb_to_big5($euc_cn); # XX GBK XXXXX Big5 XXXXXXXXXXXXX XXXXXXXX Perl XXXXXXXXXXXXXXXXXXXXX ( XXXXXXXXXXXXXXXXXX ), XXXXXXXXXXXXXXXX Perl XXXXXXXX , XXXX Unicode XXXXXXXXXXX . XXXXX , XXXXXXXXXXXXXXXXXXXX: XXXXX Perl XXXXXXXXXXX < http:\/\/www.perl.com\/> Perl XXXXXXXX ( XXXXXXXXXXXXXXXXX ) < http:\/\/www.cpan.org\/> Perl XXXXXXXXXXXX (Comprehensive Perl Archive Network) < http:\/\/lists.perl.org\/> Perl XXXXXXXXXXXX XXXX Perl XXXXXXX < http:\/\/www.oreilly.com.tw\/chinese\/perl\/index.html> XXXXXXXXXXXXXXXXXXXXX Perl XXXXX < http:\/\/groups.google.com\/groups?q=tw.bbs.comp.lang.perl> XXXXX Perl XXXXXXXXXXXX ( XXXXXXXXXX BBS XXX Perl XXXXXXXX ) Perl XXXXXXXXXXXX < http:\/\/www.pm.org\/groups\/asia.html> XXXXX Perl XXXXXXXXX < http:\/\/irc.elixus.org\/> XXXXXXXXXXXXXXXXXX Unicode XXXXXXXXX < http:\/\/www.unicode.org\/> Unicode XXXXXXXX (Unicode XXXXXXXXXXXXXXX ) < http:\/\/www.cl.cam.ac.uk\/%7Emgk25\/unicode.html> Unix\/Linux XXXXX UTF-8 XXX Unicode XXXXXX XXXXXXXXXXX XXXXXXXXX \" XXXXXXXX \" XXXXX \" XXXXXXXX \"? < http:\/\/www.csie.ntu.edu.tw\/~b7506051\/mozilla\/faq.html#faqglossary> XXXXXXXXXXXXXXXX < http:\/\/www.cpatch.org\/> Linux XXXXXXXXXXXXXXXX < http:\/\/www.linux.org.tw\/CLDP\/>","Process Name":"perltw","Link":"https:\/\/linux.die.net\/man\/1\/perltw"}},{"Process":{"Description":"Important Caveats Unicode support is an extensive requirement. While Perl does not implement the Unicode standard or the accompanying technical reports from cover to cover, Perl does support many Unicode features. People who want to learn to use Unicode in Perl, should probably read the Perl Unicode tutorial, perlunitut, before reading this reference document. Input and Output Layers Perl knows when a filehandle uses Perl's internal Unicode encodings ( UTF-8 , or UTF-EBCDIC if in EBCDIC ) if the filehandle is opened with the \":utf8\" layer. Other encodings can be converted to Perl's encoding on input or from Perl's encoding on output by use of the \":encoding(...)\" layer. See open. To indicate that Perl source itself is in UTF-8 , use \"use utf8;\". Regular Expressions The regular expression compiler produces polymorphic opcodes. That is, the pattern adapts to the data and automatically switches to the Unicode character scheme when presented with data that is internally encoded in UTF-8 -- or instead uses a traditional byte scheme when presented with byte data. \"use utf8\" still needed to enable UTF-8\/UTF-EBCDIC in scripts As a compatibility measure, the \"use utf8\" pragma must be explicitly included to enable recognition of UTF-8 in the Perl scripts themselves (in string or regular expression literals, or in identifier names) on ASCII-based machines or to recognize UTF-EBCDIC on EBCDIC-based machines. These are the only times when an explicit \"use utf8\" is needed. See utf8. BOM-marked scripts and UTF-16 scripts autodetected If a Perl script begins marked with the Unicode BOM ( UTF-16LE , UTF16-BE , or UTF-8 ), or if the script looks like non-BOM-marked UTF-16 of either endianness, Perl will correctly read in the script as Unicode. (BOMless UTF-8 cannot be effectively recognized or differentiated from ISO 8859-1 or other eight-bit encodings.) \"use encoding\" needed to upgrade non-Latin-1 byte strings By default, there is a fundamental asymmetry in Perl's Unicode model: implicit upgrading from byte strings to Unicode strings assumes that they were encoded in ISO 8859-1 (Latin-1), but Unicode strings are downgraded with UTF-8 encoding. This happens because the first 256 codepoints in Unicode happens to agree with Latin-1. See \"Byte and Character Semantics\" for more details. Byte and Character Semantics Beginning with version 5.6, Perl uses logically-wide characters to represent strings internally. In future, Perl-level operations will be expected to work with characters rather than bytes. However, as an interim compatibility measure, Perl aims to provide a safe migration path from byte semantics to character semantics for programs. For operations where Perl can unambiguously decide that the input data are characters, Perl switches to character semantics. For operations where this determination cannot be made without additional information from the user, Perl decides in favor of compatibility and chooses to use byte semantics. Under byte semantics, when \"use locale\" is in effect, Perl uses the semantics associated with the current locale. Absent a \"use locale\", Perl currently uses US-ASCII (or Basic Latin in Unicode terminology) byte semantics, meaning that characters whose ordinal numbers are in the range 128 - 255 are undefined except for their ordinal numbers. This means that none have case (upper and lower), nor are any a member of character classes, like \"[:alpha:]\" or \"\\w\". (But all do belong to the \"\\W\" class or the Perl regular expression extension \"[:^alpha:]\".) This behavior preserves compatibility with earlier versions of Perl, which allowed byte semantics in Perl operations only if none of the program's inputs were marked as being as source of Unicode character data. Such data may come from filehandles, from calls to external programs, from information provided by the system (such as %ENV), or from literals and constants in the source text. The \"bytes\" pragma will always, regardless of platform, force byte semantics in a particular lexical scope. See bytes. The \"utf8\" pragma is primarily a compatibility device that enables recognition of UTF- (8|EBCDIC) in literals encountered by the parser. Note that this pragma is only required while Perl defaults to byte semantics; when character semantics become the default, this pragma may become a no-op. See utf8. Unless explicitly stated, Perl operators use character semantics for Unicode data and byte semantics for non-Unicode data. The decision to use character semantics is made transparently. If input data comes from a Unicode source--for example, if a character encoding layer is added to a filehandle or a literal Unicode string constant appears in a program--character semantics apply. Otherwise, byte semantics are in effect. The \"bytes\" pragma should be used to force byte semantics on Unicode data. If strings operating under byte semantics and strings with Unicode character data are concatenated, the new string will have character semantics. This can cause surprises: See \" BUGS \", below Under character semantics, many operations that formerly operated on bytes now operate on characters. A character in Perl is logically just a number ranging from 0 to 2**31 or so. Larger characters may encode into longer sequences of bytes internally, but this internal detail is mostly hidden for Perl code. See perluniintro for more. Effects of Character Semantics Character semantics have the following effects: \u2022 Strings--including hash keys--and regular expression patterns may contain characters that have an ordinal value larger than 255. If you use a Unicode editor to edit your program, Unicode characters may occur directly within the literal strings in UTF-8 encoding, or UTF-16 . (The former requires a BOM or \"use utf8\", the latter requires a BOM .) Unicode characters can also be added to a string by using the \"\\x{...}\" notation. The Unicode code for the desired character, in hexadecimal, should be placed in the braces. For instance, a smiley face is \"\\x{263A}\". This encoding scheme works for all characters, but for characters under 0x100, note that Perl may use an 8 bit encoding internally, for optimization and\/or backward compatibility. Additionally, if you use charnames ':full'; you can use the \"\\N{...}\" notation and put the official Unicode character name within the braces, such as \"\\N{WHITE SMILING FACE}\". \u2022 If an appropriate encoding is specified, identifiers within the Perl script may contain Unicode alphanumeric characters, including ideographs. Perl does not currently attempt to canonicalize variable names. \u2022 Regular expressions match characters instead of bytes. \".\" matches a character instead of a byte. \u2022 Character classes in regular expressions match characters instead of bytes and match against the character properties specified in the Unicode properties database. \"\\w\" can be used to match a Japanese ideograph, for instance. \u2022 Named Unicode properties, scripts, and block ranges may be used like character classes via the \"\\p{}\" \"matches property\" construct and the \"\\P{}\" negation, \"doesn't match property\". See \"Unicode Character Properties\" for more details. You can define your own character properties and use them in the regular expression with the \"\\p{}\" or \"\\P{}\" construct. See \"User-Defined Character Properties\" for more details. \u2022 The special pattern \"\\X\" matches any extended Unicode sequence--\"a combining character sequence\" in Standardese--where the first character is a base character and subsequent characters are mark characters that apply to the base character. \"\\X\" is equivalent to \"(?>\\PM\\pM*)\". \u2022 The \"tr\/\/\/\" operator translates characters instead of bytes. Note that the \"tr\/\/\/CU\" functionality has been removed. For similar functionality see pack('U0', ...) and pack('C0', ...). \u2022 Case translation operators use the Unicode case translation tables when character input is provided. Note that \"uc()\", or \"\\U\" in interpolated strings, translates to uppercase, while \"ucfirst\", or \"\\u\" in interpolated strings, translates to titlecase in languages that make the distinction. \u2022 Most operators that deal with positions or lengths in a string will automatically switch to using character positions, including \"chop()\", \"chomp()\", \"substr()\", \"pos()\", \"index()\", \"rindex()\", \"sprintf()\", \"write()\", and \"length()\". An operator that specifically does not switch is \"vec()\". Operators that really don't care include operators that treat strings as a bucket of bits such as \"sort()\", and operators dealing with filenames. \u2022 The \"pack()\"\/\"unpack()\" letter \"C\" does not change, since it is often used for byte-oriented formats. Again, think \"char\" in the C language. There is a new \"U\" specifier that converts between Unicode characters and code points. There is also a \"W\" specifier that is the equivalent of \"chr\"\/ \"ord\" and properly handles character values even if they are above 255. \u2022 The \"chr()\" and \"ord()\" functions work on characters, similar to \"pack(\"W\")\" and \"unpack(\"W\")\", not \"pack(\"C\")\" and \"unpack(\"C\")\". \"pack(\"C\")\" and \"unpack(\"C\")\" are methods for emulating byte-oriented \"chr()\" and \"ord()\" on Unicode strings. While these methods reveal the internal encoding of Unicode strings, that is not something one normally needs to care about at all. \u2022 The bit string operators, \"& | ^ ~\", can operate on character data. However, for backward compatibility, such as when using bit string operations when characters are all less than 256 in ordinal value, one should not use \"~\" (the bit complement) with characters of both values less than 256 and values greater than 256. Most importantly, DeMorgan's laws (\"~($x|$y) eq ~$x&~$y\" and \"~($x&$y) eq ~$x|~$y\") will not hold. The reason for this mathematical faux pas is that the complement cannot return both the 8-bit (byte-wide) bit complement and the full character-wide bit complement. \u2022 lc(), uc(), lcfirst(), and ucfirst() work for the following cases: \u2022 the case mapping is from a single Unicode character to another single Unicode character, or \u2022 the case mapping is from a single Unicode character to more than one Unicode character. Things to do with locales (Lithuanian, Turkish, Azeri) do not work since Perl does not understand the concept of Unicode locales. See the Unicode Technical Report #21, Case Mappings, for more details. But you can also define your own mappings to be used in the lc(), lcfirst(), uc(), and ucfirst() (or their string-inlined versions). See \"User-Defined Case Mappings\" for more details. \u2022 And finally, \"scalar reverse()\" reverses by character rather than by byte. Unicode Character Properties Named Unicode properties, scripts, and block ranges may be used like character classes via the \"\\p{}\" \"matches property\" construct and the \"\\P{}\" negation, \"doesn't match property\". For instance, \"\\p{Lu}\" matches any character with the Unicode \"Lu\" (Letter, uppercase) property, while \"\\p{M}\" matches any character with an \"M\" (mark--accents and such) property. Brackets are not required for single letter properties, so \"\\p{M}\" is equivalent to \"\\pM\". Many predefined properties are available, such as \"\\p{Mirrored}\" and \"\\p{Tibetan}\". The official Unicode script and block names have spaces and dashes as separators, but for convenience you can use dashes, spaces, or underbars, and case is unimportant. It is recommended, however, that for consistency you use the following naming: the official Unicode script, property, or block name (see below for the additional rules that apply to block names) with whitespace and dashes removed, and the words \"uppercase-first-lowercase-rest\". \"Latin-1 Supplement\" thus becomes \"Latin1Supplement\". You can also use negation in both \"\\p{}\" and \"\\P{}\" by introducing a caret (^) between the first brace and the property name: \"\\p{^Tamil}\" is equal to \"\\P{Tamil}\". NOTE: the properties, scripts, and blocks listed here are as of Unicode 5.0.0 in July 2006. General Category Here are the basic Unicode General Category properties, followed by their long form. You can use either; \"\\p{Lu}\" and \"\\p{UppercaseLetter}\", for instance, are identical. Short       Long\n\nL           Letter\nLC          CasedLetter\nLu          UppercaseLetter\nLl          LowercaseLetter\nLt          TitlecaseLetter\nLm          ModifierLetter\nLo          OtherLetter\n\nM           Mark\nMn          NonspacingMark\nMc          SpacingMark\nMe          EnclosingMark\n\nN           Number\nNd          DecimalNumber\nNl          LetterNumber\nNo          OtherNumber\n\nP           Punctuation\nPc          ConnectorPunctuation\nPd          DashPunctuation\nPs          OpenPunctuation\nPe          ClosePunctuation\nPi          InitialPunctuation\n            (may behave like Ps or Pe depending on usage)\nPf          FinalPunctuation\n            (may behave like Ps or Pe depending on usage)\nPo          OtherPunctuation\n\nS           Symbol\nSm          MathSymbol\nSc          CurrencySymbol\nSk          ModifierSymbol\nSo          OtherSymbol\n\nZ           Separator\nZs          SpaceSeparator\nZl          LineSeparator\nZp          ParagraphSeparator\n\nC           Other\nCc          Control\nCf          Format\nCs          Surrogate   (not usable)\nCo          PrivateUse\nCn          Unassigned Single-letter properties match all characters in any of the two-letter sub-properties starting with the same letter. \"LC\" and \"L&\" are special cases, which are aliases for the set of \"Ll\", \"Lu\", and \"Lt\". Because Perl hides the need for the user to understand the internal representation of Unicode characters, there is no need to implement the somewhat messy concept of surrogates. \"Cs\" is therefore not supported. Bidirectional Character Types Because scripts differ in their directionality--Hebrew is written right to left, for example--Unicode supplies these properties in the BidiClass class: Property    Meaning\n\nL           Left-to-Right\nLRE         Left-to-Right Embedding\nLRO         Left-to-Right Override\nR           Right-to-Left\nAL          Right-to-Left Arabic\nRLE         Right-to-Left Embedding\nRLO         Right-to-Left Override\nPDF         Pop Directional Format\nEN          European Number\nES          European Number Separator\nET          European Number Terminator\nAN          Arabic Number\nCS          Common Number Separator\nNSM         Non-Spacing Mark\nBN          Boundary Neutral\nB           Paragraph Separator\nS           Segment Separator\nWS          Whitespace\nON          Other Neutrals For example, \"\\p{BidiClass:R}\" matches characters that are normally written right to left. Scripts The script names which can be used by \"\\p{...}\" and \"\\P{...}\", such as in \"\\p{Latin}\" or \"\\p{Cyrillic}\", are as follows: Arabic\nArmenian\nBalinese\nBengali\nBopomofo\nBraille\nBuginese\nBuhid\nCanadianAboriginal\nCherokee\nCoptic\nCuneiform\nCypriot\nCyrillic\nDeseret\nDevanagari\nEthiopic\nGeorgian\nGlagolitic\nGothic\nGreek\nGujarati\nGurmukhi\nHan\nHangul\nHanunoo\nHebrew\nHiragana\nInherited\nKannada\nKatakana\nKharoshthi\nKhmer\nLao\nLatin\nLimbu\nLinearB\nMalayalam\nMongolian\nMyanmar\nNewTaiLue\nNko\nOgham\nOldItalic\nOldPersian\nOriya\nOsmanya\nPhagsPa\nPhoenician\nRunic\nShavian\nSinhala\nSylotiNagri\nSyriac\nTagalog\nTagbanwa\nTaiLe\nTamil\nTelugu\nThaana\nThai\nTibetan\nTifinagh\nUgaritic\nYi Extended property classes Extended property classes can supplement the basic properties, defined by the PropList Unicode database: ASCIIHexDigit\nBidiControl\nDash\nDeprecated\nDiacritic\nExtender\nHexDigit\nHyphen\nIdeographic\nIDSBinaryOperator\nIDSTrinaryOperator\nJoinControl\nLogicalOrderException\nNoncharacterCodePoint\nOtherAlphabetic\nOtherDefaultIgnorableCodePoint\nOtherGraphemeExtend\nOtherIDStart\nOtherIDContinue\nOtherLowercase\nOtherMath\nOtherUppercase\nPatternSyntax\nPatternWhiteSpace\nQuotationMark\nRadical\nSoftDotted\nSTerm\nTerminalPunctuation\nUnifiedIdeograph\nVariationSelector\nWhiteSpace and there are further derived properties: Alphabetic  =  Lu + Ll + Lt + Lm + Lo + Nl + OtherAlphabetic\nLowercase   =  Ll + OtherLowercase\nUppercase   =  Lu + OtherUppercase\nMath        =  Sm + OtherMath\n\nIDStart     =  Lu + Ll + Lt + Lm + Lo + Nl + OtherIDStart\nIDContinue  =  IDStart + Mn + Mc + Nd + Pc + OtherIDContinue\n\nDefaultIgnorableCodePoint\n            =  OtherDefaultIgnorableCodePoint\n               + Cf + Cc + Cs + Noncharacters + VariationSelector\n               - WhiteSpace - FFF9..FFFB (Annotation Characters)\n\nAny         =  Any code points (i.e. U+0000 to U+10FFFF)\nAssigned    =  Any non-Cn code points (i.e. synonym for \\P{Cn})\nUnassigned  =  Synonym for \\p{Cn}\nASCII       =  ASCII (i.e. U+0000 to U+007F)\n\nCommon      =  Any character (or unassigned code point)\n               not explicitly assigned to a script Use of \"Is\" Prefix For backward compatibility (with Perl 5.6), all properties mentioned so far may have \"Is\" prepended to their name, so \"\\P{IsLu}\", for example, is equal to \"\\P{Lu}\". Blocks In addition to scripts, Unicode also defines blocks of characters. The difference between scripts and blocks is that the concept of scripts is closer to natural languages, while the concept of blocks is more of an artificial grouping based on groups of 256 Unicode characters. For example, the \"Latin\" script contains letters from many blocks but does not contain all the characters from those blocks. It does not, for example, contain digits, because digits are shared across many scripts. Digits and similar groups, like punctuation, are in a category called \"Common\". For more about scripts, see the UAX#24 \"Script Names\": http:\/\/www.unicode.org\/reports\/tr24\/ For more about blocks, see: http:\/\/www.unicode.org\/Public\/UNIDATA\/Blocks.txt Block names are given with the \"In\" prefix. For example, the Katakana block is referenced via \"\\p{InKatakana}\". The \"In\" prefix may be omitted if there is no naming conflict with a script or any other property, but it is recommended that \"In\" always be used for block tests to avoid confusion. These block names are supported: InAegeanNumbers\nInAlphabeticPresentationForms\nInAncientGreekMusicalNotation\nInAncientGreekNumbers\nInArabic\nInArabicPresentationFormsA\nInArabicPresentationFormsB\nInArabicSupplement\nInArmenian\nInArrows\nInBalinese\nInBasicLatin\nInBengali\nInBlockElements\nInBopomofo\nInBopomofoExtended\nInBoxDrawing\nInBraillePatterns\nInBuginese\nInBuhid\nInByzantineMusicalSymbols\nInCJKCompatibility\nInCJKCompatibilityForms\nInCJKCompatibilityIdeographs\nInCJKCompatibilityIdeographsSupplement\nInCJKRadicalsSupplement\nInCJKStrokes\nInCJKSymbolsAndPunctuation\nInCJKUnifiedIdeographs\nInCJKUnifiedIdeographsExtensionA\nInCJKUnifiedIdeographsExtensionB\nInCherokee\nInCombiningDiacriticalMarks\nInCombiningDiacriticalMarksSupplement\nInCombiningDiacriticalMarksforSymbols\nInCombiningHalfMarks\nInControlPictures\nInCoptic\nInCountingRodNumerals\nInCuneiform\nInCuneiformNumbersAndPunctuation\nInCurrencySymbols\nInCypriotSyllabary\nInCyrillic\nInCyrillicSupplement\nInDeseret\nInDevanagari\nInDingbats\nInEnclosedAlphanumerics\nInEnclosedCJKLettersAndMonths\nInEthiopic\nInEthiopicExtended\nInEthiopicSupplement\nInGeneralPunctuation\nInGeometricShapes\nInGeorgian\nInGeorgianSupplement\nInGlagolitic\nInGothic\nInGreekExtended\nInGreekAndCoptic\nInGujarati\nInGurmukhi\nInHalfwidthAndFullwidthForms\nInHangulCompatibilityJamo\nInHangulJamo\nInHangulSyllables\nInHanunoo\nInHebrew\nInHighPrivateUseSurrogates\nInHighSurrogates\nInHiragana\nInIPAExtensions\nInIdeographicDescriptionCharacters\nInKanbun\nInKangxiRadicals\nInKannada\nInKatakana\nInKatakanaPhoneticExtensions\nInKharoshthi\nInKhmer\nInKhmerSymbols\nInLao\nInLatin1Supplement\nInLatinExtendedA\nInLatinExtendedAdditional\nInLatinExtendedB\nInLatinExtendedC\nInLatinExtendedD\nInLetterlikeSymbols\nInLimbu\nInLinearBIdeograms\nInLinearBSyllabary\nInLowSurrogates\nInMalayalam\nInMathematicalAlphanumericSymbols\nInMathematicalOperators\nInMiscellaneousMathematicalSymbolsA\nInMiscellaneousMathematicalSymbolsB\nInMiscellaneousSymbols\nInMiscellaneousSymbolsAndArrows\nInMiscellaneousTechnical\nInModifierToneLetters\nInMongolian\nInMusicalSymbols\nInMyanmar\nInNKo\nInNewTaiLue\nInNumberForms\nInOgham\nInOldItalic\nInOldPersian\nInOpticalCharacterRecognition\nInOriya\nInOsmanya\nInPhagspa\nInPhoenician\nInPhoneticExtensions\nInPhoneticExtensionsSupplement\nInPrivateUseArea\nInRunic\nInShavian\nInSinhala\nInSmallFormVariants\nInSpacingModifierLetters\nInSpecials\nInSuperscriptsAndSubscripts\nInSupplementalArrowsA\nInSupplementalArrowsB\nInSupplementalMathematicalOperators\nInSupplementalPunctuation\nInSupplementaryPrivateUseAreaA\nInSupplementaryPrivateUseAreaB\nInSylotiNagri\nInSyriac\nInTagalog\nInTagbanwa\nInTags\nInTaiLe\nInTaiXuanJingSymbols\nInTamil\nInTelugu\nInThaana\nInThai\nInTibetan\nInTifinagh\nInUgaritic\nInUnifiedCanadianAboriginalSyllabics\nInVariationSelectors\nInVariationSelectorsSupplement\nInVerticalForms\nInYiRadicals\nInYiSyllables\nInYijingHexagramSymbols User-Defined Character Properties You can define your own character properties by defining subroutines whose names begin with \"In\" or \"Is\". The subroutines can be defined in any package. The user-defined properties can be used in the regular expression \"\\p\" and \"\\P\" constructs; if you are using a user-defined property from a package other than the one you are in, you must specify its package in the \"\\p\" or \"\\P\" construct. # assuming property IsForeign defined in Lang::\npackage main;  # property package name required\nif ($txt =~ \/\\p{Lang::IsForeign}+\/) { ... }\n\npackage Lang;  # property package name not required\nif ($txt =~ \/\\p{IsForeign}+\/) { ... } Note that the effect is compile-time and immutable once defined. The subroutines must return a specially-formatted string, with one or more newline-separated lines. Each line must be one of the following: \u2022 A single hexadecimal number denoting a Unicode code point to include. \u2022 Two hexadecimal numbers separated by horizontal whitespace (space or tabular characters) denoting a range of Unicode code points to include. \u2022 Something to include, prefixed by \"+\": a built-in character property (prefixed by \"utf8::\") or a user-defined character property, to represent all the characters in that property; two hexadecimal code points for a range; or a single hexadecimal code point. \u2022 Something to exclude, prefixed by \"-\": an existing character property (prefixed by \"utf8::\") or a user-defined character property, to represent all the characters in that property; two hexadecimal code points for a range; or a single hexadecimal code point. \u2022 Something to negate, prefixed \"!\": an existing character property (prefixed by \"utf8::\") or a user-defined character property, to represent all the characters in that property; two hexadecimal code points for a range; or a single hexadecimal code point. \u2022 Something to intersect with, prefixed by \"&\": an existing character property (prefixed by \"utf8::\") or a user-defined character property, for all the characters except the characters in the property; two hexadecimal code points for a range; or a single hexadecimal code point. For example, to define a property that covers both the Japanese syllabaries (hiragana and katakana), you can define sub InKana {\n    return <<END;\n3040\\t309F\n30A0\\t30FF\nEND\n} Imagine that the here-doc end marker is at the beginning of the line. Now you can use \"\\p{InKana}\" and \"\\P{InKana}\". You could also have used the existing block property names: sub InKana {\n    return <<'END';\n+utf8::InHiragana\n+utf8::InKatakana\nEND\n} Suppose you wanted to match only the allocated characters, not the raw block ranges: in other words, you want to remove the non-characters: sub InKana {\n    return <<'END';\n+utf8::InHiragana\n+utf8::InKatakana\n-utf8::IsCn\nEND\n} The negation is useful for defining (surprise!) negated classes. sub InNotKana {\n    return <<'END';\n!utf8::InHiragana\n-utf8::InKatakana\n+utf8::IsCn\nEND\n} Intersection is useful for getting the common characters matched by two (or more) classes. sub InFooAndBar {\n    return <<'END';\n+main::Foo\n&main::Bar\nEND\n} It's important to remember not to use \"&\" for the first set -- that would be intersecting with nothing (resulting in an empty set). User-Defined Case Mappings You can also define your own mappings to be used in the lc(), lcfirst(), uc(), and ucfirst() (or their string-inlined versions). The principle is similar to that of user-defined character properties: to define subroutines in the \"main\" package with names like \"ToLower\" (for lc() and lcfirst()), \"ToTitle\" (for the first character in ucfirst()), and \"ToUpper\" (for uc(), and the rest of the characters in ucfirst()). The string returned by the subroutines needs now to be three hexadecimal numbers separated by tabulators: start of the source range, end of the source range, and start of the destination range. For example: sub ToUpper {\n    return <<END;\n0061\\t0063\\t0041\nEND\n} defines an uc() mapping that causes only the characters \"a\", \"b\", and \"c\" to be mapped to \"A\", \"B\", \"C\", all other characters will remain unchanged. If there is no source range to speak of, that is, the mapping is from a single character to another single character, leave the end of the source range empty, but the two tabulator characters are still needed. For example: sub ToLower {\n    return <<END;\n0041\\t\\t0061\nEND\n} defines a lc() mapping that causes only \"A\" to be mapped to \"a\", all other characters will remain unchanged. (For serious hackers only) If you want to introspect the default mappings, you can find the data in the directory $Config{privlib}\/unicore\/To\/. The mapping data is returned as the here-document, and the \"utf8::ToSpecFoo\" are special exception mappings derived from <$Config{privlib}>\/unicore\/SpecialCasing.txt. The \"Digit\" and \"Fold\" mappings that one can see in the directory are not directly user-accessible, one can use either the \"Unicode::UCD\" module, or just match case-insensitively (that's when the \"Fold\" mapping is used). A final note on the user-defined case mappings: they will be used only if the scalar has been marked as having Unicode characters. Old byte-style strings will not be affected. Character Encodings for Input and Output See Encode. Unicode Regular Expression Support Level The following list of Unicode support for regular expressions describes all the features currently supported. The references to \"Level N\" and the section numbers refer to the Unicode Technical Standard #18, \"Unicode Regular Expressions\", version 11, in May 2005. \u2022 Level 1 - Basic Unicode Support RL1.1   Hex Notation                        - done          [1]\nRL1.2   Properties                          - done          [2][3]\nRL1.2a  Compatibility Properties            - done          [4]\nRL1.3   Subtraction and Intersection        - MISSING       [5]\nRL1.4   Simple Word Boundaries              - done          [6]\nRL1.5   Simple Loose Matches                - done          [7]\nRL1.6   Line Boundaries                     - MISSING       [8]\nRL1.7   Supplementary Code Points           - done          [9]\n\n[1]  \\x{...}\n[2]  \\p{...} \\P{...}\n[3]  supports not only minimal list (general category, scripts,\n     Alphabetic, Lowercase, Uppercase, WhiteSpace,\n     NoncharacterCodePoint, DefaultIgnorableCodePoint, Any,\n     ASCII, Assigned), but also bidirectional types, blocks, etc.\n     (see \"Unicode Character Properties\")\n[4]  \\d \\D \\s \\S \\w \\W \\X [:prop:] [:^prop:]\n[5]  can use regular expression look-ahead [a] or\n     user-defined character properties [b] to emulate set operations\n[6]  \\b \\B\n[7]  note that Perl does Full case-folding in matching, not Simple:\n     for example U+1F88 is equivalent to U+1F00 U+03B9,\n     not with 1F80.  This difference matters mainly for certain Greek\n     capital letters with certain modifiers: the Full case-folding\n     decomposes the letter, while the Simple case-folding would map\n     it to a single character.\n[8]  should do ^ and $ also on U+000B (\\v in C), FF (\\f), CR (\\r),\n     CRLF (\\r\\n), NEL (U+0085), LS (U+2028), and PS (U+2029);\n     should also affect <>, $., and script line numbers;\n     should not split lines within CRLF [c] (i.e. there is no empty\n     line between \\r and \\n)\n[9]  UTF-8\/UTF-EBDDIC used in perl allows not only U+10000 to U+10FFFF\n     but also beyond U+10FFFF [d] [a] You can mimic class subtraction using lookahead. For example, what UTS#18 might write as [{Greek}-[{UNASSIGNED}]] in Perl can be written as: (?!\\p{Unassigned})\\p{InGreekAndCoptic}\n(?=\\p{Assigned})\\p{InGreekAndCoptic} But in this particular example, you probably really want \\p{GreekAndCoptic} which will match assigned characters known to be part of the Greek script. Also see the Unicode::Regex::Set module, it does implement the full UTS#18 grouping, intersection, union, and removal (subtraction) syntax. [b] '+' for union, '-' for removal (set-difference), '&' for intersection (see \"User-Defined Character Properties\") [c] Try the \":crlf\" layer (see PerlIO). [d] Avoid \"use warning 'utf8';\" (or say \"no warning 'utf8';\") to allow U+FFFF (\"\\x{FFFF}\"). \u2022 Level 2 - Extended Unicode Support RL2.1   Canonical Equivalents           - MISSING       [10][11]\nRL2.2   Default Grapheme Clusters       - MISSING       [12][13]\nRL2.3   Default Word Boundaries         - MISSING       [14]\nRL2.4   Default Loose Matches           - MISSING       [15]\nRL2.5   Name Properties                 - MISSING       [16]\nRL2.6   Wildcard Properties             - MISSING\n\n[10] see UAX#15 \"Unicode Normalization Forms\"\n[11] have Unicode::Normalize but not integrated to regexes\n[12] have \\X but at this level . should equal that\n[13] UAX#29 \"Text Boundaries\" considers CRLF and Hangul syllable\n     clusters as a single grapheme cluster.\n[14] see UAX#29, Word Boundaries\n[15] see UAX#21 \"Case Mappings\"\n[16] have \\N{...} but neither compute names of CJK Ideographs\n     and Hangul Syllables nor use a loose match [e] [e] \"\\N{...}\" allows namespaces (see charnames). \u2022 Level 3 - Tailored Support   RL3.1   Tailored Punctuation            - MISSING\n  RL3.2   Tailored Grapheme Clusters      - MISSING       [17][18]\n  RL3.3   Tailored Word Boundaries        - MISSING\n  RL3.4   Tailored Loose Matches          - MISSING\n  RL3.5   Tailored Ranges                 - MISSING\n  RL3.6   Context Matching                - MISSING       [19]\n  RL3.7   Incremental Matches             - MISSING\n( RL3.8   Unicode Set Sharing )\n  RL3.9   Possible Match Sets             - MISSING\n  RL3.10  Folded Matching                 - MISSING       [20]\n  RL3.11  Submatchers                     - MISSING\n\n  [17] see UAX#10 \"Unicode Collation Algorithms\"\n  [18] have Unicode::Collate but not integrated to regexes\n  [19] have (?<=x) and (?=x), but look-aheads or look-behinds should see\n       outside of the target substring\n  [20] need insensitive matching for linguistic features other than case;\n       for example, hiragana to katakana, wide and narrow, simplified Han\n       to traditional Han (see UTR#30 \"Character Foldings\") Unicode Encodings Unicode characters are assigned to code points, which are abstract numbers. To use these numbers, various encodings are needed. \u2022 UTF-8 UTF-8 is a variable-length (1 to 6 bytes, current character allocations require 4 bytes), byte-order independent encoding. For ASCII (and we really do mean 7-bit ASCII , not another 8-bit encoding), UTF-8 is transparent. The following table is from Unicode 3.2. Code Points            1st Byte  2nd Byte  3rd Byte  4th Byte\n\n  U+0000..U+007F       00..7F\n  U+0080..U+07FF       C2..DF    80..BF\n  U+0800..U+0FFF       E0        A0..BF    80..BF\n  U+1000..U+CFFF       E1..EC    80..BF    80..BF\n  U+D000..U+D7FF       ED        80..9F    80..BF\n  U+D800..U+DFFF       ******* ill-formed *******\n  U+E000..U+FFFF       EE..EF    80..BF    80..BF\n U+10000..U+3FFFF      F0        90..BF    80..BF    80..BF\n U+40000..U+FFFFF      F1..F3    80..BF    80..BF    80..BF\nU+100000..U+10FFFF     F4        80..8F    80..BF    80..BF Note the \"A0..BF\" in \"U+0800..U+0FFF\", the \"80..9F\" in \"U+D000...U+D7FF\", the \"90..B\"F in \"U+10000..U+3FFFF\", and the \"80...8F\" in \"U+100000..U+10FFFF\". The \"gaps\" are caused by legal UTF-8 avoiding non-shortest encodings: it is technically possible to UTF-8-encode a single code point in different ways, but that is explicitly forbidden, and the shortest possible encoding should always be used. So that's what Perl does. Another way to look at it is via bits: Code Points                    1st Byte   2nd Byte  3rd Byte  4th Byte\n\n                   0aaaaaaa     0aaaaaaa\n           00000bbbbbaaaaaa     110bbbbb  10aaaaaa\n           ccccbbbbbbaaaaaa     1110cccc  10bbbbbb  10aaaaaa\n 00000dddccccccbbbbbbaaaaaa     11110ddd  10cccccc  10bbbbbb  10aaaaaa As you can see, the continuation bytes all begin with 10, and the leading bits of the start byte tell how many bytes the are in the encoded character. \u2022 UTF-EBCDIC Like UTF-8 but EBCDIC-safe, in the way that UTF-8 is ASCII-safe. \u2022 UTF-16 , UTF-16BE , UTF-16LE , Surrogates, and BOMs (Byte Order Marks) The followings items are mostly for reference and general Unicode knowledge, Perl doesn't use these constructs internally. UTF-16 is a 2 or 4 byte encoding. The Unicode code points \"U+0000..U+FFFF\" are stored in a single 16-bit unit, and the code points \"U+10000..U+10FFFF\" in two 16-bit units. The latter case is using surrogates, the first 16-bit unit being the high surrogate, and the second being the low surrogate. Surrogates are code points set aside to encode the \"U+10000..U+10FFFF\" range of Unicode code points in pairs of 16-bit units. The high surrogates are the range \"U+D800..U+DBFF\", and the low surrogates are the range \"U+DC00..U+DFFF\". The surrogate encoding is $hi = ($uni - 0x10000) \/ 0x400 + 0xD800;\n$lo = ($uni - 0x10000) % 0x400 + 0xDC00; and the decoding is $uni = 0x10000 + ($hi - 0xD800) * 0x400 + ($lo - 0xDC00); If you try to generate surrogates (for example by using chr()), you will get a warning if warnings are turned on, because those code points are not valid for a Unicode character. Because of the 16-bitness, UTF-16 is byte-order dependent. UTF-16 itself can be used for in-memory computations, but if storage or transfer is required either UTF-16BE (big-endian) or UTF-16LE (little-endian) encodings must be chosen. This introduces another problem: what if you just know that your data is UTF-16 , but you don't know which endianness? Byte Order Marks, or BOMs, are a solution to this. A special character has been reserved in Unicode to function as a byte order marker: the character with the code point \"U+FEFF\" is the BOM . The trick is that if you read a BOM , you will know the byte order, since if it was written on a big-endian platform, you will read the bytes \"0xFE 0xFF\", but if it was written on a little-endian platform, you will read the bytes \"0xFF 0xFE\". (And if the originating platform was writing in UTF-8 , you will read the bytes \"0xEF 0xBB 0xBF\".) The way this trick works is that the character with the code point \"U+FFFE\" is guaranteed not to be a valid Unicode character, so the sequence of bytes \"0xFF 0xFE\" is unambiguously \" BOM , represented in little-endian format\" and cannot be \"U+FFFE\", represented in big-endian format\". \u2022 UTF-32 , UTF-32BE , UTF-32LE The UTF-32 family is pretty much like the UTF-16 family, expect that the units are 32-bit, and therefore the surrogate scheme is not needed. The BOM signatures will be \"0x00 0x00 0xFE 0xFF\" for BE and \"0xFF 0xFE 0x00 0x00\" for LE . \u2022 UCS-2 , UCS-4 Encodings defined by the ISO 10646 standard. UCS-2 is a 16-bit encoding. Unlike UTF-16 , UCS-2 is not extensible beyond \"U+FFFF\", because it does not use surrogates. UCS-4 is a 32-bit encoding, functionally identical to UTF-32 . \u2022 UTF-7 A seven-bit safe (non-eight-bit) encoding, which is useful if the transport or storage is not eight-bit safe. Defined by RFC 2152. Security Implications of Unicode \u2022 Malformed UTF-8 Unfortunately, the specification of UTF-8 leaves some room for interpretation of how many bytes of encoded output one should generate from one input Unicode character. Strictly speaking, the shortest possible sequence of UTF-8 bytes should be generated, because otherwise there is potential for an input buffer overflow at the receiving end of a UTF-8 connection. Perl always generates the shortest length UTF-8 , and with warnings on Perl will warn about non-shortest length UTF-8 along with other malformations, such as the surrogates, which are not real Unicode code points. \u2022 Regular expressions behave slightly differently between byte data and character (Unicode) data. For example, the \"word character\" character class \"\\w\" will work differently depending on if data is eight-bit bytes or Unicode. In the first case, the set of \"\\w\" characters is either small--the default set of alphabetic characters, digits, and the \"_\"--or, if you are using a locale (see perllocale), the \"\\w\" might contain a few more letters according to your language and country. In the second case, the \"\\w\" set of characters is much, much larger. Most importantly, even in the set of the first 256 characters, it will probably match different characters: unlike most locales, which are specific to a language and country pair, Unicode classifies all the characters that are letters somewhere as \"\\w\". For example, your locale might not think that LATIN SMALL LETTER ETH is a letter (unless you happen to speak Icelandic), but Unicode does. As discussed elsewhere, Perl has one foot (two hooves?) planted in each of two worlds: the old world of bytes and the new world of characters, upgrading from bytes to characters when necessary. If your legacy code does not explicitly use Unicode, no automatic switch-over to characters should happen. Characters shouldn't get downgraded to bytes, either. It is possible to accidentally mix bytes and characters, however (see perluniintro), in which case \"\\w\" in regular expressions might start behaving differently. Review your code. Use warnings and the \"strict\" pragma. Unicode in Perl on EBCDIC The way Unicode is handled on EBCDIC platforms is still experimental. On such platforms, references to UTF-8 encoding in this document and elsewhere should be read as meaning the UTF-EBCDIC specified in Unicode Technical Report 16, unless ASCII vs. EBCDIC issues are specifically discussed. There is no \"utfebcdic\" pragma or \":utfebcdic\" layer; rather, \"utf8\" and \":utf8\" are reused to mean the platform's \"natural\" 8-bit encoding of Unicode. See perlebcdic for more discussion of the issues. Locales Usually locale settings and Unicode do not affect each other, but there are a couple of exceptions: \u2022 You can enable automatic UTF-8-ification of your standard file handles, default \"open()\" layer, and @ARGV by using either the \"-C\" command line switch or the \"PERL_UNICODE\" environment variable, see perlrun for the documentation of the \"-C\" switch. \u2022 Perl tries really hard to work both with Unicode and the old byte-oriented world. Most often this is nice, but sometimes Perl's straddling of the proverbial fence causes problems. When Unicode Does Not Happen While Perl does have extensive ways to input and output in Unicode, and few other 'entry points' like the @ARGV which can be interpreted as Unicode ( UTF-8 ), there still are many places where Unicode (in some encoding or another) could be given as arguments or received as results, or both, but it is not. The following are such interfaces. For all of these interfaces Perl currently (as of 5.8.3) simply assumes byte strings both as arguments and results, or UTF-8 strings if the \"encoding\" pragma has been used. One reason why Perl does not attempt to resolve the role of Unicode in this cases is that the answers are highly dependent on the operating system and the file system(s). For example, whether filenames can be in Unicode, and in exactly what kind of encoding, is not exactly a portable concept. Similarly for the qx and system: how well will the 'command line interface' (and which of them?) handle Unicode? \u2022 chdir, chmod, chown, chroot, exec, link, lstat, mkdir, rename, rmdir, stat, symlink, truncate, unlink, utime, -X \u2022 %ENV \u2022 glob (aka the <*>) \u2022 open, opendir, sysopen \u2022 qx (aka the backtick operator), system \u2022 readdir, readlink Forcing Unicode in Perl (Or Unforcing Unicode in Perl) Sometimes (see \"When Unicode Does Not Happen\") there are situations where you simply need to force a byte string into UTF-8 , or vice versa. The low-level calls utf8::upgrade($bytestring) and utf8::downgrade($utf8string[, FAIL_OK ]) are the answers. Note that utf8::downgrade() can fail if the string contains characters that don't fit into a byte. Using Unicode in XS If you want to handle Perl Unicode in XS extensions, you may find the following C APIs useful. See also \"Unicode Support\" in perlguts for an explanation about Unicode at the XS level, and perlapi for the API details. \u2022 \"DO_UTF8(sv)\" returns true if the \"UTF8\" flag is on and the bytes pragma is not in effect. \"SvUTF8(sv)\" returns true if the \"UTF8\" flag is on; the bytes pragma is ignored. The \"UTF8\" flag being on does not mean that there are any characters of code points greater than 255 (or 127) in the scalar or that there are even any characters in the scalar. What the \"UTF8\" flag means is that the sequence of octets in the representation of the scalar is the sequence of UTF-8 encoded code points of the characters of a string. The \"UTF8\" flag being off means that each octet in this representation encodes a single character with code point 0..255 within the string. Perl's Unicode model is not to use UTF-8 until it is absolutely necessary. \u2022 \"uvchr_to_utf8(buf, chr)\" writes a Unicode character code point into a buffer encoding the code point as UTF-8 , and returns a pointer pointing after the UTF-8 bytes. It works appropriately on EBCDIC machines. \u2022 \"utf8_to_uvchr(buf, lenp)\" reads UTF-8 encoded bytes from a buffer and returns the Unicode character code point and, optionally, the length of the UTF-8 byte sequence. It works appropriately on EBCDIC machines. \u2022 \"utf8_length(start, end)\" returns the length of the UTF-8 encoded buffer in characters. \"sv_len_utf8(sv)\" returns the length of the UTF-8 encoded scalar. \u2022 \"sv_utf8_upgrade(sv)\" converts the string of the scalar to its UTF-8 encoded form. \"sv_utf8_downgrade(sv)\" does the opposite, if possible. \"sv_utf8_encode(sv)\" is like sv_utf8_upgrade except that it does not set the \"UTF8\" flag. \"sv_utf8_decode()\" does the opposite of \"sv_utf8_encode()\". Note that none of these are to be used as general-purpose encoding or decoding interfaces: \"use Encode\" for that. \"sv_utf8_upgrade()\" is affected by the encoding pragma but \"sv_utf8_downgrade()\" is not (since the encoding pragma is designed to be a one-way street). \u2022 is_utf8_char(s) returns true if the pointer points to a valid UTF-8 character. \u2022 \"is_utf8_string(buf, len)\" returns true if \"len\" bytes of the buffer are valid UTF-8 . \u2022 \"UTF8SKIP(buf)\" will return the number of bytes in the UTF-8 encoded character in the buffer. \"UNISKIP(chr)\" will return the number of bytes required to UTF-8-encode the Unicode character code point. \"UTF8SKIP()\" is useful for example for iterating over the characters of a UTF-8 encoded buffer; \"UNISKIP()\" is useful, for example, in computing the size required for a UTF-8 encoded buffer. \u2022 \"utf8_distance(a, b)\" will tell the distance in characters between the two pointers pointing to the same UTF-8 encoded buffer. \u2022 \"utf8_hop(s, off)\" will return a pointer to a UTF-8 encoded buffer that is \"off\" (positive or negative) Unicode characters displaced from the UTF-8 buffer \"s\". Be careful not to overstep the buffer: \"utf8_hop()\" will merrily run off the end or the beginning of the buffer if told to do so. \u2022 \"pv_uni_display(dsv, spv, len, pvlim, flags)\" and \"sv_uni_display(dsv, ssv, pvlim, flags)\" are useful for debugging the output of Unicode strings and scalars. By default they are useful only for debugging--they display all characters as hexadecimal code points--but with the flags \"UNI_DISPLAY_ISPRINT\", \"UNI_DISPLAY_BACKSLASH\", and \"UNI_DISPLAY_QQ\" you can make the output more readable. \u2022 \"ibcmp_utf8(s1, pe1, l1, u1, s2, pe2, l2, u2)\" can be used to compare two strings case-insensitively in Unicode. For case-sensitive comparisons you can just use \"memEQ()\" and \"memNE()\" as usual. For more information, see perlapi, and utf8.c and utf8.h in the Perl source code distribution.","Process Name":"perlunicode","Link":"https:\/\/linux.die.net\/man\/1\/perlunicode"}},{"Process":{"Description":"","Process Name":"perlunifaq","Link":"https:\/\/linux.die.net\/man\/1\/perlunifaq"}},{"Process":{"Description":"This document gives a general idea of Unicode and how to use Unicode in Perl. Unicode Unicode is a character set standard which plans to codify all of the writing systems of the world, plus many other symbols. Unicode and ISO\/IEC 10646 are coordinated standards that provide code points for characters in almost all modern character set standards, covering more than 30 writing systems and hundreds of languages, including all commercially-important modern languages. All characters in the largest Chinese, Japanese, and Korean dictionaries are also encoded. The standards will eventually cover almost all characters in more than 250 writing systems and thousands of languages. Unicode 1.0 was released in October 1991, and 4.0 in April 2003. A Unicode character is an abstract entity. It is not bound to any particular integer width, especially not to the C language \"char\". Unicode is language-neutral and display-neutral: it does not encode the language of the text and it does not generally define fonts or other graphical layout details. Unicode operates on characters and on text built from those characters. Unicode defines characters like \"LATIN CAPITAL LETTER A\" or \"GREEK SMALL LETTER ALPHA\" and unique numbers for the characters, in this case 0x0041 and 0x03B1, respectively. These unique numbers are called code points. The Unicode standard prefers using hexadecimal notation for the code points. If numbers like 0x0041 are unfamiliar to you, take a peek at a later section, \"Hexadecimal Notation\". The Unicode standard uses the notation \"U+0041 LATIN CAPITAL LETTER A\", to give the hexadecimal code point and the normative name of the character. Unicode also defines various properties for the characters, like \"uppercase\" or \"lowercase\", \"decimal digit\", or \"punctuation\"; these properties are independent of the names of the characters. Furthermore, various operations on the characters like uppercasing, lowercasing, and collating (sorting) are defined. A Unicode character consists either of a single code point, or a base character (like \"LATIN CAPITAL LETTER A\"), followed by one or more modifiers (like \"COMBINING ACUTE ACCENT\"). This sequence of base character and modifiers is called a combining character sequence. Whether to call these combining character sequences \"characters\" depends on your point of view. If you are a programmer, you probably would tend towards seeing each element in the sequences as one unit, or \"character\". The whole sequence could be seen as one \"character\", however, from the user's point of view, since that's probably what it looks like in the context of the user's language. With this \"whole sequence\" view of characters, the total number of characters is open-ended. But in the programmer's \"one unit is one character\" point of view, the concept of \"characters\" is more deterministic. In this document, we take that second point of view: one \"character\" is one Unicode code point, be it a base character or a combining character. For some combinations, there are precomposed characters. \"LATIN CAPITAL LETTER A WITH ACUTE\", for example, is defined as a single code point. These precomposed characters are, however, only available for some combinations, and are mainly meant to support round-trip conversions between Unicode and legacy standards (like the ISO 8859). In the general case, the composing method is more extensible. To support conversion between different compositions of the characters, various normalization forms to standardize representations are also defined. Because of backward compatibility with legacy encodings, the \"a unique number for every character\" idea breaks down a bit: instead, there is \"at least one number for every character\". The same character could be represented differently in several legacy encodings. The converse is also not true: some code points do not have an assigned character. Firstly, there are unallocated code points within otherwise used blocks. Secondly, there are special Unicode control characters that do not represent true characters. A common myth about Unicode is that it would be \"16-bit\", that is, Unicode is only represented as 0x10000 (or 65536) characters from 0x0000 to 0xFFFF. This is untrue. Since Unicode 2.0 (July 1996), Unicode has been defined all the way up to 21 bits (0x10FFFF), and since Unicode 3.1 (March 2001), characters have been defined beyond 0xFFFF. The first 0x10000 characters are called the Plane 0, or the Basic Multilingual Plane ( BMP ). With Unicode 3.1, 17 (yes, seventeen) planes in all were defined--but they are nowhere near full of defined characters, yet. Another myth is that the 256-character blocks have something to do with languages--that each block would define the characters used by a language or a set of languages. This is also untrue. The division into blocks exists, but it is almost completely accidental--an artifact of how the characters have been and still are allocated. Instead, there is a concept called scripts, which is more useful: there is \"Latin\" script, \"Greek\" script, and so on. Scripts usually span varied parts of several blocks. For further information see Unicode::UCD. The Unicode code points are just abstract numbers. To input and output these abstract numbers, the numbers must be encoded or serialised somehow. Unicode defines several character encoding forms, of which UTF-8 is perhaps the most popular. UTF-8 is a variable length encoding that encodes Unicode characters as 1 to 6 bytes (only 4 with the currently defined characters). Other encodings include UTF-16 and UTF-32 and their big- and little-endian variants ( UTF-8 is byte-order independent) The ISO\/IEC 10646 defines the UCS-2 and UCS-4 encoding forms. For more information about encodings--for instance, to learn what surrogates and byte order marks (BOMs) are--see perlunicode. Perl's Unicode Support Starting from Perl 5.6.0, Perl has had the capacity to handle Unicode natively. Perl 5.8.0, however, is the first recommended release for serious Unicode work. The maintenance release 5.6.1 fixed many of the problems of the initial Unicode implementation, but for example regular expressions still do not work with Unicode in 5.6.1. Starting from Perl 5.8.0, the use of \"use utf8\" is needed only in much more restricted circumstances. In earlier releases the \"utf8\" pragma was used to declare that operations in the current block or file would be Unicode-aware. This model was found to be wrong, or at least clumsy: the \"Unicodeness\" is now carried with the data, instead of being attached to the operations. Only one case remains where an explicit \"use utf8\" is needed: if your Perl script itself is encoded in UTF-8 , you can use UTF-8 in your identifier names, and in string and regular expression literals, by saying \"use utf8\". This is not the default because scripts with legacy 8-bit data in them would break. See utf8. Perl's Unicode Model Perl supports both pre-5.6 strings of eight-bit native bytes, and strings of Unicode characters. The principle is that Perl tries to keep its data as eight-bit bytes for as long as possible, but as soon as Unicodeness cannot be avoided, the data is transparently upgraded to Unicode. Internally, Perl currently uses either whatever the native eight-bit character set of the platform (for example Latin-1) is, defaulting to UTF-8 , to encode Unicode strings. Specifically, if all code points in the string are 0xFF or less, Perl uses the native eight-bit character set. Otherwise, it uses UTF-8 . A user of Perl does not normally need to know nor care how Perl happens to encode its internal strings, but it becomes relevant when outputting Unicode strings to a stream without a PerlIO layer -- one with the \"default\" encoding. In such a case, the raw bytes used internally (the native character set or UTF-8 , as appropriate for each string) will be used, and a \"Wide character\" warning will be issued if those strings contain a character beyond 0x00FF. For example, perl -e 'print \"\\x{DF}\\n\", \"\\x{0100}\\x{DF}\\n\"' produces a fairly useless mixture of native bytes and UTF-8 , as well as a warning: Wide character in print at ... To output UTF-8 , use the \":encoding\" or \":utf8\" output layer. Prepending binmode(STDOUT, \":utf8\"); to this sample program ensures that the output is completely UTF-8 , and removes the program's warning. You can enable automatic UTF-8-ification of your standard file handles, default \"open()\" layer, and @ARGV by using either the \"-C\" command line switch or the \"PERL_UNICODE\" environment variable, see perlrun for the documentation of the \"-C\" switch. Note that this means that Perl expects other software to work, too: if Perl has been led to believe that STDIN should be UTF-8 , but then STDIN coming in from another command is not UTF-8 , Perl will complain about the malformed UTF-8 . All features that combine Unicode and I\/O also require using the new PerlIO feature. Almost all Perl 5.8 platforms do use PerlIO, though: you can see whether yours is by running \"perl -V\" and looking for \"useperlio=define\". Unicode and EBCDIC Perl 5.8.0 also supports Unicode on EBCDIC platforms. There, Unicode support is somewhat more complex to implement since additional conversions are needed at every step. Some problems remain, see perlebcdic for details. In any case, the Unicode support on EBCDIC platforms is better than in the 5.6 series, which didn't work much at all for EBCDIC platform. On EBCDIC platforms, the internal Unicode encoding form is UTF-EBCDIC instead of UTF-8 . The difference is that as UTF-8 is \"ASCII-safe\" in that ASCII characters encode to UTF-8 as-is, while UTF-EBCDIC is \"EBCDIC-safe\". Creating Unicode To create Unicode characters in literals for code points above 0xFF, use the \"\\x{...}\" notation in double-quoted strings: my $smiley = \"\\x{263a}\"; Similarly, it can be used in regular expression literals $smiley =~ \/\\x{263a}\/; At run-time you can use \"chr()\": my $hebrew_alef = chr(0x05d0); See \"Further Resources\" for how to find all these numeric codes. Naturally, \"ord()\" will do the reverse: it turns a character into a code point. Note that \"\\x..\" (no \"{}\" and only two hexadecimal digits), \"\\x{...}\", and \"chr(...)\" for arguments less than 0x100 (decimal 256) generate an eight-bit character for backward compatibility with older Perls. For arguments of 0x100 or more, Unicode characters are always produced. If you want to force the production of Unicode characters regardless of the numeric value, use \"pack(\"U\", ...)\" instead of \"\\x..\", \"\\x{...}\", or \"chr()\". You can also use the \"charnames\" pragma to invoke characters by name in double-quoted strings: use charnames ':full';\nmy $arabic_alef = \"\\N{ARABIC LETTER ALEF}\"; And, as mentioned above, you can also \"pack()\" numbers into Unicode characters: my $georgian_an  = pack(\"U\", 0x10a0); Note that both \"\\x{...}\" and \"\\N{...}\" are compile-time string constants: you cannot use variables in them. if you want similar run-time functionality, use \"chr()\" and \"charnames::vianame()\". If you want to force the result to Unicode characters, use the special \"U0\" prefix. It consumes no arguments but causes the following bytes to be interpreted as the UTF-8 encoding of Unicode characters: my $chars = pack(\"U0W*\", 0x80, 0x42); Likewise, you can stop such UTF-8 interpretation by using the special \"C0\" prefix. Handling Unicode Handling Unicode is for the most part transparent: just use the strings as usual. Functions like \"index()\", \"length()\", and \"substr()\" will work on the Unicode characters; regular expressions will work on the Unicode characters (see perlunicode and perlretut). Note that Perl considers combining character sequences to be separate characters, so for example use charnames ':full';\nprint length(\"\\N{LATIN CAPITAL LETTER A}\\N{COMBINING ACUTE ACCENT}\"), \"\\n\"; will print 2, not 1. The only exception is that regular expressions have \"\\X\" for matching a combining character sequence. Life is not quite so transparent, however, when working with legacy encodings, I\/O, and certain special cases: Legacy Encodings When you combine legacy data and Unicode the legacy data needs to be upgraded to Unicode. Normally ISO 8859-1 (or EBCDIC , if applicable) is assumed. The \"Encode\" module knows about many encodings and has interfaces for doing conversions between those encodings: use Encode 'decode';\n$data = decode(\"iso-8859-3\", $data); # convert from legacy to utf-8 Unicode I\/O Normally, writing out Unicode data print FH $some_string_with_unicode, \"\\n\"; produces raw bytes that Perl happens to use to internally encode the Unicode string. Perl's internal encoding depends on the system as well as what characters happen to be in the string at the time. If any of the characters are at code points 0x100 or above, you will get a warning. To ensure that the output is explicitly rendered in the encoding you desire--and to avoid the warning--open the stream with the desired encoding. Some examples: open FH, \">:utf8\", \"file\";\n\nopen FH, \">:encoding(ucs2)\",      \"file\";\nopen FH, \">:encoding(UTF-8)\",     \"file\";\nopen FH, \">:encoding(shift_jis)\", \"file\"; and on already open streams, use \"binmode()\": binmode(STDOUT, \":utf8\");\n\nbinmode(STDOUT, \":encoding(ucs2)\");\nbinmode(STDOUT, \":encoding(UTF-8)\");\nbinmode(STDOUT, \":encoding(shift_jis)\"); The matching of encoding names is loose: case does not matter, and many encodings have several aliases. Note that the \":utf8\" layer must always be specified exactly like that; it is not subject to the loose matching of encoding names. Also note that \":utf8\" is unsafe for input, because it accepts the data without validating that it is indeed valid UTF8 . See PerlIO for the \":utf8\" layer, PerlIO::encoding and Encode::PerlIO for the \":encoding()\" layer, and Encode::Supported for many encodings supported by the \"Encode\" module. Reading in a file that you know happens to be encoded in one of the Unicode or legacy encodings does not magically turn the data into Unicode in Perl's eyes. To do that, specify the appropriate layer when opening files open(my $fh,'<:encoding(utf8)', 'anything');\nmy $line_of_unicode = <$fh>;\n\nopen(my $fh,'<:encoding(Big5)', 'anything');\nmy $line_of_unicode = <$fh>; The I\/O layers can also be specified more flexibly with the \"open\" pragma. See open, or look at the following example. use open ':encoding(utf8)'; # input\/output default encoding will be UTF-8\nopen X, \">file\";\nprint X chr(0x100), \"\\n\";\nclose X;\nopen Y, \"<file\";\nprintf \"%#x\\n\", ord(<Y>); # this should print 0x100\nclose Y; With the \"open\" pragma you can use the \":locale\" layer BEGIN { $ENV{LC_ALL} = $ENV{LANG} = 'ru_RU.KOI8-R' }\n# the :locale will probe the locale environment variables like LC_ALL\nuse open OUT => ':locale'; # russki parusski\nopen(O, \">koi8\");\nprint O chr(0x430); # Unicode CYRILLIC SMALL LETTER A = KOI8-R 0xc1\nclose O;\nopen(I, \"<koi8\");\nprintf \"%#x\\n\", ord(<I>), \"\\n\"; # this should print 0xc1\nclose I; These methods install a transparent filter on the I\/O stream that converts data from the specified encoding when it is read in from the stream. The result is always Unicode. The open pragma affects all the \"open()\" calls after the pragma by setting default layers. If you want to affect only certain streams, use explicit layers directly in the \"open()\" call. You can switch encodings on an already opened stream by using \"binmode()\"; see \"binmode\" in perlfunc. The \":locale\" does not currently (as of Perl 5.8.0) work with \"open()\" and \"binmode()\", only with the \"open\" pragma. The \":utf8\" and \":encoding(...)\" methods do work with all of \"open()\", \"binmode()\", and the \"open\" pragma. Similarly, you may use these I\/O layers on output streams to automatically convert Unicode to the specified encoding when it is written to the stream. For example, the following snippet copies the contents of the file \"text.jis\" (encoded as ISO-2022-JP , aka JIS ) to the file \"text.utf8\", encoded as UTF-8: open(my $nihongo, '<:encoding(iso-2022-jp)', 'text.jis');\nopen(my $unicode, '>:utf8',                  'text.utf8');\nwhile (<$nihongo>) { print $unicode $_ } The naming of encodings, both by the \"open()\" and by the \"open\" pragma allows for flexible names: \"koi8-r\" and \"KOI8R\" will both be understood. Common encodings recognized by ISO , MIME , IANA , and various other standardisation organisations are recognised; for a more detailed list see Encode::Supported. \"read()\" reads characters and returns the number of characters. \"seek()\" and \"tell()\" operate on byte counts, as do \"sysread()\" and \"sysseek()\". Notice that because of the default behaviour of not doing any conversion upon input if there is no default layer, it is easy to mistakenly write code that keeps on expanding a file by repeatedly encoding the data: # BAD CODE WARNING\nopen F, \"file\";\nlocal $\/; ## read in the whole file of 8-bit characters\n$t = <F>;\nclose F;\nopen F, \">:encoding(utf8)\", \"file\";\nprint F $t; ## convert to UTF-8 on output\nclose F; If you run this code twice, the contents of the file will be twice UTF-8 encoded. A \"use open ':encoding(utf8)'\" would have avoided the bug, or explicitly opening also the file for input as UTF-8 . NOTE : the \":utf8\" and \":encoding\" features work only if your Perl has been built with the new PerlIO feature (which is the default on most systems). Displaying Unicode As Text Sometimes you might want to display Perl scalars containing Unicode as simple ASCII (or EBCDIC ) text. The following subroutine converts its argument so that Unicode characters with code points greater than 255 are displayed as \"\\x{...}\", control characters (like \"\\n\") are displayed as \"\\x..\", and the rest of the characters as themselves: sub nice_string {\n    join(\"\",\n      map { $_ > 255 ?                  # if wide character...\n            sprintf(\"\\\\x{%04X}\", $_) :  # \\x{...}\n            chr($_) =~ \/[[:cntrl:]]\/ ?  # else if control character ...\n            sprintf(\"\\\\x%02X\", $_) :    # \\x..\n            quotemeta(chr($_))          # else quoted or as themselves\n      } unpack(\"W*\", $_[0]));           # unpack Unicode characters\n} For example, nice_string(\"foo\\x{100}bar\\n\") returns the string 'foo\\x{0100}bar\\x0A' which is ready to be printed. Special Cases \u2022 Bit Complement Operator ~ And vec() The bit complement operator \"~\" may produce surprising results if used on strings containing characters with ordinal values above 255. In such a case, the results are consistent with the internal encoding of the characters, but not with much else. So don't do that. Similarly for \"vec()\": you will be operating on the internally-encoded bit patterns of the Unicode characters, not on the code point values, which is very probably not what you want. \u2022 Peeking At Perl's Internal Encoding Normal users of Perl should never care how Perl encodes any particular Unicode string (because the normal ways to get at the contents of a string with Unicode--via input and output--should always be via explicitly-defined I\/O layers). But if you must, there are two ways of looking behind the scenes. One way of peeking inside the internal encoding of Unicode characters is to use \"unpack(\"C*\", ...\" to get the bytes of whatever the string encoding happens to be, or \"unpack(\"U0..\", ...)\" to get the bytes of the UTF-8 encoding: # this prints  c4 80  for the UTF-8 bytes 0xc4 0x80\nprint join(\" \", unpack(\"U0(H2)*\", pack(\"U\", 0x100))), \"\\n\"; Yet another way would be to use the Devel::Peek module: perl -MDevel::Peek -e 'Dump(chr(0x100))' That shows the \"UTF8\" flag in FLAGS and both the UTF-8 bytes and Unicode characters in \"PV\". See also later in this document the discussion about the \"utf8::is_utf8()\" function. Advanced Topics \u2022 String Equivalence The question of string equivalence turns somewhat complicated in Unicode: what do you mean by \"equal\"? (Is \"LATIN CAPITAL LETTER A WITH ACUTE\" equal to \"LATIN CAPITAL LETTER A\"?) The short answer is that by default Perl compares equivalence (\"eq\", \"ne\") based only on code points of the characters. In the above case, the answer is no (because 0x00C1 != 0x0041). But sometimes, any CAPITAL LETTER As should be considered equal, or even As of any case. The long answer is that you need to consider character normalization and casing issues: see Unicode::Normalize, Unicode Technical Reports #15 and #21, Unicode Normalization Forms and Case Mappings, <http:\/\/www.unicode.org\/unicode\/reports\/tr15\/> and <http:\/\/www.unicode.org\/unicode\/reports\/tr21\/> As of Perl 5.8.0, the \"Full\" case-folding of Case Mappings\/SpecialCasing is implemented. \u2022 String Collation People like to see their strings nicely sorted--or as Unicode parlance goes, collated. But again, what do you mean by collate? (Does \"LATIN CAPITAL LETTER A WITH ACUTE\" come before or after \"LATIN CAPITAL LETTER A WITH GRAVE\"?) The short answer is that by default, Perl compares strings (\"lt\", \"le\", \"cmp\", \"ge\", \"gt\") based only on the code points of the characters. In the above case, the answer is \"after\", since 0x00C1 > 0x00C0. The long answer is that \"it depends\", and a good answer cannot be given without knowing (at the very least) the language context. See Unicode::Collate, and Unicode Collation Algorithm <http:\/\/www.unicode.org\/unicode\/reports\/tr10\/> Miscellaneous \u2022 Character Ranges and Classes Character ranges in regular expression character classes ( \"\/[a-z]\/\") and in the \"tr\/\/\/\" (also known as \"y\/\/\/\") operator are not magically Unicode-aware. What this means is that \"[A-Za-z]\" will not magically start to mean \"all alphabetic letters\"; not that it does mean that even for 8-bit characters, you should be using \"\/[[:alpha:]]\/\" in that case. For specifying character classes like that in regular expressions, you can use the various Unicode properties--\"\\pL\", or perhaps \"\\p{Alphabetic}\", in this particular case. You can use Unicode code points as the end points of character ranges, but there is no magic associated with specifying a certain range. For further information--there are dozens of Unicode character classes--see perlunicode. \u2022 String-To-Number Conversions Unicode does define several other decimal--and numeric--characters besides the familiar 0 to 9, such as the Arabic and Indic digits. Perl does not support string-to-number conversion for digits other than ASCII 0 to 9 (and ASCII a to f for hexadecimal). Questions With Answers \u2022 Will My Old Scripts Break? Very probably not. Unless you are generating Unicode characters somehow, old behaviour should be preserved. About the only behaviour that has changed and which could start generating Unicode is the old behaviour of \"chr()\" where supplying an argument more than 255 produced a character modulo 255. \"chr(300)\", for example, was equal to \"chr(45)\" or \"-\" (in ASCII ), now it is LATIN CAPITAL LETTER I WITH BREVE . \u2022 How Do I Make My Scripts Work With Unicode? Very little work should be needed since nothing changes until you generate Unicode data. The most important thing is getting input as Unicode; for that, see the earlier I\/O discussion. \u2022 How Do I Know Whether My String Is In Unicode? You shouldn't have to care. But you may, because currently the semantics of the characters whose ordinals are in the range 128 to 255 is different depending on whether the string they are contained within is in Unicode or not. (See perlunicode.) To determine if a string is in Unicode, use: print utf8::is_utf8($string) ? 1 : 0, \"\\n\"; But note that this doesn't mean that any of the characters in the string are necessary UTF-8 encoded, or that any of the characters have code points greater than 0xFF (255) or even 0x80 (128), or that the string has any characters at all. All the \"is_utf8()\" does is to return the value of the internal \"utf8ness\" flag attached to the $string. If the flag is off, the bytes in the scalar are interpreted as a single byte encoding. If the flag is on, the bytes in the scalar are interpreted as the (multi-byte, variable-length) UTF-8 encoded code points of the characters. Bytes added to an UTF-8 encoded string are automatically upgraded to UTF-8 . If mixed non-UTF-8 and UTF-8 scalars are merged (double-quoted interpolation, explicit concatenation, and printf\/sprintf parameter substitution), the result will be UTF-8 encoded as if copies of the byte strings were upgraded to UTF-8: for example, $a = \"ab\\x80c\";\n$b = \"\\x{100}\";\nprint \"$a = $b\\n\"; the output string will be UTF-8-encoded \"ab\\x80c = \\x{100}\\n\", but $a will stay byte-encoded. Sometimes you might really need to know the byte length of a string instead of the character length. For that use either the \"Encode::encode_utf8()\" function or the \"bytes\" pragma and the \"length()\" function: my $unicode = chr(0x100);\nprint length($unicode), \"\\n\"; # will print 1\nrequire Encode;\nprint length(Encode::encode_utf8($unicode)), \"\\n\"; # will print 2\nuse bytes;\nprint length($unicode), \"\\n\"; # will also print 2\n                              # (the 0xC4 0x80 of the UTF-8) \u2022 How Do I Detect Data That's Not Valid In a Particular Encoding? Use the \"Encode\" package to try converting it. For example, use Encode 'decode_utf8';\n\nif (eval { decode_utf8($string, Encode::FB_CROAK); 1 }) {\n    # $string is valid utf8\n} else {\n    # $string is not valid utf8\n} Or use \"unpack\" to try decoding it: use warnings;\n@chars = unpack(\"C0U*\", $string_of_bytes_that_I_think_is_utf8); If invalid, a \"Malformed UTF-8 character\" warning is produced. The \"C0\" means \"process the string character per character\". Without that, the \"unpack(\"U*\", ...)\" would work in \"U0\" mode (the default if the format string starts with \"U\") and it would return the bytes making up the UTF-8 encoding of the target string, something that will always work. \u2022 How Do I Convert Binary Data Into a Particular Encoding, Or Vice Versa? This probably isn't as useful as you might think. Normally, you shouldn't need to. In one sense, what you are asking doesn't make much sense: encodings are for characters, and binary data are not \"characters\", so converting \"data\" into some encoding isn't meaningful unless you know in what character set and encoding the binary data is in, in which case it's not just binary data, now is it? If you have a raw sequence of bytes that you know should be interpreted via a particular encoding, you can use \"Encode\": use Encode 'from_to';\nfrom_to($data, \"iso-8859-1\", \"utf-8\"); # from latin-1 to utf-8 The call to \"from_to()\" changes the bytes in $data, but nothing material about the nature of the string has changed as far as Perl is concerned. Both before and after the call, the string $data contains just a bunch of 8-bit bytes. As far as Perl is concerned, the encoding of the string remains as \"system-native 8-bit bytes\". You might relate this to a fictional 'Translate' module: use Translate;\nmy $phrase = \"Yes\";\nTranslate::from_to($phrase, 'english', 'deutsch');\n## phrase now contains \"Ja\" The contents of the string changes, but not the nature of the string. Perl doesn't know any more after the call than before that the contents of the string indicates the affirmative. Back to converting data. If you have (or want) data in your system's native 8-bit encoding (e.g. Latin-1, EBCDIC , etc.), you can use pack\/unpack to convert to\/from Unicode. $native_string  = pack(\"W*\", unpack(\"U*\", $Unicode_string));\n$Unicode_string = pack(\"U*\", unpack(\"W*\", $native_string)); If you have a sequence of bytes you know is valid UTF-8 , but Perl doesn't know it yet, you can make Perl a believer, too: use Encode 'decode_utf8';\n$Unicode = decode_utf8($bytes); or: $Unicode = pack(\"U0a*\", $bytes); You can find the bytes that make up a UTF-8 sequence with @bytes = unpack(\"C*\", $Unicode_string) and you can create well-formed Unicode with $Unicode_string = pack(\"U*\", 0xff, ...) \u2022 How Do I Display Unicode? How Do I Input Unicode? See < http:\/\/www.alanwood.net\/unicode\/> and < http:\/\/www.cl.cam.ac.uk\/~mgk25\/unicode.html> \u2022 How Does Unicode Work With Traditional Locales? In Perl, not very well. Avoid using locales through the \"locale\" pragma. Use only one or the other. But see perlrun for the description of the \"-C\" switch and its environment counterpart, $ENV{PERL_UNICODE} to see how to enable various Unicode features, for example by using locale settings. Hexadecimal Notation The Unicode standard prefers using hexadecimal notation because that more clearly shows the division of Unicode into blocks of 256 characters. Hexadecimal is also simply shorter than decimal. You can use decimal notation, too, but learning to use hexadecimal just makes life easier with the Unicode standard. The \"U+HHHH\" notation uses hexadecimal, for example. The \"0x\" prefix means a hexadecimal number, the digits are 0-9 and a-f (or A-F, case doesn't matter). Each hexadecimal digit represents four bits, or half a byte. \"print 0x..., \"\\n\"\" will show a hexadecimal number in decimal, and \"printf \"%x\\n\", $decimal\" will show a decimal number in hexadecimal. If you have just the \"hex digits\" of a hexadecimal number, you can use the \"hex()\" function. print 0x0009, \"\\n\";    # 9\nprint 0x000a, \"\\n\";    # 10\nprint 0x000f, \"\\n\";    # 15\nprint 0x0010, \"\\n\";    # 16\nprint 0x0011, \"\\n\";    # 17\nprint 0x0100, \"\\n\";    # 256\n\nprint 0x0041, \"\\n\";    # 65\n\nprintf \"%x\\n\",  65;    # 41\nprintf \"%#x\\n\", 65;    # 0x41\n\nprint hex(\"41\"), \"\\n\"; # 65 Further Resources \u2022 Unicode Consortium < http:\/\/www.unicode.org\/> \u2022 Unicode FAQ < http:\/\/www.unicode.org\/unicode\/faq\/> \u2022 Unicode Glossary < http:\/\/www.unicode.org\/glossary\/> \u2022 Unicode Useful Resources < http:\/\/www.unicode.org\/unicode\/onlinedat\/resources.html> \u2022 Unicode and Multilingual Support in HTML , Fonts, Web Browsers and Other Applications < http:\/\/www.alanwood.net\/unicode\/> \u2022 UTF-8 and Unicode FAQ for Unix\/Linux < http:\/\/www.cl.cam.ac.uk\/~mgk25\/unicode.html> \u2022 Legacy Character Sets < http:\/\/www.czyborra.com\/> < http:\/\/www.eki.ee\/letter\/> \u2022 The Unicode support files live within the Perl installation in the directory $Config{installprivlib}\/unicore in Perl 5.8.0 or newer, and $Config{installprivlib}\/unicode in the Perl 5.6 series. (The renaming to lib\/unicore was done to avoid naming conflicts with lib\/Unicode in case-insensitive filesystems.) The main Unicode data file is UnicodeData.txt (or Unicode.301 in Perl 5.6.1.) You can find the $Config{installprivlib} by perl \"-V:installprivlib\" You can explore various information from the Unicode data files using the \"Unicode::UCD\" module.","Process Name":"perluniintro","Link":"https:\/\/linux.die.net\/man\/1\/perluniintro"}},{"Process":{"Description":"The days of just flinging strings around are over. It's well established that modern programs need to be capable of communicating funny accented letters, and things like euro symbols. This means that programmers need new habits. It's easy to program Unicode capable software, but it does require discipline to do it right. There's a lot to know about character sets, and text encodings. It's probably best to spend a full day learning all this, but the basics can be learned in minutes. These are not the very basics, though. It is assumed that you already know the difference between bytes and characters, and realise (and accept!) that there are many different character sets and encodings, and that your program has to be explicit about them. Recommended reading is \"The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!)\" by Joel Spolsky, at <http:\/\/joelonsoftware.com\/articles\/Unicode.html>. This tutorial speaks in rather absolute terms, and provides only a limited view of the wealth of character string related features that Perl has to offer. For most projects, this information will probably suffice. Definitions It's important to set a few things straight first. This is the most important part of this tutorial. This view may conflict with other information that you may have found on the web, but that's mostly because many sources are wrong. You may have to re-read this entire section a few times... Unicode Unicode is a character set with room for lots of characters. The ordinal value of a character is called a code point. There are many, many code points, but computers work with bytes, and a byte can have only 256 values. Unicode has many more characters, so you need a method to make these accessible. Unicode is encoded using several competing encodings, of which UTF-8 is the most used. In a Unicode encoding, multiple subsequent bytes can be used to store a single code point, or simply: character. UTF-8 UTF-8 is a Unicode encoding. Many people think that Unicode and UTF-8 are the same thing, but they're not. There are more Unicode encodings, but much of the world has standardized on UTF-8 . UTF-8 treats the first 128 codepoints, 0..127, the same as ASCII . They take only one byte per character. All other characters are encoded as two or more (up to six) bytes using a complex scheme. Fortunately, Perl handles this for us, so we don't have to worry about this. Text strings (character strings) Text strings, or character strings are made of characters. Bytes are irrelevant here, and so are encodings. Each character is just that: the character. Text strings are also called Unicode strings, because in Perl, every text string is a Unicode string. On a text string, you would do things like: $text =~ s\/foo\/bar\/;\nif ($string =~ \/^\\d+$\/) { ... }\n$text = ucfirst $text;\nmy $character_count = length $text; The value of a character ( \"ord\", \"chr\") is the corresponding Unicode code point. Binary strings (byte strings) Binary strings, or byte strings are made of bytes. Here, you don't have characters, just bytes. All communication with the outside world (anything outside of your current Perl process) is done in binary. On a binary string, you would do things like: my (@length_content) = unpack \"(V\/a)*\", $binary;\n$binary =~ s\/\\x00\\x0F\/\\xFF\\xF0\/;  # for the brave :)\nprint {$fh} $binary;\nmy $byte_count = length $binary; Encoding Encoding (as a verb) is the conversion from text to binary. To encode, you have to supply the target encoding, for example \"iso-8859-1\" or \"UTF-8\". Some encodings, like the \"iso-8859\" (\"latin\") range, do not support the full Unicode standard; characters that can't be represented are lost in the conversion. Decoding Decoding is the conversion from binary to text. To decode, you have to know what encoding was used during the encoding phase. And most of all, it must be something decodable. It doesn't make much sense to decode a PNG image into a text string. Internal format Perl has an internal format, an encoding that it uses to encode text strings so it can store them in memory. All text strings are in this internal format. In fact, text strings are never in any other format! You shouldn't worry about what this format is, because conversion is automatically done when you decode or encode. Your new toolkit Add to your standard heading the following line: use Encode qw(encode decode); Or, if you're lazy, just: use Encode; I\/O flow (the actual 5 minute tutorial) The typical input\/output flow of a program is: 1. Receive and decode\n2. Process\n3. Encode and output If your input is binary, and is supposed to remain binary, you shouldn't decode it to a text string, of course. But in all other cases, you should decode it. Decoding can't happen reliably if you don't know how the data was encoded. If you get to choose, it's a good idea to standardize on UTF-8 . my $foo   = decode('UTF-8', get 'http:\/\/example.com\/');\nmy $bar   = decode('ISO-8859-1', readline STDIN);\nmy $xyzzy = decode('Windows-1251', $cgi->param('foo')); Processing happens as you knew before. The only difference is that you're now using characters instead of bytes. That's very useful if you use things like \"substr\", or \"length\". It's important to realize that there are no bytes in a text string. Of course, Perl has its internal encoding to store the string in memory, but ignore that. If you have to do anything with the number of bytes, it's probably best to move that part to step 3, just after you've encoded the string. Then you know exactly how many bytes it will be in the destination string. The syntax for encoding text strings to binary strings is as simple as decoding: $body = encode('UTF-8', $body); If you needed to know the length of the string in bytes, now's the perfect time for that. Because $body is now a byte string, \"length\" will report the number of bytes, instead of the number of characters. The number of characters is no longer known, because characters only exist in text strings. my $byte_count = length $body; And if the protocol you're using supports a way of letting the recipient know which character encoding you used, please help the receiving end by using that feature! For example, E-mail and HTTP support MIME headers, so you can use the \"Content-Type\" header. They can also have \"Content-Length\" to indicate the number of bytes, which is always a good idea to supply if the number is known. \"Content-Type: text\/plain; charset=UTF-8\",\n\"Content-Length: $byte_count\"","Process Name":"perlunitut","Link":"https:\/\/linux.die.net\/man\/1\/perlunitut"}},{"Process":{"Description":"Along with the Perl interpreter itself, the Perl distribution installs a range of utilities on your system. There are also several utilities which are used by the Perl distribution itself as part of the install process. This document exists to list all of these utilities, explain what they are for and provide pointers to each module's documentation, if appropriate.","Process Name":"perlutil","Link":"https:\/\/linux.die.net\/man\/1\/perlutil"}},{"Process":{"Description":"Perl 5.7.2 (Developmental) or Perl 5.8.x (forthcoming) for UTS","Process Name":"perluts","Link":"https:\/\/linux.die.net\/man\/1\/perluts"}},{"Process":{"Description":"Predefined Names The following names have special meaning to Perl. Most punctuation names have reasonable mnemonics, or analogs in the shells. Nevertheless, if you wish to use long variable names, you need only say use English; at the top of your program. This aliases all the short names to the long names in the current package. Some even have medium names, generally borrowed from awk. In general, it's best to use the use English '-no_match_vars'; invocation if you don't need $PREMATCH, $MATCH, or $POSTMATCH, as it avoids a certain performance hit with the use of regular expressions. See English. Variables that depend on the currently selected filehandle may be set by calling an appropriate object method on the IO::Handle object, although this is less efficient than using the regular built-in variables. (Summary lines below for this contain the word HANDLE .) First you must say use IO::Handle; after which you may use either method HANDLE EXPR or more safely, HANDLE->method(EXPR) Each method returns the old value of the IO::Handle attribute. The methods each take an optional EXPR , which, if supplied, specifies the new value for the IO::Handle attribute in question. If not supplied, most methods do nothing to the current value--except for autoflush(), which will assume a 1 for you, just to be different. Because loading in the IO::Handle class is an expensive operation, you should learn how to use the regular built-in variables. A few of these variables are considered \"read-only\". This means that if you try to assign to this variable, either directly or indirectly through a reference, you'll raise a run-time exception. You should be very careful when modifying the default values of most special variables described in this document. In most cases you want to localize these variables before changing them, since if you don't, the change may affect other modules which rely on the default values of the special variables that you have changed. This is one of the correct ways to read the whole file at once: open my $fh, \"<\", \"foo\" or die $!;\nlocal $\/; # enable localized slurp mode\nmy $content = <$fh>;\nclose $fh; But the following code is quite bad: open my $fh, \"<\", \"foo\" or die $!;\nundef $\/; # enable slurp mode\nmy $content = <$fh>;\nclose $fh; since some other module, may want to read data from some file in the default \"line mode\", so if the code we have just presented has been executed, the global value of $\/ is now changed for any other code running inside the same Perl interpreter. Usually when a variable is localized you want to make sure that this change affects the shortest scope possible. So unless you are already inside some short \"{}\" block, you should create one yourself. For example: my $content = '';\nopen my $fh, \"<\", \"foo\" or die $!;\n{\n    local $\/;\n    $content = <$fh>;\n}\nclose $fh; Here is an example of how your own code can go broken: for (1..5){\n    nasty_break();\n    print \"$_ \";\n}\nsub nasty_break {\n    $_ = 5;\n    # do something with $_\n} You probably expect this code to print: 1 2 3 4 5 but instead you get: 5 5 5 5 5 Why? Because nasty_break() modifies $_ without localizing it first. The fix is to add local(): local $_ = 5; It's easy to notice the problem in such a short example, but in more complicated code you are looking for trouble if you don't localize changes to the special variables. The following list is ordered by scalar variables first, then the arrays, then the hashes. $ARG $_ The default input and pattern-searching space. The following pairs are equivalent: while (<>) {...}    # equivalent only in while!\nwhile (defined($_ = <>)) {...}\n\n\/^Subject:\/\n$_ =~ \/^Subject:\/\n\ntr\/a-z\/A-Z\/\n$_ =~ tr\/a-z\/A-Z\/\n\nchomp\nchomp($_) Here are the places where Perl will assume $_ even if you don't use it: \u2022 The following functions: abs, alarm, chomp, chop, chr, chroot, cos, defined, eval, exp, glob, hex, int, lc, lcfirst, length, log, lstat, mkdir, oct, ord, pos, print, quotemeta, readlink, readpipe, ref, require, reverse (in scalar context only), rmdir, sin, split (on its second argument), sqrt, stat, study, uc, ucfirst, unlink, unpack. \u2022 All file tests ( \"-f\", \"-d\") except for \"-t\", which defaults to STDIN . See \"-X\" in perlfunc \u2022 The pattern matching operations \"m\/\/\", \"s\/\/\/\" and \"tr\/\/\/\" (aka \"y\/\/\/\") when used without an \"=~\" operator. \u2022 The default iterator variable in a \"foreach\" loop if no other variable is supplied. \u2022 The implicit iterator variable in the grep() and map() functions. \u2022 The implicit variable of given(). \u2022 The default place to put an input record when a \"<FH>\" operation's result is tested by itself as the sole criterion of a \"while\" test. Outside a \"while\" test, this will not happen. As $_ is a global variable, this may lead in some cases to unwanted side-effects. As of perl 5.9.1, you can now use a lexical version of $_ by declaring it in a file or in a block with \"my\". Moreover, declaring \"our $_\" restores the global $_ in the current scope. (Mnemonic: underline is understood in certain operations.) $a $b Special package variables when using sort(), see \"sort\" in perlfunc. Because of this specialness $a and $b don't need to be declared (using use vars, or our()) even when using the \"strict 'vars'\" pragma. Don't lexicalize them with \"my $a\" or \"my $b\" if you want to be able to use them in the sort() comparison block or function. $< digits> Contains the subpattern from the corresponding set of capturing parentheses from the last pattern match, not counting patterns matched in nested blocks that have been exited already. (Mnemonic: like \\digits.) These variables are all read-only and dynamically scoped to the current BLOCK . $MATCH $& The string matched by the last successful pattern match (not counting any matches hidden within a BLOCK or eval() enclosed by the current BLOCK ). (Mnemonic: like & in some editors.) This variable is read-only and dynamically scoped to the current BLOCK . The use of this variable anywhere in a program imposes a considerable performance penalty on all regular expression matches. See \" BUGS \". See \"@-\" for a replacement. ${^MATCH} This is similar to $& ( $MATCH) except that it does not incur the performance penalty associated with that variable, and is only guaranteed to return a defined value when the pattern was compiled or executed with the \"\/p\" modifier. $PREMATCH \"$`\" The string preceding whatever was matched by the last successful pattern match (not counting any matches hidden within a BLOCK or eval enclosed by the current BLOCK ). (Mnemonic: \"`\" often precedes a quoted string.) This variable is read-only. The use of this variable anywhere in a program imposes a considerable performance penalty on all regular expression matches. See \" BUGS \". See \"@-\" for a replacement. ${^PREMATCH} This is similar to \"$`\" ($PREMATCH) except that it does not incur the performance penalty associated with that variable, and is only guaranteed to return a defined value when the pattern was compiled or executed with the \"\/p\" modifier. $POSTMATCH \"$'\" The string following whatever was matched by the last successful pattern match (not counting any matches hidden within a BLOCK or eval() enclosed by the current BLOCK ). (Mnemonic: \"'\" often follows a quoted string.) Example: local $_ = 'abcdefghi';\n\/def\/;\nprint \"$`:$&:$'\\n\";         # prints abc:def:ghi This variable is read-only and dynamically scoped to the current BLOCK . The use of this variable anywhere in a program imposes a considerable performance penalty on all regular expression matches. See \" BUGS \". See \"@-\" for a replacement. ${^POSTMATCH} This is similar to \"$'\" ( $POSTMATCH) except that it does not incur the performance penalty associated with that variable, and is only guaranteed to return a defined value when the pattern was compiled or executed with the \"\/p\" modifier. $LAST_PAREN_MATCH $+ The text matched by the last bracket of the last successful search pattern. This is useful if you don't know which one of a set of alternative patterns matched. For example: \/Version: (.*)|Revision: (.*)\/ && ($rev = $+); (Mnemonic: be positive and forward looking.) This variable is read-only and dynamically scoped to the current BLOCK . $LAST_SUBMATCH_RESULT $^N The text matched by the used group most-recently closed (i.e. the group with the rightmost closing parenthesis) of the last successful search pattern. (Mnemonic: the (possibly) Nested parenthesis that most recently closed.) This is primarily used inside \"(?{...})\" blocks for examining text recently matched. For example, to effectively capture text to a variable (in addition to $1, $2, etc.), replace \"(...)\" with (?:(...)(?{ $var = $^N })) By setting and then using $var in this way relieves you from having to worry about exactly which numbered set of parentheses they are. This variable is dynamically scoped to the current BLOCK . @LAST_MATCH_END @+ This array holds the offsets of the ends of the last successful submatches in the currently active dynamic scope. $+[0] is the offset into the string of the end of the entire match. This is the same value as what the \"pos\" function returns when called on the variable that was matched against. The nth element of this array holds the offset of the nth submatch, so $+[1] is the offset past where $1 ends, $+[2] the offset past where $2 ends, and so on. You can use $#+ to determine how many subgroups were in the last successful match. See the examples given for the \"@-\" variable. %LAST_PAREN_MATCH %+ Similar to \"@+\", the \"%+\" hash allows access to the named capture buffers, should they exist, in the last successful match in the currently active dynamic scope. For example, $+{foo} is equivalent to $1 after the following match: 'foo' =~ \/(?<foo>foo)\/; The keys of the \"%+\" hash list only the names of buffers that have captured (and that are thus associated to defined values). The underlying behaviour of \"%+\" is provided by the Tie::Hash::NamedCapture module. Note: \"%-\" and \"%+\" are tied views into a common internal hash associated with the last successful regular expression. Therefore mixing iterative access to them via \"each\" may have unpredictable results. Likewise, if the last successful match changes, then the results may be surprising. HANDLE- >input_line_number( EXPR ) $INPUT_LINE_NUMBER $NR $. Current line number for the last filehandle accessed. Each filehandle in Perl counts the number of lines that have been read from it. (Depending on the value of $\/, Perl's idea of what constitutes a line may not match yours.) When a line is read from a filehandle (via readline() or \"<>\"), or when tell() or seek() is called on it, $. becomes an alias to the line counter for that filehandle. You can adjust the counter by assigning to $., but this will not actually move the seek pointer. Localizing $. will not localize the filehandle's line count. Instead, it will localize perl's notion of which filehandle $. is currently aliased to. $. is reset when the filehandle is closed, but not when an open filehandle is reopened without an intervening close(). For more details, see \"I\/O Operators\" in perlop. Because \"<>\" never does an explicit close, line numbers increase across ARGV files (but see examples in \"eof\" in perlfunc). You can also use \"HANDLE->input_line_number(EXPR)\" to access the line counter for a given filehandle without having to worry about which handle you last accessed. (Mnemonic: many programs use \".\" to mean the current line number.) IO::Handle->input_record_separator( EXPR ) $INPUT_RECORD_SEPARATOR $RS $\/ The input record separator, newline by default. This influences Perl's idea of what a \"line\" is. Works like awk's RS variable, including treating empty lines as a terminator if set to the null string. (An empty line cannot contain any spaces or tabs.) You may set it to a multi-character string to match a multi-character terminator, or to \"undef\" to read through the end of file. Setting it to \"\\n\\n\" means something slightly different than setting to \"\", if the file contains consecutive empty lines. Setting to \"\" will treat two or more consecutive empty lines as a single empty line. Setting to \"\\n\\n\" will blindly assume that the next input character belongs to the next paragraph, even if it's a newline. (Mnemonic: \/ delimits line boundaries when quoting poetry.) local $\/;           # enable \"slurp\" mode\nlocal $_ = <FH>;    # whole file now here\ns\/\\n[ \\t]+\/ \/g; Remember: the value of $\/ is a string, not a regex. awk has to be better for something. :-) Setting $\/ to a reference to an integer, scalar containing an integer, or scalar that's convertible to an integer will attempt to read records instead of lines, with the maximum record size being the referenced integer. So this: local $\/ = \\32768; # or \\\"32768\", or \\$var_containing_32768\nopen my $fh, \"<\", $myfile or die $!;\nlocal $_ = <$fh>; will read a record of no more than 32768 bytes from FILE . If you're not reading from a record-oriented file (or your OS doesn't have record-oriented files), then you'll likely get a full chunk of data with every read. If a record is larger than the record size you've set, you'll get the record back in pieces. Trying to set the record size to zero or less will cause reading in the (rest of the) whole file. On VMS , record reads are done with the equivalent of \"sysread\", so it's best not to mix record and non-record reads on the same file. (This is unlikely to be a problem, because any file you'd want to read in record mode is probably unusable in line mode.) Non-VMS systems do normal I\/O, so it's safe to mix record and non-record reads of a file. See also \"Newlines\" in perlport. Also see $.. HANDLE- >autoflush( EXPR ) $OUTPUT_AUTOFLUSH $| If set to nonzero, forces a flush right away and after every write or print on the currently selected output channel. Default is 0 (regardless of whether the channel is really buffered by the system or not; $| tells you only whether you've asked Perl explicitly to flush after each write). STDOUT will typically be line buffered if output is to the terminal and block buffered otherwise. Setting this variable is useful primarily when you are outputting to a pipe or socket, such as when you are running a Perl program under rsh and want to see the output as it's happening. This has no effect on input buffering. See \"getc\" in perlfunc for that. See \"select\" in perldoc on how to select the output channel. See also IO::Handle. (Mnemonic: when you want your pipes to be piping hot.) IO::Handle->output_field_separator EXPR $OUTPUT_FIELD_SEPARATOR $OFS $, The output field separator for the print operator. If defined, this value is printed between each of print's arguments. Default is \"undef\". (Mnemonic: what is printed when there is a \",\" in your print statement.) IO::Handle->output_record_separator EXPR $OUTPUT_RECORD_SEPARATOR $ORS $\\ The output record separator for the print operator. If defined, this value is printed after the last of print's arguments. Default is \"undef\". (Mnemonic: you set \"$\\\" instead of adding \"\\n\" at the end of the print. Also, it's just like $\/, but it's what you get \"back\" from Perl.) $LIST_SEPARATOR $\" This is like $, except that it applies to array and slice values interpolated into a double-quoted string (or similar interpreted string). Default is a space. (Mnemonic: obvious, I think.) $SUBSCRIPT_SEPARATOR $SUBSEP $; The subscript separator for multidimensional array emulation. If you refer to a hash element as $foo{$a,$b,$c} it really means $foo{join($;, $a, $b, $c)} But don't put @foo{$a,$b,$c}      # a slice--note the @ which means ($foo{$a},$foo{$b},$foo{$c}) Default is \"\\034\", the same as SUBSEP in awk. If your keys contain binary data there might not be any safe value for $;. (Mnemonic: comma (the syntactic subscript separator) is a semi-semicolon. Yeah, I know, it's pretty lame, but $, is already taken for something more important.) Consider using \"real\" multidimensional arrays as described in perllol. HANDLE- >format_page_number( EXPR ) $FORMAT_PAGE_NUMBER $% The current page number of the currently selected output channel. Used with formats. (Mnemonic: % is page number in nroff.) HANDLE- >format_lines_per_page( EXPR ) $FORMAT_LINES_PER_PAGE $= The current page length (printable lines) of the currently selected output channel. Default is 60. Used with formats. (Mnemonic: = has horizontal lines.) HANDLE- >format_lines_left( EXPR ) $FORMAT_LINES_LEFT $- The number of lines left on the page of the currently selected output channel. Used with formats. (Mnemonic: lines_on_page - lines_printed.) @LAST_MATCH_START @- $-[0] is the offset of the start of the last successful match. \"$-[\"n\"]\" is the offset of the start of the substring matched by n-th subpattern, or undef if the subpattern did not match. Thus after a match against $_, $& coincides with \"substr $_, $-[0], $+[0] - $-[0]\". Similarly, $ n coincides with \"substr $_, $-[n], $+[n] - $-[n]\" if \"$-[n]\" is defined, and $+ coincides with \"substr $_, $-[$#-], $+[$#-] - $-[$#-]\". One can use \"$#-\" to find the last matched subgroup in the last successful match. Contrast with $#+, the number of subgroups in the regular expression. Compare with \"@+\". This array holds the offsets of the beginnings of the last successful submatches in the currently active dynamic scope. \"$-[0]\" is the offset into the string of the beginning of the entire match. The nth element of this array holds the offset of the nth submatch, so \"$-[1]\" is the offset where $1 begins, \"$-[2]\" the offset where $2 begins, and so on. After a match against some variable $var: \"$`\" is the same as \"substr($var, 0, $-[0])\" $& is the same as \"substr($var, $-[0], $+[0] - $-[0])\" \"$'\" is the same as \"substr($var, $+[0])\" $1 is the same as \"substr($var, $-[1], $+[1] - $-[1])\" $2 is the same as \"substr($var, $-[2], $+[2] - $-[2])\" $3 is the same as \"substr($var, $-[3], $+[3] - $-[3])\" %- Similar to \"%+\", this variable allows access to the named capture buffers in the last successful match in the currently active dynamic scope. To each capture buffer name found in the regular expression, it associates a reference to an array containing the list of values captured by all buffers with that name (should there be several of them), in the order where they appear. Here's an example: if ('1234' =~ \/(?<A>1)(?<B>2)(?<A>3)(?<B>4)\/) {\n    foreach my $bufname (sort keys %-) {\n        my $ary = $-{$bufname};\n        foreach my $idx (0..$#$ary) {\n            print \"\\$-{$bufname}[$idx] : \",\n                  (defined($ary->[$idx]) ? \"'$ary->[$idx]'\" : \"undef\"),\n                  \"\\n\";\n        }\n    }\n} would print out: $-{A}[0] : '1'\n$-{A}[1] : '3'\n$-{B}[0] : '2'\n$-{B}[1] : '4' The keys of the \"%-\" hash correspond to all buffer names found in the regular expression. The behaviour of \"%-\" is implemented via the Tie::Hash::NamedCapture module. Note: \"%-\" and \"%+\" are tied views into a common internal hash associated with the last successful regular expression. Therefore mixing iterative access to them via \"each\" may have unpredictable results. Likewise, if the last successful match changes, then the results may be surprising. HANDLE- >format_name( EXPR ) $FORMAT_NAME $~ The name of the current report format for the currently selected output channel. Default is the name of the filehandle. (Mnemonic: brother to $^.) HANDLE- >format_top_name( EXPR ) $FORMAT_TOP_NAME $^ The name of the current top-of-page format for the currently selected output channel. Default is the name of the filehandle with _TOP appended. (Mnemonic: points to top of page.) IO::Handle->format_line_break_characters EXPR $FORMAT_LINE_BREAK_CHARACTERS $: The current set of characters after which a string may be broken to fill continuation fields (starting with ^) in a format. Default is \" \\n-\", to break on whitespace or hyphens. (Mnemonic: a \"colon\" in poetry is a part of a line.) IO::Handle->format_formfeed EXPR $FORMAT_FORMFEED $^L What formats output as a form feed. Default is \\f. $ACCUMULATOR $^A The current value of the write() accumulator for format() lines. A format contains formline() calls that put their result into $^A. After calling its format, write() prints out the contents of $^A and empties. So you never really see the contents of $^A unless you call formline() yourself and then look at it. See perlform and \"formline()\" in perlfunc. $CHILD_ERROR $? The status returned by the last pipe close, backtick (\"``\") command, successful call to wait() or waitpid(), or from the system() operator. This is just the 16-bit status word returned by the traditional Unix wait() system call (or else is made up to look like it). Thus, the exit value of the subprocess is really (\"$? >> 8\"), and \"$? & 127\" gives which signal, if any, the process died from, and \"$? & 128\" reports whether there was a core dump. (Mnemonic: similar to sh and ksh.) Additionally, if the \"h_errno\" variable is supported in C, its value is returned via $? if any \"gethost*()\" function fails. If you have installed a signal handler for \"SIGCHLD\", the value of $? will usually be wrong outside that handler. Inside an \"END\" subroutine $? contains the value that is going to be given to \"exit()\". You can modify $? in an \"END\" subroutine to change the exit status of your program. For example: END {\n    $? = 1 if $? == 255;  # die would make it 255\n} Under VMS , the pragma \"use vmsish 'status'\" makes $? reflect the actual VMS exit status, instead of the default emulation of POSIX status; see \"$?\" in perlvms for details. Also see \"Error Indicators\". ${^CHILD_ERROR_NATIVE} The native status returned by the last pipe close, backtick ( \"``\") command, successful call to wait() or waitpid(), or from the system() operator. On POSIX-like systems this value can be decoded with the WIFEXITED , WEXITSTATUS , WIFSIGNALED , WTERMSIG , WIFSTOPPED , WSTOPSIG and WIFCONTINUED functions provided by the POSIX module. Under VMS this reflects the actual VMS exit status; i.e. it is the same as $? when the pragma \"use vmsish 'status'\" is in effect. ${^ENCODING} The object reference to the Encode object that is used to convert the source code to Unicode. Thanks to this variable your perl script does not have to be written in UTF-8 . Default is undef. The direct manipulation of this variable is highly discouraged. $OS_ERROR $ERRNO $! If used numerically, yields the current value of the C \"errno\" variable, or in other words, if a system or library call fails, it sets this variable. This means that the value of $! is meaningful only immediately after a failure: if (open my $fh, \"<\", $filename) {\n    # Here $! is meaningless.\n    ...\n} else {\n    # ONLY here is $! meaningful.\n    ...\n    # Already here $! might be meaningless.\n}\n# Since here we might have either success or failure,\n# here $! is meaningless. In the above meaningless stands for anything: zero, non-zero, \"undef\". A successful system or library call does not set the variable to zero. If used as a string, yields the corresponding system error string. You can assign a number to $! to set errno if, for instance, you want \"$!\" to return the string for error n, or you want to set the exit value for the die() operator. (Mnemonic: What just went bang?) Also see \"Error Indicators\". %OS_ERROR %ERRNO %! Each element of \"%!\" has a true value only if $! is set to that value. For example, $!{ENOENT} is true if and only if the current value of $! is \"ENOENT\"; that is, if the most recent error was \"No such file or directory\" (or its moral equivalent: not all operating systems give that exact error, and certainly not all languages). To check if a particular key is meaningful on your system, use \"exists $!{the_key}\"; for a list of legal keys, use \"keys %!\". See Errno for more information, and also see above for the validity of $!. $EXTENDED_OS_ERROR $^E Error information specific to the current operating system. At the moment, this differs from $! under only VMS , OS\/2 , and Win32 (and for MacPerl). On all other platforms, $^E is always just the same as $!. Under VMS , $^E provides the VMS status value from the last system error. This is more specific information about the last system error than that provided by $!. This is particularly important when $! is set to EVMSERR . Under OS\/2 , $^E is set to the error code of the last call to OS\/2 API either via CRT , or directly from perl. Under Win32, $^E always returns the last error information reported by the Win32 call \"GetLastError()\" which describes the last error from within the Win32 API . Most Win32-specific code will report errors via $^E. ANSI C and Unix-like calls set \"errno\" and so most portable Perl code will report errors via $!. Caveats mentioned in the description of $! generally apply to $^E, also. (Mnemonic: Extra error explanation.) Also see \"Error Indicators\". $EVAL_ERROR $@ The Perl syntax error message from the last eval() operator. If $@ is the null string, the last eval() parsed and executed correctly (although the operations you invoked may have failed in the normal fashion). (Mnemonic: Where was the syntax error \"at\"?) Warning messages are not collected in this variable. You can, however, set up a routine to process warnings by setting $SIG{__WARN__} as described below. Also see \"Error Indicators\". $PROCESS_ID $PID $$ The process number of the Perl running this script. You should consider this variable read-only, although it will be altered across fork() calls. (Mnemonic: same as shells.) Note for Linux users: on Linux, the C functions \"getpid()\" and \"getppid()\" return different values from different threads. In order to be portable, this behavior is not reflected by $$, whose value remains consistent across threads. If you want to call the underlying \"getpid()\", you may use the CPAN module \"Linux::Pid\". $REAL_USER_ID $UID $< The real uid of this process. (Mnemonic: it's the uid you came from, if you're running setuid.) You can change both the real uid and the effective uid at the same time by using POSIX::setuid(). Since changes to $< require a system call, check $! after a change attempt to detect any possible errors. $EFFECTIVE_USER_ID $EUID $> The effective uid of this process. Example: $< = $>;            # set real to effective uid\n($<,$>) = ($>,$<);  # swap real and effective uid You can change both the effective uid and the real uid at the same time by using POSIX::setuid(). Changes to $> require a check to $! to detect any possible errors after an attempted change. (Mnemonic: it's the uid you went to, if you're running setuid.) $< and $> can be swapped only on machines supporting setreuid(). $REAL_GROUP_ID $GID $( The real gid of this process. If you are on a machine that supports membership in multiple groups simultaneously, gives a space separated list of groups you are in. The first number is the one returned by getgid(), and the subsequent ones by getgroups(), one of which may be the same as the first number. However, a value assigned to $( must be a single number used to set the real gid. So the value given by $( should not be assigned back to $( without being forced numeric, such as by adding zero. Note that this is different to the effective gid ( $)) which does take a list. You can change both the real gid and the effective gid at the same time by using POSIX::setgid(). Changes to $( require a check to $! to detect any possible errors after an attempted change. (Mnemonic: parentheses are used to group things. The real gid is the group you left, if you're running setgid.) $EFFECTIVE_GROUP_ID $EGID $) The effective gid of this process. If you are on a machine that supports membership in multiple groups simultaneously, gives a space separated list of groups you are in. The first number is the one returned by getegid(), and the subsequent ones by getgroups(), one of which may be the same as the first number. Similarly, a value assigned to $) must also be a space-separated list of numbers. The first number sets the effective gid, and the rest (if any) are passed to setgroups(). To get the effect of an empty list for setgroups(), just repeat the new effective gid; that is, to force an effective gid of 5 and an effectively empty setgroups() list, say \" $) = \"5 5\" \". You can change both the effective gid and the real gid at the same time by using POSIX::setgid() (use only a single numeric argument). Changes to $) require a check to $! to detect any possible errors after an attempted change. (Mnemonic: parentheses are used to group things. The effective gid is the group that's right for you, if you're running setgid.) $<, $>, $( and $) can be set only on machines that support the corresponding set[re][ug]id() routine. $( and $) can be swapped only on machines supporting setregid(). $PROGRAM_NAME $0 Contains the name of the program being executed. On some (read: not all) operating systems assigning to $0 modifies the argument area that the \"ps\" program sees. On some platforms you may have to use special \"ps\" options or a different \"ps\" to see the changes. Modifying the $0 is more useful as a way of indicating the current program state than it is for hiding the program you're running. (Mnemonic: same as sh and ksh.) Note that there are platform specific limitations on the maximum length of $0. In the most extreme case it may be limited to the space occupied by the original $0. In some platforms there may be arbitrary amount of padding, for example space characters, after the modified name as shown by \"ps\". In some platforms this padding may extend all the way to the original length of the argument area, no matter what you do (this is the case for example with Linux 2.2). Note for BSD users: setting $0 does not completely remove \"perl\" from the ps(1) output. For example, setting $0 to \"foobar\" may result in \"perl: foobar (perl)\" (whether both the \"perl: \" prefix and the \" (perl)\" suffix are shown depends on your exact BSD variant and version). This is an operating system feature, Perl cannot help it. In multithreaded scripts Perl coordinates the threads so that any thread may modify its copy of the $0 and the change becomes visible to ps(1) (assuming the operating system plays along). Note that the view of $0 the other threads have will not change since they have their own copies of it. If the program has been given to perl via the switches \"-e\" or \"-E\", $0 will contain the string \"-e\". $[ The index of the first element in an array, and of the first character in a substring. Default is 0, but you could theoretically set it to 1 to make Perl behave more like awk (or Fortran) when subscripting and when evaluating the index() and substr() functions. (Mnemonic: [ begins subscripts.) As of release 5 of Perl, assignment to $[ is treated as a compiler directive, and cannot influence the behavior of any other file. (That's why you can only assign compile-time constants to it.) Its use is highly discouraged. Note that, unlike other compile-time directives (such as strict), assignment to $[ can be seen from outer lexical scopes in the same file. However, you can use local() on it to strictly bind its value to a lexical block. $] The version + patchlevel \/ 1000 of the Perl interpreter. This variable can be used to determine whether the Perl interpreter executing a script is in the right range of versions. (Mnemonic: Is this version of perl in the right bracket?) Example: warn \"No checksumming!\\n\" if $] < 3.019; See also the documentation of \"use VERSION\" and \"require VERSION\" for a convenient way to fail if the running Perl interpreter is too old. The floating point representation can sometimes lead to inaccurate numeric comparisons. See $^V for a more modern representation of the Perl version that allows accurate string comparisons. $COMPILING $^C The current value of the flag associated with the -c switch. Mainly of use with -MO=... to allow code to alter its behavior when being compiled, such as for example to AUTOLOAD at compile time rather than normal, deferred loading. Setting \"$^C = 1\" is similar to calling \"B::minus_c\". $DEBUGGING $^D The current value of the debugging flags. (Mnemonic: value of -D switch.) May be read or set. Like its command-line equivalent, you can use numeric or symbolic values, eg \"$^D = 10\" or \"$^D = \"st\"\". ${^RE_DEBUG_FLAGS} The current value of the regex debugging flags. Set to 0 for no debug output even when the re 'debug' module is loaded. See re for details. ${^RE_TRIE_MAXBUF} Controls how certain regex optimisations are applied and how much memory they utilize. This value by default is 65536 which corresponds to a 512kB temporary cache. Set this to a higher value to trade memory for speed when matching large alternations. Set it to a lower value if you want the optimisations to be as conservative of memory as possible but still occur, and set it to a negative value to prevent the optimisation and conserve the most memory. Under normal situations this variable should be of no interest to you. $SYSTEM_FD_MAX $^F The maximum system file descriptor, ordinarily 2. System file descriptors are passed to exec()ed processes, while higher file descriptors are not. Also, during an open(), system file descriptors are preserved even if the open() fails. (Ordinary file descriptors are closed before the open() is attempted.) The close-on-exec status of a file descriptor will be decided according to the value of $^F when the corresponding file, pipe, or socket was opened, not the time of the exec(). $^H WARNING: This variable is strictly for internal use only. Its availability, behavior, and contents are subject to change without notice. This variable contains compile-time hints for the Perl interpreter. At the end of compilation of a BLOCK the value of this variable is restored to the value when the interpreter started to compile the BLOCK . When perl begins to parse any block construct that provides a lexical scope (e.g., eval body, required file, subroutine body, loop body, or conditional block), the existing value of $^H is saved, but its value is left unchanged. When the compilation of the block is completed, it regains the saved value. Between the points where its value is saved and restored, code that executes within BEGIN blocks is free to change the value of $^H. This behavior provides the semantic of lexical scoping, and is used in, for instance, the \"use strict\" pragma. The contents should be an integer; different bits of it are used for different pragmatic flags. Here's an example: sub add_100 { $^H |= 0x100 }\n\nsub foo {\n    BEGIN { add_100() }\n    bar->baz($boon);\n} Consider what happens during execution of the BEGIN block. At this point the BEGIN block has already been compiled, but the body of foo() is still being compiled. The new value of $^H will therefore be visible only while the body of foo() is being compiled. Substitution of the above BEGIN block with: BEGIN { require strict; strict->import('vars') } demonstrates how \"use strict 'vars'\" is implemented. Here's a conditional version of the same lexical pragma: BEGIN { require strict; strict->import('vars') if $condition } %^H The %^H hash provides the same scoping semantic as $^H. This makes it useful for implementation of lexically scoped pragmas. See perlpragma. $INPLACE_EDIT $^I The current value of the inplace-edit extension. Use \"undef\" to disable inplace editing. (Mnemonic: value of -i switch.) $^M By default, running out of memory is an untrappable, fatal error. However, if suitably built, Perl can use the contents of $^M as an emergency memory pool after die()ing. Suppose that your Perl were compiled with \"-DPERL_EMERGENCY_SBRK\" and used Perl's malloc. Then $^M = 'a' x (1 << 16); would allocate a 64K buffer for use in an emergency. See the INSTALL file in the Perl distribution for information on how to add custom C compilation flags when compiling perl. To discourage casual use of this advanced feature, there is no English long name for this variable. $OSNAME $^O The name of the operating system under which this copy of Perl was built, as determined during the configuration process. The value is identical to $Config{'osname'}. See also Config and the -V command-line switch documented in perlrun. In Windows platforms, $^O is not very helpful: since it is always \"MSWin32\", it doesn't tell the difference between 95\/98\/ME\/NT\/2000\/XP\/CE\/.NET. Use Win32::GetOSName() or Win32::GetOSVersion() (see Win32 and perlport) to distinguish between the variants. ${^OPEN} An internal variable used by PerlIO. A string in two parts, separated by a \"\\0\" byte, the first part describes the input layers, the second part describes the output layers. $PERLDB $^P The internal variable for debugging support. The meanings of the various bits are subject to change, but currently indicate: 0x01 Debug subroutine enter\/exit. 0x02 Line-by-line debugging. Causes DB::DB () subroutine to be called for each statement executed. Also causes saving source code lines (like 0x400). 0x04 Switch off optimizations. 0x08 Preserve more data for future interactive inspections. 0x10 Keep info about source lines on which a subroutine is defined. 0x20 Start with single-step on. 0x40 Use subroutine address instead of name when reporting. 0x80 Report \"goto &subroutine\" as well. 0x100 Provide informative \"file\" names for evals based on the place they were compiled. 0x200 Provide informative names to anonymous subroutines based on the place they were compiled. 0x400 Save source code lines into \"@{\"_<$filename\"}\". Some bits may be relevant at compile-time only, some at run-time only. This is a new mechanism and the details may change. See also perldebguts. $LAST_REGEXP_CODE_RESULT $^R The result of evaluation of the last successful \"(?{ code })\" regular expression assertion (see perlre). May be written to. $EXCEPTIONS_BEING_CAUGHT $^S Current state of the interpreter. $^S         State\n---------   -------------------\nundef       Parsing module\/eval\ntrue (1)    Executing an eval\nfalse (0)   Otherwise The first state may happen in $SIG{__DIE__} and $SIG{__WARN__} handlers. $BASETIME $^T The time at which the program began running, in seconds since the epoch (beginning of 1970). The values returned by the -M, -A, and -C filetests are based on this value. ${^TAINT} Reflects if taint mode is on or off. 1 for on (the program was run with -T), 0 for off, -1 when only taint warnings are enabled (i.e. with -t or -TU). This variable is read-only. ${^UNICODE} Reflects certain Unicode settings of Perl. See perlrun documentation for the \"-C\" switch for more information about the possible values. This variable is set during Perl startup and is thereafter read-only. ${^UTF8CACHE} This variable controls the state of the internal UTF-8 offset caching code. 1 for on (the default), 0 for off, -1 to debug the caching code by checking all its results against linear scans, and panicking on any discrepancy. ${^UTF8LOCALE} This variable indicates whether an UTF-8 locale was detected by perl at startup. This information is used by perl when it's in adjust-utf8ness-to-locale mode (as when run with the \"-CL\" command-line switch); see perlrun for more info on this. $PERL_VERSION $^V The revision, version, and subversion of the Perl interpreter, represented as a \"version\" object. This variable first appeared in perl 5.6.0; earlier versions of perl will see an undefined value. Before perl 5.10.0 $^V was represented as a v-string. $^V can be used to determine whether the Perl interpreter executing a script is in the right range of versions. (Mnemonic: use ^V for Version Control.) Example: warn \"Hashes not randomized!\\n\" if !$^V or $^V lt v5.8.1 To convert $^V into its string representation use sprintf()'s \"%vd\" conversion: printf \"version is v%vd\\n\", $^V;  # Perl's version See the documentation of \"use VERSION\" and \"require VERSION\" for a convenient way to fail if the running Perl interpreter is too old. See also $] for an older representation of the Perl version. $WARNING $^W The current value of the warning switch, initially true if -w was used, false otherwise, but directly modifiable. (Mnemonic: related to the -w switch.) See also warnings. ${^WARNING_BITS} The current set of warning checks enabled by the \"use warnings\" pragma. See the documentation of \"warnings\" for more details. ${^WIN32_SLOPPY_STAT} If this variable is set to a true value, then stat() on Windows will not try to open the file. This means that the link count cannot be determined and file attributes may be out of date if additional hardlinks to the file exist. On the other hand, not opening the file is considerably faster, especially for files on network drives. This variable could be set in the sitecustomize.pl file to configure the local Perl installation to use \"sloppy\" stat() by default. See perlrun for more information about site customization. $EXECUTABLE_NAME $^X The name used to execute the current copy of Perl, from C's \"argv[0]\" or (where supported) \/proc\/self\/exe. Depending on the host operating system, the value of $^X may be a relative or absolute pathname of the perl program file, or may be the string used to invoke perl but not the pathname of the perl program file. Also, most operating systems permit invoking programs that are not in the PATH environment variable, so there is no guarantee that the value of $^X is in PATH . For VMS , the value may or may not include a version number. You usually can use the value of $^X to re-invoke an independent copy of the same perl that is currently running, e.g., @first_run = `$^X -le \"print int rand 100 for 1..100\"`; But recall that not all operating systems support forking or capturing of the output of commands, so this complex statement may not be portable. It is not safe to use the value of $^X as a path name of a file, as some operating systems that have a mandatory suffix on executable files do not require use of the suffix when invoking a command. To convert the value of $^X to a path name, use the following statements: # Build up a set of file names (not command names).\nuse Config;\n$this_perl = $^X;\nif ($^O ne 'VMS')\n   {$this_perl .= $Config{_exe}\n        unless $this_perl =~ m\/$Config{_exe}$\/i;} Because many operating systems permit anyone with read access to the Perl program file to make a copy of it, patch the copy, and then execute the copy, the security-conscious Perl programmer should take care to invoke the installed copy of perl, not the copy referenced by $^X. The following statements accomplish this goal, and produce a pathname that can be invoked as a command or referenced as a file. use Config;\n$secure_perl_path = $Config{perlpath};\nif ($^O ne 'VMS')\n   {$secure_perl_path .= $Config{_exe}\n        unless $secure_perl_path =~ m\/$Config{_exe}$\/i;} ARGV The special filehandle that iterates over command-line filenames in @ARGV. Usually written as the null filehandle in the angle operator \"<>\". Note that currently \"ARGV\" only has its magical effect within the \"<>\" operator; elsewhere it is just a plain filehandle corresponding to the last file opened by \"<>\". In particular, passing \"\\*ARGV\" as a parameter to a function that expects a filehandle may not cause your function to automatically read the contents of all the files in @ARGV. $ARGV contains the name of the current file when reading from <>. @ARGV The array @ARGV contains the command-line arguments intended for the script. $#ARGV is generally the number of arguments minus one, because $ARGV[0] is the first argument, not the program's command name itself. See $0 for the command name. ARGVOUT The special filehandle that points to the currently open output file when doing edit-in-place processing with -i. Useful when you have to do a lot of inserting and don't want to keep modifying $_. See perlrun for the -i switch. @F The array @F contains the fields of each line read in when autosplit mode is turned on. See perlrun for the -a switch. This array is package-specific, and must be declared or given a full package name if not in package main when running under \"strict 'vars'\". @INC The array @INC contains the list of places that the \"do EXPR\", \"require\", or \"use\" constructs look for their library files. It initially consists of the arguments to any -I command-line switches, followed by the default Perl library, probably \/usr\/local\/lib\/perl, followed by \".\", to represent the current directory. (\".\" will not be appended if taint checks are enabled, either by \"-T\" or by \"-t\".) If you need to modify this at runtime, you should use the \"use lib\" pragma to get the machine-dependent library properly loaded also: use lib '\/mypath\/libdir\/';\nuse SomeMod; You can also insert hooks into the file inclusion system by putting Perl code directly into @INC. Those hooks may be subroutine references, array references or blessed objects. See \"require\" in perlfunc for details. @ARG @_ Within a subroutine the array @_ contains the parameters passed to that subroutine. See perlsub. %INC The hash %INC contains entries for each filename included via the \"do\", \"require\", or \"use\" operators. The key is the filename you specified (with module names converted to pathnames), and the value is the location of the file found. The \"require\" operator uses this hash to determine whether a particular file has already been included. If the file was loaded via a hook (e.g. a subroutine reference, see \"require\" in perlfunc for a description of these hooks), this hook is by default inserted into %INC in place of a filename. Note, however, that the hook may have set the %INC entry by itself to provide some more specific info. %ENV $ENV{expr} The hash %ENV contains your current environment. Setting a value in \"ENV\" changes the environment for any child processes you subsequently fork() off. %SIG $SIG{expr} The hash %SIG contains signal handlers for signals. For example: sub handler {       # 1st argument is signal name\n    my($sig) = @_;\n    print \"Caught a SIG$sig--shutting down\\n\";\n    close(LOG);\n    exit(0);\n}\n\n$SIG{'INT'}  = \\&handler;\n$SIG{'QUIT'} = \\&handler;\n...\n$SIG{'INT'}  = 'DEFAULT';   # restore default action\n$SIG{'QUIT'} = 'IGNORE';    # ignore SIGQUIT Using a value of 'IGNORE' usually has the effect of ignoring the signal, except for the \"CHLD\" signal. See perlipc for more about this special case. Here are some other examples: $SIG{\"PIPE\"} = \"Plumber\";   # assumes main::Plumber (not recommended)\n$SIG{\"PIPE\"} = \\&Plumber;   # just fine; assume current Plumber\n$SIG{\"PIPE\"} = *Plumber;    # somewhat esoteric\n$SIG{\"PIPE\"} = Plumber();   # oops, what did Plumber() return?? Be sure not to use a bareword as the name of a signal handler, lest you inadvertently call it. If your system has the sigaction() function then signal handlers are installed using it. This means you get reliable signal handling. The default delivery policy of signals changed in Perl 5.8.0 from immediate (also known as \"unsafe\") to deferred, also known as \"safe signals\". See perlipc for more information. Certain internal hooks can be also set using the %SIG hash. The routine indicated by $SIG{__WARN__} is called when a warning message is about to be printed. The warning message is passed as the first argument. The presence of a \"__WARN__\" hook causes the ordinary printing of warnings to \"STDERR\" to be suppressed. You can use this to save warnings in a variable, or turn warnings into fatal errors, like this: local $SIG{__WARN__} = sub { die $_[0] };\neval $proggie; As the 'IGNORE' hook is not supported by \"__WARN__\", you can disable warnings using the empty subroutine: local $SIG{__WARN__} = sub {}; The routine indicated by $SIG{__DIE__} is called when a fatal exception is about to be thrown. The error message is passed as the first argument. When a \"__DIE__\" hook routine returns, the exception processing continues as it would have in the absence of the hook, unless the hook routine itself exits via a \"goto\", a loop exit, or a \"die()\". The \"__DIE__\" handler is explicitly disabled during the call, so that you can die from a \"__DIE__\" handler. Similarly for \"__WARN__\". Due to an implementation glitch, the $SIG{__DIE__} hook is called even inside an eval(). Do not use this to rewrite a pending exception in $@, or as a bizarre substitute for overriding \"CORE::GLOBAL::die()\". This strange action at a distance may be fixed in a future release so that $SIG{__DIE__} is only called if your program is about to exit, as was the original intent. Any other use is deprecated. \"__DIE__\"\/\"__WARN__\" handlers are very special in one respect: they may be called to report (probable) errors found by the parser. In such a case the parser may be in inconsistent state, so any attempt to evaluate Perl code from such a handler will probably result in a segfault. This means that warnings or errors that result from parsing Perl should be used with extreme caution, like this: require Carp if defined $^S;\nCarp::confess(\"Something wrong\") if defined &Carp::confess;\ndie \"Something wrong, but could not load Carp to give backtrace...\n     To see backtrace try starting Perl with -MCarp switch\"; Here the first line will load Carp unless it is the parser who called the handler. The second line will print backtrace and die if Carp was available. The third line will be executed only if Carp was not available. See \"die\" in perlfunc, \"warn\" in perlfunc, \"eval\" in perlfunc, and warnings for additional information. Error Indicators The variables $@, $!, $^E, and $? contain information about different types of error conditions that may appear during execution of a Perl program. The variables are shown ordered by the \"distance\" between the subsystem which reported the error and the Perl process. They correspond to errors detected by the Perl interpreter, C library, operating system, or an external program, respectively. To illustrate the differences between these variables, consider the following Perl expression, which uses a single-quoted string: eval q{\n    open my $pipe, \"\/cdrom\/install |\" or die $!;\n    my @res = <$pipe>;\n    close $pipe or die \"bad pipe: $?, $!\";\n}; After execution of this statement all 4 variables may have been set. $@ is set if the string to be \"eval\"-ed did not compile (this may happen if \"open\" or \"close\" were imported with bad prototypes), or if Perl code executed during evaluation die()d . In these cases the value of $@ is the compile error, or the argument to \"die\" (which will interpolate $! and $?). (See also Fatal, though.) When the eval() expression above is executed, open(), \"<PIPE>\", and \"close\" are translated to calls in the C run-time library and thence to the operating system kernel. $! is set to the C library's \"errno\" if one of these calls fails. Under a few operating systems, $^E may contain a more verbose error indicator, such as in this case, \" CDROM tray not closed.\" Systems that do not support extended error messages leave $^E the same as $!. Finally, $? may be set to non-0 value if the external program \/cdrom\/install fails. The upper eight bits reflect specific error conditions encountered by the program (the program's exit() value). The lower eight bits reflect mode of failure, like signal death and core dump information See wait(2) for details. In contrast to $! and $^E, which are set only if error condition is detected, the variable $? is set on each \"wait\" or pipe \"close\", overwriting the old value. This is more like $@, which on every eval() is always set on failure and cleared on success. For more details, see the individual descriptions at $@, $!, $^E, and $?. Technical Note on the Syntax of Variable Names Variable names in Perl can have several formats. Usually, they must begin with a letter or underscore, in which case they can be arbitrarily long (up to an internal limit of 251 characters) and may contain letters, digits, underscores, or the special sequence \"::\" or \"'\". In this case, the part before the last \"::\" or \"'\" is taken to be a package qualifier; see perlmod. Perl variable names may also be a sequence of digits or a single punctuation or control character. These names are all reserved for special uses by Perl; for example, the all-digits names are used to hold data captured by backreferences after a regular expression match. Perl has a special syntax for the single-control-character names: It understands \"^X\" (caret \"X\") to mean the control-\"X\" character. For example, the notation $^W (dollar-sign caret \"W\") is the scalar variable whose name is the single character control-\"W\". This is better than typing a literal control-\"W\" into your program. Finally, new in Perl 5.6, Perl variable names may be alphanumeric strings that begin with control characters (or better yet, a caret). These variables must be written in the form \"${^Foo}\"; the braces are not optional. \"${^Foo}\" denotes the scalar variable whose name is a control-\"F\" followed by two \"o\"'s. These variables are reserved for future special uses by Perl, except for the ones that begin with \"^_\" (control-underscore or caret-underscore). No control-character name that begins with \"^_\" will acquire a special meaning in any future version of Perl; such names may therefore be used safely in programs. $^_ itself, however, is reserved. Perl identifiers that begin with digits, control characters, or punctuation characters are exempt from the effects of the \"package\" declaration and are always forced to be in package \"main\"; they are also exempt from \"strict 'vars'\" errors. A few other names are also exempt in these ways: ENV             STDIN\nINC             STDOUT\nARGV            STDERR\nARGVOUT         _\nSIG In particular, the new special \"${^_XYZ}\" variables are always taken to be in package \"main\", regardless of any \"package\" declarations presently in scope.","Process Name":"perlvar","Link":"https:\/\/linux.die.net\/man\/1\/perlvar"}},{"Process":{"Description":"\"perlver\" is a console script created to provide convenient access to the functionality provided by Perl::MinimumVersion. The synopsis above pretty much covers all you need to know at this point.","Process Name":"perlver","Link":"https:\/\/linux.die.net\/man\/1\/perlver"}},{"Process":{"Description":"This is a fully ported perl for VM\/ESA 2.3.0. It may work on other versions, but that's the one we've tested it on. If you've downloaded the binary distribution, it needs to be installed below \/usr\/local. Source code distributions have an automated \"make install\" step that means you do not need to extract the source code below \/usr\/local (though that is where it will be installed by default). You may need to worry about the networking configuration files discussed in the last bullet below. Unpacking Perl Distribution on VM\/ESA To extract an ASCII tar archive on VM\/ESA , try this: pax -o to=IBM-1047,from=ISO8859-1 -r < latest.tar Setup Perl and utilities on VM\/ESA GNU make for VM\/ESA , which may be required for the build of perl, is available from: http:\/\/vm.marist.edu\/~neale\/vmoe.html Configure Perl on VM\/ESA Once you've unpacked the distribution, run Configure (see INSTALL for full discussion of the Configure options), and then run make, then \"make test\" then \"make install\" (this last step may require UID=0 privileges). There is a \"hints\" file for vmesa that specifies the correct values for most things. Some things to watch out for are: \u2022 this port does support dynamic loading but it's not had much testing \u2022 Don't turn on the compiler optimization flag \"-O\". There's a bug in the compiler ( APAR PQ18812 ) that generates some bad code the optimizer is on. \u2022 As VM\/ESA doesn't fully support the fork() API programs relying on this call will not work. I've replaced fork()\/exec() with spawn() and the standalone exec() with spawn(). This has a side effect when opening unnamed pipes in a shell script: there is no child process generated under. \u2022 At the moment the hints file for VM\/ESA basically bypasses all of the automatic configuration process. This is because Configure relies on: 1. The header files living in the Byte File System (you could put the there if you want); 2. The C preprocessor including the #include statements in the preprocessor output (.i) file. Testing Anomalies of Perl on VM\/ESA The \"make test\" step runs a Perl Verification Procedure, usually before installation. As the 5.6.1 kit was being assembled the following \"failures\" were known to appear on some machines during \"make test\" (mostly due to ASCII vs. EBCDIC conflicts), your results may differ: [the list of failures being compiled] Usage Hints for Perl on VM\/ESA When using perl on VM\/ESA please keep in mind that the EBCDIC and ASCII character sets are different. Perl builtin functions that may behave differently under EBCDIC are mentioned in the perlport.pod document. OpenEdition ( UNIX System Services) does not (yet) support the #! means of script invocation. See: head `whence perldoc` for an example of how to use the \"eval exec\" trick to ask the shell to have perl run your scripts for you.","Process Name":"perlvmesa","Link":"https:\/\/linux.die.net\/man\/1\/perlvmesa"}},{"Process":{"Description":"Gathered below are notes describing details of Perl 5's behavior on VMS . They are a supplement to the regular Perl 5 documentation, so we have focussed on the ways in which Perl 5 functions differently under VMS than it does under Unix, and on the interactions between Perl and the rest of the operating system. We haven't tried to duplicate complete descriptions of Perl features from the main Perl documentation, which can be found in the [.pod] subdirectory of the Perl distribution. We hope these notes will save you from confusion and lost sleep when writing Perl scripts on VMS . If you find we've missed something you think should appear here, please don't hesitate to drop a line to vmsperl@perl.org.","Process Name":"perlvms","Link":"https:\/\/linux.die.net\/man\/1\/perlvms"}},{"Process":{"Description":"","Process Name":"perlvos","Link":"https:\/\/linux.die.net\/man\/1\/perlvos"}},{"Process":{"Description":"Before you start, you should glance through the README file found in the top-level directory to which the Perl distribution was extracted. Make sure you read and understand the terms under which this software is being distributed. Also make sure you read \" BUGS AND CAVEATS \" below for the known limitations of this port. The INSTALL file in the perl top-level has much information that is only relevant to people building Perl on Unix-like systems. In particular, you can safely ignore any information that talks about \"Configure\". You may also want to look at two other options for building a perl that will work on Windows NT: the README .cygwin and README .os2 files, each of which give a different set of rules to build a Perl that will work on Win32 platforms. Those two methods will probably enable you to build a more Unix-compatible perl, but you will also need to download and use various other build-time and run-time support software described in those files. This set of instructions is meant to describe a so-called \"native\" port of Perl to Win32 platforms. This includes both 32-bit and 64-bit Windows operating systems. The resulting Perl requires no additional software to run (other than what came with your operating system). Currently, this port is capable of using one of the following compilers on the Intel x86 architecture: Borland C++           version 5.02 or later\nMicrosoft Visual C++  version 2.0 or later\nMinGW with gcc        gcc version 2.95.2 or later The last of these is a high quality freeware compiler. Use version 3.2.x or later for the best results with this compiler. The Borland C ++ and Microsoft Visual C ++ compilers are also now being given away free. The Borland compiler is available as \"Borland C ++ Compiler Free Command Line Tools\" and is the same compiler that ships with the full \"Borland C ++ Builder\" product. The Microsoft compiler is available as \"Visual C ++ Toolkit 2003\" or \"Visual C ++ 2005\/2008 Express Edition\" (and also as part of the \".NET Framework SDK \") and is the same compiler that ships with \"Visual C ++ .NET 2003 Professional\" or \"Visual C ++ 2005\/2008 Professional\" respectively. This port can also be built on the Intel IA64 using: Microsoft Platform SDK    Nov 2001 (64-bit compiler and tools) The MS Platform SDK can be downloaded from http:\/\/www.microsoft.com\/. This port fully supports MakeMaker (the set of modules that is used to build extensions to perl). Therefore, you should be able to build and install most extensions found in the CPAN sites. See \"Usage Hints for Perl on Win32\" below for general hints about this. Setting Up Perl on Win32 Make You need a \"make\" program to build the sources. If you are using Visual C ++ or the Platform SDK tools under Windows NT\/2000\/XP , nmake will work. All other builds need dmake. dmake is a freely available make that has very nice macro features and parallelability. A port of dmake for Windows is available from: http:\/\/search.cpan.org\/dist\/dmake\/ Fetch and install dmake somewhere on your path. There exists a minor coexistence problem with dmake and Borland C ++ compilers. Namely, if a distribution has C files named with mixed case letters, they will be compiled into appropriate .obj-files named with all lowercase letters, and every time dmake is invoked to bring files up to date, it will try to recompile such files again. For example, Tk distribution has a lot of such files, resulting in needless recompiles every time dmake is invoked. To avoid this, you may use the script \"sync_ext.pl\" after a successful build. It is available in the win32 subdirectory of the Perl source distribution. Command Shell Use the default \"cmd\" shell that comes with NT . Some versions of the popular 4DOS\/NT shell have incompatibilities that may cause you trouble. If the build fails under that shell, try building again with the cmd shell. The nmake Makefile also has known incompatibilities with the \"command.com\" shell that comes with Windows 9x. You will need to use dmake and makefile.mk to build under Windows 9x. The surest way to build it is on Windows NT\/2000\/XP , using the cmd shell. Make sure the path to the build directory does not contain spaces. The build usually works in this circumstance, but some tests will fail. Borland C ++ If you are using the Borland compiler, you will need dmake. (The make that Borland supplies is seriously crippled and will not work for MakeMaker builds.) See \"Make\" above. Microsoft Visual C ++ The nmake that comes with Visual C ++ will suffice for building. You will need to run the VCVARS32 .BAT file, usually found somewhere like C:\\MSDEV4.2\\BIN or C:\\Program Files\\Microsoft Visual Studio\\VC98\\Bin. This will set your build environment. You can also use dmake to build using Visual C ++ ; provided, however, you set OSRELEASE to \"microsft\" (or whatever the directory name under which the Visual C dmake configuration lives) in your environment and edit win32\/config.vc to change \"make=nmake\" into \"make=dmake\". The latter step is only essential if you want to use dmake as your default make for building extensions using MakeMaker. Microsoft Visual C ++ 2008 Express Edition This free version of Visual C ++ 2008 Professional contains the same compiler and linker that ship with the full version, and also contains everything necessary to build Perl, rather than requiring a separate download of the Platform SDK like previous versions did. This package can be downloaded by searching for \"Visual Studio 2008 Express Edition\" in the Download Center at http:\/\/www.microsoft.com\/downloads\/search.aspx?displaylang=en. (Providing exact links to these packages has proven a pointless task because the links keep on changing so often.) Install Visual C ++ 2008, then setup your environment using C:\\Program Files\\Microsoft Visual Studio 9.0\\Common7\\Tools\\vsvars32.bat (assuming the default installation location was chosen). Perl should now build using the win32\/Makefile. You will need to edit that file to set CCTYPE = MSVC90FREE first. Microsoft Visual C ++ 2005 Express Edition This free version of Visual C ++ 2005 Professional contains the same compiler and linker that ship with the full version, but doesn't contain everything necessary to build Perl. You will also need to download the \"Platform SDK \" (the \"Core SDK \" and \" MDAC SDK \" components are required) for more header files and libraries. These packages can both be downloaded by searching in the Download Center at http:\/\/www.microsoft.com\/downloads\/search.aspx?displaylang=en. (Providing exact links to these packages has proven a pointless task because the links keep on changing so often.) Try to obtain the latest version of the Platform SDK . Sometimes these packages contain a particular Windows OS version in their name, but actually work on other OS versions too. For example, the \"Windows Server 2003 R2 Platform SDK \" also runs on Windows XP SP2 and Windows 2000. According to the download pages these packages are only supported on Windows 2000\/XP\/2003, so trying to use these tools on Windows 95\/98\/ME and even Windows NT probably won't work. Install Visual C ++ 2005 first, then the Platform SDK . Setup your environment as follows (assuming default installation locations were chosen): SET PlatformSDKDir=C:\\Program Files\\Microsoft Platform SDK\n\nSET PATH=%SystemRoot%\\system32;%SystemRoot%;C:\\Program Files\\Microsoft Visual Studio 8\\Common7\\IDE;C:\\Program Files\\Microsoft Visual Studio 8\\VC\\BIN;C:\\Program Files\\Microsoft Visual Studio 8\\Common7\\Tools;C:\\Program Files\\Microsoft Visual Studio 8\\SDK\\v2.0\\bin;C:\\WINDOWS\\Microsoft.NET\\Framework\\v2.0.50727;C:\\Program Files\\Microsoft Visual Studio 8\\VC\\VCPackages;%PlatformSDKDir%\\Bin\n\nSET INCLUDE=C:\\Program Files\\Microsoft Visual Studio 8\\VC\\INCLUDE;%PlatformSDKDir%\\include\n\nSET LIB=C:\\Program Files\\Microsoft Visual Studio 8\\VC\\LIB;C:\\Program Files\\Microsoft Visual Studio 8\\SDK\\v2.0\\lib;%PlatformSDKDir%\\lib\n\nSET LIBPATH=C:\\WINDOWS\\Microsoft.NET\\Framework\\v2.0.50727 (The PlatformSDKDir might need to be set differently depending on which version you are using. Earlier versions installed into \"C:\\Program Files\\Microsoft SDK \", while the latest versions install into version-specific locations such as \"C:\\Program Files\\Microsoft Platform SDK for Windows Server 2003 R2\".) Perl should now build using the win32\/Makefile. You will need to edit that file to set CCTYPE = MSVC80FREE and to set CCHOME , CCINCDIR and CCLIBDIR as per the environment setup above. Microsoft Visual C ++ Toolkit 2003 This free toolkit contains the same compiler and linker that ship with Visual C ++ .NET 2003 Professional, but doesn't contain everything necessary to build Perl. You will also need to download the \"Platform SDK \" (the \"Core SDK \" and \" MDAC SDK \" components are required) for header files, libraries and rc.exe, and \".NET Framework SDK \" for more libraries and nmake.exe. Note that the latter (which also includes the free compiler and linker) requires the \".NET Framework Redistributable\" to be installed first. This can be downloaded and installed separately, but is included in the \"Visual C ++ Toolkit 2003\" anyway. These packages can all be downloaded by searching in the Download Center at http:\/\/www.microsoft.com\/downloads\/search.aspx?displaylang=en. (Providing exact links to these packages has proven a pointless task because the links keep on changing so often.) Try to obtain the latest version of the Platform SDK . Sometimes these packages contain a particular Windows OS version in their name, but actually work on other OS versions too. For example, the \"Windows Server 2003 R2 Platform SDK \" also runs on Windows XP SP2 and Windows 2000. According to the download pages these packages are only supported on Windows 2000\/XP\/2003, so trying to use these tools on Windows 95\/98\/ME and even Windows NT probably won't work. Install the Toolkit first, then the Platform SDK , then the .NET Framework SDK . Setup your environment as follows (assuming default installation locations were chosen): SET PlatformSDKDir=C:\\Program Files\\Microsoft Platform SDK\n\nSET PATH=%SystemRoot%\\system32;%SystemRoot%;C:\\Program Files\\Microsoft Visual C++ Toolkit 2003\\bin;%PlatformSDKDir%\\Bin;C:\\Program Files\\Microsoft.NET\\SDK\\v1.1\\Bin\n\nSET INCLUDE=C:\\Program Files\\Microsoft Visual C++ Toolkit 2003\\include;%PlatformSDKDir%\\include;C:\\Program Files\\Microsoft Visual Studio .NET 2003\\Vc7\\include\n\nSET LIB=C:\\Program Files\\Microsoft Visual C++ Toolkit 2003\\lib;%PlatformSDKDir%\\lib;C:\\Program Files\\Microsoft Visual Studio .NET 2003\\Vc7\\lib (The PlatformSDKDir might need to be set differently depending on which version you are using. Earlier versions installed into \"C:\\Program Files\\Microsoft SDK \", while the latest versions install into version-specific locations such as \"C:\\Program Files\\Microsoft Platform SDK for Windows Server 2003 R2\".) Several required files will still be missing: \u2022 cvtres.exe is required by link.exe when using a .res file. It is actually installed by the .NET Framework SDK , but into a location such as the following: C:\\WINDOWS\\Microsoft.NET\\Framework\\v1.1.4322 Copy it from there to %PlatformSDKDir%\\Bin \u2022 lib.exe is normally used to build libraries, but link.exe with the \/lib option also works, so change win32\/config.vc to use it instead: Change the line reading: ar='lib' to: ar='link \/lib' It may also be useful to create a batch file called lib.bat in C:\\Program Files\\Microsoft Visual C ++ Toolkit 2003\\bin containing: @echo off\nlink \/lib %* for the benefit of any naughty C extension modules that you might want to build later which explicitly reference \"lib\" rather than taking their value from $Config{ar}. \u2022 setargv.obj is required to build perlglob.exe (and perl.exe if the USE_SETARGV option is enabled). The Platform SDK supplies this object file in source form in %PlatformSDKDir%\\src\\crt. Copy setargv.c, cruntime.h and internal.h from there to some temporary location and build setargv.obj using cl.exe \/c \/I. \/D_CRTBLD setargv.c Then copy setargv.obj to %PlatformSDKDir%\\lib Alternatively, if you don't need perlglob.exe and don't need to enable the USE_SETARGV option then you can safely just remove all mention of $( GLOBEXE ) from win32\/Makefile and setargv.obj won't be required anyway. Perl should now build using the win32\/Makefile. You will need to edit that file to set CCTYPE = MSVC70FREE and to set CCHOME , CCINCDIR and CCLIBDIR as per the environment setup above. Microsoft Platform SDK 64-bit Compiler The nmake that comes with the Platform SDK will suffice for building Perl. Make sure you are building within one of the \"Build Environment\" shells available after you install the Platform SDK from the Start Menu. MinGW release 3 with gcc The latest release of MinGW at the time of writing is 3.1.0, which contains gcc-3.2.3. It can be downloaded here: http:\/\/www.mingw.org\/ Perl also compiles with earlier releases of gcc (2.95.2 and up). See below for notes about using earlier versions of MinGW\/gcc. You also need dmake. See \"Make\" above on how to get it. MinGW release 1 with gcc The MinGW-1.1 bundle contains gcc-2.95.3. Make sure you install the binaries that work with MSVCRT .DLL as indicated in the README for the GCC bundle. You may need to set up a few environment variables (usually ran from a batch file). There are a couple of problems with the version of gcc-2.95.2-msvcrt.exe released 7 November 1999: \u2022 It left out a fix for certain command line quotes. To fix this, be sure to download and install the file fixes\/quote-fix-msvcrt.exe from the above ftp location. \u2022 The definition of the fpos_t type in stdio.h may be wrong. If your stdio.h has this problem, you will see an exception when running the test t\/lib\/io_xs.t. To fix this, change the typedef for fpos_t from \"long\" to \"long long\" in the file i386-mingw32msvc\/include\/stdio.h, and rebuild. A potentially simpler to install (but probably soon-to-be-outdated) bundle of the above package with the mentioned fixes already applied is available here: http:\/\/downloads.ActiveState.com\/pub\/staff\/gsar\/gcc-2.95.2-msvcrt.zip\nftp:\/\/ftp.ActiveState.com\/pub\/staff\/gsar\/gcc-2.95.2-msvcrt.zip Building \u2022 Make sure you are in the \"win32\" subdirectory under the perl toplevel. This directory contains a \"Makefile\" that will work with versions of nmake that come with Visual C ++ or the Platform SDK , and a dmake \"makefile.mk\" that will work for all supported compilers. The defaults in the dmake makefile are setup to build using MinGW\/gcc. \u2022 Edit the makefile.mk (or Makefile, if you're using nmake) and change the values of INST_DRV and INST_TOP . You can also enable various build flags. These are explained in the makefiles. Note that it is generally not a good idea to try to build a perl with INST_DRV and INST_TOP set to a path that already exists from a previous build. In particular, this may cause problems with the lib\/ExtUtils\/t\/Embed.t test, which attempts to build a test program and may end up building against the installed perl's lib\/CORE directory rather than the one being tested. You will have to make sure that CCTYPE is set correctly and that CCHOME points to wherever you installed your compiler. The default value for CCHOME in the makefiles for Visual C ++ may not be correct for some versions. Make sure the default exists and is valid. You may also need to comment out the \"DELAYLOAD = ...\" line in the Makefile if you're using VC++ 6.0 without the latest service pack and the linker reports an internal error. If you are using VC++ 4.2 or earlier then you'll have to change the \/EHsc option in the CXX_FLAG macro to the equivalent \/GX option. If you have either the source or a library that contains des_fcrypt(), enable the appropriate option in the makefile. A ready-to-use version of fcrypt.c, based on the version originally written by Eric Young at ftp:\/\/ftp.funet.fi\/pub\/crypt\/mirrors\/dsi\/libdes\/, is bundled with the distribution and CRYPT_SRC is set to use it. Alternatively, if you have built a library that contains des_fcrypt(), you can set CRYPT_LIB to point to the library name. Perl will also build without des_fcrypt(), but the crypt() builtin will fail at run time. If you want build some core extensions statically into perl's dll, specify them in the STATIC_EXT macro. Be sure to read the instructions near the top of the makefiles carefully. \u2022 Type \"dmake\" (or \"nmake\" if you are using that make). This should build everything. Specifically, it will create perl.exe, perl510.dll at the perl toplevel, and various other extension dll's under the lib\\auto directory. If the build fails for any reason, make sure you have done the previous steps correctly. Testing Perl on Win32 Type \"dmake test\" (or \"nmake test\"). This will run most of the tests from the testsuite (many tests will be skipped). There should be no test failures when running under Windows NT\/2000\/XP . Many tests will fail under Windows 9x due to the inferior command shell. Some test failures may occur if you use a command shell other than the native \"cmd.exe\", or if you are building from a path that contains spaces. So don't do that. If you are running the tests from a emacs shell window, you may see failures in op\/stat.t. Run \"dmake test-notty\" in that case. If you're using the Borland compiler, you may see a failure in op\/taint.t arising from the inability to find the Borland Runtime DLLs on the system default path. You will need to copy the DLLs reported by the messages from where Borland chose to install it, into the Windows system directory (usually somewhere like C:\\WINNT\\SYSTEM32) and rerun the test. If you're using Borland compiler versions 5.2 and below, you may run into problems finding the correct header files when building extensions. For example, building the \"Tk\" extension may fail because both perl and Tk contain a header file called \"patchlevel.h\". The latest Borland compiler (v5.5) is free of this misbehaviour, and it even supports an option -VI- for backward (bugward) compatibility for using the old Borland search algorithm to locate header files. If you run the tests on a FAT partition, you may see some failures for \"link()\" related tests (op\/write.t, op\/stat.t ...). Testing on NTFS avoids these errors. Furthermore, you should make sure that during \"make test\" you do not have any GNU tool packages in your path: some toolkits like Unixutils include some tools (\"type\" for instance) which override the Windows ones and makes tests fail. Remove them from your path while testing to avoid these errors. Please report any other failures as described under \" BUGS AND CAVEATS \". Installation of Perl on Win32 Type \"dmake install\" (or \"nmake install\"). This will put the newly built perl and the libraries under whatever \"INST_TOP\" points to in the Makefile. It will also install the pod documentation under \"$INST_TOP\\$INST_VER\\lib\\pod\" and HTML versions of the same under \"$INST_TOP\\$INST_VER\\lib\\pod\\html\". To use the Perl you just installed you will need to add a new entry to your PATH environment variable: \"$INST_TOP\\bin\", e.g. set PATH=c:\\perl\\bin;%PATH% If you opted to uncomment \"INST_VER\" and \"INST_ARCH\" in the makefile then the installation structure is a little more complicated and you will need to add two new PATH components instead: \"$INST_TOP\\$INST_VER\\bin\" and \"$INST_TOP\\$INST_VER\\bin\\$ARCHNAME\", e.g. set PATH=c:\\perl\\5.6.0\\bin;c:\\perl\\5.6.0\\bin\\MSWin32-x86;%PATH% Usage Hints for Perl on Win32 Environment Variables The installation paths that you set during the build get compiled into perl, so you don't have to do anything additional to start using that perl (except add its location to your PATH variable). If you put extensions in unusual places, you can set PERL5LIB to a list of paths separated by semicolons where you want perl to look for libraries. Look for descriptions of other environment variables you can set in perlrun. You can also control the shell that perl uses to run system() and backtick commands via PERL5SHELL . See perlrun. Perl does not depend on the registry, but it can look up certain default values if you choose to put them there. Perl attempts to read entries from \"HKEY_CURRENT_USER\\Software\\Perl\" and \"HKEY_LOCAL_MACHINE\\Software\\Perl\". Entries in the former override entries in the latter. One or more of the following entries (of type REG_SZ or REG_EXPAND_SZ ) may be set: lib-$]              version-specific standard library path to add to @INC\nlib                 standard library path to add to @INC\nsitelib-$]          version-specific site library path to add to @INC\nsitelib             site library path to add to @INC\nvendorlib-$]        version-specific vendor library path to add to @INC\nvendorlib           vendor library path to add to @INC\nPERL*               fallback for all %ENV lookups that begin with \"PERL\" Note the $] in the above is not literal. Substitute whatever version of perl you want to honor that entry, e.g. 5.6.0. Paths must be separated with semicolons, as usual on win32. File Globbing By default, perl handles file globbing using the File::Glob extension, which provides portable globbing. If you want perl to use globbing that emulates the quirks of DOS filename conventions, you might want to consider using File::DosGlob to override the internal glob() implementation. See File::DosGlob for details. Using perl from the command line If you are accustomed to using perl from various command-line shells found in UNIX environments, you will be less than pleased with what Windows offers by way of a command shell. The crucial thing to understand about the Windows environment is that the command line you type in is processed twice before Perl sees it. First, your command shell (usually CMD .EXE on Windows NT , and COMMAND .COM on Windows 9x) preprocesses the command line, to handle redirection, environment variable expansion, and location of the executable to run. Then, the perl executable splits the remaining command line into individual arguments, using the C runtime library upon which Perl was built. It is particularly important to note that neither the shell nor the C runtime do any wildcard expansions of command-line arguments (so wildcards need not be quoted). Also, the quoting behaviours of the shell and the C runtime are rudimentary at best (and may, if you are using a non-standard shell, be inconsistent). The only (useful) quote character is the double quote (\"). It can be used to protect spaces and other special characters in arguments. The Windows NT documentation has almost no description of how the quoting rules are implemented, but here are some general observations based on experiments: The C runtime breaks arguments at spaces and passes them to programs in argc\/argv. Double quotes can be used to prevent arguments with spaces in them from being split up. You can put a double quote in an argument by escaping it with a backslash and enclosing the whole argument within double quotes. The backslash and the pair of double quotes surrounding the argument will be stripped by the C runtime. The file redirection characters \"<\", \">\", and \"|\" can be quoted by double quotes (although there are suggestions that this may not always be true). Single quotes are not treated as quotes by the shell or the C runtime, they don't get stripped by the shell (just to make this type of quoting completely useless). The caret \"^\" has also been observed to behave as a quoting character, but this appears to be a shell feature, and the caret is not stripped from the command line, so Perl still sees it (and the C runtime phase does not treat the caret as a quote character). Here are some examples of usage of the \"cmd\" shell: This prints two doublequotes: perl -e \"print '\\\"\\\"' \" This does the same: perl -e \"print \\\"\\\\\\\"\\\\\\\"\\\" \" This prints \"bar\" and writes \"foo\" to the file \"blurch\": perl -e \"print 'foo'; print STDERR 'bar'\" > blurch This prints \"foo\" (\"bar\" disappears into nowhereland): perl -e \"print 'foo'; print STDERR 'bar'\" 2> nul This prints \"bar\" and writes \"foo\" into the file \"blurch\": perl -e \"print 'foo'; print STDERR 'bar'\" 1> blurch This pipes \"foo\" to the \"less\" pager and prints \"bar\" on the console: perl -e \"print 'foo'; print STDERR 'bar'\" | less This pipes \"foo\\nbar\\n\" to the less pager: perl -le \"print 'foo'; print STDERR 'bar'\" 2>&1 | less This pipes \"foo\" to the pager and writes \"bar\" in the file \"blurch\": perl -e \"print 'foo'; print STDERR 'bar'\" 2> blurch | less Discovering the usefulness of the \"command.com\" shell on Windows 9x is left as an exercise to the reader :) One particularly pernicious problem with the 4NT command shell for Windows NT is that it (nearly) always treats a % character as indicating that environment variable expansion is needed. Under this shell, it is therefore important to always double any % characters which you want Perl to see (for example, for hash variables), even when they are quoted. Building Extensions The Comprehensive Perl Archive Network ( CPAN ) offers a wealth of extensions, some of which require a C compiler to build. Look in http:\/\/www.cpan.org\/ for more information on CPAN . Note that not all of the extensions available from CPAN may work in the Win32 environment; you should check the information at http:\/\/testers.cpan.org\/ before investing too much effort into porting modules that don't readily build. Most extensions (whether they require a C compiler or not) can be built, tested and installed with the standard mantra: perl Makefile.PL\n$MAKE\n$MAKE test\n$MAKE install where $MAKE is whatever 'make' program you have configured perl to use. Use \"perl -V:make\" to find out what this is. Some extensions may not provide a testsuite (so \"$MAKE test\" may not do anything or fail), but most serious ones do. It is important that you use a supported 'make' program, and ensure Config.pm knows about it. If you don't have nmake, you can either get dmake from the location mentioned earlier or get an old version of nmake reportedly available from: http:\/\/download.microsoft.com\/download\/vc15\/Patch\/1.52\/W95\/EN-US\/nmake15.exe Another option is to use the make written in Perl, available from CPAN . http:\/\/www.cpan.org\/modules\/by-module\/Make\/ You may also use dmake. See \"Make\" above on how to get it. Note that MakeMaker actually emits makefiles with different syntax depending on what 'make' it thinks you are using. Therefore, it is important that one of the following values appears in Config.pm: make='nmake'        # MakeMaker emits nmake syntax\nmake='dmake'        # MakeMaker emits dmake syntax\nany other value     # MakeMaker emits generic make syntax\n                        (e.g GNU make, or Perl make) If the value doesn't match the 'make' program you want to use, edit Config.pm to fix it. If a module implements XSUBs, you will need one of the supported C compilers. You must make sure you have set up the environment for the compiler for command-line compilation. If a module does not build for some reason, look carefully for why it failed, and report problems to the module author. If it looks like the extension building support is at fault, report that with full details of how the build failed using the perlbug utility. Command-line Wildcard Expansion The default command shells on DOS descendant operating systems (such as they are) usually do not expand wildcard arguments supplied to programs. They consider it the application's job to handle that. This is commonly achieved by linking the application (in our case, perl) with startup code that the C runtime libraries usually provide. However, doing that results in incompatible perl versions (since the behavior of the argv expansion code differs depending on the compiler, and it is even buggy on some compilers). Besides, it may be a source of frustration if you use such a perl binary with an alternate shell that *does* expand wildcards. Instead, the following solution works rather well. The nice things about it are 1) you can start using it right away; 2) it is more powerful, because it will do the right thing with a pattern like *\/*\/*.c; 3) you can decide whether you do\/don't want to use it; and 4) you can extend the method to add any customizations (or even entirely different kinds of wildcard expansion). C:\\> copy con c:\\perl\\lib\\Wild.pm\n# Wild.pm - emulate shell @ARGV expansion on shells that don't\nuse File::DosGlob;\n@ARGV = map {\n              my @g = File::DosGlob::glob($_) if \/[*?]\/;\n              @g ? @g : $_;\n            } @ARGV;\n1;\n^Z\nC:\\> set PERL5OPT=-MWild\nC:\\> perl -le \"for (@ARGV) { print }\" *\/*\/perl*.c\np4view\/perl\/perl.c\np4view\/perl\/perlio.c\np4view\/perl\/perly.c\nperl5.005\/win32\/perlglob.c\nperl5.005\/win32\/perllib.c\nperl5.005\/win32\/perlglob.c\nperl5.005\/win32\/perllib.c\nperl5.005\/win32\/perlglob.c\nperl5.005\/win32\/perllib.c Note there are two distinct steps there: 1) You'll have to create Wild.pm and put it in your perl lib directory. 2) You'll need to set the PERL5OPT environment variable. If you want argv expansion to be the default, just set PERL5OPT in your default startup environment. If you are using the Visual C compiler, you can get the C runtime's command line wildcard expansion built into perl binary. The resulting binary will always expand unquoted command lines, which may not be what you want if you use a shell that does that for you. The expansion done is also somewhat less powerful than the approach suggested above. Win32 Specific Extensions A number of extensions specific to the Win32 platform are available from CPAN . You may find that many of these extensions are meant to be used under the Activeware port of Perl, which used to be the only native port for the Win32 platform. Since the Activeware port does not have adequate support for Perl's extension building tools, these extensions typically do not support those tools either and, therefore, cannot be built using the generic steps shown in the previous section. To ensure smooth transitioning of existing code that uses the ActiveState port, there is a bundle of Win32 extensions that contains all of the ActiveState extensions and several other Win32 extensions from CPAN in source form, along with many added bugfixes, and with MakeMaker support. The latest version of this bundle is available at: http:\/\/search.cpan.org\/dist\/libwin32\/ See the README in that distribution for building and installation instructions. Notes on 64-bit Windows Windows .NET Server supports the LLP64 data model on the Intel Itanium architecture. The LLP64 data model is different from the LP64 data model that is the norm on 64-bit Unix platforms. In the former, \"int\" and \"long\" are both 32-bit data types, while pointers are 64 bits wide. In addition, there is a separate 64-bit wide integral type, \"__int64\". In contrast, the LP64 data model that is pervasive on Unix platforms provides \"int\" as the 32-bit type, while both the \"long\" type and pointers are of 64-bit precision. Note that both models provide for 64-bits of addressability. 64-bit Windows running on Itanium is capable of running 32-bit x86 binaries transparently. This means that you could use a 32-bit build of Perl on a 64-bit system. Given this, why would one want to build a 64-bit build of Perl? Here are some reasons why you would bother: \u2022 A 64-bit native application will run much more efficiently on Itanium hardware. \u2022 There is no 2GB limit on process size. \u2022 Perl automatically provides large file support when built under 64-bit Windows. \u2022 Embedding Perl inside a 64-bit application. Running Perl Scripts Perl scripts on UNIX use the \"#!\" (a.k.a \"shebang\") line to indicate to the OS that it should execute the file using perl. Win32 has no comparable means to indicate arbitrary files are executables. Instead, all available methods to execute plain text files on Win32 rely on the file \"extension\". There are three methods to use this to execute perl scripts: 1. There is a facility called \"file extension associations\" that will work in Windows NT 4.0. This can be manipulated via the two commands \"assoc\" and \"ftype\" that come standard with Windows NT 4.0. Type \"ftype \/?\" for a complete example of how to set this up for perl scripts (Say what? You thought Windows NT wasn't perl-ready? :). 2. Since file associations don't work everywhere, and there are reportedly bugs with file associations where it does work, the old method of wrapping the perl script to make it look like a regular batch file to the OS , may be used. The install process makes available the \"pl2bat.bat\" script which can be used to wrap perl scripts into batch files. For example: pl2bat foo.pl will create the file \" FOO .BAT\". Note \"pl2bat\" strips any .pl suffix and adds a .bat suffix to the generated file. If you use the 4DOS\/NT or similar command shell, note that \"pl2bat\" uses the \"%*\" variable in the generated batch file to refer to all the command line arguments, so you may need to make sure that construct works in batch files. As of this writing, 4DOS\/NT users will need a \"ParameterChar = *\" statement in their 4NT.INI file or will need to execute \"setdos \/p*\" in the 4DOS\/NT startup file to enable this to work. 3. Using \"pl2bat\" has a few problems: the file name gets changed, so scripts that rely on $0 to find what they must do may not run properly; running \"pl2bat\" replicates the contents of the original script, and so this process can be maintenance intensive if the originals get updated often. A different approach that avoids both problems is possible. A script called \"runperl.bat\" is available that can be copied to any filename (along with the .bat suffix). For example, if you call it \"foo.bat\", it will run the file \"foo\" when it is executed. Since you can run batch files on Win32 platforms simply by typing the name (without the extension), this effectively runs the file \"foo\", when you type either \"foo\" or \"foo.bat\". With this method, \"foo.bat\" can even be in a different location than the file \"foo\", as long as \"foo\" is available somewhere on the PATH . If your scripts are on a filesystem that allows symbolic links, you can even avoid copying \"runperl.bat\". Here's a diversion: copy \"runperl.bat\" to \"runperl\", and type \"runperl\". Explain the observed behavior, or lack thereof. :) Hint: .gnidnats llits er'uoy fi ,\"lrepnur\" eteled :tniH Miscellaneous Things A full set of HTML documentation is installed, so you should be able to use it if you have a web browser installed on your system. \"perldoc\" is also a useful tool for browsing information contained in the documentation, especially in conjunction with a pager like \"less\" (recent versions of which have Win32 support). You may have to set the PAGER environment variable to use a specific pager. \"perldoc -f foo\" will print information about the perl operator \"foo\". One common mistake when using this port with a GUI library like \"Tk\" is assuming that Perl's normal behavior of opening a command-line window will go away. This isn't the case. If you want to start a copy of \"perl\" without opening a command-line window, use the \"wperl\" executable built during the installation process. Usage is exactly the same as normal \"perl\" on Win32, except that options like \"-h\" don't work (since they need a command-line window to print to). If you find bugs in perl, you can run \"perlbug\" to create a bug report (you may have to send it manually if \"perlbug\" cannot find a mailer on your system).","Process Name":"perlwin32","Link":"https:\/\/linux.die.net\/man\/1\/perlwin32"}},{"Process":{"Description":"Introduction XS is an interface description file format used to create an extension interface between Perl and C code (or a C library) which one wishes to use with Perl. The XS interface is combined with the library to create a new library which can then be either dynamically loaded or statically linked into perl. The XS interface description is written in the XS language and is the core component of the Perl extension interface. An XSUB forms the basic unit of the XS interface. After compilation by the xsubpp compiler, each XSUB amounts to a C function definition which will provide the glue between Perl calling conventions and C calling conventions. The glue code pulls the arguments from the Perl stack, converts these Perl values to the formats expected by a C function, call this C function, transfers the return values of the C function back to Perl. Return values here may be a conventional C return value or any C function arguments that may serve as output parameters. These return values may be passed back to Perl either by putting them on the Perl stack, or by modifying the arguments supplied from the Perl side. The above is a somewhat simplified view of what really happens. Since Perl allows more flexible calling conventions than C, XSUBs may do much more in practice, such as checking input parameters for validity, throwing exceptions (or returning undef\/empty list) if the return value from the C function indicates failure, calling different C functions based on numbers and types of the arguments, providing an object-oriented interface, etc. Of course, one could write such glue code directly in C. However, this would be a tedious task, especially if one needs to write glue for multiple C functions, and\/or one is not familiar enough with the Perl stack discipline and other such arcana. XS comes to the rescue here: instead of writing this glue C code in long-hand, one can write a more concise short-hand description of what should be done by the glue, and let the XS compiler xsubpp handle the rest. The XS language allows one to describe the mapping between how the C routine is used, and how the corresponding Perl routine is used. It also allows creation of Perl routines which are directly translated to C code and which are not related to a pre-existing C function. In cases when the C interface coincides with the Perl interface, the XSUB declaration is almost identical to a declaration of a C function (in K&R style). In such circumstances, there is another tool called \"h2xs\" that is able to translate an entire C header file into a corresponding XS file that will provide glue to the functions\/macros described in the header file. The XS compiler is called xsubpp. This compiler creates the constructs necessary to let an XSUB manipulate Perl values, and creates the glue necessary to let Perl call the XSUB . The compiler uses typemaps to determine how to map C function parameters and output values to Perl values and back. The default typemap (which comes with Perl) handles many common C types. A supplementary typemap may also be needed to handle any special structures and types for the library being linked. A file in XS format starts with a C language section which goes until the first \"MODULE =\" directive. Other XS directives and XSUB definitions may follow this line. The \"language\" used in this part of the file is usually referred to as the XS language. xsubpp recognizes and skips POD (see perlpod) in both the C and XS language sections, which allows the XS file to contain embedded documentation. See perlxstut for a tutorial on the whole extension creation process. Note: For some extensions, Dave Beazley's SWIG system may provide a significantly more convenient mechanism for creating the extension glue code. See http:\/\/www.swig.org\/ for more information. On The Road Many of the examples which follow will concentrate on creating an interface between Perl and the ONC+ RPC bind library functions. The rpcb_gettime() function is used to demonstrate many features of the XS language. This function has two parameters; the first is an input parameter and the second is an output parameter. The function also returns a status value. bool_t rpcb_gettime(const char *host, time_t *timep); From C this function will be called with the following statements. #include <rpc\/rpc.h>\nbool_t status;\ntime_t timep;\nstatus = rpcb_gettime( \"localhost\", &timep ); If an XSUB is created to offer a direct translation between this function and Perl, then this XSUB will be used from Perl with the following code. The $status and $timep variables will contain the output of the function. use RPC;\n$status = rpcb_gettime( \"localhost\", $timep ); The following XS file shows an XS subroutine, or XSUB , which demonstrates one possible interface to the rpcb_gettime() function. This XSUB represents a direct translation between C and Perl and so preserves the interface even from Perl. This XSUB will be invoked from Perl with the usage shown above. Note that the first three #include statements, for \"EXTERN.h\", \"perl.h\", and \"XSUB.h\", will always be present at the beginning of an XS file. This approach and others will be expanded later in this document. #include \"EXTERN.h\"\n#include \"perl.h\"\n#include \"XSUB.h\"\n#include <rpc\/rpc.h>\n\nMODULE = RPC  PACKAGE = RPC\n\nbool_t\nrpcb_gettime(host,timep)\n     char *host\n     time_t &timep\n   OUTPUT:\n     timep Any extension to Perl, including those containing XSUBs, should have a Perl module to serve as the bootstrap which pulls the extension into Perl. This module will export the extension's functions and variables to the Perl program and will cause the extension's XSUBs to be linked into Perl. The following module will be used for most of the examples in this document and should be used from Perl with the \"use\" command as shown earlier. Perl modules are explained in more detail later in this document. package RPC;\n\nrequire Exporter;\nrequire DynaLoader;\n@ISA = qw(Exporter DynaLoader);\n@EXPORT = qw( rpcb_gettime );\n\nbootstrap RPC;\n1; Throughout this document a variety of interfaces to the rpcb_gettime() XSUB will be explored. The XSUBs will take their parameters in different orders or will take different numbers of parameters. In each case the XSUB is an abstraction between Perl and the real C rpcb_gettime() function, and the XSUB must always ensure that the real rpcb_gettime() function is called with the correct parameters. This abstraction will allow the programmer to create a more Perl-like interface to the C function. The Anatomy of an XSUB The simplest XSUBs consist of 3 parts: a description of the return value, the name of the XSUB routine and the names of its arguments, and a description of types or formats of the arguments. The following XSUB allows a Perl program to access a C library function called sin(). The XSUB will imitate the C function which takes a single argument and returns a single value. double\nsin(x)\n  double x Optionally, one can merge the description of types and the list of argument names, rewriting this as double\nsin(double x) This makes this XSUB look similar to an ANSI C declaration. An optional semicolon is allowed after the argument list, as in double\nsin(double x); Parameters with C pointer types can have different semantic: C functions with similar declarations bool string_looks_as_a_number(char *s);\nbool make_char_uppercase(char *c); are used in absolutely incompatible manner. Parameters to these functions could be described xsubpp like this: char *  s\nchar    &c Both these XS declarations correspond to the \"char*\" C type, but they have different semantics, see \"The & Unary Operator\". It is convenient to think that the indirection operator \"*\" should be considered as a part of the type and the address operator \"&\" should be considered part of the variable. See \"The Typemap\" for more info about handling qualifiers and unary operators in C types. The function name and the return type must be placed on separate lines and should be flush left-adjusted. INCORRECT                        CORRECT\n\ndouble sin(x)                    double\n  double x                       sin(x)\n                                   double x The rest of the function description may be indented or left-adjusted. The following example shows a function with its body left-adjusted. Most examples in this document will indent the body for better readability. CORRECT\n\ndouble\nsin(x)\ndouble x More complicated XSUBs may contain many other sections. Each section of an XSUB starts with the corresponding keyword, such as INIT: or CLEANUP: . However, the first two lines of an XSUB always contain the same data: descriptions of the return type and the names of the function and its parameters. Whatever immediately follows these is considered to be an INPUT: section unless explicitly marked with another keyword. (See \"The INPUT: Keyword\".) An XSUB section continues until another section-start keyword is found. The Argument Stack The Perl argument stack is used to store the values which are sent as parameters to the XSUB and to store the XSUB 's return value(s). In reality all Perl functions (including non-XSUB ones) keep their values on this stack all the same time, each limited to its own range of positions on the stack. In this document the first position on that stack which belongs to the active function will be referred to as position 0 for that function. XSUBs refer to their stack arguments with the macro ST (x), where x refers to a position in this XSUB 's part of the stack. Position 0 for that function would be known to the XSUB as ST (0). The XSUB 's incoming parameters and outgoing return values always begin at ST (0). For many simple cases the xsubpp compiler will generate the code necessary to handle the argument stack by embedding code fragments found in the typemaps. In more complex cases the programmer must supply the code. The RETVAL Variable The RETVAL variable is a special C variable that is declared automatically for you. The C type of RETVAL matches the return type of the C library function. The xsubpp compiler will declare this variable in each XSUB with non- \"void\" return type. By default the generated C function will use RETVAL to hold the return value of the C library function being called. In simple cases the value of RETVAL will be placed in ST (0) of the argument stack where it can be received by Perl as the return value of the XSUB . If the XSUB has a return type of \"void\" then the compiler will not declare a RETVAL variable for that function. When using a PPCODE: section no manipulation of the RETVAL variable is required, the section may use direct stack manipulation to place output values on the stack. If PPCODE: directive is not used, \"void\" return value should be used only for subroutines which do not return a value, even if CODE: directive is used which sets ST (0) explicitly. Older versions of this document recommended to use \"void\" return value in such cases. It was discovered that this could lead to segfaults in cases when XSUB was truly \"void\". This practice is now deprecated, and may be not supported at some future version. Use the return value \"SV *\" in such cases. (Currently \"xsubpp\" contains some heuristic code which tries to disambiguate between \"truly-void\" and \"old-practice-declared-as-void\" functions. Hence your code is at mercy of this heuristics unless you use \"SV *\" as return value.) Returning SVs, AVs and HVs through RETVAL When you're using RETVAL to return an \"SV *\", there's some magic going on behind the scenes that should be mentioned. When you're manipulating the argument stack using the ST (x) macro, for example, you usually have to pay special attention to reference counts. (For more about reference counts, see perlguts.) To make your life easier, the typemap file automatically makes \"RETVAL\" mortal when you're returning an \"SV *\". Thus, the following two XSUBs are more or less equivalent: void\nalpha()\n    PPCODE:\n        ST(0) = newSVpv(\"Hello World\",0);\n        sv_2mortal(ST(0));\n        XSRETURN(1);\n\nSV *\nbeta()\n    CODE:\n        RETVAL = newSVpv(\"Hello World\",0);\n    OUTPUT:\n        RETVAL This is quite useful as it usually improves readability. While this works fine for an \"SV *\", it's unfortunately not as easy to have \"AV *\" or \"HV *\" as a return value. You should be able to write: AV *\narray()\n    CODE:\n        RETVAL = newAV();\n        \/* do something with RETVAL *\/\n    OUTPUT:\n        RETVAL But due to an unfixable bug (fixing it would break lots of existing CPAN modules) in the typemap file, the reference count of the \"AV *\" is not properly decremented. Thus, the above XSUB would leak memory whenever it is being called. The same problem exists for \"HV *\". When you're returning an \"AV *\" or a \"HV *\", you have to make sure their reference count is decremented by making the AV or HV mortal: AV *\narray()\n    CODE:\n        RETVAL = newAV();\n        sv_2mortal((SV*)RETVAL);\n        \/* do something with RETVAL *\/\n    OUTPUT:\n        RETVAL And also remember that you don't have to do this for an \"SV *\". The MODULE Keyword The MODULE keyword is used to start the XS code and to specify the package of the functions which are being defined. All text preceding the first MODULE keyword is considered C code and is passed through to the output with POD stripped, but otherwise untouched. Every XS module will have a bootstrap function which is used to hook the XSUBs into Perl. The package name of this bootstrap function will match the value of the last MODULE statement in the XS source files. The value of MODULE should always remain constant within the same XS file, though this is not required. The following example will start the XS code and will place all functions in a package named RPC . MODULE = RPC The PACKAGE Keyword When functions within an XS source file must be separated into packages the PACKAGE keyword should be used. This keyword is used with the MODULE keyword and must follow immediately after it when used. MODULE = RPC  PACKAGE = RPC\n\n[ XS code in package RPC ]\n\nMODULE = RPC  PACKAGE = RPCB\n\n[ XS code in package RPCB ]\n\nMODULE = RPC  PACKAGE = RPC\n\n[ XS code in package RPC ] The same package name can be used more than once, allowing for non-contiguous code. This is useful if you have a stronger ordering principle than package names. Although this keyword is optional and in some cases provides redundant information it should always be used. This keyword will ensure that the XSUBs appear in the desired package. The PREFIX Keyword The PREFIX keyword designates prefixes which should be removed from the Perl function names. If the C function is \"rpcb_gettime()\" and the PREFIX value is \"rpcb_\" then Perl will see this function as \"gettime()\". This keyword should follow the PACKAGE keyword when used. If PACKAGE is not used then PREFIX should follow the MODULE keyword. MODULE = RPC  PREFIX = rpc_\n\nMODULE = RPC  PACKAGE = RPCB  PREFIX = rpcb_ The OUTPUT: Keyword The OUTPUT: keyword indicates that certain function parameters should be updated (new values made visible to Perl) when the XSUB terminates or that certain values should be returned to the calling Perl function. For simple functions which have no CODE: or PPCODE: section, such as the sin() function above, the RETVAL variable is automatically designated as an output value. For more complex functions the xsubpp compiler will need help to determine which variables are output variables. This keyword will normally be used to complement the CODE: keyword. The RETVAL variable is not recognized as an output variable when the CODE: keyword is present. The OUTPUT: keyword is used in this situation to tell the compiler that RETVAL really is an output variable. The OUTPUT: keyword can also be used to indicate that function parameters are output variables. This may be necessary when a parameter has been modified within the function and the programmer would like the update to be seen by Perl. bool_t\nrpcb_gettime(host,timep)\n     char *host\n     time_t &timep\n   OUTPUT:\n     timep The OUTPUT: keyword will also allow an output parameter to be mapped to a matching piece of code rather than to a typemap. bool_t\nrpcb_gettime(host,timep)\n     char *host\n     time_t &timep\n   OUTPUT:\n     timep sv_setnv(ST(1), (double)timep); xsubpp emits an automatic \"SvSETMAGIC()\" for all parameters in the OUTPUT section of the XSUB , except RETVAL . This is the usually desired behavior, as it takes care of properly invoking 'set' magic on output parameters (needed for hash or array element parameters that must be created if they didn't exist). If for some reason, this behavior is not desired, the OUTPUT section may contain a \"SETMAGIC: DISABLE\" line to disable it for the remainder of the parameters in the OUTPUT section. Likewise, \"SETMAGIC: ENABLE\" can be used to reenable it for the remainder of the OUTPUT section. See perlguts for more details about 'set' magic. The NO_OUTPUT Keyword The NO_OUTPUT can be placed as the first token of the XSUB . This keyword indicates that while the C subroutine we provide an interface to has a non- \"void\" return type, the return value of this C subroutine should not be returned from the generated Perl subroutine. With this keyword present \"The RETVAL Variable\" is created, and in the generated call to the subroutine this variable is assigned to, but the value of this variable is not going to be used in the auto-generated code. This keyword makes sense only if \"RETVAL\" is going to be accessed by the user-supplied code. It is especially useful to make a function interface more Perl-like, especially when the C return value is just an error condition indicator. For example, NO_OUTPUT int\ndelete_file(char *name)\n  POSTCALL:\n    if (RETVAL != 0)\n        croak(\"Error %d while deleting file '%s'\", RETVAL, name); Here the generated XS function returns nothing on success, and will die() with a meaningful error message on error. The CODE: Keyword This keyword is used in more complicated XSUBs which require special handling for the C function. The RETVAL variable is still declared, but it will not be returned unless it is specified in the OUTPUT: section. The following XSUB is for a C function which requires special handling of its parameters. The Perl usage is given first. $status = rpcb_gettime( \"localhost\", $timep ); The XSUB follows. bool_t\nrpcb_gettime(host,timep)\n     char *host\n     time_t timep\n   CODE:\n          RETVAL = rpcb_gettime( host, &timep );\n   OUTPUT:\n     timep\n     RETVAL The INIT: Keyword The INIT: keyword allows initialization to be inserted into the XSUB before the compiler generates the call to the C function. Unlike the CODE: keyword above, this keyword does not affect the way the compiler handles RETVAL . bool_t\nrpcb_gettime(host,timep)\n      char *host\n      time_t &timep\n    INIT:\n      printf(\"# Host is %s\\n\", host );\n    OUTPUT:\n      timep Another use for the INIT: section is to check for preconditions before making a call to the C function: long long\nlldiv(a,b)\n    long long a\n    long long b\n  INIT:\n    if (a == 0 && b == 0)\n        XSRETURN_UNDEF;\n    if (b == 0)\n        croak(\"lldiv: cannot divide by 0\"); The NO_INIT Keyword The NO_INIT keyword is used to indicate that a function parameter is being used only as an output value. The xsubpp compiler will normally generate code to read the values of all function parameters from the argument stack and assign them to C variables upon entry to the function. NO_INIT will tell the compiler that some parameters will be used for output rather than for input and that they will be handled before the function terminates. The following example shows a variation of the rpcb_gettime() function. This function uses the timep variable only as an output variable and does not care about its initial contents. bool_t\nrpcb_gettime(host,timep)\n     char *host\n     time_t &timep = NO_INIT\n   OUTPUT:\n     timep Initializing Function Parameters C function parameters are normally initialized with their values from the argument stack (which in turn contains the parameters that were passed to the XSUB from Perl). The typemaps contain the code segments which are used to translate the Perl values to the C parameters. The programmer, however, is allowed to override the typemaps and supply alternate (or additional) initialization code. Initialization code starts with the first \"=\", \";\" or \"+\" on a line in the INPUT: section. The only exception happens if this \";\" terminates the line, then this \";\" is quietly ignored. The following code demonstrates how to supply initialization code for function parameters. The initialization code is eval'ed within double quotes by the compiler before it is added to the output so anything which should be interpreted literally [mainly \"$\", \"@\", or \"\\\\\"] must be protected with backslashes. The variables $var, $arg, and $type can be used as in typemaps. bool_t\nrpcb_gettime(host,timep)\n     char *host = (char *)SvPV_nolen($arg);\n     time_t &timep = 0;\n   OUTPUT:\n     timep This should not be used to supply default values for parameters. One would normally use this when a function parameter must be processed by another library function before it can be used. Default parameters are covered in the next section. If the initialization begins with \"=\", then it is output in the declaration for the input variable, replacing the initialization supplied by the typemap. If the initialization begins with \";\" or \"+\", then it is performed after all of the input variables have been declared. In the \";\" case the initialization normally supplied by the typemap is not performed. For the \"+\" case, the declaration for the variable will include the initialization from the typemap. A global variable, %v, is available for the truly rare case where information from one initialization is needed in another initialization. Here's a truly obscure example: bool_t\nrpcb_gettime(host,timep)\n     time_t &timep; \/* \\$v{timep}=@{[$v{timep}=$arg]} *\/\n     char *host + SvOK($v{timep}) ? SvPV_nolen($arg) : NULL;\n   OUTPUT:\n     timep The construct \"\\$v{timep}=@{[$v{timep}=$arg]}\" used in the above example has a two-fold purpose: first, when this line is processed by xsubpp, the Perl snippet \"$v{timep}=$arg\" is evaluated. Second, the text of the evaluated snippet is output into the generated C file (inside a C comment)! During the processing of \"char *host\" line, $arg will evaluate to ST(0), and $v{timep} will evaluate to ST(1). Default Parameter Values Default values for XSUB arguments can be specified by placing an assignment statement in the parameter list. The default value may be a number, a string or the special string \"NO_INIT\". Defaults should always be used on the right-most parameters only. To allow the XSUB for rpcb_gettime() to have a default host value the parameters to the XSUB could be rearranged. The XSUB will then call the real rpcb_gettime() function with the parameters in the correct order. This XSUB can be called from Perl with either of the following statements: $status = rpcb_gettime( $timep, $host );\n\n$status = rpcb_gettime( $timep ); The XSUB will look like the code which follows. A CODE: block is used to call the real rpcb_gettime() function with the parameters in the correct order for that function. bool_t\nrpcb_gettime(timep,host=\"localhost\")\n     char *host\n     time_t timep = NO_INIT\n   CODE:\n          RETVAL = rpcb_gettime( host, &timep );\n   OUTPUT:\n     timep\n     RETVAL The PREINIT: Keyword The PREINIT: keyword allows extra variables to be declared immediately before or after the declarations of the parameters from the INPUT: section are emitted. If a variable is declared inside a CODE: section it will follow any typemap code that is emitted for the input parameters. This may result in the declaration ending up after C code, which is C syntax error. Similar errors may happen with an explicit \";\"-type or \"+\"-type initialization of parameters is used (see \"Initializing Function Parameters\"). Declaring these variables in an INIT: section will not help. In such cases, to force an additional variable to be declared together with declarations of other variables, place the declaration into a PREINIT: section. The PREINIT: keyword may be used one or more times within an XSUB . The following examples are equivalent, but if the code is using complex typemaps then the first example is safer. bool_t\nrpcb_gettime(timep)\n     time_t timep = NO_INIT\n   PREINIT:\n     char *host = \"localhost\";\n   CODE:\n     RETVAL = rpcb_gettime( host, &timep );\n   OUTPUT:\n     timep\n     RETVAL For this particular case an INIT: keyword would generate the same C code as the PREINIT: keyword. Another correct, but error-prone example: bool_t\nrpcb_gettime(timep)\n     time_t timep = NO_INIT\n   CODE:\n     char *host = \"localhost\";\n     RETVAL = rpcb_gettime( host, &timep );\n   OUTPUT:\n     timep\n     RETVAL Another way to declare \"host\" is to use a C block in the CODE: section: bool_t\nrpcb_gettime(timep)\n     time_t timep = NO_INIT\n   CODE:\n     {\n       char *host = \"localhost\";\n       RETVAL = rpcb_gettime( host, &timep );\n     }\n   OUTPUT:\n     timep\n     RETVAL The ability to put additional declarations before the typemap entries are processed is very handy in the cases when typemap conversions manipulate some global state: MyObject\nmutate(o)\n    PREINIT:\n        MyState st = global_state;\n    INPUT:\n        MyObject o;\n    CLEANUP:\n        reset_to(global_state, st); Here we suppose that conversion to \"MyObject\" in the INPUT: section and from MyObject when processing RETVAL will modify a global variable \"global_state\". After these conversions are performed, we restore the old value of \"global_state\" (to avoid memory leaks, for example). There is another way to trade clarity for compactness: INPUT sections allow declaration of C variables which do not appear in the parameter list of a subroutine. Thus the above code for mutate() can be rewritten as MyObject\nmutate(o)\n      MyState st = global_state;\n      MyObject o;\n    CLEANUP:\n      reset_to(global_state, st); and the code for rpcb_gettime() can be rewritten as bool_t\nrpcb_gettime(timep)\n     time_t timep = NO_INIT\n     char *host = \"localhost\";\n   C_ARGS:\n     host, &timep\n   OUTPUT:\n     timep\n     RETVAL The SCOPE: Keyword The SCOPE: keyword allows scoping to be enabled for a particular XSUB . If enabled, the XSUB will invoke ENTER and LEAVE automatically. To support potentially complex type mappings, if a typemap entry used by an XSUB contains a comment like \"\/*scope*\/\" then scoping will be automatically enabled for that XSUB . To enable scoping: SCOPE: ENABLE To disable scoping: SCOPE: DISABLE The INPUT: Keyword The XSUB 's parameters are usually evaluated immediately after entering the XSUB . The INPUT: keyword can be used to force those parameters to be evaluated a little later. The INPUT: keyword can be used multiple times within an XSUB and can be used to list one or more input variables. This keyword is used with the PREINIT: keyword. The following example shows how the input parameter \"timep\" can be evaluated late, after a PREINIT . bool_t\nrpcb_gettime(host,timep)\n      char *host\n    PREINIT:\n      time_t tt;\n    INPUT:\n      time_t timep\n    CODE:\n           RETVAL = rpcb_gettime( host, &tt );\n           timep = tt;\n    OUTPUT:\n      timep\n      RETVAL The next example shows each input parameter evaluated late. bool_t\nrpcb_gettime(host,timep)\n    PREINIT:\n      time_t tt;\n    INPUT:\n      char *host\n    PREINIT:\n      char *h;\n    INPUT:\n      time_t timep\n    CODE:\n           h = host;\n           RETVAL = rpcb_gettime( h, &tt );\n           timep = tt;\n    OUTPUT:\n      timep\n      RETVAL Since INPUT sections allow declaration of C variables which do not appear in the parameter list of a subroutine, this may be shortened to: bool_t\nrpcb_gettime(host,timep)\n      time_t tt;\n      char *host;\n      char *h = host;\n      time_t timep;\n    CODE:\n      RETVAL = rpcb_gettime( h, &tt );\n      timep = tt;\n    OUTPUT:\n      timep\n      RETVAL (We used our knowledge that input conversion for \"char *\" is a \"simple\" one, thus \"host\" is initialized on the declaration line, and our assignment \"h = host\" is not performed too early. Otherwise one would need to have the assignment \"h = host\" in a CODE: or INIT: section.) The IN\/OUTLIST\/IN_OUTLIST\/OUT\/IN_OUT Keywords In the list of parameters for an XSUB , one can precede parameter names by the \"IN\"\/ \"OUTLIST\"\/ \"IN_OUTLIST\"\/ \"OUT\"\/ \"IN_OUT\" keywords. \"IN\" keyword is the default, the other keywords indicate how the Perl interface should differ from the C interface. Parameters preceded by \"OUTLIST\"\/\"IN_OUTLIST\"\/\"OUT\"\/\"IN_OUT\" keywords are considered to be used by the C subroutine via pointers. \"OUTLIST\"\/\"OUT\" keywords indicate that the C subroutine does not inspect the memory pointed by this parameter, but will write through this pointer to provide additional return values. Parameters preceded by \"OUTLIST\" keyword do not appear in the usage signature of the generated Perl function. Parameters preceded by \"IN_OUTLIST\"\/\"IN_OUT\"\/\"OUT\" do appear as parameters to the Perl function. With the exception of \"OUT\"-parameters, these parameters are converted to the corresponding C type, then pointers to these data are given as arguments to the C function. It is expected that the C function will write through these pointers. The return list of the generated Perl function consists of the C return value from the function (unless the XSUB is of \"void\" return type or \"The NO_OUTPUT Keyword\" was used) followed by all the \"OUTLIST\" and \"IN_OUTLIST\" parameters (in the order of appearance). On the return from the XSUB the \"IN_OUT\"\/\"OUT\" Perl parameter will be modified to have the values written by the C function. For example, an XSUB void\nday_month(OUTLIST day, IN unix_time, OUTLIST month)\n  int day\n  int unix_time\n  int month should be used from Perl as my ($day, $month) = day_month(time); The C signature of the corresponding function should be void day_month(int *day, int unix_time, int *month); The \"IN\"\/ \"OUTLIST\"\/ \"IN_OUTLIST\"\/ \"IN_OUT\"\/ \"OUT\" keywords can be mixed with ANSI-style declarations, as in void\nday_month(OUTLIST int day, int unix_time, OUTLIST int month) (here the optional \"IN\" keyword is omitted). The \"IN_OUT\" parameters are identical with parameters introduced with \"The & Unary Operator\" and put into the \"OUTPUT:\" section (see \"The OUTPUT: Keyword\"). The \"IN_OUTLIST\" parameters are very similar, the only difference being that the value C function writes through the pointer would not modify the Perl parameter, but is put in the output list. The \"OUTLIST\"\/\"OUT\" parameter differ from \"IN_OUTLIST\"\/\"IN_OUT\" parameters only by the initial value of the Perl parameter not being read (and not being given to the C function - which gets some garbage instead). For example, the same C function as above can be interfaced with as void day_month(OUT int day, int unix_time, OUT int month); or void\nday_month(day, unix_time, month)\n    int &day = NO_INIT\n    int  unix_time\n    int &month = NO_INIT\n  OUTPUT:\n    day\n    month However, the generated Perl function is called in very C-ish style: my ($day, $month);\nday_month($day, time, $month); The \"length(NAME)\" Keyword If one of the input arguments to the C function is the length of a string argument \"NAME\", one can substitute the name of the length-argument by \"length(NAME)\" in the XSUB declaration. This argument must be omitted when the generated Perl function is called. E.g., void\ndump_chars(char *s, short l)\n{\n  short n = 0;\n  while (n < l) {\n      printf(\"s[%d] = \\\"\\\\%#03o\\\"\\n\", n, (int)s[n]);\n      n++;\n  }\n}\n\nMODULE = x            PACKAGE = x\n\nvoid dump_chars(char *s, short length(s)) should be called as \"dump_chars($string)\". This directive is supported with ANSI-type function declarations only. Variable-length Parameter Lists XSUBs can have variable-length parameter lists by specifying an ellipsis \"(...)\" in the parameter list. This use of the ellipsis is similar to that found in ANSI C. The programmer is able to determine the number of arguments passed to the XSUB by examining the \"items\" variable which the xsubpp compiler supplies for all XSUBs. By using this mechanism one can create an XSUB which accepts a list of parameters of unknown length. The host parameter for the rpcb_gettime() XSUB can be optional so the ellipsis can be used to indicate that the XSUB will take a variable number of parameters. Perl should be able to call this XSUB with either of the following statements. $status = rpcb_gettime( $timep, $host );\n\n$status = rpcb_gettime( $timep ); The XS code, with ellipsis, follows. bool_t\nrpcb_gettime(timep, ...)\n     time_t timep = NO_INIT\n   PREINIT:\n     char *host = \"localhost\";\n   CODE:\n     if( items > 1 )\n          host = (char *)SvPV_nolen(ST(1));\n     RETVAL = rpcb_gettime( host, &timep );\n   OUTPUT:\n     timep\n     RETVAL The C_ARGS: Keyword The C_ARGS: keyword allows creating of XSUBS which have different calling sequence from Perl than from C, without a need to write CODE: or PPCODE: section. The contents of the C_ARGS: paragraph is put as the argument to the called C function without any change. For example, suppose that a C function is declared as symbolic nth_derivative(int n, symbolic function, int flags); and that the default flags are kept in a global C variable \"default_flags\". Suppose that you want to create an interface which is called as $second_deriv = $function->nth_derivative(2); To do this, declare the XSUB as symbolic\nnth_derivative(function, n)\n    symbolic        function\n    int             n\n  C_ARGS:\n    n, function, default_flags The PPCODE: Keyword The PPCODE: keyword is an alternate form of the CODE: keyword and is used to tell the xsubpp compiler that the programmer is supplying the code to control the argument stack for the XSUBs return values. Occasionally one will want an XSUB to return a list of values rather than a single value. In these cases one must use PPCODE: and then explicitly push the list of values on the stack. The PPCODE: and CODE: keywords should not be used together within the same XSUB . The actual difference between PPCODE: and CODE: sections is in the initialization of \"SP\" macro (which stands for the current Perl stack pointer), and in the handling of data on the stack when returning from an XSUB . In CODE: sections SP preserves the value which was on entry to the XSUB: SP is on the function pointer (which follows the last parameter). In PPCODE: sections SP is moved backward to the beginning of the parameter list, which allows \"PUSH*()\" macros to place output values in the place Perl expects them to be when the XSUB returns back to Perl. The generated trailer for a CODE: section ensures that the number of return values Perl will see is either 0 or 1 (depending on the \"void\"ness of the return value of the C function, and heuristics mentioned in \"The RETVAL Variable\"). The trailer generated for a PPCODE: section is based on the number of return values and on the number of times \"SP\" was updated by \"[X]PUSH*()\" macros. Note that macros ST(i), \"XST_m*()\" and \"XSRETURN*()\" work equally well in CODE: sections and PPCODE: sections. The following XSUB will call the C rpcb_gettime() function and will return its two output values, timep and status, to Perl as a single list. void\nrpcb_gettime(host)\n     char *host\n   PREINIT:\n     time_t  timep;\n     bool_t  status;\n   PPCODE:\n     status = rpcb_gettime( host, &timep );\n     EXTEND(SP, 2);\n     PUSHs(sv_2mortal(newSViv(status)));\n     PUSHs(sv_2mortal(newSViv(timep))); Notice that the programmer must supply the C code necessary to have the real rpcb_gettime() function called and to have the return values properly placed on the argument stack. The \"void\" return type for this function tells the xsubpp compiler that the RETVAL variable is not needed or used and that it should not be created. In most scenarios the void return type should be used with the PPCODE: directive. The EXTEND () macro is used to make room on the argument stack for 2 return values. The PPCODE: directive causes the xsubpp compiler to create a stack pointer available as \"SP\", and it is this pointer which is being used in the EXTEND () macro. The values are then pushed onto the stack with the PUSHs() macro. Now the rpcb_gettime() function can be used from Perl with the following statement. ($status, $timep) = rpcb_gettime(\"localhost\"); When handling output parameters with a PPCODE section, be sure to handle 'set' magic properly. See perlguts for details about 'set' magic. Returning Undef And Empty Lists Occasionally the programmer will want to return simply \"undef\" or an empty list if a function fails rather than a separate status value. The rpcb_gettime() function offers just this situation. If the function succeeds we would like to have it return the time and if it fails we would like to have undef returned. In the following Perl code the value of $timep will either be undef or it will be a valid time. $timep = rpcb_gettime( \"localhost\" ); The following XSUB uses the \"SV *\" return type as a mnemonic only, and uses a CODE: block to indicate to the compiler that the programmer has supplied all the necessary code. The sv_newmortal() call will initialize the return value to undef, making that the default return value. SV *\nrpcb_gettime(host)\n     char *  host\n   PREINIT:\n     time_t  timep;\n     bool_t x;\n   CODE:\n     ST(0) = sv_newmortal();\n     if( rpcb_gettime( host, &timep ) )\n          sv_setnv( ST(0), (double)timep); The next example demonstrates how one would place an explicit undef in the return value, should the need arise. SV *\nrpcb_gettime(host)\n     char *  host\n   PREINIT:\n     time_t  timep;\n     bool_t x;\n   CODE:\n     if( rpcb_gettime( host, &timep ) ){\n          ST(0) = sv_newmortal();\n          sv_setnv( ST(0), (double)timep);\n     }\n     else{\n          ST(0) = &PL_sv_undef;\n     } To return an empty list one must use a PPCODE: block and then not push return values on the stack. void\nrpcb_gettime(host)\n     char *host\n   PREINIT:\n     time_t  timep;\n   PPCODE:\n     if( rpcb_gettime( host, &timep ) )\n          PUSHs(sv_2mortal(newSViv(timep)));\n     else{\n         \/* Nothing pushed on stack, so an empty\n          * list is implicitly returned. *\/\n     } Some people may be inclined to include an explicit \"return\" in the above XSUB , rather than letting control fall through to the end. In those situations \"XSRETURN_EMPTY\" should be used, instead. This will ensure that the XSUB stack is properly adjusted. Consult perlapi for other \"XSRETURN\" macros. Since \"XSRETURN_*\" macros can be used with CODE blocks as well, one can rewrite this example as: int\nrpcb_gettime(host)\n     char *host\n   PREINIT:\n     time_t  timep;\n   CODE:\n     RETVAL = rpcb_gettime( host, &timep );\n     if (RETVAL == 0)\n           XSRETURN_UNDEF;\n   OUTPUT:\n     RETVAL In fact, one can put this check into a POSTCALL: section as well. Together with PREINIT: simplifications, this leads to: int\nrpcb_gettime(host)\n     char *host\n     time_t  timep;\n   POSTCALL:\n     if (RETVAL == 0)\n           XSRETURN_UNDEF; The REQUIRE: Keyword The REQUIRE: keyword is used to indicate the minimum version of the xsubpp compiler needed to compile the XS module. An XS module which contains the following statement will compile with only xsubpp version 1.922 or greater: REQUIRE: 1.922 The CLEANUP: Keyword This keyword can be used when an XSUB requires special cleanup procedures before it terminates. When the CLEANUP: keyword is used it must follow any CODE: , PPCODE: , or OUTPUT: blocks which are present in the XSUB . The code specified for the cleanup block will be added as the last statements in the XSUB . The POSTCALL: Keyword This keyword can be used when an XSUB requires special procedures executed after the C subroutine call is performed. When the POSTCALL: keyword is used it must precede OUTPUT: and CLEANUP: blocks which are present in the XSUB . See examples in \"The NO_OUTPUT Keyword\" and \"Returning Undef And Empty Lists\". The POSTCALL: block does not make a lot of sense when the C subroutine call is supplied by user by providing either CODE: or PPCODE: section. The BOOT: Keyword The BOOT: keyword is used to add code to the extension's bootstrap function. The bootstrap function is generated by the xsubpp compiler and normally holds the statements necessary to register any XSUBs with Perl. With the BOOT: keyword the programmer can tell the compiler to add extra statements to the bootstrap function. This keyword may be used any time after the first MODULE keyword and should appear on a line by itself. The first blank line after the keyword will terminate the code block. BOOT:\n# The following message will be printed when the\n# bootstrap function executes.\nprintf(\"Hello from the bootstrap!\\n\"); The VERSIONCHECK: Keyword The VERSIONCHECK: keyword corresponds to xsubpp's \"-versioncheck\" and \"-noversioncheck\" options. This keyword overrides the command line options. Version checking is enabled by default. When version checking is enabled the XS module will attempt to verify that its version matches the version of the PM module. To enable version checking: VERSIONCHECK: ENABLE To disable version checking: VERSIONCHECK: DISABLE Note that if the version of the PM module is an NV (a floating point number), it will be stringified with a possible loss of precision (currently chopping to nine decimal places) so that it may not match the version of the XS module anymore. Quoting the $VERSION declaration to make it a string is recommended if long version numbers are used. The PROTOTYPES: Keyword The PROTOTYPES: keyword corresponds to xsubpp's \"-prototypes\" and \"-noprototypes\" options. This keyword overrides the command line options. Prototypes are enabled by default. When prototypes are enabled XSUBs will be given Perl prototypes. This keyword may be used multiple times in an XS module to enable and disable prototypes for different parts of the module. To enable prototypes: PROTOTYPES: ENABLE To disable prototypes: PROTOTYPES: DISABLE The PROTOTYPE: Keyword This keyword is similar to the PROTOTYPES: keyword above but can be used to force xsubpp to use a specific prototype for the XSUB . This keyword overrides all other prototype options and keywords but affects only the current XSUB . Consult \"Prototypes\" in perlsub for information about Perl prototypes. bool_t\nrpcb_gettime(timep, ...)\n      time_t timep = NO_INIT\n    PROTOTYPE: $;$\n    PREINIT:\n      char *host = \"localhost\";\n    CODE:\n              if( items > 1 )\n                   host = (char *)SvPV_nolen(ST(1));\n              RETVAL = rpcb_gettime( host, &timep );\n    OUTPUT:\n      timep\n      RETVAL If the prototypes are enabled, you can disable it locally for a given XSUB as in the following example: void\nrpcb_gettime_noproto()\n    PROTOTYPE: DISABLE\n... The ALIAS: Keyword The ALIAS: keyword allows an XSUB to have two or more unique Perl names and to know which of those names was used when it was invoked. The Perl names may be fully-qualified with package names. Each alias is given an index. The compiler will setup a variable called \"ix\" which contain the index of the alias which was used. When the XSUB is called with its declared name \"ix\" will be 0. The following example will create aliases \"FOO::gettime()\" and \"BAR::getit()\" for this function. bool_t\nrpcb_gettime(host,timep)\n      char *host\n      time_t &timep\n    ALIAS:\n        FOO::gettime = 1\n        BAR::getit = 2\n    INIT:\n      printf(\"# ix = %d\\n\", ix );\n    OUTPUT:\n      timep The OVERLOAD: Keyword Instead of writing an overloaded interface using pure Perl, you can also use the OVERLOAD keyword to define additional Perl names for your functions (like the ALIAS: keyword above). However, the overloaded functions must be defined with three parameters (except for the nomethod() function which needs four parameters). If any function has the OVERLOAD: keyword, several additional lines will be defined in the c file generated by xsubpp in order to register with the overload magic. Since blessed objects are actually stored as RV 's, it is useful to use the typemap features to preprocess parameters and extract the actual SV stored within the blessed RV . See the sample for T_PTROBJ_SPECIAL below. To use the OVERLOAD: keyword, create an XS function which takes three input parameters ( or use the c style '...' definition) like this: SV *\ncmp (lobj, robj, swap)\nMy_Module_obj    lobj\nMy_Module_obj    robj\nIV               swap\nOVERLOAD: cmp <=>\n{ \/* function defined here *\/} In this case, the function will overload both of the three way comparison operators. For all overload operations using non-alpha characters, you must type the parameter without quoting, separating multiple overloads with whitespace. Note that \"\" (the stringify overload) should be entered as \\\"\\\" (i.e. escaped). The FALLBACK: Keyword In addition to the OVERLOAD keyword, if you need to control how Perl autogenerates missing overloaded operators, you can set the FALLBACK keyword in the module header section, like this: MODULE = RPC  PACKAGE = RPC\n\nFALLBACK: TRUE\n... where FALLBACK can take any of the three values TRUE , FALSE , or UNDEF . If you do not set any FALLBACK value when using OVERLOAD , it defaults to UNDEF . FALLBACK is not used except when one or more functions using OVERLOAD have been defined. Please see \"Fallback\" in overload for more details. The INTERFACE: Keyword This keyword declares the current XSUB as a keeper of the given calling signature. If some text follows this keyword, it is considered as a list of functions which have this signature, and should be attached to the current XSUB . For example, if you have 4 C functions multiply(), divide(), add(), subtract() all having the signature: symbolic f(symbolic, symbolic); you can make them all to use the same XSUB using this: symbolic\ninterface_s_ss(arg1, arg2)\n    symbolic        arg1\n    symbolic        arg2\nINTERFACE:\n    multiply divide\n    add subtract (This is the complete XSUB code for 4 Perl functions!) Four generated Perl function share names with corresponding C functions. The advantage of this approach comparing to ALIAS: keyword is that there is no need to code a switch statement, each Perl function (which shares the same XSUB ) knows which C function it should call. Additionally, one can attach an extra function remainder() at runtime by using CV *mycv = newXSproto(\"Symbolic::remainder\",\n                      XS_Symbolic_interface_s_ss, __FILE__, \"$$\");\nXSINTERFACE_FUNC_SET(mycv, remainder); say, from another XSUB . (This example supposes that there was no INTERFACE_MACRO: section, otherwise one needs to use something else instead of \"XSINTERFACE_FUNC_SET\", see the next section.) The INTERFACE_MACRO: Keyword This keyword allows one to define an INTERFACE using a different way to extract a function pointer from an XSUB . The text which follows this keyword should give the name of macros which would extract\/set a function pointer. The extractor macro is given return type, \"CV*\", and \"XSANY.any_dptr\" for this \"CV*\". The setter macro is given cv, and the function pointer. The default value is \"XSINTERFACE_FUNC\" and \"XSINTERFACE_FUNC_SET\". An INTERFACE keyword with an empty list of functions can be omitted if INTERFACE_MACRO keyword is used. Suppose that in the previous example functions pointers for multiply(), divide(), add(), subtract() are kept in a global C array \"fp[]\" with offsets being \"multiply_off\", \"divide_off\", \"add_off\", \"subtract_off\". Then one can use #define XSINTERFACE_FUNC_BYOFFSET(ret,cv,f) \\\n    ((XSINTERFACE_CVT_ANON(ret))fp[CvXSUBANY(cv).any_i32])\n#define XSINTERFACE_FUNC_BYOFFSET_set(cv,f) \\\n    CvXSUBANY(cv).any_i32 = CAT2( f, _off ) in C section, symbolic\ninterface_s_ss(arg1, arg2)\n    symbolic        arg1\n    symbolic        arg2\n  INTERFACE_MACRO:\n    XSINTERFACE_FUNC_BYOFFSET\n    XSINTERFACE_FUNC_BYOFFSET_set\n  INTERFACE:\n    multiply divide\n    add subtract in XSUB section. The INCLUDE: Keyword This keyword can be used to pull other files into the XS module. The other files may have XS code. INCLUDE: can also be used to run a command to generate the XS code to be pulled into the module. The file Rpcb1.xsh contains our \"rpcb_gettime()\" function: bool_t\nrpcb_gettime(host,timep)\n      char *host\n      time_t &timep\n    OUTPUT:\n      timep The XS module can use INCLUDE: to pull that file into it. INCLUDE: Rpcb1.xsh If the parameters to the INCLUDE: keyword are followed by a pipe ( \"|\") then the compiler will interpret the parameters as a command. INCLUDE: cat Rpcb1.xsh | The CASE: Keyword The CASE: keyword allows an XSUB to have multiple distinct parts with each part acting as a virtual XSUB . CASE: is greedy and if it is used then all other XS keywords must be contained within a CASE: . This means nothing may precede the first CASE: in the XSUB and anything following the last CASE: is included in that case. A CASE: might switch via a parameter of the XSUB , via the \"ix\" ALIAS: variable (see \"The ALIAS: Keyword\"), or maybe via the \"items\" variable (see \"Variable-length Parameter Lists\"). The last CASE: becomes the default case if it is not associated with a conditional. The following example shows CASE switched via \"ix\" with a function \"rpcb_gettime()\" having an alias \"x_gettime()\". When the function is called as \"rpcb_gettime()\" its parameters are the usual \"(char *host, time_t *timep)\", but when the function is called as \"x_gettime()\" its parameters are reversed, \"(time_t *timep, char *host)\". long\nrpcb_gettime(a,b)\n  CASE: ix == 1\n    ALIAS:\n      x_gettime = 1\n    INPUT:\n      # 'a' is timep, 'b' is host\n      char *b\n      time_t a = NO_INIT\n    CODE:\n           RETVAL = rpcb_gettime( b, &a );\n    OUTPUT:\n      a\n      RETVAL\n  CASE:\n      # 'a' is host, 'b' is timep\n      char *a\n      time_t &b = NO_INIT\n    OUTPUT:\n      b\n      RETVAL That function can be called with either of the following statements. Note the different argument lists. $status = rpcb_gettime( $host, $timep );\n\n$status = x_gettime( $timep, $host ); The & Unary Operator The \"&\" unary operator in the INPUT: section is used to tell xsubpp that it should convert a Perl value to\/from C using the C type to the left of \"&\", but provide a pointer to this value when the C function is called. This is useful to avoid a CODE: block for a C function which takes a parameter by reference. Typically, the parameter should be not a pointer type (an \"int\" or \"long\" but not an \"int*\" or \"long*\"). The following XSUB will generate incorrect C code. The xsubpp compiler will turn this into code which calls \"rpcb_gettime()\" with parameters \"(char *host, time_t timep)\", but the real \"rpcb_gettime()\" wants the \"timep\" parameter to be of type \"time_t*\" rather than \"time_t\". bool_t\nrpcb_gettime(host,timep)\n      char *host\n      time_t timep\n    OUTPUT:\n      timep That problem is corrected by using the \"&\" operator. The xsubpp compiler will now turn this into code which calls \"rpcb_gettime()\" correctly with parameters \"(char *host, time_t *timep)\". It does this by carrying the \"&\" through, so the function call looks like \"rpcb_gettime(host, &timep)\". bool_t\nrpcb_gettime(host,timep)\n      char *host\n      time_t &timep\n    OUTPUT:\n      timep Inserting POD , Comments and C Preprocessor Directives C preprocessor directives are allowed within BOOT: , PREINIT: INIT: , CODE: , PPCODE: , POSTCALL: , and CLEANUP: blocks, as well as outside the functions. Comments are allowed anywhere after the MODULE keyword. The compiler will pass the preprocessor directives through untouched and will remove the commented lines. POD documentation is allowed at any point, both in the C and XS language sections. POD must be terminated with a \"=cut\" command; \"xsubpp\" will exit with an error if it does not. It is very unlikely that human generated C code will be mistaken for POD , as most indenting styles result in whitespace in front of any line starting with \"=\". Machine generated XS files may fall into this trap unless care is taken to ensure that a space breaks the sequence \"\\n=\". Comments can be added to XSUBs by placing a \"#\" as the first non-whitespace of a line. Care should be taken to avoid making the comment look like a C preprocessor directive, lest it be interpreted as such. The simplest way to prevent this is to put whitespace in front of the \"#\". If you use preprocessor directives to choose one of two versions of a function, use #if ... version1\n#else \/* ... version2  *\/\n#endif and not #if ... version1\n#endif\n#if ... version2\n#endif because otherwise xsubpp will believe that you made a duplicate definition of the function. Also, put a blank line before the #else\/#endif so it will not be seen as part of the function body. Using XS With C ++ If an XSUB name contains \"::\", it is considered to be a C ++ method. The generated Perl function will assume that its first argument is an object pointer. The object pointer will be stored in a variable called THIS . The object should have been created by C ++ with the new() function and should be blessed by Perl with the sv_setref_pv() macro. The blessing of the object by Perl can be handled by a typemap. An example typemap is shown at the end of this section. If the return type of the XSUB includes \"static\", the method is considered to be a static method. It will call the C ++ function using the class::method() syntax. If the method is not static the function will be called using the THIS- >method() syntax. The next examples will use the following C ++ class. class color {\n     public:\n     color();\n     ~color();\n     int blue();\n     void set_blue( int );\n\n     private:\n     int c_blue;\n}; The XSUBs for the blue() and set_blue() methods are defined with the class name but the parameter for the object ( THIS , or \"self\") is implicit and is not listed. int\ncolor::blue()\n\nvoid\ncolor::set_blue( val )\n     int val Both Perl functions will expect an object as the first parameter. In the generated C ++ code the object is called \"THIS\", and the method call will be performed on this object. So in the C ++ code the blue() and set_blue() methods will be called as this: RETVAL = THIS->blue();\n\nTHIS->set_blue( val ); You could also write a single get\/set method using an optional argument: int\ncolor::blue( val = NO_INIT )\n    int val\n    PROTOTYPE $;$\n    CODE:\n        if (items > 1)\n            THIS->set_blue( val );\n        RETVAL = THIS->blue();\n    OUTPUT:\n        RETVAL If the function's name is DESTROY then the C ++ \"delete\" function will be called and \"THIS\" will be given as its parameter. The generated C ++ code for void\ncolor::DESTROY() will look like this: color *THIS = ...; \/\/ Initialized as in typemap\n\ndelete THIS; If the function's name is new then the C ++ \"new\" function will be called to create a dynamic C ++ object. The XSUB will expect the class name, which will be kept in a variable called \"CLASS\", to be given as the first argument. color *\ncolor::new() The generated C ++ code will call \"new\". RETVAL = new color(); The following is an example of a typemap that could be used for this C ++ example. TYPEMAP\ncolor *             O_OBJECT\n\nOUTPUT\n# The Perl object is blessed into 'CLASS', which should be a\n# char* having the name of the package for the blessing.\nO_OBJECT\n    sv_setref_pv( $arg, CLASS, (void*)$var );\n\nINPUT\nO_OBJECT\n    if( sv_isobject($arg) && (SvTYPE(SvRV($arg)) == SVt_PVMG) )\n            $var = ($type)SvIV((SV*)SvRV( $arg ));\n    else{\n            warn( \\\"${Package}::$func_name() -- $var is not a blessed SV reference\\\" );\n            XSRETURN_UNDEF;\n    } Interface Strategy When designing an interface between Perl and a C library a straight translation from C to XS (such as created by \"h2xs -x\") is often sufficient. However, sometimes the interface will look very C-like and occasionally nonintuitive, especially when the C function modifies one of its parameters, or returns failure inband (as in \"negative return values mean failure\"). In cases where the programmer wishes to create a more Perl-like interface the following strategy may help to identify the more critical parts of the interface. Identify the C functions with input\/output or output parameters. The XSUBs for these functions may be able to return lists to Perl. Identify the C functions which use some inband info as an indication of failure. They may be candidates to return undef or an empty list in case of failure. If the failure may be detected without a call to the C function, you may want to use an INIT: section to report the failure. For failures detectable after the C function returns one may want to use a POSTCALL: section to process the failure. In more complicated cases use CODE: or PPCODE: sections. If many functions use the same failure indication based on the return value, you may want to create a special typedef to handle this situation. Put typedef int negative_is_failure; near the beginning of XS file, and create an OUTPUT typemap entry for \"negative_is_failure\" which converts negative values to \"undef\", or maybe croak()s. After this the return value of type \"negative_is_failure\" will create more Perl-like interface. Identify which values are used by only the C and XSUB functions themselves, say, when a parameter to a function should be a contents of a global variable. If Perl does not need to access the contents of the value then it may not be necessary to provide a translation for that value from C to Perl. Identify the pointers in the C function parameter lists and return values. Some pointers may be used to implement input\/output or output parameters, they can be handled in XS with the \"&\" unary operator, and, possibly, using the NO_INIT keyword. Some others will require handling of types like \"int *\", and one needs to decide what a useful Perl translation will do in such a case. When the semantic is clear, it is advisable to put the translation into a typemap file. Identify the structures used by the C functions. In many cases it may be helpful to use the T_PTROBJ typemap for these structures so they can be manipulated by Perl as blessed objects. (This is handled automatically by \"h2xs -x\".) If the same C type is used in several different contexts which require different translations, \"typedef\" several new types mapped to this C type, and create separate typemap entries for these new types. Use these types in declarations of return type and parameters to XSUBs. Perl Objects And C Structures When dealing with C structures one should select either T_PTROBJ or T_PTRREF for the XS type. Both types are designed to handle pointers to complex objects. The T_PTRREF type will allow the Perl object to be unblessed while the T_PTROBJ type requires that the object be blessed. By using T_PTROBJ one can achieve a form of type-checking because the XSUB will attempt to verify that the Perl object is of the expected type. The following XS code shows the getnetconfigent() function which is used with ONC+ TIRPC . The getnetconfigent() function will return a pointer to a C structure and has the C prototype shown below. The example will demonstrate how the C pointer will become a Perl reference. Perl will consider this reference to be a pointer to a blessed object and will attempt to call a destructor for the object. A destructor will be provided in the XS source to free the memory used by getnetconfigent(). Destructors in XS can be created by specifying an XSUB function whose name ends with the word DESTROY . XS destructors can be used to free memory which may have been malloc'd by another XSUB . struct netconfig *getnetconfigent(const char *netid); A \"typedef\" will be created for \"struct netconfig\". The Perl object will be blessed in a class matching the name of the C type, with the tag \"Ptr\" appended, and the name should not have embedded spaces if it will be a Perl package name. The destructor will be placed in a class corresponding to the class of the object and the PREFIX keyword will be used to trim the name to the word DESTROY as Perl will expect. typedef struct netconfig Netconfig;\n\nMODULE = RPC  PACKAGE = RPC\n\nNetconfig *\ngetnetconfigent(netid)\n     char *netid\n\nMODULE = RPC  PACKAGE = NetconfigPtr  PREFIX = rpcb_\n\nvoid\nrpcb_DESTROY(netconf)\n     Netconfig *netconf\n   CODE:\n     printf(\"Now in NetconfigPtr::DESTROY\\n\");\n     free( netconf ); This example requires the following typemap entry. Consult the typemap section for more information about adding new typemaps for an extension. TYPEMAP\nNetconfig *  T_PTROBJ This example will be used with the following Perl statements. use RPC;\n$netconf = getnetconfigent(\"udp\"); When Perl destroys the object referenced by $netconf it will send the object to the supplied XSUB DESTROY function. Perl cannot determine, and does not care, that this object is a C struct and not a Perl object. In this sense, there is no difference between the object created by the getnetconfigent() XSUB and an object created by a normal Perl subroutine. The Typemap The typemap is a collection of code fragments which are used by the xsubpp compiler to map C function parameters and values to Perl values. The typemap file may consist of three sections labelled \"TYPEMAP\", \"INPUT\", and \"OUTPUT\". An unlabelled initial section is assumed to be a \"TYPEMAP\" section. The INPUT section tells the compiler how to translate Perl values into variables of certain C types. The OUTPUT section tells the compiler how to translate the values from certain C types into values Perl can understand. The TYPEMAP section tells the compiler which of the INPUT and OUTPUT code fragments should be used to map a given C type to a Perl value. The section labels \"TYPEMAP\", \"INPUT\", or \"OUTPUT\" must begin in the first column on a line by themselves, and must be in uppercase. The default typemap in the \"lib\/ExtUtils\" directory of the Perl source contains many useful types which can be used by Perl extensions. Some extensions define additional typemaps which they keep in their own directory. These additional typemaps may reference INPUT and OUTPUT maps in the main typemap. The xsubpp compiler will allow the extension's own typemap to override any mappings which are in the default typemap. Most extensions which require a custom typemap will need only the TYPEMAP section of the typemap file. The custom typemap used in the getnetconfigent() example shown earlier demonstrates what may be the typical use of extension typemaps. That typemap is used to equate a C structure with the T_PTROBJ typemap. The typemap used by getnetconfigent() is shown here. Note that the C type is separated from the XS type with a tab and that the C unary operator \"*\" is considered to be a part of the C type name. TYPEMAP\nNetconfig *<tab>T_PTROBJ Here's a more complicated example: suppose that you wanted \"struct netconfig\" to be blessed into the class \"Net::Config\". One way to do this is to use underscores (_) to separate package names, as follows: typedef struct netconfig * Net_Config; And then provide a typemap entry \"T_PTROBJ_SPECIAL\" that maps underscores to double-colons (::), and declare \"Net_Config\" to be of that type: TYPEMAP\nNet_Config      T_PTROBJ_SPECIAL\n\nINPUT\nT_PTROBJ_SPECIAL\n        if (sv_derived_from($arg, \\\"${(my $ntt=$ntype)=~s\/_\/::\/g;\\$ntt}\\\")) {\n                IV tmp = SvIV((SV*)SvRV($arg));\n                $var = INT2PTR($type, tmp);\n        }\n        else\n                croak(\\\"$var is not of type ${(my $ntt=$ntype)=~s\/_\/::\/g;\\$ntt}\\\")\n\nOUTPUT\nT_PTROBJ_SPECIAL\n        sv_setref_pv($arg, \\\"${(my $ntt=$ntype)=~s\/_\/::\/g;\\$ntt}\\\",\n        (void*)$var); The INPUT and OUTPUT sections substitute underscores for double-colons on the fly, giving the desired effect. This example demonstrates some of the power and versatility of the typemap facility. The INT2PTR macro (defined in perl.h) casts an integer to a pointer, of a given type, taking care of the possible different size of integers and pointers. There are also PTR2IV , PTR2UV , PTR2NV macros, to map the other way, which may be useful in OUTPUT sections. Safely Storing Static Data in XS Starting with Perl 5.8, a macro framework has been defined to allow static data to be safely stored in XS modules that will be accessed from a multi-threaded Perl. Although primarily designed for use with multi-threaded Perl, the macros have been designed so that they will work with non-threaded Perl as well. It is therefore strongly recommended that these macros be used by all XS modules that make use of static data. The easiest way to get a template set of macros to use is by specifying the \"-g\" (\"--global\") option with h2xs (see h2xs). Below is an example module that makes use of the macros. #include \"EXTERN.h\"\n#include \"perl.h\"\n#include \"XSUB.h\"\n\n\/* Global Data *\/\n\n#define MY_CXT_KEY \"BlindMice::_guts\" XS_VERSION\n\ntypedef struct {\n    int count;\n    char name[3][100];\n} my_cxt_t;\n\nSTART_MY_CXT\n\nMODULE = BlindMice           PACKAGE = BlindMice\n\nBOOT:\n{\n    MY_CXT_INIT;\n    MY_CXT.count = 0;\n    strcpy(MY_CXT.name[0], \"None\");\n    strcpy(MY_CXT.name[1], \"None\");\n    strcpy(MY_CXT.name[2], \"None\");\n}\n\nint\nnewMouse(char * name)\n    char * name;\n    PREINIT:\n      dMY_CXT;\n    CODE:\n      if (MY_CXT.count >= 3) {\n          warn(\"Already have 3 blind mice\");\n          RETVAL = 0;\n      }\n      else {\n          RETVAL = ++ MY_CXT.count;\n          strcpy(MY_CXT.name[MY_CXT.count - 1], name);\n      }\n\nchar *\nget_mouse_name(index)\n  int index\n  CODE:\n    dMY_CXT;\n    RETVAL = MY_CXT.lives ++;\n    if (index > MY_CXT.count)\n      croak(\"There are only 3 blind mice.\");\n    else\n      RETVAL = newSVpv(MY_CXT.name[index - 1]);\n\nvoid\nCLONE(...)\n    CODE:\n    MY_CXT_CLONE; REFERENCE MY_CXT_KEY This macro is used to define a unique key to refer to the static data for an XS module. The suggested naming scheme, as used by h2xs, is to use a string that consists of the module name, the string \"::_guts\" and the module version number. #define MY_CXT_KEY \"MyModule::_guts\" XS_VERSION typedef my_cxt_t This struct typedef must always be called \"my_cxt_t\" -- the other \"CXT*\" macros assume the existence of the \"my_cxt_t\" typedef name. Declare a typedef named \"my_cxt_t\" that is a structure that contains all the data that needs to be interpreter-local. typedef struct {\n    int some_value;\n} my_cxt_t; START_MY_CXT Always place the START_MY_CXT macro directly after the declaration of \"my_cxt_t\". MY_CXT_INIT The MY_CXT_INIT macro initialises storage for the \"my_cxt_t\" struct. It must be called exactly once -- typically in a BOOT: section. If you are maintaining multiple interpreters, it should be called once in each interpreter instance, except for interpreters cloned from existing ones. (But see \"MY_CXT_CLONE\" below.) dMY_CXT Use the dMY_CXT macro (a declaration) in all the functions that access MY_CXT . MY_CXT Use the MY_CXT macro to access members of the \"my_cxt_t\" struct. For example, if \"my_cxt_t\" is typedef struct {\n    int index;\n} my_cxt_t; then use this to access the \"index\" member dMY_CXT;\nMY_CXT.index = 2; aMY_CXT\/pMY_CXT \"dMY_CXT\" may be quite expensive to calculate, and to avoid the overhead of invoking it in each function it is possible to pass the declaration onto other functions using the \"aMY_CXT\"\/ \"pMY_CXT\" macros, eg void sub1() {\n    dMY_CXT;\n    MY_CXT.index = 1;\n    sub2(aMY_CXT);\n}\n\nvoid sub2(pMY_CXT) {\n    MY_CXT.index = 2;\n} Analogously to \"pTHX\", there are equivalent forms for when the macro is the first or last in multiple arguments, where an underscore represents a comma, i.e. \"_aMY_CXT\", \"aMY_CXT_\", \"_pMY_CXT\" and \"pMY_CXT_\". MY_CXT_CLONE By default, when a new interpreter is created as a copy of an existing one (eg via \"threads->create()\"), both interpreters share the same physical my_cxt_t structure. Calling \"MY_CXT_CLONE\" (typically via the package's \"CLONE()\" function), causes a byte-for-byte copy of the structure to be taken, and any future dMY_CXT will cause the copy to be accessed instead. MY_CXT_INIT_INTERP (my_perl) dMY_CXT_INTERP(my_perl) These are versions of the macros which take an explicit interpreter as an argument. Note that these macros will only work together within the same source file; that is, a dMY_CTX in one source file will access a different structure than a dMY_CTX in another source file. Thread-aware system interfaces Starting from Perl 5.8, in C\/C ++ level Perl knows how to wrap system\/library interfaces that have thread-aware versions (e.g. getpwent_r()) into frontend macros (e.g. getpwent()) that correctly handle the multithreaded interaction with the Perl interpreter. This will happen transparently, the only thing you need to do is to instantiate a Perl interpreter. This wrapping happens always when compiling Perl core source ( PERL_CORE is defined) or the Perl core extensions ( PERL_EXT is defined). When compiling XS code outside of Perl core the wrapping does not take place. Note, however, that intermixing the _r-forms (as Perl compiled for multithreaded operation will do) and the _r-less forms is neither well-defined (inconsistent results, data corruption, or even crashes become more likely), nor is it very portable.","Process Name":"perlxs","Link":"https:\/\/linux.die.net\/man\/1\/perlxs"}},{"Process":{"Description":"This tutorial will educate the reader on the steps involved in creating a Perl extension. The reader is assumed to have access to perlguts, perlapi and perlxs. This tutorial starts with very simple examples and becomes more complex, with each new example adding new features. Certain concepts may not be completely explained until later in the tutorial in order to slowly ease the reader into building extensions. This tutorial was written from a Unix point of view. Where I know them to be otherwise different for other platforms (e.g. Win32), I will list them. If you find something that was missed, please let me know.","Process Name":"perlxstut","Link":"https:\/\/linux.die.net\/man\/1\/perlxstut"}},{"Process":{"Description":"This tools allow to list the declarative security attributes present in an assembly. The security attributes are either found on the assembly level, on the classes and the methods. This tool is useful to diagnose why an assembly won't load or why some class\/method throws SecurityException.","Process Name":"permview","Link":"https:\/\/linux.die.net\/man\/1\/permview"}},{"Process":{"Description":"For most system errors, MySQL displays, in addition to an internal text message, the system error code in one of the following styles: message ... (errno: #)\nmessage ... (Errcode: #) You can find out what the error code means by examining the documentation for your system or by using the perror utility. perror prints a description for a system error code or for a storage engine (table handler) error code. Invoke perror like this: shell> perror [options] errorcode ...\n Example: shell> perror 13 64\nOS error code  13:  Permission denied\nOS error code  64:  Machine is not on the network To obtain the error message for a MySQL Cluster error code, invoke perror with the --ndb option: shell> perror --ndb errorcode\n Note that the meaning of system error messages may be dependent on your operating system. A given error code may mean different things on different operating systems. perror supports the following options. \u2022 --help, --info, -I, -? Display a help message and exit. \u2022 --ndb Print the error message for a MySQL Cluster error code. \u2022 --silent, -s Silent mode. Print only the error message. \u2022 --verbose, -v Verbose mode. Print error code and message. This is the default behavior. \u2022 --version, -V Display version information and exit.","Process Name":"perror","Link":"https:\/\/linux.die.net\/man\/1\/perror"}},{"Process":{"Description":"petit was developed to quickly analyze syslog and Apache log files in large environments. It can also be used for word discovery within log data. It is a general purpose tool that can do hashing, word counts, and command line graphing of Apache and syslog files. It is designed to be a standard Unix tool that can be employed with pipes or by opening files. Petit works by sifting data with standard patterns and allows for custom filters and fingerprints. This leaves the analyst with data that is both varied and interesting. FILE can be Syslog, Apache Access, Apache Error, Snort or Raw log files. Petit can also be used to analyze any type of file as a Raw log file, but since time\/date is not understood, they cannot be graphed.","Process Name":"petit","Link":"https:\/\/linux.die.net\/man\/1\/petit"}},{"Process":{"Description":"petri simulates mold growing in a petri dish via a state-heavy grid of automata (vaguely like Conway's Life, only with much more state per cell).","Process Name":"petri","Link":"https:\/\/linux.die.net\/man\/1\/petri"}},{"Process":{"Description":"This script invokes gs(1) to make an AFM file from PFB \/ PFA and (optionally) PFM files. Output goes to fontfilename.afm, which must not already exist.","Process Name":"pf2afm","Link":"https:\/\/linux.die.net\/man\/1\/pf2afm"}},{"Process":{"Description":"The program pfaedit allows you to create and modify font files, accepting input in the following formats (with associated file extensions appearing in parentheses): Glyph Bitmap Distribution (.bdf) Macintosh resource fonts (.dfont, .bin, .hqx) OpenType (.otf) pfaeditspline font database (.sfd) , which includes: ASCII format (.pfa) Binary format (.pfb) CID-keyed fonts, Adobe convention used primarily for Asian characters (.cid, .otf) Type 0 (.ps) Type 3 (.ps) Scaleable vector graphics fonts (.svg) TeX bitmap (.pk) TrueType (.ttf, .ttc) X11 bitmap (.pcf) If the argument list contains a font file name (or several), pfaedit opens a fontview window for each font displaying the characters of the that font. In the absence of options or arguments, the program opens a file-picker window, allowing you to browse your disk to find a font file, or create a new one. This manual page is intended only as a rudimentary overview; see the HTML Users Manual for more complete information.","Process Name":"pfaedit","Link":"https:\/\/linux.die.net\/man\/1\/pfaedit"}},{"Process":{"Description":"Program converts a binary MSDOS representation for a type1 PostScript font into a readable ASCII version. The MSDOS newline (\\r) is converted into the UNIX newline (\\n). The output is written in a file whose name is the name that is provided on the command line or the basename of the input file plus extension \".pfa\". With the -v option you get some information about what the program is doing.","Process Name":"pfb2pfa","Link":"https:\/\/linux.die.net\/man\/1\/pfb2pfa"}},{"Process":{"Description":"This script invokes gs(1) to convert a .pfb file into a .pfa file.","Process Name":"pfbtopfa","Link":"https:\/\/linux.die.net\/man\/1\/pfbtopfa"}},{"Process":{"Description":"pfbtops translates a PostScript font in .pfb format to ASCII. If pfb_file is omitted the pfb file will be read from the standard input. The ASCII format PostScript font will be written on the standard output. PostScript fonts for MS-DOS are normally supplied in .pfb format. The resulting ASCII format PostScript font can be used with groff. It must first be listed in \/usr\/share\/groff\/1.18.1.4\/font\/devps\/download.","Process Name":"pfbtops","Link":"https:\/\/linux.die.net\/man\/1\/pfbtops"}},{"Process":{"Description":"This manual page documents briefly the pfc command. pfc is the Precompiled Filter Compiler - a tool to generate \"active precompiled filters\". If your pppd supports this feature, you can use this utility to generate the filter files. The Active Filter allows a connect on demand pppd to determine what is 'interesting' traffic, and then initiate the PPP session. The tool allows you to create the filters, in libpcap format, for use by pppd. Common filters are used to ignore traffic (ie: ntp, various protocol keepalives, etc...) so PPP sessions are not initiated until 'real' traffic requires them. Note that the generated compiled filter expression is specific to point-to-point links, and differs from the format generated by tcpdump -ddd. (specify precompiled-active-filter=\/etc\/ppp\/your.active.filter in the ppp options file)","Process Name":"pfc","Link":"https:\/\/linux.die.net\/man\/1\/pfc"}},{"Process":{"Description":"This program uses podgrep program to search your configuration's perlfunc for function definitions. It honors a -f flag to format through pod2text and a -p flag to send the output through the pager. (Actually, it just passes these to podgrep.)","Process Name":"pfcat","Link":"https:\/\/linux.die.net\/man\/1\/pfcat"}},{"Process":{"Description":"Pflogsumm is a log analyzer\/summarizer for the Postfix MTA.  It is\ndesigned to provide an over-view of Postfix activity, with just enough\ndetail to give the administrator a \"heads up\" for potential trouble\nspots.\n\nPflogsumm generates summaries and, in some cases, detailed reports of\nmail server traffic volumes, rejected and bounced email, and server\nwarnings, errors and panics.","Process Name":"pflogsumm","Link":"https:\/\/linux.die.net\/man\/1\/pflogsumm"}},{"Process":{"Description":"This program is part of Netpbm(1). pfmtopam reads a PFM (Portable Float Map) image and converts it to PAM. See pamtopfm(1)foradescriptionof PFM. If you want one of the older, more portable Netpbm formats, run the output through pamtopnm. pamtopfm creates a PAM with tuple type 'RGB' or 'GRAYSCALE' depending on whether or not the PFM is in the color subformat. Use pamtopfm(1)toconvertaPFM image to Netpbm format.","Process Name":"pfmtopam","Link":"https:\/\/linux.die.net\/man\/1\/pfmtopam"}},{"Process":{"Description":"put the following in your ~\/.pfq.yml TSE:\n  - 2010\nEmerging:\n  - 3481 Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"pfq","Link":"https:\/\/linux.die.net\/man\/1\/pfq"}},{"Process":{"Description":"pfqueue is a simple console tool for managing MTA (Mail Transfer Agent) message queues. It handles queues through 'backends', libraries that interact with the MTA, and displays informations through a console, ncurses based 'frontend'. Currently, pfqueue has backends for Postfix (both 1.x and 2.x) and Exim (both version 3 and 4).","Process Name":"pfqueue","Link":"https:\/\/linux.die.net\/man\/1\/pfqueue"}},{"Process":{"Description":"Ftp is the user interface to the Internet standard File Transfer Protocol. The program allows a user to transfer files to and from a remote network site. Options may be specified at the command line, or to the command interpreter.       -A'      Use active mode for data transfers. This is useful fortransmissions to servers which do not support passive connections(for whatever reason.) -p' Use passive mode for data transfers. Allows use of ftp in environments where a firewall prevents connections from the outside world back to the client machine. Requires that the ftp server support the PASV command. This is the default now for all clients (ftp and pftp) due to security concerns using the PORT transfer mode. The flag is kept for compatibility only and has no effect anymore. -i' Turns off interactive prompting during multiple file transfers. -n' Restrains ftp from attempting ''auto-login'' upon initial connection. If auto-login is enabled, ftp will check the .netrc (see netrc(5)) file in the user's home directory for an entry describing an account on the remote machine. If no entry exists, ftp will prompt for the remote machine login name (default is the user identity on the local machine), and, if necessary, prompt for a password and an account with which to login. -e' Disables command editing and history support, if it was compiled into the ftp executable. Otherwise, does nothing. -g' Disables file name globbing. -m' The default requires that ftp explicitly binds to the same interface for the data channel as the control channel in passive mode. Useful on multi-homed clients. This option disables this behavior. -v' Verbose option forces ftp to show all responses from the remote server, as well as report on data transfer statistics. -d' Enables debugging. The client host with which ftp is to communicate may be specified on the command line. If this is done, ftp will immediately attempt to establish a connection to an FTP server on that host; otherwise, ftp will enter its command interpreter and await instructions from the user. When ftp is awaiting commands from the user the prompt 'ftp>' is provided to the user. The following commands are recognized by ftp: ! [command [args]] Invoke an interactive shell on the local machine. If there are arguments, the first is taken to be a command to execute directly, with the rest of the arguments as its arguments. $ macro-name [args] Execute the macro macro-name that was defined with the macdef command. Arguments are passed to the macro unglobbed. account [passwd] Supply a supplemental password required by a remote system for access to resources once a login has been successfully completed. If no argument is included, the user will be prompted for an account password in a non-echoing input mode. append local-file [remote-file] Append a local file to a file on the remote machine. If remote-file is left unspecified, the local file name is used in naming the remote file after being altered by any ntrans or nmap setting. File transfer uses the current settings for type, format, mode, and structure. ascii' Set the file transfer type to network ASCII. This is the default type. bell' Arrange that a bell be sounded after each file transfer command is completed. binary' Set the file transfer type to support binary image transfer. bye' Terminate the FTP session with the remote server and exit ftp. An end of file will also terminate the session and exit. case' Toggle remote computer file name case mapping during mget commands. When case is on (default is off), remote computer file names with all letters in upper case are written in the local directory with the letters mapped to lower case. cd remote-directory Change the working directory on the remote machine to remote-directory. cdup' Change the remote machine working directory to the parent of the current remote machine working directory. chmod mode file-name Change the permission modes of the file file-name on the remote sytem to mode. close' Terminate the FTP session with the remote server, and return to the command interpreter. Any defined macros are erased. cr' Toggle carriage return stripping during ascii type file retrieval. Records are denoted by a carriage return\/linefeed sequence during ascii type file transfer. When cr is on (the default), carriage returns are stripped from this sequence to conform with the UNIX single linefeed record delimiter. Records on non-UNIX remote systems may contain single linefeeds; when an ascii type transfer is made, these linefeeds may be distinguished from a record delimiter only when cr is off. delete remote-file Delete the file remote-file on the remote machine. debug [debug-value] Toggle debugging mode. If an optional debug-value is specified it is used to set the debugging level. When debugging is on, ftp prints each command sent to the remote machine, preceded by the string '-->' dir [remote-directory] [local-file] Print a listing of the directory contents in the directory, remote-directory, and, optionally, placing the output in local-file. If interactive prompting is on, ftp will prompt the user to verify that the last argument is indeed the target local file for receiving dir output. If no directory is specified, the current working directory on the remote machine is used. If no local file is specified, or local-file is -, output comes to the terminal. disconnect A synonym for close. form format Set the file transfer form to format. The default format is ''file''. get remote-file [local-file] Retrieve the remote-file and store it on the local machine. If the local file name is not specified, it is given the same name it has on the remote machine, subject to alteration by the current case, ntrans, and nmap settings. The current settings for type, form, mode, and structure are used while transferring the file. glob' Toggle filename expansion for mdelete, mget and mput. If globbing is turned off with glob, the file name arguments are taken literally and not expanded. Globbing for mput is done as in csh(1). For mdelete and mget, each remote file name is expanded separately on the remote machine and the lists are not merged. Expansion of a directory name is likely to be different from expansion of the name of an ordinary file: the exact result depends on the foreign operating system and ftp server, and can be previewed by doing 'mls remote-files -' Note: mget and mput are not meant to transfer entire directory subtrees of files. That can be done by transferring a tar(1) archive of the subtree (in binary mode). hash' Toggle hash-sign (''#'') printing for each data block transferred. The size of a data block is 1024 bytes. help [command] Print an informative message about the meaning of command. If no argument is given, ftp prints a list of the known commands. idle [seconds] Set the inactivity timer on the remote server to seconds seconds. If seconds is ommitted, the current inactivity timer is printed. lcd [directory] Change the working directory on the local machine. If no directory is specified, the user's home directory is used. ls [remote-directory] [local-file] Print a listing of the contents of a directory on the remote machine. The listing includes any system-dependent information that the server chooses to include; for example, most UNIX systems will produce output from the command 'ls -l'. (See also nlist.) If remote-directory is left unspecified, the current working directory is used. If interactive prompting is on, ftp will prompt the user to verify that the last argument is indeed the target local file for receiving ls output. If no local file is specified, or if local-file is '-', the output is sent to the terminal. macdef macro-name Define a macro. Subsequent lines are stored as the macro macro-name; a null line (consecutive newline characters in a file or carriage returns from the terminal) terminates macro input mode. There is a limit of 16 macros and 4096 total characters in all defined macros. Macros remain defined until a close command is executed. The macro processor interprets '$' and '\\' as special characters. A '$' followed by a number (or numbers) is replaced by the corresponding argument on the macro invocation command line. A '$' followed by an 'i' signals that macro processor that the executing macro is to be looped. On the first pass '$i' is replaced by the first argument on the macro invocation command line, on the second pass it is replaced by the second argument, and so on. A '\\' followed by any character is replaced by that character. Use the '\\' to prevent special treatment of the '$'. mdelete [remote-files] Delete the remote-files on the remote machine. mdir remote-files local-file Like dir, except multiple remote files may be specified. If interactive prompting is on, ftp will prompt the user to verify that the last argument is indeed the target local file for receiving mdir output. mget remote-files Expand the remote-files on the remote machine and do a get for each file name thus produced. See glob for details on the filename expansion. Resulting file names will then be processed according to case, ntrans, and nmap settings. Files are transferred into the local working directory, which can be changed with 'lcd directory'; new local directories can be created with '! mkdir directory'. mkdir directory-name Make a directory on the remote machine. mls remote-files local-file Like nlist, except multiple remote files may be specified, and the local-file must be specified. If interactive prompting is on, ftp will prompt the user to verify that the last argument is indeed the target local file for receiving mls output. mode [mode-name] Set the file transfer mode to mode-name. The default mode is ''stream'' mode. modtime file-name Show the last modification time of the file on the remote machine. mput local-files Expand wild cards in the list of local files given as arguments and do a put for each file in the resulting list. See glob for details of filename expansion. Resulting file names will then be processed according to ntrans and nmap settings. newer file-name [local-file] Get the file only if the modification time of the remote file is more recent that the file on the current system. If the file does not exist on the current system, the remote file is considered newer. Otherwise, this command is identical to get. nlist [remote-directory] [local-file] Print a list of the files in a directory on the remote machine. If remote-directory is left unspecified, the current working directory is used. If interactive prompting is on, ftp will prompt the user to verify that the last argument is indeed the target local file for receiving nlist output. If no local file is specified, or if local-file is -, the output is sent to the terminal. nmap [inpattern outpattern] Set or unset the filename mapping mechanism. If no arguments are specified, the filename mapping mechanism is unset. If arguments are specified, remote filenames are mapped during mput commands and put commands issued without a specified remote target filename. If arguments are specified, local filenames are mapped during mget commands and get commands issued without a specified local target filename. This command is useful when connecting to a non-UNIX remote computer with different file naming conventions or practices. The mapping follows the pattern set by inpattern and outpattern. [Inpattern] is a template for incoming filenames (which may have already been processed according to the ntrans and case settings). Variable templating is accomplished by including the sequences '$1', '$2', ..., '$9' in inpattern. Use '\\' to prevent this special treatment of the '$' character. All other characters are treated literally, and are used to determine the nmap [inpattern] variable values. For example, given inpattern $1.$2 and the remote file name \"mydata.data\", $1 would have the value \"mydata\", and $2 would have the value \"data\". The outpattern determines the resulting mapped filename. The sequences '$1', '$2', ...., '$9' are replaced by any value resulting from the inpattern template. The sequence '$0' is replace by the original filename. Additionally, the sequence '[seq1, seq2]' is replaced by [seq1] if seq1 is not a null string; otherwise it is replaced by seq2. For example, the command nmap $1.$2.$3 [$1,$2].[$2,file] would yield the output filename \"myfile.data\" for input filenames \"myfile.data\" and \"myfile.data.old\", \"myfile.file\" for the input filename \"myfile\", and \"myfile.myfile\" for the input filename \".myfile\". Spaces may be included in outpattern, as in the example: 'nmap $1 sed \"s\/ *$\/\/\" > $1' . Use the '\\' character to prevent special treatment of the '$','[','[', and ',' characters.        ntrans [inchars [outchars]] Set or unset the filename character translation mechanism. If no arguments are specified, the filename character translation mechanism is unset. If arguments are specified, characters in remote filenames are translated during mput commands and put commands issued without a specified remote target filename. If arguments are specified, characters in local filenames are translated during mget commands and get commands issued without a specified local target filename. This command is useful when connecting to a non-UNIX remote computer with different file naming conventions or practices. Characters in a filename matching a character in inchars are replaced with the corresponding character in outchars. If the character's position in inchars is longer than the length of outchars, the character is deleted from the file name. open host [port] Establish a connection to the specified host FTP server. An optional port number may be supplied, in which case, ftp will attempt to contact an FTP server at that port. If the auto-login option is on (default), ftp will also attempt to automatically log the user in to the FTP server (see below). prompt' Toggle interactive prompting. Interactive prompting occurs during multiple file transfers to allow the user to selectively retrieve or store files. If prompting is turned off (default is on), any mget or mput will transfer all files, and any mdelete will delete all files. proxy ftp-command Execute an ftp command on a secondary control connection. This command allows simultaneous connection to two remote ftp servers for transferring files between the two servers. The first proxy command should be an open, to establish the secondary control connection. Enter the command \"proxy ?\" to see other ftp commands executable on the secondary connection. The following commands behave differently when prefaced by proxy: open will not define new macros during the auto-login process, close will not erase existing macro definitions, get and mget transfer files from the host on the primary control connection to the host on the secondary control connection, and put, mput, and append transfer files from the host on the secondary control connection to the host on the primary control connection. Third party file transfers depend upon support of the ftp protocol PASV command by the server on the secondary control connection. put local-file [remote-file] Store a local file on the remote machine. If remote-file is left unspecified, the local file name is used after processing according to any ntrans or nmap settings in naming the remote file. File transfer uses the current settings for type, format, mode, and structure. pwd' Print the name of the current working directory on the remote machine. quit' A synonym for bye. quote arg1 arg2 ... The arguments specified are sent, verbatim, to the remote FTP server. recv remote-file [local-file] A synonym for get. reget remote-file [local-file] Reget acts like get, except that if local-file exists and is smaller than remote-file, local-file is presumed to be a partially transferred copy of remote-file and the transfer is continued from the apparent point of failure. This command is useful when transferring very large files over networks that are prone to dropping connections. remotehelp [command-name] Request help from the remote FTP server. If a command-name is specified it is supplied to the server as well. remotestatus [file-name] With no arguments, show status of remote machine. If file-name is specified, show status of file-name on remote machine. rename [from] [to] Rename the file from on the remote machine, to the file to. reset' Clear reply queue. This command re-synchronizes command\/reply sequencing with the remote ftp server. Resynchronization may be necessary following a violation of the ftp protocol by the remote server. restart marker Restart the immediately following get or put at the indicated marker. On UNIX systems, marker is usually a byte offset into the file. rmdir directory-name Delete a directory on the remote machine. runique' Toggle storing of files on the local system with unique filenames. If a file already exists with a name equal to the target local filename for a get or mget command, a \".1\" is appended to the name. If the resulting name matches another existing file, a \".2\" is appended to the original name. If this process continues up to \".99\", an error message is printed, and the transfer does not take place. The generated unique filename will be reported. Note that runique will not affect local files generated from a shell command (see below). The default value is off. send local-file [remote-file] A synonym for put. sendport' Toggle the use of PORT commands. By default, ftp will attempt to use a PORT command when establishing a connection for each data transfer. The use of PORT commands can prevent delays when performing multiple file transfers. If the PORT command fails, ftp will use the default data port. When the use of PORT commands is disabled, no attempt will be made to use PORT commands for each data transfer. This is useful for certain FTP implementations which do ignore PORT commands but, incorrectly, indicate they've been accepted. site arg1 arg2 ... The arguments specified are sent, verbatim, to the remote FTP server as a SITE command. size file-name Return size of file-name on remote machine. status' Show the current status of ftp. struct [struct-name] Set the file transfer structure to struct-name. By default ''stream'' structure is used. sunique' Toggle storing of files on remote machine under unique file names. Remote ftp server must support ftp protocol STOU command for successful completion. The remote server will report unique name. Default value is off. system' Show the type of operating system running on the remote machine. tenex' Set the file transfer type to that needed to talk to TENEX machines. trace' Toggle packet tracing. type [type-name] Set the file transfer type to type-name. If no type is specified, the current type is printed. The default type is network ASCII. umask [newmask] Set the default umask on the remote server to newmask. If newmask is ommitted, the current umask is printed. user user-name [password] [account] Identify yourself to the remote FTP server. If the password is not specified and the server requires it, ftp will prompt the user for it (after disabling local echo). If an account field is not specified, and the FTP server requires it, the user will be prompted for it. If an account field is specified, an account command will be relayed to the remote server after the login sequence is completed if the remote server did not require it for logging in. Unless ftp is invoked with ''auto-login'' disabled, this process is done automatically on initial connection to the FTP server. verbose' Toggle verbose mode. In verbose mode, all responses from the FTP server are displayed to the user. In addition, if verbose is on, when a file transfer completes, statistics regarding the efficiency of the transfer are reported. By default, verbose is on. ? [command] A synonym for help. Command arguments which have embedded spaces may be quoted with quote '\"' marks.","Process Name":"pftp","Link":"https:\/\/linux.die.net\/man\/1\/pftp"}},{"Process":{"Description":"pfunc searches the named FILES for all calls to the given subroutine. It will report back the file and line number each call is found on along with what sort of call it is function            foo()\nclass method        Class->foo()\nobject method       $obj->foo()","Process Name":"pfunc","Link":"https:\/\/linux.die.net\/man\/1\/pfunc"}},{"Process":{"Description":"The pg_config utility prints configuration parameters of the currently installed version of PostgreSQL. It is intended, for example, to be used by software packages that want to interface to PostgreSQL to facilitate finding the required header files and libraries.","Process Name":"pg_config","Link":"https:\/\/linux.die.net\/man\/1\/pg_config"}},{"Process":{"Description":"pg_controldata prints information initialized during initdb, such as the catalog version. It also shows information about write-ahead logging and checkpoint processing. This information is cluster-wide, and not specific to any one database. This utility can only be run by the user who initialized the cluster because it requires read access to the data directory. You can specify the data directory on the command line, or use the environment variable PGDATA.","Process Name":"pg_controldata","Link":"https:\/\/linux.die.net\/man\/1\/pg_controldata"}},{"Process":{"Description":"pg_ctl is a utility for starting, stopping, or restarting the PostgreSQL backend server (postgres(1)), or displaying the status of a running server. Although the server can be started manually, pg_ctl encapsulates tasks such as redirecting log output and properly detaching from the terminal and process group. It also provides convenient options for controlled shutdown. In start mode, a new server is launched. The server is started in the background, and standard input is attached to \/dev\/null. The standard output and standard error are either appended to a log file (if the -l option is used), or redirected to pg_ctl's standard output (not standard error). If no log file is chosen, the standard output of pg_ctl should be redirected to a file or piped to another process such as a log rotating program like rotatelogs; otherwise postgres will write its output to the controlling terminal (from the background) and will not leave the shell's process group. In stop mode, the server that is running in the specified data directory is shut down. Three different shutdown methods can be selected with the -m option: ''Smart'' mode waits for online backup mode to finish and all the clients to disconnect. This is the default. ''Fast'' mode does not wait for clients to disconnect and will terminate an online backup in progress. All active transactions are rolled back and clients are forcibly disconnected, then the server is shut down. ''Immediate'' mode will abort all server processes without a clean shutdown. This will lead to a recovery run on restart. restart mode effectively executes a stop followed by a start. This allows changing the postgres command-line options. reload mode simply sends the postgres process a SIGHUP signal, causing it to reread its configuration files (postgresql.conf, pg_hba.conf, etc.). This allows changing of configuration-file options that do not require a complete restart to take effect. status mode checks whether a server is running in the specified data directory. If it is, the PID and the command line options that were used to invoke it are displayed. kill mode allows you to send a signal to a specified process. This is particularly valuable for Microsoft Windows which does not have a kill command. Use --help to see a list of supported signal names. register mode allows you to register a system service on Microsoft Windows. unregister mode allows you to unregister a system service on Microsoft Windows, previously registered with the register command.","Process Name":"pg_ctl","Link":"https:\/\/linux.die.net\/man\/1\/pg_ctl"}},{"Process":{"Description":"pg_dump is a utility for backing up a PostgreSQL database. It makes consistent backups even if the database is being used concurrently. pg_dump does not block other users accessing the database (readers or writers). Dumps can be output in script or archive file formats. Script dumps are plain-text files containing the SQL commands required to reconstruct the database to the state it was in at the time it was saved. To restore from such a script, feed it to psql(1). Script files can be used to reconstruct the database even on other machines and other architectures; with some modifications even on other SQL database products. The alternative archive file formats must be used with pg_restore(1) to rebuild the database. They allow pg_restore to be selective about what is restored, or even to reorder the items prior to being restored. The archive file formats are designed to be portable across architectures. When used with one of the archive file formats and combined with pg_restore, pg_dump provides a flexible archival and transfer mechanism. pg_dump can be used to backup an entire database, then pg_restore can be used to examine the archive and\/or select which parts of the database are to be restored. The most flexible output file format is the ''custom'' format (-Fc). It allows for selection and reordering of all archived items, and is compressed by default. The tar format (-Ft) is not compressed and it is not possible to reorder data when loading, but it is otherwise quite flexible; moreover, it can be manipulated with standard Unix tools such as tar. While running pg_dump, one should examine the output for any warnings (printed on standard error), especially in light of the limitations listed below.","Process Name":"pg_dump","Link":"https:\/\/linux.die.net\/man\/1\/pg_dump"}},{"Process":{"Description":"pg_dumpall is a utility for writing out (''dumping'') all PostgreSQL databases of a cluster into one script file. The script file contains SQL commands that can be used as input to psql(1) to restore the databases. It does this by calling pg_dump(1) for each database in a cluster. pg_dumpall also dumps global objects that are common to all databases. (pg_dump does not save these objects.) This currently includes information about database users and groups, tablespaces, and properties such as access permissions that apply to databases as a whole. Since pg_dumpall reads tables from all databases you will most likely have to connect as a database superuser in order to produce a complete dump. Also you will need superuser privileges to execute the saved script in order to be allowed to add users and groups, and to create databases. The SQL script will be written to the standard output. Shell operators should be used to redirect it into a file. pg_dumpall needs to connect several times to the PostgreSQL server (once per database). If you use password authentication it will ask for a password each time. It is convenient to have a ~\/.pgpass file in such cases. See in the documentation for more information.","Process Name":"pg_dumpall","Link":"https:\/\/linux.die.net\/man\/1\/pg_dumpall"}},{"Process":{"Description":"pg_resetxlog clears the write-ahead log (WAL) and optionally resets some other control information stored in the pg_control file. This function is sometimes needed if these files have become corrupted. It should be used only as a last resort, when the server will not start due to such corruption. After running this command, it should be possible to start the server, but bear in mind that the database might contain inconsistent data due to partially-committed transactions. You should immediately dump your data, run initdb, and reload. After reload, check for inconsistencies and repair as needed. This utility can only be run by the user who installed the server, because it requires read\/write access to the data directory. For safety reasons, you must specify the data directory on the command line. pg_resetxlog does not use the environment variable PGDATA. If pg_resetxlog complains that it cannot determine valid data for pg_control, you can force it to proceed anyway by specifying the -f (force) switch. In this case plausible values will be substituted for the missing data. Most of the fields can be expected to match, but manual assistance might be needed for the next OID, next transaction ID and epoch, next multitransaction ID and offset, and WAL starting address fields. These fields can be set using the switches discussed below. If you are not able to determine correct values for all these fields, -f can still be used, but the recovered database must be treated with even more suspicion than usual: an immediate dump and reload is imperative. Do not execute any data-modifying operations in the database before you dump, as any such action is likely to make the corruption worse. The -o, -x, -e, -m, -O, and -l switches allow the next OID, next transaction ID, next transaction ID's epoch, next multitransaction ID, next multitransaction offset, and WAL starting address values to be set manually. These are only needed when pg_resetxlog is unable to determine appropriate values by reading pg_control. Safe values can be determined as follows: \u2022 A safe value for the next transaction ID (-x) can be determined by looking for the numerically largest file name in the directory pg_clog under the data directory, adding one, and then multiplying by 1048576. Note that the file names are in hexadecimal. It is usually easiest to specify the switch value in hexadecimal too. For example, if 0011 is the largest entry in pg_clog, -x 0x1200000 will work (five trailing zeroes provide the proper multiplier). \u2022 A safe value for the next multitransaction ID (-m) can be determined by looking for the numerically largest file name in the directory pg_multixact\/offsets under the data directory, adding one, and then multiplying by 65536. As above, the file names are in hexadecimal, so the easiest way to do this is to specify the switch value in hexadecimal and add four zeroes. \u2022 A safe value for the next multitransaction offset (-O) can be determined by looking for the numerically largest file name in the directory pg_multixact\/members under the data directory, adding one, and then multiplying by 65536. As above, the file names are in hexadecimal, so the easiest way to do this is to specify the switch value in hexadecimal and add four zeroes. \u2022 The WAL starting address (-l) should be larger than any WAL segment file name currently existing in the directory pg_xlog under the data directory. These names are also in hexadecimal and have three parts. The first part is the ''timeline ID'' and should usually be kept the same. Do not choose a value larger than 255 (0xFF) for the third part; instead increment the second part and reset the third part to 0. For example, if 00000001000000320000004A is the largest entry in pg_xlog, -l 0x1,0x32,0x4B will work; but if the largest entry is 000000010000003A000000FF, choose -l 0x1,0x3B,0x0 or more. Note: pg_resetxlog itself looks at the files in pg_xlog and chooses a default -l setting beyond the last existing file name. Therefore, manual adjustment of -l should only be needed if you are aware of WAL segment files that are not currently present in pg_xlog, such as entries in an offline archive; or if the contents of pg_xlog have been lost entirely. \u2022 There is no comparably easy way to determine a next OID that's beyond the largest one in the database, but fortunately it is not critical to get the next-OID setting right. \u2022 The transaction ID epoch is not actually stored anywhere in the database except in the field that is set by pg_resetxlog, so any value will work so far as the database itself is concerned. You might need to adjust this value to ensure that replication systems such as Slony-I work correctly - if so, an appropriate value should be obtainable from the state of the downstream replicated database. The -n (no operation) switch instructs pg_resetxlog to print the values reconstructed from pg_control and then exit without modifying anything. This is mainly a debugging tool, but can be useful as a sanity check before allowing pg_resetxlog to proceed for real.","Process Name":"pg_resetxlog","Link":"https:\/\/linux.die.net\/man\/1\/pg_resetxlog"}},{"Process":{"Description":"pg_restore is a utility for restoring a PostgreSQL database from an archive created by pg_dump(1) in one of the non-plain-text formats. It will issue the commands necessary to reconstruct the database to the state it was in at the time it was saved. The archive files also allow pg_restore to be selective about what is restored, or even to reorder the items prior to being restored. The archive files are designed to be portable across architectures. pg_restore can operate in two modes. If a database name is specified, pg_restore connects to that database and restores archive contents directly into the database. Otherwise, a script containing the SQL commands necessary to rebuild the database is created and written to a file or standard output. This script output is equivalent to the plain text output format of pg_dump. Some of the options controlling the output are therefore analogous to pg_dump options. Obviously, pg_restore cannot restore information that is not present in the archive file. For instance, if the archive was made using the ''dump data as INSERT commands'' option, pg_restore will not be able to load the data using COPY statements.","Process Name":"pg_restore","Link":"https:\/\/linux.die.net\/man\/1\/pg_restore"}},{"Process":{"Description":"Gawk is the GNU Project's implementation of the AWK programming language. It conforms to the definition of the language in the POSIX 1003.1 Standard. This version in turn is based on the description in The AWK Programming Language, by Aho, Kernighan, and Weinberger, with the additional features found in the System V Release 4 version of UNIX awk. Gawk also provides more recent Bell Laboratories awk extensions, and a number of GNU -specific extensions. Pgawk is the profiling version of gawk. It is identical in every way to gawk, except that programs run more slowly, and it automatically produces an execution profile in the file awkprof.out when done. See the --profile option, below. The command line consists of options to gawk itself, the AWK program text (if not supplied via the -f or --file options), and values to be made available in the ARGC and ARGV pre-defined AWK variables.","Process Name":"pgawk","Link":"https:\/\/linux.die.net\/man\/1\/pgawk"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmabel reads as input a PGM image, which it assumes to be an image of a rotational symmetric transparent object. The image must have a vertical symmetry axis. pgmabel produces as output an image of a cross-section of the image. pgmabel does the calculation by performing the Abel Integration for Deconvolution of an axial-symmetrical image by solving the system of linear equations. After integration, pgmabel weights all gray-values of one side by the surface area of the calculated ring in square pixels divided by 4*factor multiplied by the size of one pixel (pixsize). With the -verbose option, pgmabel prints the weighting factors. Where the caculation generates a negative result, the output is black. The computation is unstable against periodic structures with size 2 in the vertical direction.","Process Name":"pgmabel","Link":"https:\/\/linux.die.net\/man\/1\/pgmabel"}},{"Process":{"Description":"This is a make tool using Makefile::Parser::GmakeDB, Makefile::AST, and Makefile::AST::Evaluator. This script is primary for testing the whole toolchain via running GNU make's official test suite. As of this writing, pgmake-db has already passed 51% of GNU make 3.81's test suite.","Process Name":"pgmake-db","Link":"https:\/\/linux.die.net\/man\/1\/pgmake-db"}},{"Process":{"Description":"Pgmap utility gets informations from \/proc\/kpagecount, \/proc\/kpageflags and \/proc\/[pid]\/pagemap. Using libpagemap library for that.","Process Name":"pgmap","Link":"https:\/\/linux.die.net\/man\/1\/pgmap"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmbentley reads a PGM image as input and performs the Bentley Effect, and writes a PGM image as output. The Bentley Effect is described in 'Beyond Photography' by Holzmann, chapter 4, photo 4. It's a vertical smearing based on brightness.","Process Name":"pgmbentley","Link":"https:\/\/linux.die.net\/man\/1\/pgmbentley"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmcrater creates a PGM image which mimics cratered terrain. The PGM image is created by simulating the impact of a given number of craters with random position and size, then rendering the resulting terrain elevations based on a light source shining from one side of the screen. The size distribution of the craters is based on a power law which results in many more small craters than large ones. The number of craters of a given size varies as the reciprocal of the area as described on pages 31 and 32 of Peitgen and Saupe[1]; cratered bodies in the Solar System are observed to obey this relationship. The formula used to obtain crater radii governed by this law from a uniformly distributed pseudorandom sequence was developed by Rudy Rucker. High resolution images with large numbers of craters often benefit from being piped through pnmsmooth. The averaging performed by this process eliminates some of the jagged pixels and lends a mellow ''telescopic image'' feel to the overall picture. pgmcrater simulates only small craters, which are hemispherical in shape (regardless of the incidence angle of the impacting body, as long as the velocity is sufficiently high). Large craters, such as Copernicus and Tycho on the Moon, have a ''walled plain'' shape with a cross-section more like:       \/\\                            \/\\\n_____\/  \\____________\/\\____________\/  \\_____ Larger craters should really use this profile, including the central peak, and totally obliterate the pre-existing terrain. The randomness in the image is limited before Netpbm 10.37 (December 2006) -- if you run the program twice in the same second, you may get identical output.","Process Name":"pgmcrater","Link":"https:\/\/linux.die.net\/man\/1\/pgmcrater"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmdeshadow removes gray shadows from an image. This is useful for an image containing text, such as a scanned book pages, where a shadow typically appears near the book crease or near one side of the image. pgmdeshadow recognizes a gray shadow as an area of smoothly changing color, starting from the outer edges of the image. The program uses a simple image reconstruction algorithm to determine the local shadow gray level, then divides each pixel's gray level by the local shadow gray level. The algorithm is the 'fast hybrid grayscale reruction' algorithm from Luc Vincent, \"Morphological Grayscale Reruction in Image Analysis: Applications and Efficient Algorithms.","Process Name":"pgmdeshadow","Link":"https:\/\/linux.die.net\/man\/1\/pgmdeshadow"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmedge was replaced in Netpbm 10.14 (March 2002) by pamedge(1). pamedge is backward compatible with pgmedge, but works on color images too.","Process Name":"pgmedge","Link":"https:\/\/linux.die.net\/man\/1\/pgmedge"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmenhance reads a PGM image as input, enhances the edges, and writes a PGM image as output. The edge enhancing technique is taken from Philip R. Thompson's 'xim' program, which in turn took it from section 6 of 'Digital Halftones by Dot Diffusion', D. E. Knuth, ACM Transaction on Graphics Vol. 6, No. 4, October 1987, which in turn got it from two 1976 papers by J. F. Jarvis et. al.","Process Name":"pgmenhance","Link":"https:\/\/linux.die.net\/man\/1\/pgmenhance"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmhist reads a PGM image as input and prints a histogram of the gray values.","Process Name":"pgmhist","Link":"https:\/\/linux.die.net\/man\/1\/pgmhist"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmkernel generates a convolution kernel that you can use with pnmconvol. The kernel is one where the weight of each location is inversely proportional to its distance from the center of the kernel. pgmkernel generates a PGM image of size width by height (or width by width if you don't specify height. pgmkernel computes the convolution function K as follows. K(i,j) = 1 \/ ( 1 + w * sqrt(i^2 + j^2)) where w is a coefficient specified via the -weight option. i and j are measured in pixels. K is zero everywhere beyond the specified kernel width and height. pgmkernel generates the output PGM file in the Plain (text) variation of PGM.","Process Name":"pgmkernel","Link":"https:\/\/linux.die.net\/man\/1\/pgmkernel"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmmake produces a PGM image of the specified gray level, width, height, and maxval. Specify the gray level (graylevel) as a decimal floating point number in the range [0, 1]. E.g. 1 is white, 0 is black, and 0.5 is half luminosity gray.","Process Name":"pgmmake","Link":"https:\/\/linux.die.net\/man\/1\/pgmmake"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmmedian applies a median filter to a PGM image, using either the histogram sort or select kth value method to determine the median. See the -type and -cutoff options for information on how pgmmedian chooses between the two methods.","Process Name":"pgmmedian","Link":"https:\/\/linux.die.net\/man\/1\/pgmmedian"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmminkowski computes the 3 Minkowski integrals of a PGM image. The Minkowski integrals mathematically characterize the shapes in the image and hence are the basis of \"morphological image analysis.\" Hadwiger's theorem has it that these integrals are the only motion-invariant, additive and conditionally continuous functions of a two-dimensional image, which means that they are preserved under certain kinds of deformations of the image. On top of that, they are very easy and quickly calculated. This makes them of interest for certain kinds of pattern recognition. Basically, the Minkowski integrals are the area, total perimeter length, and the Euler characteristic of the image, where these metrics apply to the foreground image, not the rectangular PGM image itself. The foreground image consists of all the pixels in the image that are white. For a grayscale image, there is some threshold of intensity applied to categorize pixels into black and white, and the Minkowski integrals are calculated as a function of this threshold value. The total surface area refers to the number of white pixels in the PGM and the perimeter is the sum of perimeters of each closed white region in the PGM. For a grayscale image, these numbers are a function of the threshold of what you want to call black or white. pgmminkowski reports these numbers as a function of the threshold for all possible threshold values. Since the total surface area can increase only as a function of the threshold, it is a reparameterization of the threshold. It turns out that if you consider the other two functions, the boundary length and the Euler characteristic, as a function of the first one, the surface, you get two functions that are a fingerprint of the picture. This fingerprint is e.g. sufficient to recognize the difference between pictures of different crystal lattices under a scanning tunnelling electron microscope. For more information about Minkowski integrals, see e.g. \u2022 K. Michielsen and H. De Raedt, \"Integral-Geometry Morphological Image Analysis\", Phys. Rep. 347, 461-538 (2001). \u2022 J.S. Kole, K. Michielsen, and H. De Raedt, \"Morphological Image Analysis of Quantum Motion in Billiards\", Phys. Rev. E 63, 016201-1 - 016201-7 (2001) The output is suitable for direct use as a datafile in gnuplot. In addition to the three Minkowski integrals, pgmminkowski also lists the horizontal and vertical edge counts.","Process Name":"pgmminkowski","Link":"https:\/\/linux.die.net\/man\/1\/pgmminkowski"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmmorphconv performs morphological convolutions on a PGM image: dilation and erosion. pgmmorphconv performs a \"topological\" convolution. For each pixel of the input, pgmmorphconv generates an output pixel in the same position. To determine the intensity of the output pixel, pgmmorphconv lays the template image over the input image such that the middle pixel of the template is over the input pixel in question. pgmmorphconv looks at the input pixels underneath each white pixel in the template. For a dilation, the maximum intensity of all those pixels is the intensity of the output pixel. For an erosion, it is the minimum. Thus, the dilation effect is that bright areas of the input get bigger and dark areas smaller. The erosion effect is the opposite. The simplest template image would be one with a white pixel in the middle and the rest black. This would produce an output image identical to the input. Another simple template image is a fully white square. This causes bright or dark areas to expand in all directions. A template image that is white on the left side and black on the right would smear the image to the right. The template file named by templatefile contains the template image as a PBM image. It must have an odd number of rows and an odd number of columns, so there is a definite middle pixel. It must contain at least one white pixel. This is similar to the continuous convolution done by pnmconvol, except that with pnmconvol the output intensity is a weighted average of nearby input pixels instead of a minimum or maximum. This convolution changes the three Minkowski integrals in a predefined way, and can be used to filter an image to enhance certain features, to ease their automatic recognition. The options -erode and -dilate obviously produce an erosion or dilation, respectively. The -open option causes pgmmorphconv to perform first an erode and then a dilate operation. The -close option causes a dilate first and then an erode. If you specify none of these options, it is the same as -dilate.","Process Name":"pgmmorphconv","Link":"https:\/\/linux.die.net\/man\/1\/pgmmorphconv"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmnoise creates a PGM image that is made up of pixels of random brightness. The maxval is 255. You specify the dimensions of the image with the width and height arguments. The randomness in the image is limited before Netpbm 10.37 (December 2006) -- if you run the program twice in the same second, you may get identical output.","Process Name":"pgmnoise","Link":"https:\/\/linux.die.net\/man\/1\/pgmnoise"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmnorm was replaced in Netpbm 9.25 (March 2002) by pnmnorm(1). pnmnorm is backward compatible with pgmnorm, but it also handles PPM images.","Process Name":"pgmnorm","Link":"https:\/\/linux.die.net\/man\/1\/pgmnorm"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmoil was replaced in Netpbm 9.16 (July 2001) by pamoil(1). pamoil is backward compatible with pgmoil, but works on color images too.","Process Name":"pgmoil","Link":"https:\/\/linux.die.net\/man\/1\/pgmoil"}},{"Process":{"Description":"This program is part of Netpbm(1). Generates a graymap of the specified size containing a black-to-white ramp. These ramps are useful for multiplying with other images, using pamarith. The ramp is linear in brightness, not intensity. I.e. the gamma-corrected sample values in the PGM rise linearly with distance from the corner of the image. If you want a ramp that is linear in light intensity, use pnmgamma with pgmramp. To generate a simple ramp of all the values from 0 to maxval, and not necessarily a graphic image, use pamseq(1). ppmrainbow does something similar to what pgmramp does, but for color. The image fades between two colors of your choice.","Process Name":"pgmramp","Link":"https:\/\/linux.die.net\/man\/1\/pgmramp"}},{"Process":{"Description":"This program is part of Netpbm(1). Starting with Netpbm 10.3, pgmslice is obsolete. Use pamslice(1)instead.Itisbackward compatible.","Process Name":"pgmslice","Link":"https:\/\/linux.die.net\/man\/1\/pgmslice"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmtexture reads a PGM image as input and calculates textural features based on spatial dependence matrices at 0, 45, 90, and 135 degrees for a distance d (default = 1). Textural features include: \u2022 Angular Second Moment \u2022 Contrast \u2022 Correlation \u2022 Variance \u2022 Inverse Difference Moment \u2022 Sum Average \u2022 Sum Variance \u2022 Sum Entropy \u2022 Entropy \u2022 Difference Variance \u2022 Difference Entropy \u2022 Information Measures of Correlation \u2022 Maximal Correlation Coefficient Algorithm taken from: Haralick, R.M., K. Shanmugam, and I. Dinstein. 1973. Textural features for image classification. IEEE Transactions on Systems, Man, and Cybertinetics, SMC-3(6):610-621.","Process Name":"pgmtexture","Link":"https:\/\/linux.die.net\/man\/1\/pgmtexture"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmtofs reads a PGM image as input and produces Usenix FaceSaver(tm) format as output. FaceSaver is a registered trademark of Metron Computerware Ltd. of Oakland, CA.","Process Name":"pgmtofs","Link":"https:\/\/linux.die.net\/man\/1\/pgmtofs"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmtolispm reads a PGM image as input and produces a Lisp Machine bitmap as output. This is the file format read by the tv:read-bit-array-file function on TI Explorer and Symbolics lisp machines. Given a PGM (instead of a PBM), pgmtolispm outputs a multi-plane image. This is probably not useful unless you have a color lisp machine. Multi-plane bitmaps on lisp machines are color; but the lispm image file format does not include a color map, so we must treat it as a graymap instead. This is unfortunate.","Process Name":"pgmtolispm","Link":"https:\/\/linux.die.net\/man\/1\/pgmtolispm"}},{"Process":{"Description":"This program is part of Netpbm(1). This program is obsolete since Netpbm 10.23 (July 2004). Use pamditherbw(1)todowhatthisprogram used to do. pgmtopbm never was the simple converter it appeared to be. It was a dithering program. Unfortunately, it didn't do the dithering properly because it treated the PGM input samples as if they were directly proportional to light intensity, but they are actually gamma-adjusted. pamditherbw is backward compatible with pgmtopbm except that it does the correct gamma adjustments. produces PAM output instead of PBM. (Modern Netpbm programs that accept PBM input also accept PAM input, but if you need actual PBM, you can use pamtopbm with pamditherbw). So use the manual for pamditherbw for pgmtopbm, except ignore anything that says it was added after Netpbm Release 10.23 and ignore any options that are not shown in the synopsis above. Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"pgmtopbm","Link":"https:\/\/linux.die.net\/man\/1\/pgmtopbm"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmtopgm simply copies a PGM image from Standard Input to Standard Output. This may seem an unnecessary duplication of cat, but remember that a PGM program can read a PBM image as if it were PGM. So pgmtopgm can read either a PBM or PGM image and produce a PGM image as output. Even that is of limited usefulness because of the fact that almost any program to which you would feed the resulting PGM image could also just take the original image directly. However, sometimes you really need a true PGM image. When you know you have a PBM image and want a PGM image, pbmtopgm is a more general way to do that conversion.","Process Name":"pgmtopgm","Link":"https:\/\/linux.die.net\/man\/1\/pgmtopgm"}},{"Process":{"Description":"This program is part of Netpbm(1). pgmtoppm reads a PGM as input and produces a PPM file as output with a specific color assigned to each gray value in the input. If you specify one color argument, black in the pgm file stays black and white in the pgm file turns into the specified color in the ppm file. Gray values in between are linearly mapped to differing intensities of the specified color. If you specify two color arguments (separated by a hyphen), then black gets mapped to the first color and white gets mapped to the second and gray values in between get mapped linearly (across a three dimensional space) to colors in between. Specify the color (color) as described for the argument of the ppm_parsecolor() library routine . Also, you can specify an entire colormap with the -map option. The mapfile is just a ppm file; it can be any shape, all that matters is the colors in it and their order. In this case, black gets mapped into the first color in the map file, and white gets mapped to the last and gray values in between are mapped linearly onto the sequence of colors in between. The maxval of the output image is the maxval of the map image. A more direct way to specify a particular color to replace each particular gray level is to use pamlookup. You make an index file that explicitly associates a color with each possible gray level.","Process Name":"pgmtoppm","Link":"https:\/\/linux.die.net\/man\/1\/pgmtoppm"}},{"Process":{"Description":"pgmtoy4m repacks the PGM output from mpeg2dec into YUV4MPEG2 4:2:0p. No actual changes to the data are made. The data is unpacked from the quasi-PGM format and placed in YUV4MPEG2 format with the specified sample aspect, frame rate and field order. Output must be either to a pipe or a file, leaving stdout as a terminal will elicit an error and the program will exit.","Process Name":"pgmtoy4m","Link":"https:\/\/linux.die.net\/man\/1\/pgmtoy4m"}},{"Process":{"Description":"The pgpverify program reads (on standard input) a Usenet control message that has been cryptographically signed using the signcontrol program (or some other program that produces a compatible format). pgpverify then uses a PGP implementation to determine who signed the control message. If the control message has a valid signature, pgpverify prints (to stdout) the user ID of the key that signed the message. Otherwise, it exits with a non-zero exit status. If pgpverify is installed as part of INN , it uses INN 's configuration to determine what signature verification program to use, how to log errors, what temporary directory to use, and what keyring to use. Otherwise, all of those parameters can be set by editing the beginning of this script. By default, when running as part of INN , pgpverify expects the PGP key ring to be found in pathetc\/pgp (as either pubring.pgp or pubring.gpg depending on whether PGP or GnuPG is used to verify signatures). If that directory doesn't exist, it will fall back on using the default key ring, which is in a .pgp or .gnupg subdirectory of the running user's home directory.","Process Name":"pgpverify","Link":"https:\/\/linux.die.net\/man\/1\/pgpverify"}},{"Process":{"Description":"pgrep looks through the currently running processes and lists the process IDs which matches the selection criteria to stdout. All the criteria have to match. For example, pgrep -u root sshd will only list the processes called sshd AND owned by root. On the other hand, pgrep -u root,daemon will list the processes owned by root OR daemon. pkill will send the specified signal (by default SIGTERM) to each process instead of listing them on stdout.","Process Name":"pgrep","Link":"https:\/\/linux.die.net\/man\/1\/pgrep"}},{"Process":{"Description":"pgtclsh is a Tcl shell interface extended with PostgreSQL database access functions. (Essentially, it is tclsh with libpgtcl loaded.) Like with the regular Tcl shell, the first command line argument is a script file, any remaining arguments are passed to the script. If no script file is named, the shell is interactive. A Tcl shell with Tk and PostgreSQL functions is available as pgtksh(1).","Process Name":"pgtclsh","Link":"https:\/\/linux.die.net\/man\/1\/pgtclsh"}},{"Process":{"Description":"pho displays images, in the formats handled by the gdk-pixbuf package, to an X display. It is intended as a lightweight and fast viewer, optimized for rapidly going through large numbers of uploaded images. pho is entirely keyboard driven, and allows for interactive rotation and taking of notes on each image. It resizes after rotations and will always attempt to show the image as large as possible. The final rotation reached for each image will be remembered and printed when the program exits (for use with a batch image rotation script). pho can also remember up to ten lists of images (numbered 0-9) which can correspond to anything the user wishes. The image lists will be printed to standard output when pho exits. Use this to keep notes on which images you want to save to the web, which images contain images of your dog, etc.","Process Name":"pho","Link":"https:\/\/linux.die.net\/man\/1\/pho"}},{"Process":{"Description":"phoa2d converts $HOME\/.gcin\/pho.tab.src to $HOME\/.gcin\/pho.tab, which is used by Bopomofo and Tsin input methods. phod2a converts $HOME\/.gcin\/pho.tab to $HOME\/.gcin\/pho.tab.src, which may be edited by users.","Process Name":"phoa2d","Link":"https:\/\/linux.die.net\/man\/1\/phoa2d"}},{"Process":{"Description":"Takes one argument, a \"string\". Converts each character of \"string\" to its equivalent \"word\" in the Phonetic Alphabet. Prints these \"words\", three \"words\" per line, one space between \"words\" In other words, read the output aloud to your military friends and they'll know exactly what you're spelling.","Process Name":"phonetize","Link":"https:\/\/linux.die.net\/man\/1\/phonetize"}},{"Process":{"Description":"The Phoronix Test Suite is the most comprehensive testing and benchmarking platform available for Linux, Solaris, Mac OS X, and BSD operating systems. The Phoronix Test Suite allows for carrying out tests in a fully automated manner from test installation to execution and reporting. All tests are meant to be easily reproducible, easy-to-use, and support fully automated execution. The Phoronix Test Suite is open-source under the GNU GPLv3 license and is developed by Phoronix Media in cooperation with partners. Version 1.0 of the Phoronix Test Suite was publicly released in 2008.","Process Name":"phoronix-test-suite","Link":"https:\/\/linux.die.net\/man\/1\/phoronix-test-suite"}},{"Process":{"Description":"The phosphor program draws text on the screen in a very large pixelated font that looks like an old low resolution dumb tty. The pixels flare and fade out as if the phosphor was very long-sustain. It is also a fully functional vt100 terminal emulator.","Process Name":"phosphor","Link":"https:\/\/linux.die.net\/man\/1\/phosphor"}},{"Process":{"Description":"PhotoRec is file data recovery software designed to recover lost files including video, documents and archives from Hard Disks and CDRom and lost pictures (Photo Recovery) from digital camera memory. PhotoRec ignores the filesystem and goes after the underlying data, so it'll work even if your media's filesystem is severely damaged or formatted. PhotoRec is safe to use, it will never attempt to write to the drive or memory support you are about to recover lost data from.","Process Name":"photorec","Link":"https:\/\/linux.die.net\/man\/1\/photorec"}},{"Process":{"Description":"PHP is a widely-used general-purpose scripting language that is especially suited for Web development and can be embedded into HTML. This is the command line interface that enables you to do the following: You can parse and execute files by using parameter -f followed by the name of the file to be executed. Using parameter -r you can directly execute PHP code simply as you would do inside a .php file when using the eval() function. It is also possible to process the standard input line by line using either the parameter -R or -F. In this mode each separate input line causes the code specified by -R or the file specified by -F to be executed. You can access the input line by $argn. While processing the input lines $argi contains the number of the actual line being processed. Further more the parameters -B and -E can be used to execute code (see -r) before and after all input lines have been processed respectively. Notice that the input is read from STDIN and therefore reading from STDIN explicitly changes the next input line or skips input lines. If none of -r -f -B -R -F or -E is present but a single parameter is given then this parameter is taken as the filename to parse and execute (same as with -f). If no parameter is present then the standard input is read and executed.","Process Name":"php","Link":"https:\/\/linux.die.net\/man\/1\/php"}},{"Process":{"Description":"php-config is a simple shell script for obtaining information about installed PHP configuration.","Process Name":"php-config","Link":"https:\/\/linux.die.net\/man\/1\/php-config"}},{"Process":{"Description":"See: http:\/\/translate.sourceforge.net\/wiki\/toolkit\/php2po for examples and usage instructions","Process Name":"php2po","Link":"https:\/\/linux.die.net\/man\/1\/php2po"}},{"Process":{"Description":"phpize is a shell script to prepare PHP extension for compiling.","Process Name":"phpize","Link":"https:\/\/linux.die.net\/man\/1\/phpize"}},{"Process":{"Description":"pi-getram is used to fetch the current RAM image from your Palm handheld for use in debugging.","Process Name":"pi-getram","Link":"https:\/\/linux.die.net\/man\/1\/pi-getram"}},{"Process":{"Description":"pi-getrom is used to fetch the ROM from your Palm handheld for use in debugging Palm applications through the use of POSE, the Palm OS Emulator application. Note, because pi-getrom uses the low-level RPC protocol to fetch the ROM image, and the new OS5 devices do not use this protocol, you currently cannot fetch an OS5 ROM image using this utility. This will be updated in a future release to handle fetching OS5 ROM images, using the debugger protocol.","Process Name":"pi-getrom","Link":"https:\/\/linux.die.net\/man\/1\/pi-getrom"}},{"Process":{"Description":"This program is part of Netpbm(1). pi1toppm reads an Atari Degas .pi1 file as input and produces a PPM image as output.","Process Name":"pi1toppm","Link":"https:\/\/linux.die.net\/man\/1\/pi1toppm"}},{"Process":{"Description":"This program is part of Netpbm(1). pi3topbm reads an Atari Degas .pi3 file as input and produces a PBM image as output.","Process Name":"pi3topbm","Link":"https:\/\/linux.die.net\/man\/1\/pi3topbm"}},{"Process":{"Description":"pia is a small X11 tool which plays movie files.","Process Name":"pia","Link":"https:\/\/linux.die.net\/man\/1\/pia"}},{"Process":{"Description":"pianobar is a lightweight console music player for the personalized online radio pandora.com.","Process Name":"pianobar","Link":"https:\/\/linux.die.net\/man\/1\/pianobar"}},{"Process":{"Description":"This manual page describes the GNU version of pic, which is part of the groff document formatting system. pic compiles descriptions of pictures embedded within troff or TeX input files into commands that are understood by TeX or troff. Each picture starts with a line beginning with .PS and ends with a line beginning with .PE. Anything outside of .PS and .PE is passed through without change. It is the user's responsibility to provide appropriate definitions of the PS and PE macros. When the macro package being used does not supply such definitions (for example, old versions of -ms), appropriate definitions can be obtained with -mpic: these will center each picture.","Process Name":"pic","Link":"https:\/\/linux.die.net\/man\/1\/pic"}},{"Process":{"Description":"Reads a PIC program as input; produces an image file (by default in Portable Network Graphics format) suitable for the Web as output. Also translates eqn(1) constructs, so it can be used for generating images of mathematical formulae. PIC is a rather expressive graphics minilanguage suitable for producing box-and-arrow diagrams of the kind frequently used in technical papers and textbooks. The language is sufficiently flexible to be quite useful for state charts, Petri-net diagrams, flow charts, simple circuit schematics, jumper layouts, and other kinds of illustration involving repetitive uses of simple geometric forms and splines. Because PIC descriptions are procedural and object-based, they are both compact and easy to modify. The PIC language is fully documented in \"Making Pictures With GNU PIC\", a document which is part of the groff(1) distribution. Your input PIC code should not be wrapped with the .PS and .PE macros that normally guard it within groff(1) macros. The output image will be a black-on-white graphic clipped to the smallest possible bounding box that contains all the black pixels. By specifying command-line options to be passed to convert(1) you can give it a border, set the background transparent, set the image's pixel density, or perform other useful transformations. This program uses pic(1), eqn(1), groff(1), gs(1), and the ImageMagick convert(1) program. These programs must be installed on your system and accessible on your $PATH for pic2graph to work.","Process Name":"pic2graph","Link":"https:\/\/linux.die.net\/man\/1\/pic2graph"}},{"Process":{"Description":"Pic2tpic reads the pic files given on the command line (or stdin if none are given) and writes their tpic equivalent to stdout.","Process Name":"pic2tpic","Link":"https:\/\/linux.die.net\/man\/1\/pic2tpic"}},{"Process":{"Description":"Pico is a simple, display-oriented text editor based on the Alpine message system composer. As with Alpine, commands are displayed at the bottom of the screen, and context-sensitive help is provided. As characters are typed they are immediately inserted into the text. Editing commands are entered using control-key combinations. As a work-around for communications programs that swallow certain control characters, you can emulate a control key by pressing ESCAPE twice, followed by the desired control character, e.g. \"ESC ESC c\" would be equivalent to entering a ctrl-c. The editor has five basic features: paragraph justification, searching, block cut\/paste, a spelling checker, and a file browser. Paragraph justification (or filling) takes place in the paragraph that contains the cursor, or, if the cursor is between lines, in the paragraph immediately below. Paragraphs are delimited by blank lines, or by lines beginning with a space or tab. Unjustification can be done immediately after justification using the control-U key combination. String searches are not sensitive to case. A search begins at the current cursor position and wraps around the end of the text. The most recent search string is offered as the default in subsequent searches. Blocks of text can be moved, copied or deleted with creative use of the command for mark (ctrl-^), delete (ctrl-k) and undelete (ctrl-u). The delete command will remove text between the \"mark\" and the current cursor position, and place it in the \"cut\" buffer. The undelete command effects a \"paste\" at the current cursor position. The spell checker examines all words in the text. It then offers, in turn, each misspelled word for correction while highlighting it in the text. Spell checking can be cancelled at any time. Alternatively, pico will substitute for the default spell checking routine a routine defined by the SPELL environment variable. The replacement routine should read standard input and write standard output. The file browser is offered as an option in the \"Read File\" and \"Write Out\" command prompts. It is intended to help in searching for specific files and navigating directory hierarchies. Filenames with sizes and names of directories in the current working directory are presented for selection. The current working directory is displayed on the top line of the display while the list of available commands takes up the bottom two. Several basic file manipulation functions are supported: file renaming, copying, and deletion. More specific help is available in pico's online help.","Process Name":"pico","Link":"https:\/\/linux.die.net\/man\/1\/pico"}},{"Process":{"Description":"piconv is perl version of iconv, a character encoding converter widely available for various Unixen today. This script was primarily a technology demonstrator for Perl 5.8.0, but you can use piconv in the place of iconv for virtually any case. piconv converts the character encoding of either STDIN or files specified in the argument and prints out to STDOUT . Here is the list of options. Each option can be in short format (-f) or long (--from). -f,--from from_encoding Specifies the encoding you are converting from. Unlike iconv, this option can be omitted. In such cases, the current locale is used. -t,--to to_encoding Specifies the encoding you are converting to. Unlike iconv, this option can be omitted. In such cases, the current locale is used. Therefore, when both -f and -t are omitted, piconv just acts like cat. -s,--string string uses string instead of file for the source of text. -l,--list Lists all available encodings, one per line, in case-insensitive order. Note that only the canonical names are listed; many aliases exist. For example, the names are case-insensitive, and many standard and common aliases work, such as \"latin1\" for \" ISO-8859-1 \", or \"ibm850\" instead of \"cp850\", or \"winlatin1\" for \"cp1252\". See Encode::Supported for a full discussion. -C,--check N Check the validity of the stream if N = 1. When N = -1, something interesting happens when it encounters an invalid character. -c Same as \"-C 1\". -p,--perlqq --htmlcref --xmlcref Applies PERLQQ , HTMLCREF , XMLCREF , respectively. Try piconv -f utf8 -t ascii --perlqq To see what it does. -h,--help Show usage. -D,--debug Invokes debugging mode. Primarily for Encode hackers. -S,--scheme scheme Selects which scheme is to be used for conversion. Available schemes are as follows: from_to Uses Encode::from_to for conversion. This is the default. decode_encode Input strings are decode()d then encode()d. A straight two-step implementation. perlio The new perlIO layer is used. NI-S ' favorite. You should use this option if you are using UTF-16 and others which linefeed is not $\/. Like the -D option, this is also for Encode hackers.","Process Name":"piconv","Link":"https:\/\/linux.die.net\/man\/1\/piconv"}},{"Process":{"Description":"See <URL: http:\/\/www.iki.fi\/hyvatti\/pic\/picprog.html>.","Process Name":"picprog","Link":"https:\/\/linux.die.net\/man\/1\/picprog"}},{"Process":{"Description":"pidgin is a graphical modular messaging client based on libpurple which is capable of connecting to AIM, MSN, Yahoo!, XMPP, ICQ, IRC, SILC, Novell GroupWise, Lotus Sametime, Zephyr, Gadu-Gadu, and QQ all at once. It has many common features found in other clients, as well as many unique features. Pidgin is not endorsed by or affiliated with America Online, ICQ, Microsoft, or Yahoo. Pidgin can be extended by plugins written in multiple programming languages and controlled through DBus or purple-remote.","Process Name":"pidgin","Link":"https:\/\/linux.die.net\/man\/1\/pidgin"}},{"Process":{"Description":"pidl is an IDL compiler written in Perl that aims to be somewhat compatible with the midl compiler. IDL is short for \"Interface Definition Language\". pidl can generate stubs for DCE\/RPC server code, DCE\/RPC client code and Wireshark dissectors for DCE\/RPC traffic. IDL compilers like pidl take a description of an interface as their input and use it to generate C (though support for other languages may be added later) code that can use these interfaces, pretty print data sent using these interfaces, or even generate Wireshark dissectors that can parse data sent over the wire by these interfaces. pidl takes IDL files in the same format as is used by midl, converts it to a .pidl file (which contains pidl's internal representation of the interface) and can then generate whatever output you need. .pidl files should be used for debugging purposes only. Write your interface definitions in .idl format. The goal of pidl is to implement a IDL compiler that can be used while developing the RPC subsystem in Samba (for both marshalling\/unmarshalling and debugging purposes).","Process Name":"pidl","Link":"https:\/\/linux.die.net\/man\/1\/pidl"}},{"Process":{"Description":"The pidstat command is used for monitoring individual tasks currently being managed by the Linux kernel. It writes to standard output activities for every task selected with option -p or for every task managed by the Linux kernel if option -p ALL has been used. Not selecting any tasks is equivalent to specifying -p ALL but only active tasks (tasks with non-zero statistics values) will appear in the report. The pidstat command can also be used for monitoring the child processes of selected tasks. Read about option -T below. The interval parameter specifies the amount of time in seconds between each report. A value of 0 (or no parameters at all) indicates that tasks statistics are to be reported for the time since system startup (boot). The count parameter can be specified in conjunction with the interval parameter if this one is not set to zero. The value of count determines the number of reports generated at interval seconds apart. If the interval parameter is specified without the count parameter, the pidstat command generates reports continuously. You can select information about specific task activities using flags. Not specifying any flags selects only CPU activity.","Process Name":"pidstat","Link":"https:\/\/linux.die.net\/man\/1\/pidstat"}},{"Process":{"Description":"Pidstatd will start a UDP daemon. The daemon responds to requests that contain a PID with a packet indicating the PID and if the PID currently exists. The Perl IPC::Locker package optionally uses this daemon to break locks for PIDs that no longer exists.","Process Name":"pidstatd","Link":"https:\/\/linux.die.net\/man\/1\/pidstatd"}},{"Process":{"Description":"Chdir to the specified directory, if specified and possible, then run the arguments as a command in the foreground. When the foreground process exits, return its exit status. This is basically the same as running the command directly. In the background, watch the specified pid on the specified host. If pidstatd is running on the specified host, and the specified pid goes away, kill the foreground command. Alternatively pass the PID of any process with --foreground. When the foreground process exits, the background job exits; if the specified watched PID exits, the foreground pid is killed. Common usage is to kill remote rsh children when a parent is kill -9ed. An example Perl application would invoke: system(\"rsh \\$remote_host pidwatch\"\n       .\" --cd \\$ENV{PWD} --host \\$ENV{HOST} --pid \\$\\$\"\n       .\"\\$remote_command...\"); Another usage is as a \"barrier\" to start the new step in a script when another process completes. Just use a sleep with a appropriate timeout value: pidwatch --host HOST --pid PID sleep 9999999\necho PID has completed, do whatever is next","Process Name":"pidwatch","Link":"https:\/\/linux.die.net\/man\/1\/pidwatch"}},{"Process":{"Description":"This draws a bunch of moving circles which switch from visibility to invisibility when they intersect.","Process Name":"piecewise","Link":"https:\/\/linux.die.net\/man\/1\/piecewise"}},{"Process":{"Description":"Pigz compresses using threads to make use of multiple processors and cores. The input is broken up into 128 KB chunks with each compressed in parallel. The individual check value for each chunk is also calculated in parallel. The compressed data is written in order to the output, and a combined check value is calculated from the individual check values. The compressed data format generated is in the gzip, zlib, or single-entry zip format using the deflate compression method. The compression produces partial raw deflate streams which are concatenated by a single write thread and wrapped with the appropriate header and trailer, where the trailer contains the combined check value. Each partial raw deflate stream is terminated by an empty stored block (using the Z_SYNC_FLUSH option of zlib), in order to end that partial bit stream at a byte boundary. That allows the partial streams to be concatenated simply as sequences of bytes. This adds a very small four to five byte overhead to the output for each input chunk. The default input block size is 128K, but can be changed with the -b option. The number of compress threads is set by default to the number of online processors, which can be changed using the -p option. Specifying -p 1 avoids the use of threads entirely. The input blocks, while compressed independently, have the last 32K of the previous block loaded as a preset dictionary to preserve the compression effectiveness of deflating in a single thread. This can be turned off using the -i or --independent option, so that the blocks can be decompressed independently for partial error recovery or for random access. Decompression can't be parallelized, at least not without specially prepared deflate streams for that purpose. As a result, pigz uses a single thread (the main thread) for decompression, but will create three other threads for reading, writing, and check calculation, which can speed up decompression under some circumstances. Parallel decompression can be turned off by specifying one process ( -dp 1 or -tp 1 ). Compressed files can be restored to their original form using pigz -d or unpigz.","Process Name":"pigz","Link":"https:\/\/linux.die.net\/man\/1\/pigz"}},{"Process":{"Description":"","Process Name":"piklab","Link":"https:\/\/linux.die.net\/man\/1\/piklab"}},{"Process":{"Description":"This manual page documents briefly the piklab-hex command. Piklab-hex is a command line tool to check files, if they are valid Hex-files which comply with the INHEX-Standard defined by Intel corporation.","Process Name":"piklab-hex","Link":"https:\/\/linux.die.net\/man\/1\/piklab-hex"}},{"Process":{"Description":"This manual page documents briefly the piklab-prog command. Piklab-prog is a command line tool, which can be used to program microcontrollers with program and data, stored in a HEX-file to a connected programmer. It supports the most common serial, parallel and usb programmers, like ICD2, Pickit2, PicStart+) and debuggers (ICD2).","Process Name":"piklab-prog","Link":"https:\/\/linux.die.net\/man\/1\/piklab-prog"}},{"Process":{"Description":"Pilot is a simple, display-oriented file system browser based on the Alpine message system composer. As with Alpine, commands are displayed at the bottom of the screen, and context-sensitive help is provided. Pilot displays the current working directory at the top of the screen. The directory's contents are displayed in columns of file name, file size pairs. Names that are directories are indicated by the name \"(dir)\" in place of the file size. The parent of the current working directory is indicated by the file name \"..\" and size of \"(parent dir)\". File names that are symbolic links to other files are displayed with a file size of \"--\". Several basic file manipulation commands are provided: Delete, Rename, Copy, View, Launch, and Edit. The \"View\" and \"Edit\" commands operate on text files only. By default, the \"View\" command displays files using \"alpine -F\", but will respect the environment variable PAGER if set. The \"Edit\" command simply invokes \"pico\". The \"Launch\" command provides a convenient way to either execute the selected file or to run an application on it. More specific help is available in pilot's online help.","Process Name":"pilot","Link":"https:\/\/linux.die.net\/man\/1\/pilot"}},{"Process":{"Description":"pilot-addresses allows the user to read all entries from a Palm handheld such as those made by Palm, Handspring, Handera, TRGPro, Sony or other Palm handheld in the Palm Address Book application, write new entries into the database, and delete a category or delete all entries in the database.","Process Name":"pilot-addresses","Link":"https:\/\/linux.die.net\/man\/1\/pilot-addresses"}},{"Process":{"Description":"pilot-clip is used to get or set the Palm Clipboard contents from STDOUT\/STDIN. You must provide one of -g or -s.","Process Name":"pilot-clip","Link":"https:\/\/linux.die.net\/man\/1\/pilot-clip"}},{"Process":{"Description":"","Process Name":"pilot-csd","Link":"https:\/\/linux.die.net\/man\/1\/pilot-csd"}},{"Process":{"Description":"pilot-debugsh is a commandline interface to the Palm debug monitor. Use device file \/dev\/tty<0..n> to communicate with the Palm handheld. If this is not specified, pilot-debugsh will output a simple usage help message.","Process Name":"pilot-debugsh","Link":"https:\/\/linux.die.net\/man\/1\/pilot-debugsh"}},{"Process":{"Description":"pilot-dedupe is used to remove duplicate records from any Palm database.","Process Name":"pilot-dedupe","Link":"https:\/\/linux.die.net\/man\/1\/pilot-dedupe"}},{"Process":{"Description":"pilot-dlpsh allows the user to connect to a Palm handheld and execute arbitrary DLP commands. pilot-dlpsh can query many different types of information from your Palm device, such as username, memory capacity, set the time, as well as other useful functions. Once connected, the user may execute most of the built-in DLP commands. (See BUILT-IN COMMANDS below for more detail on currently supported options). The connection to the Pilot is kept alive by sending a PadTickle packet to the Pilot after a small period of non-activity. (7 seconds by default)","Process Name":"pilot-dlpsh","Link":"https:\/\/linux.die.net\/man\/1\/pilot-dlpsh"}},{"Process":{"Description":"pilot-file is used to Dump application and header information from your local PRC\/PDB files. pilot-file does not connect to your Palm.","Process Name":"pilot-file","Link":"https:\/\/linux.die.net\/man\/1\/pilot-file"}},{"Process":{"Description":"This is a palm conduit to fetch, install, or remove, Foto files from a Palm. It can also convert *.jpg.pdb files that have already been fetched from the Palm to jpeg files. Delete all, or named fotos from handheld. Install one, or many jpeg images to handheld. List all jpeg files and thumbnails on handheld. Fetch all jpeg files, or certain ones by name. Tries to detect if a file really is a jpeg and refuses to install it, if it is not. pilot-foto allows you to do multiple operations in one sync. For instance, delete test.jpg and install test.jpg.","Process Name":"pilot-foto","Link":"https:\/\/linux.die.net\/man\/1\/pilot-foto"}},{"Process":{"Description":"Copies Treo \"foto\" databases to current directory and extracts the .jpg image files within them.","Process Name":"pilot-foto-treo600","Link":"https:\/\/linux.die.net\/man\/1\/pilot-foto-treo600"}},{"Process":{"Description":"Copies Treo \"foto\" databases to current directory and extracts the .jpg image files within them.","Process Name":"pilot-foto-treo650","Link":"https:\/\/linux.die.net\/man\/1\/pilot-foto-treo650"}},{"Process":{"Description":"pilot-getram is used to fetch the current RAM image from your Palm handheld for use in debugging. pilot-getromtoken, pilot-getrom and pilot-getram are inter-related. All relevant code is implemented in pilot-getrom, and you can do pilot-getromtoken --ram filename to get the RAM dump if you like. Note, because pilot-getrom uses the low-level RPC protocol to fetch the ROM image, and the new OS5 devices do not use this protocol, you currently cannot fetch an OS5 ROM image using this utility. This will be updated in a future release to handle fetching OS5 ROM images, using the debugger protocol.","Process Name":"pilot-getram","Link":"https:\/\/linux.die.net\/man\/1\/pilot-getram"}},{"Process":{"Description":"pilot-getrom is used to fetch the ROM from your Palm handheld for use in debugging Palm applications through the use of POSE, the Palm OS Emulator application. Note, because pilot-getrom uses the low-level RPC protocol to fetch the ROM image, and the new OS5 devices do not use this protocol, you currently cannot fetch an OS5 ROM image using this utility. This will be updated in a future release to handle fetching OS5 ROM images, using the debugger protocol.","Process Name":"pilot-getrom","Link":"https:\/\/linux.die.net\/man\/1\/pilot-getrom"}},{"Process":{"Description":"Tokens you may currently extract are: adcc: Entropy for internal A->D convertor calibration irda: Present only on memory card w\/IrDA support snum: Device serial number (from Memory Card Flash ID) pilot-getromtoken is used to fetch the ROM from your Palm handheld for use in debugging Palm applications through the use of POSE, the Palm OS Emulator application. Note, because pilot-getrom uses the low-level RPC protocol to fetch the ROM image, and the new OS5 devices do not use this protocol, you currently cannot fetch an OS5 ROM image using this utility. This will be updated in a future release to handle fetching OS5 ROM images, using the debugger protocol.","Process Name":"pilot-getromtoken","Link":"https:\/\/linux.die.net\/man\/1\/pilot-getromtoken"}},{"Process":{"Description":"Hi-Notes must be installed on your Palm handheld (and at least one entry must exist within Hi-Notes). By default, the contents of your Palm's Hi-Notes database (Hi-NoteDB.pdb) will be written to STDOUT as a standard Unix mailbox (in mbox-format) file, with each memo as a separate message. The subject of each message will be set as the category. The memos will be written to STDOUT unless the -d option is specified. Using -d will be save the memos in subdirectories of dir. Each subdirectory will contain the name of a category on the Palm where the record was stored, and will contain the memos found in that category. Each memo's filename will be the first line (up to the first 40 characters) of the memo. Control characters, slashes, and equal signs that would otherwise appear in filenames are converted using the correct MIME's quoted-printable encoding. Please see http:\/\/www.cyclos.com\/ for more information on Hi-Note.","Process Name":"pilot-hinotes","Link":"https:\/\/linux.die.net\/man\/1\/pilot-hinotes"}},{"Process":{"Description":"pilot-install-datebook allows the user to create one or more datebook entries from one or more source files. The format of the source file contains one datebook entry per line, containing four tab separated fields. The fields are start date\/time, end date\/time, alarm settings, and the description of datebook entry. This program doesn't yet support repeated entries. The date and time must be in format understood by parsedate.y. At the very least, the following two formats are understood: August 11, 1997 0800 GMT+300 1997\/08\/11 08:22:33 GMT+300 If either one of the date and time fields is empty, the entry is installed without time. If the alarm field is empty, the entry is installed without setting any alarms. The alarm field can contain numbers followed by \"m\" (minutes), \"h\" (hours), or \"d\" (days).","Process Name":"pilot-install-datebook","Link":"https:\/\/linux.die.net\/man\/1\/pilot-install-datebook"}},{"Process":{"Description":"pilot-install-expenses allows a Palm handheld with the Expense application to have expense records synchronized to it from the commandline. You can pass any of the fields (except categories, currently) to pilot-install-expenses and create new expense records on your Palm handheld.","Process Name":"pilot-install-expenses","Link":"https:\/\/linux.die.net\/man\/1\/pilot-install-expenses"}},{"Process":{"Description":"pilot-install-hinote allows the user to write one or more files as a new Hi-Note or into the Hi-Notes Palm application itself, on the Palm handheld. Please see http:\/\/www.cyclos.com\/ for more information on Hi-Note.","Process Name":"pilot-install-hinote","Link":"https:\/\/linux.die.net\/man\/1\/pilot-install-hinote"}},{"Process":{"Description":"pilot-install-memo allows the user to write one or more files as a new memo or memos, respectively, onto the Palm handheld.","Process Name":"pilot-install-memo","Link":"https:\/\/linux.die.net\/man\/1\/pilot-install-memo"}},{"Process":{"Description":"pilot-install-netsync allows the user to read or change the Network Preferences stored on the Palm.","Process Name":"pilot-install-netsync","Link":"https:\/\/linux.die.net\/man\/1\/pilot-install-netsync"}},{"Process":{"Description":"pilot-install-todo allows the user to install one new ToDo list entry with specified paramters passed to pilot-install-todo and add a Note entry using text found in a filename <filename> passed to pilot-install-todo.","Process Name":"pilot-install-todo","Link":"https:\/\/linux.die.net\/man\/1\/pilot-install-todo"}},{"Process":{"Description":"pilot-install-todos allows the user to update the Palm ToDo list with entries from a local file. The format of this file is a simple line-by-line ToDo task entry. For each new line in the local file, a new task is created in the ToDo database on the Palm.","Process Name":"pilot-install-todos","Link":"https:\/\/linux.die.net\/man\/1\/pilot-install-todos"}},{"Process":{"Description":"pilot-install-user allows the user to read or change the User and UserID information on the Palm handheld.","Process Name":"pilot-install-user","Link":"https:\/\/linux.die.net\/man\/1\/pilot-install-user"}},{"Process":{"Description":"By default, the contents of your Palm's memo database will be written to standard output as a standard UNIX mailbox (mbox-format) file, with each memo as a separate message. The subject of each message will be the category. If '-s' is specified, then instead of being written to standard output, memos will be saved in subdirectories of dir. Each subdirectory will be the name of a category on the Palm, and will contain the memos in that category. Each filename will be the first line (up to the first 40 characters) of the memo. Control characters, slashes, and equal signs that would otherwise appear in filenames are converted after the fashion of MIME's quoted-printable encoding. Note that if you have two memos in the same category whose first lines are identical, one of them will be overwritten. If '-f' is specified, the specified file will be treated as a memo database from which to read memos, rather than HotSyncing from the Palm.","Process Name":"pilot-memos","Link":"https:\/\/linux.die.net\/man\/1\/pilot-memos"}},{"Process":{"Description":"This will bind your locally connected device to a network port, and redirect them through the network device to a listening server as specified in the LANSync Preferences panel on your Palm.","Process Name":"pilot-nredir","Link":"https:\/\/linux.die.net\/man\/1\/pilot-nredir"}},{"Process":{"Description":"pilot-read-expenses is used to output the Expense data in a simple text format, which can be used to import into any other application you wish, such as Excel or other application. If you have expense entries saved on your Palm in the ExpenseDB.pdb file, you can export them to a simple text format, and redirect that to a file\/pipe, or STDOUT (the default) using pilot-read-expenses. The output data will resemble something like the following: Category: Unfiled Type:   5 Payment:   7 Currency:  23 Amount: 400.00 Vendor: Super Salads City: Westerly\nAttendees: Joe, Mary, Bob Note: Some simple note text Date: Fri May 9 00:00:00 2004","Process Name":"pilot-read-expenses","Link":"https:\/\/linux.die.net\/man\/1\/pilot-read-expenses"}},{"Process":{"Description":"Note, this is not the same as the iCal calendar format. pilot-read-ical allows the user to retrieve the contents of the ToDo and Datebook databases on a Palm handheld, and convert their contents to an Ical calendar. Note that the calendar file named by filename will be deleted, so do not use your main calendar. Instead, use a separate one for this purpose, and include it in your main calendar. As pilot-read-ical works by passing a script to ical, the ical application must be in your $PATH.","Process Name":"pilot-read-ical","Link":"https:\/\/linux.die.net\/man\/1\/pilot-read-ical"}},{"Process":{"Description":"Connect to the Palm handheld and list the record information found in the Palm Notepad application (found on OS4 and newer devices). If --type is specified, each record's image will be converted to files, using Portable Network Graphic (.png) or Portable Pixmap (.ppm) format. pilot-read-notepad allows a user running PalmOS 4.0 or later to read the data stored in the Palm Notepad application and extract the data into images and convert them to Portable Network Graphics (.png) or Portable Pixmap (.ppm) files.","Process Name":"pilot-read-notepad","Link":"https:\/\/linux.die.net\/man\/1\/pilot-read-notepad"}},{"Process":{"Description":"pilot-read-palmpix allows a Kodak PalmPix camera user to extract the images from their Palm handheld and convert them to Portable Network Graphic (.png) or Portable Pixmap (.ppm) files on their system. The default output type is Portable Pixmap (.ppm). pilot-read-palmpix converts all pictures in the files given, or if no files are given, on a Palm handheld, to Portable Pixmap files.","Process Name":"pilot-read-palmpix","Link":"https:\/\/linux.die.net\/man\/1\/pilot-read-palmpix"}},{"Process":{"Description":"ScreenShot is a Palm-compatible application for OS4 and OS5. ScreenShot captures the current screen of any application. All color and grayscale modes, as well as extended screen sizes and virtual Graffiti areas are supported. Also exports as JPG\/GIF\/BMP to card. For more information on ScreenShot, go to http:\/\/linkesoft.com\/screenshot\/","Process Name":"pilot-read-screenshot","Link":"https:\/\/linux.die.net\/man\/1\/pilot-read-screenshot"}},{"Process":{"Description":"pilot-read-todos will read the ToDo database on the Palm handheld, or read the ToDoDB.pdb file directly from disk on your desktop machine, and print the contents to STDOUT (generally the screen). Use only one of --port or --file.","Process Name":"pilot-read-todos","Link":"https:\/\/linux.die.net\/man\/1\/pilot-read-todos"}},{"Process":{"Description":"Synchronize your Veo Traveler databases with your desktop machine. Output defaults to ppm.","Process Name":"pilot-read-veo","Link":"https:\/\/linux.die.net\/man\/1\/pilot-read-veo"}},{"Process":{"Description":"Your Datebook database will be written to STDOUT as it is converted unless redirected to a file.","Process Name":"pilot-reminders","Link":"https:\/\/linux.die.net\/man\/1\/pilot-reminders"}},{"Process":{"Description":"Currently the stored name and file type is not queried so you can potentially install a PDF file, and retrieve it as a ZIP file. You must take care to remember what type of file you are installing and fetching. This will be updated in a later release to handle this type of capability, as well as handle multiple 'Schlep' files.","Process Name":"pilot-schlep","Link":"https:\/\/linux.die.net\/man\/1\/pilot-schlep"}},{"Process":{"Description":"","Process Name":"pilot-wav","Link":"https:\/\/linux.die.net\/man\/1\/pilot-wav"}},{"Process":{"Description":"This is the swiss-army-knife of the entire pilot-link suite. pilot-xfer allows the user to install databases contained in the standard .prc (Palm Resource Database), .pdb (Palm Record Database), and .pqa (Palm Query Application) formats onto a Palm, retrieve databases from the Palm, list the databases contained in a Palm, backup or restore all of the databases at once as well as many other powerful operations performed on a Palm handheld device.","Process Name":"pilot-xfer","Link":"https:\/\/linux.die.net\/man\/1\/pilot-xfer"}},{"Process":{"Description":"Alpine is a screen-oriented message-handling tool. In its default configuration, Alpine offers an intentionally limited set of functions geared toward the novice user, but it also has a large list of optional \"power-user\" and personal-preference features. alpinef is a variant of Alpine that uses function keys rather than mnemonic single-letter commands. Alpine's basic feature set includes: View, Save, Export, Delete, Print, Reply and Forward messages. Compose messages in a simple editor (Pico) with word-wrap and a spelling checker. Messages may be postponed for later completion. Full-screen selection and management of message folders. Address book to keep a list of long or frequently-used addresses. Personal distribution lists may be defined. Addresses may be taken into the address book from incoming mail without retyping them. New mail checking and notification occurs automatically every 2.5 minutes and after certain commands, e.g. refresh-screen (Ctrl-L). On-line, context-sensitive help screens. Alpine supports MIME (Multipurpose Internet Mail Extensions), an Internet Standard for representing multipart and multimedia data in email. Alpine allows you to save MIME objects to files, and in some cases, can also initiate the correct program for viewing the object. It uses the system's mailcap configuration file to determine what program can process a particular MIME object type. Alpine's message composer does not have integral multimedia capability, but any type of data file --including multimedia-- can be attached to a text message and sent using MIME's encoding rules. This allows any group of individuals with MIME-capable mail software (e.g. Alpine, PC-Alpine, or many other programs) to exchange formatted documents, spread-sheets, image files, etc, via Internet email. Alpine uses the c-client messaging API to access local and remote mail folders. This library provides a variety of low-level message-handling functions, including drivers for a variety of different mail file formats, as well as routines to access remote mail and news servers, using IMAP (Internet Message Access Protocol) and NNTP (Network News Transport Protocol). Outgoing mail is usually posted directly via SMTP (Simple Mail Transfer Protocol).","Process Name":"pine","Link":"https:\/\/linux.die.net\/man\/1\/pine"}},{"Process":{"Description":"This is a program for viewing info files. You specify which page you want to read by passing it an infopage argument. This argument contains the name of an info page (i.e. 'bash'). The program will then (by default) search for it in the current directory, \/usr\/share\/info, \/usr\/info, \/usr\/local\/share\/info, \/usr\/local\/info. and \/opt\/info. The search path can be adjusted by INFOPATH environment variable or in the configuration file. Pinfo will also automatically add the suffix '-info', '-info.Z', '-info.gz', or '-info.bz2'. At present other suffixes are not recognized, but you can easily add them to the function openinfo() in filehandling_functions.c. When the search for info pages fails, man is called with the infopage argument, and it's output is parsed by pinfo. This means that when you don't have the appropriate info page, but have a man page instead; the man page will be viewed. When no infopage is specified, the default 'dir' page is shown. Supported options are -h, --help - print help information and exit. -v, --version - print version information and exit. -m, --manual - uses manual page instead of info by default. (pinfo -m could be used as a manual pager). Warning: Everything what follows this option is passed to the 'man' program. Don't be confused if pinfo options, which followed '-m' don't work. When using this option, pinfo does not parse the info options as usual! It invokes the man part of program. You can also call the man function of pinfo in another way. When pinfo is called with an argv[0] (the program file name), which contains the word 'man' in it's name, the man functions are enabled automatically. Previously there was a symlink to pinfo, called pman, but I had to remove it from the distribution, since it's name was in conflict with some other utility. Anyway, you can feel free to create such a link if you wish. -r, --raw-filename - uses a raw filename first (i.e. the name which you specified as infopage is considered to be a real file in the specified location). -f, --file synonym for -r. -a, --apropos - if this is set, apropos is called when no man or info page could be found. -c, --cut-man-headers - if this is set, man parsing code will try to cut out the repeated man headers. Use with care. ;) -s, --squeeze-lines- cut empty lines from manual pages. This option enables auto cutting of every repeated newline in a manual page. -t, --force-manual-tag-table- forces manual detection of tag table. This allows you to view info pages, which may be corrupted. (as i.e. version of jed's pages, shipped with RH5.0). The tag table corruption usually appears in that the info links, which you follow, move you to quite unexpected nodes. --node=nodename, --node nodename- Go to the node 'nodename' of info file. Since 0.6.7 it is also possible to specify nodes as in standalone info via file names, like '(gcc)Introduction'. --rcfile=filename, --rcfile filename- Use alternate configuration file. --long-manual-links, -l- Use long link names in manuals. On some systems the manual hierarchy is divided into subsections like '3ncurses', etc, while on other systems all belongs to section '3'. If this option is what your system is like, feel free to use it. --clear-at-exit, -x- Clear screen at exit. The options are handled by GNU getopt, so you can here (as in other programs) abbreviate the option names to the minimal number of characters by which the options differ. Warning! If you do not have getopt, these options will not work!","Process Name":"pinfo","Link":"https:\/\/linux.die.net\/man\/1\/pinfo"}},{"Process":{"Description":"-l produce long format output for the specified USERs -b omit the user's home directory and shell in long format -h omit the user's project file in long format -p omit the user's plan file in long format -s do short format output, this is the default -f omit the line of column headings in short format -w omit the user's full name in short format -i omit the user's full name and remote host in short format -q omit the user's full name, remote host and idle time in short format --help display this help and exit --version output version information and exit A lightweight 'finger' program; print user information. The utmp file will be \/var\/run\/utmp.","Process Name":"pinky","Link":"https:\/\/linux.die.net\/man\/1\/pinky"}},{"Process":{"Description":"This script is the command-line interface to \"Shell::Perl\" which does it all. By now, read the fine details at \"Shell::Perl\" documentation.","Process Name":"pirl","Link":"https:\/\/linux.die.net\/man\/1\/pirl"}},{"Process":{"Description":"pisg is a program which takes IRC logfiles and turns the into nice looking stats, which can be amusing to show to the users of your channel. It's quite simple to set up using command line parameters or a configuration file.","Process Name":"pisg","Link":"https:\/\/linux.die.net\/man\/1\/pisg"}},{"Process":{"Description":"pitchplay allows playback of audio tracks with cdda2wav with pitches specified in percentage with 100% being the original pitch, 50% being one octave lower, 200% one octave higher.","Process Name":"pitchplay","Link":"https:\/\/linux.die.net\/man\/1\/pitchplay"}},{"Process":{"Description":"","Process Name":"piv-tool","Link":"https:\/\/linux.die.net\/man\/1\/piv-tool"}},{"Process":{"Description":"This program is part of Netpbm(1). pjtoppm reads an HP PaintJet file as input and converts it into a PPM image. This was a quick hack to save some trees, and it only handles a small subset of the paintjet commands. In particular, it will only handle enough commands to convert most raster image files.","Process Name":"pjtoppm","Link":"https:\/\/linux.die.net\/man\/1\/pjtoppm"}},{"Process":{"Description":"This manual page documents briefly the pk-debuginfo-install command. pk-debuginfo-install is the command line client for installing debuginfo packages.","Process Name":"pk-debuginfo-install","Link":"https:\/\/linux.die.net\/man\/1\/pk-debuginfo-install"}},{"Process":{"Description":"This manual page documents briefly the pk-device-rebind command. pk-device-rebind is the command line client for reloading devices after firmware has been installed.","Process Name":"pk-device-rebind","Link":"https:\/\/linux.die.net\/man\/1\/pk-device-rebind"}},{"Process":{"Description":"This program generates a bitmap (ASCII file) which can be used to create X11 applications. The bitmap file consists of all pixels of the specified character (via the -c or -o option) from the given pkfont. The format is described in bitmap(X11). The pkfont is a packed fontfile generated by gftopk(TeX) from a gffont. A gffont is the output of METAFONT a program to design fonts in a device independant way. With the -b flag a bitmap is generated in which all black pixels are drawn as a '*' and all white bits as a '.'. With the -h flag a hexadecimal bitmap dump is generated. The -W and\/or -H options can be used to create a bitmap of respectivally 'width' and 'height' pixels. The pk-bitmap will in this case be centered according to these new dimensions. The output is written to the standard output.","Process Name":"pk2bm","Link":"https:\/\/linux.die.net\/man\/1\/pk2bm"}},{"Process":{"Description":"pkaction is used to obtain information about registered PolicyKit actions. If called with --action-id then all actions are displayed. Otherwise the action action. If called without the --verbose option only the name of the action is shown. Otherwise details about the actions are shown.","Process Name":"pkaction","Link":"https:\/\/linux.die.net\/man\/1\/pkaction"}},{"Process":{"Description":"pkcheck is used to check whether a process, specified by either --process or --system-bus-name, is authorized for action. The --detail option can be used zero or more times to pass details about action. If --allow-user-interaction is passed, pkcheck blocks while waiting for authentication. This command is a simple wrapper around the PolicyKit D-Bus interface; see the D-Bus interface documentation for details.","Process Name":"pkcheck","Link":"https:\/\/linux.die.net\/man\/1\/pkcheck"}},{"Process":{"Description":"This manual page documents briefly the pkcon command. pkcon is the command line client for PackageKit.","Process Name":"pkcon","Link":"https:\/\/linux.die.net\/man\/1\/pkcon"}},{"Process":{"Description":"The pkcs11-tool utility is used to manage the data objects on smart cards and similar PKCS #11 security tokens. Users can list and read PINs, keys and certificates stored on the token. User PIN authentication is performed for those operations that require it.","Process Name":"pkcs11-tool","Link":"https:\/\/linux.die.net\/man\/1\/pkcs11-tool"}},{"Process":{"Description":"card_eventmgr is a SmartCard Monitoring that listen to the status of the card reader and dispatch actions on several events. card_eventmgr can be used to several actions, like lock screen on card removal Three events are supported: card insert, card removal and timeout on removed card. Actions to take are specified in the configuration file","Process Name":"pkcs11_eventmgr","Link":"https:\/\/linux.die.net\/man\/1\/pkcs11_eventmgr"}},{"Process":{"Description":"pkcs11_inspect uses the pam_pkcs11 library infrastructure to get the content of a certificate and display it. pkcs11_inspect uses the same configuration file and arguments than pam_pkcs11(8) PAM module. It loads defined mapper modules, and use them to look into the certificate for required entries (ie: ms_mapper looks for ms UPN entries, and so on). When a mapper module finds a proper entry in the certificate, it converts to UTF-8 and print it to stdout.","Process Name":"pkcs11_inspect","Link":"https:\/\/linux.die.net\/man\/1\/pkcs11_inspect"}},{"Process":{"Description":"pkcs11_listcerts display all the certificates.","Process Name":"pkcs11_listcerts","Link":"https:\/\/linux.die.net\/man\/1\/pkcs11_listcerts"}},{"Process":{"Description":"pkcs11_setup display all the certificates.","Process Name":"pkcs11_setup","Link":"https:\/\/linux.die.net\/man\/1\/pkcs11_setup"}},{"Process":{"Description":"Script that detects available tokens from installed shared object libraries and writes corresponding records to the pk_config_data file. The pkcsslotd daemon later uses this information when initializing the tokens. The script should be run each time a new token has been installed or uninstalled.","Process Name":"pkcs11_startup","Link":"https:\/\/linux.die.net\/man\/1\/pkcs11_startup"}},{"Process":{"Description":"The pkcs12 command allows PKCS#12 files (sometimes referred to as PFX files) to be created and parsed. PKCS#12 files are used by several programs including Netscape, MSIE and MS Outlook.","Process Name":"pkcs12","Link":"https:\/\/linux.die.net\/man\/1\/pkcs12"}},{"Process":{"Description":"The pkcs15-crypt utility can be used from the command line to perform cryptographic operations such as computing digital signatures or decrypting data, using keys stored on a PKCS #15 compliant smart card.","Process Name":"pkcs15-crypt","Link":"https:\/\/linux.die.net\/man\/1\/pkcs15-crypt"}},{"Process":{"Description":"The pkcs15-init utility can be used to create a PKCS #15 structure on a smart card, and add key or certificate objects. Details of the structure that will be created are controlled via profiles. The profile used by default is pkcs15. Alternative profiles can be specified via the -p switch.","Process Name":"pkcs15-init","Link":"https:\/\/linux.die.net\/man\/1\/pkcs15-init"}},{"Process":{"Description":"The pkcs15-tool utility is used to manipulate the PKCS #15 data structures on smart cards and similar security tokens. Users can list and read PINs, keys and certificates stored on the token. User PIN authentication is performed for those operations that require it.","Process Name":"pkcs15-tool","Link":"https:\/\/linux.die.net\/man\/1\/pkcs15-tool"}},{"Process":{"Description":"The pkcs7 command processes PKCS#7 files in DER or PEM format.","Process Name":"pkcs7","Link":"https:\/\/linux.die.net\/man\/1\/pkcs7"}},{"Process":{"Description":"The pkcs8 command processes private keys in PKCS#8 format. It can handle both unencrypted PKCS#8 PrivateKeyInfo format and EncryptedPrivateKeyInfo format with a variety of PKCS#5 (v1.5 and v2.0) and PKCS#12 algorithms.","Process Name":"pkcs8","Link":"https:\/\/linux.die.net\/man\/1\/pkcs8"}},{"Process":{"Description":"The pkcsconf utility displays and configures the state of the pkcsslotd daemon and the tokens managed by the daemon.","Process Name":"pkcsconf","Link":"https:\/\/linux.die.net\/man\/1\/pkcsconf"}},{"Process":{"Description":"pkexec allows an authorized user to execute PROGRAM as another user. If username is not specified, then the program will be executed as the administrative super user, root.","Process Name":"pkexec","Link":"https:\/\/linux.die.net\/man\/1\/pkexec"}},{"Process":{"Description":"The pkey command processes public or private keys. They can be converted between various forms and their components printed out.","Process Name":"pkey","Link":"https:\/\/linux.die.net\/man\/1\/pkey"}},{"Process":{"Description":"The pkey command processes public or private keys. They can be converted between various forms and their components printed out.","Process Name":"pkeyparam","Link":"https:\/\/linux.die.net\/man\/1\/pkeyparam"}},{"Process":{"Description":"The pkeyutl command can be used to perform public key operations using any supported algorithm.","Process Name":"pkeyutl","Link":"https:\/\/linux.die.net\/man\/1\/pkeyutl"}},{"Process":{"Description":"The pkg-config program is used to retrieve information about installed libraries in the system. It is typically used to compile and link against one or more libraries. Here is a typical usage scenario in a Makefile: program: program.c cc program.c 'pkg-config --cflags --libs gnomeui' pkg-config retrieves information about packages from special metadata files. These files are named after the package, with the extension .pc. By default, pkg-config looks in the directory prefix\/lib\/pkgconfig for these files; it will also look in the colon-separated (on Windows, semicolon-separated) list of directories specified by the PKG_CONFIG_PATH environment variable. The package name specified on the pkg-config command line is defined to be the name of the metadata file, minus the .pc extension. If a library can install multiple versions simultaneously, it must give each version its own name (for example, GTK 1.2 might have the package name \"gtk+\" while GTK 2.0 has \"gtk+-2.0\").","Process Name":"pkg-config","Link":"https:\/\/linux.die.net\/man\/1\/pkg-config"}},{"Process":{"Description":"pkgdata takes a set of data files and packages them for use by ICU or applications that use ICU. The typical reason to package files using pkgdata is to make their distribution easier and their loading by ICU faster and less consuming of limited system resources such as file descriptors. Packaged data also allow applications to be distributed with fewer resource files, or even with none at all if they link against the packaged data directly. pkgdata supports a few different methods of packaging data that serve different purposes. The default packaging mode is common, or archive. In this mode, the different data files are bundled together as an architecture-dependent file that can later be memory mapped for use by ICU. Data packaged using this mode will be looked up under the ICU data directory. Such packaging is easy to use for applications resource bundles, for example, as long as the application can install the packaged file in the ICU data directory. Another packaging mode is the dll, or library, mode, where the data files are compiled into a shared library. ICU used to be able to dynamically load these shared libraries, but as of ICU 2.0, such support has been removed. This mode is still useful for two main purposes: to build ICU itself, as the ICU data is packaged as a shared library by default; and to build resource bundles that are linked to the application that uses them. Such resource bundles can then be placed anywhere where the system's dynamic linker will be looking for shared libraries, instead of being forced to live inside the ICU data directory. The static packaging mode is similar to the shared library one except that it produces a static library. Finally, pkgdata supports a files mode which simply copies the data files instead of packaging them as a single file or library. This mode is mainly intended to provide support for building ICU before it is packaged as separate small packages for distribution with operating systems such as Debian GNU\/Linux for example. Please refer to the packaging documentation in the ICU source distribution for further information on the use of this mode. pkgdata builds, packages, installs, or cleans the appropriate data based on the options given without the need to call GNU make anymore.","Process Name":"pkgdata","Link":"https:\/\/linux.die.net\/man\/1\/pkgdata"}},{"Process":{"Description":"This manual page documents briefly the pkgenpack command. pkgenpack is the command line client for PackageKit for creating service packs.","Process Name":"pkgenpack","Link":"https:\/\/linux.die.net\/man\/1\/pkgenpack"}},{"Process":{"Description":"pgrep looks through the currently running processes and lists the process IDs which matches the selection criteria to stdout. All the criteria have to match. For example, pgrep -u root sshd will only list the processes called sshd AND owned by root. On the other hand, pgrep -u root,daemon will list the processes owned by root OR daemon. pkill will send the specified signal (by default SIGTERM) to each process instead of listing them on stdout.","Process Name":"pkill","Link":"https:\/\/linux.die.net\/man\/1\/pkill"}},{"Process":{"Description":"pklogin_finder uses the pam_pkcs11 library infrastructure to interactively map a PKCS#11 provided certificate to a user. pklogin_finder uses the the same configuration file and arguments than pam_pkcs11(8) PAM module. Load defined mapper modules, and try to find a map between found certificates and a user login.","Process Name":"pklogin_finder","Link":"https:\/\/linux.die.net\/man\/1\/pklogin_finder"}},{"Process":{"Description":"This manual page documents briefly the pkmon command. pkmon is the command line client for PackageKit.","Process Name":"pkmon","Link":"https:\/\/linux.die.net\/man\/1\/pkmon"}},{"Process":{"Description":"pkpgcounter v3.50 (c) 2003, 2004, 2005, 2006, 2007 Jerome Alet pkpgcounter is a generic Page Description Language parser. pkpgcounter parses any number of input files and\/or its standard input and outputs the number of pages needed to print these documents. pkpgcounter can also compute the percent of ink coverage in different colorspaces for several file formats. pkpgcounter currently recognizes the following document formats : * PostScript (both DSC compliant and binary) * PDF * PCLXL (aka PCL6) * PCL3\/4\/5 * DVI * OpenDocument (ISO\/IEC DIS 26300) * Microsoft Word (c) (tm) (r) (etc...) * Plain text * TIFF * Several other image formats * ESC\/P2 * Zenographics ZjStream * Samsung QPDL (aka SPL2) * Samsung SPL1 * ESC\/PageS03 * Brother HBP * Hewlett-Packard LIDIL (hpijs) * Structured Fax * Canon BJ\/BJC * ASCII PNM (Netpbm) The ten latter ones, as well as some TIFF documents, are currently only supported in page counting mode. command line usage : pkpgcounter [options] [files] options : -v | --version Prints pkpgcounter's version number then exits. -h | --help Prints this message then exits. -d | --debug Activate debug mode. -cCOLORSPACE, --colorspace= COLORSPACE Activate the computation of ink usage, and defines the colorspace to use. Supported values are 'BW' (Black), 'RGB', 'CMYK', 'CMY', and 'GC' (Grayscale vs Color). 'GC' is useful if you only need to differentiate grayscale pages from coloured pages but don't care about ink usage per se. -rRESOLUTION, --resolution= RESOLUTION The resolution in DPI to use when checking ink usage. Lower resolution is faster but less accurate. Default is 72 dpi. examples : CW$ pkpgcounter file1.ps file2.escp2 file3.pclxl <file4.pcl345 Will launch pkpgcounter and will output the total number of pages needed to print all the documents specified. CW$ pkpgcounter --colorspace bw --resolution 150 file1.ps Will output the percent of black ink needed on each page of the file1.ps file rendered at 150 dpi. This program is free software: you can redistribute it and\/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see <http:\/\/www.gnu.org\/licenses\/>. Please e-mail bugs to: alet@librelogiciel.com Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"pkpgcounter","Link":"https:\/\/linux.die.net\/man\/1\/pkpgcounter"}},{"Process":{"Description":"This manual page is not meant to be exhaustive. The complete documentation for this version of TeX can be found in the info file or manual Web2C: A TeX implementation. The pktogf program converts a packed font file (pk) to a generic font file (gf). Packed font files are much smaller than the corresponding gf files, but some DVI readers only understand gf files. The pk_file_name on the command line must be complete. Because the resolution is part of the extension, it would not make sense to append a default extension as is done with TeX or DVI-reading software. The gf_file_name defaults to the same (stripped) name as pk_file_name, and it is placed in the current working directory with the gf suffix replacing pk. For example, the input file io.300pk would become io.300gf.","Process Name":"pktogf","Link":"https:\/\/linux.die.net\/man\/1\/pktogf"}},{"Process":{"Description":"This program is part of Netpbm(1). pktopbm reads a packed (PK) font file as input, and produces PBM images as output. If the filename '-' is used for any of the filenames, the standard input stream (or standard output where appropriate) will be used. If either the width or height is specified, this value will be used for all bitmaps produced. Also if one or both values are specified, the bitmap will be relocated with the hoffset and voffset given in the pkfile. The basepoint will be placed in the lower left corner of the bitmap if the bitmap is bigger than the specified size it will be truncated at the top or right.","Process Name":"pktopbm","Link":"https:\/\/linux.die.net\/man\/1\/pktopbm"}},{"Process":{"Description":"The pktstat program displays a real-time summary of packet activity on an interface. Each line displays the data rate associated with different classes of packets. pktstat understands the following command line options:             -1'      Single-shot (batch) mode.  pktstat collects data forwaittime seconds (see -w option) then emits a line indicatingthe number of flows detected, and the period of data capturein seconds.  Then, each flow line is printed in the form ofthe number of data link octets associated with the flow, thenumber of data link frames (packets), and then the flowdescription. -a abbrev Add abbrev to the list of abbreviation patterns. (See below for details.) -A file Read abbreviation patterns from the given file. (See Abbreviations, below.) If the option -A none is given, then default abbreviation files are not loaded. -B' Display data rates in bytes per second (Bps) instead of in bits per second (bps). -c' Do not combine some packet classes into one class. For example, TCP connections are kept as two separate flows. -F' Show full hostnames. Normally, hostnames are truncated to the first component of their domain name before display. -i interface Listen on the given interface. If not specified, a suitable interface is chosen. -k keeptime When no packets have been seen for a particular class, retain an entry on the display for this many screen seconds. Defaults to 10. -l' Display and sort flows by when they were last seen. (Incompatible with -t) -m maxbps Fix the maximum bit rate for the interface at maxbps instead of auto-detecting it. -n' Do not try and resolve hostnames or service port numbers. -p' Show packet counts instead of bit counts. -P' Do not try to put the interface into promiscuous mode. -t' \"Top\" mode. Sorts the display by bit count (or packet count if -p was given) instead of by the name. -T' Show totals. -w waittime Refresh the display every waittime seconds. The default is 5 seconds. filter-expr Only consider packets matching the given filter-expr. If no filter is provided, all packets are considered. See tcpdump(8) for information on valid expressions. If the terminal supports it, the display briefly highlights in bold new connections or old connections carrying data after a period of inactivity. Simple statistics about the interface are also displayed such as the current and average bit rates (measured just above the data link layer). Load averages refer to bit rate decayed averages for the last 1, 5 and 15 minutes. During display, the following keystrokes are recognised: q' quit Ctrl-L' redraw screen t' toggle the -t flag (top mode)","Process Name":"pktstat","Link":"https:\/\/linux.die.net\/man\/1\/pktstat"}},{"Process":{"Description":"This manual page is not meant to be exhaustive. The complete documentation for this version of TeX can be found in the info file or manual Web2C: A TeX implementation. The pktype program translates a packed font file (pk) (output by, for example, gftopk(1) to a file that humans can read. It also serves as a pk file-validating program (i.e., if pktype can read it, it's correct) and as an example of a pk-reading program for other software that wants to read pk files. The pk_file on the command line must be complete. Because the resolution is part of the extension, it would not make sense to append a default extension as is done with TeX or DVI-reading software. If no output_file is specified, the plain text translation is written to standard output. The output file gives a compact encoding of the packed encoding, using conventions described in the source code. Run lengths of black pixels alternate with parenthesized run lengths of white pixels, and brackets are used to indicate when a row should be repeated.","Process Name":"pktype","Link":"https:\/\/linux.die.net\/man\/1\/pktype"}},{"Process":{"Description":"SWI-Prolog is an ISO compatible Prolog compiler. It has a good collection of built-in predicates, a large set of which it shares with Edinburgh C-Prolog, Quintus Prolog and SICStus Prolog. Among its features are a very fast compiler, a Quintus-like module system, library autoloading, garbage collection, atom garbage collection, fast bi-directional C interface, true C++ interface, execution profiling and many more. Add-on packages provide graphics (XPCE), TCP\/IP, process controll, SGML\/XML\/HTML\/RDF support and many more. In addition, XPCE provides a development environment, consisting of hypertext help-system, source-level debugger, integrated editor and many navigation tools. This manual page only lists the commandline options. Full documentation is available on-line as well as in HTML and PDF format from the WWW home page.","Process Name":"pl","Link":"https:\/\/linux.die.net\/man\/1\/pl"}},{"Process":{"Description":"pl2pm is a tool to aid in the conversion of Perl4-style .pl library files to Perl5-style library modules. Usually, your old .pl file will still work fine and you should only use this tool if you plan to update your library to use some of the newer Perl 5 features, such as AutoLoading.","Process Name":"pl2pm","Link":"https:\/\/linux.die.net\/man\/1\/pl2pm"}},{"Process":{"Description":"Planets is a simple interactive program for playing with simulations of planetary systems. It is great teaching tool for understanding how gravitation works on a planetary level. The user interface is aimed at being simple enough for a fairly young kid can get some joy of it. There's also a special kid-mode aimed at very young children which grabs the focus and converts key banging into lots of random planets.","Process Name":"planets","Link":"https:\/\/linux.die.net\/man\/1\/planets"}},{"Process":{"Description":"planner is a Project Management application that supports Gantt charts, resource allocation and integration with other GNOME applications.","Process Name":"planner","Link":"https:\/\/linux.die.net\/man\/1\/planner"}},{"Process":{"Description":"","Process Name":"plantuml","Link":"https:\/\/linux.die.net\/man\/1\/plantuml"}},{"Process":{"Description":"plasmaengineexplorer is a graphical tool allowing developers to test Plasma data engines without writing a Plasma applet. If no options are given, it will start without any data engine selected. The required data engine can be selected from a drop-down list. Only installed data engines will be found. kbuildsycoca4 may need to be run for newly-installed data engines to be found.","Process Name":"plasmaengineexplorer","Link":"https:\/\/linux.die.net\/man\/1\/plasmaengineexplorer"}},{"Process":{"Description":"Introduction SoX reads and writes audio files in most popular formats and can optionally apply effects to them; it can combine multiple input sources, synthesise audio, and, on many systems, act as a general purpose audio player or a multi-track audio recorder. It also has limited ability to split the input in to multiple output files. Almost all SoX functionality is available using just the sox command, however, to simplify playing and recording audio, if SoX is invoked as play the output file is automatically set to be the default sound device and if invoked as rec the default sound device is used as an input source. Additionally, the soxi(1) command provides a convenient way to just query audio file header information. The heart of SoX is a library called libSoX. Those interested in extending SoX or using it in other programs should refer to the libSoX manual page: libsox(3). SoX is a command-line audio processing tool, particularly suited to making quick, simple edits and to batch processing. If you need an interactive, graphical audio editor, use audacity(1). The overall SoX processing chain can be summarised as follows: To show how this works in practise, here is a selection of examples of how SoX might be used. The simple sox recital.au recital.wav translates an audio file in Sun AU format to a Microsoft WAV file, whilst sox recital.au -r 12k -b 8 -c 1 recital.wav vol 0.7 dither performs the same format translation, but also changes the audio sampling rate & sample size, down-mixes to mono, and applies the vol and dither effects. sox -r 8k -u -b 8 -c 1 voice-memo.raw voice-memo.wav converts 'raw' (a.k.a. 'headerless') audio to a self-descibing file format, sox slow.aiff fixed.aiff speed 1.027 adjusts audio speed, sox short.au long.au longer.au concatenates two audio files, and sox -m music.mp3 voice.wav mixed.flac mixes together two audio files. play \"The Moonbeams\/Greatest\/*.ogg\" bass +3 plays a collection of audio files whilst applying a bass boosting effect, play -n -c1 synth sin %-12 sin %-9 sin %-5 sin %-2 fade q 0.1 1 0.1 plays a synthesised 'A minor seventh' chord with a pipe-organ sound, rec -c 2 test.aiff trim 0 10 records 10 seconds of stereo audio, and rec -M take1.aiff take1-dub.aiff records a new track in a multi-track recording. rec -r 44100 -2 -s -p silence 1 0.50 0.1% 1 10:00 0.1% | \\\n     sox -p song.ogg silence 1 0.50 0.1% 1 2.0 0.1% : \\\n     newfile : restart records a stream of audio such as LP\/cassette and splits in to multiple audio files at points with 2 seconds of silence. Also does not start recording until it detects audio is playing and stops after it sees 10 minutes of silence. N.B. Detailed explanations of how to use all SoX parameters, file formats, and effects can be found below in this manual, and in soxformat(7). File Format Types There are two types of audio file format that SoX can work with. The first is 'self-describing'; these formats include a header that completely describes the characteristics of the audio data that follows. The second type is 'headerless' (or 'raw data'); here, the audio data characteristics must be described using the SoX command line. The following four characteristics are sufficient to describe the format of audio data such that it can be processed with SoX: sample rate The sample rate in samples per second ('Hertz' or 'Hz'). For example, digital telephony traditionally uses a sample rate of 8000 Hz (8 kHz); audio Compact Discs use 44100 Hz (44.1 kHz); Digital Audio Tape and many computer systems use 48 kHz; professional audio systems typically use 96 or 192 kHz. sample size The number of bits used to store each sample. The most popular is 16-bit (two bytes); 8-bit (one byte) was popular in the early days of computer audio, and is still used in telephony; 24-bit (three bytes) is used, primarily as an intermediate format, in the professional audio arena. Other sizes are also used. data encoding The way in which each audio sample is represented (or 'encoded'). Some encodings have variants with different byte-orderings or bit-orderings; some 'compress' the audio data, i.e. the stored audio data takes up less space (i.e. disk-space or transmission band-width) than the other format parameters and the number of samples would imply. Commonly-used encoding types include floating-point, -law, ADPCM, signed-integer PCM, and FLAC. channels The number of audio channels contained in the file. One ('mono') and two ('stereo') are widely used. 'Surround sound' audio typically contains six or more channels. The term 'bit-rate' is sometimes used as an overall measure of an audio format and may incorporate elements of all of the above. Most self-describing formats also allow textual 'comments' to be embedded in the file that can be used to describe the audio in some way, e.g. for music, the title, the author, etc. One important use of audio file comments is to convey 'Replay Gain' information. SoX supports applying Replay Gain information, but not generating it. Note that by default, SoX copies input file comments to output files that support comments, so output files may contain Replay Gain information if some was present in the input file. In this case, if anything other than a simple format conversion was performed then the output file Replay Gain information is likely to be incorrect and so should be recalculated using a tool that supports this (not SoX). The soxi(1) command can be used to display information from audio file headers. Determining & Setting The File Format There are several mechanisms available for SoX to use to determine or set the format characteristics of an audio file. Depending on the circumstances, individual characteristics may be determined or set using different mechanisms. To determine the format of an input file, SoX will use, in order of precedence and as given or available: To set the output file format, SoX will use, in order of precedence and as given or available: For all files, SoX will exit with an error if the file type cannot be determined; command-line format options may need to be added or changed to resolve the problem. Play, Rec, & Default Audio Devices Some systems provide more than one type of (SoX-compatible) audio driver, e.g. ALSA & OSS, or SUNAU & AO. Systems can also have more than one audio device (a.k.a. 'sound card'). If more than one audio driver has been built-in to SoX, and the default selected by SoX when using rec or play is not the one that is wanted, then the AUDIODRIVER environment variable can be used to override the default. For example (on many systems): set AUDIODRIVER=oss\nplay ... For rec, play, and sox, the AUDIODEV environment variable can be used to override the default audio device; e.g. set AUDIODEV=\/dev\/dsp2\nplay ...\nsox ... -t oss or set AUDIODEV=hw:0\nplay ...\nsox ... -t alsa (Note that the syntax of the set command may vary from system to system.) When playing a file with a sample rate that is not supported by the audio output device, SoX will automatically invoke the rate effect to perform the necessary sample rate conversion. For compatibility with old hardware, here, the default rate quality level is set to 'low'; however, this can be changed if desired, by explicitly specifing the rate effect with a different quality level, e.g. play ... rate -m or by setting the environment varible PLAY_RATE_ARG to the desired quality option, e.g. set PLAY_RATE_ARG=-m\nplay ... (Note that the syntax of the set command may vary from system to system.) To help with setting a suitable recording level, SoX includes a simple VU meter which can be invoked (before making the actual recording) as follows: rec -n The recording level should be adjusted (using the system-provided mixer program, not SoX) so that the meter is at most occasionally full scale, and never 'in the red' (an exclamation mark is shown). Accuracy Many file formats that compress audio discard some of the audio signal information whilst doing so; converting to such a format then converting back again will not produce an exact copy of the original audio. This is the case for many formats used in telephony (e.g. A-law, GSM) where low signal bandwidth is more important than high audio fidelity, and for many formats used in portable music players (e.g. MP3, Vorbis) where adequate fidelity can be retained even with the large compression ratios that are needed to make portable players practical. Formats that discard audio signal information are called 'lossy', and formats that do not, 'lossless'. The term 'quality' is used as a measure of how closely the original audio signal can be reproduced when using a lossy format. Audio file conversion with SoX is lossless when it can be, i.e. when not using lossy compression, when not reducing the sampling rate or number of channels, and when the number of bits used in the destination format is not less than in the source format. E.g. converting from an 8-bit PCM format to a 16-bit PCM format is lossless but converting from an 8-bit PCM format to (8-bit) A-law isn't. N.B. SoX converts all audio files to an internal uncompressed format before performing any audio processing; this means that manipulating a file that is stored in a lossy format can cause further losses in audio fidelity. E.g. with sox long.mp3 short.mp3 trim 10 SoX first decompresses the input MP3 file, then applies the trim effect, and finally creates the output MP3 file by recompressing the audio - with a possible reduction in fidelity above that which occurred when the input file was created. Hence, if what is ultimately desired is lossily compressed audio, it is highly recommended to perform all audio processing using lossless file formats and then convert to the lossy format only at the final stage. N.B. Applying multiple effects with a single SoX invocation will, in general, produce more accurate results than those produced using multiple SoX invocations; hence this is also recommended. Clipping Clipping is distortion that occurs when an audio signal level (or 'volume') exceeds the range of the chosen representation. It is nearly always undesirable and so should usually be corrected by adjusting the level prior to the point at which clipping occurs. In SoX, clipping could occur, as you might expect, when using the vol effect to increase the audio volume, but could also occur with many other effects, when converting one format to another, and even when simply playing the audio. Playing an audio file often involves re-sampling, and processing by analogue components that can introduce a small DC offset and\/or amplification, all of which can produce distortion if the audio signal level was initially too close to the clipping point. For these reasons, it is usual to make sure that an audio file's signal level does not exceed around 70% of the maximum (linear) range available, as this will avoid the majority of clipping problems. SoX's stat effect can assist in determining the signal level in an audio file; the gain or vol effect can be used to prevent clipping, e.g. sox dull.au bright.au gain -6 treble +6 guarantees that the treble boost will not clip. If clipping occurs at any point during processing, then SoX will display a warning message to that effect. Input File Combining SoX's input combiner can be configured (see OPTIONS below) to combine multiple files using any of the following methods: 'concatenate', 'sequence', 'mix', 'mix-power', or 'merge'. The default method is 'sequence' for play, and 'concatenate' for rec and sox. For all methods other than 'sequence', multiple input files must have the same sampling rate; if necessary, separate SoX invocations can be used to make sampling rate adjustments prior to combining. If the 'concatenate' combining method is selected (usually, this will be by default) then the input files must also have the same number of channels. The audio from each input will be concatenated in the order given to form the output file. The 'sequence' combining method is selected automatically for play. It is similar to 'concatenate' in that the audio from each input file is sent serially to the output file, however here the output file may be closed and reopened at the corresponding transition between input files - this may be just what is needed when sending different types of audio to an output device, but is not generally useful when the output is a normal file. If either the 'mix' or 'mix-power' combining method is selected, then two or more input files must be given and will be mixed together to form the output file. The number of channels in each input file need not be the same, however, SoX will issue a warning if they are not and some channels in the output file will not contain audio from every input file. A mixed audio file cannot be un-mixed (without reference to the orignal input files). If the 'merge' combining method is selected, then two or more input files must be given and will be merged together to form the output file. The number of channels in each input file need not be the same. A merged audio file comprises all of the channels from all of the input files; un-merging is possible using multiple invocations of SoX with the remix effect. For example, two mono files could be merged to form one stereo file; the first and second mono files would become the left and right channels of the stereo file. When combining input files, SoX applies any specified effects (including, for example, the vol volume adjustment effect) after the audio has been combined; however, it is often useful to be able to set the volume of (i.e. 'balance') the inputs individually, before combining takes place. For all combining methods, input file volume adjustments can be made manually using the -v option (below) which can be given for one or more input files; if it is given for only some of the input files then the others receive no volume adjustment. In some circumstances, automatic volume adjustments may be applied (see below). The -V option (below) can be used to show the input file volume adjustments that have been selected (either manually or automatically). There are some special considerations that need to made when mixing input files: Unlike the other methods, 'mix' combining has the potential to cause clipping in the combiner if no balancing is performed. So here, if manual volume adjustments are not given, to ensure that clipping does not occur, SoX will automatically adjust the volume (amplitude) of each input signal by a factor of \/ n , where n is the number of input files. If this results in audio that is too quiet or otherwise unbalanced then the input file volumes can be set manually as described above; using the norm effect on the mix is another alternative. If mixed audio seems loud enough at some points through the mixed audio but too quiet in others, then dynamic-range compression should be applied to correct this - see the compand effect. With the 'mix-power' combine method, the mixed volume is appropriately equal to that of one of the input signals. This is achieved by balancing using a factor of \/ n instead of \/ n . Note that this balancing factor does not guarantee that no clipping will occur, however, in many cases, the number of clips will be low and the resultant distortion imperceptable. Output Files SoX's default behavior is to take one or more input files and write them to a single output file. This behavior can be changed by specifying the pseudo-effect 'newfile' within the effects list. SoX will then enter multiple output mode. In multiple output mode, a new file is created when the effects prior to the 'newfile' indicate they are done. The effects chain listed after 'newfile' is then started up and its output is saved to the new file. In multiple output mode, a unique number will automatically be appended to the end of all filenames. If the filename has an extension then the number is inserted before the extension. This behavior can be customized by placing a %n anywhere in the filename where the number should be substituted. An optional number can be placed after the % to indicate a minimum fixed width for the number. Multiple output mode is not very useful unless an effect that will stop the effects chain early is specified before the 'newfile'. If end of file is reached before the effects chain stops itself then no new file will be created as it would be empty. The following is an example of splitting the first 60 seconds of an input file in to two 30 second files and ignoring the rest. sox song.wav ringtone%1n.wav trim 0 30 : newfile : trim 0 30 Stopping SoX Usually SoX will complete its processing and exit automatically once it has read all available audio data from the input files. If desired, it can be terminated earlier by sending an interrupt signal to the process (usually by pressing the keyboard interrupt key which is usually Ctrl-C). This is a natural requirement in some circumstances, e.g. when using SoX to make a recording. Note that when using SoX to play multiple files, Ctrl-C behaves slightly differently: pressing it once causes SoX to skip to the next file; pressing it twice in quick succession causes SoX to exit. Another option to stop processing early is to use an effect that has a time period or sample count to determine the stopping point. The trim effect is an example of this. Once all effects chains have stopped then SoX will also stop.","Process Name":"play","Link":"https:\/\/linux.die.net\/man\/1\/play"}},{"Process":{"Description":"The playbucket program plays the bucket corresponding to the specified file. If no corresponding bucket exits, playbucket will create one. playbucket sets its close down mode to AuCloseDownRetainPermanent so the bucket is retained.","Process Name":"playbucket","Link":"https:\/\/linux.die.net\/man\/1\/playbucket"}},{"Process":{"Description":"playdv reads in DV-encoded video data from file and displays it on screen. -v, --version show playdv version number. --disable-audio skip audio decoding. --disable-video skip video decoding. -n, --num-frames= count stop playing after count frames. --dump-frames= pattern save a PPM image of each frame to an individual file. pattern determines the file names and may be given in printf-style taking one numeric argument that gets replaced with the current frame number. Like capture%05d.ppm for files capture00001.ppm, capture00002.ppm, etc. Use - to stream the frames to stdout. --no-mmap don't use mmap for reading (useful for pipes). -l, --loop-count= count loop playback count= times, 0 for infinite. Audio Output Options --audio-device= devicename target audio device; e.g. \/dev\/dsp, which is also the default. --audio-file= file send raw decoded audio stream to file, skipping audio ioctls. --audio-mix= (-16 .. 16) mixing level of 4 channel audio for 32KHz 12bit. 0 [default]. -16 selects second channel, 16 selects first channel. Video Output Options -d, --display=(0|1|2|3) method used to display video data on screen: 0=autoselect [default], 1=gtk, 2=Xv, 3=SDL. Xv is usually the fastest but requires XFree86 version 4.0 or higher with XVideo extensions. --aspect=(n|w|normal|wide) video display aspect ratio (for Xv only): n=normal 4:3, w=wide 16:9 . Not all window manager support resizing at fixed aspect ratio. If they do, resizing is done at fixed aspect ratio. --size=(10 .. 100) initial scaleing percentage (for Xv only): 10 <= n <= 100. Decoder Options -V, --video-system=(0|1|2|3) sets the video standard of the incoming DV data: 0=autoselect [default], 1=525\/60 4:1:1 (NTSC), 2=625\/50 4:2:0 (PAL,IEC 61834 DV), 3=625\/50 4:1:1 (PAL,SMPTE 314M DV). Autoselect usually works fine. Only use this option if you know what you are doing. Video Decode Options -q, --quality=(1|2|3) quality level of desired video decoding. The process of decoding DV data is split into several steps. Each additional step enhances output quality, but of course also slows down decoding. If your machine is too slow to keep up an interactive frame rate, you might want to decrease this number: 1=DC and no ACs, 2=DC and single-pass for ACs, 3=DC and multi-pass for ACs [default]. -m, --monochrome skip decoding of color blocks. Another way to speed up the decoding process. Audio Decode Options -f, --frequency=(0|1|2|3) frequency of audio data in the input stream: 0=autodetect [default], 1=32 kHz, 2=44.1 kHz, 3=48 kHz. -Q, --quantization=(0|1|2) dynamic range of audio data in the input stream: 0=autodetect [default], 1=12 bit, 2=16bit. -e, --emphasis=(0|1|2) first-order preemphasis of 50\/15 us: 0=autodetect [default], 1=on, 2=off. Help Options - ?, --help Show help message. Use this command to get a brief description of available options. --usage Display brief usage message.","Process Name":"playdv","Link":"https:\/\/linux.die.net\/man\/1\/playdv"}},{"Process":{"Description":"plaympeg is an MPEG audio and video player that uses the SDL MPEG Player Library. It can play back MPEG audio (layer 1, 2 and 3), MPEG video (MPEG-1) and MPEG system (audio and video combined) files. MPEG-2 video files (as found on DVDs) are not supported. The video player works best on a 16 bit color depth X11 display, it works on other color depths with reduced speed as well. You'll need a CPU with 300 MHz or more to play back an MPEG system stream with 25 frames per secons (fps) at full speed.","Process Name":"plaympeg","Link":"https:\/\/linux.die.net\/man\/1\/plaympeg"}},{"Process":{"Description":"Property lists in GNUstep are hierarchical lists of values or attribute-value pairs. Programmatically they are represented by instances of the NSString, NSData, NSArray, or NSDictionary (most common) class (which may contain other instances of such classes). These instances can be serialized as binary objects to form a persistent representation. In addition, there are two alternative human-readable representations. The first, utilized in NeXTstep and OpenStep, utilizes a text format with equals signs expressing attribute-value bindings and set braces expressing hierarchical organization. The second, often (uninformatively) referred to as \"plist\" format, is in XML and is used by Mac OS X. The tools described here are utilities for manipulating the various persistent property list representations as files. pldes filename(s) Converts a binary serialised property list (class instance) to a text representation. plget key Reads a text representation of a dictionary in property list format as standard input, extracts the string value held in that dictionary with the specified key, and writes the result to standard output. Multiple keys may be used to extract values from nested dictionaries. plser filename(s) Converts a text representation of a property list to a binary serialized representation. plmerge [ destination-file ] [ input-file(s) ] Merges text property lists into a single property list plparse filename(s) Checks that each file contains a valid text representation of a property list. pl2link input-file [ destination-file ] Produces a desktop link file for KDE and Gnome for the given text representation of a property list. pl -input [ input-file ] Takes the serialized plist represented by input-file and outputs it to standard output. pl -output [ destination-file ] Takes a plist from standard input and serializes it into destination-file.","Process Name":"pldes","Link":"https:\/\/linux.die.net\/man\/1\/pldes"}},{"Process":{"Description":"Options include: -h, --help Show this message -v Print the version -f= format Set the output format, includes \"default\", \"compressed\" -c Keep \/* *\/ comments in output -r Read from STDIN instead of input-file -w Watch input-file, and compile to output-file if it is changed -T Dump formatted parse tree -X Dump raw parse tree Site Search Library linux docs linux man pages page load time Toys world sunlight moon phase trace explorer","Process Name":"plessc","Link":"https:\/\/linux.die.net\/man\/1\/plessc"}},{"Process":{"Description":"plex is a program generator that is used to generate the Turbo Pascal source code for a lexical analyzer subroutine from the specification of an input language by a regular expression grammar. plex parses the source grammar contained in lex-file (with default suffix .l) and writes the constructed lexical analyzer subroutine to the specified output-file (with default suffix .pas); if no output file is specified, output goes to lex-file with new suffix .pas. If any errors are found during compilation, error messages are written to the list file (lex-file with new suffix .lst). The generated output file contains a lexical analyzer routine, yylex, implemented as: function yylex : Integer; This routine has to be called by your main program to execute the lexical analyzer. The return value of the yylex routine usually denotes the number of a token recognized by the lexical analyzer (see the return routine in the LexLib unit). At end-of-file the yylex routine normally returns 0. The code template for the yylex routine may be found in the yylex.cod file. This file is needed by TP Lex when it constructs the output file. It must be present either in the current directory or in the directory from which TP Lex was executed (TP Lex searches these directories in the indicated order). (NB: For the Linux\/Free Pascal version, the code template is searched in some directory defined at compile-time instead of the execution path, usually \/usr\/lib\/fpc\/lexyacc.) The TP Lex library (LexLib) unit is required by programs using Lex-generated lexical analyzers; you will therefore have to put an appropriate uses clause into your program or unit that contains the lexical analyzer routine. The LexLib unit also provides various useful utility routines; see the file lexlib.pas for further information.","Process Name":"plex","Link":"https:\/\/linux.die.net\/man\/1\/plex"}},{"Process":{"Description":"plink is a network connection tool supporting several protocols.","Process Name":"plink","Link":"https:\/\/linux.die.net\/man\/1\/plink"}},{"Process":{"Description":"PLIST is a program to list the contents of code output files generated by AS, a cross assembler for a variety of microprocessors and -controllers. PLIST takes only one argument: the name of the file to list. If [ name ] does not have an extension, the default extension '.p' will be added automatically. The output consists of a single line for each record in the file, listing the target processor, target address space, number of code\/data bytes, and start\/stop address. Note that the difference between the start and stop address need not equal the number of bytes, since there are target processors whose memory is not bytewise-organized. The records that specify entry address and file creator have a different layout and therefore have a little bit different look in PLIST's output. PLIST does not accept multiple file arguments; processing of several files must be done with individual calls.","Process Name":"plist","Link":"https:\/\/linux.die.net\/man\/1\/plist"}},{"Process":{"Description":"The utility plld is a front-end for the C-compiler and linker to create a stand-alone executable from a series of C\/C++ and Prolog input files. It extracts information from the SWI-Prolog executable pl, after which it scans the arguments and breaks them into several categories. It then calls the C-compiler to create an executable containing the user's C-code and the SWI-Prolog kernel. After this, it will call the development environment to create a Prolog saved state from the prolog files and finally it will create the target executable by concatenating the state to the emulator. See also qsave_program\/2 from the SWI-Prolog manual. Options -pl prolog Specifies the prolog version to use. The default is pl. This flag may be used to choose between different versions installed on your system, or to specify a modified version. A modified version should understands the flags -dump-runtime-variables -f file -F file -g goal -t toplevel . -help Shows options briefly -nostate Just relinks the kernel. The newly linked kernel can only function in the presence of the development system. Any supplied prolog sourcefiles are ignored, and so are the options -goal -toplevel -initfile. -class This is the preferred way to attach external modules to Prolog if dynamic loading is not supported on your system. -c Compile C or C++ source-files into object files. This turns plld into a replacement for the C or C++ compiler where proper options such as the location of the include directory are passed automatically to the compiler. -E Invoke the C preprocessor. Used to make plld a replacement for the C or C++ compiler. -shared Link C, C++ or object files into a shared object (DLL) that can be loaded by the load_foreign_library\/1 predicate. If used with -c it sets the proper options to compile a C or C++ file ready for linking into a shared object. -embed-shared Embed SWI-Prolog into a DLL\/Shared object rather than an executable. See the reference manual for details. -dll Windows only Same as -embed-shared Backward compatibility. -F base By default, none is passed to the pl command to create the saved state. Using -F xpce you can specify loading xpce.rc, making XPCE available to the saved state. -goal goal The goal that is initially executed when the toplevel is started using PL_toplevel(). E.i. the default. -g flag for the new executable. -toplevel goal The goal that is executed as the main toplevel goal. E.i. the default. -t flag for the new executable. -initfile file The file that is loaded by the toplevel. E.i. the default. -f flag for the new executable. -class {runtime,kernel,development} Set the save-class of the Prolog saved-state that is created. If runtime (default), the resulting system leave interpretation of all arguments to the application. If kernel all predicates will be locked for the tracer. Finally, if development the state is saved 'as-is' and the resulting system processes options just as the basic SWI-Prolog executable does. See also qsave_program\/2 in the SWI-Prolog reference manual. -v Verbose operation. This echos the commands before executing them. Note that some commands are printed as shell commands, but actually executed by plld itself for compatibility with the Win32 platforms. -f Fake operation. Together with -v this prints the commands that need to be executed without actually doing anything. -E cppargument ... If the first option is -E, all subsequent options are appended and handed to the program selected by SWI-Prolog configure to run cpp. -o file Specifies the name of the final executable. The default is a.out. -cc C-compiler Specify the compiler to use for *.c files. Default is the compiler used to compile SWI-Prolog itself, as read from the feature c_cc. -c++ C++-compiler Specify the compiler to use for C++ input files. If the C-compiler is gcc this is g++, otherwise c++ is assumed. -ld linker Specifies the linker to use. Default is the C-compiler. On Win32 platforms, the default is link.exe. -l library Specifies a C-library for linking the application. By default, -lpl ( -lplmt if pl supports threading) as well as the libraries required by the SWI-Prolog kernel will be passed to the C-compiler. -L library-directory Specifies an additional library directory for the C-compiler. By default, the runtime directory for the current architecture is passed. -g|-I*|-D*|-U*|-O*|-W* Passed to the compiler as c-flags. By default, the SWI-Prolog include directory is passed as additional include directory. The following -D flags are added by plld: -D__SWI_PROLOG__ and -D__SWI_EMBEDDED__. -pl-options* Specify additional options for pl. The first character following -pl-options determines the option-separator. The remainder of the argument is split using this separator and the parts are added to the option list for Prolog. See also -cc-options and -ld-options -ld-options* Additional options passed to the linker. For example: -ld-options,-Bstatic -cc-options* Additional options passed to both C- and C++-compiler. *.o Passed as input files to the linker. *.c Compiled using the C-compiler, after which the object-file is passed to the linker. The object file is deleted at cleanup. *.cc|*.C|*.cxx|*.cpp Compiled using the C++-compiler, after which the object-file is passed to the linker. The object file is deleted at cleanup. *.pl|*.qlf Passed as Prolog input files","Process Name":"plld","Link":"https:\/\/linux.die.net\/man\/1\/plld"}},{"Process":{"Description":"This utility mainly serves as a quick check for what does and what does not work in Makefile::Parser. Please don't use it in production.","Process Name":"plmake","Link":"https:\/\/linux.die.net\/man\/1\/plmake"}},{"Process":{"Description":"plot translates files in GNU metafile format to other graphics formats, or displays them on an X Window System display. GNU metafile format is a device-independent format for the storage of graphic data. It is the default output format of the programs graph(1), pic2plot(1), tek2plot(1), and plotfont(1), and is further documented in plot(5), since it is an enhanced version of the traditional plot(5) format found on non-GNU systems. It can also be produced by the GNU libplot 2-D graphics export library (see plot(3)). The output format is specified with the -T option. The possible output formats and display types are the same as those supported by graph(1), plotfont(1), pic2plot(1), and tek2plot(1). If an output file is produced, it is written to standard output. Options and file names may be interspersed on the command line, but the options are processed before the file names are read. If -- is seen, it is interpreted as the end of the options. If no file names are specified, or the file name - is encountered, the standard input is read.","Process Name":"plot","Link":"https:\/\/linux.die.net\/man\/1\/plot"}},{"Process":{"Description":"plotfont produces a character map for any font that is supported by the plotting utilities, which include graph(1), plot(1), pic2plot(1), tek2plot(1), and the GNU libplot 2-D graphics export library (see plot(3)). Which fonts are supported depends on the output format, which is specified by the -T option. A listing of the fonts available in any specified output format may be obtained with the --help-fonts option (see below). The character map, or maps, will be written to standard output in the specified format. For example, the Times-Roman font is available when producing Postscript output. The command plotfont -T ps Times-Roman > charmap.ps will yield a character map of the Times-Roman font, in a Postscript format that can be viewed or edited with the idraw(1) drawing editor. The Times-Roman font is also available when producing Fig output, which can be viewed or edited with the xfig(1) drawing editor. The command plotfont -T fig Times-Roman > charmap.fig will yield the same character map, but in Fig format rather than in Postscript format. As another example, the Univers font is available when producing PCL 5 output. The command plotfont -T pcl Univers > charmap.pcl will produce a character map of the Univers font, in PCL 5 format. When producing output for the X Window System, i.e., for a popped-up window, any scalable X Window System font that has an XLFD (i.e., X Logical Font Description) name is supported. For example, the command plotfont -T X utopia-medium-r-normal will pop up a window, and draw a character map of the Utopia-Regular font. \"utopia-medium-r-normal\" is a truncated version of the Utopia-Regular font's XLFD name. The Utopia-Regular font is available on most X Window System displays.","Process Name":"plotfont","Link":"https:\/\/linux.die.net\/man\/1\/plotfont"}},{"Process":{"Description":"plowdel is a command-line tool designed for deleting files on file-sharing websites. It acts like a web browser, retrieving pages and filling HTML forms. Currently supported hosting sites list is available in README file. Some sites may require authentication for deleting files. See specific module options below.","Process Name":"plowdel","Link":"https:\/\/linux.die.net\/man\/1\/plowdel"}},{"Process":{"Description":"plowdown is a command-line tool designed for automatic download on file-sharing websites. It acts like a web browser, retrieving pages and filling HTML forms (including captchas). Currently supported hosting sites list is available in README file.","Process Name":"plowdown","Link":"https:\/\/linux.die.net\/man\/1\/plowdown"}},{"Process":{"Description":"plowlist is a command-line tool designed for listing links (files) on file-sharing websites. Provided links can be downloaded with plowdown(1). Currently supported hosting sites list is available in README file.","Process Name":"plowlist","Link":"https:\/\/linux.die.net\/man\/1\/plowlist"}},{"Process":{"Description":"plowprobe is a command-line tool designed for retrieving metadata from file-sharing download links. Information are printed on stdout (only alive links). Provided links can also be downloaded with plowdown(1). Currently supported hosting sites list is available in README file.","Process Name":"plowprobe","Link":"https:\/\/linux.die.net\/man\/1\/plowprobe"}},{"Process":{"Description":"plowup is a command-line tool designed for automatic upload on file-sharing websites. It acts like a web browser, retrieving pages and filling HTML forms. Currently supported hosting sites list is available in README file. Anonymous upload is not allowed by all sites, some of them may require authentication. See specific module options below.","Process Name":"plowup","Link":"https:\/\/linux.die.net\/man\/1\/plowup"}},{"Process":{"Description":"The utility plrc allows for examining and modifying the SWI-Prolog resource data associated with a SWI-Prolog save-state or runtime executable as created using SWI-Prolog's predicate qsave_program\/[1,2]. Options l archive[member ...] List the contents of the resource archive. If no members are specified, the entire content is listed. x archive [member ...] Extract members from the archive into the current directory. If no members are specified, the entire content is extracted. Each member is extracted into a file with the same name as the archive member. a archive [member ...] Add files to the archive. If the archive already contains a member with the same name, the contents is replaced. Anywhere in the sequence of members, the options --class= class and --encoding= encoding may appear. They affect the class and encoding of subsequent files. The initial class is data and encoding none. d archive member ... Delete members from the archive.","Process Name":"plrc","Link":"https:\/\/linux.die.net\/man\/1\/plrc"}},{"Process":{"Description":"pls list the contents of a directory on a device connected through SynCE. Forward slashes ('\/') on the command line are converted to backward slashes ('\\'). File attributes A Archive C Compressed D Directory H Hidden I In ROM M ROM module (can only be executed, not read!) N Normal R Read-only S System T Temporary","Process Name":"pls","Link":"https:\/\/linux.die.net\/man\/1\/pls"}},{"Process":{"Description":"This manual page documents briefly the plserver, command. plserver is just a front-end to the pltkMain() function. Structured along the preferred lines for extended wish'es. It typically runs as a child process from the PLplot TK driver to render output. Can use either TK send or Tcl-DP RPC for communication, depending on how it is invoked. Note that plserver can be used the same way as wish or dpwish, as it contains the functionality of each of these (except the -notk Tcl-DP command-line option is not supported).","Process Name":"plserver","Link":"https:\/\/linux.die.net\/man\/1\/plserver"}},{"Process":{"Description":"This manual page documents briefly the pltcl command. pltcl is the main program for Tcl interface to PLplot. Allows interpretive execution of plotting primitives without regard to output driver. It is essentially an extended tclsh, with knowledge of the complete PLplot Tcl API.","Process Name":"pltcl","Link":"https:\/\/linux.die.net\/man\/1\/pltcl"}},{"Process":{"Description":"This manual page documents briefly the pltek command. pltek is a program that review a Tektronix vector file whose name is given as argument.","Process Name":"pltek","Link":"https:\/\/linux.die.net\/man\/1\/pltek"}},{"Process":{"Description":"This manual page is not meant to be exhaustive. The complete documentation for this version of TeX can be found in the info file or manual Web2C: A TeX implementation. The pltotf program translates a (human-oriented) Web property list file to a (program-oriented) TeX font metric file. Thus, after editing the property list file, a TFM file can be generated for use with, for example, tex(1). Both the pl_file_name and the tfm_file_name must be complete; no adding of default extensions or path searching is done.","Process Name":"pltotf","Link":"https:\/\/linux.die.net\/man\/1\/pltotf"}},{"Process":{"Description":"plugctl is a program to get or set the value of a plug's attribute. plug is one of oMPR, iMPR, oPCR[n], or iPCR[n] (case insensitive). Please supply a numerical index for [n]. This manual page was written for the Debian distribution because the original program does not have a manual page.","Process Name":"plugctl","Link":"https:\/\/linux.die.net\/man\/1\/plugctl"}},{"Process":{"Description":"This manual page documents briefly the plugreport and was written for the Debian distribution because the original program does not have a manual page. plugreport is a program to read all MPR\/PCR registers from all devices and report them.","Process Name":"plugreport","Link":"https:\/\/linux.die.net\/man\/1\/plugreport"}},{"Process":{"Description":"This program is used to show what modules a program would load at compile time via \"use\". Because this installs an at-exit handler and then uses Perl's -c flag for compile only, it will not find modules loaded at run-time. Use the Devel::Loaded module for that.","Process Name":"plxload","Link":"https:\/\/linux.die.net\/man\/1\/plxload"}},{"Process":{"Description":"powerman provides power management in a data center or compute cluster environment. It performs operations such as power on, power off, and power cycle via remote power controller (RPC) devices. Target hostnames are mapped to plugs on RPC devices in powerman.conf(5).","Process Name":"pm","Link":"https:\/\/linux.die.net\/man\/1\/pm"}},{"Process":{"Description":"This manual page documents briefly the pm-is-supported command. The intended purpose of pm-is-supported is to find out which power management modes are supported by the system. hald(8) will call it to do just that.","Process Name":"pm-is-supported","Link":"https:\/\/linux.die.net\/man\/1\/pm-is-supported"}},{"Process":{"Description":"This manual page documents briefly the pm-pmu command. pm-pmu is a command line program to test whether the computer is running on line power","Process Name":"pm-pmu","Link":"https:\/\/linux.die.net\/man\/1\/pm-pmu"}},{"Process":{"Description":"This tool reports the locations of installed perl modules. By default it lists the location of each specified module that would be loaded by require.","Process Name":"pm_which","Link":"https:\/\/linux.die.net\/man\/1\/pm_which"}},{"Process":{"Description":"A collection of one or more Performance Co-Pilot (PCP) archive logs may be combined with a control file to produce a PCP archive folio. Archive folios are created using either mkaf(1) or the interactive ''record mode'' services of PCP clients like pmchart(1). pmafm provides a number of services that may be used to process folios. In particular, it provides support for execution of PCP tools using one or more of the component archive logs within an archive folio. The target folio is identified by the folio control file folioname. The syntax for a folio control file is described in mkaf(1). If present, the command and arguments following folioname are interpreted and executed as a single command, otherwise commands are read from standard input. The following commands are supported. archives Subsequent commands apply to all archives in the folio. archives N[,...] Archives within a folio are numbered 1, 2, etc. Subsequent commands are restricted to apply only to the designated archives. archives name[,...] Archives within a folio have unique names. Subsequent commands are restricted to apply only to the designated archives. check Validate the presence and format of each file in the folio and the component archives. help A brief reminder of the command syntax. ? is a synonym for help. hosts Subsequent commands apply to all archives in the folio. hosts hostname[,...] Subsequent commands are restricted to apply only to those archives that match the designated hostnames. list [ verbose] Display the contents of the folio. By default the control header and the ordinal number, hostname and archive base name for each archive in the folio. The verbose option causes pmafm to dump the label record from each archive using pmdumplog -l. The first named archive in the folio is assumed to be associated with the default host for any tool that tries to replay multiple archives from the folio. quit Exit pmafm. remove Echo on standard output the sh(1) commands required to remove all of the physical files associated with this archive folio. repeat tool [ arg ...] Execute the known PCP tool once per selected archive. For example, the command repeat pmval -t60 kernel.all.load would run pmval(1) once per archive, with an appropriate -a argument. replay Some archive folios are created by tools (e.g. pmchart(1)) that provide sufficient information to allow all of the information in all of the archives of a folio to be replayed. [ run] tool [ arg ...] Execute the known PCP tool on the selected archives. Some PCP tools are able to process multiple concurrent archives, and in this case the tool is run once with the list of all selected archives passed via a -a argument. Otherwise, this command is synonymous with repeat. selections Display those archives that would be selected for processing with a repeat, replay or run command. The restrictions via any hosts and archives commands are conjuncted. These restrictions serve to limit the specific archives processed in the subsequent repeat, replay, run and selections commands. By default, all archives are selected. Keywords in commands may be abbreviated provided no ambiguity is introduced, e.g. help, hel and he are synonymous, but h is ambiguous.","Process Name":"pmafm","Link":"https:\/\/linux.die.net\/man\/1\/pmafm"}},{"Process":{"Description":"Performs the same function as make(1) but is written entirely in perl. A subset of GNU make extensions is supported. For details see Make for the underlying perl module.","Process Name":"pmake","Link":"https:\/\/linux.die.net\/man\/1\/pmake"}},{"Process":{"Description":"This program runs through all your installed modules and tells you what they're for and what version number they are at. The following options are honored: -v give debug info -w warn about missing descriptions on modules -a include relative paths -s sort output within each directory","Process Name":"pmall","Link":"https:\/\/linux.die.net\/man\/1\/pmall"}},{"Process":{"Description":"Send a module's pod through pod2text and your pager. This is mostly here for people too lazy to type $ pod2text `pmpath CGI` | $PAGER","Process Name":"pman","Link":"https:\/\/linux.die.net\/man\/1\/pman"}},{"Process":{"Description":"The pmap command reports the memory map of a process or processes.","Process Name":"pmap","Link":"https:\/\/linux.die.net\/man\/1\/pmap"}},{"Process":{"Description":"Given a module name, figure out the path name and send that to the user's pager. $ pmcat CGI This works also on alternate installed versions of Perl: $ oldperl -S pmcat strict\n\n$ filsperl -S pmcat Threads This command is mostly here for people too lazy to type $ more `pmpath CGI`","Process Name":"pmcat","Link":"https:\/\/linux.die.net\/man\/1\/pmcat"}},{"Process":{"Description":"pmcd is the collector used by the Performance Co-Pilot (see pcpintro(1)) to gather performance metrics on a system. As a rule, there must be an instance of pmcd running on a system for any performance metrics to be available to the PCP. pmcd accepts connections from client applications running either on the same machine or remotely and provides them with metrics and other related information from the machine that pmcd is executing on. pmcd delegates most of this request servicing to a collection of Performance Metrics Domain Agents (or just agents), where each agent is responsible for a particular group of metrics, known as the domain of the agent. For example the environ agent is responsible for reporting information relating to the environment of a Challenge system, such as the cabinet temperature and voltage levels of the power supply. The agents may be processes started by pmcd, independent processes or Dynamic Shared Objects (DSOs, see dso(5)) attached to pmcd's address space. The configuration section below describes how connections to agents are specified. The options to pmcd are as follows. -f By default pmcd is started as a daemon. The -f option indicates that it should run in the foreground. This is most useful when trying to diagnose problems with misbehaving agents. -i ipaddress This option is usually only used on hosts with more than one network interface. If no -i options are specified pmcd accepts connections made to any of its host's IP (Internet Protocol) addresses. The -i option is used to specify explicitly an IP address that connections should be accepted on. ipaddress should be in the standard dotted form (e.g. 100.23.45.6). The -i option may be used multiple times to define a list of IP addresses. Connections made to any other IP addresses the host has will be refused. This can be used to limit connections to one network interface if the host is a network gateway. It is also useful if the host takes over the IP address of another host that has failed. In such a situation only the standard IP addresses of the host should be given (not the ones inherited from the failed host). This allows PCP applications to determine that a host has failed, rather than connecting to the host that has assumed the identity of the failed host. -l logfile By default a log file named pmcd.log is written in the directory $PCP_LOG_DIR\/pmcd. The -l option causes the log file to be written to logfile instead of the default. If the log file cannot be created or is not writable, output is written to the standard error instead. -L bytes PDUs received by pmcd from monitoring clients are restricted to a maximum size of 65536 bytes by default to defend against Denial of Service attacks. The -L option may be used to change the maximum incoming PDU size. -n pmnsfile Normally pmcd loads the default Performance Metrics Name Space (PMNS) from $PCP_VAR_DIR\/pmns\/root, however if the -n option is specified an alternative namespace is loaded from the file pmnsfile. -N pmnsfile Same function as -n, except for the handling of duplicate Performance Metric Identifiers (PMIDs) in pmnsfile - duplicates are allowed with -N they are not allowed with -n. -q timeout The pmcd to agent version exchange protocol (new in PCP 2.0 - introduced to provide backward compatibility) uses this timeout to specify how long pmcd should wait before assuming that no version response is coming from an agent. If this timeout is reached, the agent is assumed to be an agent which does not understand the PCP 2.0 protocol. The default timeout interval is five seconds, but the -q option allows an alternative timeout interval (which must be greater than zero) to be specified. The unit of time is seconds. -t timeout To prevent misbehaving clients or agents from hanging the entire Performance Metrics Collection System (PMCS), pmcd uses timeouts on PDU exchanges with clients and agents running as processes. By default the timeout interval is five seconds. The -t option allows an alternative timeout interval in seconds to be specified. If timeout is zero, timeouts are turned off. It is almost impossible to use the debugger interactively on an agent unless timeouts have been turned off for its \"parent\" pmcd. Once pmcd is running, the timeout may be dynamically modified by storing an integer value (the timeout in seconds) into the metric pmcd.control.timeout via pmstore(1). -T traceflag To assist with error diagnosis for agents and\/or clients of pmcd that are not behaving correctly, an internal event tracing mechanism is supported within pmcd. The value of traceflag is interpreted as a bit field with the following control functions: 1 enable client connection tracing 2 enable PDU tracing 256 unbuffered event tracing By default, event tracing is buffered using a circular buffer that is over-written as new events are recorded. The default buffer size holds the last 20 events, although this number may be over-ridden by using pmstore(1) to modify the metric pmcd.control.tracebufs. Similarly once pmcd is running, the event tracing control may be dynamically modified by storing 1 (enable) or 0 (disable) into the metrics pmcd.control.traceconn, pmcd.control.tracepdu and pmcd.control.tracenobuf. These metrics map to the bit fields associated with the traceflag argument for the -T option. When operating in buffered mode, the event trace buffer will be dumped whenever an agent connection is terminated by pmcd, or when any value is stored into the metric pmcd.control.dumptrace via pmstore(1). In unbuffered mode, every event will be reported when it occurs. -x file Before the pmcd logfile can be opened, pmcd may encounter a fatal error which prevents it from starting. By default, the output describing this error is sent to \/dev\/tty but it may redirected to file. If a PDU exchange with an agent times out, the agent has violated the requirement that it delivers metrics with little or no delay. This is deemed a protocol failure and the agent is disconnected from pmcd. Any subsequent requests for information from the agent will fail with a status indicating that there is no agent to provide it. It is possible to specify host-level access control to pmcd. This allows one to prevent users from certain hosts from accessing the metrics provided by pmcd and is described in more detail in the Section on ACCESS CONTROL below.","Process Name":"pmcd","Link":"https:\/\/linux.die.net\/man\/1\/pmcd"}},{"Process":{"Description":"pmcd_wait waits for the Performance Metrics Collector Daemon (PMCD) to be running and accepting client connections. Unless directed to another host by the -h option, pmcd_wait will try to contact pmcd(1) on the local host. pmcd_wait will timeout and abandon the attempt to connect to pmcd after 60 seconds. This default timeout interval may be changed using the -t option, where the interval argument follows the syntax described in pcpintro(1) and in the simplest form may be an unsigned integer (the implied units in this case are seconds). On successful connection to pmcd an exit status of zero is returned. If an error or timeout occurs, then a non-zero exit status is returned as described below. The other options are as follows: -v This option turns the verbose mode on. With the verbose mode off (which is the default), no output will be generated. With verbose mode on, error messages will be output on stderr.","Process Name":"pmcd_wait","Link":"https:\/\/linux.die.net\/man\/1\/pmcd_wait"}},{"Process":{"Description":"pmchart is a graphical utility that plots performance metrics values available through the facilities of the Performance Co-Pilot (PCP). Multiple charts can be displayed simultaneously, either aligned on the unified time axis (X-axis), and through the use of multiple interface Tabs. Metric values can be sourced from one or more live hosts (simultaneously). Alternatively, one or more PCP archives can be used as a source of historical data. See pcpintro(1) for an in-depth discussion of the capabilities of the PCP framework, many of which are used by pmchart. Many aspects of the behaviour of pmchart can be customised through the interface. In particular, the use of \"views\" (refer to the section describing VIEWS later in this document) allows predefined sets of metrics and charting parameters like colors, scaling, titles, legends, and so on to be stored for later use, or use with different hosts and archives. In addition, the Preferences dialog allows customisations to the rest of the pmchart user interface to be saved and restored between different invocations of the tool. This allows the default background color, highlight color, contents and location of the toolbar, and many other aspects to be configured. pmchart makes extensive use of the pmtime(1) utility for time control, refer to the pmtime manual page for further details of its operation. Options which control the default source, timing and layout of the pmchart window are as follows: -a Performance metric values are retrieved from the Performance Co-Pilot (PCP) archive log file identified by the base name archive, by default. The initial Tab created will be an archive mode Tab. Multiple -a options can be presented, and the list of archives is used for sourcing metric values. Any sources listed on the command line are assumed to be archives if this option is used. -c configfile specifies an initial view to load, using the default source of metrics. Multiple -c views can be specified, and they will all be opened in the default Tab with the default source of metrics. -C Used with -c, the view(s) are parsed, any errors are reported, and the tool exits. This is primarily intended for testing purposes. If a second -C option is presented, pmchart also connects to pmcd(1) to check the semantics of metrics. -g Generate image with the specified geometry (width and height). This option is only useful when used in conjunction with the -o option for generating an output image. The geometry argument takes the form \"WxH\" (e.g. 240x120). -h Current performance metric values are retrieved from the nominated host machine by default. Multiple -h options can be presented, and the list of hosts is used for sourcing metric values. Any sources listed on the command line are assumed to be hosts if this option is used. -o Generate an image file named outfile, and then exit. This is most useful when run with an archive and one or more views. The generated image will be in the format specified as the file extension (automatically determined from outfile). If no extension can be determined, then the GIF format is used and the generated file is named with this extension. The supported image file formats include: bmp, jpeg, jpg, png, ppm, tif, tiff, xbm, and xpm. -p port number for connection to an existing pmtime time control process. -s Specifies the number of samples that will be retained before discarding old data (replaced by new values at the current time position). This value can subsequently be modified through the Edit Tab dialog. -t Sets the inital update interval to something other than the default 1 second. The interval argument follows the syntax described in pcpintro(1), and in the simplest form may be an unsigned integer (the implied units in this case are seconds). -v Sets the inital visible samples that will be displayed in all charts in the default Tab. This value must be less than or equal to the total number of samples retained (the -s value). -Z By default, pmtime reports the time of day according to the local timezone on the system where pmchart is run. The -Z option changes the timezone to timezone in the format of the environment variable TZ as described in environ(5). -z Change the reporting timezone to the local timezone at the host that is the source of the performance metrics, as identified via either the -h or -a options. The -S, -T, -O and -A options may be used to define a time window to restrict the samples retrieved, set an initial origin within the time window, or specify a \"natural\" alignment of the sample times; refer to pcpintro(1) for a complete description of these options.","Process Name":"pmchart","Link":"https:\/\/linux.die.net\/man\/1\/pmchart"}},{"Process":{"Description":"pmclient is a simple client that uses the Performance Metrics Application Programming Interface (PMAPI) to report some high-level system performance metrics. The real value of pmclient is as a sample client using the PMAPI, and to this end the source code is shipped on both Irix, where it is included in the pcp.sw.demo images of the Performance Co-Pilot (PCP) product (see pcpintro(1)), and on Linux, where it is included into the PCP Source RPM. Normally pmclient operates on the distributed Performance Metrics Name Space (PMNS), however if the -n option is specified an alternative local PMNS is loaded from the file pmnsfile. Unless directed to another host by the -h option, or to an archive by the -a option, pmclient will contact the Performance Metrics Collector Daemon (PMCD) on the local host to obtain the required information. The -a and -h options are mutually exclusive. By default, pmclient reports the time of day according to the local timezone on the system where pmclient is run. The -Z option changes the timezone to timezone in the format of the environment variable TZ as described in environ(5). The -z option changes the timezone to the local timezone at the host that is the source of the performance metrics, as identified via either the -h or -a options. Other options control the specific information to be reported. -p The default behavior for replaying an archive, is to replay at full speed. The -p option may be used in conjunction with an archive, to request that the prevailing real-time delay be applied between samples (see -t) to effect a pause. -S numsec The -S option may be used in conjunction with an archive to request that display start at the time numsec seconds from the start of the archive. -s samples The argument samples defines the number of samples to be retrieved and reported. If samples is 0 or -s is not specified, pmclient will sample and report continuously (in real time mode) or until the end of the PCP archive (in archive mode). -t interval The default update interval may be set to something other than the default 5 seconds. The interval argument follows the syntax described in pcpintro(1), and in the simplest form may be an unsigned integer (the implied units in this case are seconds). The output from pmclient is directed to standard output, and lists + Aggregate CPU utilization, in the range 0 to 1. + If the system has more than 1 CPU, the ordinal number of the busiest CPU, in the range 0 to ... + If the system has more than 1 CPU, the CPU utilization for the busiest CPU. + Real free memory in Mbytes. + Aggregate physical disk I\/O operations per second (IOPS). + Load average over the last 1 minute and over the last 15 minutes.","Process Name":"pmclient","Link":"https:\/\/linux.die.net\/man\/1\/pmclient"}},{"Process":{"Description":"pmcollectl is a system-level performance monitoring utility that records or displays specific operating system data for one or more sets of subsystems. Any of the subsystems (such as CPU, Disks, Memory or Sockets) can be included or excluded from data collection. Data can either be displayed immediately to a terminal, or stored in files for retrospective analysis. pmcollectl is a python(1) script providing much of the functionality available from the collectl(1) Linux utility (which happens to be written in perl(1)). It makes use of the Performance Co-Pilot (PCP) toolkit to simplify its implementation, as well as provide more of the collectl functionality on platforms other than Linux. pmcollectl has two primary modes of operation: 1. Record Mode (-f or --filename option) which reads data from a live system and writes output to a file or displays it on a terminal. 2. Playback Mode (-p or --playback option) which reads data from one or more PCP archive files and displays output on a terminal. Note that these files are not raw collectl format data, rather they are archives created by the pmlogger(1) utility (possibly indirectly, through use of the -f option to pmcollectl).","Process Name":"pmcollectl","Link":"https:\/\/linux.die.net\/man\/1\/pmcollectl"}},{"Process":{"Description":"pmconfig displays the values for some or all configuration parameters of the local Performance Co-Pilot toolkit installation. It is primarily used in conjunction with the $PCP_DIR environment variable to setup scripts running under the Windows operating system, where the filesystem hierarcy is very different to the of Linux\/UNIX-based operating systems.","Process Name":"pmconfig","Link":"https:\/\/linux.die.net\/man\/1\/pmconfig"}},{"Process":{"Description":"pmquery provides a command-line-option compatible implementation of the xconfirm and xmessage tools, using a look-and-feel that is consistent with pmchart. Several extensions to the functionality of the original tools have been made, in order to improve their specific utility for pmchart, but wherever possible the original semantics remain. pmconfirm displays a line of text for each -t argument specified (or a file when the -file argument is used), and a button for each -b argument specified. When one of the buttons is pressed, the label of that button is written to pmquery's standard output. This provides a means of communication\/feedback from within shell scripts and a means to display useful information to a user from an application. pmmessage displays a window containing a message from the command line, a file, or standard input. It additionally allows buttons to be associated with an exit status, and only optionally will write the label of the button to standard output. pmquery extends the above tools to additionally support limited user input, as free form text. In this -input mode, any text entered will be output when the default button is pressed. A default text can be entered using the same mechanisms as the other tools. Command line options are available to specify font style, frame style, modality and one of several different icons to be presented for tailored visual feedback to the user. -c or -center Center the window on the display. -nearmouse Pop up the window near the mouse cursor. -b button-name Displays a button with the label button-name. If button-name is the empty string, the button in that position is not displayed. If no -b arguments are present, the default is a button with the label Continue. The exit status associated with button-name is zero. -B button-name Displays a button with the label button-name and specifies it as the button to be activated when enter is pressed. The exit status associated with button-name is zero. -buttons button,button,... This option will create one button for each comma-separated button argument. Each button consists of a label optionally followed by a colon and an exit value. The exit value will be returned if that button is selected. The default exit value is 100 plus the button number. Buttons are numbered from the left starting with one. -default label Defines the button with a matching label to be the default. If not specified there is no default. The corresponding resource is defaultButton. Pressing Return anywhere in the xmessage window will activate the default button. The default button has a wider border than the others. -t message Displays message. Any number of strings can be listed on the command line (each must be preceded with the -t option). -file filename Displays the file filename. All -t options will be ignored. A filename of ' -' reads from standard input. -icon icontype Displays the icon icontype where icontype is one of: info, error, question, warning, critical. action is also accepted as a synonym for error for backward compatibility. pmquery introduces the additional archive and host icon types as well as the original xconfirm types listed earlier. -font fontname Use fontname as the font. This option is only available when using the X Window System. -header string Use string as the window title. -print This causes the program to write the label of the button pressed to standard output. It is the default behaviour for pmconfirm and pmquery. -noprint This causes the program to not write the label of the button pressed to standard output. It is the default behaviour for pmmessage. -geometry geometry-string This provides xconfirm with an X-compatible geometry string specification. This option is only available when using the X Window System. -useslider When displaying a file, always use a slider instead of determining automatically whether a slider is necessary. -noslider Do not create a slider, and clip text to the window size, instead of determining automatically whether a slider is necessary.. -noframe Do not display a frame around the contents. -exclusive Grab the keyboard\/pointer and do not allow further input until a button is pressed. -timeout secs Exit with status 0 after secs seconds if the user has not clicked on a button yet. The corresponding resource is timeout.","Process Name":"pmconfirm","Link":"https:\/\/linux.die.net\/man\/1\/pmconfirm"}},{"Process":{"Description":"pmcpp provides a very simple pre-processor for manipulating Performance Metric Name Space (PMNS) files for the Performance Co-Pilot (PCP). It is most commonly used internally to process the PMNS file(s) after pmloadnamespace(3) or pmloadasciinamespace(3) is called. Input lines are read from infile (or standard input if infile is not specified), processed and written to standard output. All C-style comments of the form \/* ... *\/ are stripped from the input stream. There are no predefined macros for pmcpp although macros may be defined on the command line using the -D option, where name and value must follow the same rules as described below for the #define directive. pmcpp accepts the following directives in the input stream (like cpp(1)): * #include \"filename\" or #include < filename > In either case the directory search path for filename tries filename first, then the directory for the command line infile (if any), followed by the $PCP_VAR_DIR\/pmns directory. #include directives may be nested, up to a maximum depth of 5. * #define name value Defines a value for the macro name which must be a valid C-style name, so leading alphabetic or ''_'' followed by zero or more alphanumerics or ''_''. value is optional (and defaults to an empty value) but when present it may not contain white space and quoting or escaping is not supported. * #undef name Removes the macro definition, if any, for name. * #ifdef name ... #endif or #ifndef name ... #endif The enclosing lines will be stripped or included, depending if the macro name is defined or not. Macro substitution is achieved by breaking the input stream into words separated by white space or one of the characters ''.'' or '':'' - this matches the syntax of the PMNS, see pmns(4). Each word is checked and if it matches a macro name, the word is replaced by the macro value, otherwise the word is unchanged. There is generally one output line for each input line, although the line may be empty if the text has been stripped due to the handling of comments or conditional directives. When there is a change in the input stream, an additional output line is generated of the form: # line \"name\" to indicate the following line of output corresponds to line number line of the input file name. Important cpp(1) features that are not supported by pmcpp include: * #if expr ... #endif * Nested use of #ifdef or #ifndef. * #else within an #ifdef or #ifndef. * Stripping C++ style comments, as in \/\/ comment * Error recovery - the first error encountered by pmcpp will be fatal. * cpp(1) command line options like -U , -P and -I.","Process Name":"pmcpp","Link":"https:\/\/linux.die.net\/man\/1\/pmcpp"}},{"Process":{"Description":"pmdabash is an experimental Performance Metrics Domain Agent (PMDA) which exports \"xtrace\" events from a traced bash(1) process. This includes the command execution information that would usually be sent to standard error with the set -x option to the shell. Event metrics are exported showing each command executed, the function name and line number in the script, and a timestamp. Additionally, the process identifier for the shell and its parent process are exported. This requires bash version 4 or later. A brief description of the pmdabash command line options follows: -d It is absolutely crucial that the performance metrics domain number specified here is unique and consistent. That is, domain should be different for every PMDA on the one host, and the same domain number should be used for the same PMDA on all hosts. -l Location of the log file. By default, a log file named bash.log is written in the current directory of pmcd(1) when pmdabash is started, i.e. $PCP_LOG_DIR\/pmcd. If the log file cannot be created or is not writable, output is written to the standard error instead. -s Amount of time (in seconds) between subsequent evaluations of the shell trace file descriptor(s). The default is 2 seconds. -m Maximum amount of memory to be allowed for each event queue (one per traced process). The default is 2 megabytes.","Process Name":"pmdabash","Link":"https:\/\/linux.die.net\/man\/1\/pmdabash"}},{"Process":{"Description":"pmdabonding is a Performance Metrics Domain Agent ( PMDA ) which exports metric values from bonded network interfaces in the Linux kernel.","Process Name":"pmdabonding","Link":"https:\/\/linux.die.net\/man\/1\/pmdabonding"}},{"Process":{"Description":"pmdacisco is a Performance Metrics Domain Agent (PMDA) which extracts performance metrics from one or more Cisco routers. A brief description of the pmdacisco command line options follows: -d It is absolutely crucial that the performance metrics domain number specified here is unique and consistent. That is, domain should be different for every PMDA on the one host, and the same domain number should be used for the same PMDA on all hosts. -l Location of the log file. By default, a log file named cisco.log is written in the current directory of pmcd(1) when pmdacisco is started, i.e. $PCP_LOG_DIR\/pmcd. If the log file cannot be created or is not writable, output is written to the standard error instead. -P By default, it is assumed that no user-level password is required to access the Cisco's telnet port. If user-level passwords have been enabled on the Ciscos, then those passwords must be specified to pmdacisco. If specified with the -P option, password will be used as the default user-level password for all Ciscos. See also the INTERFACE IDENTIFICATION section below. -r pmdacisco will refresh the current values for all performance metrics by contacting each Cisco router once every refresh seconds. The default refresh is 120 seconds. -s The Cisco command prompt ends with the string prompt. The default value is ''>''. The only way pmdacisco can synchronize the sending of commands and the parsing of output is by recognizing prompt as a unique string that comes at the end of all output, i.e. as the command prompt when waiting for the next command. -U By default, it is assumed that no username login is required to access the Cisco's telnet port. If username login has been enabled on the Ciscos, then the corresponding usernames must be specified to pmdacisco. If specified with the -U option, username will be used as the default username login for all Ciscos. See also the INTERFACE IDENTIFICATION section below. -x Connect to the Cisco via TCP port number port rather than the default 23 for a telnet connection. For each interface, once the telnet connection is established, pmdacisco is willing to wait up to 5 seconds for the Cisco to provide a new snapshot of the requested information. If this does not happen, the telnet connection is broken and no values are returned. This prevents pmdacisco tying up the Cisco's telnet ports waiting indefinitely when the response from the router is not what is expected, e.g. if the format of the ''show int'' output changes, or the command is in error because an interface is no longer configured on the router.","Process Name":"pmdacisco","Link":"https:\/\/linux.die.net\/man\/1\/pmdacisco"}},{"Process":{"Description":"Simple database response time measurement PMDA . dbprobe.pl(1) should be configured to use the type of DBI appropriate for your database, which includes: RDBMS flavour, user\/password, delay between \"ping\" requests, and the SQL statement to use. pmdadbping runs dbprobe.pl(1), and exports the performance measurements it makes available as PCP metrics.","Process Name":"pmdadbping","Link":"https:\/\/linux.die.net\/man\/1\/pmdadbping"}},{"Process":{"Description":"pmdaelasticsearch is a Performance Metrics Domain Agent ( PMDA ) which exports metric values from elasticsearch.","Process Name":"pmdaelasticsearch","Link":"https:\/\/linux.die.net\/man\/1\/pmdaelasticsearch"}},{"Process":{"Description":"pmdagpsd is a Performance Metrics Domain Agent ( PMDA ) which exports values from the gpsd daemon.","Process Name":"pmdagpsd","Link":"https:\/\/linux.die.net\/man\/1\/pmdagpsd"}},{"Process":{"Description":"pmdakvm is a Performance Metrics Domain Agent ( PMDA ) which exports metric values from the Linux KVM virtualisation subsystem. Unlike many PMDAs it dynamically enumerates its metric hierarchy, based entirely on the contents of \/sys\/kernel\/debug\/kvm.","Process Name":"pmdakvm","Link":"https:\/\/linux.die.net\/man\/1\/pmdakvm"}},{"Process":{"Description":"pmdamailq is a Performance Metrics Domain Agent (PMDA) which extracts performance metrics describing the state of the e-mail queues managed by sendmail(1) and other mail transfer agents. The mailq PMDA exports metrics that measure the total number of entries in the mail queue, and the subtotals for entries that have been queued for various time periods. A brief description of the pmdamailq command line options follows: -b The binlist argument specifies a list of delay thresholds used to ''bin'' the entries in the queue into a a histogram based on how long the entry has been in the mail queue. The default thresholds are: 1 hour, 4 hours, 8 hours, 1 day, 3 days and 7 days. The entries in binlist are comma separated time intervals, using the syntax described in pcpintro(1) for an update or reporting interval, e.g. the default list could be specified using the value 1hr,4hrs,8hrs,1day,3days,7days. Values in binlist are assumed to be in ascending order, and mail items in the queue less than the first threshold are binned into a special bin labeled ''recent''. -d It is absolutely crucial that the performance metrics domain number specified here is unique and consistent. That is, domain should be different for every PMDA on the one host, and the same domain number should be used for the same PMDA on all hosts. -l Location of the log file. By default, a log file named mailq.log is written in the current directory of pmcd(1) when pmdamailq is started, i.e. $PCP_LOG_DIR\/pmcd . If the log file cannot be created or is not writable, output is written to the standard error instead. -r Use an extended regular expression to match file names in the mail queue directory, rather than assuming all \"df\" prefixed files in the directory are mail files (the \"df\" prefix is the sendmail convention, but this convention is not followed by other mail daemons). The regex pattern specified should conform to the POSIX format described in regex(3), and it describes file names that should be considered mail. The optional queuedir argument defines the directory in which pmdamailq expects to find the mail queue. The default is \/var\/spool\/mqueue.","Process Name":"pmdamailq","Link":"https:\/\/linux.die.net\/man\/1\/pmdamailq"}},{"Process":{"Description":"This PMDA extracts performance data from memcached, a distributed memory caching daemon commonly used to improve web serving performance. A farm of memcached processes over multiple servers can be utilised by a single web application, increasing the total available object cache size, and decreasing the database load associated with smaller cache sizes. This system is described in detail at http:\/\/www.danga.com\/memcached.","Process Name":"pmdamemcache","Link":"https:\/\/linux.die.net\/man\/1\/pmdamemcache"}},{"Process":{"Description":"pmdamysql is a Performance Co-Pilot PMDA which extracts live performance data from a running MySQL database.","Process Name":"pmdamysql","Link":"https:\/\/linux.die.net\/man\/1\/pmdamysql"}},{"Process":{"Description":"pmdanamed is a Performance Metrics Domain Agent ( PMDA ) which exports metric values from the BIND DNS server. Further details on BIND can be found at http:\/\/isc.org\/. Currently, only BIND version 9.4 is supported.","Process Name":"pmdanamed","Link":"https:\/\/linux.die.net\/man\/1\/pmdanamed"}},{"Process":{"Description":"pmdanetfilter is a Performance Metrics Domain Agent ( PMDA ) which exports metric values from IP connection tracking module in the Linux kernel.","Process Name":"pmdanetfilter","Link":"https:\/\/linux.die.net\/man\/1\/pmdanetfilter"}},{"Process":{"Description":"pmdanews is an example Performance Metrics Domain Agent ( PMDA ) which exports metric values related to a set of newsgroups.","Process Name":"pmdanews","Link":"https:\/\/linux.die.net\/man\/1\/pmdanews"}},{"Process":{"Description":"pmdapdns is a Performance Metrics Domain Agent ( PMDA ) which exports metric values from the PowerDNS authorative daemon as well as the recursive resolver.","Process Name":"pmdapdns","Link":"https:\/\/linux.die.net\/man\/1\/pmdapdns"}},{"Process":{"Description":"pmdapostfix is a Performance Metrics Domain Agent ( PMDA ) which exports mail queue sizes as reported by qshape(1), as well as aggregate statistics collected from mail.log.","Process Name":"pmdapostfix","Link":"https:\/\/linux.die.net\/man\/1\/pmdapostfix"}},{"Process":{"Description":"pmdapostgresql is a Performance Co-Pilot PMDA which extracts live performance data from a running PostgreSQL database.","Process Name":"pmdapostgresql","Link":"https:\/\/linux.die.net\/man\/1\/pmdapostgresql"}},{"Process":{"Description":null,"Process Name":"pmdarsyslog","Link":"https:\/\/linux.die.net\/man\/1\/pmdarsyslog"}},{"Process":{"Description":null,"Process Name":"pmdasamba","Link":"https:\/\/linux.die.net\/man\/1\/pmdasamba"}},{"Process":{"Description":null,"Process Name":"pmdasample","Link":"https:\/\/linux.die.net\/man\/1\/pmdasample"}},{"Process":{"Description":null,"Process Name":"pmdasendmail","Link":"https:\/\/linux.die.net\/man\/1\/pmdasendmail"}},{"Process":{"Description":null,"Process Name":"pmdashping","Link":"https:\/\/linux.die.net\/man\/1\/pmdashping"}},{"Process":{"Description":null,"Process Name":"pmdasimple","Link":"https:\/\/linux.die.net\/man\/1\/pmdasimple"}},{"Process":{"Description":null,"Process Name":"pmdasnmp","Link":"https:\/\/linux.die.net\/man\/1\/pmdasnmp"}},{"Process":{"Description":null,"Process Name":"pmdasummary","Link":"https:\/\/linux.die.net\/man\/1\/pmdasummary"}},{"Process":{"Description":null,"Process Name":"pmdasystemtap","Link":"https:\/\/linux.die.net\/man\/1\/pmdasystemtap"}},{"Process":{"Description":null,"Process Name":"pmdate","Link":"https:\/\/linux.die.net\/man\/1\/pmdate"}},{"Process":{"Description":null,"Process Name":"pmdatrace","Link":"https:\/\/linux.die.net\/man\/1\/pmdatrace"}},{"Process":{"Description":null,"Process Name":"pmdatrivial","Link":"https:\/\/linux.die.net\/man\/1\/pmdatrivial"}},{"Process":{"Description":null,"Process Name":"pmdatxmon","Link":"https:\/\/linux.die.net\/man\/1\/pmdatxmon"}},{"Process":{"Description":null,"Process Name":"pmdavmware","Link":"https:\/\/linux.die.net\/man\/1\/pmdavmware"}},{"Process":{"Description":null,"Process Name":"pmdaweblog","Link":"https:\/\/linux.die.net\/man\/1\/pmdaweblog"}},{"Process":{"Description":null,"Process Name":"pmdazimbra","Link":"https:\/\/linux.die.net\/man\/1\/pmdazimbra"}},{"Process":{"Description":null,"Process Name":"pmdbg","Link":"https:\/\/linux.die.net\/man\/1\/pmdbg"}},{"Process":{"Description":null,"Process Name":"pmdesc","Link":"https:\/\/linux.die.net\/man\/1\/pmdesc"}},{"Process":{"Description":null,"Process Name":"pmdirs","Link":"https:\/\/linux.die.net\/man\/1\/pmdirs"}},{"Process":{"Description":null,"Process Name":"pmdumplog","Link":"https:\/\/linux.die.net\/man\/1\/pmdumplog"}},{"Process":{"Description":null,"Process Name":"pmdumptext","Link":"https:\/\/linux.die.net\/man\/1\/pmdumptext"}},{"Process":{"Description":null,"Process Name":"pmerr","Link":"https:\/\/linux.die.net\/man\/1\/pmerr"}},{"Process":{"Description":null,"Process Name":"pmeth","Link":"https:\/\/linux.die.net\/man\/1\/pmeth"}},{"Process":{"Description":null,"Process Name":"pmevent","Link":"https:\/\/linux.die.net\/man\/1\/pmevent"}},{"Process":{"Description":null,"Process Name":"pmexp","Link":"https:\/\/linux.die.net\/man\/1\/pmexp"}},{"Process":{"Description":null,"Process Name":"pmfunc","Link":"https:\/\/linux.die.net\/man\/1\/pmfunc"}},{"Process":{"Description":null,"Process Name":"pmgenmap","Link":"https:\/\/linux.die.net\/man\/1\/pmgenmap"}},{"Process":{"Description":null,"Process Name":"pmhostname","Link":"https:\/\/linux.die.net\/man\/1\/pmhostname"}},{"Process":{"Description":null,"Process Name":"pmie","Link":"https:\/\/linux.die.net\/man\/1\/pmie"}},{"Process":{"Description":null,"Process Name":"pmie2col","Link":"https:\/\/linux.die.net\/man\/1\/pmie2col"}},{"Process":{"Description":null,"Process Name":"pmie_check","Link":"https:\/\/linux.die.net\/man\/1\/pmie_check"}},{"Process":{"Description":null,"Process Name":"pmie_daily","Link":"https:\/\/linux.die.net\/man\/1\/pmie_daily"}},{"Process":{"Description":null,"Process Name":"pmieconf","Link":"https:\/\/linux.die.net\/man\/1\/pmieconf"}},{"Process":{"Description":null,"Process Name":"pmiestatus","Link":"https:\/\/linux.die.net\/man\/1\/pmiestatus"}},{"Process":{"Description":null,"Process Name":"pminfo","Link":"https:\/\/linux.die.net\/man\/1\/pminfo"}},{"Process":{"Description":null,"Process Name":"pminst","Link":"https:\/\/linux.die.net\/man\/1\/pminst"}},{"Process":{"Description":null,"Process Name":"pmkdir","Link":"https:\/\/linux.die.net\/man\/1\/pmkdir"}},{"Process":{"Description":null,"Process Name":"pmkpasswd","Link":"https:\/\/linux.die.net\/man\/1\/pmkpasswd"}},{"Process":{"Description":null,"Process Name":"pmlc","Link":"https:\/\/linux.die.net\/man\/1\/pmlc"}},{"Process":{"Description":null,"Process Name":"pmload","Link":"https:\/\/linux.die.net\/man\/1\/pmload"}},{"Process":{"Description":null,"Process Name":"pmlock","Link":"https:\/\/linux.die.net\/man\/1\/pmlock"}},{"Process":{"Description":null,"Process Name":"pmlogcheck","Link":"https:\/\/linux.die.net\/man\/1\/pmlogcheck"}},{"Process":{"Description":null,"Process Name":"pmlogconf","Link":"https:\/\/linux.die.net\/man\/1\/pmlogconf"}},{"Process":{"Description":null,"Process Name":"pmlogextract","Link":"https:\/\/linux.die.net\/man\/1\/pmlogextract"}},{"Process":{"Description":null,"Process Name":"pmlogger","Link":"https:\/\/linux.die.net\/man\/1\/pmlogger"}},{"Process":{"Description":null,"Process Name":"pmlogger_check","Link":"https:\/\/linux.die.net\/man\/1\/pmlogger_check"}},{"Process":{"Description":null,"Process Name":"pmlogger_daily","Link":"https:\/\/linux.die.net\/man\/1\/pmlogger_daily"}},{"Process":{"Description":null,"Process Name":"pmlogger_merge","Link":"https:\/\/linux.die.net\/man\/1\/pmlogger_merge"}},{"Process":{"Description":null,"Process Name":"pmloglabel","Link":"https:\/\/linux.die.net\/man\/1\/pmloglabel"}},{"Process":{"Description":null,"Process Name":"pmlogreduce","Link":"https:\/\/linux.die.net\/man\/1\/pmlogreduce"}},{"Process":{"Description":null,"Process Name":"pmlogrewrite","Link":"https:\/\/linux.die.net\/man\/1\/pmlogrewrite"}},{"Process":{"Description":null,"Process Name":"pmlogsummary","Link":"https:\/\/linux.die.net\/man\/1\/pmlogsummary"}},{"Process":{"Description":null,"Process Name":"pmls","Link":"https:\/\/linux.die.net\/man\/1\/pmls"}},{"Process":{"Description":null,"Process Name":"pmmessage","Link":"https:\/\/linux.die.net\/man\/1\/pmmessage"}},{"Process":{"Description":null,"Process Name":"pmnewlog","Link":"https:\/\/linux.die.net\/man\/1\/pmnewlog"}},{"Process":{"Description":null,"Process Name":"pmnsadd","Link":"https:\/\/linux.die.net\/man\/1\/pmnsadd"}},{"Process":{"Description":null,"Process Name":"pmnscomp","Link":"https:\/\/linux.die.net\/man\/1\/pmnscomp"}},{"Process":{"Description":null,"Process Name":"pmnsdel","Link":"https:\/\/linux.die.net\/man\/1\/pmnsdel"}},{"Process":{"Description":null,"Process Name":"pmnsmerge","Link":"https:\/\/linux.die.net\/man\/1\/pmnsmerge"}},{"Process":{"Description":null,"Process Name":"pmount","Link":"https:\/\/linux.die.net\/man\/1\/pmount"}},{"Process":{"Description":null,"Process Name":"pmpath","Link":"https:\/\/linux.die.net\/man\/1\/pmpath"}},{"Process":{"Description":null,"Process Name":"pmpost","Link":"https:\/\/linux.die.net\/man\/1\/pmpost"}},{"Process":{"Description":null,"Process Name":"pmprobe","Link":"https:\/\/linux.die.net\/man\/1\/pmprobe"}},{"Process":{"Description":null,"Process Name":"pmproxy","Link":"https:\/\/linux.die.net\/man\/1\/pmproxy"}},{"Process":{"Description":null,"Process Name":"pmquery","Link":"https:\/\/linux.die.net\/man\/1\/pmquery"}},{"Process":{"Description":null,"Process Name":"pmsignal","Link":"https:\/\/linux.die.net\/man\/1\/pmsignal"}},{"Process":{"Description":null,"Process Name":"pmsleep","Link":"https:\/\/linux.die.net\/man\/1\/pmsleep"}},{"Process":{"Description":null,"Process Name":"pmsnap","Link":"https:\/\/linux.die.net\/man\/1\/pmsnap"}},{"Process":{"Description":null,"Process Name":"pmsocks","Link":"https:\/\/linux.die.net\/man\/1\/pmsocks"}},{"Process":{"Description":null,"Process Name":"pmstat","Link":"https:\/\/linux.die.net\/man\/1\/pmstat"}},{"Process":{"Description":null,"Process Name":"pmstore","Link":"https:\/\/linux.die.net\/man\/1\/pmstore"}},{"Process":{"Description":null,"Process Name":"pmtime","Link":"https:\/\/linux.die.net\/man\/1\/pmtime"}},{"Process":{"Description":null,"Process Name":"pmtrace","Link":"https:\/\/linux.die.net\/man\/1\/pmtrace"}},{"Process":{"Description":null,"Process Name":"pmumps","Link":"https:\/\/linux.die.net\/man\/1\/pmumps"}},{"Process":{"Description":null,"Process Name":"pmv","Link":"https:\/\/linux.die.net\/man\/1\/pmv"}},{"Process":{"Description":null,"Process Name":"pmval","Link":"https:\/\/linux.die.net\/man\/1\/pmval"}},{"Process":{"Description":null,"Process Name":"pmvers","Link":"https:\/\/linux.die.net\/man\/1\/pmvers"}},{"Process":{"Description":null,"Process Name":"pnee","Link":"https:\/\/linux.die.net\/man\/1\/pnee"}},{"Process":{"Description":null,"Process Name":"png2ico","Link":"https:\/\/linux.die.net\/man\/1\/png2ico"}},{"Process":{"Description":null,"Process Name":"png2pat","Link":"https:\/\/linux.die.net\/man\/1\/png2pat"}},{"Process":{"Description":null,"Process Name":"png2swf","Link":"https:\/\/linux.die.net\/man\/1\/png2swf"}},{"Process":{"Description":null,"Process Name":"png2yuv","Link":"https:\/\/linux.die.net\/man\/1\/png2yuv"}},{"Process":{"Description":null,"Process Name":"pngtoexr","Link":"https:\/\/linux.die.net\/man\/1\/pngtoexr"}},{"Process":{"Description":null,"Process Name":"pngtopam","Link":"https:\/\/linux.die.net\/man\/1\/pngtopam"}},{"Process":{"Description":null,"Process Name":"pngtopnm","Link":"https:\/\/linux.die.net\/man\/1\/pngtopnm"}},{"Process":{"Description":null,"Process Name":"pnm2ppa","Link":"https:\/\/linux.die.net\/man\/1\/pnm2ppa"}},{"Process":{"Description":null,"Process Name":"pnmalias","Link":"https:\/\/linux.die.net\/man\/1\/pnmalias"}},{"Process":{"Description":null,"Process Name":"pnmarith","Link":"https:\/\/linux.die.net\/man\/1\/pnmarith"}},{"Process":{"Description":null,"Process Name":"pnmcat","Link":"https:\/\/linux.die.net\/man\/1\/pnmcat"}},{"Process":{"Description":null,"Process Name":"pnmcolormap","Link":"https:\/\/linux.die.net\/man\/1\/pnmcolormap"}},{"Process":{"Description":null,"Process Name":"pnmcomp","Link":"https:\/\/linux.die.net\/man\/1\/pnmcomp"}},{"Process":{"Description":null,"Process Name":"pnmconvol","Link":"https:\/\/linux.die.net\/man\/1\/pnmconvol"}},{"Process":{"Description":null,"Process Name":"pnmcrop","Link":"https:\/\/linux.die.net\/man\/1\/pnmcrop"}},{"Process":{"Description":null,"Process Name":"pnmcut","Link":"https:\/\/linux.die.net\/man\/1\/pnmcut"}},{"Process":{"Description":null,"Process Name":"pnmdepth","Link":"https:\/\/linux.die.net\/man\/1\/pnmdepth"}},{"Process":{"Description":null,"Process Name":"pnmenlarge","Link":"https:\/\/linux.die.net\/man\/1\/pnmenlarge"}},{"Process":{"Description":null,"Process Name":"pnmfile","Link":"https:\/\/linux.die.net\/man\/1\/pnmfile"}},{"Process":{"Description":null,"Process Name":"pnmflip","Link":"https:\/\/linux.die.net\/man\/1\/pnmflip"}},{"Process":{"Description":null,"Process Name":"pnmgamma","Link":"https:\/\/linux.die.net\/man\/1\/pnmgamma"}},{"Process":{"Description":null,"Process Name":"pnmhisteq","Link":"https:\/\/linux.die.net\/man\/1\/pnmhisteq"}},{"Process":{"Description":null,"Process Name":"pnmindex","Link":"https:\/\/linux.die.net\/man\/1\/pnmindex"}},{"Process":{"Description":null,"Process Name":"pnminterp","Link":"https:\/\/linux.die.net\/man\/1\/pnminterp"}},{"Process":{"Description":null,"Process Name":"pnminvert","Link":"https:\/\/linux.die.net\/man\/1\/pnminvert"}},{"Process":{"Description":null,"Process Name":"pnmmargin","Link":"https:\/\/linux.die.net\/man\/1\/pnmmargin"}},{"Process":{"Description":null,"Process Name":"pnmmercator","Link":"https:\/\/linux.die.net\/man\/1\/pnmmercator"}},{"Process":{"Description":null,"Process Name":"pnmmontage","Link":"https:\/\/linux.die.net\/man\/1\/pnmmontage"}},{"Process":{"Description":null,"Process Name":"pnmnlfilt","Link":"https:\/\/linux.die.net\/man\/1\/pnmnlfilt"}},{"Process":{"Description":null,"Process Name":"pnmnoraw","Link":"https:\/\/linux.die.net\/man\/1\/pnmnoraw"}},{"Process":{"Description":null,"Process Name":"pnmnorm","Link":"https:\/\/linux.die.net\/man\/1\/pnmnorm"}},{"Process":{"Description":null,"Process Name":"pnmpad","Link":"https:\/\/linux.die.net\/man\/1\/pnmpad"}},{"Process":{"Description":null,"Process Name":"pnmpaste","Link":"https:\/\/linux.die.net\/man\/1\/pnmpaste"}},{"Process":{"Description":null,"Process Name":"pnmpsnr","Link":"https:\/\/linux.die.net\/man\/1\/pnmpsnr"}},{"Process":{"Description":null,"Process Name":"pnmquant","Link":"https:\/\/linux.die.net\/man\/1\/pnmquant"}},{"Process":{"Description":null,"Process Name":"pnmremap","Link":"https:\/\/linux.die.net\/man\/1\/pnmremap"}},{"Process":{"Description":null,"Process Name":"pnmrotate","Link":"https:\/\/linux.die.net\/man\/1\/pnmrotate"}},{"Process":{"Description":null,"Process Name":"pnmscale","Link":"https:\/\/linux.die.net\/man\/1\/pnmscale"}},{"Process":{"Description":null,"Process Name":"pnmscalefixed","Link":"https:\/\/linux.die.net\/man\/1\/pnmscalefixed"}},{"Process":{"Description":null,"Process Name":"pnmshear","Link":"https:\/\/linux.die.net\/man\/1\/pnmshear"}},{"Process":{"Description":null,"Process Name":"pnmsmooth","Link":"https:\/\/linux.die.net\/man\/1\/pnmsmooth"}},{"Process":{"Description":null,"Process Name":"pnmsplit","Link":"https:\/\/linux.die.net\/man\/1\/pnmsplit"}},{"Process":{"Description":null,"Process Name":"pnmstitch","Link":"https:\/\/linux.die.net\/man\/1\/pnmstitch"}},{"Process":{"Description":null,"Process Name":"pnmtile","Link":"https:\/\/linux.die.net\/man\/1\/pnmtile"}},{"Process":{"Description":null,"Process Name":"pnmtoddif","Link":"https:\/\/linux.die.net\/man\/1\/pnmtoddif"}},{"Process":{"Description":null,"Process Name":"pnmtofiasco","Link":"https:\/\/linux.die.net\/man\/1\/pnmtofiasco"}},{"Process":{"Description":null,"Process Name":"pnmtofits","Link":"https:\/\/linux.die.net\/man\/1\/pnmtofits"}},{"Process":{"Description":null,"Process Name":"pnmtojbig","Link":"https:\/\/linux.die.net\/man\/1\/pnmtojbig"}},{"Process":{"Description":null,"Process Name":"pnmtojpeg","Link":"https:\/\/linux.die.net\/man\/1\/pnmtojpeg"}},{"Process":{"Description":null,"Process Name":"pnmtopalm","Link":"https:\/\/linux.die.net\/man\/1\/pnmtopalm"}},{"Process":{"Description":null,"Process Name":"pnmtopclxl","Link":"https:\/\/linux.die.net\/man\/1\/pnmtopclxl"}},{"Process":{"Description":null,"Process Name":"pnmtoplainpnm","Link":"https:\/\/linux.die.net\/man\/1\/pnmtoplainpnm"}},{"Process":{"Description":null,"Process Name":"pnmtopng","Link":"https:\/\/linux.die.net\/man\/1\/pnmtopng"}},{"Process":{"Description":null,"Process Name":"pnmtopnm","Link":"https:\/\/linux.die.net\/man\/1\/pnmtopnm"}},{"Process":{"Description":null,"Process Name":"pnmtops","Link":"https:\/\/linux.die.net\/man\/1\/pnmtops"}},{"Process":{"Description":null,"Process Name":"pnmtorast","Link":"https:\/\/linux.die.net\/man\/1\/pnmtorast"}},{"Process":{"Description":null,"Process Name":"pnmtorle","Link":"https:\/\/linux.die.net\/man\/1\/pnmtorle"}},{"Process":{"Description":null,"Process Name":"pnmtosgi","Link":"https:\/\/linux.die.net\/man\/1\/pnmtosgi"}},{"Process":{"Description":null,"Process Name":"pnmtosir","Link":"https:\/\/linux.die.net\/man\/1\/pnmtosir"}},{"Process":{"Description":null,"Process Name":"pnmtotiff","Link":"https:\/\/linux.die.net\/man\/1\/pnmtotiff"}},{"Process":{"Description":null,"Process Name":"pnmtotiffcmyk","Link":"https:\/\/linux.die.net\/man\/1\/pnmtotiffcmyk"}},{"Process":{"Description":null,"Process Name":"pnmtoxwd","Link":"https:\/\/linux.die.net\/man\/1\/pnmtoxwd"}},{"Process":{"Description":null,"Process Name":"pnmtoy4m","Link":"https:\/\/linux.die.net\/man\/1\/pnmtoy4m"}},{"Process":{"Description":null,"Process Name":"po2csv","Link":"https:\/\/linux.die.net\/man\/1\/po2csv"}},{"Process":{"Description":null,"Process Name":"po2html","Link":"https:\/\/linux.die.net\/man\/1\/po2html"}},{"Process":{"Description":null,"Process Name":"po2ini","Link":"https:\/\/linux.die.net\/man\/1\/po2ini"}},{"Process":{"Description":null,"Process Name":"po2json","Link":"https:\/\/linux.die.net\/man\/1\/po2json"}},{"Process":{"Description":null,"Process Name":"po2moz","Link":"https:\/\/linux.die.net\/man\/1\/po2moz"}},{"Process":{"Description":null,"Process Name":"po2oo","Link":"https:\/\/linux.die.net\/man\/1\/po2oo"}},{"Process":{"Description":null,"Process Name":"po2php","Link":"https:\/\/linux.die.net\/man\/1\/po2php"}},{"Process":{"Description":null,"Process Name":"po2prop","Link":"https:\/\/linux.die.net\/man\/1\/po2prop"}},{"Process":{"Description":null,"Process Name":"po2rc","Link":"https:\/\/linux.die.net\/man\/1\/po2rc"}},{"Process":{"Description":null,"Process Name":"po2symb","Link":"https:\/\/linux.die.net\/man\/1\/po2symb"}},{"Process":{"Description":null,"Process Name":"po2tiki","Link":"https:\/\/linux.die.net\/man\/1\/po2tiki"}},{"Process":{"Description":null,"Process Name":"po2tmx","Link":"https:\/\/linux.die.net\/man\/1\/po2tmx"}},{"Process":{"Description":null,"Process Name":"po2ts","Link":"https:\/\/linux.die.net\/man\/1\/po2ts"}},{"Process":{"Description":null,"Process Name":"po2txt","Link":"https:\/\/linux.die.net\/man\/1\/po2txt"}},{"Process":{"Description":null,"Process Name":"po2web2py","Link":"https:\/\/linux.die.net\/man\/1\/po2web2py"}},{"Process":{"Description":null,"Process Name":"po2wordfast","Link":"https:\/\/linux.die.net\/man\/1\/po2wordfast"}},{"Process":{"Description":null,"Process Name":"po2xliff","Link":"https:\/\/linux.die.net\/man\/1\/po2xliff"}},{"Process":{"Description":null,"Process Name":"po2xml","Link":"https:\/\/linux.die.net\/man\/1\/po2xml"}},{"Process":{"Description":null,"Process Name":"po4a","Link":"https:\/\/linux.die.net\/man\/1\/po4a"}},{"Process":{"Description":null,"Process Name":"po4a-build","Link":"https:\/\/linux.die.net\/man\/1\/po4a-build"}},{"Process":{"Description":null,"Process Name":"po4a-gettextize","Link":"https:\/\/linux.die.net\/man\/1\/po4a-gettextize"}},{"Process":{"Description":null,"Process Name":"po4a-normalize","Link":"https:\/\/linux.die.net\/man\/1\/po4a-normalize"}},{"Process":{"Description":null,"Process Name":"po4a-translate","Link":"https:\/\/linux.die.net\/man\/1\/po4a-translate"}},{"Process":{"Description":null,"Process Name":"po4a-updatepo","Link":"https:\/\/linux.die.net\/man\/1\/po4a-updatepo"}},{"Process":{"Description":null,"Process Name":"po4aman-display-po","Link":"https:\/\/linux.die.net\/man\/1\/po4aman-display-po"}},{"Process":{"Description":null,"Process Name":"po4apod-display-po","Link":"https:\/\/linux.die.net\/man\/1\/po4apod-display-po"}},{"Process":{"Description":null,"Process Name":"poclean","Link":"https:\/\/linux.die.net\/man\/1\/poclean"}},{"Process":{"Description":null,"Process Name":"pocompile","Link":"https:\/\/linux.die.net\/man\/1\/pocompile"}},{"Process":{"Description":null,"Process Name":"poconflicts","Link":"https:\/\/linux.die.net\/man\/1\/poconflicts"}},{"Process":{"Description":null,"Process Name":"pod2docbook","Link":"https:\/\/linux.die.net\/man\/1\/pod2docbook"}},{"Process":{"Description":null,"Process Name":"pod2html","Link":"https:\/\/linux.die.net\/man\/1\/pod2html"}},{"Process":{"Description":null,"Process Name":"pod2latex","Link":"https:\/\/linux.die.net\/man\/1\/pod2latex"}},{"Process":{"Description":null,"Process Name":"pod2man","Link":"https:\/\/linux.die.net\/man\/1\/pod2man"}},{"Process":{"Description":null,"Process Name":"pod2readme","Link":"https:\/\/linux.die.net\/man\/1\/pod2readme"}},{"Process":{"Description":null,"Process Name":"pod2test","Link":"https:\/\/linux.die.net\/man\/1\/pod2test"}},{"Process":{"Description":null,"Process Name":"pod2text","Link":"https:\/\/linux.die.net\/man\/1\/pod2text"}},{"Process":{"Description":null,"Process Name":"pod2usage","Link":"https:\/\/linux.die.net\/man\/1\/pod2usage"}},{"Process":{"Description":null,"Process Name":"pod2wiki","Link":"https:\/\/linux.die.net\/man\/1\/pod2wiki"}},{"Process":{"Description":null,"Process Name":"pod2xhtml","Link":"https:\/\/linux.die.net\/man\/1\/pod2xhtml"}},{"Process":{"Description":null,"Process Name":"pod2xml","Link":"https:\/\/linux.die.net\/man\/1\/pod2xml"}},{"Process":{"Description":null,"Process Name":"podchecker","Link":"https:\/\/linux.die.net\/man\/1\/podchecker"}},{"Process":{"Description":null,"Process Name":"podebug","Link":"https:\/\/linux.die.net\/man\/1\/podebug"}},{"Process":{"Description":null,"Process Name":"podgrep","Link":"https:\/\/linux.die.net\/man\/1\/podgrep"}},{"Process":{"Description":null,"Process Name":"podlint","Link":"https:\/\/linux.die.net\/man\/1\/podlint"}},{"Process":{"Description":null,"Process Name":"podofobox","Link":"https:\/\/linux.die.net\/man\/1\/podofobox"}},{"Process":{"Description":null,"Process Name":"podofocountpages","Link":"https:\/\/linux.die.net\/man\/1\/podofocountpages"}},{"Process":{"Description":null,"Process Name":"podofocrop","Link":"https:\/\/linux.die.net\/man\/1\/podofocrop"}},{"Process":{"Description":null,"Process Name":"podofoencrypt","Link":"https:\/\/linux.die.net\/man\/1\/podofoencrypt"}},{"Process":{"Description":null,"Process Name":"podofoimg2pdf","Link":"https:\/\/linux.die.net\/man\/1\/podofoimg2pdf"}},{"Process":{"Description":null,"Process Name":"podofoimgextract","Link":"https:\/\/linux.die.net\/man\/1\/podofoimgextract"}},{"Process":{"Description":null,"Process Name":"podofoimpose","Link":"https:\/\/linux.die.net\/man\/1\/podofoimpose"}},{"Process":{"Description":null,"Process Name":"podofoincrementalupdates","Link":"https:\/\/linux.die.net\/man\/1\/podofoincrementalupdates"}},{"Process":{"Description":null,"Process Name":"podofomerge","Link":"https:\/\/linux.die.net\/man\/1\/podofomerge"}},{"Process":{"Description":null,"Process Name":"podofopages","Link":"https:\/\/linux.die.net\/man\/1\/podofopages"}},{"Process":{"Description":null,"Process Name":"podofopdfinfo","Link":"https:\/\/linux.die.net\/man\/1\/podofopdfinfo"}},{"Process":{"Description":null,"Process Name":"podofotxt2pdf","Link":"https:\/\/linux.die.net\/man\/1\/podofotxt2pdf"}},{"Process":{"Description":null,"Process Name":"podofotxtextract","Link":"https:\/\/linux.die.net\/man\/1\/podofotxtextract"}},{"Process":{"Description":null,"Process Name":"podofouncompress","Link":"https:\/\/linux.die.net\/man\/1\/podofouncompress"}},{"Process":{"Description":null,"Process Name":"podofoxmp","Link":"https:\/\/linux.die.net\/man\/1\/podofoxmp"}},{"Process":{"Description":null,"Process Name":"podpath","Link":"https:\/\/linux.die.net\/man\/1\/podpath"}},{"Process":{"Description":null,"Process Name":"pods","Link":"https:\/\/linux.die.net\/man\/1\/pods"}},{"Process":{"Description":null,"Process Name":"podselect","Link":"https:\/\/linux.die.net\/man\/1\/podselect"}},{"Process":{"Description":null,"Process Name":"podtoc","Link":"https:\/\/linux.die.net\/man\/1\/podtoc"}},{"Process":{"Description":null,"Process Name":"podviewer","Link":"https:\/\/linux.die.net\/man\/1\/podviewer"}},{"Process":{"Description":null,"Process Name":"poe-gen-tests","Link":"https:\/\/linux.die.net\/man\/1\/poe-gen-tests"}},{"Process":{"Description":null,"Process Name":"poedit","Link":"https:\/\/linux.die.net\/man\/1\/poedit"}},{"Process":{"Description":null,"Process Name":"pofilter","Link":"https:\/\/linux.die.net\/man\/1\/pofilter"}},{"Process":{"Description":null,"Process Name":"pogo","Link":"https:\/\/linux.die.net\/man\/1\/pogo"}},{"Process":{"Description":null,"Process Name":"pogrep","Link":"https:\/\/linux.die.net\/man\/1\/pogrep"}},{"Process":{"Description":null,"Process Name":"pointer-capture-applet","Link":"https:\/\/linux.die.net\/man\/1\/pointer-capture-applet"}},{"Process":{"Description":null,"Process Name":"policytool-java-1.6.0-openjdk","Link":"https:\/\/linux.die.net\/man\/1\/policytool-java-1.6.0-openjdk"}},{"Process":{"Description":null,"Process Name":"policytool-java-1.7.0-openjdk","Link":"https:\/\/linux.die.net\/man\/1\/policytool-java-1.7.0-openjdk"}},{"Process":{"Description":null,"Process Name":"polipo","Link":"https:\/\/linux.die.net\/man\/1\/polipo"}},{"Process":{"Description":null,"Process Name":"polyhedra","Link":"https:\/\/linux.die.net\/man\/1\/polyhedra"}},{"Process":{"Description":null,"Process Name":"polymerge","Link":"https:\/\/linux.die.net\/man\/1\/polymerge"}},{"Process":{"Description":null,"Process Name":"polyominoes","Link":"https:\/\/linux.die.net\/man\/1\/polyominoes"}},{"Process":{"Description":null,"Process Name":"polytopes","Link":"https:\/\/linux.die.net\/man\/1\/polytopes"}},{"Process":{"Description":null,"Process Name":"pom2","Link":"https:\/\/linux.die.net\/man\/1\/pom2"}},{"Process":{"Description":null,"Process Name":"pomdump","Link":"https:\/\/linux.die.net\/man\/1\/pomdump"}},{"Process":{"Description":null,"Process Name":"pomerge","Link":"https:\/\/linux.die.net\/man\/1\/pomerge"}},{"Process":{"Description":null,"Process Name":"pondus","Link":"https:\/\/linux.die.net\/man\/1\/pondus"}},{"Process":{"Description":null,"Process Name":"pong","Link":"https:\/\/linux.die.net\/man\/1\/pong"}},{"Process":{"Description":null,"Process Name":"pooltype","Link":"https:\/\/linux.die.net\/man\/1\/pooltype"}},{"Process":{"Description":null,"Process Name":"pop3test","Link":"https:\/\/linux.die.net\/man\/1\/pop3test"}},{"Process":{"Description":null,"Process Name":"popd","Link":"https:\/\/linux.die.net\/man\/1\/popd"}},{"Process":{"Description":null,"Process Name":"porestructure","Link":"https:\/\/linux.die.net\/man\/1\/porestructure"}},{"Process":{"Description":null,"Process Name":"portrelease","Link":"https:\/\/linux.die.net\/man\/1\/portrelease"}},{"Process":{"Description":null,"Process Name":"portreserve","Link":"https:\/\/linux.die.net\/man\/1\/portreserve"}},{"Process":{"Description":null,"Process Name":"posegment","Link":"https:\/\/linux.die.net\/man\/1\/posegment"}},{"Process":{"Description":null,"Process Name":"post","Link":"https:\/\/linux.die.net\/man\/1\/post"}},{"Process":{"Description":null,"Process Name":"postalias","Link":"https:\/\/linux.die.net\/man\/1\/postalias"}},{"Process":{"Description":null,"Process Name":"postcat","Link":"https:\/\/linux.die.net\/man\/1\/postcat"}},{"Process":{"Description":null,"Process Name":"postconf","Link":"https:\/\/linux.die.net\/man\/1\/postconf"}},{"Process":{"Description":null,"Process Name":"postdrop","Link":"https:\/\/linux.die.net\/man\/1\/postdrop"}},{"Process":{"Description":null,"Process Name":"postfix","Link":"https:\/\/linux.die.net\/man\/1\/postfix"}},{"Process":{"Description":null,"Process Name":"postgres","Link":"https:\/\/linux.die.net\/man\/1\/postgres"}},{"Process":{"Description":null,"Process Name":"postgresql_autodoc","Link":"https:\/\/linux.die.net\/man\/1\/postgresql_autodoc"}},{"Process":{"Description":null,"Process Name":"postkick","Link":"https:\/\/linux.die.net\/man\/1\/postkick"}},{"Process":{"Description":null,"Process Name":"postlock","Link":"https:\/\/linux.die.net\/man\/1\/postlock"}},{"Process":{"Description":null,"Process Name":"postlog","Link":"https:\/\/linux.die.net\/man\/1\/postlog"}},{"Process":{"Description":null,"Process Name":"postmap","Link":"https:\/\/linux.die.net\/man\/1\/postmap"}},{"Process":{"Description":null,"Process Name":"postmaster","Link":"https:\/\/linux.die.net\/man\/1\/postmaster"}},{"Process":{"Description":null,"Process Name":"postmulti","Link":"https:\/\/linux.die.net\/man\/1\/postmulti"}},{"Process":{"Description":null,"Process Name":"postqueue","Link":"https:\/\/linux.die.net\/man\/1\/postqueue"}},{"Process":{"Description":null,"Process Name":"postsuper","Link":"https:\/\/linux.die.net\/man\/1\/postsuper"}},{"Process":{"Description":null,"Process Name":"postw32","Link":"https:\/\/linux.die.net\/man\/1\/postw32"}},{"Process":{"Description":null,"Process Name":"poswap","Link":"https:\/\/linux.die.net\/man\/1\/poswap"}},{"Process":{"Description":null,"Process Name":"pot2po","Link":"https:\/\/linux.die.net\/man\/1\/pot2po"}},{"Process":{"Description":null,"Process Name":"poterminology","Link":"https:\/\/linux.die.net\/man\/1\/poterminology"}},{"Process":{"Description":null,"Process Name":"potrace","Link":"https:\/\/linux.die.net\/man\/1\/potrace"}},{"Process":{"Description":null,"Process Name":"powerman","Link":"https:\/\/linux.die.net\/man\/1\/powerman"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-addr2line","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-addr2line"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-ar","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-ar"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-as","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-as"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-c++filt","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-c++filt"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-cpp","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-cpp"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-dlltool","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-dlltool"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-elfedit","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-elfedit"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-gcc","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-gcc"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-gcov","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-gcov"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-gprof","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-gprof"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-ld","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-ld"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-nlmconv","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-nlmconv"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-nm","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-nm"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-objcopy","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-objcopy"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-objdump","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-objdump"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-ranlib","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-ranlib"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-readelf","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-readelf"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-size","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-size"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-strings","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-strings"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-strip","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-strip"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-windmc","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-windmc"}},{"Process":{"Description":null,"Process Name":"powerpc64-linux-gnu-windres","Link":"https:\/\/linux.die.net\/man\/1\/powerpc64-linux-gnu-windres"}},{"Process":{"Description":null,"Process Name":"powertop","Link":"https:\/\/linux.die.net\/man\/1\/powertop"}},{"Process":{"Description":null,"Process Name":"ppc386","Link":"https:\/\/linux.die.net\/man\/1\/ppc386"}},{"Process":{"Description":null,"Process Name":"ppcarm","Link":"https:\/\/linux.die.net\/man\/1\/ppcarm"}},{"Process":{"Description":null,"Process Name":"ppcppc","Link":"https:\/\/linux.die.net\/man\/1\/ppcppc"}},{"Process":{"Description":null,"Process Name":"ppcsparc","Link":"https:\/\/linux.die.net\/man\/1\/ppcsparc"}},{"Process":{"Description":null,"Process Name":"ppcx64","Link":"https:\/\/linux.die.net\/man\/1\/ppcx64"}},{"Process":{"Description":null,"Process Name":"ppdc","Link":"https:\/\/linux.die.net\/man\/1\/ppdc"}},{"Process":{"Description":null,"Process Name":"ppdep","Link":"https:\/\/linux.die.net\/man\/1\/ppdep"}},{"Process":{"Description":null,"Process Name":"ppdhtml","Link":"https:\/\/linux.die.net\/man\/1\/ppdhtml"}},{"Process":{"Description":null,"Process Name":"ppdi","Link":"https:\/\/linux.die.net\/man\/1\/ppdi"}},{"Process":{"Description":null,"Process Name":"ppdmerge","Link":"https:\/\/linux.die.net\/man\/1\/ppdmerge"}},{"Process":{"Description":null,"Process Name":"ppdpo","Link":"https:\/\/linux.die.net\/man\/1\/ppdpo"}},{"Process":{"Description":null,"Process Name":"ppl-config","Link":"https:\/\/linux.die.net\/man\/1\/ppl-config"}},{"Process":{"Description":null,"Process Name":"ppl_lcdd","Link":"https:\/\/linux.die.net\/man\/1\/ppl_lcdd"}},{"Process":{"Description":null,"Process Name":"ppl_lpsol","Link":"https:\/\/linux.die.net\/man\/1\/ppl_lpsol"}},{"Process":{"Description":null,"Process Name":"ppm2nokia","Link":"https:\/\/linux.die.net\/man\/1\/ppm2nokia"}},{"Process":{"Description":null,"Process Name":"ppm2tiff","Link":"https:\/\/linux.die.net\/man\/1\/ppm2tiff"}},{"Process":{"Description":null,"Process Name":"ppm3d","Link":"https:\/\/linux.die.net\/man\/1\/ppm3d"}},{"Process":{"Description":null,"Process Name":"ppmbrighten","Link":"https:\/\/linux.die.net\/man\/1\/ppmbrighten"}},{"Process":{"Description":null,"Process Name":"ppmchange","Link":"https:\/\/linux.die.net\/man\/1\/ppmchange"}},{"Process":{"Description":null,"Process Name":"ppmcie","Link":"https:\/\/linux.die.net\/man\/1\/ppmcie"}},{"Process":{"Description":null,"Process Name":"ppmcolormask","Link":"https:\/\/linux.die.net\/man\/1\/ppmcolormask"}},{"Process":{"Description":null,"Process Name":"ppmcolors","Link":"https:\/\/linux.die.net\/man\/1\/ppmcolors"}},{"Process":{"Description":null,"Process Name":"ppmdcfont","Link":"https:\/\/linux.die.net\/man\/1\/ppmdcfont"}},{"Process":{"Description":null,"Process Name":"ppmddumpfont","Link":"https:\/\/linux.die.net\/man\/1\/ppmddumpfont"}},{"Process":{"Description":null,"Process Name":"ppmdim","Link":"https:\/\/linux.die.net\/man\/1\/ppmdim"}},{"Process":{"Description":null,"Process Name":"ppmdist","Link":"https:\/\/linux.die.net\/man\/1\/ppmdist"}},{"Process":{"Description":null,"Process Name":"ppmdither","Link":"https:\/\/linux.die.net\/man\/1\/ppmdither"}},{"Process":{"Description":null,"Process Name":"ppmdmkfont","Link":"https:\/\/linux.die.net\/man\/1\/ppmdmkfont"}},{"Process":{"Description":null,"Process Name":"ppmdraw","Link":"https:\/\/linux.die.net\/man\/1\/ppmdraw"}},{"Process":{"Description":null,"Process Name":"ppmfade","Link":"https:\/\/linux.die.net\/man\/1\/ppmfade"}},{"Process":{"Description":null,"Process Name":"ppmflash","Link":"https:\/\/linux.die.net\/man\/1\/ppmflash"}},{"Process":{"Description":null,"Process Name":"ppmforge","Link":"https:\/\/linux.die.net\/man\/1\/ppmforge"}},{"Process":{"Description":null,"Process Name":"ppmhist","Link":"https:\/\/linux.die.net\/man\/1\/ppmhist"}},{"Process":{"Description":null,"Process Name":"ppmlabel","Link":"https:\/\/linux.die.net\/man\/1\/ppmlabel"}},{"Process":{"Description":null,"Process Name":"ppmmake","Link":"https:\/\/linux.die.net\/man\/1\/ppmmake"}},{"Process":{"Description":null,"Process Name":"ppmmix","Link":"https:\/\/linux.die.net\/man\/1\/ppmmix"}},{"Process":{"Description":null,"Process Name":"ppmnorm","Link":"https:\/\/linux.die.net\/man\/1\/ppmnorm"}},{"Process":{"Description":null,"Process Name":"ppmntsc","Link":"https:\/\/linux.die.net\/man\/1\/ppmntsc"}},{"Process":{"Description":null,"Process Name":"ppmpat","Link":"https:\/\/linux.die.net\/man\/1\/ppmpat"}},{"Process":{"Description":null,"Process Name":"ppmquant","Link":"https:\/\/linux.die.net\/man\/1\/ppmquant"}},{"Process":{"Description":null,"Process Name":"ppmquantall","Link":"https:\/\/linux.die.net\/man\/1\/ppmquantall"}},{"Process":{"Description":null,"Process Name":"ppmrainbow","Link":"https:\/\/linux.die.net\/man\/1\/ppmrainbow"}},{"Process":{"Description":null,"Process Name":"ppmrelief","Link":"https:\/\/linux.die.net\/man\/1\/ppmrelief"}},{"Process":{"Description":null,"Process Name":"ppmrough","Link":"https:\/\/linux.die.net\/man\/1\/ppmrough"}},{"Process":{"Description":null,"Process Name":"ppmshadow","Link":"https:\/\/linux.die.net\/man\/1\/ppmshadow"}},{"Process":{"Description":null,"Process Name":"ppmshift","Link":"https:\/\/linux.die.net\/man\/1\/ppmshift"}},{"Process":{"Description":null,"Process Name":"ppmspread","Link":"https:\/\/linux.die.net\/man\/1\/ppmspread"}},{"Process":{"Description":null,"Process Name":"ppmtoacad","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoacad"}},{"Process":{"Description":null,"Process Name":"ppmtoarbtxt","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoarbtxt"}},{"Process":{"Description":null,"Process Name":"ppmtobmp","Link":"https:\/\/linux.die.net\/man\/1\/ppmtobmp"}},{"Process":{"Description":null,"Process Name":"ppmtoexr","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoexr"}},{"Process":{"Description":null,"Process Name":"ppmtoeyuv","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoeyuv"}},{"Process":{"Description":null,"Process Name":"ppmtogif","Link":"https:\/\/linux.die.net\/man\/1\/ppmtogif"}},{"Process":{"Description":null,"Process Name":"ppmtoicr","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoicr"}},{"Process":{"Description":null,"Process Name":"ppmtoilbm","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoilbm"}},{"Process":{"Description":null,"Process Name":"ppmtojpeg","Link":"https:\/\/linux.die.net\/man\/1\/ppmtojpeg"}},{"Process":{"Description":null,"Process Name":"ppmtoleaf","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoleaf"}},{"Process":{"Description":null,"Process Name":"ppmtolj","Link":"https:\/\/linux.die.net\/man\/1\/ppmtolj"}},{"Process":{"Description":null,"Process Name":"ppmtolss16","Link":"https:\/\/linux.die.net\/man\/1\/ppmtolss16"}},{"Process":{"Description":null,"Process Name":"ppmtomap","Link":"https:\/\/linux.die.net\/man\/1\/ppmtomap"}},{"Process":{"Description":null,"Process Name":"ppmtomitsu","Link":"https:\/\/linux.die.net\/man\/1\/ppmtomitsu"}},{"Process":{"Description":null,"Process Name":"ppmtoneo","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoneo"}},{"Process":{"Description":null,"Process Name":"ppmtopcx","Link":"https:\/\/linux.die.net\/man\/1\/ppmtopcx"}},{"Process":{"Description":null,"Process Name":"ppmtopgm","Link":"https:\/\/linux.die.net\/man\/1\/ppmtopgm"}},{"Process":{"Description":null,"Process Name":"ppmtopi1","Link":"https:\/\/linux.die.net\/man\/1\/ppmtopi1"}},{"Process":{"Description":null,"Process Name":"ppmtopict","Link":"https:\/\/linux.die.net\/man\/1\/ppmtopict"}},{"Process":{"Description":null,"Process Name":"ppmtopj","Link":"https:\/\/linux.die.net\/man\/1\/ppmtopj"}},{"Process":{"Description":null,"Process Name":"ppmtopjxl","Link":"https:\/\/linux.die.net\/man\/1\/ppmtopjxl"}},{"Process":{"Description":null,"Process Name":"ppmtoppm","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoppm"}},{"Process":{"Description":null,"Process Name":"ppmtopuzz","Link":"https:\/\/linux.die.net\/man\/1\/ppmtopuzz"}},{"Process":{"Description":null,"Process Name":"ppmtorgb3","Link":"https:\/\/linux.die.net\/man\/1\/ppmtorgb3"}},{"Process":{"Description":null,"Process Name":"ppmtosixel","Link":"https:\/\/linux.die.net\/man\/1\/ppmtosixel"}},{"Process":{"Description":null,"Process Name":"ppmtoterm","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoterm"}},{"Process":{"Description":null,"Process Name":"ppmtouil","Link":"https:\/\/linux.die.net\/man\/1\/ppmtouil"}},{"Process":{"Description":null,"Process Name":"ppmtowinicon","Link":"https:\/\/linux.die.net\/man\/1\/ppmtowinicon"}},{"Process":{"Description":null,"Process Name":"ppmtoxpm","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoxpm"}},{"Process":{"Description":null,"Process Name":"ppmtoy4m","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoy4m"}},{"Process":{"Description":null,"Process Name":"ppmtoyuv","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoyuv"}},{"Process":{"Description":null,"Process Name":"ppmtoyuvsplit","Link":"https:\/\/linux.die.net\/man\/1\/ppmtoyuvsplit"}},{"Process":{"Description":null,"Process Name":"ppmtv","Link":"https:\/\/linux.die.net\/man\/1\/ppmtv"}},{"Process":{"Description":null,"Process Name":"ppmwheel","Link":"https:\/\/linux.die.net\/man\/1\/ppmwheel"}},{"Process":{"Description":null,"Process Name":"pport","Link":"https:\/\/linux.die.net\/man\/1\/pport"}},{"Process":{"Description":null,"Process Name":"pportd","Link":"https:\/\/linux.die.net\/man\/1\/pportd"}},{"Process":{"Description":null,"Process Name":"pprof","Link":"https:\/\/linux.die.net\/man\/1\/pprof"}},{"Process":{"Description":null,"Process Name":"pptemplate","Link":"https:\/\/linux.die.net\/man\/1\/pptemplate"}},{"Process":{"Description":null,"Process Name":"ppudump","Link":"https:\/\/linux.die.net\/man\/1\/ppudump"}},{"Process":{"Description":null,"Process Name":"ppufiles","Link":"https:\/\/linux.die.net\/man\/1\/ppufiles"}},{"Process":{"Description":null,"Process Name":"ppumove","Link":"https:\/\/linux.die.net\/man\/1\/ppumove"}},{"Process":{"Description":null,"Process Name":"pq2","Link":"https:\/\/linux.die.net\/man\/1\/pq2"}},{"Process":{"Description":null,"Process Name":"pq2-ana-dist","Link":"https:\/\/linux.die.net\/man\/1\/pq2-ana-dist"}},{"Process":{"Description":null,"Process Name":"pq2-cache","Link":"https:\/\/linux.die.net\/man\/1\/pq2-cache"}},{"Process":{"Description":null,"Process Name":"pq2-info-server","Link":"https:\/\/linux.die.net\/man\/1\/pq2-info-server"}},{"Process":{"Description":null,"Process Name":"pq2-ls","Link":"https:\/\/linux.die.net\/man\/1\/pq2-ls"}},{"Process":{"Description":null,"Process Name":"pq2-ls-files","Link":"https:\/\/linux.die.net\/man\/1\/pq2-ls-files"}},{"Process":{"Description":null,"Process Name":"pq2-ls-files-server","Link":"https:\/\/linux.die.net\/man\/1\/pq2-ls-files-server"}},{"Process":{"Description":null,"Process Name":"pq2-put","Link":"https:\/\/linux.die.net\/man\/1\/pq2-put"}},{"Process":{"Description":null,"Process Name":"pq2-redistribute","Link":"https:\/\/linux.die.net\/man\/1\/pq2-redistribute"}},{"Process":{"Description":null,"Process Name":"pq2-rm","Link":"https:\/\/linux.die.net\/man\/1\/pq2-rm"}},{"Process":{"Description":null,"Process Name":"pq2-verify","Link":"https:\/\/linux.die.net\/man\/1\/pq2-verify"}},{"Process":{"Description":null,"Process Name":"pr","Link":"https:\/\/linux.die.net\/man\/1\/pr"}},{"Process":{"Description":null,"Process Name":"pr3287","Link":"https:\/\/linux.die.net\/man\/1\/pr3287"}},{"Process":{"Description":null,"Process Name":"prancid","Link":"https:\/\/linux.die.net\/man\/1\/prancid"}},{"Process":{"Description":null,"Process Name":"pre2ncgm","Link":"https:\/\/linux.die.net\/man\/1\/pre2ncgm"}},{"Process":{"Description":null,"Process Name":"preparehistfactory","Link":"https:\/\/linux.die.net\/man\/1\/preparehistfactory"}},{"Process":{"Description":null,"Process Name":"pretranslate","Link":"https:\/\/linux.die.net\/man\/1\/pretranslate"}},{"Process":{"Description":null,"Process Name":"prevd","Link":"https:\/\/linux.die.net\/man\/1\/prevd"}},{"Process":{"Description":null,"Process Name":"prezip-bin","Link":"https:\/\/linux.die.net\/man\/1\/prezip-bin"}},{"Process":{"Description":null,"Process Name":"prg2lout","Link":"https:\/\/linux.die.net\/man\/1\/prg2lout"}},{"Process":{"Description":null,"Process Name":"printafm","Link":"https:\/\/linux.die.net\/man\/1\/printafm"}},{"Process":{"Description":null,"Process Name":"printcbm","Link":"https:\/\/linux.die.net\/man\/1\/printcbm"}},{"Process":{"Description":null,"Process Name":"printenv","Link":"https:\/\/linux.die.net\/man\/1\/printenv"}},{"Process":{"Description":null,"Process Name":"printf","Link":"https:\/\/linux.die.net\/man\/1\/printf"}},{"Process":{"Description":null,"Process Name":"printlines","Link":"https:\/\/linux.die.net\/man\/1\/printlines"}},{"Process":{"Description":null,"Process Name":"privoxy","Link":"https:\/\/linux.die.net\/man\/1\/privoxy"}},{"Process":{"Description":null,"Process Name":"prj2make","Link":"https:\/\/linux.die.net\/man\/1\/prj2make"}},{"Process":{"Description":null,"Process Name":"prm","Link":"https:\/\/linux.die.net\/man\/1\/prm"}},{"Process":{"Description":null,"Process Name":"prmdir","Link":"https:\/\/linux.die.net\/man\/1\/prmdir"}},{"Process":{"Description":null,"Process Name":"processcsv.py","Link":"https:\/\/linux.die.net\/man\/1\/processcsv.py"}},{"Process":{"Description":null,"Process Name":"procmail","Link":"https:\/\/linux.die.net\/man\/1\/procmail"}},{"Process":{"Description":null,"Process Name":"procserv","Link":"https:\/\/linux.die.net\/man\/1\/procserv"}},{"Process":{"Description":null,"Process Name":"profiles","Link":"https:\/\/linux.die.net\/man\/1\/profiles"}},{"Process":{"Description":null,"Process Name":"progress","Link":"https:\/\/linux.die.net\/man\/1\/progress"}},{"Process":{"Description":null,"Process Name":"proj","Link":"https:\/\/linux.die.net\/man\/1\/proj"}},{"Process":{"Description":null,"Process Name":"project","Link":"https:\/\/linux.die.net\/man\/1\/project"}},{"Process":{"Description":null,"Process Name":"proof","Link":"https:\/\/linux.die.net\/man\/1\/proof"}},{"Process":{"Description":null,"Process Name":"proofd","Link":"https:\/\/linux.die.net\/man\/1\/proofd"}},{"Process":{"Description":null,"Process Name":"proofserv","Link":"https:\/\/linux.die.net\/man\/1\/proofserv"}},{"Process":{"Description":null,"Process Name":"prop2po","Link":"https:\/\/linux.die.net\/man\/1\/prop2po"}},{"Process":{"Description":null,"Process Name":"propwatch","Link":"https:\/\/linux.die.net\/man\/1\/propwatch"}},{"Process":{"Description":null,"Process Name":"prosodyctl","Link":"https:\/\/linux.die.net\/man\/1\/prosodyctl"}},{"Process":{"Description":null,"Process Name":"protoize","Link":"https:\/\/linux.die.net\/man\/1\/protoize"}},{"Process":{"Description":null,"Process Name":"proton","Link":"https:\/\/linux.die.net\/man\/1\/proton"}},{"Process":{"Description":null,"Process Name":"prove","Link":"https:\/\/linux.die.net\/man\/1\/prove"}},{"Process":{"Description":null,"Process Name":"providence","Link":"https:\/\/linux.die.net\/man\/1\/providence"}},{"Process":{"Description":null,"Process Name":"proxy-init.pl","Link":"https:\/\/linux.die.net\/man\/1\/proxy-init.pl"}},{"Process":{"Description":null,"Process Name":"proxymngr","Link":"https:\/\/linux.die.net\/man\/1\/proxymngr"}},{"Process":{"Description":null,"Process Name":"proxytunnel","Link":"https:\/\/linux.die.net\/man\/1\/proxytunnel"}},{"Process":{"Description":null,"Process Name":"prqd","Link":"https:\/\/linux.die.net\/man\/1\/prqd"}},{"Process":{"Description":null,"Process Name":"prqdcl","Link":"https:\/\/linux.die.net\/man\/1\/prqdcl"}},{"Process":{"Description":null,"Process Name":"prun","Link":"https:\/\/linux.die.net\/man\/1\/prun"}},{"Process":{"Description":null,"Process Name":"prune","Link":"https:\/\/linux.die.net\/man\/1\/prune"}},{"Process":{"Description":null,"Process Name":"pruneemptydirs","Link":"https:\/\/linux.die.net\/man\/1\/pruneemptydirs"}},{"Process":{"Description":null,"Process Name":"ps","Link":"https:\/\/linux.die.net\/man\/1\/ps"}},{"Process":{"Description":null,"Process Name":"ps2ascii","Link":"https:\/\/linux.die.net\/man\/1\/ps2ascii"}},{"Process":{"Description":null,"Process Name":"ps2eps","Link":"https:\/\/linux.die.net\/man\/1\/ps2eps"}},{"Process":{"Description":null,"Process Name":"ps2epsi","Link":"https:\/\/linux.die.net\/man\/1\/ps2epsi"}},{"Process":{"Description":null,"Process Name":"ps2frag","Link":"https:\/\/linux.die.net\/man\/1\/ps2frag"}},{"Process":{"Description":null,"Process Name":"ps2pdf","Link":"https:\/\/linux.die.net\/man\/1\/ps2pdf"}},{"Process":{"Description":null,"Process Name":"ps2pdf12","Link":"https:\/\/linux.die.net\/man\/1\/ps2pdf12"}},{"Process":{"Description":null,"Process Name":"ps2pdf13","Link":"https:\/\/linux.die.net\/man\/1\/ps2pdf13"}},{"Process":{"Description":null,"Process Name":"ps2pdfwr","Link":"https:\/\/linux.die.net\/man\/1\/ps2pdfwr"}},{"Process":{"Description":null,"Process Name":"ps2pk","Link":"https:\/\/linux.die.net\/man\/1\/ps2pk"}},{"Process":{"Description":null,"Process Name":"ps2ps","Link":"https:\/\/linux.die.net\/man\/1\/ps2ps"}},{"Process":{"Description":null,"Process Name":"ps2raster","Link":"https:\/\/linux.die.net\/man\/1\/ps2raster"}},{"Process":{"Description":null,"Process Name":"ps2sp","Link":"https:\/\/linux.die.net\/man\/1\/ps2sp"}},{"Process":{"Description":null,"Process Name":"ps_evol","Link":"https:\/\/linux.die.net\/man\/1\/ps_evol"}},{"Process":{"Description":null,"Process Name":"psame","Link":"https:\/\/linux.die.net\/man\/1\/psame"}},{"Process":{"Description":null,"Process Name":"psbasemap","Link":"https:\/\/linux.die.net\/man\/1\/psbasemap"}},{"Process":{"Description":null,"Process Name":"psbbox","Link":"https:\/\/linux.die.net\/man\/1\/psbbox"}},{"Process":{"Description":null,"Process Name":"psblack","Link":"https:\/\/linux.die.net\/man\/1\/psblack"}},{"Process":{"Description":null,"Process Name":"psbook","Link":"https:\/\/linux.die.net\/man\/1\/psbook"}},{"Process":{"Description":null,"Process Name":"psclip","Link":"https:\/\/linux.die.net\/man\/1\/psclip"}},{"Process":{"Description":null,"Process Name":"pscoast","Link":"https:\/\/linux.die.net\/man\/1\/pscoast"}},{"Process":{"Description":null,"Process Name":"pscontour","Link":"https:\/\/linux.die.net\/man\/1\/pscontour"}},{"Process":{"Description":null,"Process Name":"pscoupe","Link":"https:\/\/linux.die.net\/man\/1\/pscoupe"}},{"Process":{"Description":null,"Process Name":"pscp","Link":"https:\/\/linux.die.net\/man\/1\/pscp"}},{"Process":{"Description":null,"Process Name":"pscss","Link":"https:\/\/linux.die.net\/man\/1\/pscss"}},{"Process":{"Description":null,"Process Name":"psed","Link":"https:\/\/linux.die.net\/man\/1\/psed"}},{"Process":{"Description":null,"Process Name":"psfaddtable","Link":"https:\/\/linux.die.net\/man\/1\/psfaddtable"}},{"Process":{"Description":null,"Process Name":"psfgettable","Link":"https:\/\/linux.die.net\/man\/1\/psfgettable"}},{"Process":{"Description":null,"Process Name":"psfstriptable","Link":"https:\/\/linux.die.net\/man\/1\/psfstriptable"}},{"Process":{"Description":null,"Process Name":"psftp","Link":"https:\/\/linux.die.net\/man\/1\/psftp"}},{"Process":{"Description":null,"Process Name":"psfxtable","Link":"https:\/\/linux.die.net\/man\/1\/psfxtable"}},{"Process":{"Description":null,"Process Name":"pshistogram","Link":"https:\/\/linux.die.net\/man\/1\/pshistogram"}},{"Process":{"Description":null,"Process Name":"psiconv","Link":"https:\/\/linux.die.net\/man\/1\/psiconv"}},{"Process":{"Description":null,"Process Name":"psiconv-config","Link":"https:\/\/linux.die.net\/man\/1\/psiconv-config"}},{"Process":{"Description":null,"Process Name":"psidtopgm","Link":"https:\/\/linux.die.net\/man\/1\/psidtopgm"}},{"Process":{"Description":null,"Process Name":"psimage","Link":"https:\/\/linux.die.net\/man\/1\/psimage"}},{"Process":{"Description":null,"Process Name":"psk-crack","Link":"https:\/\/linux.die.net\/man\/1\/psk-crack"}},{"Process":{"Description":null,"Process Name":"psktool","Link":"https:\/\/linux.die.net\/man\/1\/psktool"}},{"Process":{"Description":null,"Process Name":"pslatex","Link":"https:\/\/linux.die.net\/man\/1\/pslatex"}},{"Process":{"Description":null,"Process Name":"pslegend","Link":"https:\/\/linux.die.net\/man\/1\/pslegend"}},{"Process":{"Description":null,"Process Name":"pslogin","Link":"https:\/\/linux.die.net\/man\/1\/pslogin"}},{"Process":{"Description":null,"Process Name":"psmandup","Link":"https:\/\/linux.die.net\/man\/1\/psmandup"}},{"Process":{"Description":null,"Process Name":"psmask","Link":"https:\/\/linux.die.net\/man\/1\/psmask"}},{"Process":{"Description":null,"Process Name":"psmeca","Link":"https:\/\/linux.die.net\/man\/1\/psmeca"}},{"Process":{"Description":null,"Process Name":"psmegaplot","Link":"https:\/\/linux.die.net\/man\/1\/psmegaplot"}},{"Process":{"Description":null,"Process Name":"psmerge","Link":"https:\/\/linux.die.net\/man\/1\/psmerge"}},{"Process":{"Description":null,"Process Name":"psnup","Link":"https:\/\/linux.die.net\/man\/1\/psnup"}},{"Process":{"Description":null,"Process Name":"psonly","Link":"https:\/\/linux.die.net\/man\/1\/psonly"}},{"Process":{"Description":null,"Process Name":"pspax","Link":"https:\/\/linux.die.net\/man\/1\/pspax"}},{"Process":{"Description":null,"Process Name":"pspell-config","Link":"https:\/\/linux.die.net\/man\/1\/pspell-config"}},{"Process":{"Description":null,"Process Name":"psplit","Link":"https:\/\/linux.die.net\/man\/1\/psplit"}},{"Process":{"Description":null,"Process Name":"pspolar","Link":"https:\/\/linux.die.net\/man\/1\/pspolar"}},{"Process":{"Description":null,"Process Name":"psql","Link":"https:\/\/linux.die.net\/man\/1\/psql"}},{"Process":{"Description":null,"Process Name":"psresize","Link":"https:\/\/linux.die.net\/man\/1\/psresize"}},{"Process":{"Description":null,"Process Name":"psrose","Link":"https:\/\/linux.die.net\/man\/1\/psrose"}},{"Process":{"Description":null,"Process Name":"psscale","Link":"https:\/\/linux.die.net\/man\/1\/psscale"}},{"Process":{"Description":null,"Process Name":"pssegy","Link":"https:\/\/linux.die.net\/man\/1\/pssegy"}},{"Process":{"Description":null,"Process Name":"pssegyz","Link":"https:\/\/linux.die.net\/man\/1\/pssegyz"}},{"Process":{"Description":null,"Process Name":"psselect","Link":"https:\/\/linux.die.net\/man\/1\/psselect"}},{"Process":{"Description":null,"Process Name":"psset","Link":"https:\/\/linux.die.net\/man\/1\/psset"}},{"Process":{"Description":null,"Process Name":"pssh","Link":"https:\/\/linux.die.net\/man\/1\/pssh"}},{"Process":{"Description":null,"Process Name":"pst2dii","Link":"https:\/\/linux.die.net\/man\/1\/pst2dii"}},{"Process":{"Description":null,"Process Name":"pst2ldif","Link":"https:\/\/linux.die.net\/man\/1\/pst2ldif"}},{"Process":{"Description":null,"Process Name":"pstack","Link":"https:\/\/linux.die.net\/man\/1\/pstack"}},{"Process":{"Description":null,"Process Name":"pstatus","Link":"https:\/\/linux.die.net\/man\/1\/pstatus"}},{"Process":{"Description":null,"Process Name":"pstex2eps","Link":"https:\/\/linux.die.net\/man\/1\/pstex2eps"}},{"Process":{"Description":null,"Process Name":"pstext","Link":"https:\/\/linux.die.net\/man\/1\/pstext"}},{"Process":{"Description":null,"Process Name":"pstoedit","Link":"https:\/\/linux.die.net\/man\/1\/pstoedit"}},{"Process":{"Description":null,"Process Name":"pstoimg","Link":"https:\/\/linux.die.net\/man\/1\/pstoimg"}},{"Process":{"Description":null,"Process Name":"pstopdf","Link":"https:\/\/linux.die.net\/man\/1\/pstopdf"}},{"Process":{"Description":null,"Process Name":"pstopnm","Link":"https:\/\/linux.die.net\/man\/1\/pstopnm"}},{"Process":{"Description":null,"Process Name":"pstops","Link":"https:\/\/linux.die.net\/man\/1\/pstops"}},{"Process":{"Description":null,"Process Name":"pstree","Link":"https:\/\/linux.die.net\/man\/1\/pstree"}},{"Process":{"Description":null,"Process Name":"pstruct","Link":"https:\/\/linux.die.net\/man\/1\/pstruct"}},{"Process":{"Description":null,"Process Name":"psub","Link":"https:\/\/linux.die.net\/man\/1\/psub"}},{"Process":{"Description":null,"Process Name":"psvelo","Link":"https:\/\/linux.die.net\/man\/1\/psvelo"}},{"Process":{"Description":null,"Process Name":"pswhite","Link":"https:\/\/linux.die.net\/man\/1\/pswhite"}},{"Process":{"Description":null,"Process Name":"pswiggle","Link":"https:\/\/linux.die.net\/man\/1\/pswiggle"}},{"Process":{"Description":null,"Process Name":"pswrap","Link":"https:\/\/linux.die.net\/man\/1\/pswrap"}},{"Process":{"Description":null,"Process Name":"psxy","Link":"https:\/\/linux.die.net\/man\/1\/psxy"}},{"Process":{"Description":null,"Process Name":"psxyz","Link":"https:\/\/linux.die.net\/man\/1\/psxyz"}},{"Process":{"Description":null,"Process Name":"ptagdir","Link":"https:\/\/linux.die.net\/man\/1\/ptagdir"}},{"Process":{"Description":null,"Process Name":"ptags","Link":"https:\/\/linux.die.net\/man\/1\/ptags"}},{"Process":{"Description":null,"Process Name":"ptar","Link":"https:\/\/linux.die.net\/man\/1\/ptar"}},{"Process":{"Description":null,"Process Name":"ptardiff","Link":"https:\/\/linux.die.net\/man\/1\/ptardiff"}},{"Process":{"Description":null,"Process Name":"pterm","Link":"https:\/\/linux.die.net\/man\/1\/pterm"}},{"Process":{"Description":null,"Process Name":"pth-config","Link":"https:\/\/linux.die.net\/man\/1\/pth-config"}},{"Process":{"Description":null,"Process Name":"ptked","Link":"https:\/\/linux.die.net\/man\/1\/ptked"}},{"Process":{"Description":null,"Process Name":"ptksh","Link":"https:\/\/linux.die.net\/man\/1\/ptksh"}},{"Process":{"Description":null,"Process Name":"ptop","Link":"https:\/\/linux.die.net\/man\/1\/ptop"}},{"Process":{"Description":null,"Process Name":"ptx","Link":"https:\/\/linux.die.net\/man\/1\/ptx"}},{"Process":{"Description":null,"Process Name":"publican","Link":"https:\/\/linux.die.net\/man\/1\/publican"}},{"Process":{"Description":null,"Process Name":"pullnews","Link":"https:\/\/linux.die.net\/man\/1\/pullnews"}},{"Process":{"Description":null,"Process Name":"pulsar","Link":"https:\/\/linux.die.net\/man\/1\/pulsar"}},{"Process":{"Description":null,"Process Name":"pulseaudio","Link":"https:\/\/linux.die.net\/man\/1\/pulseaudio"}},{"Process":{"Description":null,"Process Name":"pumount","Link":"https:\/\/linux.die.net\/man\/1\/pumount"}},{"Process":{"Description":null,"Process Name":"pump","Link":"https:\/\/linux.die.net\/man\/1\/pump"}},{"Process":{"Description":null,"Process Name":"pure","Link":"https:\/\/linux.die.net\/man\/1\/pure"}},{"Process":{"Description":null,"Process Name":"pushd","Link":"https:\/\/linux.die.net\/man\/1\/pushd"}},{"Process":{"Description":null,"Process Name":"putty","Link":"https:\/\/linux.die.net\/man\/1\/putty"}},{"Process":{"Description":null,"Process Name":"puttygen","Link":"https:\/\/linux.die.net\/man\/1\/puttygen"}},{"Process":{"Description":null,"Process Name":"puttytel","Link":"https:\/\/linux.die.net\/man\/1\/puttytel"}},{"Process":{"Description":null,"Process Name":"puudecode","Link":"https:\/\/linux.die.net\/man\/1\/puudecode"}},{"Process":{"Description":null,"Process Name":"puuencode","Link":"https:\/\/linux.die.net\/man\/1\/puuencode"}},{"Process":{"Description":null,"Process Name":"pv","Link":"https:\/\/linux.die.net\/man\/1\/pv"}},{"Process":{"Description":null,"Process Name":"pva-addvo","Link":"https:\/\/linux.die.net\/man\/1\/pva-addvo"}},{"Process":{"Description":null,"Process Name":"pva-dbschema-update","Link":"https:\/\/linux.die.net\/man\/1\/pva-dbschema-update"}},{"Process":{"Description":null,"Process Name":"pvf","Link":"https:\/\/linux.die.net\/man\/1\/pvf"}},{"Process":{"Description":null,"Process Name":"pvfamp","Link":"https:\/\/linux.die.net\/man\/1\/pvfamp"}},{"Process":{"Description":null,"Process Name":"pvfcut","Link":"https:\/\/linux.die.net\/man\/1\/pvfcut"}},{"Process":{"Description":null,"Process Name":"pvfecho","Link":"https:\/\/linux.die.net\/man\/1\/pvfecho"}},{"Process":{"Description":null,"Process Name":"pvffft","Link":"https:\/\/linux.die.net\/man\/1\/pvffft"}},{"Process":{"Description":null,"Process Name":"pvffile","Link":"https:\/\/linux.die.net\/man\/1\/pvffile"}},{"Process":{"Description":null,"Process Name":"pvffilter","Link":"https:\/\/linux.die.net\/man\/1\/pvffilter"}},{"Process":{"Description":null,"Process Name":"pvfmix","Link":"https:\/\/linux.die.net\/man\/1\/pvfmix"}},{"Process":{"Description":null,"Process Name":"pvfnoise","Link":"https:\/\/linux.die.net\/man\/1\/pvfnoise"}},{"Process":{"Description":null,"Process Name":"pvfreverse","Link":"https:\/\/linux.die.net\/man\/1\/pvfreverse"}},{"Process":{"Description":null,"Process Name":"pvfsine","Link":"https:\/\/linux.die.net\/man\/1\/pvfsine"}},{"Process":{"Description":null,"Process Name":"pvfspeed","Link":"https:\/\/linux.die.net\/man\/1\/pvfspeed"}},{"Process":{"Description":null,"Process Name":"pvftoau","Link":"https:\/\/linux.die.net\/man\/1\/pvftoau"}},{"Process":{"Description":null,"Process Name":"pvftobasic","Link":"https:\/\/linux.die.net\/man\/1\/pvftobasic"}},{"Process":{"Description":null,"Process Name":"pvftolin","Link":"https:\/\/linux.die.net\/man\/1\/pvftolin"}},{"Process":{"Description":null,"Process Name":"pvftormd","Link":"https:\/\/linux.die.net\/man\/1\/pvftormd"}},{"Process":{"Description":null,"Process Name":"pvftovoc","Link":"https:\/\/linux.die.net\/man\/1\/pvftovoc"}},{"Process":{"Description":null,"Process Name":"pvftowav","Link":"https:\/\/linux.die.net\/man\/1\/pvftowav"}},{"Process":{"Description":null,"Process Name":"pvm","Link":"https:\/\/linux.die.net\/man\/1\/pvm"}},{"Process":{"Description":null,"Process Name":"pvm_intro","Link":"https:\/\/linux.die.net\/man\/1\/pvm_intro"}},{"Process":{"Description":null,"Process Name":"pvm_shmd","Link":"https:\/\/linux.die.net\/man\/1\/pvm_shmd"}},{"Process":{"Description":null,"Process Name":"pvmd","Link":"https:\/\/linux.die.net\/man\/1\/pvmd"}},{"Process":{"Description":null,"Process Name":"pvmd3","Link":"https:\/\/linux.die.net\/man\/1\/pvmd3"}},{"Process":{"Description":null,"Process Name":"pwd","Link":"https:\/\/linux.die.net\/man\/1\/pwd"}},{"Process":{"Description":null,"Process Name":"pwdhash","Link":"https:\/\/linux.die.net\/man\/1\/pwdhash"}},{"Process":{"Description":null,"Process Name":"pwdx","Link":"https:\/\/linux.die.net\/man\/1\/pwdx"}},{"Process":{"Description":null,"Process Name":"pwgen","Link":"https:\/\/linux.die.net\/man\/1\/pwgen"}},{"Process":{"Description":null,"Process Name":"pwhich","Link":"https:\/\/linux.die.net\/man\/1\/pwhich"}},{"Process":{"Description":null,"Process Name":"pwhois","Link":"https:\/\/linux.die.net\/man\/1\/pwhois"}},{"Process":{"Description":null,"Process Name":"pwmake","Link":"https:\/\/linux.die.net\/man\/1\/pwmake"}},{"Process":{"Description":null,"Process Name":"pwscore","Link":"https:\/\/linux.die.net\/man\/1\/pwscore"}},{"Process":{"Description":null,"Process Name":"pxz","Link":"https:\/\/linux.die.net\/man\/1\/pxz"}},{"Process":{"Description":null,"Process Name":"pyacc","Link":"https:\/\/linux.die.net\/man\/1\/pyacc"}},{"Process":{"Description":null,"Process Name":"pycolor","Link":"https:\/\/linux.die.net\/man\/1\/pycolor"}},{"Process":{"Description":null,"Process Name":"pydf","Link":"https:\/\/linux.die.net\/man\/1\/pydf"}},{"Process":{"Description":null,"Process Name":"pygmentize","Link":"https:\/\/linux.die.net\/man\/1\/pygmentize"}},{"Process":{"Description":null,"Process Name":"pyhtmlizer","Link":"https:\/\/linux.die.net\/man\/1\/pyhtmlizer"}},{"Process":{"Description":null,"Process Name":"pylint","Link":"https:\/\/linux.die.net\/man\/1\/pylint"}},{"Process":{"Description":null,"Process Name":"pynag","Link":"https:\/\/linux.die.net\/man\/1\/pynag"}},{"Process":{"Description":null,"Process Name":"pyreverse","Link":"https:\/\/linux.die.net\/man\/1\/pyreverse"}},{"Process":{"Description":null,"Process Name":"pyro","Link":"https:\/\/linux.die.net\/man\/1\/pyro"}},{"Process":{"Description":null,"Process Name":"python","Link":"https:\/\/linux.die.net\/man\/1\/python"}},{"Process":{"Description":null,"Process Name":"python-nitrate","Link":"https:\/\/linux.die.net\/man\/1\/python-nitrate"}},{"Process":{"Description":null,"Process Name":"pytrademgen","Link":"https:\/\/linux.die.net\/man\/1\/pytrademgen"}}]