[{"Process":{"Description":"Program nad2nad is a filter to convert data between North America Datum 1927 (NAD27) and North American Datum 1983. nad2nad can optionally process both State Plane Coordinate System (SPCS) and Universal Transverse Mercator (UTM) grid data as well as geographic data for both input and output. This can also be accomplished with the cs2cs program. The following control parameters can appear in any order: -[i|o] keyword[,keyword] The -i and -o option expect keyword arguments which define various characteristics and processing modes of the respective input data. Usage allows multiple arguments to be included with a - operator when separated by commas. Datum conversion requires the data to be in geographic coordinates, but nad2nad will allow conversion of data to and from SPCS or UTM grid systems. The following are keywords and arguments recognized by both the -i and -o that will apply to respective input and output conversion of user data to internal geographic coordinates: 27|83 datum of data utm=n UTM coordinates in meters for zone n spcs=n for data in SPCS coordinates, where n is state zone number. feet data units are in U.S. Surveyor's feet. This is allowed only when the spcs option been previously used. Default coordinates are in meters. bin for data in binary form. rev data in lat-lon order rather than default lon-lat order. hp=ss use high precision conversion zone ss. Certain States have ancillary correction tables to further refine the basic conus table. Ss key and States are: FL Florida MD Maryland TN Tennessee WI Wisconsin WO Washington, Oregon and northern part of California. -t a A specifies a character employed as the first character to denote a control line to be passed through without processing. This option applicable to ascii input only. (# is the default value). -e string String is an arbitrary string to be output if an error is detected during data transformations. The default value is: *\\t*. Note that if the -o bin option is employed, an error is output as HUGE_VAL for both values. -r region specifies which regional conversion table to employ which are identified by the following: conus - conterminous 48 States alaska - State of Alaska hawaii - State of Hawaii prvi - Puerto Rico and Virgin Islands stgeorge - St. George Is, Alaska stpaul - St. Paul Is, Alaska stlrnc - St. Lawrence Is, Alaska -E Input coordinates are echoed to output before ouput values. -f format Format is a printf format string to control the form of the output values. For inverse projections, the output will be in degrees when this option is employed. If a format is specified for inverse projection the output data will be in decimal degrees. The default format is %.2f for forward projection and DMS for inverse. -[w|W] n N is the number of significant fractional digits to employ for seconds output (when the option is not specified, -w3 is assumed). When -W is employed the fields will be constant width and with leading zeroes. One or more files (processed in left to right order) specify the source of data to be transformed. A - will specify the location of processing standard input. If no files are specified, the input is assumed to be from stdin. For ASCII input data the two data values must be in the first two white space separated fields and when both input and output are ASCII all trailing portions of the input line are appended to the output line. Input geographic data (longitude and latitude) must be in DMS format when neither utm nor spcs is specified, otherwise in meters or feet (feet option used). Input data fields must be separated by white space and not have imbedded white space. Output data will be in tab separated fields of DMS or grid coordinates in meters or feet. Any data after the two input values are echoed after the two output data values.","Process Name":"nad2nad","Link":"https:\/\/linux.die.net\/man\/1\/nad2nad"}},{"Process":{"Description":"Nagstamon is a Nagios status monitor which takes place in systray or on desktop (GNOME, KDE) as floating statusbar to inform you in realtime about the status of your Nagios monitored network. Nagstamon connects to multiple Nagios, Opsview, Icinga, Centreon, Op5\/Ninja and Check_MK Multisite monitoring servers.. The command can optionally take one argument giving the path to an alternate configuration file.","Process Name":"nagstamon","Link":"https:\/\/linux.die.net\/man\/1\/nagstamon"}},{"Process":{"Description":"Mailx is an intelligent mail processing system, which has a command syntax reminiscent of ed(1) with lines replaced by messages. It is based on Berkeley Mail 8.1, is intended to provide the functionality of the POSIX mailx command, and offers extensions for MIME, IMAP, POP3, SMTP, and S\/MIME. Mailx provides enhanced features for interactive use, such as caching and disconnected operation for IMAP, message threading, scoring, and filtering. It is also usable as a mail batch language, both for sending and receiving mail. The following options are accepted: -A name Executes an account command (see below) for name after the startup files have been read. -a file Attach the given file to the message. -B Make standard input and standard output line-buffered. -b address Send blind carbon copies to list. List should be a comma-separated list of names. -c address Send carbon copies to list of users. -D Start in disconnected mode; see the description for the disconnected variable option. -d Enables debugging messages and disables the actual delivery of messages. Unlike -v, this option is intended for mailx development only. -e Just check if mail is present in the system mailbox. If yes, return an exit status of zero, else, a non-zero value. -E If an outgoing message does not contain any text in its first or only message part, do not send it but discard it silently, effectively setting the skipemptybody variable at program startup. This is useful for sending messages from scripts started by cron(8). -f [ file] Read in the contents of the user's mbox (or the specified file) for processing; when mailx is quit, it writes undeleted messages back to this file. The string file is handled as described for the folder command below. -F Save the message to send in a file named after the local part of the first recipient's address. -H Print header summaries for all messages and exit. -h hops Invoke sendmail with the specified hop count. This option has no effect when SMTP is used for sending mail. -i Ignore tty interrupt signals. This is particularly useful when using mailx on noisy phone lines. -I Shows the 'Newsgroup:' or 'Article-Id:' fields in the header summary. Only applicable in combination with -f. -n Inhibits reading \/etc\/mail.rc upon startup. This option should be activated for mailx scripts that are invoked on more than one machine, because the contents of that file may differ between them. -N Inhibits the initial display of message headers when reading mail or editing a mail folder. -q file Start the message with the contents of the specified file. May be given in send mode only. -r address Sets the From address. Overrides any from variable specified in environment or startup files. Tilde escapes are disabled. The -r address options are passed to the mail transfer agent unless SMTP is used. This option exists for compatibility only; it is recommended to set the from variable directly instead. -R Opens any folders read-only. -s subject Specify subject on command line (only the first argument after the -s flag is used as a subject; be careful to quote subjects containing spaces). -S variable[ = value] Sets the internal option variable and, in case of a string option, assigns value to it. -T name Writes the 'Message-Id:' and 'Article-Id:' header fields of each message read in the file name. Implies -I. Compressed files are handled as described for the folder command below. -t The message to be sent is expected to contain a message header with 'To:', 'Cc:', or 'Bcc:' fields giving its recipients. Recipients specified on the command line are ignored. -u user Reads the mailbox of the given user name. -v Verbose mode. The details of delivery are displayed on the user's terminal. -V Print mailx's version and exit. -~ Enable tilde escapes even if not in interactive mode. Sending mail To send a message to one or more people, mailx can be invoked with arguments which are the names of people to whom the mail will be sent. The user is then expected to type in his message, followed by an 'control-D' at the beginning of a line. The section below Replying to or originating mail, describes some features of mailx available to help when composing letters. Reading mail In normal usage mailx is given no arguments and checks the user's mail out of the post office, then prints out a one line header of each message found. The current message is initially the first message (numbered 1) and can be printed using the print command which can be abbreviated 'p'). The user can move among the messages much as he moves between lines in ed(1), with the commands '+' and '-' moving backwards and forwards, and simple numbers. Disposing of mail After examining a message the user can delete 'd') the message or reply 'r') to it. Deletion causes the mailx program to forget about the message. This is not irreversible; the message can be undeleted 'u') by giving its number, or the mailx session can be aborted by giving the exit 'x') command. Deleted messages will, however, usually disappear never to be seen again. Specifying messages Commands such as print and delete can be given a list of message numbers as arguments to apply to a number of messages at once. Thus ' delete 1 2' deletes messages 1 and 2, while ' delete 1-5' deletes messages 1 through 5. In sorted or threaded mode (see the sort and thread commands), ' delete 1-5' deletes the messages that are located between (and including) messages 1 through 5 in the sorted\/threaded order, as shown in the header summary. The following special message names exist: :n All new messages. :o All old messages (any not in state read or new). :u All unread messages. :d All deleted messages (for the undelete command). :r All read messages. :f All 'flagged' messages. :a All answered messages (cf. the markanswered variable). :t All messages marked as draft. :k All 'killed' messages. :j All messages classified as junk. . The current message. ; The message that was previously the current message. , The parent message of the current message, that is the message with the Message-ID given in the 'In-Reply-To:' field or the last entry of the 'References:' field of the current message. - The next previous undeleted message, or the next previous deleted message for the undelete command. In sorted\/threaded mode, the next previous such message in the sorted\/threaded order. + The next undeleted message, or the next deleted message for the undelete command. In sorted\/threaded mode, the next such message in the sorted\/threaded order. ^ The first undeleted message, or the first deleted message for the undelete command. In sorted\/threaded mode, the first such message in the sorted\/threaded order. $ The last message. In sorted\/threaded mode, the last message in the sorted\/threaded order. &x In threaded mode, selects the message addressed with x, where x is any other message specification, and all messages from the thread that begins at it. Otherwise, it is identical to x. If x is omitted, the thread beginning with the current message is selected. * All messages. ' All messages that were included in the message list for the previous command. \/ string All messages that contain string in the subject field (case ignored). See also the searchheaders variable. If string is empty, the string from the previous specification of that type is used again. address All messages from address. ( criterion ) All messages that satisfy the given IMAP-style SEARCH criterion. This addressing mode is available with all types of folders; for folders not located on IMAP servers, or for servers unable to execute the SEARCH command, mailx will perform the search locally. Strings must be enclosed by double quotes '\"' in their entirety if they contain white space or parentheses; within the quotes, only backslash '\\' is recognized as an escape character. All string searches are case-insensitive. When the description indicates that the 'envelope' representation of an address field is used, this means that the search string is checked against both a list constructed as (\"real name\" \"source-route\" \"local-part\" \"domain-part\")\n\n for each address, and the addresses without real names from the respective header field. Criteria can be nested using parentheses. ( criterion1 criterion2 ... criterionN ) All messages that satisfy all of the given criteria. (or criterion1 criterion2 ) All messages that satisfy either criterion1 or criterion2, or both. To connect more than two criteria using 'or', (or) specifications have to be nested using additional parentheses, as with '(or a (or b c))'; '(or a b c)' means ((a or b) and c). For a simple 'or' operation of independent criteria on the lowest nesting level, it is possible to achieve similar effects by using three separate criteria, as with '(a) (b) (c)'. (not criterion ) All messages that do not satisfy criterion. (bcc string ) All messages that contain string in the 'envelope' representation of the Bcc: field. (cc string ) All messages that contain string in the 'envelope' representation of the Cc: field. (from string ) All messages that contain string in the 'envelope' representation of the From: field. (subject string ) All messages that contain string in the Subject: field. (to string ) All messages that contain string in the 'envelope' representation of the To: field. (header name string ) All messages that contain string in the specified Name: field. (body string ) All messages that contain string in their body. (text string ) All messages that contain string in their header or body. (larger size ) All messages that are larger than size (in bytes). (smaller size ) All messages that are smaller than size (in bytes). (before date ) All messages that were received before date; date must be in the form d[ d] - mon - yyyy, where d[ d] is the day of the month as one or two digits, mon is the name of the month-one of 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', or 'Dec', and yyyy is the year as four digits; e.g. \"30-Aug-2004\". (on date ) All messages that were received on the specified date. (since date ) All messages that were received since the specified date. (sentbefore date ) All messages that were sent on the specified date. (senton date ) All messages that were sent on the specified date. (sentsince date ) All messages that were sent since the specified date. () The same criterion as for the previous search. This specification cannot be used as part of another criterion. If the previous command line contained more than one independent criterion, the last of those criteria is used. A practical method to read a set of messages is to issue a from command with the search criteria first to check for appropriate messages, and to read each single message then by typing ' '' repeatedly. Replying to or originating mail The reply command can be used to set up a response to a message, sending it back to the person who it was from. Text the user types in then, up to an end-of-file, defines the contents of the message. While the user is composing a message, mailx treats lines beginning with the character '~' specially. For instance, typing '~m' (alone on a line) will place a copy of the current message into the response right shifting it by a tabstop (see indentprefix variable, below). Other escapes will set up subject fields, add and delete recipients to the message, attach files to it and allow the user to escape to an editor to revise the message or to a shell to run some commands. (These options are given in the summary below.) Ending a mail processing session The user can end a mailx session with the quit ('q') command. Messages which have been examined go to the user's mbox file unless they have been deleted in which case they are discarded. Unexamined messages go back to the post office. (See the -f option above). Personal and systemwide distribution lists It is also possible to create a personal distribution lists so that, for instance, the user can send mail to ' cohorts' and have it go to a group of people. Such lists can be defined by placing a line like         alias cohorts bill ozalp jkf mark kridle@ucbcory\n\n in the file .mailrc in the user's home directory. The current list of such aliases can be displayed with the alias command in mailx. System wide distribution lists can be created by editing \/etc\/aliases, see aliases(5) and sendmail(8); these are kept in a different syntax. In mail the user sends, personal aliases will be expanded in mail sent to others so that they will be able to reply to the recipients. System wide aliases are not expanded when the mail is sent, but any reply returned to the machine will have the system wide alias expanded as all mail goes through sendmail. Recipient address specifications When an address is used to name a recipient (in any of To, Cc, or Bcc), names of local mail folders and pipes to external commands can also be specified; the message text is then written to them. The rules are: Any name which starts with a ' |' character specifies a pipe, the command string following the '|' is executed and the message is sent to its standard input; any other name which contains a ' @' character is treated as a mail address; any other name which starts with a ' +' character specifies a folder name; any other name which contains a ' \/' character but no ' !' or ' %' character before also specifies a folder name; what remains is treated as a mail address. Compressed folders are handled as described for the folder command below. Network mail (Internet \/ ARPA, UUCP, Berknet) See mailaddr(7) for a description of network addresses. Mailx has a number of options which can be set in the .mailrc file to alter its behavior; thus ' set askcc' enables the askcc feature. (These options are summarized below). MIME types For any outgoing attachment, mailx tries to determine the content type. It does this by reading MIME type files whose lines have the following syntax:         type\/subtype      extension [extension . . .] where type\/subtype are strings describing the file contents, and extension is the part of a filename starting after the last dot. Any line not immediately beginning with an ASCII alphabetical character is ignored by mailx. If there is a match with the extension of the file to attach, the given type\/subtype pair is used. Otherwise, or if the filename has no extension, the content types text\/plain or application\/octet-stream are used, the first for text or international text files, the second for any file that contains formatting characters other than newlines and horizontal tabulators. Character sets Mailx normally detects the character set of the terminal using the LC_CTYPE locale setting. If the locale cannot be used appropriately, the ttycharset variable should be set to provide an explicit value. When reading messages, their text is converted to the terminal character set if possible. Unprintable characters and illegal byte sequences are detected and replaced by Unicode substitute characters or question marks unless the print-all-chars is set at initialization time. The character set for outgoing messages is not necessarily the same as the one used on the terminal. If an outgoing text message contains characters not representable in US-ASCII, the character set being used must be declared within its header. Permissible values can be declared using the sendcharsets variable, separated by commas; mailx tries each of the values in order and uses the first appropriate one. If the message contains characters that cannot be represented in any of the given character sets, the message will not be sent, and its text will be saved to the 'dead.letter' file. Messages that contain NUL bytes are not converted. Outgoing attachments are converted if they are plain text. If the sendcharsets variable contains more than one character set name, the ~@ tilde escape will ask for the character sets for individual attachments if it is invoked without arguments. Best results are usually achieved when mailx is run in a UTF-8 locale on a UTF-8 capable terminal. In this setup, characters from various countries can be displayed, while it is still possible to use more simple character sets for sending to retain maximum compatibility with older mail clients. Commands Each command is typed on a line by itself, and may take arguments following the command word. The command need not be typed in its entirety - the first command which matches the typed prefix is used. For commands which take message lists as arguments, if no message list is given, then the next message forward which satisfies the command's requirements is used. If there are no messages forward of the current message, the search proceeds backwards, and if there are no good messages at all, mailx types ' applicable messages' and aborts the command. If the command begins with a # sign, the line is ignored. The arguments to commands can be quoted, using the following methods: \u2022 An argument can be enclosed between paired double-quotes \"\" or single-quotes ''; any white space, shell word expansion, or backslash characters within the quotes are treated literally as part of the argument. A double-quote will be treated literally within single-quotes and vice versa. These special properties of the quote marks occur only when they are paired at the beginning and end of the argument. \u2022 A backslash outside of the enclosing quotes is discarded and the following character is treated literally as part of the argument. \u2022 An unquoted backslash at the end of a command line is discarded and the next line continues the command. Filenames, where expected, are subjected to the following transformations, in sequence: \u2022 If the filename begins with an unquoted plus sign, and the folder variable is defined, the plus sign will be replaced by the value of the folder variable followed by a slash. If the folder variable is unset or is set to null, the filename will be unchanged. \u2022 Shell word expansions are applied to the filename. If more than a single pathname results from this expansion and the command is expecting one file, an error results. The following commands are provided: - Print out the preceding message. If given a numeric argument n, goes to the n'th previous message and prints it. ? Prints a brief summary of commands. ! Executes the shell (see sh(1) and csh(1)) command which follows. | A synonym for the pipe command. account (ac) Creates, selects or lists an email account. An account is formed by a group of commands, primarily of those to set variables. With two arguments, of which the second is a '{', the first argument gives an account name, and the following lines create a group of commands for that account until a line containing a single '}' appears. With one argument, the previously created group of commands for the account name is executed, and a folder command is executed for the system mailbox or inbox of that account. Without arguments, the list of accounts and their contents are printed. As an example,     account myisp {\n        set folder=imaps:\/\/mylogin@imap.myisp.example\n        set record=+Sent\n        set from=\"myname@myisp.example (My Name)\"\n        set smtp=smtp.myisp.example\n    }\n creates an account named 'myisp' which can later be selected by specifying 'account myisp'. alias (a) With no arguments, prints out all currently-defined aliases. With one argument, prints out that alias. With more than one argument, creates a new alias or changes an old one. alternates (alt) The alternates command is useful if the user has accounts on several machines. It can be used to inform mailx that the listed addresses all belong to the invoking user. When he replies to messages, mailx will not send a copy of the message to any of the addresses listed on the alternates list. If the alternates command is given with no argument, the current set of alternate names is displayed. answered (ans) Takes a message list and marks each message as a having been answered. This mark has no technical meaning in the mail system; it just causes messages to be marked in the header summary, and makes them specially addressable. cache Only applicable to cached IMAP mailboxes; takes a message list and reads the specified messages into the IMAP cache. call Calls a macro (see the define command). cd Same as chdir. certsave Only applicable to S\/MIME signed messages. Takes a message list and a file name and saves the certificates contained within the message signatures to the named file in both human-readable and PEM format. The certificates can later be used to send encrypted messages to the messages' originators by setting the smime-encrypt-user@host variable. chdir (ch) Changes the user's working directory to that specified, if given. If no directory is given, then changes to the user's login directory. classify (cl) Takes a list of messages and examines their contents for characteristics of junk mail using Bayesian filtering. Messages considered to be junk are then marked as such. The junk mail database is not changed. collapse (coll) Only applicable to threaded mode. Takes a message list and makes all replies to these messages invisible in header summaries, unless they are in state 'new'. connect (conn) If operating in disconnected mode on an IMAP mailbox, switch to online mode and connect to the mail server while retaining the mailbox status. See the description of the disconnected variable for more information. copy (c) The copy command does the same thing that save does, except that it does not mark the messages it is used on for deletion when the user quits. Compressed files and IMAP mailboxes are handled as described for the folder command. Copy (C) Similar to copy, but saves the messages in a file named after the local part of the sender address of the first message. decrypt (dec) For unencrypted messages, this command is identical to copy. Encrypted messages are first decrypted, if possible, and then copied. Decrypt (Dec) Similar to decrypt, but saves the messages in a file named after the local part of the sender address of the first message. define (def) Defines a macro. A macro definition is a sequence of commands in the following form: define name { command1 command2 ... commandN } Once defined, a macro can be explicitly invoked using the call command, or can be implicitly invoked by setting the folder-hook or folder-hook-fullname variables. defines Prints the currently defined macros including their contents. delete (d) Takes a list of messages as argument and marks them all as deleted. Deleted messages will not be saved in mbox, nor will they be available for most other commands. discard Same as ignore. disconnect (disco) If operating in online mode on an IMAP mailbox, switch to disconnected mode while retaining the mailbox status. See the description of the disconnected variable for more information. A list of messages may optionally be given as argument; the respective messages are then read into the cache before the connection is closed. Thus 'disco *' makes the entire current mailbox available for disconnected use. dp or dt Deletes the current message and prints the next message. If there is no next message, mailx says ' at EOF'. draft Takes a message list and marks each message as a draft. This mark has no technical meaning in the mail system; it just causes messages to be marked in the header summary, and makes them specially addressable. echo Echoes its arguments, resolving special names as documented for the folder command. The escape sequences '\\a', '\\b', '\\c', '\\f', '\\n', '\\r', '\\t', '\\v', '\\\\', and '\\0num' are interpreted as with the echo(1) command. edit (e) Takes a list of messages and points the text editor at each one in turn. Modified contents are discarded unless the writebackedited variable is set. else Marks the end of the then-part of an if statement and the beginning of the part to take effect if the condition of the if statement is false. endif Marks the end of an if statement. exit (ex or x) Effects an immediate return to the Shell without modifying the user's system mailbox, his mbox file, or his edit file in -f. file (fi) The same as folder. flag (fl) Takes a message list and marks the messages as 'flagged' for urgent\/special attention. This mark has no technical meaning in the mail system; it just causes messages to be highlighted in the header summary, and makes them specially addressable. folders With no arguments, list the names of the folders in the folder directory. With an existing folder as an argument, lists then names of folders below the named folder; e.g. the command 'folders @' lists the folders on the base level of the current IMAP server. See also the imap-list-depth variable. folder (fold) The folder command switches to a new mail file or folder. With no arguments, it tells the user which file he is currently reading. If an argument is given, it will write out changes (such as deletions) the user has made in the current file and read in the new file. Some special conventions are recognized for the name. # means the previous file, % means the invoking user's system mailbox, %user means user's system mailbox, & means the invoking user's mbox file, and +file means a file in the folder directory. %:filespec expands to the same value as filespec, but the file is handled as a system mailbox e. g. by the mbox and save commands. If the name matches one of the strings defined with the shortcut command, it is replaced by its long form and expanded. If the name ends with .gz or .bz2, it is treated as compressed with gzip(1) or bzip2(1), respectively. Likewise, if name does not exist, but either name.gz or name.bz2 exists, the compressed file is used. If name refers to a directory with the subdirectories 'tmp', 'new', and 'cur', it is treated as a folder in maildir format. A name of the form protocol :\/\/[ user @] host[ : port][ \/ file] is taken as an Internet mailbox specification. The supported protocols are currently imap (IMAP v4r1), imaps (IMAP with SSL\/TLS encryption), pop3 (POP3), and pop3s (POP3 with SSL\/TLS encryption). If user contains special characters, in particular '\/' or '%', they must be escaped in URL notation, as '%2F' or '%25'. The optional file part applies to IMAP only; if it is omitted, the default 'INBOX' is used. If mailx is connected to an IMAP server, a name of the form @mailbox refers to the mailbox on that server. If the 'folder' variable refers to an IMAP account, the special name '%' selects the 'INBOX' on that account. Followup (F) Similar to Respond, but saves the message in a file named after the local part of the first recipient's address. followup (fo) Similar to respond, but saves the message in a file named after the local part of the first recipient's address. followupall Similar to followup, but responds to all recipients regardless of the flipr and Replyall variables. followupsender Similar to Followup, but responds to the sender only regardless of the flipr and Replyall variables. forward (fwd) Takes a message and the address of a recipient and forwards the message to him. The text of the original message is included in the new one, with the value of the fwdheading variable printed before. The fwdignore and fwdretain commands specify which header fields are included in the new message. Only the first part of a multipart message is included unless the forward-as-attachment option is set. Forward (Fwd) Similar to forward, but saves the message in a file named after the local part of the recipient's address. from (f) Takes a list of messages and prints their message headers, piped through the pager if the output does not fit on the screen. fwdignore Specifies which header fields are to be ignored with the forward command. This command has no effect when the forward-as-attachment option is set. fwdretain Specifies which header fields are to be retained with the forward command. fwdretain overrides fwdignore. This command has no effect when the forward-as-attachment option is set. good (go) Takes a list of messages and marks all of them as not being junk mail. Data from these messages is then inserted into the junk mail database for future classification. headers (h) Lists the current range of headers, which is an 18-message group. If a '+' argument is given, then the next 18-message group is printed, and if a '-' argument is given, the previous 18-message group is printed. help A synonym for ?. hold (ho, also preserve) Takes a message list and marks each message therein to be saved in the user's system mailbox instead of in mbox. Does not override the delete command. mailx deviates from the POSIX standard with this command, as a 'next' command issued after 'hold' will display the following message, not the current one. if Commands in mailx's startup files can be executed conditionally depending on whether the user is sending or receiving mail with the if command. For example: if receive commands . . . endif An else form is also available:         if receive\n                commands . . .\n        else\n                commands . . .\n        endif\n\n Note that the only allowed conditions are receive, send, and term (execute command if standard input is a tty). ignore Add the list of header fields named to the ignored list. Header fields in the ignore list are not printed on the terminal when a message is printed. This command is very handy for suppression of certain machine-generated header fields. The Type and Print commands can be used to print a message in its entirety, including ignored fields. If ignore is executed with no arguments, it lists the current set of ignored fields. imap Sends command strings directly to the current IMAP server. Mailx operates always in IMAP selected state on the current mailbox; commands that change this will produce undesirable results and should be avoided. Useful IMAP commands are: create Takes the name of an IMAP mailbox as an argument and creates it. getquotaroot Takes the name of an IMAP mailbox as an argument and prints the quotas that apply to the mailbox. Not all IMAP servers support this command. namespace Takes no arguments and prints the Personal Namespaces, the Other User's Namespaces, and the Shared Namespaces. Each namespace type is printed in parentheses; if there are multiple namespaces of the same type, inner parentheses separate them. For each namespace, a namespace prefix and a hierarchy separator is listed. Not all IMAP servers support this command. inc Same as newmail. junk (j) Takes a list of messages and marks all of them as junk mail. Data from these messages is then inserted into the junk mail database for future classification. kill (k) Takes a list of messages and 'kills' them. Killed messages are not printed in header summaries, and are ignored by the next command. The kill command also sets the score of the messages to negative infinity, so that subsequent score commands will not unkill them again. Killing is only effective for the current session on a folder; when it is quit, all messages are automatically unkilled. list Prints the names of all available commands. Mail (M) Similar to mail, but saves the message in a file named after the local part of the first recipient's address. mail (m) Takes as argument login names and distribution group names and sends mail to those people. mbox Indicate that a list of messages be sent to mbox in the user's home directory when mailx is quit. This is the default action for messages if unless the hold option is set. mailx deviates from the POSIX standard with this command, as a 'next' command issued after 'mbox' will display the following message, not the current one. move (mv) Acts like copy, but marks the messages for deletion if they were transferred successfully. Move (Mv) Similar to move, but moves the messages to a file named after the local part of the sender address of the first message. newmail Checks for new mail in the current folder without committing any changes before. If new mail is present, a message is printed. If the header variable is set, the headers of each new message are also printed. next (n) like + or CR) Goes to the next message in sequence and types it. With an argument list, types the next matching message. New Same as unread. new Same as unread. online Same as connect. noop If the current folder is located on an IMAP or POP3 server, a NOOP command is sent. Otherwise, no operation is performed. Pipe (Pi) Like pipe but also pipes ignored header fields and all parts of MIME multipart\/alternative messages. pipe (pi) Takes a message list and a shell command and pipes the messages through the command. Without an argument, the current message is piped through the command given by the cmd variable. If the page variable is set, every message is followed by a formfeed character. preserve (pre) A synonym for hold. Print (P) Like print but also prints out ignored header fields and all parts of MIME multipart\/alternative messages. See also print, ignore, and retain. print (p) Takes a message list and types out each message on the user's terminal. If the message is a MIME multipart message, all parts with a content type of 'text' or 'message' are shown, the other are hidden except for their headers. Messages are decrypted and converted to the terminal character set if necessary. probability (prob) For each word given as argument, the contents of its junk mail database entry are printed. quit (q) Terminates the session, saving all undeleted, unsaved messages in the user's mbox file in his login directory, preserving all messages marked with hold or preserve or never referenced in his system mailbox, and removing all other messages from his system mailbox. If new mail has arrived during the session, the message 'You have new mail' is given. If given while editing a mailbox file with the -f flag, then the edit file is rewritten. A return to the Shell is effected, unless the rewrite of edit file fails, in which case the user can escape with the exit command. redirect (red) Same as resend. Redirect (Red) Same as Resend. remove (rem) Removes the named folders. The user is asked for confirmation in interactive mode. rename (ren) Takes the name of an existing folder and the name for the new folder and renames the first to the second one. Both folders must be of the same type and must be located on the current server for IMAP. Reply (R) Reply to originator. Does not reply to other recipients of the original message. reply (r) Takes a message list and sends mail to the sender and all recipients of the specified message. The default message must not be deleted. replyall Similar to reply, but responds to all recipients regardless of the flipr and Replyall variables. replysender Similar to Reply, but responds to the sender only regardless of the flipr and Replyall variables. Resend Like resend, but does not add any header lines. This is not a way to hide the sender's identity, but useful for sending a message again to the same recipients. resend Takes a list of messages and a user name and sends each message to the named user. 'Resent-From:' and related header fields are prepended to the new copy of the message. Respond Same as Reply. respond Same as reply. respondall Same as replyall. respondsender Same as replysender. retain Add the list of header fields named to the retained list. Only the header fields in the retain list are shown on the terminal when a message is printed. All other header fields are suppressed. The Type and Print commands can be used to print a message in its entirety. If retain is executed with no arguments, it lists the current set of retained fields. Save (S) Similar to save, but saves the messages in a file named after the local part of the sender of the first message instead of taking a filename argument. save (s) Takes a message list and a filename and appends each message in turn to the end of the file. If no filename is given, the mbox file is used. The filename in quotes, followed by the line count and character count is echoed on the user's terminal. If editing a system mailbox, the messages are marked for deletion. Compressed files and IMAP mailboxes are handled as described for the -f command line option above. savediscard Same as saveignore. saveignore Saveignore is to save what ignore is to print and type. Header fields thus marked are filtered out when saving a message by save or when automatically saving to mbox. This command should only be applied to header fields that do not contain information needed to decode the message, as MIME content fields do. If saving messages on an IMAP account, ignoring fields makes it impossible to copy the data directly on the server, thus operation usually becomes much slower. saveretain Saveretain is to save what retain is to print and type. Header fields thus marked are the only ones saved with a message when saving by save or when automatically saving to mbox. Saveretain overrides saveignore. The use of this command is strongly discouraged since it may strip header fields that are needed to decode the message correctly. score (sc) Takes a message list and a floating point number and adds the number to the score of each given message. All messages start at score 0 when a folder is opened. When the score of a message becomes negative, it is 'killed' with the effects described for the kill command; otherwise if it was negative before and becomes positive, it is 'unkilled'. Scores only refer to the currently opened instance of a folder. set (se) With no arguments, prints all variable values, piped through the pager if the output does not fit on the screen. Otherwise, sets option. Arguments are of the form option=value (no space before or after =) or option. Quotation marks may be placed around any part of the assignment statement to quote blanks or tabs, i.e. 'set indentprefix=\"->\"'. If an argument begins with no, as in 'set nosave', the effect is the same as invoking the unset command with the remaining part of the variable ('unset save'). seen Takes a message list and marks all messages as having been read. shell (sh) Invokes an interactive version of the shell. shortcut Defines a shortcut name and its string for expansion, as described for the folder command. With no arguments, a list of defined shortcuts is printed. show (Sh) Like print, but performs neither MIME decoding nor decryption so that the raw message text is shown. size Takes a message list and prints out the size in characters of each message. sort Create a sorted representation of the current folder, and change the next command and the addressing modes such that they refer to messages in the sorted order. Message numbers are the same as in regular mode. If the header variable is set, a header summary in the new order is also printed. Possible sorting criteria are: date Sort the messages by their 'Date:' field, that is by the time they were sent. from Sort messages by the value of their 'From:' field, that is by the address of the sender. If the showname variable is set, the sender's real name (if any) is used. size Sort the messages by their size. score Sort the messages by their score. status Sort the messages by their message status (new, read, old, etc.). subject Sort the messages by their subject. thread Create a threaded order, as with the thread command. to Sort messages by the value of their 'To:' field, that is by the address of the recipient. If the showname variable is set, the recipient's real name (if any) is used. If no argument is given, the current sorting criterion is printed. source The source command reads commands from a file. thread (th) Create a threaded representation of the current folder, i.e. indent messages that are replies to other messages in the header display, and change the next command and the addressing modes such that they refer to messages in the threaded order. Message numbers are the same as in unthreaded mode. If the header variable is set, a header summary in threaded order is also printed. top Takes a message list and prints the top few lines of each. The number of lines printed is controlled by the variable toplines and defaults to five. touch Takes a message list and marks the messages for saving in the mbox file. mailx deviates from the POSIX standard with this command, as a 'next' command issued after 'mbox' will display the following message, not the current one. Type (T) Identical to the Print command. type (t) A synonym for print. unalias Takes a list of names defined by alias commands and discards the remembered groups of users. The group names no longer have any significance. unanswered Takes a message list and marks each message as not having been answered. uncollapse (unc) Only applicable to threaded mode. Takes a message list and makes the message and all replies to it visible in header summaries again. When a message becomes the current message, it is automatically made visible. Also when a message with collapsed replies is printed, all of these are automatically uncollapsed. undef Undefines each of the named macros. It is not an error to use a name that does not belong to one of the currently defined macros. undelete (u) Takes a message list and marks each message as not being deleted. undraft Takes a message list and marks each message as a draft. unflag Takes a message list and marks each message as not being 'flagged'. unfwdignore Removes the header field names from the list of ignored fields for the forward command. unfwdretain Removes the header field names from the list of retained fields for the forward command. ungood Takes a message list and undoes the effect of a good command that was previously applied on exactly these messages. unignore Removes the header field names from the list of ignored fields. unjunk Takes a message list and undoes the effect of a junk command that was previously applied on exactly these messages. unkill Takes a message list and 'unkills' each message. Also sets the score of the messages to 0. Unread Same as unread. unread (U) Takes a message list and marks each message as not having been read. unretain Removes the header field names from the list of retained fields. unsaveignore Removes the header field names from the list of ignored fields for saving. unsaveretain Removes the header field names from the list of retained fields for saving. unset Takes a list of option names and discards their remembered values; the inverse of set. unshortcut Deletes the shortcut names given as arguments. unsort Disable sorted or threaded mode (see the sort and thread commands), return to normal message order and, if the header variable is set, print a header summary. unthread (unth) Same as unsort. verify (verif) Takes a message list and verifies each message. If a message is not an S\/MIME signed message, verification will fail for it. The verification process checks if the message was signed using a valid certificate, if the message sender's email address matches one of those contained within the certificate, and if the message content has been altered. visual (v) Takes a message list and invokes the display editor on each message. Modified contents are discarded unless the writebackedited variable is set. write (w) For conventional messages, the body without all headers is written. The output is decrypted and converted to its native format, if necessary. If the output file exists, the text is appended.-If a message is in MIME multipart format, its first part is written to the specified file as for conventional messages, and the user is asked for a filename to save each other part; if the contents of the first part are not to be saved, 'write \/dev\/null' can be used. For the second and subsequent parts, if the filename given starts with a '|' character, the part is piped through the remainder of the filename interpreted as a shell command. In non-interactive mode, only the parts of the multipart message that have a filename given in the part header are written, the other are discarded. The original message is never marked for deletion in the originating mail folder. For attachments, the contents of the destination file are overwritten if the file previously existed. No special handling of compressed files is performed. xit (x) A synonym for exit. z Mailx presents message headers in windowfuls as described under the headers command. The z command scrolls to the next window of messages. If an argument is given, it specifies the window to use. A number prefixed by '+' or '-' indicates that the window is calculated in relation to the current position. A number without a prefix specifies an absolute window number, and a '$' lets mailx scroll to the last window of messages. Z Similar to z, but scrolls to the next or previous window that contains at least one new or 'flagged' message. Tilde escapes Here is a summary of the tilde escapes, which are used when composing messages to perform special functions. Tilde escapes are only recognized at the beginning of lines. The name ' tilde escape' is somewhat of a misnomer since the actual escape character can be set by the option escape. ~! command Execute the indicated shell command, then return to the message. ~. Same effect as typing the end-of-file character. ~< filename Identical to ~r. ~<! command Command is executed using the shell. Its standard output is inserted into the message. ~@ [ filename . . . ] With no arguments, edit the attachment list. First, the user can edit all existing attachment data. If an attachment's file name is left empty, that attachment is deleted from the list. When the end of the attachment list is reached, mailx will ask for further attachments, until an empty file name is given. If filename arguments are specified, all of them are appended to the end of the attachment list. Filenames which contain white space can only be specified with the first method (no filename arguments). ~A Inserts the string contained in the Sign variable (same as '~i Sign'). The escape sequences '\\t' (tabulator) and '\\n' (newline) are understood. ~a Inserts the string contained in the sign variable (same as '~i sign'). The escape sequences '\\t' (tabulator) and '\\n' (newline) are understood. ~b name . . . Add the given names to the list of carbon copy recipients but do not make the names visible in the Cc: line ('blind' carbon copy). ~c name . . . Add the given names to the list of carbon copy recipients. ~d Read the file 'dead.letter' from the user's home directory into the message. ~e Invoke the text editor on the message collected so far. After the editing session is finished, the user may continue appending text to the message. ~f messages Read the named messages into the message being sent. If no messages are specified, read in the current message. Message headers currently being ignored (by the ignore or retain command) are not included. For MIME multipart messages, only the first printable part is included. ~F messages Identical to ~f, except all message headers and all MIME parts are included. ~h Edit the message header fields 'To:', 'Cc:', 'Bcc:', and 'Subject:' by typing each one in turn and allowing the user to append text to the end or modify the field by using the current terminal erase and kill characters. ~H Edit the message header fields 'From:', 'Reply-To:', 'Sender:', and 'Organization:' in the same manner as described for ~h. The default values for these fields originate from the from, replyto, and ORGANIZATION variables. If this tilde command has been used, changing the variables has no effect on the current message anymore. ~i variable Insert the value of the specified variable into the message adding a newline character at the end. If the variable is unset or empty, the message remains unaltered. The escape sequences ' \\t' (tabulator) and ' \\n' (newline) are understood. ~m messages Read the named messages into the message being sent, indented by a tab or by the value of indentprefix. If no messages are specified, read the current message. Message headers currently being ignored (by the ignore or retain command) are not included. For MIME multipart messages, only the first printable part is included. ~M messages Identical to ~m, except all message headers and all MIME parts are included. ~p Print out the message collected so far, prefaced by the message header fields and followed by the attachment list, if any. If the message text is longer than the screen size, it is piped through the pager. ~q Abort the message being sent, copying the message to 'dead.letter' in the user's home directory if save is set. ~r filename Read the named file into the message. ~s string Cause the named string to become the current subject field. ~t name . . . Add the given names to the direct recipient list. ~v Invoke an alternate editor (defined by the VISUAL option) on the message collected so far. Usually, the alternate editor will be a screen editor. After the editor is quit, the user may resume appending text to the end of the message. ~w filename Write the message onto the named file. If the file exists, the message is appended to it. ~x Same as ~q, except that the message is not saved to the 'dead.letter' file. ~| command Pipe the message through the command as a filter. If the command gives no output or terminates abnormally, retain the original text of the message. The command fmt(1) is often used as command to rejustify the message. ~: mailx-command Execute the given mailx command. Not all commands, however, are allowed. ~_ mailx-command Identical to ~:. ~~ string Insert the string of text in the message prefaced by a single ~. If the escape character has been changed, that character must be doubled in order to send it at the beginning of a line. Variable options Options are controlled via set and unset commands, see their entries for a syntax description. An option is also set if it is passed to mailx as part of the environment (this is not restricted to specific variables as in the POSIX standard). A value given in a startup file overrides a value imported from the environment. Options may be either binary, in which case it is only significant to see whether they are set or not; or string, in which case the actual value is of interest. Binary options The binary options include the following: allnet Causes only the local part to be evaluated when comparing addresses. append Causes messages saved in mbox to be appended to the end rather than prepended. This should always be set. ask or asksub Causes mailx to prompt for the subject of each message sent. If the user responds with simply a newline, no subject field will be sent. askatend Causes the prompts for 'Cc:' and 'Bcc:' lists to appear after the message has been edited. askattach If set, mailx asks for files to attach at the end of each message. Responding with a newline indicates not to include an attachment. askcc Causes the user to be prompted for additional carbon copy recipients (at the end of each message if askatend or bsdcompat is set). Responding with a newline indicates the user's satisfaction with the current list. askbcc Causes the user to be prompted for additional blind carbon copy recipients (at the end of each message if askatend or bsdcompat is set). Responding with a newline indicates the user's satisfaction with the current list. asksign Causes the user to be prompted if the message is to be signed at the end of each message. The smime-sign variable is ignored when this variable is set. autocollapse Causes threads to be collapsed automatically when threaded mode is entered (see the collapse command). autoinc Same as newmail. autoprint Causes the delete command to behave like dp - thus, after deleting a message, the next one will be typed automatically. autothread Causes threaded mode (see the thread command) to be entered automatically when a folder is opened. bang Enables the substitution of '!' by the contents of the last command line in shell escapes. bsdannounce Causes automatic display of a header summary after executing a folder command. bsdcompat Sets some cosmetical features to traditional BSD style; has the same affect as setting 'askatend' and all other variables prefixed with 'bsd', setting prompt to '& ', and changing the default pager to more. bsdflags Changes the letters printed in the first column of a header summary to traditional BSD style. bsdheadline Changes the display of columns in a header summary to traditional BSD style. bsdmsgs Changes some informational messages to traditional BSD style. bsdorder Causes the 'Subject:' field to appear immediately after the 'To:' field in message headers and with the ~h tilde command. bsdset Changes the output format of the set command to traditional BSD style. chained-junk-tokens Normally, the Bayesian junk mail filter bases its classifications on single word tokens extracted from messages. If this option is set, adjacent words are combined to pairs, which are then used as additional tokens. This usually improves the accuracy of the filter, but also increases the junk mail database five- to tenfold. datefield The date in a header summary is normally the date of the mailbox 'From ' line of the message. If this variable is set, the date as given in the 'Date:' header field is used, converted to local time. debug Prints debugging messages and disables the actual delivery of messages. Unlike verbose, this option is intended for mailx development only. disconnected When an IMAP mailbox is selected and this variable is set, no connection to the server is initiated. Instead, data is obtained from the local cache (see imap-cache). Mailboxes that are not present in the cache and messages that have not yet entirely been fetched from the server are not available; to fetch all messages in a mailbox at once, the command 'copy * \/dev\/null' can be used while still in online mode. Changes that are made to IMAP mailboxes in disconnected mode are queued and committed later when a connection to that server is opened in online mode. This procedure is not completely reliable since it cannot be guaranteed that the IMAP unique identifiers (UIDs) on the server still match the ones in the cache at that time. Data is saved to 'dead.letter' when this problem occurs. disconnected- user @ host The specified account is handled as described for the disconnected variable above, but other accounts are not affected. dot The binary option dot causes mailx to interpret a period alone on a line as the terminator of a message the user is sending. editheaders When a message is edited while being composed, its header is included in the editable text. 'To:', 'Cc:', 'Bcc:', 'Subject:', 'From:', 'Reply-To:', 'Sender:', and 'Organization:' fields are accepted within the header, other fields are ignored. emptybox If set, an empty mailbox file is not removed. This may improve the interoperability with other mail user agents when using a common folder directory. emptystart If the mailbox is empty, mailx normally prints 'No mail for user' and exits immediately. If this option is set, mailx starts even with an empty mailbox. flipr Exchanges the Respond with the respond commands and vice-versa. forward-as-attachment Original messages are normally sent as inline text with the forward command, and only the first part of a multipart message is included. With this option, messages are sent as MIME message\/rfc822 attachments, and all of their parts are included. The fwdignore and fwdretain options are ignored when the forward-as-attachment option is set. fullnames When replying to a message, mailx normally removes the comment parts of email addresses, which by convention contain the full names of the recipients. If this variable is set, such stripping is not performed, and comments are retained. header Causes the header summary to be written at startup and after commands that affect the number of messages or the order of messages in the current folder; enabled by default. hold This option is used to hold messages in the system mailbox by default. ignore Causes interrupt signals from the terminal to be ignored and echoed as @'s. ignoreeof An option related to dot is ignoreeof which makes mailx refuse to accept a control-d as the end of a message. Ignoreeof also applies to mailx command mode. imap-use-starttls Causes mailx to issue a STARTTLS command to make an unencrypted IMAP session SSL\/TLS encrypted. This functionality is not supported by all servers, and is not used if the session is already encrypted by the IMAPS method. imap-use-starttls- user @ host Activates imap-use-starttls for a specific account. keep This option causes mailx to truncate the user's system mailbox instead of deleting it when it is empty. This should always be set, since it prevents malicious users from creating fake mail folders in a world-writable spool directory. keepsave When a message is saved, it is usually discarded from the originating folder when mailx is quit. Setting this option causes all saved message to be retained. markanswered When a message is replied to and this variable is set, it is marked as having been answered. This mark has no technical meaning in the mail system; it just causes messages to be marked in the header summary, and makes them specially addressable. metoo Usually, when a group is expanded that contains the sender, the sender is removed from the expansion. Setting this option causes the sender to be included in the group. newmail Checks for new mail in the current folder each time the prompt is printed. For IMAP mailboxes, the server is then polled for new mail, which may result in delayed operation if the connection to the server is slow. A maildir folder must be re-scanned to determine if new mail has arrived. If this variable is set to the special value nopoll, an IMAP server is not actively asked for new mail, but new mail may still be detected and announced with any other IMAP command that is sent to the server. A maildir folder is not scanned then. In any case, the IMAP server may send notifications about messages that have been deleted on the server by another process or client. In this case, 'Expunged n messages' is printed regardless of this variable, and message numbers may have changed. noheader Setting the option noheader is the same as giving the -N flag on the command line. outfolder Causes the filename given in the record variable and the sender-based filenames for the Copy and Save commands to be interpreted relative to the directory given in the folder variable rather than to the current directory unless it is an absolute pathname. page If set, each message the pipe command prints out is followed by a formfeed character. piperaw Send messages to the pipe command without performing MIME and character set conversions. pop3-use-apop If this variable is set, the APOP authentication method is used when a connection to a POP3 server is initiated. The advantage of this method over the usual USER\/PASS authentication is that the password is not sent over the network in clear text. The connection fails if the server does not support the APOP command. pop3-use-apop- user @ host Enables pop3-use-apop for a specific account. pop3-use-starttls Causes mailx to issue a STLS command to make an unencrypted POP3 session SSL\/TLS encrypted. This functionality is not supported by all servers, and is not used if the session is already encrypted by the POP3S method. pop3-use-starttls- user @ host Activates pop3-use-starttls for a specific account. print-all-chars This option causes all characters to be considered printable. It is only effective if given in a startup file. With this option set, some character sequences in messages may put the user's terminal in an undefined state when printed; it should only be used as a last resort if no working system locale can be found. print-alternatives When a MIME message part of type multipart\/alternative is displayed and it contains a subpart of type text\/plain, other parts are normally discarded. Setting this variable causes all subparts to be displayed, just as if the surrounding part was of type multipart\/mixed. quiet Suppresses the printing of the version when first invoked. record-resent If both this variable and the record variable are set, the resend and Resend commands save messages to the record folder as it is normally only done for newly composed messages. reply-in-same-charset If this variable is set, mailx first tries to use the same character set of the original message for replies. If this fails, the sendcharsets variable is evaluated as usual. Replyall Reverses the sense of reply and Reply commands. save When the user aborts a message with two RUBOUT (interrupt characters) mailx copies the partial letter to the file 'dead.letter' in the home directory. This option is set by default. searchheaders If this option is set, then a message-list specifier in the form ' \/x:y' will expand to all messages containing the substring ' y' in the header field ' x'. The string search is case insensitive. sendwait When sending a message, wait until the mail transfer agent exits before accepting further commands. If the mail transfer agent returns a non-zero exit status, the exit status of mailx will also be non-zero. showlast Setting this option causes mailx to start at the last message instead of the first one when opening a mail folder. showname Causes mailx to use the sender's real name instead of the plain address in the header field summary and in message specifications. showto Causes the recipient of the message to be shown in the header summary if the message was sent by the user. skipemptybody If an outgoing message does not contain any text in its first or only message part, do not send it but discard it silently (see also the -E option). smime-force-encryption Causes mailx to refuse sending unencrypted messages. smime-sign If this variable is set, outgoing messages are S\/MIME signed with the user's private key. Signing a message enables a recipient to verify that the sender used a valid certificate, that the email addresses in the certificate match those in the message header, and that the message content has not been altered. It does not change the message text, and people will be able to read the message as usual. smime-no-default-ca Do not load the default CA locations when verifying S\/MIME signed messages. Only applicable if S\/MIME support is built using OpenSSL. smtp-use-starttls Causes mailx to issue a STARTTLS command to make an SMTP session SSL\/TLS encrypted. Not all servers support this command; because of common implementation defects, it cannot be automatically determined whether a server supports it or not. ssl-no-default-ca Do not load the default CA locations to verify SSL\/TLS server certificates. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-v2-allow Accept SSLv2 connections. These are normally not allowed because this protocol version is insecure. stealthmua Inhibits the generation of the 'Message-Id:' and 'User-Agent:' header fields that include obvious references to mailx. There are two pitfalls associated with this: First, the message id of outgoing messages is not known anymore. Second, an expert may still use the remaining information in the header to track down the originating mail user agent. verbose Setting the option verbose is the same as using the -v flag on the command line. When mailx runs in verbose mode, details of the actual message delivery and protocol conversations for IMAP, POP3, and SMTP, as well as of other internal processes, are displayed on the user's terminal, This is sometimes useful to debug problems. Mailx prints all data that is sent to remote servers in clear texts, including passwords, so care should be taken that no unauthorized option can view the screen if this option is enabled. writebackedited If this variable is set, messages modified using the edit or visual commands are written back to the current folder when it is quit. This is only possible for writable folders in mbox format. Setting this variable also disables MIME decoding and decryption for the editing commands. String Options The string options include the following: attrlist A sequence of characters to print in the 'attribute' column of a header summary, each for one type of messages in the following order: new, unread but old, new but read, read and old, saved, preserved, mboxed, flagged, answered, draft, killed, start of a collapsed thread, collapsed, classified as junk. The default is 'NUROSPMFATK+-J', or 'NU *HMFATK+-J' if bsdflags or the SYSV3 environment variable are set. autobcc Specifies a list of recipients to which a blind carbon copy of each outgoing message will be sent automatically. autocc Specifies a list of recipients to which a carbon copy of each outgoing message will be sent automatically. autosort Causes sorted mode (see the sort command) to be entered automatically with the value of this option as sorting method when a folder is opened. cmd The default value for the pipe command. crt The valued option crt is used as a threshold to determine how long a message must be before PAGER is used to read it. If crt is set without a value, then the height of the terminal screen stored in the system is used to compute the threshold (see stty(1)). DEAD The name of the file to use for saving aborted messages. This defaults to 'dead.letter' in the user's home directory. EDITOR Pathname of the text editor to use in the edit command and ~e escape. If not defined, then a default editor is used. encoding The default MIME encoding to use in outgoing text messages and message parts. Valid values are 8bit or quoted-printable. The default is 8bit. In case the mail transfer system is not ESMTP compliant, quoted-printable should be used instead. If there is no need to encode a message, 7bit transfer mode is used, without regard to the value of this variable. Binary data is always encoded in base64 mode. escape If defined, the first character of this option gives the character to use in the place of ~ to denote escapes. folder The name of the directory to use for storing folders of messages. All folder names that begin with '+' refer to files below that directory. If the directory name begins with a '\/', mailx considers it to be an absolute pathname; otherwise, the folder directory is found relative to the user's home directory. The directory name may also refer to an IMAP account; any names that begin with '+' then refer to IMAP mailboxes on that account. An IMAP folder is normally given in the form imaps:\/\/mylogin@imap.myisp.example In this case, the '+' and '@' prefixes for folder names have the same effect (see the folder command). Some IMAP servers do not accept the creation of mailboxes in the hierarchy base; they require that they are created as subfolders of 'INBOX'. With such servers, a folder name of the form imaps:\/\/mylogin@imap.myisp.example\/INBOX. should be used (the last character is the server's hierarchy delimiter). Folder names prefixed by '+' will then refer to folders below 'INBOX', while folder names prefixed by '@' refer to folders below the hierarchy base. See the imap namespace command for a method to detect the appropriate prefix and delimiter. folder-hook When a folder is opened and this variable is set, the macro corresponding to the value of this variable is executed. The macro is also invoked when new mail arrives, but message lists for commands executed from the macro only include newly arrived messages then. folder-hook- fullname When a folder named fullname is opened, the macro corresponding to the value of this variable is executed. Unlike other folder specifications, the fully expanded name of a folder, without metacharacters, is used to avoid ambiguities. The macro specified with folder-hook is not executed if this variable is effective for a folder (unless it is explicitly invoked within the called macro). from The address (or a list of addresses) to put into the 'From:' field of the message header. If replying to a message, these addresses are handled as if they were in the alternates list. If the machine's hostname is not valid at the Internet (for example at a dialup machine), either this variable or hostname have to be set to get correct Message-ID header fields. If from contains more than one address, the sender variable must also be set. fwdheading The string to print before the text of a message with the forward command (unless the forward-as-attachment variable is set). Defaults to ''-------- Original Message --------'' if unset. If it is set to the empty string, no heading is printed. headline A format string to use for the header summary, similar to printf formats. A '%' character introduces a format specifier. It may be followed by a number indicating the field width. If the field is a number, the width may be negative, which indicates that it is to be left-aligned. Valid format specifiers are: The default is '%>%a%m %18f %16d %4l\/%-5o %i%s', or '%>%a%m %20f %16d %3l\/%-5o %i%S' if bsdcompat is set. hostname Use this string as hostname when expanding local addresses instead of the value obtained from uname(2) and getaddrinfo(3). imap-auth Sets the IMAP authentication method. Valid values are 'login' for the usual password-based authentication (the default), 'cram-md5', which is a password-based authentication that does not send the password over the network in clear text, and 'gssapi' for GSSAPI-based authentication. imap-auth- user @ host Sets the IMAP authentication method for a specific account. imap-cache Enables caching of IMAP mailboxes. The value of this variable must point to a directory that is either existent or can be created by mailx. All contents of the cache can be deleted by mailx at any time; it is not safe to make assumptions about them. imap-keepalive IMAP servers may close the connection after a period of inactivity; the standard requires this to be at least 30 minutes, but practical experience may vary. Setting this variable to a numeric value greater than 0 causes a NOOP command to be sent each value seconds if no other operation is performed. imap-list-depth When retrieving the list of folders on an IMAP server, the folders command stops after it has reached a certain depth to avoid possible infinite loops. The value of this variable sets the maximum depth allowed. The default is 2. If the folder separator on the current IMAP server is a slash '\/', this variable has no effect, and the folders command does not descend to subfolders. indentprefix String used by the ' ~m' and ' ~M' tilde escapes and by the quote option for indenting messages, in place of the normal tab character (^I). Be sure to quote the value if it contains spaces or tabs. junkdb The location of the junk mail database. The string is treated like a folder name, as described for the folder command. The files in the junk mail database are normally stored in compress(1) format for saving space. If processing time is considered more important, uncompress(1) can be used to store them in plain form. Mailx will then work using the uncompressed files. LISTER Pathname of the directory lister to use in the folders command when operating on local mailboxes. Default is \/bin\/ls. MAIL Is used as the user's mailbox, if set. Otherwise, a system-dependent default is used. Can be a protocol:\/\/ string (see the folder command for more information). MAILX_HEAD A string to put at the beginning of each new message. The escape sequences ' \\t' (tabulator) and ' \\n' (newline) are understood. MAILX_TAIL A string to put at the end of each new message. The escape sequences ' \\t' (tabulator) and ' \\n' (newline) are understood. maximum-unencoded-line-length Messages that contain lines longer than the value of this variable are encoded in quoted-printable even if they contain only ASCII characters. The maximum effective value is 950. If set to 0, all ASCII text messages are encoded in quoted-printable. S\/MIME signed messages are always encoded in quoted-printable regardless of the value of this variable. MBOX The name of the mbox file. It can be the name of a folder. The default is 'mbox' in the user's home directory. NAIL_EXTRA_RC The name of an optional startup file to be read after ~\/.mailrc. This variable is ignored if it is imported from the environment; it has an effect only if it is set in \/etc\/mail.rc or ~\/.mailrc to allow bypassing the configuration with e. g. 'MAILRC=\/dev\/null'. Use this file for commands that are not understood by other mailx implementations. newfolders If this variable has the value maildir, newly created local folders will be in maildir format. nss-config-dir A directory that contains the files cert N.db to retrieve certificates, key N.db to retrieve private keys, and secmod.db, where N is a digit. These are usually taken from Mozilla installations, so an appropriate value might be '~\/.mozilla\/firefox\/default.clm'. Mailx opens these files read-only and does not modify them. However, if the files are modified by Mozilla while mailx is running, it will print a 'Bad database' message. It may be necessary to create copies of these files that are exclusively used by mailx then. Only applicable if S\/MIME and SSL\/TLS support is built using Network Security Services (NSS). ORGANIZATION The value to put into the 'Organization:' field of the message header. PAGER Pathname of the program to use in the more command or when crt variable is set. The default paginator pg(1) or, in BSD compatibility mode, more(1) is used if this option is not defined. password- user @ host Set the password for user when connecting to host. If no such variable is defined for a host, the user will be asked for a password on standard input. Specifying passwords in a startup file is generally a security risk, the file should be readable by the invoking user only. pipe- content\/subcontent When a MIME message part of content\/subcontent type is displayed or it is replied to, its text is filtered through the value of this variable interpreted as a shell command. Special care must be taken when using such commands as mail viruses may be distributed by this method; if messages of type application\/x-sh were filtered through the shell, for example, a message sender could easily execute arbitrary code on the system mailx is running on. pop3-keepalive POP3 servers may close the connection after a period of inactivity; the standard requires this to be at least 10 minutes, but practical experience may vary. Setting this variable to a numeric value greater than 0 causes a NOOP command to be sent each value seconds if no other operation is performed. prompt The string printed when a command is accepted. Defaults to '? ', or to '& ' if the bsdcompat variable is set. quote If set, mailx starts a replying message with the original message prefixed by the value of the variable indentprefix. Normally, a heading consisting of 'Fromheaderfield wrote:' is printed before the quotation. If the string noheading is assigned to the quote variable, this heading is omitted. If the string headers is assigned, the headers selected by the ignore\/retain commands are printed above the message body, thus quote acts like an automatic ~m command then. If the string allheaders is assigned, all headers are printed above the message body, and all MIME parts are included, thus quote acts like an automatic ~M command then. record If defined, gives the pathname of the folder used to record all outgoing mail. If not defined, then outgoing mail is not so saved. When saving to this folder fails, the message is not sent but saved to the 'dead.letter' file instead. replyto A list of addresses to put into the 'Reply-To:' field of the message header. If replying to a message, such addresses are handled as if they were in the alternates list. screen When mailx initially prints the message headers, it determines the number to print by looking at the speed of the terminal. The faster the terminal, the more it prints. This option overrides this calculation and specifies how many message headers are printed. This number is also used for scrolling with the z command. sendcharsets A comma-separated list of character set names that can be used in Internet mail. When a message that contains characters not representable in US-ASCII is prepared for sending, mailx tries to convert its text to each of the given character sets in order and uses the first appropriate one. The default is 'utf-8'. Character sets assigned to this variable should be ordered in ascending complexity. That is, the list should start with e.g. 'iso-8859-1' for compatibility with older mail clients, might contain some other language-specific character sets, and should end with 'utf-8' to handle messages that combine texts in multiple languages. sender An address that is put into the 'Sender:' field of outgoing messages. This field needs not normally be present. It is, however, required if the 'From:' field contains more than one address. It can also be used to indicate that a message was sent on behalf of somebody other; in this case, 'From:' should contain the address of the person that took responsibility for the message, and 'Sender:' should contain the address of the person that actually sent the message. The sender address is handled as if it were in the alternates list. sendmail To use an alternate mail delivery system, set this option to the full pathname of the program to use. This should be used with care. SHELL Pathname of the shell to use in the ! command and the ~! escape. A default shell is used if this option is not defined. Sign A string for use with the ~A command. sign A string for use with the ~a command. signature Must correspond to the name of a readable file if set. The file's content is then appended to each singlepart message and to the first part of each multipart message. Be warned that there is no possibility to edit the signature for an individual message. smime-ca-dir Specifies a directory with CA certificates for verification of S\/MIME signed messages. The format is the same as described in ssl_ctx_load_verify_locations(3). Only applicable if S\/MIME support is built using OpenSSL. smime-ca-file Specifies a file with CA certificates for verification of S\/MIME signed messages. The format is the same as described in ssl_ctx_load_verify_locations(3). Only applicable if S\/MIME support is built using OpenSSL. smime-cipher- user@host Specifies a cipher to use when generating S\/MIME encrypted messages for user@host. Valid ciphers are rc2-40 (RC2 with 40 bits), rc2-64 (RC2 with 64 bits), des (DES, 56 bits) and des-ede3 (3DES, 112\/168 bits). The default is 3DES. It is not recommended to use the other ciphers unless a recipient's client is actually unable to handle 3DES since they are comparatively weak; but even so, the recipient should upgrade his software in preference. smime-crl-file Specifies a file that contains a CRL in PEM format to use when verifying S\/MIME messages. Only applicable if S\/MIME support is built using OpenSSL. smime-crl-dir Specifies a directory that contains files with CRLs in PEM format to use when verifying S\/MIME messages. Only applicable if S\/MIME support is built using OpenSSL. smime-encrypt- user@host If this variable is set, messages to user@host are encrypted before sending. If S\/MIME support is built using OpenSSL, the value of the variable must be set to the name of a file that contains a certificate in PEM format. If S\/MIME support is built using NSS, the value of this variable is ignored, but if multiple certificates for user@host are available, the smime-nickname-user@host variable should be set. Otherwise a certificate for the recipient is automatically retrieved from the certificate database, if possible. If a message is sent to multiple recipients, each of them for whom a corresponding variable is set will receive an individually encrypted message; other recipients will continue to receive the message in plain text unless the smime-force-encryption variable is set. It is recommended to sign encrypted messages, i.e. to also set the smime-sign variable. smime-nickname- user@host Specifies the nickname of a certificate to be used when encrypting messages for user@host . Only applicable if S\/MIME support is built using NSS. smime-sign-cert Points to a file in PEM format that contains the user's private key as well as his certificate. Both are used with S\/MIME for signing and decrypting messages. Only applicable if S\/MIME support is built using OpenSSL. smime-sign-cert- user@host Overrides smime-sign-cert for the specific addresses. When signing messages and the value of the from variable is set to user@host, the specific file is used. When decrypting messages, their recipient fields (To: and Cc:) are searched for addresses for which such a variable is set. Mailx always uses the first address that matches, so if the same message is sent to more than one of the user's addresses using different encryption keys, decryption might fail. Only applicable if S\/MIME support is built using OpenSSL. smime-sign-nickname Specifies that the named certificate be used for signing mail. If this variable is not set, but a single certificate matching the current from address is found in the database, that one is used automatically. Only applicable if S\/MIME support is built using NSS. smime-sign-nickname- user@host Overrides smime-sign-nickname for a specific address. Only applicable if S\/MIME support is built using NSS. smtp Normally, mailx invokes sendmail(8) directly to transfer messages. If the smtp variable is set, a SMTP connection to the server specified by the value of this variable is used instead. If the SMTP server does not use the standard port, a value of server:port can be given, with port as a name or as a number. There are two possible methods to get SSL\/TLS encrypted SMTP sessions: First, the STARTTLS command can be used to encrypt a session after it has been initiated, but before any user-related data has been sent; see smtp-use-starttls above. Second, some servers accept sessions that are encrypted from their beginning on. This mode is configured by assigning smtps:\/\/ server[ : port] to the smtp variable. The SMTP transfer is executed in a child process; unless either the sendwait or the verbose variable is set, this process runs asynchronously. If it receives a TERM signal, it will abort and save the message to the 'dead.letter' file. smtp-auth Sets the SMTP authentication method. If set to 'login', or if unset and smtp-auth-user is set, AUTH LOGIN is used. If set to 'cram-md5', AUTH CRAM-MD5 is used; if set to 'plain', AUTH PLAIN is used. Otherwise, no SMTP authentication is performed. smtp-auth- user @ host Overrides smtp-auth for specific values of sender addresses, depending on the from variable. smtp-auth-password Sets the global password for SMTP AUTH. Both user and password have to be given for AUTH LOGIN and AUTH CRAM-MD5. smtp-auth-password- user @ host Overrides smtp-auth-password for specific values of sender addresses, depending on the from variable. smtp-auth-user Sets the global user name for SMTP AUTH. Both user and password have to be given for AUTH LOGIN and AUTH CRAM-MD5. If this variable is set but neither smtp-auth-password or a matching smtp-auth-password-user@host can be found, mailx will as for a password on the user's terminal. smtp-auth-user- user @ host Overrides smtp-auth-user for specific values of sender addresses, depending on the from variable. ssl-ca-dir Specifies a directory with CA certificates for verification of SSL\/TLS server certificates. See ssl_ctx_load_verify_locations(3) for more information. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-ca-file Specifies a file with CA certificates for verification of SSL\/TLS server certificates. See ssl_ctx_load_verify_locations(3) for more information. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-cert Sets the file name for a SSL\/TLS client certificate required by some servers. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-cert- user @ host Sets an account-specific file name for a SSL\/TLS client certificate required by some servers. Overrides ssl-cert for the specified account. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-cipher-list Specifies a list of ciphers for SSL\/TLS connections. See ciphers(1) for more information. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-crl-file Specifies a file that contains a CRL in PEM format to use when verifying SSL\/TLS server certificates. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-crl-dir Specifies a directory that contains files with CRLs in PEM format to use when verifying SSL\/TLS server certificates. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-key Sets the file name for the private key of a SSL\/TLS client certificate. If unset, the name of the certificate file is used. The file is expected to be in PEM format. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-key- user @ host Sets an account-specific file name for the private key of a SSL\/TLS client certificate. Overrides ssl-key for the specified account. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-method Selects a SSL\/TLS protocol version; valid values are 'ssl2', 'ssl3', and 'tls1'. If unset, the method is selected automatically, if possible. ssl-method- user @ host Overrides ssl-method for a specific account. ssl-rand-egd Gives the pathname to an entropy daemon socket, see rand_egd(3). ssl-rand-file Gives the pathname to a file with entropy data, see rand_load_file(3). If the file is a regular file writable by the invoking user, new data is written to it after it has been loaded. Only applicable if SSL\/TLS support is built using OpenSSL. ssl-verify Sets the action to be performed if an error occurs during SSL\/TLS server certificate validation. Valid values are 'strict' (fail and close connection immediately), 'ask' (ask whether to continue on standard input), 'warn' (print a warning and continue), 'ignore' (do not perform validation). The default is 'ask'. ssl-verify- user @ host Overrides ssl-verify for a specific account. toplines If defined, gives the number of lines of a message to be printed out with the top command; normally, the first five lines are printed. ttycharset The character set of the terminal mailx operates on. There is normally no need to set this variable since mailx can determine this automatically by looking at the LC_CTYPE locale setting; if this succeeds, the value is assigned at startup and will be displayed by the set command. Note that this is not necessarily a character set name that can be used in Internet messages. VISUAL Pathname of the text editor to use in the visual command and ~v escape.","Process Name":"nail","Link":"https:\/\/linux.die.net\/man\/1\/nail"}},{"Process":{"Description":"naim is the original ncurses AIM client. It uses the TOC protocol, and features many commonly-requested features found nowhere else, while still providing an intuitive chat interface.","Process Name":"naim","Link":"https:\/\/linux.die.net\/man\/1\/naim"}},{"Process":{"Description":"","Process Name":"name2addr","Link":"https:\/\/linux.die.net\/man\/1\/name2addr"}},{"Process":{"Description":"The nameclt command invokes operations on the Naming Service. The allowed operations are: list <context-name> lists contexts and objects bound in the context with the specified name. bind_new_context <context-name> binds name to a new context, and returns the stringified context IOR. remove_context <context-name> unbinds and destroys the named context, as long as it is empty. bind <object-name> <stringified-IOR> binds name to object. unbind <object-name> unbinds name and object. resolve <object-name> returns stringified IOR bound to specified name.","Process Name":"nameclt","Link":"https:\/\/linux.die.net\/man\/1\/nameclt"}},{"Process":{"Description":"Namei uses its arguments as pathnames to any type of Unix file (symlinks, files, directories, and so forth). Namei then follows each pathname until a terminal point is found (a file, directory, char device, etc). If it finds a symbolic link, we show the link, and start following it, indenting the output to show the context. This program is useful for finding a \"too many levels of symbolic links\" problems. For each line output, namei outputs a the following characters to identify the file types found: f: = the pathname we are currently trying to resolve\n d = directory\n l = symbolic link (both the link and it's contents are output)\n s = socket\n b = block device\n c = character device\n p = FIFO (named pipe)\n - = regular file\n ? = an error of some kind Namei prints an informative message when the maximum number of symbolic links this system can have has been exceeded.","Process Name":"namei","Link":"https:\/\/linux.die.net\/man\/1\/namei"}},{"Process":{"Description":"This manual page briefly documents the nano command. nano is a small, free and friendly editor which aims to replace Pico, the default editor included in the non-free Pine package. Rather than just copying Pico's look and feel, nano also implements some missing (or disabled by default) features in Pico, such as \"search and replace\" and \"go to line and column number\".","Process Name":"nano","Link":"https:\/\/linux.die.net\/man\/1\/nano"}},{"Process":{"Description":"The Network Audio System service provides applications with the ability to send and receive audio data such as voice, sound effects, and music in a network environment. A audio server inside the desktop terminal or personal computer controls the various input and output devices in response to messages sent from client programs running on other hosts. A variety of utility programs are provided that can be used to play or record audio using shell scripts or command-line procedures. More ambitious applications can communicate directly with the audio server using a C-language programming library. The Network Audio System service supports a variety of the common formats used to store sound data. Audio inputs and outputs can run at a any of a range of sampling rates. The audio server automatically converts all data to the designed format or rate. Streams of data from multiple inputs can be mixed together and directed to any attached output device. Sounds that are used many times can be stored in the server so that they do not need to be transmitted over the network each time they are played. Furthermore, inputs can be hooked directly to outputs (for example, a CD player can be connected to a set of speakers) so that data can be played without requiring any client intervention or network traffic.","Process Name":"nas","Link":"https:\/\/linux.die.net\/man\/1\/nas"}},{"Process":{"Description":"nasd is the generic name for the Network Audio System server. It is frequently a link or a copy of the appropriate server binary for driving the most frequently used server on a given machine.","Process Name":"nasd","Link":"https:\/\/linux.die.net\/man\/1\/nasd"}},{"Process":{"Description":"The nasm command assembles the file filename and directs output to the file outfile if specified. If outfile is not specified, nasm will derive a default output file name from the name of its input file, usually by appending '.o' or '.obj', or by removing all extensions for a raw binary file. Failing that, the output file name will be 'nasm.out'. OPTIONS -@ filename Causes nasm to process options from filename as if they were included on the command line. -a Causes nasm to assemble the given input file without first applying the macro preprocessor. -D macro[=value] Pre-defines a single-line macro. -d macro[=value] Same as the -D option. -e Causes nasm to preprocess the given input file, and write the output to stdout (or the specified output file name), and not actually assemble anything. -f format Specifies the output file format. To see a list of valid output formats, use the -hf option. -g Causes nasm to generate debug information in selected format -h Causes nasm to exit immediately, after giving a summary of its invocation options. -hf Same as -h , but also lists all valid output formats. -I directory Adds a directory to the search path for include files. The directory specification must include the trailing slash, as it will be directly prepended to the name of the include file. -i directory Same as the -I option. -l listfile Causes an assembly listing to be directed to the given file, in which the original source is displayed on the right hand side (plus the source for included files and the expansions of multi-line macros) and the generated code is shown in hex on the left. -M Causes nasm to output Makefile-style dependencies to stdout; normal output is suppressed. -O number optimize branch offsets (-O0 disables, default). -o outfile Specifies a precise name for the output file, overriding nasm's default means of determining it. -P file Specifies a file to be pre-included, before the main source file starts to be processed. -p file Same as the -P option. -r Causes nasm to exit immediately, after displaying its version number. (obsolete) -s Causes nasm to send its error messages and\/or help text to stdout instead of stderr. -t Causes nasm to assemble in SciTech TASM compatible mode -U macro Undefines a single-line macro. -u macro Same as the -U option. -v Causes nasm to exit immediately, after displaying its version number. -w [+-]foo Causes nasm to enable or disable certain classes of warning messages, for example -w+orphan-labels or -w-macro-params -X format specifies error reporting format (gnu or vc). -Z filename Causes nasm to redirect error messages to filename. This option exists to support operating systems on which stderr is not easily redirected. SYNTAX This man page does not fully describe the syntax of nasm's assembly language, but does give a summary of the differences from other assemblers. Registers have no leading '%' sign, unlike gas, and floating-point stack registers are referred to as st0, st1, and so on. Floating-point instructions may use either the single-operand form or the double. A TO keyword is provided; thus, one could either write fadd st0,st1 fadd st1,st0 or one could use the alternative single-operand forms fadd st1 fadd to st1 Uninitialised storage is reserved using the RESB, RESW, RESD, RESQ, REST and RESO pseudo-opcodes, each taking one parameter which gives the number of bytes, words, doublewords, quadwords or ten-byte words to reserve. Repetition of data items is not done by the DUP keyword as seen in DOS assemblers, but by the use of the TIMES prefix, like this: message: times 3 db 'abc' times 64-$+message db 0 which defines the string 'abcabcabc', followed by the right number of zero bytes to make the total length up to 64 bytes. Symbol references are always understood to be immediate (i.e. the address of the symbol), unless square brackets are used, in which case the contents of the memory location are used. Thus: mov ax,wordvar loads AX with the address of the variable 'wordvar', whereas mov ax,[wordvar] mov ax,[wordvar+1] mov ax,[es:wordvar+bx] all refer to the contents of memory locations. The syntaxes mov ax,es:wordvar[bx] es mov ax,wordvar[1] are not legal at all, although the use of a segment register name as an instruction prefix is valid, and can be used with instructions such as LODSB which can't be overridden any other way. Constants may be expressed numerically in most formats: a trailing H, Q or B denotes hex, octal or binary respectively, and a leading '0x' or '$' denotes hex as well. Leading zeros are not treated specially at all. Character constants may be enclosed in single or double quotes; there is no escape character. The ordering is little-endian (reversed), so that the character constant 'abcd' denotes 0x64636261 and not 0x61626364. Local labels begin with a period, and their 'locality' is granted by the assembler prepending the name of the previous non-local symbol. Thus declaring a label '.loop' after a label 'label' has actually defined a symbol called 'label.loop'. DIRECTIVES SECTION name or SEGMENT name causes nasm to direct all following code to the named section. Section names vary with output file format, although most formats support the names .text, .data and .bss. (The exception is the obj format, in which all segments are user-definable.) ABSOLUTE address causes nasm to position its notional assembly point at an absolute address: so no code or data may be generated, but you can use RESB, RESW and RESD to move the assembly point further on, and you can define labels. So this directive may be used to define data structures. When you have finished doing absolute assembly, you must issue another SECTION directive to return to normal assembly. BITS 16, BITS 32 or BITS 64 switches the default processor mode for which nasm is generating code: it is equivalent to USE16 or USE32 in DOS assemblers. EXTERN symbol and GLOBAL symbol import and export symbol definitions, respectively, from and to other modules. Note that the GLOBAL directive must appear before the definition of the symbol it refers to. STRUC strucname and ENDSTRUC, when used to bracket a number of RESB, RESW or similar instructions, define a data structure. In addition to defining the offsets of the structure members, the construct also defines a symbol for the size of the structure, which is simply the structure name with _size tacked on to the end. FORMAT-SPECIFIC DIRECTIVES ORG address is used by the bin flat-form binary output format, and specifies the address at which the output code will eventually be loaded. GROUP grpname seg1 seg2... is used by the obj (Microsoft 16-bit) output format, and defines segment groups. This format also uses UPPERCASE, which directs that all segment, group and symbol names output to the object file should be in uppercase. Note that the actual assembly is still case sensitive. LIBRARY libname is used by the rdf output format, and causes a dependency record to be written to the output file which indicates that the program requires a certain library in order to run. MACRO PREPROCESSOR Single-line macros are defined using the %define or %idefine commands, in a similar fashion to the C preprocessor. They can be overloaded with respect to number of parameters, although defining a macro with no parameters prevents the definition of any macro with the same name taking parameters, and vice versa. %define defines macros whose names match case-sensitively, whereas %idefine defines case-insensitive macros. Multi-line macros are defined using %macro and %imacro (the distinction is the same as that between %define and %idefine), whose syntax is as follows: %macro name minprm[- maxprm][+][.nolist] [ defaults] <some lines of macro expansion text> %endmacro Again, these macros may be overloaded. The trailing plus sign indicates that any parameters after the last one get subsumed, with their separating commas, into the last parameter. The defaults part can be used to specify defaults for unspecified macro parameters after minparam. %endm is a valid synonym for %endmacro. To refer to the macro parameters within a macro expansion, you use %1, %2 and so on. You can also enforce that a macro parameter should contain a condition code by using %+1, and you can invert the condition code by using %-1. You can also define a label specific to a macro invocation by prefixing it with a double % sign. Files can be included using the %include directive, which works like C. The preprocessor has a 'context stack', which may be used by one macro to store information that a later one will retrieve. You can push a context on the stack using %push, remove one using %pop, and change the name of the top context (without disturbing any associated definitions) using %repl. Labels and %define macros specific to the top context may be defined by prefixing their names with %$, and things specific to the next context down with %$$, and so on. Conditional assembly is done by means of %ifdef, %ifndef, %else and %endif as in C. (Except that %ifdef can accept several putative macro names, and will evaluate TRUE if any of them is defined.) In addition, the directives %ifctx and %ifnctx can be used to condition on the name of the top context on the context stack. The obvious set of 'else-if' directives, %elifdef, %elifndef, %elifctx and %elifnctx are also supported.","Process Name":"nasm","Link":"https:\/\/linux.die.net\/man\/1\/nasm"}},{"Process":{"Description":"The Java compiler and other Java tools can only process files which contain Latin-1 and\/or Unicode-encoded (\\udddd notation) characters. native2ascii converts files which contain other character encodings into files containing Latin-1 and\/or Unicode-encoded charaters. If outputfile is omitted, standard output is used for output. If, in addition, inputfile is omitted, standard input is used for input.","Process Name":"native2ascii-java-1.6.0-openjdk","Link":"https:\/\/linux.die.net\/man\/1\/native2ascii-java-1.6.0-openjdk"}},{"Process":{"Description":"native2ascii converts files that are encoded to any character encoding that is supported by the Java runtime environment to files encoded in ASCII, using Unicode escapes (\"\\uxxxx\" notation) for all characters that are not part of the ASCII character set. This process is required for properties files containing characters not in ISO-8859-1 character sets. The tool can also perform the reverse conversion. If outputfile is omitted, standard output is used for output. If, in addition, inputfile is omitted, standard input is used for input.","Process Name":"native2ascii-java-1.7.0-openjdk","Link":"https:\/\/linux.die.net\/man\/1\/native2ascii-java-1.7.0-openjdk"}},{"Process":{"Description":"This manual page documents briefly the natspec command. This manual page was written for the Debian distribution because the original program does not have a manual page. natspec is a command line utility to access libnatspec functions.","Process Name":"natspec","Link":"https:\/\/linux.die.net\/man\/1\/natspec"}},{"Process":{"Description":"This manual page documents briefly the nautilus command. This manual page was written for the Debian GNU\/Linux distribution because the original program does not have a manual page. Nautilus is the file manager for the GNOME desktop.","Process Name":"nautilus","Link":"https:\/\/linux.die.net\/man\/1\/nautilus"}},{"Process":{"Description":"This manual page documents briefly the nautilus-connect-server command. Nautilus Connect Server is the connection manager for the GNOME desktop. You can use the file manager to access a remote server, be it an FTP site, a Windows share, a WebDav server or an SSH server.","Process Name":"nautilus-connect-server","Link":"https:\/\/linux.die.net\/man\/1\/nautilus-connect-server"}},{"Process":{"Description":"This manual page documents briefly the nautilus-file-management-properties command. File Management Preferences allows an user to configure the way nautilus looks. You can specify a default view, and select sort options and display options. You can also specify default settings for icon views and list views.","Process Name":"nautilus-file-management-properties","Link":"https:\/\/linux.die.net\/man\/1\/nautilus-file-management-properties"}},{"Process":{"Description":"Send FILE(s) via email or instant messenger. A dialog window presents a choice of carrier application and recipient of the file(s). Recipent names can be selected from a list or autocompleted. The selected application is then opened with the file(s) and recipient ready for transfer. The application is intented to integrate with nautilus and is written for the GNOME graphical desktop.","Process Name":"nautilus-sendto","Link":"https:\/\/linux.die.net\/man\/1\/nautilus-sendto"}},{"Process":{"Description":"Nawk scans each input file for lines that match any of a set of patterns specified literally in prog or in one or more files specified as -f progfile. With each pattern there can be an associated action that will be performed when a line of a file matches the pattern. Each line is matched against the pattern portion of every pattern-action statement; the associated action is performed for each matched pattern. The file name - means the standard input. Any file of the form var=value is treated as an assignment, not a filename, and is executed at the time it would have been opened if it were a filename. The option -v followed by var=value is an assignment to be done before prog is executed; any number of -v options may be present. The -F fs option defines the input field separator to be the regular expression fs. An input line is normally made up of fields separated by white space, or by regular expression FS. The fields are denoted $1, $2, ..., while $0 refers to the entire line. If FS is null, the input line is split into one field per character. A pattern-action statement has the form pattern { action } A missing { action } means print the line; a missing pattern always matches. Pattern-action statements are separated by newlines or semicolons. An action is a sequence of statements. A statement can be one of the following:        if( expression ) statement [ else statement ]\n       while( expression ) statement\n       for( expression ; expression ; expression ) statement\n       for( var in array ) statement\n       do statement while( expression )\n       break\n       continue\n       { [ statement ... ] } expression # commonly var = expression print [ expression-list ] [ > expression ] printf format [ , expression-list ] [ > expression ] return [ expression ] next # skip remaining patterns on this input line nextfile # skip rest of this file, open next, start at top delete array [ expression ]# delete an array element delete array # delete all elements of array exit [ expression ] # exit immediately; status is expression Statements are terminated by semicolons, newlines or right braces. An empty expression-list stands for $0. String constants are quoted \" \", with the usual C escapes recognized within. Expressions take on string or numeric values as appropriate, and are built using the operators + - * \/ % ^ (exponentiation), and concatenation (indicated by white space). The operators ! ++ -- += -= *= \/= %= ^= > >= < <= == != ?: are also available in expressions. Variables may be scalars, array elements (denoted x [ i ] ) or fields. Variables are initialized to the null string. Array subscripts may be any string, not necessarily numeric; this allows for a form of associative memory. Multiple subscripts such as [i,j,k] are permitted; the constituents are concatenated, separated by the value of SUBSEP. The print statement prints its arguments on the standard output (or on a file if >file or >>file is present or on a pipe if |cmd is present), separated by the current output field separator, and terminated by the output record separator. file and cmd may be literal names or parenthesized expressions; identical string values in different statements denote the same open file. The printf statement formats its expression list according to the format (see printf(3)). The built-in function close(expr) closes the file or pipe expr. The built-in function fflush(expr) flushes any buffered output for the file or pipe expr. The mathematical functions exp, log, sqrt, sin, cos, and atan2 are built in. Other built-in functions: length the length of its argument taken as a string, or of $0 if no argument. rand random number on (0,1) srand sets seed for rand and returns the previous seed. int truncates to an integer value substr( s , m , n ) the n-character substring of s that begins at position m counted from 1. index( s , t ) the position in s where the string t occurs, or 0 if it does not. match( s , r ) the position in s where the regular expression r occurs, or 0 if it does not. The variables RSTART and RLENGTH are set to the position and length of the matched string. split( s , a , fs ) splits the string s into array elements a [1] , a [2] , ..., a [ n ] , and returns n. The separation is done with the regular expression fs or with the field separator FS if fs is not given. An empty string as field separator splits the string into one array element per character. sub( r , t , s ) substitutes t for the first occurrence of the regular expression r in the string s. If s is not given, $0 is used. gsub same as sub except that all occurrences of the regular expression are replaced; sub and gsub return the number of replacements. sprintf( fmt , expr , ... ) the string resulting from formatting expr ... according to the printf(3) format fmt system( cmd ) executes cmd and returns its exit status tolower( str ) returns a copy of str with all upper-case characters translated to their corresponding lower-case equivalents. toupper( str ) returns a copy of str with all lower-case characters translated to their corresponding upper-case equivalents. The ''function'' getline sets $0 to the next input record from the current input file; getline < file sets $0 to the next record from file. getline x sets variable x instead. Finally, cmd | getline pipes the output of cmd into getline; each call of getline returns the next line of output from cmd. In all cases, getline returns 1 for a successful input, 0 for end of file, and -1 for an error. Patterns are arbitrary Boolean combinations (with ! || &&) of regular expressions and relational expressions. Regular expressions are as in egrep; see grep(1). Isolated regular expressions in a pattern apply to the entire line. Regular expressions may also occur in relational expressions, using the operators ~ and !~. \/re\/ is a constant regular expression; any string (constant or variable) may be used as a regular expression, except in the position of an isolated regular expression in a pattern. A pattern may consist of two patterns separated by a comma; in this case, the action is performed for all lines from an occurrence of the first pattern though an occurrence of the second. A relational expression is one of the following: expression matchop regular-expression expression relop expression expression in array-name ( expr , expr,... ) in array-name where a relop is any of the six relational operators in C, and a matchop is either ~ (matches) or !~ (does not match). A conditional is an arithmetic expression, a relational expression, or a Boolean combination of these. The special patterns BEGIN and END may be used to capture control before the first input line is read and after the last. BEGIN and END do not combine with other patterns. Variable names with special meanings: CONVFMT conversion format used when converting numbers (default %.6g) FS regular expression used to separate fields; also settable by option -Ffs. NF number of fields in the current record NR ordinal number of the current record FNR ordinal number of the current record in the current file FILENAME the name of the current input file RS input record separator (default newline) OFS output field separator (default blank) ORS output record separator (default newline) OFMT output format for numbers (default %.6g) SUBSEP separates multiple subscripts (default 034) ARGC argument count, assignable ARGV argument array, assignable; non-null members are taken as filenames ENVIRON array of environment variables; subscripts are names. Functions may be defined (at the position of a pattern-action statement) thus: function foo(a, b, c) { ...; return x } Parameters are passed by value if scalar and by reference if array name; functions may be called recursively. Parameters are local to the function; all other variables are global. Thus local variables may be created by providing excess parameters in the function definition.","Process Name":"nawk","Link":"https:\/\/linux.die.net\/man\/1\/nawk"}},{"Process":{"Description":"The nc (or netcat) utility is used for just about anything under the sun involving TCP or UDP. It can open TCP connections, send UDP packets, listen on arbitrary TCP and UDP ports, do port scanning, and deal with both IPv4 and IPv6. Unlike telnet(1), nc scripts nicely, and separates error messages onto standard error instead of sending them to standard output, as telnet(1) does with some. Common uses include:              \u2022 simple TCP proxies \u2022 shell-script based HTTP clients and servers \u2022 network daemon testing \u2022 a SOCKS or HTTP ProxyCommand for ssh(1) \u2022 and much, much more The options are as follows: -4' Forces nc to use IPv4 addresses only. -6' Forces nc to use IPv6 addresses only. -D' Enable debugging on the socket. -d' Do not attempt to read from stdin. -h' Prints out nc help. -i interval Specifies a delay time interval between lines of text sent and received. Also causes a delay time between connections to multiple ports. -k' Forces nc to stay listening for another connection after its current connection is completed. It is an error to use this option without the -l option. -l' Used to specify that nc should listen for an incoming connection rather than initiate a connection to a remote host. It is an error to use this option in conjunction with the -p, -s, or -z options. Additionally, any timeouts specified with the -w option are ignored. -n' Do not do any DNS or service lookups on any specified addresses, hostnames or ports. -p source_port Specifies the source port nc should use, subject to privilege restrictions and availability. It is an error to use this option in conjunction with the -l option. -r' Specifies that source and\/or destination ports should be chosen randomly instead of sequentially within a range or in the order that the system assigns them. -S' Enables the RFC 2385 TCP MD5 signature option. -s source_ip_address Specifies the IP of the interface which is used to send the packets. It is an error to use this option in conjunction with the -l option. -T ToS Specifies IP Type of Service (ToS) for the connection. Valid values are the tokens ''lowdelay'', ''throughput'', ''reliability'', or an 8-bit hexadecimal value preceded by ''0x''. -C' Send CRLF as line-ending -t' Causes nc to send RFC 854 DON'T and WON'T responses to RFC 854 DO and WILL requests. This makes it possible to use nc to script telnet sessions. -U' Specifies to use Unix Domain Sockets. -u' Use UDP instead of the default option of TCP. -v' Have nc give more verbose output. -w timeout If a connection and stdin are idle for more than timeout seconds, then the connection is silently closed. The -w flag has no effect on the -l option, i.e. nc will listen forever for a connection, with or without the -w flag. The default is no timeout. -X proxy_version Requests that nc should use the specified protocol when talking to the proxy server. Supported protocols are ''4'' (SOCKS v.4), ''5'' (SOCKS v.5) and ''connect'' (HTTPS proxy). If the protocol is not specified, SOCKS version 5 is used. -x proxy_address[ :port] Requests that nc should connect to hostname using a proxy at proxy_address and port. If port is not specified, the well-known port for the proxy protocol is used (1080 for SOCKS, 3128 for HTTPS). -z' Specifies that nc should just scan for listening daemons, without sending any data to them. It is an error to use this option in conjunction with the -l option. hostname can be a numerical IP address or a symbolic hostname (unless the -n option is given). In general, a hostname must be specified, unless the -l option is given (in which case the local host is used). port[s] can be single integers or ranges. Ranges are in the form nn-mm. In general, a destination port must be specified, unless the -U option is given (in which case a socket must be specified). CLIENT\/SERVER MODEL It is quite simple to build a very basic client\/server model using nc. On one console, start nc listening on a specific port for a connection. For example: $ nc -l 1234 nc is now listening on port 1234 for a connection. On a second console (or a second machine), connect to the machine and port being listened on: $ nc 127.0.0.1 1234 There should now be a connection between the ports. Anything typed at the second console will be concatenated to the first, and vice-versa. After the connection has been set up, nc does not really care which side is being used as a 'server' and which side is being used as a 'client'. The connection may be terminated using an EOF ('^D').","Process Name":"nc","Link":"https:\/\/linux.die.net\/man\/1\/nc"}},{"Process":{"Description":"nc2xy reads one or more netCDF files with column data and writes out those columns in ASCII format to standard output, so that they can be used by psxy, psxyz, or xyz2grd. Modify the precision of the ASCII output format by editing the D_FORMAT parameter in your .gmtdefaults4 file or use --D_FORMAT= value on the command line. files Names of netCDF files to be converted.","Process Name":"nc2xy","Link":"https:\/\/linux.die.net\/man\/1\/nc2xy"}},{"Process":{"Description":"ncap arithmetically processes a netCDF file. However, in about 2008 ncap was deprecated in favor of ncap2 which far surpasses its capbilities. ncap will eventually be completely removed from NCO. It is currently retained only because it provides an easier-to-build arithmetic operator than ncap2. The processing instructions are contained either in the NCO script file fl.nco or in a sequence of command line arguments. The options -s (or long options --spt or --script) are used for in-line scripts and -S (or long options --fl_spt or --script-file) are used to provide the filename where (usually multiple) scripting commands are pre-stored. ncap was written to perform arbitrary albebraic transformations of data and archive the results as easily as possible. Missing values are treated correctly. The results of the algebraic manipulations are called derived fields. Unlike the other operators, ncap does not accept a list of variables to be operated on as an argument to -v. Rather, the -v switch takes no arguments and indicates that ncap should output only user-defined variables. ncap does not accept or understand the -x switch.","Process Name":"ncap","Link":"https:\/\/linux.die.net\/man\/1\/ncap"}},{"Process":{"Description":"ncap2 supercedes and is backwards-compatible with ncap which is now deprecated. Both operators arithmetically process netCDF files. The primary ncap2 documentation is currently the sample script <http:\/\/nco.sf.net\/ncap2.in> The remainder of this manpage is identical to the ncap manpage. The processing instructions are contained either in the NCO script file fl.nco or in a sequence of command line arguments. The options -s (or long options --spt or --script) are used for in-line scripts and -S (or long options --fl_spt or --script-file) are used to provide the filename where (usually multiple) scripting commands are pre-stored. ncap2 was written to perform arbitrary albebraic transformations of data and archive the results as easily as possible. Missing values are treated correctly. The results of the algebraic manipulations are called derived fields. Unlike the other operators, ncap2 does not accept a list of variables to be operated on as an argument to -v. Rather, the -v switch takes no arguments and indicates that ncap2 should output only user-defined variables. ncap2 does not accept or understand the -x switch.","Process Name":"ncap2","Link":"https:\/\/linux.die.net\/man\/1\/ncap2"}},{"Process":{"Description":"ncargcc is a script that invokes the C compiler\/linker with the proper NCAR Graphics LLU (low-level utility) libraries. Arguments presented above are associated with NCAR Graphics. All other arguments and options are identical to the cc command on your particular machine; arguments that include quoted strings may have to be enclosed in single quotes. NOTE: ncargcc cannot be used to compile NCAR Graphics C programs that call the HLUs (high-level utilities). You must use nhlcc instead. See the nhlcc man page for more information. If you don't want to use ncargcc, you can just type it on the command line to see what gets included in the link line, and then you can add this information to your own Makefile or script. It is important to note that you must define the macro NeedFuncProto in order for function prototyping to work correctly. In order to run ncargcc, you must have your NCARG_ROOT environment variable set to the directory pathname where the NCAR Graphics libraries, binaries, and include files were installed. If you are not sure what NCARG_ROOT should be set to, please check with your system administrator or the site representative for NCAR Graphics. If the NCAR Graphics libraries, binaries, and include files were not installed under one root directory, then you will need to set the environment variables NCARG_LIB, NCARG_BIN, and NCARG_INCLUDE instead. Please see \"man ncargintro\" for more information. When ncargcc is invoked with the -ictrans option the resulting executable will, upon invocation, send its metafile output to the translator ictrans. The environment variable GRAPHCAP must be set to a valid graphics output device whenever the executable is executed. By default, ncargcc will load the X11 library when linking your C program. If you try running ncargcc and the compiler complains that it cannot find the library for X11, then try running ncargcc -L\/xxx\/yyy\/zzz program.c where \/xxx\/yyy\/zzz is the path leading to your X11 library. If you do not have the X11 library, or else you just don't want to link it in, you can use the -noX11 option. OPTIONS -ngmath Links in the NCAR Graphics ngmath library. -smooth Link in the \"smooth\" objects. -quick Link in the \"quick\" objects. -super Link in the \"super\" objects. -agupwrtx Link in the \"agupwrtx\" library. -ncarbd Use this option for compilers that appear to be having trouble initializing blockdata variables. It will cause a small subroutine to be linked in that helps force the loading of blockdata initialization routines. -ngmathbd Just like with the -ncarbd option, use this option for compilers that appear to be having trouble initializing Ngmath-related blockdata variables. It will cause a small subroutine to be linked in that helps force the loading of Ngmath blockdata initialization routines. Note: this option doesn't need to be specified separately if you are already including the -ncarbd and -ngmath options. -noX11 Do not link in the X library when linking the code. By default, ncargf77 will load the X11 library when linking your Fortran program. This is because the GKS library now has an X11 driver. If you try running ncargf77 and the compiler complains that it cannot find the library for X11, then try running ncargf77 -L\/xxx\/yyy\/zzz program.f where \/xxx\/yyy\/zzz is the path leading to your X11 library. If you do not have the X11 library, or else you just don't want it to be loaded, you can use the -noX11 option.","Process Name":"ncargcc","Link":"https:\/\/linux.die.net\/man\/1\/ncargcc"}},{"Process":{"Description":"ncargex provides the user with access to over 300 complete example NCAR Graphics Fortran and C source codes, including the examples in the NCAR Graphics Tutorial. ncargex copies the source code for the specified example(s) into the current directory and then compiles, links, and executes the example. Depending on the type of workstation specified on the command line, the output may either be an NCGM (NCAR Graphics Metafile) file, one of many types of PostScript files, or a text dump. It is also possible for no output to be produced if you select the \"x11\" workstation, in which case each frame is displayed directly to a separate X window after it is generated. If no workstation is specified on the command line, then it defaults to an \"NCGM\", unless the example is a special one which is discussed below. If you select one of the workstation types that produces an output file, then the file name will have the same name as the example and ending with an appropriate suffix: \".ncgm\", \".txt\", \".ps\", etc. Certain examples were created to demonstrate a particular function, like how to rename your metafile from within the program, how to use the full page when going to PostScript output, how to use the X11 driver and produce a graphic file at the same time, etc. If the example that you ask for is one of these, a message will be printed to this effect to alert you. In order to run ncargex, you must have your NCARG_ROOT environment variable set to the parent directory where the NCAR Graphics libraries, binaries, and include files were installed. If this environment variable is not set, ncargex will attempt to set it for you. If the NCAR Graphics libraries, binaries, and include files were not installed under one parent directory, then you will need to set the environment variables NCARG_LIB, NCARG_BIN, and NCARG_INCLUDE instead. Please see \"man ncargintro\" for more information.","Process Name":"ncargex","Link":"https:\/\/linux.die.net\/man\/1\/ncargex"}},{"Process":{"Description":null,"Process Name":"ncargf77","Link":"https:\/\/linux.die.net\/man\/1\/ncargf77"}},{"Process":{"Description":"ncargf90 is a script that invokes the FORTRAN 90 compiler\/linker with the proper NCAR Graphics LLU (low-level utility) libraries. Arguments presented above are associated with NCAR Graphics. All other arguments and options are identical to the f90 command on your particular machine; arguments that include quoted strings may have to be enclosed in single quotes. NOTE: ncargf90 cannot be used to compile NCAR Graphics Fortran programs that call the HLUs (high-level utilities). You must use nhlf90 instead. See the nhlf90 man page for more information. In order to run ncargf90, you must have your NCARG_ROOT environment variable set to the directory pathname where the NCAR Graphics libraries, binaries, and include files were installed. If you are not sure what NCARG_ROOT should be set to, please check with your system administrator or the site representative for NCAR Graphics. If the NCAR Graphics libraries, binaries, and include files were not installed under one root directory, then you will need to set the environment variables NCARG_LIB, NCARG_BIN, and NCARG_INCLUDE instead. Please see \"man ncargintro\" for more information. Note that, on some systems, if you supply your own binary libraries in addition to the ones automatically referenced by ncargf90, all the libraries must have been created in a similar fashion. OPTIONS -ngmath Links in the NCAR Graphics ngmath library. -smooth Link in the \"smooth\" objects. -quick Link in the \"quick\" objects. -super Link in the \"super\" objects. -agupwrtx Link in the \"agupwrtx\" library. -ictrans When ncargf90 is invoked with the this option, the resulting executable will, upon invocation, send its metafile output to the translator ictrans . The environment variable GRAPHCAP must be set to a valid graphics output device whenever the executable is executed. -noX11 Do not link in the X library when linking the code. By default, ncargf90 will load the X11 library when linking your Fortran program. This is because the GKS library now has an X11 driver. If you try running ncargf90 and the compiler complains that it cannot find the library for X11, then try running ncargf90 -L\/xxx\/yyy\/zzz program.f where \/xxx\/yyy\/zzz is the path leading to your X11 library. If you do not have the X11 library, or else you just don't want it to be loaded, you can use the -noX11 option.","Process Name":"ncargf90","Link":"https:\/\/linux.die.net\/man\/1\/ncargf90"}},{"Process":{"Description":"ncargfile provides the user with access to special NCAR Graphics files or tables. ncargfile copies the specified file(s) into the current directory. In order to run ncargfile, you must have your NCARG_ROOT environment variable set to the directory pathname where the NCAR Graphics libraries, binaries, and include files were installed. If you are not sure what NCARG_ROOT should be set to, please check with your system administrator or the site representative for NCAR Graphics. If the NCAR Graphics libraries, binaries, and include files were not installed under one root directory, then you will need to set the environment variables NCARG_LIB, NCARG_BIN, and NCARG_INCLUDE instead. Please see \"man ncargintro\" for more information. Currently, only one table is available with ncargfile, and that is the table of Ezmap Area identifiers, called \"ezmap_area_ids\".","Process Name":"ncargfile","Link":"https:\/\/linux.die.net\/man\/1\/ncargfile"}},{"Process":{"Description":"ncargpath has one argument which is the shortened name of the directory whose full pathname you want returned or the name of the attribute whose default value you want. It is used by several NCAR Graphics scripts to find the pathname to certain installables. For example, the script ncargex uses ncargpath to determine where the directory that contains all the examples is installed. The following arguments are recognized: bin Directory where NCAR Graphics binaries are installed. config Directory where NCAR Graphics configuration files are installed. data Directory where NCAR Graphics HLU and NCL example data files are installed. database Directory where NCAR Graphics databases (like the Ezmap database) are installed. doc Directory where NCAR Graphics PostScript documents are installed. examples Directory where NCAR Graphics LLU Fortran and C examples are installed. fontcap The default fontcap being used; only returns a valid fontcap if the environment variable FONTCAP is set. fontcaps Directory where NCAR Graphics fontcaps are installed. gks_output The default name of the metafile. graphcap The default graphcap being used; only returns a valid graphcap if the environment variable GRAPHCAP is set. graphcaps Directory where NCAR Graphics graphcaps are installed. hluex Directory where NCAR Graphics HLU Fortran and C examples are installed. include Directory where NCAR Graphics include files are installed. lib Directory where NCAR Graphics libraries are installed. man Directory where NCAR Graphics man pages are installed. ncarg Root directory where NCAR Graphics examples, databases, resource files, etc. are installed. nclex Directory where NCAR Graphics NCL examples are installed. ngwww Directory where NCAR Graphics HTML files are installed (if they were installed). ngurl URL for the NCAR Graphics documentation. resfiles Directory where resource files for the NCL and HLU examples are installed. root Parent directory where NCAR Graphics is installed. sysappres Directory where the NCAR Graphics systems application resource file is installed. sysresfile Directory where the NCAR Graphics system resource file is installed. tests Directory where NCAR Graphics LLU Fortran and C test examples are installed. tmp Directory where NCAR Graphics temporary files will be written. tutorial Directory where NCAR Graphics LLU tutorial C and Fortran examples are installed. usrresfile Directory where the NCAR Graphics user resource file is installed. xapp Directory where NCAR Graphics X application default files are installed.","Process Name":"ncargpath","Link":"https:\/\/linux.die.net\/man\/1\/ncargpath"}},{"Process":{"Description":"ncargrun is a script that invokes \"program-name\", which uses the NCAR GKS library, and applies the specified options. Prior to running your program, this script sets the environment variables NCARG_GKS_OUTPUT, NCARG_GKS_PSOUTPUT, and NCARG_GKS_PDFOUTPUT to produce the desired effect.","Process Name":"ncargrun","Link":"https:\/\/linux.die.net\/man\/1\/ncargrun"}},{"Process":{"Description":"This command allows you to determine what version of NCAR Graphics that you are currently using. This can be helpful when trying to get consulting help on NCAR Graphics.","Process Name":"ncargversion","Link":"https:\/\/linux.die.net\/man\/1\/ncargversion"}},{"Process":{"Description":"\"ncarlogo2ps\" takes as input a PostScript file created from NCAR Graphics 3.2 or later, or created from a \"ctrans -d ps.color\" command, and adds an NCAR logo to each frame. The options are: -s size Specifies the height of the logo in inches. The default is 0.517 inches. -p position x:y specifies the X-Y position of the center of the logo in inches. Only the \"-p\" is significant. The default is 7.35:2.3 -angle ang Specifies the angle in degrees to rotate the logo from the defualt upright position. -input input_file Specifies the PostScript input file. This must have been generated by NCAR Graphics. If no input option is specified, the input defaults to standard in. -output output_file Specifies the PostScript output file. If no output option is specified, the output defaults to standard out. The options may appear in any order and only the first character is significant.","Process Name":"ncarlogo2ps","Link":"https:\/\/linux.die.net\/man\/1\/ncarlogo2ps"}},{"Process":{"Description":null,"Process Name":"ncat","Link":"https:\/\/linux.die.net\/man\/1\/ncat"}},{"Process":{"Description":"ncatted edits attributes in a netCDF file. If you are editing attributes then you are spending too much time in the world of metadata, and ncatted was written to get you back out as quickly and painlessly as possible. ncatted can append, create, delete, modify, and overwrite attributes (all explained below). Furthermore, ncatted allows each editing operation to be applied to every variable in a file, thus saving you time when you want to change attribute conventions throughout a file. ncatted interprets character attributes as strings. Because repeated use of ncatted can considerably increase the size of the history global attribute, the -h switch is provided to override automatically appending the command to the history global attribute in the output-file. When ncatted is used to change the _FillValue attribute, it changes the associated missing data self-consistently. If the internal floating point representation of a missing value, e.g., 1.0e36, differs between two machines then netCDF files produced on those machines will have incompatible missing values. This allows ncatted to change the missing values in files from different machines to a single value so that the files may then be concatenated together, e.g., by ncrcat, without losing any information. The key to mastering ncatted is understanding the meaning of the structure describing the attribute modification, att_dsc. Each att_dsc contains five elements, which makes using ncatted somewhat complicated, but powerful. The att_dsc argument structure contains five arguments in the following order: att_dsc = att_nm, var_nm, mode, att_type, att_val att_nm Attribute name. Example: units var_nm Variable name. Example: pressure mode Edit mode abbreviation. Example: a. See below for complete listing of valid values of mode. att_type Attribute type abbreviation. Example: c. See below for complete listing of valid values of att_type. att_val Attribute value. Example: pascal. There should be no empty space between these five consecutive arguments. The description of these arguments follows in their order of appearance. The value of att_nm is the name of the attribute you want to edit. This meaning of this should be clear to all users of the ncatted operator. The value of var_nm is the name of the variable containing the attribute (named att_nm) that you want to edit. There are two very important and useful exceptions to this rule. The value of var_nm can also be used to direct ncatted to edit global attributes, or to repeat the editing operation for every variable in a file. A value of var_nm of globalrq indicates that att_nm refers to a global attribute, rather than a particular variable's attribute. This is the method ncatted supports for editing global attributes. If var_nm is left blank, on the other hand, then ncatted attempts to perform the editing operation on every variable in the file. This option may be convenient to use if you decide to change the conventions you use for describing the data. The value of mode is a single character abbreviation ( a, c, d, m, or o) standing for one of five editing modes: a Append. Append value att_val to current var_nm attribute att_nm value att_val, if any. If var_nm does not have an attribute att_nm, there is no effect. c Create. Create variable var_nm attribute att_nm with att_val if att_nm does not yet exist. If var_nm already has an attribute att_nm, there is no effect. d Delete. Delete current var_nm attribute att_nm. If var_nm does not have an attribute att_nm, there is no effect. When Delete mode is selected, the att_type and att_val arguments are superfluous and may be left blank. m Modify. Change value of current var_nm attribute att_nm to value att_val. If var_nm does not have an attribute att_nm, there is no effect. o Overwrite. Write attribute att_nm with value att_val to variable var_nm, overwriting existing attribute att_nm, if any. This is the default mode. The value of att_type is a single character abbreviation ( f, d, l, s, c, or b) standing for one of the six primitive netCDF data types: f Float. Value(s) specified in att_val will be stored as netCDF intrinsic type NC_FLOAT. d Double. Value(s) specified in att_val will be stored as netCDF intrinsic type NC_DOUBLE. l Long. Value(s) specified in att_val will be stored as netCDF intrinsic type NC_LONG. s Short. Value(s) specified in att_val will be stored as netCDF intrinsic type NC_SHORT. c Char. Value(s) specified in att_val will be stored as netCDF intrinsic type NC_CHAR. b Byte. Value(s) specified in att_val will be stored as netCDF intrinsic type NC_BYTE. The specification of att_type is optional in Delete mode. The value of att_val is what you want to change attribute att_nm to contain. The specification of att_val is optional in Delete mode. Attribute values for all types besides NC_CHAR must have an attribute length of at least one. Thus att_val may be a single value or one-dimensional array of elements of type att_type. If the att_val is not set or is set to empty space, and the att_type is NC_CHAR, e.g., -a units,T,o,c,\"\"\"\" or -a units,T,o,c,, then the corresponding attribute is set to have zero length. When specifying an array of values, it is safest to enclose att_val in double or single quotes, e.g., -a levels,T,o,s,\"1,2,3,4\"\"\" or -a levels,T,o,s,'1,2,3,4'. The quotes are strictly unnecessary around att_val except when att_val contains characters which would confuse the calling shell, such as spaces, commas, and wildcard characters. NCO processing of NC_CHAR attributes is a bit like Perl in that it attempts to do what you want by default (but this sometimes causes unexpected results if you want unusual data storage). If the att_type is NC_CHAR then the argument is interpreted as a string and it may contain C-language escape sequences, which NCO will interpret before writing anything to disk. NCO translates valid escape sequences and stores the appropriate ASCII code instead. Since two byte escape sequences represent one byte ASCII codes, e.g., ASCII 10 (decimal), the stored string attribute is one byte shorter than the input string length for each embedded escape sequence. These sequences in particular allow convenient editing of formatted text attributes. See ncks netCDF Kitchen Sink, for more examples of string formatting (with the ncks -s option) with special characters. Analogous to printf, other special characters are also allowed by ncatted if they are \"protected\" by a backslash. NCO simply strips away the leading backslash from these characters before editing the attribute. No other characters require protection by a backslash. Backslashes which precede any other character will not be filtered and will be included in the attribute. Note that the NUL character which terminates C language strings is assumed and need not be explicitly specified. If NUL is input, it will not be translated (because it would terminate the string in an additional location). Because of these context-sensitive rules, if wish to use an attribute of type NC_CHAR to store data, rather than text strings, you should use ncatted with care.","Process Name":"ncatted","Link":"https:\/\/linux.die.net\/man\/1\/ncatted"}},{"Process":{"Description":null,"Process Name":"ncbo","Link":"https:\/\/linux.die.net\/man\/1\/ncbo"}},{"Process":{"Description":"ncc is a program that can help you hack\/study the source code of C programs. It will report which functions call which other functions, which functions are called by other functions and what global variables and members of structures are used by functions. This is useful if you want to analyse a program and eventually hack it.","Process Name":"ncc","Link":"https:\/\/linux.die.net\/man\/1\/ncc"}},{"Process":{"Description":null,"Process Name":"nccnav","Link":"https:\/\/linux.die.net\/man\/1\/nccnav"}},{"Process":{"Description":"nccopy copies an input netCDF file (in any of the four format variants) to an output netCDF file, in any of the four format variants, if possible. For example, if built with the netCDF-3 library, a netCDF classic file may be copied to a netCDF 64-bit offset file, permitting larger variables. If built with the netCDF-4 library, a netCDF classic file may be copied to a netCDF-4 file or to a netCDF-4 classic model file as well, permitting later efficient schema changes, larger variable sizes, adding variables that use compressed or chunked storage, and use of other netCDF-4 features in case the output uses the enhanced netCDF model. nccopy also serves as an example of a generic netCDF-4 program, with its ability to read any valid netCDF file and handle nested groups, strings, and any user-defined types, including arbitrarily nested compound types, variable-length types, and data of any valid netCDF-4 type. Other generic utility programs can make use of parts of nccopy for more complex operations on netCDF data. As of NetCDF version 4.1, and if DAP support was enabled when nccopy was built, the file name may specify a DAP URL. This allows nccopy to convert data on DAP servers to local netCDF files.","Process Name":"nccopy","Link":"https:\/\/linux.die.net\/man\/1\/nccopy"}},{"Process":{"Description":"ncdiff subtracts variables in file_2 from the corresponding variables (those with the same name) in file_1 and stores the results in file_3. Variables in file_2 are broadcast to conform to the corresponding variable in file_1 if necessary. Broadcasting a variable means creating data in non-existing dimensions from the data in existing dimensions. For example, a two dimensional variable in file_2 can be subtracted from a four, three, or two (but not one or zero) dimensional variable (of the same name) in file_1. This functionality allows the user to compute anomalies from the mean. Note that variables in file_1 are not broadcast to conform to the dimensions in file_2. Thus, ncdiff, the number of dimensions, or rank, of any processed variable in file_1 must be greater than or equal to the rank of the same variable in file_2. Furthermore, the size of all dimensions common to both file_1 and file_2 must be equal. When computing anomalies from the mean it is often the case that file_2 was created by applying an averaging operator to a file with the same dimensions as file_1, if not file_1 itself. In these cases, creating file_2 with ncra rather than ncwa will cause the ncdiff operation to fail. For concreteness say the record dimension in file_1 is time. If file_2 were created by averaging file_1 over the time dimension with the ncra operator rather than with the ncwa operator, then file_2 will have a time dimension of size 1 rather than having no time dimension at all In this case the input files to ncdiff, file_1 and file_2, will have unequally sized time dimensions which causes ncdiff to fail. To prevent this from occuring, use ncwa to remove the time dimension from file_2. An example is given below. ncdiff will never difference coordinate variables or variables of type NC_CHAR or NC_BYTE. This ensures that coordinates like (e.g., latitude and longitude) are physically meaningful in the output file, file_3. This behavior is hardcoded. ncdiff applies special rules to some NCAR CSM fields (e.g., ORO). See NCAR CSM Conventions for a complete description. Finally, we note that ncflint (ncflint netCDF File Interpolator) can be also perform file subtraction (as well as addition, multiplication and interpolation).","Process Name":"ncdiff","Link":"https:\/\/linux.die.net\/man\/1\/ncdiff"}},{"Process":{"Description":"ncdu (NCurses Disk Usage) is a curses-based version of the well-known 'du', and provides a fast way to see what directories are using your disk space.","Process Name":"ncdu","Link":"https:\/\/linux.die.net\/man\/1\/ncdu"}},{"Process":{"Description":null,"Process Name":"ncdump","Link":"https:\/\/linux.die.net\/man\/1\/ncdump"}},{"Process":{"Description":"ncea performs gridpoint averages of variables across an arbitrary number (an ensemble) of input files, with each file receiving an equal weight in the average. Each variable in the output-file will be the same size as the same variable in any one of the in the input-files, and all input-files must be the same size. Whereas ncra only performs averages over the record dimension (e.g., time), and weights each record in the record dimension evenly, ncea averages entire files, and weights each file evenly. All dimensions, including the record dimension, are treated identically and preserved in the output-file. The file is the logical unit of organization for the results of many scientific studies. Often one wishes to generate a file which is the gridpoint average of many separate files. This may be to reduce statistical noise by combining the results of a large number of experiments, or it may simply be a step in a procedure whose goal is to compute anomalies from a mean state. In any case, when one desires to generate a file whose properties are the mean of all the input files, then ncea is the operator to use. ncea assumes coordinate variable are properties common to all of the experiments and so does not average them across files. Instead, ncea copies the values of the coordinate variables from the first input file to the output file.","Process Name":"ncea","Link":"https:\/\/linux.die.net\/man\/1\/ncea"}},{"Process":{"Description":"ncecat concatenates an arbitrary number of input files into a single output file. Input files are glued together by creating a record dimension in the output file. Input files must be the same size. Each input file is stored consecutively as a single record in the output file. Each variable (except coordinate variables) in each input file becomes one record in the same variable in the output file. Coordinate variables are not concatenated, they are instead simply copied from the first input file to the output-file. Thus, the size of the output file is the sum of the sizes of the input files. Consider five realizations, 85a.nc, 85b.nc,... 85e.nc of 1985 predictions from the same climate model. Then ncecat 85?.nc 85_ens.nc glues the individual realizations together into the single file, 85_ens.nc. If an input variable was dimensioned [ lat, lon], it will have dimensions [ record, lat, lon] in the output file. A restriction of ncecat is that the hyperslabs of the processed variables must be the same from file to file. Normally this means all the input files are the same size, and contain data on different realizations of the same variables.","Process Name":"ncecat","Link":"https:\/\/linux.die.net\/man\/1\/ncecat"}},{"Process":{"Description":"ncflint creates an output file that is a linear combination of the input files. This linear combination can be a weighted average, a normalized weighted average, or an interpolation of the input files. Coordinate variables are not acted upon in any case, they are simply copied from file_1. There are two conceptually distinct methods of using ncflint. The first method is to specify the weight each input file is to have in the output file. In this method, the value val3 of a variable in the output file file_3 is determined from its values val1 and val2 in the two input files according to wgt1*val1+wgt2*val2 Here at least wgt1, and, optionally, wgt2, are specified on the command line with the -w (or --weight or --wgt_var ) switch. If only IR wgt1 is specified then wgt2 is automatically computed as wgt2=1-wgt1. Note that weights larger than 1 are allowed. Thus it is possible to specify wgt1=2 and wgt2=-3. One can use this functionality to multiply all the values in a given file by a constant. The second method of using ncflint is to specify the interpolation option with -i (or with the --ntp or --interpolate long options). This is really the inverse of the first method in the following sense. When the user specifies the weights directly, ncflint has no work to do besides multiplying the input values by their respective weights and adding the results together to produce the output values. This assumes it is the weights that are known a priori. In another class of cases it is the \"arrival value\" (i.e., val3 ) of a particular variable var that is known a priori. In this case, the implied weights can always be inferred by examining the values of var in the input files. This results in one equation in two unknowns, wgt1 and wgt2: val3=wgt1*val1+wgt2*val2. Unique determination of the weights requires imposing the additional constraint of normalization on the weights: wgt1+wgt2=1. Thus, to use the interpolation option, the user specifies var and val3 with the -i option. ncflint will compute wgt1 and wgt2, and use these weights on all variables to generate the output file. Although var may have any number of dimensions in the input files, it must represent a single, scalar value. Thus any dimensions associated with var must be \"degenerate\", i.e., of size one. If neither -i nor -w is specified on the command line, ncflint defaults to weighting each input file equally in the output file. This is equivalent to specifying -w0.5 or -w0.5,0.5. Attempting to specify both .BR -i and -w methods in the same command is an error. ncflint is programmed not to interpolate variables of type NC_CHAR and NC_BYTE. This behavior is hardcoded.","Process Name":"ncflint","Link":"https:\/\/linux.die.net\/man\/1\/ncflint"}},{"Process":{"Description":null,"Process Name":"ncftp","Link":"https:\/\/linux.die.net\/man\/1\/ncftp"}},{"Process":{"Description":"This program is responsible for processing background FTP requests. It is normally only run by ncftp and not manually by a human being, however you can run it to manually process the FTP job queue. The jobs are spool files written to a user's $HOME\/.ncftp\/spool directory and have a special format and file-naming convention (which contains when the job is to be run). ncftp runs this program when it needs to, but if the ncftpbatch daemon dies unexpectedly the jobs that are left in the queue will not be processed until another instance of ncftpbatch is run. ncftpget and ncftpput can also be used to submit jobs for batch processing, using those utilities' -b command-line flag. If desired, you can also manually create the spool files although this procedure is not documented here (see the manual page for ncftpspooler for more information on how to do that).","Process Name":"ncftpbatch","Link":"https:\/\/linux.die.net\/man\/1\/ncftpbatch"}},{"Process":{"Description":null,"Process Name":"ncftpget","Link":"https:\/\/linux.die.net\/man\/1\/ncftpget"}},{"Process":{"Description":"The purpose of ncftpls is to do remote directory listings using the File Transfer Protocol without entering an interactive shell. This lets you write shell scripts or other unattended processes that can do FTP. The default behavior is to print the directory listing in columnized format (i.e. ls -CF), but that is not very useful for scripting. This example uses the -1 flag, to print one file per line: $ ncftpls -1 ftp:\/\/ftp.ncftp.com\/pub\/ncftp\/ You can also do a remote \"ls -l\", by using \"ncftpls -l\". If you want to try other flags, you have to use them with the -x flag. For example, if you wanted to do a remote \"ls -lrt\", you could do this: $ ncftpls -x \"-lrt\" ftp:\/\/ftp.ncftp.com\/pub\/ncftp\/ By default the program tries to open the remote host and login anonymously, but you can specify a username and password information like you can with ncftpget or ncftpput. Note that the standard specifies that URL pathnames are are relative pathnames. For FTP, this means that URLs specify relative pathnames from the start directory, which for user logins, are typically the user's home directory. If you want to use absolute pathnames, you need to include a literal slash, using the \"%2F\" code for a \"\/\" character. Examples: $ ncftpls -u linus ftp:\/\/ftp.kernel.org\/%2Fusr\/src\/ $ ncftpls ftp:\/\/ steve@ftp.apple.com\/%2Fetc\/","Process Name":"ncftpls","Link":"https:\/\/linux.die.net\/man\/1\/ncftpls"}},{"Process":{"Description":"The purpose of ncftpput is to do file transfers from the command-line without entering an interactive shell. This lets you write shell scripts or other unattended processes that can do FTP. It is also useful for advanced users who want to send files from the shell command line without entering an interactive FTP program such as ncftp. By default the program tries to open the remote host and login anonymously, but you can specify a username and password information. The -u option is used to specify the username to login as, and the -p option is used to specify the password. If you are running the program from the shell, you may omit the -p option and the program will prompt you for the password. Using the -u and -p options are not recommended, because your account information is exposed to anyone who can see your shell script or your process information. For example, someone using the ps program could see your password while the program runs. You may use the -f option instead to specify a file with the account information. However, this is still not secure because anyone who has read access to the information file can see the account information. Nevertheless, if you choose to use the -f option the file should look something like this: host sphygmomanometer.ncftp.com user gleason pass mypassword Don't forget to change the permissions on this file so no one else can read them. The -d option is very useful when you are trying to diagnose why a file transfer is failing. It prints out the entire FTP conversation to the file you specify, so you can get an idea of what went wrong. If you specify the special name stdout as the name of the debugging output file, the output will instead print to the screen. Using ASCII mode is helpful when the text format of your host differs from that of the remote host. For example, if you are sending a text file from a UNIX system to a Windows-based host, you could use the -a flag which would use ASCII transfer mode so that the file created on the Windows machine would be in its native text format instead of the UNIX text format. You can upload an entire directory tree of files by using the -R flag. Example: $ ncftpput -R pikachu.nintendo.co.jp \/incoming \/tmp\/stuff This would create a \/incoming\/stuff hierarchy on the remote host. The -T and -S options are useful when you want to upload file to the remote host, but you don't want to use the destination pathname until the file is complete. Using these options, you will not destroy a remote file by the same name until your file is finished. These options are also useful when a remote process on the remote host polls a specific filename, and you don't want that process to see that file until you know the file is finished sending. Here is an example that uploads to the file \/pub\/incoming\/README, using the filename \/pub\/incoming\/README.tmp as a temporary filename: $ ncftpput -S .tmp bowser.nintendo.co.jp \/pub\/incoming \/a\/README A neat way to pipe the output from any local command into a remote file is to use the -c option, which denotes that you're using stdin as input. The following example shows how to make a backup and store it on a remote machine: $ tar cf - \/ | ncftpput -c sonic.sega.co.jp \/usr\/local\/backup.tar","Process Name":"ncftpput","Link":"https:\/\/linux.die.net\/man\/1\/ncftpput"}},{"Process":{"Description":null,"Process Name":"ncftpspooler","Link":"https:\/\/linux.die.net\/man\/1\/ncftpspooler"}},{"Process":{"Description":null,"Process Name":"ncgen","Link":"https:\/\/linux.die.net\/man\/1\/ncgen"}},{"Process":{"Description":"ncgen3 generates either a netCDF file, or C or Fortran source code to create a netCDF file. The input to ncgen3 is a description of a netCDF file in a small language known as CDL (network Common Data form Language), described below. If no options are specified in invoking ncgen3, it merely checks the syntax of the input CDL file, producing error messages for any violations of CDL syntax. Other options can be used to create the corresponding netCDF file, to generate a C program that uses the netCDF C interface to create the netCDF file, or to generate a Fortran program that uses the netCDF Fortran interface to create the same netCDF file. ncgen3 may be used with the companion program ncdump to perform some simple operations on netCDF files. For example, to rename a dimension in a netCDF file, use ncdump to get a CDL version of the netCDF file, edit the CDL file to change the name of the dimensions, and use ncgen3 to generate the corresponding netCDF file from the edited CDL file.","Process Name":"ncgen3","Link":"https:\/\/linux.die.net\/man\/1\/ncgen3"}},{"Process":{"Description":"","Process Name":"ncgm2cgm","Link":"https:\/\/linux.die.net\/man\/1\/ncgm2cgm"}},{"Process":{"Description":"Ncid displays Caller ID information sent to it by the Caller ID server. In the default GUI mode, if the server is configured to send the CID Call Log, it will load the call log in the CID log window at startup. The call log is updated by ncid whenever a call is received. Ncid also has a message window that will send a single line message to the server which, in turn, will send it to all connected clients. Ncid runs on Linux and Windows 98, ME, XP, 2000, NT. In the GUI mode, it will pop up, and go on top whenever a call comes in. In addition, it will display itself on whatever desktop is active in Linux. If ncid is given the --no-gui option, it will either output to a external program, output module, or use the verbose mode to display the CID information in a terminal window. If ncid is named tivocid, it will start in a no-gui mode and output to a external program called out2osd which displays the Caller ID on a TV using a TiVo. If ncid is named tivoncid, it will start in a no-gui mode and output to a module called ncid-tivo which displays the Caller ID on a TV using a TiVo. This option uses the TiVo program, text2osd, instead of out2osd. If ncid is configured to output to a external program, it will test for it, and if it is not found, or if it is not executable, it will terminate with a error message. The configuration file for ncid is \/etc\/ncid\/ncid.conf. The distributed output modules are listed in the ncidmodules man page, can be customized as needed in the \/etc\/ncid\/ncidmodules.conf file: Whenever the server connection is broken, ncid will normally try to reconnect once a minute. It provides a visual record of the countdown and number of tries. If the delay between attempts is set to zero seconds, ncid will not attempt a reconnect. The file menu provides three menu items in the GUI mode: reconnect provides an immediate reconnect and a reload of the call log file. This provides a way to synchronize ncid with the server call log in the event of a network problem. clear clears the call log quit terminates ncid.","Process Name":"ncid","Link":"https:\/\/linux.die.net\/man\/1\/ncid"}},{"Process":{"Description":"These are ncid output modules and are normally located in the \/usr\/share\/ncid directory. The client, ncid, can be configured to call any one module. It cannot call multiple modules, but multiple clients can be used, each calling a different output module. The ncid-hangup module uses a modem to hang up on a phone call. It works with either a modem or gateway providing the Caller ID information. The module uses minicom and runscript to talk to the modem. The ncid-initmodem module reinitializes the modem obtaining the Caller ID for the server. It can only be used if the modem supports Caller ID and sends \"RING\" at each ringing signal. If the server indicates a non-CID call, ncid-initmodem will cause ncidd to re-initialize the modem for CID. Never use this module with a modem that does not support Caller ID. The module can be used with TiVo modems that drop out of Caller ID mode. The ncid-page module is used to send a call message to a cell phone, pager, or email address. It normally sends the message as soon as the Caller ID is received. It can be configured to wait until a specific number of rings before sending the message when using a modem that indicates RING, or it can send the message if the call was unanswered or at the completion of the call when using a SIP gateway. The module requires PageTo in ncidmodules.conf to be set to the SMS gateway for your cell phone carrier. The ncid-skel output module is used as a template for writing a shell script output module. All it does is send the Caller ID data to standard output. This makes it useful for troubleshooting. Each output module can be independently configured using the module configuration file: ncidmodules.conf","Process Name":"ncidmodules","Link":"https:\/\/linux.die.net\/man\/1\/ncidmodules"}},{"Process":{"Description":"The NCID log rotation module is normally found in \/usr\/share\/ncid directory. Ncidrotate is called by \/etc\/logrotate.d\/ncid and will keep a number of lines in cidcall.log after rotation. The default is 0 lines kept. The configuration file for logrotate is \/etc\/ncid\/ncidrotate.conf","Process Name":"ncidrotate","Link":"https:\/\/linux.die.net\/man\/1\/ncidrotate"}},{"Process":{"Description":null,"Process Name":"ncidtools","Link":"https:\/\/linux.die.net\/man\/1\/ncidtools"}},{"Process":{"Description":"ncks combines selected features of ncdump, ncextr, and the nccut and ncpaste specifications into one versatile utility. ncks extracts a subset of the data from input-file and either prints it as ASCII text to stdout, or writes (or pastes) it to output-file, or both. ncks will print netCDF data in ASCII format to stdout, like ncdump, but with these differences: ncks prints data in a tabular format intended to be easy to search for the data you want, one datum per screen line, with all dimension subscripts and coordinate values (if any) preceding the datum. Option -s allows the user the format the data using C-style format strings. Options -a, -F, -H, -M, -m, -q, -s, and -u control the formatted appearance of the data. ncks will extract (and optionally create a new netCDF file comprised of) only selected variable from the input file, like ncextr but with these differences: Only variables and coordinates may be specifically included or excluded---all global attributes and any attribute associated with an extracted variable will be copied to the screen and\/or output netCDF file. Options -c, -C, -v, and -x control which variables are extracted. ncks will extract hyperslabs from the specified variables. In fact ncks implements the nccut specification exactly. Option -d controls the hyperslab specification. Input dimensions that are not associated with any output variable will not appear in the output netCDF. This feature removes superfluous dimensions from a netCDF file. ncks will append variables and attributes from the input-file to output-file if output-file is a pre-existing netCDF file whose relevant dimensions conform to dimension sizes of input-file. The append features of ncks are intended to provide a rudimentary means of adding data from one netCDF file to another, conforming, netCDF file. When naming conflicts exists between the two files, data in output-file is usually overwritten by the corresponding data from input-file. Thus it is recommended that the user backup output-file in case valuable data is accidentally overwritten. If output-file exists, the user will be queried whether to overwrite, append, or exit the ncks call completely. Choosing overwrite destroys the existing output-file and create an entirely new one from the output of the ncks call. Append has differing effects depending on the uniqueness of the variables and attributes output by ncks: If a variable or attribute extracted from input-file does not have a name conflict with the members of output-file then it will be added to output-file without overwriting any of the existing contents of output-file. In this case the relevant dimensions must agree (conform) between the two files; new dimensions are created in output-file as required. When a name conflict occurs, a global attribute from input-file will overwrite the corresponding global attribute from output-file. If the name conflict occurs for a non-record variable, then the dimensions and type of the variable (and of its coordinate dimensions, if any) must agree (conform) in both files. Then the variable values (and any coordinate dimension values) from input-file will overwrite the corresponding variable values (and coordinate dimension values, if any) in output-file Since there can only be one record dimension in a file, the record dimension must have the same name (but not necessarily the same size) in both files if a record dimension variable is to be appended. If the record dimensions are of differing sizes, the record dimension of output-file will become the greater of the two record dimension sizes, the record variable from input-file will overwrite any counterpart in output-file and fill values will be written to any gaps left in the rest of the record variables (I think). In all cases variable attributes in output-file are superseded by attributes of the same name from input-file, and left alone if there is no name conflict. Some users may wish to avoid interactive ncks queries about whether to overwrite existing data. For example, batch scripts will fail if ncks does not receive responses to its queries. Options -O and -A are available to force overwriting existing files and variables, respectively. Options specific to ncks The following list provides a short summary of the features unique to ncks. -a Do not alphabetize extracted fields. By default, the specified output variables are extracted, printed, and written to disk in alphabetical order. This tends to make long output lists easier to search for particular variables. Specifying -a results in the variables being extracted, printed, and written to disk in the order in which they were saved in the input file. Thus -a retains the original ordering of the variables. -d dim,[ min][,[ max]][,[ stride]] Add stride argument to hyperslabber. -H Print data to screen. The default behavior is to print data to screen if no netCDF output file is specified. Use -H to print data to screen if a netCDF output is specified (the same behavior applies to -m ). Unless otherwise specified (with -s), each element of the data hyperslab is printed on a separate line containing the names, indices, and, values, if any, of all of the variables dimensions. The dimension and variable indices refer to the location of the corresponding data element with respect to the variable as stored on disk (i.e., not the hyperslab). % ncks -H -C -v three_dmn_var in.nc lat[0]=-90 lev[0]=100 lon[0]=0 three_dmn_var[0]=0 lat[0]=-90 lev[0]=100 lon[1]=90 three_dmn_var[1]=1 lat[0]=-90 lev[0]=100 lon[2]=180 three_dmn_var[2]=2 ... lat[1]=90 lev[2]=1000 lon[1]=90 three_dmn_var[21]=21 lat[1]=90 lev[2]=1000 lon[2]=180 three_dmn_var[22]=22 lat[1]=90 lev[2]=1000 lon[3]=270 three_dmn_var[23]=23 Printing the same variable with the -F option shows the same variable indexed with Fortran conventions % ncks -F -H -C -v three_dmn_var in.nc lon(1)=0 lev(1)=100 lat(1)=-90 three_dmn_var(1)=0 lon(2)=90 lev(1)=100 lat(1)=-90 three_dmn_var(2)=1 lon(3)=180 lev(1)=100 lat(1)=-90 three_dmn_var(3)=2 ... Printing a hyperslab does not affect the variable or dimension indices since these indices are relative to the full variable (as stored in the input file), and the input file has not changed. However, if the hypserslab is saved to an output file and those values are printed, the indices will change: % ncks -H -d lat,90.0 -d lev,1000.0 -v three_dmn_var in.nc out.nc lat[1]=90 lev[2]=1000 lon[0]=0 three_dmn_var[20]=20 lat[1]=90 lev[2]=1000 lon[1]=90 three_dmn_var[21]=21 lat[1]=90 lev[2]=1000 lon[2]=180 three_dmn_var[22]=22 lat[1]=90 lev[2]=1000 lon[3]=270 three_dmn_var[23]=23 % ncks -H out.nc lat[0]=90 lev[0]=1000 lon[0]=0 three_dmn_var[0]=20 lat[0]=90 lev[0]=1000 lon[1]=90 three_dmn_var[1]=21 lat[0]=90 lev[0]=1000 lon[2]=180 three_dmn_var[2]=22 lat[0]=90 lev[0]=1000 lon[3]=270 three_dmn_var[3]=23 -M Print to screen the global metadata describing the file. This includes file summary information and global attributes. -m Print variable metadata to screen (similar to ncdump -h). This displays all metadata pertaining to each variable, one variable at a time. -q Toggle printing of dimension indices and coordinate values when printing arrays. The name of each variable will appear flush left in the output. This is useful when trying to locate specific variables when displaying many variables with different dimensions. The mnemonic for this option is \"quiet\". -s format String format for text output. Accepts C language escape sequences and printf() formats. -u Accompany the printing of a variable's values with its units attribute, if it exists.","Process Name":"ncks","Link":"https:\/\/linux.die.net\/man\/1\/ncks"}},{"Process":{"Description":"The netCDF Operators, or NCO are a suite of programs known as operators. Each operator is a standalone, command line program which is executed at the UNIX shell-level like, e.g., ls or mkdir. The operators take netCDF (<http:\/\/www.unidata.ucar.edu\/packages\/netcdf>) files as input, then perform a set of operations (e.g., deriving new data, averaging, hyperslabbing, or metadata manipulation) and produce a netCDF file as output. The operators are primarily designed to aid manipulation and analysis of gridded scientific data. The single command style of NCO allows users to manipulate and analyze files interactively and with simple scripts, avoiding the overhead (and some of the power) of a higher level programming environment. The NCO User's Guide illustrates their use with examples from the field of climate modeling and analysis. The available operators are: ncap2, netCDF Arithmetic Processor ncatted, netCDF Attribute Editor ncbo, netCDF Binary Operator (includes ncadd, ncsubtract, ncmultiply, ncdivide) ncea, netCDF Ensemble Averager ncecat, netCDF Ensemble Concatenator ncflint, netCDF File Interpolator ncks, netCDF Kitchen Sink ncpdq, netCDF Permute Dimensions Quickly, Pack Data Quietly ncra, netCDF Record Averager ncrcat, netCDF Record Concatenator ncrename, netCDF Renamer ncwa, netCDF Weighted Averager. (Note that the \"averagers\" are misnamed because they perform many non-linear operations as well, e.g., total, minimum, maximum, RMS). The operators are as general as netCDF itself: there are no restrictions on the contents of the netCDF file(s) used as input. NCO's internal routines are completely dynamic and impose no limit on the number or sizes of dimensions, variables, and files. NCO is designed to be used both interactively and with large batch jobs. The default operator behavior is often sufficient for everyday needs, and there are numerous command line (i.e., run-time) options, for special cases. NCO works well on all modern operating systems.","Process Name":"nco","Link":"https:\/\/linux.die.net\/man\/1\/nco"}},{"Process":{"Description":null,"Process Name":"ncpdq","Link":"https:\/\/linux.die.net\/man\/1\/ncpdq"}},{"Process":{"Description":"ncra averages record variables across an arbitrary number of input files. The record dimension is retained as a degenerate (size 1) dimension in the output variables. Input files may vary in size, but each must have a record dimension. The record coordinate, if any, should be monotonic for (or else non-fatal warnings may be generated). Hyperslabs of the record dimension which include more than one file are handled correctly. ncra supports the stride argument to the -d hyperslab option for the record dimension only, stride is not supported for non-record dimensions. ncra weights each record (e.g., time slice) in the input-files equally. ncra does not attempt to see if, say, the time coordinate is irregularly spaced and thus would require a weighted average in order to be a true time average.","Process Name":"ncra","Link":"https:\/\/linux.die.net\/man\/1\/ncra"}},{"Process":{"Description":"Ncrack is an open source tool for network authentication cracking. It was designed for high-speed parallel cracking using a dynamic engine that can adapt to different network situations. Ncrack can also be extensively fine-tuned for special cases, though the default parameters are generic enough to cover almost every situation. It is built on a modular architecture that allows for easy extension to support additional protocols. Ncrack is designed for companies and security professionals to audit large networks for default or weak passwords in a rapid and reliable way. It can also be used to conduct fairly sophisticated and intensive brute force attacks against individual services. Warning Ncrack is a new project started in the Summer of 2009. While it is already useful for some purposes, it is still unfinished, alpha quality software. You can help out by testing it and reporting any problems as described in the section called \"BUGS\". The output from Ncrack is a list of found credentials, if any, for each of the targets specified. Ncrack can also print an interactive status report of progress so far and possibly additional debugging information that can help track problems, if the user selected that option. A typical Ncrack scan is shown in Example 1. The only Ncrack arguments used in this example are the two target IP addresses along with the the corresponding ports for each of them. The two example ports 21 and 22 are automatically resolved to the default services listening on them: ftp and ssh. Example 1. A representative Ncrack scan $ ncrack 10.0.0.130:21 192.168.1.2:22\n\nStarting Ncrack 0.01ALPHA ( http:\/\/ncrack.org ) at 2009-07-24 23:05 EEST\n\nDiscovered credentials for ftp on 10.0.0.130 21\/tcp:\n10.0.0.130 21\/tcp ftp: admin hello1\nDiscovered credentials for ssh on 192.168.1.2 22\/tcp:\n192.168.1.2 22\/tcp ssh: guest 12345\n192.168.1.2 22\/tcp ssh: admin money$\n\nNcrack done: 2 services scanned in 156.03 seconds.\n\nNcrack finished. The latest version of Ncrack can be obtained from http:\/\/nmap.org\/ncrack . The latest version of this man page is available at http:\/\/nmap.org\/ncrack\/man.html .","Process Name":"ncrack","Link":"https:\/\/linux.die.net\/man\/1\/ncrack"}},{"Process":{"Description":"ncrcat concatenates record variables across an arbitrary number of input files. The final record dimension is by default the sum of the lengths of the record dimensions in the input files. Input files may vary in size, but each must have a record dimension. The record coordinate, if any, should be monotonic (or else non-fatal warnings may be generated). Hyperslabs of the record dimension which include more than one file are handled correctly. ncra supports the stride argument to the -d hyperslab option for the record dimension only, stride is not supported for non-record dimensions. ncrcat applies special rules to ARM convention time fields (e.g., time_offset).","Process Name":"ncrcat","Link":"https:\/\/linux.die.net\/man\/1\/ncrcat"}},{"Process":{"Description":"ncrename renames dimensions, variables, and attributes in a netCDF file. Each object that has a name in the list of old names is renamed using the corresponding name in the list of new names. All the new names must be unique. Every old name must exist in the input file, unless the name is preceded by the character .. The validity of the old names is not checked prior to the renaming. Thus, if an old name is specified without the the . prefix and is not present in input-file, ncrename will abort. ncrename is the exception to the normal rules that the user will be interactively prompted before an existing file is changed, and that a temporary copy of an output file is constructed during the operation. If only input-file is specified, then ncrename will change the names of the input-file in place without prompting and without creating a temporary copy of input-file. This is because the renaming operation is considered reversible if the user makes a mistake. The new_name can easily be changed back to old_name by using ncrename one more time. Note that renaming a dimension to the name of a dependent variable can be used to invert the relationship between an independent coordinate variable and a dependent variable. In this case, the named dependent variable must be one-dimensional and should have no missing values. Such a variable will become a coordinate variable. According to the netCDF User's Guide, renaming properties in netCDF files does not incur the penalty of recopying the entire file when the new_name is shorter than the old_name.","Process Name":"ncrename","Link":"https:\/\/linux.die.net\/man\/1\/ncrename"}},{"Process":{"Description":"Ncview displays 2-D slices of a netCDF data file, using the X Window System graphical user interface (Release 4 or higher). You can examine different floating point variables in the file, and animate the floating point data along the ''record dimension'' (usually time) to see how it evolves. You can also display 1-D (line plot) views of the data simply by clicking the mouse on the point of interest. When you first invoke ncview, a command panel comes up which has a number of buttons for manipulating the current view into the data file, and presenting various information about the current view. From the top, going down, the information fields are: the 'title' of the data file; the 'long_name' of the currently selected variable; the frame number (i.e., place along the scan axis) currently displayed; the minimum and maximum values of the variable; and the value of the data point under the cursor (only active when the pointer is over the color contour image). Next comes a row of buttons similar to a tape recorder, used for changing the view into the netCDF file along the scan dimension. In Version 1.XX of ncview, the scan dimension is constrained to be the ''record dimension'' (in netCDF parlance). From the left, the buttons are: the quit button; a button to take you directly to the first frame, marked \"->1\"; rewind, which loops the images going backwards; step backwards; pause; step forwards; and fast forward, which loops the images going forwards. Below this is the row of option buttons, which from the left are: the colormap button, labeled with the name of the current colormap (see below); \"Inv P\", which inverts the physical representation of the data (flips it upside-down); \"Inv C\", which inverts the colors currently being used so that the colors indicating minimum and maximum are switched; the magnification button, which sets how much image expansion the image undergoes; and the transformation button, which determines what preprocessing the data undergoes before display. For this button, \"Linear\" means no preprocessing, \"Low\" means that the data is raised to the fourth power before conversion to a pixel, so that low values are emphasized; and \"Hi\" means that the fourth root of the data is taken before conversion, so that large values are emphasized. Next comes \"Set Dim\"; pressing this pops up a window which allows you to determine which variables are shown on the X and Y axes. Note that Version 1.XX of ncview will not transpose your data! This means that, for example, you cannot simultaneously display the X dimension along the Y axis while displaying the Y dimension along the X axis---that would be an attempt to transpose the data. You can display the X dimension along the Y axis if some other variable which varies less rapidly in your particular data file (for example, depth) is on the X axis. Such a configuration is possible because it involves no transposition of data. In general you don't have to worry about this issue much, because if you attempt to pick axes which would be transposing the data, ncview switches them (and tells you that it's doing so!) so you can get the axes you want. Note that there is never any ambiguity about which dimensions are being displayed on what axes; that information is always shown in the main panel. Next is \"range\", which pops up dialog boxes to set the data min and maxes which will be contoured. Pressing with the RIGHTMOST mouse button on the \"range\" button resets the ranges to match the currently displayed slice; this is a VERY useful option, so remember it and make use of it frequently! The last button shows the method currently employed for expanding the data onto the screen; the default, \"bi-lin\", performes a bi-linear interpolation. Also available is \"repl\", which simply replicates the pixels and is somewhat faster. The next row of buttons shows what variables can be displayed from the input files. Note that when ncview first comes up, if there is more than one variable in the file, you must select a variable to display before you will see anything. If there is only one variable in the file, the selection defaults to that one. Below the variable selection buttons are the dimension information fields. All the dimensions for the displayed variable which can take on more than one value are shown here, one variable to a line. In each line, there are 6 fields of information; from left to right, they are: \"Dim\", the Dimension identifier, which is 'Scan' if the dimension is currently the scanned dimension (i.e., the dimension accessed via the tape-recorder style buttons), 'X' if the dimension appears in the color contour display along the x axis, or 'Y' if it appears in the color display along the y axis. This field will be blank if it isn't Scan, X, or Y. Next come \"Name\", the dimension's short name; \"Min\", the minimum value of the dimension; \"Current\", the current value of the dimension as displayed in the color contour panel; \"Max\", the maximum value of the dimension; and \"Units\", the dimension's units. Clicking on the \"Current\" field of a dimension allows you to change the current value of that dimension. Clicking with the left mouse button increases the current value of that dimension; clicking with the right button decreases it.","Process Name":"ncview","Link":"https:\/\/linux.die.net\/man\/1\/ncview"}},{"Process":{"Description":"ncwa averages variables in a single file over arbitrary dimensions, with options to specify weights, masks, and normalization. The default behavior of ncwa is to arithmetically average every numerical variable over all dimensions and produce a scalar result. To average variables over only a subset of their dimensions, specify these dimensions in a comma-separated list following -a, e.g., -a time,lat,lon. As with all arithmetic operators, the operation may be restricted to an arbitrary hypserslab by employing the -d option ncwa also handles values matching the variable's _FillValue attribute correctly. Moreover, ncwa understands how to manipulate user-specified weights, masks, and normalization options. With these options, ncwa can compute sophisticated averages (and integrals) from the command line. mask and weight, if specified, are broadcast to conform to the variables being averaged. The rank of variables is reduced by the number of dimensions which they are averaged over. Thus arrays which are one dimensional in the input-file and are averaged by ncwa appear in the output-file as scalars. This allows the user to infer which dimensions may have been averaged. Note that that it is impossible for ncwa to make make a weight or mask of rank W conform to a var of rank V if W > V. This situation often arises when coordinate variables (which, by definition, are one dimensional) are weighted and averaged. ncwa assumes you know this is impossible and so ncwa does not attempt to broadcast weight or mask to conform to var in this case, nor does ncwa print a warning message telling you this, because it is so common. Specifying dbg > 2 does cause ncwa to emit warnings in these situations, however. Non-coordinate variables are always masked and weighted if specified. Coordinate variables, however, may be treated specially. By default, an averaged coordinate variable, e.g., latitude, appears in output-file averaged the same way as any other variable containing an averaged dimension. In other words, by default ncwa weights and masks coordinate variables like all other variables. This design decision was intended to be helpful but for some applications it may be preferable not to weight or mask coordinate variables just like all other variables. Consider the following arguments to ncwa: lq-a latitude -w lat_wgt -d latitude,0.,90.rq where lat_wgt is a weight in the latitude dimension. Since, by default ncwa weights coordinate variables, the value of latitude in the output-file depends on the weights in lat_wgt and is not likely to be 45.---the midpoint latitude of the hyperslab. Option -I overrides this default behavior and causes ncwa not to weight or mask coordinate variables. In the above case, this causes the value of latitude in the output-file to be 45.---which is a somewhat appealing result. Thus, -I specifies simple arithmetic averages for the coordinate variables. In the case of latitude, -I specifies that you prefer to archive the central latitude of the hyperslab over which variables were averaged rather than the area weighted centroid of the hyperslab. Note that the default behavior of ( -I) changed on 1998\/12\/01---before this date the default was not to weight or mask coordinate variables. The mathematical definition of operations involving rank reduction is given above.","Process Name":"ncwa","Link":"https:\/\/linux.die.net\/man\/1\/ncwa"}},{"Process":{"Description":null,"Process Name":"ndiff","Link":"https:\/\/linux.die.net\/man\/1\/ndiff"}},{"Process":{"Description":null,"Process Name":"ndisasm","Link":"https:\/\/linux.die.net\/man\/1\/ndisasm"}},{"Process":{"Description":"ndrdump tries to parse the specified filename using Samba's parser for the specified pipe and function. The third argument should be either in or out, depending on whether the data should be parsed as a request or a reply. Running ndrdump without arguments will list the pipes for which parsers are available. Running ndrdump with one argument will list the functions that Samba can parse for the specified pipe. The primary function of ndrdump is debugging Samba's internal DCE\/RPC parsing functions. The file being parsed is usually one exported by wiresharks \"Export selected packet bytes\" function. The context argument can be used to load context data from the request packet when parsing reply packets (such as array lengths).","Process Name":"ndrdump","Link":"https:\/\/linux.die.net\/man\/1\/ndrdump"}},{"Process":{"Description":null,"Process Name":"ne","Link":"https:\/\/linux.die.net\/man\/1\/ne"}},{"Process":{"Description":"This utility will scan an image and try to set all pixels that are nearly black (or nearly white) around the collar to exactly black (or white). This is often used to 'fix up' lossy compressed airphotos so that color pixels can be treated as transparent when mosaicing. -o outfile : The name of the output file to be created. Newly created files are currently always created with the HFA driver (Erdas Imagine - .img) -white: Search for nearly white (255) pixels instead of nearly black pixels. -near dist : Select how far from black (or white) the pixel values can be and still considered near black (white). Defaults to 15. -nb non_black_pixels : number of non-black pixels that can be encountered before the giving up search inwards. Defaults to 2. infile : The input file. Any GDAL supported format, any number of bands, normally 8bit Byte bands. The algorithm processes the image one scanline at a time. A scan 'in' is done from either end setting pixels to black (white) until at least 'non_black_pixels' pixels that are more than 'dist' gray levels away from black (white) have been encountered at which point the scan stops. The nearly black (white) pixels are set to black (white). The algorithm also scans from top to bottom and from bottom to top to identify indentations in the top or bottom. The processing is all done in 8bit (Bytes). If the output file is omitted, the processed results will be written back to the input file - which must support update.","Process Name":"nearblack","Link":"https:\/\/linux.die.net\/man\/1\/nearblack"}},{"Process":{"Description":"nearneighbor reads arbitrarily located (x,y,z[,w]) triples [quadruplets] from standard input [or xyzfile(s)] and uses a nearest neighbor algorithm to assign an average value to each node that have one or more points within a radius centered on the node. The average value is computed as a weighted mean of the nearest point from each sector inside the search radius. The weighting function used is w(r) = 1 \/ (1 + d ^ 2), where d = 3 * r \/ search_radius and r is distance from the node. This weight is modulated by the observation points' weights [if supplied]. xyzfile(s) 3 [or 4, see -W] column ASCII file(s) [or binary, see -b] holding (x,y,z[,w]) data values. If no file is specified, nearneighbor will read from standard input. -G Give the name of the output grid file. -I x_inc [and optionally y_inc] is the grid spacing. Optionally, append a suffix modifier. Geographical (degrees) coordinates: Append m to indicate arc minutes or c to indicate arc seconds. If one of the units e, k, i, or n is appended instead, the increment is assumed to be given in meter, km, miles, or nautical miles, respectively, and will be converted to the equivalent degrees longitude at the middle latitude of the region (the conversion depends on ELLIPSOID). If \/ y_inc is given but set to 0 it will be reset equal to x_inc; otherwise it will be converted to degrees latitude. All coordinates: If = is appended then the corresponding max x ( east) or y ( north) may be slightly adjusted to fit exactly the given increment [by default the increment may be adjusted slightly to fit the given domain]. Finally, instead of giving an increment you may specify the number of nodes desired by appending + to the supplied integer argument; the increment is then recalculated from the number of nodes and the domain. The resulting increment value depends on whether you have selected a gridline-registered or pixel-registered grid; see Appendix B for details. Note: if -R grdfile is used then grid spacing has already been initialized; use -I to override the values. -N The circular area centered on each node is divided into sectors sectors. Average values will only be computed if there is at least one value inside at least min_sectors of the sectors for a given node. Nodes that fail this test are assigned the value NaN (but see -E). If min_sectors is omitted, each sector needs to have at least one value inside it. [Default is quadrant search with at least 50% coverage, i.e., sectors = 4 and min_sectors = 2]. Note that only the nearest value per sector enters into the averaging, not all values inside the circle. -R xmin, xmax, ymin, and ymax specify the Region of interest. For geographic regions, these limits correspond to west, east, south, and north and you may specify them in decimal degrees or in [+-]dd:mm[:ss.xxx][W|E|S|N] format. Append r if lower left and upper right map coordinates are given instead of w\/e\/s\/n. The two shorthands -Rg and -Rd stand for global domain (0\/360 and -180\/+180 in longitude respectively, with -90\/+90 in latitude). Alternatively, specify the name of an existing grid file and the -R settings (and grid spacing, if applicable) are copied from the grid. For calendar time coordinates you may either give (a) relative time (relative to the selected TIME_EPOCH and in the selected TIME_UNIT; append t to -JX| x), or (b) absolute time of the form [ date] T[ clock] (append T to -JX| x). At least one of date and clock must be present; the T is always required. The date string must be of the form [-]yyyy[-mm[-dd]] (Gregorian calendar) or yyyy[-Www[-d]] (ISO week calendar), while the clock string must be of the form hh:mm:ss[.xxx]. The use of delimiters and their type and positions must be exactly as indicated (however, input, output and plot formats are customizable; see gmtdefaults). -S Sets the search_radius in same units as the grid spacing; append m to indicate minutes or c to indicate seconds. Append k to indicate km (implies -R and -I are in degrees, and we will use a fast flat Earth approximation to calculate distance). For more accuracy, use uppercase K if distances should be calculated along geodesics. However, if the current ELLIPSOID is spherical then great circle calculations are used.","Process Name":"nearneighbor","Link":"https:\/\/linux.die.net\/man\/1\/nearneighbor"}},{"Process":{"Description":"dot draws directed graphs. It works well on DAGs and other graphs that can be drawn as hierarchies. It reads attributed graph files and writes drawings. By default, the output format dot is the input file with layout coordinates appended. neato draws undirected graphs using ''spring'' models (see Kamada and Kawai, Information Processing Letters 31:1, April 1989). Input files must be formatted in the dot attributed graph language. By default, the output of neato is the input graph with layout coordinates appended. twopi draws graphs using a radial layout (see G. Wills, Symposium on Graph Drawing GD'97, September, 1997). Basically, one node is chosen as the center and put at the origin. The remaining nodes are placed on a sequence of concentric circles centered about the origin, each a fixed radial distance from the previous circle. All nodes distance 1 from the center are placed on the first circle; all nodes distance 1 from a node on the first circle are placed on the second circle; and so forth. circo draws graphs using a circular layout (see Six and Tollis, GD '99 and ALENEX '99, and Kaufmann and Wiese, GD '02.) The tool identifies biconnected components and draws the nodes of the component on a circle. The block-cutpoint tree is then laid out using a recursive radial algorithm. Edge crossings within a circle are minimized by placing as many edges on the circle's perimeter as possible. In particular, if the component is outerplanar, the component will have a planar layout. If a node belongs to multiple non-trivial biconnected components, the layout puts the node in one of them. By default, this is the first non-trivial component found in the search from the root component. fdp draws undirected graphs using a ''spring'' model. It relies on a force-directed approach in the spirit of Fruchterman and Reingold (cf. Software-Practice & Experience 21(11), 1991, pp. 1129-1164). sfdp also draws undirected graphs using the ''spring'' model described above, but it uses a multi-scale approach to produce layouts of large graphs in a reasonably short time.","Process Name":"neato","Link":"https:\/\/linux.die.net\/man\/1\/neato"}},{"Process":{"Description":"NEdit is a standard GUI (Graphical User Interface) style text editor for programs and plain-text files. It provides mouse based editing and a streamlined editing style, based on popular Macintosh and MS Windows editors, for users of X workstations and X terminals.","Process Name":"nedit","Link":"https:\/\/linux.die.net\/man\/1\/nedit"}},{"Process":{"Description":"nedit-client is the client interface to the NEdit text editor. A server can be started explicitly by running NEdit in server mode: nedit -server If no server is running, nedit-client will start one unless configured otherwise. Client\/server mode is useful for integrating NEdit with software development environments, mailers, and other programs; or just as a quick way to open files from the shell command line without starting a new NEdit session.","Process Name":"nedit-client","Link":"https:\/\/linux.die.net\/man\/1\/nedit-client"}},{"Process":{"Description":null,"Process Name":"nemiver","Link":"https:\/\/linux.die.net\/man\/1\/nemiver"}},{"Process":{"Description":"The neon-config script provides information about an installed copy of the neon library. The --cflags and --libs options instruct how to compile and link an application against the library; the --version and --support options can help determine whether the library meets the applications requirements.","Process Name":"neon-config","Link":"https:\/\/linux.die.net\/man\/1\/neon-config"}},{"Process":{"Description":"This program is part of Netpbm(1). neotoppm reads an Atari Neochrome .neo file as input and produces a PPM image as output.","Process Name":"neotoppm","Link":"https:\/\/linux.die.net\/man\/1\/neotoppm"}},{"Process":{"Description":"The neqn program is actually just a shell script which invokes the eqn(1) command with the ascii output device. Note that eqn does not support low-resolution, typewriter-like devices (although it may work adequately for very simple input).","Process Name":"neqn","Link":"https:\/\/linux.die.net\/man\/1\/neqn"}},{"Process":{"Description":"nero is a simple router suited for small academic designs. Currently it can process designs of size up to 4K gates. GLOBAL ROUTING A design is considered as big if it contains nets which half perimeter is greater than 800 lambdas. Global routing is used on big designs. In nero, \"global routing\" means that the longuests nets are completly routed in a first step with only routing layers numbers 3 & 4. Then the smaller nets are routed with all avalaibles layers. This implies that when global routing is used, the number of routing layers is forced to at least 4. In each step, the nets are routed from the shortest to the longuest with the same routing algorithm.","Process Name":"nero","Link":"https:\/\/linux.die.net\/man\/1\/nero"}},{"Process":{"Description":"The goal of nerverot is to be interesting and compelling to watch, yet induce a state of nervous edginess in the viewer. This manpage describes v1.3 of the program.","Process Name":"nerverot","Link":"https:\/\/linux.die.net\/man\/1\/nerverot"}},{"Process":{"Description":"nescc is an extension to gcc that knows how to compile nesC applications. If invoked on regular C files, it behaves exactly like gcc. When invoked on a nesC component or interface (.nc extension) file it compiles and links (except if the -c, -S, -conly, -E or -fsyntax-only options are used) that component with the other files specified on the command line.","Process Name":"nescc","Link":"https:\/\/linux.die.net\/man\/1\/nescc"}},{"Process":{"Description":"nescc-mig is a tool to generate code to process nesC messages (which are specified by C types). The tool argument specifies what tool should be generated, the message-type specifies the C type of the message you wish to process and msg-format-file specifies a nesC file which uses that type. The message type must be defined with struct message-type, nx_struct message-type, union message-type, nx_union message-type. When used with types whose layout is platform-dependent (i.e., not defined with nx_struct or nx_union), it is important to specify the correct nescc target architecture option (-fnesc-target=...). If you are invoking nescc-mig indirectly via mig, you can use the ncc -target=... option instead. If an enum constant named AM_message_type (with message_type capitalized) is found, then the value of that constant is assumed to be the active message type for message-type. If you need access to other constants from your nesC application, please consult the nescc-ncg man page. The current tools are java, csharp, python and C, which generate java, C#, python and C code to encode and decode messages.","Process Name":"nescc-mig","Link":"https:\/\/linux.die.net\/man\/1\/nescc-mig"}},{"Process":{"Description":null,"Process Name":"nescc-ncg","Link":"https:\/\/linux.die.net\/man\/1\/nescc-ncg"}},{"Process":{"Description":"nescc-wiring is a tool to verify that wiring constraints specified on individual components are respected in a nesC program. These wiring constraints can specify that an interface provided or used by a component must be wired at least once, at most once, or exactly once. If no wiring constraints are violated, nescc-wiring terminates with an exit status of 0. Otherwise, appropriate error messages are printed and nescc-wiring terminates with a non-zero exit status. Wiring constraints are specified by placing @atmostonce(), @atleastonce() and @exactlyonce() attributes on the relevant interfaces. For instance, writing module Fun { provides interface Init @atleastonce(); ... ensures that programs using module Fun must wire its Init interface at least once. Specifically, when the annotation is placed on a provided interface, there must be the specified number of paths in the wiring graph from any module to that interface. If the annotations are placed on a used interface, there must be the specified number of paths in the wiring graph from the interface to any module. To use this wiring check tool, you must declare the @atmostonce(), @atleastonce() and @exactlyonce() attributes in some global header file as follows: struct @atleastonce() { }; struct @atmostonce() { }; struct @exactlyonce() { }; and you must pass the following options to nescc to create the XML file that you pass to nescc-wiring: -fnesc-dump=wiring -fnesc-dump='interfaces(!abstract())' -fnesc-dump='referenced(interfacedefs, components)' -fnesc-dumpfile=nesc-xml-file","Process Name":"nescc-wiring","Link":"https:\/\/linux.die.net\/man\/1\/nescc-wiring"}},{"Process":{"Description":"Nested is a specialized editor focused on creating structured documents such as reports, publications, presentations, books, etc. It is designed to help the user concentrate on writing content without been distracted by format or markup. It offers a rich WYSIWYM interface where the user writes plain text with a lightweight markup language known as txt2tags. Basic users are assisted with extensive examples, formatting buttons, a simple image gallery per document, assisted internal and external links, section based layout and easy publishing options in HTML, LaTeX or PDF. Power users will like the advanced pre-processing and post-processing options, advanced theming, version control systems compatibility, LaTeX formulas support, a complete set of keyboard shortcuts, among others. Nested separates content from presentation and publishing option, so same content can be presented as a HTML web page, a rich standard-compliant HTML presentation, a IEEE journal publication, a beautiful PDF book, etc. Nested files are plain text so they can be used with common version control systems. Please visit the program site at http:\/\/nestededitor.sourceforge.net\/.","Process Name":"nested","Link":"https:\/\/linux.die.net\/man\/1\/nested"}},{"Process":{"Description":null,"Process Name":"net-snmp-config","Link":"https:\/\/linux.die.net\/man\/1\/net-snmp-config"}},{"Process":{"Description":"The net-snmp-create-v3-user shell script is designed to create a new user in net-snmp configuration file (\/var\/net-snmp\/snmpd.conf by default).","Process Name":"net-snmp-create-v3-user","Link":"https:\/\/linux.die.net\/man\/1\/net-snmp-create-v3-user"}},{"Process":{"Description":"netatalk-config is a tool that is used to determine the compiler and linker flags that should be used to compile and link programs that use the netatalk run-time libraries.","Process Name":"netatalk-config","Link":"https:\/\/linux.die.net\/man\/1\/netatalk-config"}},{"Process":{"Description":null,"Process Name":"netcdfperl","Link":"https:\/\/linux.die.net\/man\/1\/netcdfperl"}},{"Process":{"Description":"The netkey-tool utility can be used from the command line to perform some smart card operations with NetKey E4 cards that cannot be done easily with other OpenSC-tools, such as changing local PINs, storing certificates into empty NetKey E4 cert-files or displaying the initial PUK-value.","Process Name":"netkey-tool","Link":"https:\/\/linux.die.net\/man\/1\/netkey-tool"}},{"Process":{"Description":"This program accepts and produces a variety of common network address and netmask formats. Not only can it convert address and netmask notations, but it will optimize the masks to generate the smallest list of rules. This is very handy if you've ever configured a firewall or router and some nasty network administrator before you decided that base 10 numbers were good places to start and end groups of machines.","Process Name":"netmask","Link":"https:\/\/linux.die.net\/man\/1\/netmask"}},{"Process":{"Description":"Netperf is a benchmark that can be used to measure various aspects of networking performance. Currently, its focus is on bulk data transfer and request\/response performance using either TCP or UDP, and the Berkeley Sockets interface. In addition, tests for DLPI, and Unix Domain Sockets, tests for IPv6 may be conditionally compiled-in. Global Options -4 Use AF_INET (aka IPv4) addressing for the control and possibly data connections. -6 Use AF_INET6 (aka IPv6) addressing for the control and possibly data connections. -a sizespec Alter the send and receive buffer alignments on the local system. This defaults to 8 bytes. -A sizespec As -a, but for the remote system. -B brandstr Add brandstr to the output of a test with banners disabled. -c [rate] Request CPU utilization and service demand calculations for the local system. If the optional rate parameter is specified, netperf will use that instead of calculating the rate itself. -C [rate] As -c, but for the remote system. -d Increase the quantity of debugging output displayed during a test (possibly at the expense of performance). -D [secs,units] (*) Display interim results at least every secs seconds uning units as the initial guess for units per second. This is only available when netperf has been configured with --enable-demo. -f GMKgmk Change the units of measure for *_STREAM tests. Capital letters are powers of two, lowercase are powers of ten. -F fill_file Pre-fill the send buffers with data from the named file. This is intended to provide a means for avoiding buffers that are filled with data which is trivially easy to compress. A good choice for a file that should be present on any system is this manpage - netperf.man. Other files may be provided as part of the distribution. -h Display a usage string, and exit. -H name|ip,family (*) Set the hostname (or IP address) and address family to use to establish the control connection to the remote system. Passing a single name with no comma will only set remote_host and will leave selection of address family for the control connection to the stack or by a -4 -r -6 command line option. -i max,min Set the maximum and minimum number of iterations when trying to reach certain confidence levels. -j Instruct netperf to calculate additional statistics on timing when running an omni test. Display of said statistics will depend on the presence of the corresponding output selectors in the output selection. These are MIN_LATENCY, MAX_LATENCY, P50_LATENCY, P90_LATENCY, P99_LATENCY, MEAN_LATENCY and STDDEV_LATENCY. -I lvl,[,intvl] Specify the confidence level (either 95 or 99 - 99 is the default) and the width of the confidence interval as a percentage (default 10) -l testlen Specify the length of the test (default 10 seconds). A negative value sets the number of request\/response transactions, or the number of bytes for a stream test. -L name|ip,fam (*) Set the local name|IP and\/or address family for the socket used for the control connection to the remote netserver. -n numcpus Specify the number of CPU's in the system on those systems for which netperf has no way to find the number of CPU's programatically. -N This option will tell netperf to not establish a control connection to a remote netserver. Instead it will try to establish a data connection directly, using only the information supplied by the command line parameters and\/or internal defaults. Unless other ports are provided by the command line, by default the data connection will be to the \"discard\" port for a \"STREAM\" or \"SENDFILE\" test, the \"echo\" port for an \"RR\" test or the \"chargen\" port for a \"MAERTS\" test. -o sizespec Set an offset from the alignment specified with -a. -O sizespec As -o, but for the remote system. -p portnum,locport (*) Direct the control connection to a netserver listening on the specified port, rather than using a \"netperf\" entry in \/etc\/services or the internal default (port 12865). If \",locport\" is specified the control connection will be established from that local port number. Specifying a single port number with no comma will specify only the remote netserver port number and will leave local port number selection to the stack. -P 0|1 Show (1) or suppress (0) the test banner. -S This option will cause an attempt to set SO_KEEPALIVE on the ends of the data connection for tests using BSD Sockets. It will be made on the netperf side of classic tests, and both netperf and netserver side of an omni or migrated test. -s seconds This will cause netperf to sleep \"seconds\" seconds before transferring data over the data connection. -t testname Specify the test to perform. Valid testnames include, but are not limited to, nor always compiled-in: TCP_STREAMTCP_SENDFILETCP_MAERTSTCP_RRTCP_CRRUDP_STREAMUDP_RRDLCO_STREAMDLCO_RRDLCL_STREAMDLCL_RRSTREAM_STREAMSTREAM_RRDG_STREAMDG_RRSCTP_STREAMSCTP_STREAM_MANYSCTP_RRSCTP_RR_MANYLOC_CPUREM_CPU -T lcpu,remcpu Request that netperf be bound to CPU lcpu and\/or netserver be bound to CPU rcpu. -v verbosity Set the verbosity level for the test (only with -P). -V Display the netperf version and exit. Test Specific Options -h Display a usage string based on the test name set with -t, and exit. Please consult the netperf manual Care and Feeding of Netperf 2.5.X (doc\/netperf.[pdf|html|txt]) for more information. Or you can join and send email to netperf-talk@netperf.org.","Process Name":"netperf","Link":"https:\/\/linux.die.net\/man\/1\/netperf"}},{"Process":{"Description":"NetPIPE uses a simple series of ping-pong tests over a range of message sizes to provide a complete measure of the performance of a network. It bounces messages of increasing size between two processes, whether across a network or within an SMP system. Message sizes are chosen at regular intervals, and with slight perturbations, to provide a complete evaluation of the communication system. Each data point involves many ping-pong tests to provide an accurate timing. Latencies are calculated by dividing the round trip time in half for small messages ( less than 64 Bytes ). The communication time for small messages is dominated by the overhead in the communication layers, meaning that the transmission is latency bound. For larger messages, the communication rate becomes bandwidth limited by some component in the communication subsystem (PCI bus, network card link, network switch). These measurements can be done at the message-passing layer (MPI, MPI-2, and PVM) or at the native communications layers that that run upon (TCP\/IP, GM for Myrinet cards, InfiniBand, SHMEM for the Cray T3E systems, and LAPI for IBM SP systems). Recent work is being aimed at measuring some internal system properties such as the memcpy module that measures the internal memory copy rates, or a disk module under development that measures the performance to various I\/O devices. Some uses for NetPIPE include: Comparing the latency and maximum throughput of various network cards. Comparing the performance between different types of networks. Looking for inefficiencies in the message-passing layer by comparing it to the native communication layer. Optimizing the message-passing layer and tune OS and driver parameters for optimal performance of the communication subsystem. NetPIPE is provided with many modules allowing it to interface with a wide variety of communication layers. It is fairly easy to write new interfaces for other reliable protocols by using the existing modules as examples.","Process Name":"netpipe","Link":"https:\/\/linux.die.net\/man\/1\/netpipe"}},{"Process":{"Description":"netreport tells the network management scripts to send a SIGIO signal to the process which called netreport when any network interface status changes occur.","Process Name":"netreport","Link":"https:\/\/linux.die.net\/man\/1\/netreport"}},{"Process":{"Description":"wodim is used to record data or audio Compact Discs on an Orange Book CD-Recorder or to write DVD media on a DVD-Recorder. The device is the device file or label offered by the operating system to access the recorder with SCSI GENERIC (sg) interface. Note that some operating systems may provide separate device nodes for block-oriented and sg access. For example, on older Linux systems, the sg access was available through \/dev\/sg... files while the block oriented access was done through associated (but not identical) \/dev\/hd... and \/dev\/sr... (or \/dev\/scd... ) files. In any case, the user running wodim needs read and write access to the particular device file on a Linux system. It is recommended to be root or install the application as suid-root, because certain versions of Linux (kernel) limit the set of SCSI commands allowed for non-root users. Even if usage without root identity is possible in many cases, some device drivers still may fail, show unexplainable problems and generally the problems become harder to debug. The risk for buffer-underruns is also increased. See the PROCESS SCHEDULING PRIORITY section below for more details. There is an alternative way of specifying the device, using the traditional SCSI descriptions in form of devicetype:bus\/target\/lun specification. However, the success of this method is not guaranteed since it requires an adaptation scheme for your architecture, and the numbers may vary depending on the hardware-internal numbering or on the order of hot-plug device detection. If your operating system does not provide a sufficient framework for keeping this numbers persistent, don't rely on them. See -scanbus and --devices options below for details. There are emulated SCSI compatible device systems, using the SCSI protocols transported over various hardware\/media types. The most known examples is ATAPI (\"IDE burners\") or USB storage (\"external USB case\"). If the pseudo-SCSI b\/t\/l device address specification is used instead of the native one, you need to prepend the \"devicetype:\" description to the emulated \"bus\/target\/lun\" device address. If a file \/etc\/wodim.conf exists, the parameter to the dev= option may also be a drive name label in that file (see FILES section). As a special exception, the device specification can be -1 or just omitted, which invokes automatic guessing of an appropriate device for the selected operation. However, this guessing is not available everywhere and is not reliable; it is only available for the user's convenience in simple environments. In Track At Once mode, each track corresponds to a single file that contains the prepared data for that track. If the argument is '-', standard input is used for that track. Only one track may be taken from stdin. In the other write modes, the direct file to track relation may not be implemented. In -clone mode, a single file contains all data for the whole disk. To allow DVD writing on platforms that do not implement large file support, wodim concatenates all file arguments to a single track when writing to DVD media.","Process Name":"netscsid","Link":"https:\/\/linux.die.net\/man\/1\/netscsid"}},{"Process":{"Description":"Netserver listens for connections from a netperf benchmark, and responds accordingly. It can either be run from inetd or as a standalone daemon (with the -p flag). If run from inetd the -p option should not be used. Options -4 Use AF_INET (aka IPv4) addressing for the control and possibly data connections. -6 Use AF_INET6 (aka IPv6) addressing for the control and possibly data connections. -d Increase the quantity of debugging output displayed during a test (possibly at the expense of performance). -h Display a usage string, and exit. -L name,family Set the local name and\/or address family for the socket used for the control connection. -p portnum Listen on the specified port. This is used when running as a standalone daemon. -v verbosity Set the verbosity level for the test. -V Display the netperf version and exit.","Process Name":"netserver","Link":"https:\/\/linux.die.net\/man\/1\/netserver"}},{"Process":{"Description":null,"Process Name":"netstat-nat","Link":"https:\/\/linux.die.net\/man\/1\/netstat-nat"}},{"Process":{"Description":"Netstiff (formerly known as webdiff) is a powerful and easy-to-use tool which checks for Web page and\/or FTP site updates. For the Web, updates are recognized using several test criteria (diff, html, size, date, md5sum, regexp). The FTP update checker is only able to diff on directory listings and files and to compare size and date of files. Without a given command, netstiff will check for updates of the specified URIs and then print the changes. If no configuration file exists, the configurator is launched instead. Netstiff exits after all configured URIs are checked. Occuring warnings and errors leave a message in the log file (~\/.netstiff\/lastlog) and on stderr. Use it with cron if you want to check for updates regularly.","Process Name":"netstiff","Link":"https:\/\/linux.die.net\/man\/1\/netstiff"}},{"Process":{"Description":null,"Process Name":"nettee","Link":"https:\/\/linux.die.net\/man\/1\/nettee"}},{"Process":{"Description":null,"Process Name":"netwatch","Link":"https:\/\/linux.die.net\/man\/1\/netwatch"}},{"Process":{"Description":"number number of the tool to use parameters parameters for the chosen tool number. Parameter --help shows help. Parameter --help2 shows description. When using netwox without number and parameters, it enters interactive help mode. In this mode, the user has to select a category by pressing a key. Then by choosing a tool number, its corresponding usage is displayed. Note: netwag is easier than interactive help mode.","Process Name":"netwox","Link":"https:\/\/linux.die.net\/man\/1\/netwox"}},{"Process":{"Description":"number number of the tool to use parameters parameters for the chosen tool number. Parameter --help shows help. Parameter --help2 shows description. When using netwox without number and parameters, it enters interactive help mode. In this mode, the user has to select a category by pressing a key. Then by choosing a tool number, its corresponding usage is displayed. Note: netwag is easier than interactive help mode.","Process Name":"netwox535","Link":"https:\/\/linux.die.net\/man\/1\/netwox535"}},{"Process":{"Description":null,"Process Name":"newaliases.postfix","Link":"https:\/\/linux.die.net\/man\/1\/newaliases.postfix"}},{"Process":{"Description":"Newaliases rebuilds the random access data base for the mail aliases file \/etc\/aliases. It must be run each time this file is changed in order for the change to take effect. Newaliases is identical to ''sendmail -bi''. The newaliases utility exits 0 on success, and >0 if an error occurs. Notice: do not use makemap to create the aliases data base, because newaliases puts a special token into the data base that is required by sendmail.","Process Name":"newaliases.sendmail","Link":"https:\/\/linux.die.net\/man\/1\/newaliases.sendmail"}},{"Process":{"Description":"This is a link to the ssmtp binary. It invokes \/usr\/sbin\/sendmail with the -bi option. It is provided for compatibility with the sendmail program. In this case it does absolutely nothing since sSMTP does not support \/etc\/aliases and is just there to avoid programs returning error messages.","Process Name":"newaliases.ssmtp","Link":"https:\/\/linux.die.net\/man\/1\/newaliases.ssmtp"}},{"Process":{"Description":"Exit successfully if files src1 ... srcN exist and at least one of them is not older than target. Also exit successfully if target doesn't exist.","Process Name":"newer","Link":"https:\/\/linux.die.net\/man\/1\/newer"}},{"Process":{"Description":null,"Process Name":"newgrp","Link":"https:\/\/linux.die.net\/man\/1\/newgrp"}},{"Process":{"Description":"newhelp generates the Performance Co-Pilot help text files used by Performance Metric Domain Agents (PMDAs). Normally newhelp operates on the default Performance Metrics Namespace (PMNS), however if the -n option is specified an alternative namespace is loaded from the file pmnsfile. When there is only one input file, the base name of the new database is derived from the name of the input file, otherwise the -o flag must be given to explicitly name the database. If no input files are supplied, newhelp reads from the standard input stream, in which case the -o flag must be given. If the output file name is determined to be foo, newhelp will create foo.dir and foo.pag. Although historically there have been multiple help text file formats, the only format currently supported using the -v option is version 2, and this is the default if no -v flag is provided. The -V flag causes verbose messages to be printed while newhelp is parsing its input. The first line of each entry in a help source file consists of an ''@'' character beginning the line followed by a space and then the performance metric name and a one line description of the metric. Following lines (up to the next line beginning with ''@'' or end of file) may contain a verbose help description. E.g. #\n# This is an example of newhelp's input syntax\n#\n@ kernel.all.cpu.idle CPU idle time\nA cumulative count of the number of milliseconds\nof CPU idle time, summed over all processors. Three-part numeric metric identifiers (PMIDs) may be used in place of metric names, e.g. 60.0.23 rather than kernel.all.cpu.idle in the example above. Other than for dynamic metrics (where the existence of a metric is known to a PMDA, but not visible in the PMNS and hence has no name that could be known to newhelp) use of this syntactic variant is not encouraged. Lines beginning with ''#'' are ignored, as are blank lines in the file before the first ''@''. The verbose help text is optional. As a special case, a ''metric'' name of the form NNN.MM (for numeric NNN and MM) is interpreted as an instance domain identification, and the text describes the instance domain.","Process Name":"newhelp","Link":"https:\/\/linux.die.net\/man\/1\/newhelp"}},{"Process":{"Description":"Run a new shell in a new context. The new context is derived from the old context in which newrole is originally executed. If the -r or --role option is specified, then the new context will have the role specified by ROLE. If the -t or --type option is specified, then the new context will have the type (domain) specified by TYPE. If a role is specified, but no type is specified, the default type is derived from the specified role. If the -l or --level option is specified, then the new context will have the sensitivity level specified by LEVEL. If LEVEL is a range, the new context will have the sensitivity level and clearance specified by that range. Additional arguments ARGS may be provided after a -- option, in which case they are supplied to the new shell. In particular, an argument of -- -c will cause the next argument to be treated as a command by most command interpreters. If a command argument is specified to newrole and the command name is found in \/etc\/selinux\/newrole_pam.conf, then the pam service name listed in that file for the command will be used rather than the normal newrole pam configuration. This allows for per-command pam configuration when invoked via newrole, e.g. to skip the interactive re-authentication phase. The new shell will be the shell specified in the user's entry in the \/etc\/passwd file. The -V or --version shows the current version of newrole","Process Name":"newrole","Link":"https:\/\/linux.die.net\/man\/1\/newrole"}},{"Process":{"Description":null,"Process Name":"newsq","Link":"https:\/\/linux.die.net\/man\/1\/newsq"}},{"Process":{"Description":"Vi is a screen oriented text editor. Ex is a line-oriented text editor. Ex and vi are different interfaces to the same program, and it is possible to switch back and forth during an edit session. View is the equivalent of using the -R (read-only) option of vi. This manual page is the one provided with the nex\/nvi versions of the ex\/vi text editors. Nex\/nvi are intended as bug-for-bug compatible replacements for the original Fourth Berkeley Software Distribution (4BSD) ex and vi programs. For the rest of this manual page, nex\/nvi is used only when it's necessary to distinguish it from the historic implementations of ex\/vi. This manual page is intended for users already familiar with ex\/vi. Anyone else should almost certainly read a good tutorial on the editor before this manual page. If you're in an unfamiliar environment, and you absolutely have to get work done immediately, read the section after the options description, entitled \"Fast Startup\". It's probably enough to get you going. The following options are available: -c Execute cmd immediately after starting the edit session. Particularly useful for initial positioning in the file, however cmd is not limited to positioning commands. This is the POSIX 1003.2 interface for the historic \"+cmd\" syntax. Nex\/nvi supports both the old and new syntax. -e Start editing in ex mode, as if the command name were ex. -l Start editing with the lisp and showmatch options set. -R Start editing in read-only mode, as if the command name was view, or the readonly option was set. -r Recover the specified files, or, if no files are specified, list the files that could be recovered. If no recoverable files by the specified name exist, the file is edited as if the -r option had not been specified. -S Run with the secure edit option set, disallowing all access to external programs. -s Enter batch mode; applicable only to ex edit sessions. Batch mode is useful when running ex scripts. Prompts, informative messages and other user oriented message are turned off, and no startup files or environmental variables are read. This is the POSIX 1003.2 interface for the historic \"-\" argument. Nex\/nvi supports both the old and new syntax. -t Start editing at the specified tag. (See ctags(1)). -w Set the initial window size to the specified number of lines. -v Start editing in vi mode, as if the command name was vi or view. Note that the -F option (which prevented ex\/vi from making a full backup of the target file) has been removed and is no longer available. Command input for ex\/vi is read from the standard input. In the vi interface, it is an error if standard input is not a terminal. In the ex interface, if standard input is not a terminal, ex will read commands from it regardless, however, the session will be a batch mode session, exactly as if the -s option had been specified. Ex\/vi exits 0 on success, and greater than 0 if an error occurs.","Process Name":"nex","Link":"https:\/\/linux.die.net\/man\/1\/nex"}},{"Process":{"Description":"","Process Name":"nextd","Link":"https:\/\/linux.die.net\/man\/1\/nextd"}},{"Process":{"Description":"nfs4_setfacl manipulates the NFSv4 Access Control List (ACL) of one or more files (or directories), provided they are on a mounted NFSv4 filesystem which supports ACLs. nfs4_editfacl is equivalent to nfs4_setfacl -e. Refer to the nfs4_acl(5) manpage for information about NFSv4 ACL terminology and syntax. COMMANDS -a acl_spec [ index] add the ACEs from acl_spec to file's ACL. ACEs are inserted starting at the indexth position (DEFAULT: 1) of file's ACL. -A acl_file [ index] add the ACEs from the acl_spec in acl_file to file's ACL. ACEs are inserted starting at the indexth position (DEFAULT: 1) of file's ACL. -x acl_spec | index delete ACEs matched from acl_spec - or delete the indexth ACE - from file's ACL. Note that the ordering of the ACEs in acl_spec does not matter. -X acl_file delete ACEs matched from the acl_spec in acl_file from file's ACL. Note that the ordering of the ACEs in the acl_spec does not matter. -s acl_spec set file's ACL to acl_spec. -S acl_file set file's ACL to the acl_spec in acl_file. -e, --edit edit file's ACL in the editor defined in the EDITOR environment variable (DEFAULT: vi(1)) and set the resulting ACL upon a clean exit, assuming changes made in the editor were saved. Note that if multiple files are specified, the editor will be serially invoked once per file. -m from_ace to_ace modify file's ACL in-place by replacing from_ace with to_ace. -?, -h, --help display help text and exit. --version display this program's version and exit. NOTE: if '-' is given as the acl_file with the -A\/ -X\/ -S flags, the acl_spec will be read from stdin. OPTIONS -R, --recursive recursively apply to a directory's files and subdirectories. Similar to setfacl(1), the default behavior is to follow symlinks given on the command line and to skip symlinks encountered while recursing through directories. -L, --logical in conjunction with -R\/ --recursive, a logical walk follows all symbolic links. -P, --physical in conjunction with -R\/ --recursive, a physical walk skips all symbolic links. --test display results of COMMAND, but do not save changes.","Process Name":"nfs4_editfacl","Link":"https:\/\/linux.die.net\/man\/1\/nfs4_editfacl"}},{"Process":{"Description":"nfs4_getfacl will display the NFSv4 Access Control List (ACL) for file (a file or directory), provided file is on a mounted NFSv4 filesystem which supports ACLs. If the -H\/--more-help flag is specified, nfs4_getfacl will print some information about NFSv4 ACLs and the fields used in ACEs. The output format for an NFSv4 file ACL, e.g., is: A::OWNER@:rwatTnNcCy\nA::alice@nfsdomain.org:rxtncy\nA::bob@nfsdomain.org:rwadtTnNcCy\nA:g:GROUP@:rtncy\nD:g:GROUP@:waxTC\nA::EVERYONE@:rtncy\nD::EVERYONE@:waxTC In the example output above, the user 'alice@nfsdomain.org' has the equivalent of \"read\" and \"execute\" permissions, 'bob@nfsdomain.org' has \"read\" and \"write\", and both 'GROUP@' and 'EVERYONE@' have \"read\". Refer to the nfs4_acl(5) manpage for detailed information about NFSv4 ACL terminology and syntax.","Process Name":"nfs4_getfacl","Link":"https:\/\/linux.die.net\/man\/1\/nfs4_getfacl"}},{"Process":{"Description":"nfs4_setfacl manipulates the NFSv4 Access Control List (ACL) of one or more files (or directories), provided they are on a mounted NFSv4 filesystem which supports ACLs. nfs4_editfacl is equivalent to nfs4_setfacl -e. Refer to the nfs4_acl(5) manpage for information about NFSv4 ACL terminology and syntax. COMMANDS -a acl_spec [ index] add the ACEs from acl_spec to file's ACL. ACEs are inserted starting at the indexth position (DEFAULT: 1) of file's ACL. -A acl_file [ index] add the ACEs from the acl_spec in acl_file to file's ACL. ACEs are inserted starting at the indexth position (DEFAULT: 1) of file's ACL. -x acl_spec | index delete ACEs matched from acl_spec - or delete the indexth ACE - from file's ACL. Note that the ordering of the ACEs in acl_spec does not matter. -X acl_file delete ACEs matched from the acl_spec in acl_file from file's ACL. Note that the ordering of the ACEs in the acl_spec does not matter. -s acl_spec set file's ACL to acl_spec. -S acl_file set file's ACL to the acl_spec in acl_file. -e, --edit edit file's ACL in the editor defined in the EDITOR environment variable (DEFAULT: vi(1)) and set the resulting ACL upon a clean exit, assuming changes made in the editor were saved. Note that if multiple files are specified, the editor will be serially invoked once per file. -m from_ace to_ace modify file's ACL in-place by replacing from_ace with to_ace. -?, -h, --help display help text and exit. --version display this program's version and exit. NOTE: if '-' is given as the acl_file with the -A\/ -X\/ -S flags, the acl_spec will be read from stdin. OPTIONS -R, --recursive recursively apply to a directory's files and subdirectories. Similar to setfacl(1), the default behavior is to follow symlinks given on the command line and to skip symlinks encountered while recursing through directories. -L, --logical in conjunction with -R\/ --recursive, a logical walk follows all symbolic links. -P, --physical in conjunction with -R\/ --recursive, a physical walk skips all symbolic links. --test display results of COMMAND, but do not save changes.","Process Name":"nfs4_setfacl","Link":"https:\/\/linux.die.net\/man\/1\/nfs4_setfacl"}},{"Process":{"Description":null,"Process Name":"ng4ex","Link":"https:\/\/linux.die.net\/man\/1\/ng4ex"}},{"Process":{"Description":"The ngclient2arc command scans the possible client configuration files from ARC versions before 0.9, and prints them in the new client configuration format. Then the user can put these into the client config if needed. This command does not modify any files. This command works only for client configuration.","Process Name":"ngclient2arc","Link":"https:\/\/linux.die.net\/man\/1\/ngclient2arc"}},{"Process":{"Description":"The motivation behind this little script was to have a repository for automated tests on issues that came up on the NorduGrid developers mailing list. As such this script indicates directories that are not present, checks host certificates, CA certificates and CRLs, validates the sanity of ARC configuration and tests for clock skew. BECAUSE EVERY INSTALLATION OF ARC IS DIFFERENT THIS UTILITY ONLY SUGGESTS WHAT COULD BE WRONG. SOMETIMES IT IS OVERRESTRICTIVE. AND SOMETIMES IT CAN MISS SOME MISCONFIGURATION. NEVER TREAT RESULTS PRODUCED BY IT AS ULTIMATE TRUTH.","Process Name":"ngconfigtest","Link":"https:\/\/linux.die.net\/man\/1\/ngconfigtest"}},{"Process":{"Description":"nget retrieves messages matching a regular expression, and decodes any files contained within. Multipart messages are automatically pieced together. Parts from multiple servers will be combined if needed.","Process Name":"nget","Link":"https:\/\/linux.die.net\/man\/1\/nget"}},{"Process":{"Description":"ngetlite retrieves messages as described in each listfile. Listfiles are generated with: nget -w <listfile> <retrieval args> In almost all circumstances, you will want to download and decode directly with nget. However, in some cases ngetlite can be useful on computers with low ram or cpu, that can't handle the large cache files needed for some groups. You can run nget -w on some other computer and then do the actual downloading with ngetlite using very little resources.","Process Name":"ngetlite","Link":"https:\/\/linux.die.net\/man\/1\/ngetlite"}},{"Process":{"Description":"The ngettext program translates a natural language message into the user's language, by looking up the translation in a message catalog, and chooses the appropriate plural form, which depends on the number COUNT and the language of the message catalog where the translation was found. Display native language translation of a textual message whose grammatical form depends on a number. -d, --domain= TEXTDOMAIN retrieve translated message from TEXTDOMAIN -e enable expansion of some escape sequences -E (ignored for compatibility) -h, --help display this help and exit -V, --version display version information and exit [TEXTDOMAIN] retrieve translated message from TEXTDOMAIN MSGID MSGID-PLURAL translate MSGID (singular) \/ MSGID-PLURAL (plural) COUNT choose singular\/plural form based on this value If the TEXTDOMAIN parameter is not given, the domain is determined from the environment variable TEXTDOMAIN. If the message catalog is not found in the regular directory, another location can be specified with the environment variable TEXTDOMAINDIR. Standard search directory: \/usr\/share\/locale","Process Name":"ngettext","Link":"https:\/\/linux.die.net\/man\/1\/ngettext"}},{"Process":{"Description":"ngmultidec writes an ngspice input file to standard output which describes a sub-circuit for coupled lines using uncoupled simple lossy lines. Each generated subcircuit models a 4-conductor transmission line with the following parameters: length l, line capacitance c, line resistance r, line conductance g, inductive_coeff_of_coupling k, inter-line capacitance cm, length l. Derived parameters are: lm, ctot. The values of l, c, the model name, the number of conductors and the length of the line must be specified. It is important to note that the model is a simplified one - the following assumptions are made: 1. The self-inductance l, the self-capacitance ctot (note: not c), the series resistance r and the parallel capacitance g are the same for all lines, and 2. Each line is coupled only to the two lines adjacent to it, with the same coupling parameters cm and lm. The first assumption implies that edge effects have to be neglected. The utility of these assumptions is that they make the sL+R and sC+G matrices symmetric, tridiagonal and Toeplitz, with useful consequences (see the paper referenced below). It may be noted that a symmetric two-conductor line is represented accurately by this model. Standard C language scientific (exponent) notation may be used for options' numeric values.","Process Name":"ngmultidec","Link":"https:\/\/linux.die.net\/man\/1\/ngmultidec"}},{"Process":{"Description":"ngmx is the GROMACS trajectory viewer. This program reads a trajectory file, a run input file and an index file and plots a 3D structure of your molecule on your standard X Window screen. No need for a high end graphics workstation, it even works on Monochrome screens. The following features have been implemented: 3D view, rotation, translation and scaling of your molecule(s), labels on atoms, animation of trajectories, hardcopy in PostScript format, user defined atom-filters runs on MIT-X (real X), open windows and motif, user friendly menus, option to remove periodicity, option to show computational box. Some of the more common X command line options can be used: -bg, -fg change colors, -font fontname changes the font.","Process Name":"ngmx","Link":"https:\/\/linux.die.net\/man\/1\/ngmx"}},{"Process":{"Description":"This man page is just a small overview. The primary documentation of ngspice is in the ngspice] User's Manual, which is available as a pdf file. ngnutmeg is a post processor for ngspice] - it takes the raw output file created by ngspice -r and plots the data on a graphics terminal or a workstation display. Note that the raw output file is different from the data that ngspice] writes to the standard output.","Process Name":"ngnutmeg","Link":"https:\/\/linux.die.net\/man\/1\/ngnutmeg"}},{"Process":{"Description":"Sconvert translates spice output files among three formats: the old binary format, a new binary format, and a new ascii format. The formats are specified by the fromtype and totype arguments: 'o' for the old format, 'b' for the new binary format, and 'a' for the new ascii format. Fromtype specifies the format to be read, and totype specifies the format to be written. If fromfile and tofile are given, then they are used as the input and output, otherwise standard input and output are used. (Note that this second option is only available on UNIX systems - on VMS and other systems you must supply the filenames.) If no arguments are given, the parameters are prompted for. Binary format is the preferred format for general use, as it is the most economical in terms of space and speed of access, and ascii is provided to make it easy to modify data files and transfer them between machines with different floating-point formats. The old format is provided only for backward compatibility. The three formats are as follows: Old:\n\n What Size in Bytes title 80 date 8 time 8 numoutputs 2 the integer 4 2 variable names -- char[numoutputs][8] numoutputs * 8 types of output numoutputs * 2 node index numoutputs * 2 plot title numoutputs * 24 the actual data numpoints * numoutputs * 8 Ascii: Title: Title Card String Date: Date [ Plotname: Plot Name Flags: complex or real No. Variables: numoutputs No. Points: numpoints Command: nutmeg command Variables: 0 varname1 typename1 1 varname2 typename2 etc... Values: 0 n n n n ... 1 n n n n ... And so forth... ] repeated one or more times If one of the flags is complex, the points look like r,i where r and i are floating point (in %e format). Otherwise they are in %e format. Only one of real and complex should appear. The lines are guaranteed to be less than 80 columns wide (unless the plot title or variable names are very long), so this format is safe to mail between systems like CMS. Any number of Command: lines may appear between the No. Points: and the Variables: lines, and whenever the plot is loaded into nutmeg they will be executed. Binary: Title Card (a NULL terminated string) Date, Time (a NULL terminated string) [ Plot title (a NULL terminated string) Number of variables (an int) Number of data points (an int) flags (a short) variable header struct (repeated numoutputs times) variable name (a NULL terminated string) variable type (an int) set of outputs (repeated numpoints times) ] repeated one or more times. A set of outputs is a vector of doubles of length numoutputs, or a vector of real-imaginary pairs of doubles if the data is complex.","Process Name":"ngsconvert","Link":"https:\/\/linux.die.net\/man\/1\/ngsconvert"}},{"Process":{"Description":"This man page is just a small overview. The primary documentation of ngspice is in the ngspice] User's Manual, which is available as a pdf file.","Process Name":"ngspice","Link":"https:\/\/linux.die.net\/man\/1\/ngspice"}},{"Process":{"Description":"nhlcc is a script that invokes the C compiler\/linker with the proper NCAR Graphics LLU (low-level utility) and HLU (high-level utility) libraries. Arguments presented above are associated with NCAR Graphics. All other arguments and options are identical to the cc command on your particular machine; arguments that include quoted strings may have to be enclosed in single quotes. If you don't want to use nhlcc, you can just type it on the command line to see what gets included in the link line, and then you can add this information to your own Makefile or script. It is important to note that you must define the macro NeedFuncProto in order for function prototyping to work correctly. In order to run nhlcc, you must have your NCARG_ROOT environment variable set to the directory pathname where the NCAR Graphics libraries, binaries, and include files were installed. If you are not sure what NCARG_ROOT should be set to, please check with your system administrator or the site representative for NCAR Graphics. If the NCAR Graphics libraries, binaries, and include files were not installed under one root directory, then you will need to set the environment variables NCARG_LIB, NCARG_BIN, and NCARG_INCLUDE instead. Please see \"man ncargintro\" for more information. Note that, on some systems, if you supply your own binary libraries in addition to the ones automatically referenced by nhlcc, all the libraries must have been created in a similar fashion. OPTIONS -ngmath Links in the NCAR Graphics ngmath library. -ncarbd Use this option for compilers that appear to be having trouble initializing blockdata variables. It will cause a small subroutine to be linked in that helps force the loading of blockdata initialization routines. -ngmathbd Just like with the -ncarbd option, use this option for compilers that appear to be having trouble initializing Ngmath-related blockdata variables. It will cause a small subroutine to be linked in that helps force the loading of Ngmath blockdata initialization routines. Note: this option doesn't need to be specified separately if you are already including the -ncarbd and -ngmath options. -netcdf Links in the netCDF library. This library is not part of NCAR Graphics, so check with your system administrator if you need it installed. You can obtain a copy of it by doing an anonymous ftp to unidata.ucar.edu. -hdf Links in the HDF library. This library is not part of NCAR Graphics, so check with your system administrator if you need it installed. You can obtain a copy of it by doing an anonymous ftp to ftp.ncsa.uiuc.edu.","Process Name":"nhlcc","Link":"https:\/\/linux.die.net\/man\/1\/nhlcc"}},{"Process":{"Description":"nhlf77 is a script that invokes the FORTRAN 77 compiler\/linker with the proper NCAR Graphics LLU (low-level utility) and HLU (high-level utility) libraries. Arguments presented above are associated with NCAR Graphics. All other arguments and options are identical to the f77 command on your particular machine; arguments that include quoted strings may have to be enclosed in single quotes. In order to run nhlf77, you must have your NCARG_ROOT environment variable set to the directory pathname where the NCAR Graphics libraries, binaries, and include files were installed. If you are not sure what NCARG_ROOT should be set to, please check with your system administrator or the site representative for NCAR Graphics. If the NCAR Graphics libraries, binaries, and include files were not installed under one root directory, then you will need to set the environment variables NCARG_LIB, NCARG_BIN, and NCARG_INCLUDE instead. Please see \"man ncargintro\" for more information. Note that, on some systems, if you supply your own binary libraries in addition to the ones automatically referenced by nhlf77, all the libraries must have been created in a similar fashion. OPTIONS -ngmath Links in the NCAR Graphics ngmath library. -ncarbd Use this option for compilers that appear to be having trouble initializing blockdata variables. It will cause a small subroutine to be linked in that helps force the loading of blockdata initialization routines. -ngmathbd Just like with the -ncarbd option, use this option for compilers that appear to be having trouble initializing Ngmath-related blockdata variables. It will cause a small subroutine to be linked in that helps force the loading of Ngmath blockdata initialization routines. Note: this option doesn't need to be specified separately if you are already including the -ncarbd and -ngmath options. -netcdf Links in the netCDF library. This library is not part of NCAR Graphics, so check with your system administrator if you need it installed. You can obtain a copy of it by doing an anonymous ftp to unidata.ucar.edu. -hdf Links in the HDF library. This library is not part of NCAR Graphics, so check with your system administrator if you need it installed. You can obtain a copy of it by doing an anonymous ftp to ftp.ncsa.uiuc.edu.","Process Name":"nhlf77","Link":"https:\/\/linux.die.net\/man\/1\/nhlf77"}},{"Process":{"Description":"nhlf90 is a script that invokes the FORTRAN 90 compiler\/linker with the proper NCAR Graphics LLU (low-level utility) and HLU (high-level utility) libraries. Arguments presented above are associated with NCAR Graphics. All other arguments and options are identical to the f90 command on your particular machine; arguments that include quoted strings may have to be enclosed in single quotes. In order to run nhlf90, you must have your NCARG_ROOT environment variable set to the directory pathname where the NCAR Graphics libraries, binaries, and include files were installed. If you are not sure what NCARG_ROOT should be set to, please check with your system administrator or the site representative for NCAR Graphics. If the NCAR Graphics libraries, binaries, and include files were not installed under one root directory, then you will need to set the environment variables NCARG_LIB, NCARG_BIN, and NCARG_INCLUDE instead. Please see \"man ncargintro\" for more information. Note that, on some systems, if you supply your own binary libraries in addition to the ones automatically referenced by nhlf90, all the libraries must have been created in a similar fashion. OPTIONS -ngmath Links in the NCAR Graphics ngmath library. -ncarbd Use this option for compilers that appear to be having trouble initializing blockdata variables. It will cause a small subroutine to be linked in that helps force the loading of blockdata initialization routines. -ngmathbd Just like with the -ncarbd option, use this option for compilers that appear to be having trouble initializing Ngmath-related blockdata variables. It will cause a small subroutine to be linked in that helps force the loading of Ngmath blockdata initialization routines. Note: this option doesn't need to be specified separately if you are already including the -ncarbd and -ngmath options. -netcdf Links in the netCDF library. This library is not part of NCAR Graphics, so check with your system administrator if you need it installed. You can obtain a copy of it by doing an anonymous ftp to unidata.ucar.edu. -hdf Links in the HDF library. This library is not part of NCAR Graphics, so check with your system administrator if you need it installed. You can obtain a copy of it by doing an anonymous ftp to ftp.ncsa.uiuc.edu.","Process Name":"nhlf90","Link":"https:\/\/linux.die.net\/man\/1\/nhlf90"}},{"Process":{"Description":null,"Process Name":"nice","Link":"https:\/\/linux.die.net\/man\/1\/nice"}},{"Process":{"Description":"Nickle is a desk calculator language with powerful programming and scripting capabilities. Nickle supports a variety of datatypes, especially arbitrary precision integers, rationals, and imprecise reals. The input language vaguely resembles C. Some things in C which do not translate easily are different, some design choices have been made differently, and a very few features are simply missing.","Process Name":"nickle","Link":"https:\/\/linux.die.net\/man\/1\/nickle"}},{"Process":{"Description":"naim is the original ncurses AIM client. It uses the TOC protocol, and features many commonly-requested features found nowhere else, while still providing an intuitive chat interface.","Process Name":"nicq","Link":"https:\/\/linux.die.net\/man\/1\/nicq"}},{"Process":{"Description":"The options are as follows: -oo output filename mask, default: '' -o output prefix name, default: 'image' -n number of exposures, default=0 -obsname,-observer observer's name -name,-object object's name -d auto-dark substract, dark interval, default: 0 no darks -w wait for specified num. of seconds, integer, default: 1 -b binning, default=3 -r select region by format: (x1,y1,x2,y2), default: full area -c select chip, I - imaging (default), T - tracking -v view exposed image with xnightview -p <x,y> point mode -pr radius to locate pointer star on image in pixels (default: 30) -pp toleration for pointer mode in arc seconds (default: 10) -host address:port internet address server, default: local connect -h print help","Process Name":"night_batch","Link":"https:\/\/linux.die.net\/man\/1\/night_batch"}},{"Process":{"Description":"The options are as follows: -oo output filename mask, default: '' -o output prefix name, default: 'image' -n number of exposures, default=0 -obsname,-observer observer's name -name,-object object's name -d auto-dark substract, dark interval, default: 0 no darks -w wait for specified num. of seconds, integer, default: 1 -b binning, default=3 -r select region by format: (x1,y1,x2,y2), default: full area -c select chip, I - imaging (default), T - tracking -v view exposed image with xnightview -p <x,y> point mode -pr radius to locate pointer star on image in pixels (default: 30) -pp toleration for pointer mode in arc seconds (default: 10) -host address:port internet address server, default: local connect -h print help","Process Name":"night_control","Link":"https:\/\/linux.die.net\/man\/1\/night_control"}},{"Process":{"Description":"The options are as follows: This routine is internal part of the nightview package and the user isn't supposed invoke it directly at anytime.","Process Name":"night_dark","Link":"https:\/\/linux.die.net\/man\/1\/night_dark"}},{"Process":{"Description":"The options are as follows: -oo output filename mask, default: '' -o output prefix name, default: 'd' -n number of exposures, default=0 -obsname,-observer observer's name -name,-object object's name, default: -name dark -w wait for specified num. of seconds, integer, default: 1 -b binning, default=3 -r select region by format: (x1,y1,x2,y2), default: full area -c select chip, I - imaging (default), T - tracking -v view exposed image with xnightview -host address:port internet address server, default: local connect -h print help","Process Name":"night_darks","Link":"https:\/\/linux.die.net\/man\/1\/night_darks"}},{"Process":{"Description":null,"Process Name":"night_exposure","Link":"https:\/\/linux.die.net\/man\/1\/night_exposure"}},{"Process":{"Description":"The options are as follows: options: info print current filter -f set filter, one from -list -list list of defined filters -init (re)initialize filter wheel -p show progress indicator -host address:port internet address server, default: local connect","Process Name":"night_filter","Link":"https:\/\/linux.die.net\/man\/1\/night_filter"}},{"Process":{"Description":"The options are as follows: -oo output filename mask, default: '' -o output prefix name, default: 'f' -n number of exposures, default=0 -obsname,-observer observer's name -name,-object object's name, default: -name flat -d auto-dark substract, dark interval, default: 0 no darks -w wait for specified num. of seconds, integer, default: 1 -b binning, default=3 -r select region by format: (x1,y1,x2,y2), default: full area -c select chip, I - imaging (default), T - tracking -v view exposed image with xnightview -host address:port internet address server, default: local connect -h print help","Process Name":"night_flats","Link":"https:\/\/linux.die.net\/man\/1\/night_flats"}},{"Process":{"Description":"The options are as follows: This routine is internal part of the nightview package and the user isn't supposed invoke it directly at anytime.","Process Name":"night_keylist","Link":"https:\/\/linux.die.net\/man\/1\/night_keylist"}},{"Process":{"Description":"The options are as follows: options: on switch on camera, failed if cammera not connected off switch off camera info print short info about camera login login into server (test of connection) -host address:port internet address server, default: local connect","Process Name":"night_power","Link":"https:\/\/linux.die.net\/man\/1\/night_power"}},{"Process":{"Description":"The options are as follows: options get: -t print ccd current temperature in degrees of Celsius -ta print air current temperature in degrees of Celsius -ts print temperature setpoint in degrees of Celsius -r print current cooling power (relatively, in percents) -f print current status of fan, on or off without switches print all available cooling information set: -t temperature set temperature of a cooler -off set regulation of temperature to off -host address:port internet address server, local connect is default","Process Name":"night_temperature","Link":"https:\/\/linux.die.net\/man\/1\/night_temperature"}},{"Process":{"Description":null,"Process Name":"nightfall","Link":"https:\/\/linux.die.net\/man\/1\/nightfall"}},{"Process":{"Description":"","Process Name":"nih-dbus-tool","Link":"https:\/\/linux.die.net\/man\/1\/nih-dbus-tool"}},{"Process":{"Description":"Ninjahelper is an helper script to walk you through configuration of the backup tasks for backupninja. It is a curses based \"wizard\" with an intuitive menu-driven interface.","Process Name":"ninjahelper","Link":"https:\/\/linux.die.net\/man\/1\/ninjahelper"}},{"Process":{"Description":"naim is the original ncurses AIM client. It uses the TOC protocol, and features many commonly-requested features found nowhere else, while still providing an intuitive chat interface.","Process Name":"nirc","Link":"https:\/\/linux.die.net\/man\/1\/nirc"}},{"Process":{"Description":"Hostname is the program that is used to either set or display the current host, domain or node name of the system. These names are used by many of the networking programs to identify the machine. The domain name is also used by NIS\/YP. Get Name When called without any arguments, the program displays the current names: hostname will print the name of the system as returned by the gethostname(2) function. domainname, nisdomainname, ypdomainname will print the name of the system as returned by the getdomainname(2) function. This is also known as the YP\/NIS domain name of the system. dnsdomainname will print the domain part of the FQDN (Fully Qualified Domain Name). The complete FQDN of the system is returned with hostname --fqdn. The function gethostname(2) is used to get the hostname. When the hostname -a, -d, -f or -i is called will gethostbyname(3) be called. The difference in gethostname(2) and gethostbyname(3) is that gethostbyname(3) is network aware, so it consults \/etc\/nsswitch.conf and \/etc\/host.conf to decide whether to read information in \/etc\/sysconfig\/network or \/etc\/hosts To add another dimension to this, the hostname is also set when the network interface is brought up. Set Name When called with one argument or with the --file option, the commands set the host name, the NIS\/YP domain name or the node name. Note, that only the super-user can change the names. It is not possible to set the FQDN or the DNS domain name with the dnsdomainname command (see THE FQDN below). The host name is usually set once at system startup in \/etc\/rc.d\/rc.inet1 or \/etc\/init.d\/boot (normally by reading the contents of a file which contains the host name, e.g. \/etc\/hostname). the Fqdn You can't change the FQDN (as returned by hostname --fqdn) or the DNS domain name (as returned by dnsdomainname) with this command. The FQDN of the system is the name that the resolver(3) returns for the host name. Technically: The FQDN is the name gethostbyname(2) returns for the host name returned by gethostname(2). The DNS domain name is the part after the first dot. Therefore it depends on the configuration (usually in \/etc\/host.conf) how you can change it. Usually (if the hosts file is parsed before DNS or NIS) you can change it in \/etc\/hosts. If a machine has multiple network interfaces\/addresses or is used in a mobile environment, then it may either have multiple FQDNs\/domain names or none at all. Therefore avoid using hostname --fqdn, hostname --domain and dnsdomainname. hostname --ip-address is subject to the same limitations so it should be avoided as well.","Process Name":"nisdomainname","Link":"https:\/\/linux.die.net\/man\/1\/nisdomainname"}},{"Process":{"Description":null,"Process Name":"nisserver-plugin-defs","Link":"https:\/\/linux.die.net\/man\/1\/nisserver-plugin-defs"}},{"Process":{"Description":"python-nitrate provides a high-level Python interface to the Nitrate test case management system. The package also provides standalone script 'nitrate' which allows easy experimenting with the interface directly from the Python interpreter by importing all available objects and enabling the readline support. In short, after setting your configuration you can easily manipulate all Nitrate objects from the command line, for example: $ nitrate\n>>> for case in TestRun(123):\n...     print case","Process Name":"nitrate","Link":"https:\/\/linux.die.net\/man\/1\/nitrate"}},{"Process":{"Description":null,"Process Name":"nkf","Link":"https:\/\/linux.die.net\/man\/1\/nkf"}},{"Process":{"Description":"Write each FILE to standard output, with line numbers added. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. -b, --body-numbering= STYLE use STYLE for numbering body lines -d, --section-delimiter= CC use CC for separating logical pages -f, --footer-numbering= STYLE use STYLE for numbering footer lines -h, --header-numbering= STYLE use STYLE for numbering header lines -i, --line-increment= NUMBER line number increment at each line -l, --join-blank-lines= NUMBER group of NUMBER empty lines counted as one -n, --number-format= FORMAT insert line numbers according to FORMAT -p, --no-renumber do not reset line numbers at logical pages -s, --number-separator= STRING add STRING after (possible) line number -v, --starting-line-number= NUMBER first line number on each logical page -w, --number-width= NUMBER use NUMBER columns for line numbers --help display this help and exit --version output version information and exit By default, selects -v1 -i1 -l1 -sTAB -w6 -nrn -hn -bt -fn. CC are two delimiter characters for separating logical pages, a missing second character implies :. Type \\\\ for \\. STYLE is one of: a number all lines t number only nonempty lines n number no lines pBRE number only lines that contain a match for the basic regular expression, BRE FORMAT is one of: ln left justified, no leading zeros rn right justified, no leading zeros rz right justified, leading zeros","Process Name":"nl","Link":"https:\/\/linux.die.net\/man\/1\/nl"}},{"Process":{"Description":"naim is the original ncurses AIM client. It uses the TOC protocol, and features many commonly-requested features found nowhere else, while still providing an intuitive chat interface.","Process Name":"nlily","Link":"https:\/\/linux.die.net\/man\/1\/nlily"}},{"Process":{"Description":"nload is a console application which monitors network traffic and bandwidth usage in real time. It visualizes the in- and outgoing traffic using two graphs and provides additional info like the total amount of transfered data and min\/max network usage.","Process Name":"nload","Link":"https:\/\/linux.die.net\/man\/1\/nload"}},{"Process":{"Description":"clogin is an expect(1) script to automate the process of logging into a Cisco router, catalyst switch, Extreme switch, Juniper ERX\/E-series, Procket Networks, or Redback router. There are complementary scripts for Alteon, Avocent (Cyclades), Bay Networks (nortel), ADC-kentrox EZ-T3 mux, Foundry, HP Procurve Switches and Cisco AGMs, Hitachi Routers, Juniper Networks, MRV optical switch, Netscreen firewalls, Netscaler, Riverstone, Netopia, and Lucent TNT, named alogin, avologin, blogin, elogin, flogin, fnlogin, hlogin, htlogin, jlogin, mrvlogin, nlogin, nslogin, rivlogin, tlogin, and tntlogin, respectively. clogin reads the .cloginrc file for its configuration, then connects and logs into each of the routers specified on the command line in the order listed. Command-line options exist to override some of the directives found in the .cloginrc configuration file. The command-line options are as follows: -S Save the configuration on exit, if the device prompts at logout time. This only has affect when used with -s. -V Prints package name and version strings. -c Command to be run on each router list on the command-line. Multiple commands maybe listed by separating them with semi-colons (;). The argument should be quoted to avoid shell expansion. -d Enable expect debugging. -E Specifies a variable to pass through to scripts (-s). For example, the command-line option -Efoo=bar will produce a global variable by the name Efoo with the initial value \"bar\". -e Specify a password to be supplied when gaining enable privileges on the router(s). Also see the password directive of the .cloginrc file. -f Specifies an alternate configuration file. The default is $HOME\/.cloginrc. -p Specifies a password associated with the user specified by the -u option, user directive of the .cloginrc file, or the Unix username of the user. -s The filename of an expect(1) script which will be sourced after the login is successful and is expected to return control to clogin, with the connection to the router intact, when it is done. Note that clogin disables log_user of expect(1)when -s is used. Example script(s) can be found in share\/rancid\/*.exp. -t Alters the timeout interval; the period that clogin waits for an individual command to return a prompt or the login process to produce a prompt or failure. The argument is in seconds. -u Specifies the username used when prompted. The command-line option overrides any user directive found in .cloginrc. The default is the current Unix username. -v Specifies a vty password, that which is prompted for upon connection to the router. This overrides the vty password of the .cloginrc file's password directive. -w Specifies the username used if prompted when gaining enable privileges. The command-line option overrides any user or enauser directives found in .cloginrc. The default is the current Unix username. -x Similar to the -c option; -x specifies a file with commands to run on each of the routers. The commands must not expect additional input, such as 'copy rcp startup-config' does. For example: show version\nshow logging -y Specifies the encryption algorithm for use with the ssh(1) -c option. The default encryption type is often not supported. See the ssh(1) man page for details. The default is 3des.","Process Name":"nlogin","Link":"https:\/\/linux.die.net\/man\/1\/nlogin"}},{"Process":{"Description":"GNU nm lists the symbols from object files objfile.... If no object files are listed as arguments, nm assumes the file a.out. For each symbol, nm shows: \u2022 The symbol value, in the radix selected by options (see below), or hexadecimal by default. \u2022 The symbol type. At least the following types are used; others are, as well, depending on the object file format. If lowercase, the symbol is local; if uppercase, the symbol is global (external). \"A\" The symbol's value is absolute, and will not be changed by further linking. \"B\" \"b\" The symbol is in the uninitialized data section (known as BSS ). \"C\" The symbol is common. Common symbols are uninitialized data. When linking, multiple common symbols may appear with the same name. If the symbol is defined anywhere, the common symbols are treated as undefined references. \"D\" \"d\" The symbol is in the initialized data section. \"G\" \"g\" The symbol is in an initialized data section for small objects. Some object file formats permit more efficient access to small data objects, such as a global int variable as opposed to a large global array. \"i\" For PE format files this indicates that the symbol is in a section specific to the implementation of DLLs. For ELF format files this indicates that the symbol is an indirect function. This is a GNU extension to the standard set of ELF symbol types. It indicates a symbol which if referenced by a relocation does not evaluate to its address, but instead must be invoked at runtime. The runtime execution will then return the value to be used in the relocation. \"N\" The symbol is a debugging symbol. \"p\" The symbols is in a stack unwind section. \"R\" \"r\" The symbol is in a read only data section. \"S\" \"s\" The symbol is in an uninitialized data section for small objects. \"T\" \"t\" The symbol is in the text (code) section. \"U\" The symbol is undefined. \"u\" The symbol is a unique global symbol. This is a GNU extension to the standard set of ELF symbol bindings. For such a symbol the dynamic linker will make sure that in the entire process there is just one symbol with this name and type in use. \"V\" \"v\" The symbol is a weak object. When a weak defined symbol is linked with a normal defined symbol, the normal defined symbol is used with no error. When a weak undefined symbol is linked and the symbol is not defined, the value of the weak symbol becomes zero with no error. On some systems, uppercase indicates that a default value has been specified. \"W\" \"w\" The symbol is a weak symbol that has not been specifically tagged as a weak object symbol. When a weak defined symbol is linked with a normal defined symbol, the normal defined symbol is used with no error. When a weak undefined symbol is linked and the symbol is not defined, the value of the symbol is determined in a system-specific manner without error. On some systems, uppercase indicates that a default value has been specified. \"-\" The symbol is a stabs symbol in an a.out object file. In this case, the next values printed are the stabs other field, the stabs desc field, and the stab type. Stabs symbols are used to hold debugging information. \"?\" The symbol type is unknown, or object file format specific. \u2022 The symbol name.","Process Name":"nm","Link":"https:\/\/linux.die.net\/man\/1\/nm"}},{"Process":{"Description":"nm-online is a utility to find out whether we are online. It is done by asking NetworkManager about its status. When run, nm-online waits until NetworkManager reports an active connection, or specified timeout expires. On exit, the returned status code should be checked (see the return codes bellow).","Process Name":"nm-online","Link":"https:\/\/linux.die.net\/man\/1\/nm-online"}},{"Process":{"Description":"The nm-tool utility provides information about NetworkManager, device, and wireless networks.","Process Name":"nm-tool","Link":"https:\/\/linux.die.net\/man\/1\/nm-tool"}},{"Process":{"Description":"Nmap (\"Network Mapper\") is an open source tool for network exploration and security auditing. It was designed to rapidly scan large networks, although it works fine against single hosts. Nmap uses raw IP packets in novel ways to determine what hosts are available on the network, what services (application name and version) those hosts are offering, what operating systems (and OS versions) they are running, what type of packet filters\/firewalls are in use, and dozens of other characteristics. While Nmap is commonly used for security audits, many systems and network administrators find it useful for routine tasks such as network inventory, managing service upgrade schedules, and monitoring host or service uptime. The output from Nmap is a list of scanned targets, with supplemental information on each depending on the options used. Key among that information is the \"interesting ports table\".. That table lists the port number and protocol, service name, and state. The state is either open, filtered, closed, or unfiltered. Open. means that an application on the target machine is listening for connections\/packets on that port. Filtered. means that a firewall, filter, or other network obstacle is blocking the port so that Nmap cannot tell whether it is open or closed. Closed. ports have no application listening on them, though they could open up at any time. Ports are classified as unfiltered. when they are responsive to Nmap's probes, but Nmap cannot determine whether they are open or closed. Nmap reports the state combinations open|filtered. and closed|filtered. when it cannot determine which of the two states describe a port. The port table may also include software version details when version detection has been requested. When an IP protocol scan is requested (-sO), Nmap provides information on supported IP protocols rather than listening ports. In addition to the interesting ports table, Nmap can provide further information on targets, including reverse DNS names, operating system guesses, device types, and MAC addresses. A typical Nmap scan is shown in Example 1. The only Nmap arguments used in this example are -A, to enable OS and version detection, script scanning, and traceroute; -T4 for faster execution; and then the two target hostnames. Example 1. A representative Nmap scan # nmap -A -T4 scanme.nmap.org\n\nNmap scan report for scanme.nmap.org (64.13.134.52)\nHost is up (0.045s latency).\nNot shown: 993 filtered ports\nPORT      STATE  SERVICE VERSION\n22\/tcp    open   ssh     OpenSSH 4.3 (protocol 2.0)\n| ssh-hostkey: 1024 60:ac:4d:51:b1:cd:85:09:12:16:92:76:1d:5d:27:6e (DSA)\n|_2048 2c:22:75:60:4b:c3:3b:18:a2:97:2c:96:7e:28:dc:dd (RSA)\n25\/tcp    closed smtp\n53\/tcp    open   domain\n70\/tcp    closed gopher\n80\/tcp    open   http    Apache httpd 2.2.3 ((CentOS))\n|_html-title: Go ahead and ScanMe!\n| http-methods: Potentially risky methods: TRACE\n|_See http:\/\/nmap.org\/nsedoc\/scripts\/http-methods.html\n113\/tcp   closed auth\n31337\/tcp closed Elite\nDevice type: general purpose\nRunning: Linux 2.6.X\nOS details: Linux 2.6.13 - 2.6.31, Linux 2.6.18\nNetwork Distance: 13 hops\n\nTRACEROUTE (using port 80\/tcp)\nHOP RTT       ADDRESS\n[Cut first 10 hops for brevity]\n11  80.33 ms  layer42.car2.sanjose2.level3.net (4.59.4.78)\n12  137.52 ms xe6-2.core1.svk.layer42.net (69.36.239.221)\n13  44.15 ms  scanme.nmap.org (64.13.134.52)\n\nNmap done: 1 IP address (1 host up) scanned in 22.19 seconds The newest version of Nmap can be obtained from http:\/\/nmap.org . The newest version of this man page is available at http:\/\/nmap.org\/book\/man.html . It is also included as a chapter of Nmap Network Scanning: The Official Nmap Project Guide to Network Discovery and Security Scanning (see http:\/\/nmap.org\/book\/ ).","Process Name":"nmap","Link":"https:\/\/linux.die.net\/man\/1\/nmap"}},{"Process":{"Description":"Zenmap is a multi-platform graphical Nmap frontend and results viewer. Zenmap aims to make Nmap easy for beginners to use while giving experienced Nmap users advanced features. Frequently used scans can be saved as profiles to make them easy to run repeatedly. A command creator allows interactive creation of Nmap command lines. Scan results can be saved and viewed later. Saved scan results can be compared with one another to see how they differ. The results of recent scans are stored in a searchable database. This man page only describes the few Zenmap command-line options and some critical notes. A much more detailed Zenmap User's Guide is available at http:\/\/nmap.org\/book\/zenmap.html. Other documentation and information is available from the Zenmap web page at http:\/\/nmap.org\/zenmap\/.","Process Name":"nmapfe","Link":"https:\/\/linux.die.net\/man\/1\/nmapfe"}},{"Process":{"Description":"This tool is part of the samba(7) suite. nmblookup is used to query NetBIOS names and map them to IP addresses in a network using NetBIOS over TCP\/IP queries. The options allow the name queries to be directed at a particular IP broadcast area or to a particular machine. All queries are done over UDP.","Process Name":"nmblookup","Link":"https:\/\/linux.die.net\/man\/1\/nmblookup"}},{"Process":{"Description":"This tool is part of the samba(7) suite. nmblookup4 is used to query NetBIOS names and map them to IP addresses in a network using NetBIOS over TCP\/IP queries. The options allow the name queries to be directed at a particular IP broadcast area or to a particular machine. All queries are done over UDP.","Process Name":"nmblookup4","Link":"https:\/\/linux.die.net\/man\/1\/nmblookup4"}},{"Process":{"Description":"nmcli is a command-line tool for controlling NetworkManager and getting its status. It is not meant as a replacement of nm-applet or other similar clients. Rather it's a complementary utility to these programs. The main nmcli's usage is on servers, headless machines or just for power users who prefer the command line. The use cases comprise: - Initscripts: ifup\/ifdown can utilize NetworkManager via nmcli instead of having to manage connections itself and possible interfere with NetworkManager. - Servers, headless machines: No GUI is available; then nmcli is used to talk directly to NetworkManager and control only system-wide connections. - User sessions: For this case, nmcli can talk to nm-applet to find user connections. It can still talk directly to NetworkManager for manipulating these connections. As nmcli doesn't have direct access to user configuration data in GConf, nm-applet handles that itself. That may, for example, cause the applet to pop up keyring dialogs when secrets are needed. OPTIONS -t, --terse Output is terse. This mode is designed and suitable for computer (script) processing. -p, --pretty Output is pretty. This causes nmcli to produce easy readable outputs for humans, i.e. values are aligned, headers are printed, etc. -m, --mode tabular | multiline Switch between tabular and multiline output. If omitted, default is tabular for most commands. For the commands producing more structured information, that cannot be displayed on a single line, default is multiline. Currenly, they are: 'nmcli con list id|uuid <name>'\n'nmcli dev list' tabular - Output is a table where each line describes a single entry. Columns define particular properties of the entry. multiline - Each entry comprises more lines, each property on its own line. The values are prefixed with the property name. -f, --fields <field1,field2,...> | all | common This option is used to specify what fields (column names) should be printed. Valid field names differ for specific commands. List available fields by providing an invalid value to the --fields option. all is used to print all valid field values of the command. common is used to print common field values of the command. If omitted, default is common. The option is mandatory when --terse is used. In this case, generic values all and common cannot be used. (This is to maintain compatibility when new fields are added in the future). -e, --escape yes | no Whether to escape ':' and '\\' characters in terse tabular mode. The escape character is '\\'. If omitted, default is yes. -v, --version Show nmcli version. -h, --help Print help information. OBJECT nm NetworkManager Use this object to inquire and change state of NetworkManager. COMMAND := { status | sleep | wakeup | wifi | wwan } status Show overall status of NetworkManager. This is the default action, when no command is provided to nm object. Reference to D-Bus:\nNo simple reference. sleep Put NetworkManager to sleeping mode. Thus all interfaces that NetworkManager manages are deactivated. Reference to D-Bus:\ninterface: org.freedesktop.NetworkManager\nmethod:    Sleep\narguments: TRUE wakeup Awake NetworkManager from sleep. When NetworkManager is awaken, devices are available to be activated. Reference to D-Bus:\ninterface: org.freedesktop.NetworkManager\nmethod:    Sleep\narguments: FALSE wifi [on|off] Inquire or set status of WiFi in NetworkManager. Without any further argument, WiFi status is printed; on enables WiFi; off disables WiFi. Reference to D-Bus:\nNo simple reference. wwan [on|off] Inquire or set status of WWAN in NetworkManager. Without any further argument, WWAN status is printed; on enables WWAN; off disables WWAN. Reference to D-Bus:\nNo simple reference. con Connections Get information about NetworkManager's connections. COMMAND := { list | status | up | down } list [id <id> | uuid <id> | system | user] List configured connections. Without a parameter, configured connection from both system and user settings services are listed. system argument filters only system-wide connections, user prints user connections only. In order to get connection details, id with connection's name or uuid with connection's UUID shall be specified. When no command is given to con object, the default action is 'nmcli con list'. Reference to D-Bus:\nNo simple reference. status Print status of active connections. Reference to D-Bus:\nNo simple reference. up id <id> | uuid <id> [iface <iface>] [ap <hwaddr>] [--nowait] [--timeout <timeout>] Activate a connection. The connection is identified by its name using id or UUID using uuid. For requiring particular device to activate the connection on, iface option with interface name should be given. ap option can further concretize what AP should be used in case of WiFi connection. --nowait option causes nmcli to exit immediately and not to wait for command completion. --timeout option provides a means to specify how long to wait for operation completion. Reference to D-Bus:\ninterface: org.freedesktop.NetworkManager\nmethod:    ActivateConnection\narguments: according to arguments down id <id> | uuid <id> Deactivate a connection. The connection is identified by its name using id or UUID using uuid. Reference to D-Bus:\ninterface: org.freedesktop.NetworkManager\nmethod:    DeactivateConnection\narguments: according to arguments dev Devices Get information about devices. COMMAND := { status | list | disconnect | wifi } status Print status of devices. This is the default action, when no command is specified to dev object. Reference to D-Bus:\nNo simple reference. list [iface <iface>] Get detailed information about devices. Without an argument, all devices are examined. To get information for a specific device, iface argument with the interface name should be provided. Reference to D-Bus:\nNo simple reference. disconnect iface <iface> [--nowait] [--timeout <timeout>] Disconnect a device and prevent the device from automatically activating further connections without user\/manual intervention. --nowait option causes nmcli to exit immediately and not to wait for command completion. --timeout option provides a means to specify how long to wait for operation completion. Reference to D-Bus:\ninterface: org.freedesktop.NetworkManager.Device\nmethod:    Disconnect\narguments: none wifi [list [iface <iface>] [hwaddr <hwaddr>]] List available WiFi access points. iface and hwaddr options can be used to get just APs for particular interface or specific AP, respectively. Reference to D-Bus:\nNo simple reference.","Process Name":"nmcli","Link":"https:\/\/linux.die.net\/man\/1\/nmcli"}},{"Process":{"Description":"Nntpget connects to the NNTP server at the specified host and retrieves articles from it. The Message-ID's of the desired articles are read from standard input. The articles are sent to standard output.","Process Name":"nntpget","Link":"https:\/\/linux.die.net\/man\/1\/nntpget"}},{"Process":{"Description":"nntptest is a utility that allows you to authenticate to a NNTP server and interactively issue commands to it. Once authenticated you may issue any NNTP command by simply typing it in. It is capable of multiple SASL authentication mechanisms and handles encryption layers transparently. This utility is often used for testing the operation of a nntp server. Also those developing NNTP clients find it useful.","Process Name":"nntptest","Link":"https:\/\/linux.die.net\/man\/1\/nntptest"}},{"Process":{"Description":"When invoked with the -q , -c , -n , or -s arguments, nodeattr reads the genders file and outputs a list of nodes that match the specified query. The nodes are listed in hostlist format, comma separated lists, newline separated lists, or space separated lists respectively. Genders queries will query the genders database for a set of nodes based on the union, intersection, difference, or complement of genders attributes and values. The set operation union is represented by two pipe symbols ('||'), intersection by two ampersand symbols ('&&'), difference by two minus symbols ('--'), and complement by a tilde ('~'). Parentheses may be used to change the order of operations. The -X argument and query can be used to exclude nodes from the resulting output. A query can be replaced with the -A option to cause nodeattr to print all the nodes listed in the genders database. When called with a node name (optional) and attribute name, nodeattr returns 0 to the environment if the node has the attribute; else 1. If -v is present, the attribute name and any value (see below) is printed on the standard output. If a node name is not specified, the local host is assumed. When called with the -Q argument, nodeattr will check if the node name (optional) is met by the attribute and value conditions specified in the query. If the conditions are met, nodeattr returns 0 to the environment; else 1. The query format is identical to the format listed above. If a node name is not specified, the local host is assumed. The -V option causes nodeattr to print all of the values that exist for a particular attribute. Also specifing -U with -V causes nodeattr to print out only unique values for the particular attribute. The -l option causes nodeattr to print the attributes of the specified node. If no node is listed, all attributes in the genders file are listed. The -k option checks the genders file for parse errors and proper formatting. If errors are found, information about the error will be output to standard error. Nodeattr will always check the default genders file, but a different genders file can be specified with the -f option. The -d option allows the specified genders database to be compared to the filename indicated by the -f option or the default genders database. The differences contained in the specified database will be output to standard error. The --expand option will take a genders database, expand all hostranges, and output a new genders database. The subsequent database will be identical to the first, but every node will be listed on a separate line. This option may be useful for debugging or determining the difference between databases. The --compress is opposite of the --expand option. It will output a new identical genders database with hostranges of nodes with identical attributes. Depending on the setup of your genders database, the resulting database may be longer or shorter. This option may be useful as a beginning step to compressing an existing genders database. Attribute names may optionally appear in the genders file with an equal sign followed by a value. Nodeattr ignores these values except when the -v option requests that the value, if any, be displayed; and when an attribute is specified on the command line with a value, in which case only an attribute with the specified value in the genders file will match.","Process Name":"nodeattr","Link":"https:\/\/linux.die.net\/man\/1\/nodeattr"}},{"Process":{"Description":"This little script reads in a Fido named nodelist. XXX and optionally a Fido point list named points24. YYY and generates a list with the lbdb format: <mailaddress> TAB <realname> TAB <comment> This file is written to $HOME\/.lbdb\/nodelist","Process Name":"nodelist2lbdb","Link":"https:\/\/linux.die.net\/man\/1\/nodelist2lbdb"}},{"Process":{"Description":"nodeset is an utility command provided with the ClusterShell library which implements some features of ClusterShell's NodeSet and RangeSet Python classes. It provides easy manipulation of indexed cluster nodes and node groups. It is automatically bound to the library node group resolution mechanism. Thus, nodeset is especially useful to enhance cluster aware administration shell scripts.","Process Name":"nodeset","Link":"https:\/\/linux.die.net\/man\/1\/nodeset"}},{"Process":{"Description":"this plugin is to suppress documentation : man pages and package doc","Process Name":"nodoc.plug","Link":"https:\/\/linux.die.net\/man\/1\/nodoc.plug"}},{"Process":{"Description":"noexec is a runner for invoke a program, which will be unable to create any child process.","Process Name":"noexec","Link":"https:\/\/linux.die.net\/man\/1\/noexec"}},{"Process":{"Description":"Run COMMAND, ignoring hangup signals. --help display this help and exit --version output version information and exit If standard input is a terminal, redirect it from \/dev\/null. If standard output is a terminal, append output to 'nohup.out' if possible, '$HOME\/nohup.out' otherwise. If standard error is a terminal, redirect it to standard output. To save output to FILE, use 'nohup COMMAND > FILE'. NOTE: your shell may have its own version of nohup, which usually supersedes the version described here. Please refer to your shell's documentation for details about the options it supports.","Process Name":"nohup","Link":"https:\/\/linux.die.net\/man\/1\/nohup"}},{"Process":{"Description":"nomarch lists, extracts, or tests '.arc' archives. (An alternate extension sometimes used was '.ark'; these work too.) This is a very outdated file format which should certainly not be used for anything new, but you may still need an extraction utility, and here it is. :-) The default action is to extract all files in the specified archive; see OPTIONS below for how to do other things instead.","Process Name":"nomarch","Link":"https:\/\/linux.die.net\/man\/1\/nomarch"}},{"Process":{"Description":"This script will list all files and directories in the module(s) that are not listed in the CVS\/Entries files. These may be files created during builds, new un-added sources files etc. It is a useful housekeeping tool.","Process Name":"noncvslist","Link":"https:\/\/linux.die.net\/man\/1\/noncvslist"}},{"Process":{"Description":"Draws some rotatey patterns, using OpenGL.","Process Name":"noof","Link":"https:\/\/linux.die.net\/man\/1\/noof"}},{"Process":{"Description":"nop reads a stream of graphs and prints each in pretty-printed (canonical) format on stdout. If no files are given, it reads from stdin.","Process Name":"nop","Link":"https:\/\/linux.die.net\/man\/1\/nop"}},{"Process":{"Description":"Nose is a geomview module which tests the geomview picking facility. Nose has no panel of its own. You invoke it by selecting the \"Nose\" line in the APPLICATIONS browser. Once invoked, nose waits for you to click the right mouse button with the cursor over some object in a geomview camera window. It then draws a little box on the spot where you clicked. If the picked spot is along an edge, it also draws a pair of boxes at the endpoints of the edge, and a line segment along the edge. If the picked spot is on a vertex, the box is a different color. Nose is not necessarily intended to be a useful program. It is just a simple example of how an external program can find out about and make use of geomview pick events.","Process Name":"nose","Link":"https:\/\/linux.die.net\/man\/1\/nose"}},{"Process":{"Description":"A little man with a big nose and a hat runs around spewing out messages to the screen. This code (and its bitmaps) were extracted from the xnlock program.","Process Name":"noseguy","Link":"https:\/\/linux.die.net\/man\/1\/noseguy"}},{"Process":{"Description":"nose provides extended test discovery and running features for unittest. nose collects tests automatically from python source files, directories and packages found in its working directory (which defaults to the current working directory). Any python source file, directory or package that matches the testMatch regular expression (by default: (?:^|[\\b_\\.-])[Tt]est) will be collected as a test (or source for collection of tests). In addition, all other packages found in the working directory will be examined for python source files or directories that match testMatch. Package discovery descends all the way down the tree, so package.tests and package.sub.tests and package.sub.sub2.tests will all be collected. Within a test directory or package, any python source file matching testMatch will be examined for test cases. Within a test module, functions and classes whose names match testMatch and TestCase subclasses with any name will be loaded and executed as tests. Tests may use the assert keyword or raise AssertionErrors to indicate test failure. TestCase subclasses may do the same or use the various TestCase methods available. Selecting Tests To specify which tests to run, pass test names on the command line: nosetests only_test_this.py Test names specified may be file or module names, and may optionally indicate the test case to run by separating the module or file name from the test case name with a colon. Filenames may be relative or absolute. Examples: nosetests test.module nosetests another.test:TestCase.test_method nosetests a.test:TestCase nosetests \/path\/to\/test\/file.py:test_function You may also change the working directory where nose looks for tests, use the -w switch: nosetests -w \/path\/to\/tests Note however that support for multiple -w arguments is deprecated in this version and will be removed in a future release, since as of nose 0.10 you can get the same behavior by specifying the target directories *without* the -w switch: nosetests \/path\/to\/tests \/another\/path\/to\/tests Further customization of test selection and loading is possible through the use of plugins. Test result output is identical to that of unittest, except for the additional features (error classes, and plugin-supplied features such as output capture and assert introspection) detailed in the options below. Configuration In addition to passing command-line options, you may also put configuration options in a .noserc or nose.cfg file in your home directory. These are standard .ini-style config files. Put your nosetests configuration in a [nosetests] section, with the -- prefix removed: [nosetests] verbosity=3 with-doctest=1 All configuration files that are found will be loaded and their options combined. options: -h, --help show this help message and exit -V, --version Output nose version and exit -p, --plugins Output list of available plugins and exit. Combine with higher verbosity for greater detail -v, --verbose Be more verbose. [NOSE_VERBOSE] --verbosity= VERBOSITY Set verbosity; --verbosity= 2 is the same as -v -q, --quiet -c FILES, --config= FILES Load configuration from config file(s). May be specified multiple times; in that case, all config files will be loaded and combined -w WHERE, --where= WHERE Look for tests in this directory. May be specified multiple times. The first directory passed will be used as the working directory, in place of the current working directory, which is the default. Others will be added to the list of tests to execute. [NOSE_WHERE] -m TESTMATCH, --match= TESTMATCH, --testmatch= TESTMATCH Use this regular expression to find tests [NOSE_TESTMATCH] --tests= TESTNAMES Run these tests (comma-separated list). This argument is useful mainly from configuration files; on the command line, just pass the tests to run as additional arguments with no switch. -l DEBUG, --debug= DEBUG Activate debug logging for one or more systems. Available debug loggers: nose, nose.importer, nose.inspector, nose.plugins, nose.result and nose.selector. Separate multiple names with a comma. --debug-log= DEBUGLOG Log debug messages to this file (default: sys.stderr) --logging-config= LOGGINGCONFIG, --log-config= LOGGINGCONFIG Load logging config from this file -- bypasses all other logging config settings. -e EXCLUDE, --exclude= EXCLUDE Don't run tests that match regular expression [NOSE_EXCLUDE] -i INCLUDE, --include= INCLUDE Also run tests that match regular expression [NOSE_INCLUDE] -x, --stop Stop running tests after the first error or failure -P, --no-path-adjustment Don't make any changes to sys.path when loading tests [NOSE_NOPATH] --exe Look for tests in python modules that are executable. Normal behavior is to exclude executable modules, since they may not be import-safe [NOSE_INCLUDE_EXE] --noexe DO NOT look for tests in python modules that are executable. (The default on the windows platform is to do so.) --with-html-output Enable plugin HtmlOutput: Output test results as ugly, unstyled html. [NOSE_WITH_HTML-OUTPUT] --with-watch Enable plugin NoseWatch: watch failing tests, retesting when modified [NOSE_WITH_WATCH] --with-stopwatch Enable plugin Stopwatch: (no help available) [NOSE_WITH_STOPWATCH] --faster-than= FASTER_THAN Run only tests that are faster than FASTER_THAN seconds. --stopwatch-file= STOPWATCH_FILE Store test timing results in this file. --with-figleafsections Enable plugin FigleafSections: (no help available) [NOSE_WITH_FIGLEAFSECTIONS] --figleaf-file= FIGLEAF_FILE Store figleaf section coverage in this file --decorator-file= DECORATOR_FILE Apply attributes in this file to matching functions, classes, and methods --with-tty Enable plugin NoseTTY: run nosetests more interactively [NOSE_WITH_TTY] --tty Enable plugin NoseTTY: run nosetests more interactively [NOSE_TTY] --tty-editor= NOSE_TTY_EDITOR editor program [NOSE_TTY_EDITOR or EDITOR] (currently: 'None') --tty-edit-cmd= NOSE_TTY_EDIT_CMD template to invoke edit command. [NOSE_TTY_EDIT_CMD] (currently: '%(editor)s %(filename)s --line %(lineno)s') -a ATTR, --attr= ATTR Run only tests that have attributes specified by ATTR [NOSE_ATTR] -A EXPR, --eval-attr= EXPR Run only tests for whose attributes the Python expression EXPR evaluates to True [NOSE_EVAL_ATTR] -s, --nocapture Don't capture stdout (any stdout output will be printed immediately) [NOSE_NOCAPTURE] --with-coverage Enable plugin Coverage: If you have Ned Batchelder's coverage module installed, you may activate a coverage report. The coverage report will cover any python source module imported after the start of the test run, excluding modules that match testMatch. If you want to include those modules too, use the --covertests switch, or set the NOSE_COVER_TESTS environment variable to a true value. To restrict the coverage report to modules from a particular package or packages, use the --cover-packages switch or the NOSE_COVER_PACKAGES environment variable. [NOSE_WITH_COVERAGE] --cover-package= COVER_PACKAGES Restrict coverage output to selected packages [NOSE_COVER_PACKAGE] --cover-erase Erase previously collected coverage statistics before run --cover-tests Include test modules in coverage report [NOSE_COVER_TESTS] --cover-inclusive Include all python files under working directory in coverage report. Useful for discovering holes in test coverage if not all files are imported by the test suite. [NOSE_COVER_INCLUSIVE] --pdb Drop into debugger on errors --pdb-failures Drop into debugger on failures --no-deprecated Disable special handling of DeprecatedTest exceptions. --with-doctest Enable plugin Doctest: Activate doctest plugin to find and run doctests in non-test modules. [NOSE_WITH_DOCTEST] --doctest-tests Also look for doctests in test modules [NOSE_DOCTEST_TESTS] --doctest-extension= DOCTESTEXTENSION Also look for doctests in files with this extension [NOSE_DOCTEST_EXTENSION] --with-isolation Enable plugin IsolationPlugin: Activate the isolation plugin to isolate changes to external modules to a single test module or package. The isolation plugin resets the contents of sys.modules after each test module or package runs to its state before the test. PLEASE NOTE that this plugin should not be used with the coverage plugin in any other case where module reloading may produce undesirable side-effects. [NOSE_WITH_ISOLATION] -d, --detailed-errors, --failure-detail Add detail to error output by attempting to evaluate failed asserts [NOSE_DETAILED_ERRORS] --with-profile Enable plugin Profile: Use this plugin to run tests using the hotshot profiler. [NOSE_WITH_PROFILE] --profile-sort= PROFILE_SORT Set sort order for profiler output --profile-stats-file= PROFILE_STATS_FILE Profiler stats file; default is a new temp file on each run --profile-restrict= PROFILE_RESTRICT Restrict profiler output. See help for pstats.Stats for details --no-skip Disable special handling of SkipTest exceptions. --with-id Enable plugin TestId: Activate to add a test id (like #1) to each test name output. After you've run once to generate test ids, you can re-run individual tests by activating the plugin and passing the ids (with or without the # prefix) instead of test names. [NOSE_WITH_ID] --id-file= TESTIDFILE Store test ids found in test runs in this file.","Process Name":"nosetests","Link":"https:\/\/linux.die.net\/man\/1\/nosetests"}},{"Process":{"Description":"nose collects tests automatically from python source files, directories and packages found in its working directory (which defaults to the current working directory). Any python source file, directory or package that matches the testMatch regular expression (by default: (?:^|[b_.-])[Tt]est) will be collected as a test (or source for collection of tests). In addition, all other packages found in the working directory will be examined for python source files or directories that match testMatch. Package discovery descends all the way down the tree, so package.tests and package.sub.tests and package.sub.sub2.tests will all be collected. Within a test directory or package, any python source file matching testMatch will be examined for test cases. Within a test module, functions and classes whose names match testMatch and TestCase subclasses with any name will be loaded and executed as tests. Tests may use the assert keyword or raise AssertionErrors to indicate test failure. TestCase subclasses may do the same or use the various TestCase methods available. Selecting Tests To specify which tests to run, pass test names on the command line: nosetests only_test_this.py Test names specified may be file or module names, and may optionally indicate the test case to run by separating the module or file name from the test case name with a colon. Filenames may be relative or absolute. Examples: nosetests test.module\nnosetests another.test:TestCase.test_method\nnosetests a.test:TestCase\nnosetests \/path\/to\/test\/file.py:test_function You may also change the working directory where nose looks for tests by using the -w switch: nosetests -w \/path\/to\/tests Note, however, that support for multiple -w arguments is now deprecated and will be removed in a future release. As of nose 0.10, you can get the same behavior by specifying the target directories without the -w switch: nosetests \/path\/to\/tests \/another\/path\/to\/tests Further customization of test selection and loading is possible through the use of plugins. Test result output is identical to that of unittest, except for the additional features (error classes, and plugin-supplied features such as output capture and assert introspection) detailed in the options below. Configuration In addition to passing command-line options, you may also put configuration options in your project's setup.cfg file, or a .noserc or nose.cfg file in your home directory. In any of these standard .ini-style config files, you put your nosetests configuration in a [nosetests] section. Options are the same as on the command line, with the -- prefix removed. For options that are simple switches, you must supply a value: [nosetests]\nverbosity=3\nwith-doctest=1 All configuration files that are found will be loaded and their options combined. You can override the standard config file loading with the -c option. Using Plugins There are numerous nose plugins available via easy_install and elsewhere. To use a plugin, just install it. The plugin will add command line options to nosetests. To verify that the plugin is installed, run: nosetests --plugins You can add -v or -vv to that command to show more information about each plugin. If you are running nose.main() or nose.run() from a script, you can specify a list of plugins to use by passing a list of plugins with the plugins keyword argument. 0.9 plugins nose 1.0 can use SOME plugins that were written for nose 0.9. The default plugin manager inserts a compatibility wrapper around 0.9 plugins that adapts the changed plugin api calls. However, plugins that access nose internals are likely to fail, especially if they attempt to access test case or test suite classes. For example, plugins that try to determine if a test passed to startTest is an individual test or a suite will fail, partly because suites are no longer passed to startTest and partly because it's likely that the plugin is trying to find out if the test is an instance of a class that no longer exists. 0.10 and 0.11 plugins All plugins written for nose 0.10 and 0.11 should work with nose 1.0. Options -V, --version Output nose version and exit -p, --plugins Output list of available plugins and exit. Combine with higher verbosity for greater detail -v=DEFAULT, --verbose=DEFAULT Be more verbose. [NOSE_VERBOSE] --verbosity=VERBOSITY Set verbosity; --verbosity=2 is the same as -v -q=DEFAULT, --quiet=DEFAULT Be less verbose -c=FILES, --config=FILES Load configuration from config file(s). May be specified multiple times; in that case, all config files will be loaded and combined -w=WHERE, --where=WHERE Look for tests in this directory. May be specified multiple times. The first directory passed will be used as the working directory, in place of the current working directory, which is the default. Others will be added to the list of tests to execute. [NOSE_WHERE] --py3where=PY3WHERE Look for tests in this directory under Python 3.x. Functions the same as 'where', but only applies if running under Python 3.x or above. Note that, if present under 3.x, this option completely replaces any directories specified with 'where', so the 'where' option becomes ineffective. [NOSE_PY3WHERE] -m=REGEX, --match=REGEX, --testmatch=REGEX Files, directories, function names, and class names that match this regular expression are considered tests. Default: (?:^|[b_.\/-])[Tt]est [NOSE_TESTMATCH] --tests=NAMES Run these tests (comma-separated list). This argument is useful mainly from configuration files; on the command line, just pass the tests to run as additional arguments with no switch. -l=DEFAULT, --debug=DEFAULT Activate debug logging for one or more systems. Available debug loggers: nose, nose.importer, nose.inspector, nose.plugins, nose.result and nose.selector. Separate multiple names with a comma. --debug-log=FILE Log debug messages to this file (default: sys.stderr) --logging-config=FILE, --log-config=FILE Load logging config from this file -- bypasses all other logging config settings. -I=REGEX, --ignore-files=REGEX Completely ignore any file that matches this regular expression. Takes precedence over any other settings or plugins. Specifying this option will replace the default setting. Specify this option multiple times to add more regular expressions [NOSE_IGNORE_FILES] -e=REGEX, --exclude=REGEX Don't run tests that match regular expression [NOSE_EXCLUDE] -i=REGEX, --include=REGEX This regular expression will be applied to files, directories, function names, and class names for a chance to include additional tests that do not match TESTMATCH. Specify this option multiple times to add more regular expressions [NOSE_INCLUDE] -x, --stop Stop running tests after the first error or failure -P, --no-path-adjustment Don't make any changes to sys.path when loading tests [NOSE_NOPATH] --exe Look for tests in python modules that are executable. Normal behavior is to exclude executable modules, since they may not be import-safe [NOSE_INCLUDE_EXE] --noexe DO NOT look for tests in python modules that are executable. (The default on the windows platform is to do so.) --traverse-namespace Traverse through all path entries of a namespace package --first-package-wins, --first-pkg-wins, --1st-pkg-wins nose's importer will normally evict a package from sys.modules if it sees a package with the same name in a different location. Set this option to disable that behavior. -a=ATTR, --attr=ATTR Run only tests that have attributes specified by ATTR [NOSE_ATTR] -A=EXPR, --eval-attr=EXPR Run only tests for whose attributes the Python expression EXPR evaluates to True [NOSE_EVAL_ATTR] -s, --nocapture Don't capture stdout (any stdout output will be printed immediately) [NOSE_NOCAPTURE] --nologcapture Disable logging capture plugin. Logging configurtion will be left intact. [NOSE_NOLOGCAPTURE] --logging-format=FORMAT Specify custom format to print statements. Uses the same format as used by standard logging handlers. [NOSE_LOGFORMAT] --logging-datefmt=FORMAT Specify custom date\/time format to print statements. Uses the same format as used by standard logging handlers. [NOSE_LOGDATEFMT] --logging-filter=FILTER Specify which statements to filter in\/out. By default, everything is captured. If the output is too verbose, use this option to filter out needless output. Example: filter=foo will capture statements issued ONLY to foo or foo.what.ever.sub but not foobar or other logger. Specify multiple loggers with comma: filter=foo,bar,baz. If any logger name is prefixed with a minus, eg filter=-foo, it will be excluded rather than included. Default: exclude logging messages from nose itself (-nose). [NOSE_LOGFILTER] --logging-clear-handlers Clear all other logging handlers --with-coverage Enable plugin Coverage: Activate a coverage report using Ned Batchelder's coverage module. [NOSE_WITH_COVERAGE] --cover-package=PACKAGE Restrict coverage output to selected packages [NOSE_COVER_PACKAGE] --cover-erase Erase previously collected coverage statistics before run --cover-tests Include test modules in coverage report [NOSE_COVER_TESTS] --cover-inclusive Include all python files under working directory in coverage report. Useful for discovering holes in test coverage if not all files are imported by the test suite. [NOSE_COVER_INCLUSIVE] --cover-html Produce HTML coverage information --cover-html-dir=DIR Produce HTML coverage information in dir --pdb Drop into debugger on errors --pdb-failures Drop into debugger on failures --no-deprecated Disable special handling of DeprecatedTest exceptions. --with-doctest Enable plugin Doctest: Activate doctest plugin to find and run doctests in non-test modules. [NOSE_WITH_DOCTEST] --doctest-tests Also look for doctests in test modules. Note that classes, methods and functions should have either doctests or non-doctest tests, not both. [NOSE_DOCTEST_TESTS] --doctest-extension=EXT Also look for doctests in files with this extension [NOSE_DOCTEST_EXTENSION] --doctest-result-variable=VAR Change the variable name set to the result of the last interpreter command from the default '_'. Can be used to avoid conflicts with the _() function used for text translation. [NOSE_DOCTEST_RESULT_VAR] --doctest-fixtures=SUFFIX Find fixtures for a doctest file in module with this name appended to the base name of the doctest file --with-isolation Enable plugin IsolationPlugin: Activate the isolation plugin to isolate changes to external modules to a single test module or package. The isolation plugin resets the contents of sys.modules after each test module or package runs to its state before the test. PLEASE NOTE that this plugin should not be used with the coverage plugin, or in any other case where module reloading may produce undesirable side-effects. [NOSE_WITH_ISOLATION] -d, --detailed-errors, --failure-detail Add detail to error output by attempting to evaluate failed asserts [NOSE_DETAILED_ERRORS] --with-profile Enable plugin Profile: Use this plugin to run tests using the hotshot profiler. [NOSE_WITH_PROFILE] --profile-sort=SORT Set sort order for profiler output --profile-stats-file=FILE Profiler stats file; default is a new temp file on each run --profile-restrict=RESTRICT Restrict profiler output. See help for pstats.Stats for details --no-skip Disable special handling of SkipTest exceptions. --with-id Enable plugin TestId: Activate to add a test id (like #1) to each test name output. Activate with --failed to rerun failing tests only. [NOSE_WITH_ID] --id-file=FILE Store test ids found in test runs in this file. Default is the file .noseids in the working directory. --failed Run the tests that failed in the last test run. --processes=NUM Spread test run among this many processes. Set a number equal to the number of processors or cores in your machine for best results. [NOSE_PROCESSES] --process-timeout=SECONDS Set timeout for return of results from each test runner process. [NOSE_PROCESS_TIMEOUT] --process-restartworker If set, will restart each worker process once their tests are done, this helps control memory leaks from killing the system. [NOSE_PROCESS_RESTARTWORKER] --with-xunit Enable plugin Xunit: This plugin provides test results in the standard XUnit XML format. [NOSE_WITH_XUNIT] --xunit-file=FILE Path to xml file to store the xunit report in. Default is nosetests.xml in the working directory [NOSE_XUNIT_FILE] --all-modules Enable plugin AllModules: Collect tests from all python modules. [NOSE_ALL_MODULES] --collect-only Enable collect-only: Collect and output test names only, don't run any tests. [COLLECT_ONLY]","Process Name":"nosetests1.1","Link":"https:\/\/linux.die.net\/man\/1\/nosetests1.1"}},{"Process":{"Description":"","Process Name":"not","Link":"https:\/\/linux.die.net\/man\/1\/not"}},{"Process":{"Description":"notepad is the Wine text editor, designed to be compatible with its Microsoft Windows counterpart. It supports ANSI, UTF-8 and UTF-16 files, and can read (but not write) files with Unix line endings.","Process Name":"notepad","Link":"https:\/\/linux.die.net\/man\/1\/notepad"}},{"Process":{"Description":"","Process Name":"nova-all","Link":"https:\/\/linux.die.net\/man\/1\/nova-all"}},{"Process":{"Description":"","Process Name":"nova-api","Link":"https:\/\/linux.die.net\/man\/1\/nova-api"}},{"Process":{"Description":"","Process Name":"nova-api-ec2","Link":"https:\/\/linux.die.net\/man\/1\/nova-api-ec2"}},{"Process":{"Description":"","Process Name":"nova-api-metadata","Link":"https:\/\/linux.die.net\/man\/1\/nova-api-metadata"}},{"Process":{"Description":"","Process Name":"nova-api-os-compute","Link":"https:\/\/linux.die.net\/man\/1\/nova-api-os-compute"}},{"Process":{"Description":"","Process Name":"nova-api-os-volume","Link":"https:\/\/linux.die.net\/man\/1\/nova-api-os-volume"}},{"Process":{"Description":"","Process Name":"nova-cert","Link":"https:\/\/linux.die.net\/man\/1\/nova-cert"}},{"Process":{"Description":null,"Process Name":"nova-compute","Link":"https:\/\/linux.die.net\/man\/1\/nova-compute"}},{"Process":{"Description":"","Process Name":"nova-console","Link":"https:\/\/linux.die.net\/man\/1\/nova-console"}},{"Process":{"Description":null,"Process Name":"nova-consoleauth","Link":"https:\/\/linux.die.net\/man\/1\/nova-consoleauth"}},{"Process":{"Description":"","Process Name":"nova-dhcpbridge","Link":"https:\/\/linux.die.net\/man\/1\/nova-dhcpbridge"}},{"Process":{"Description":"","Process Name":"nova-manage","Link":"https:\/\/linux.die.net\/man\/1\/nova-manage"}},{"Process":{"Description":"","Process Name":"nova-network","Link":"https:\/\/linux.die.net\/man\/1\/nova-network"}},{"Process":{"Description":"","Process Name":"nova-novncproxy","Link":"https:\/\/linux.die.net\/man\/1\/nova-novncproxy"}},{"Process":{"Description":"","Process Name":"nova-objectstore","Link":"https:\/\/linux.die.net\/man\/1\/nova-objectstore"}},{"Process":{"Description":"","Process Name":"nova-rootwrap","Link":"https:\/\/linux.die.net\/man\/1\/nova-rootwrap"}},{"Process":{"Description":"","Process Name":"nova-rpc-zmq-receiver","Link":"https:\/\/linux.die.net\/man\/1\/nova-rpc-zmq-receiver"}},{"Process":{"Description":"","Process Name":"nova-scheduler","Link":"https:\/\/linux.die.net\/man\/1\/nova-scheduler"}},{"Process":{"Description":"","Process Name":"nova-volume","Link":"https:\/\/linux.die.net\/man\/1\/nova-volume"}},{"Process":{"Description":"","Process Name":"nova-volume-usage-audit","Link":"https:\/\/linux.die.net\/man\/1\/nova-volume-usage-audit"}},{"Process":{"Description":"","Process Name":"nova-xvpvncproxy","Link":"https:\/\/linux.die.net\/man\/1\/nova-xvpvncproxy"}},{"Process":{"Description":"There may exist several versions of an RPM for a single product. novi scans directories for RPMs and finds the latest-version RPM for every product. In turn, this data can be used to: - see what are the latest RPMs on your system - fold the latest RPMs into a Kickstart tree, such that you can build systems with the updates already applied This process is part of Kickstart\/Anaconda\/Yum repository maintenance, described in the following article: \"Pre-Patched Kickstart Installs\" http:\/\/www.linuxdevcenter.com\/pub\/a\/linux\/2005\/02\/17\/kickstart_updates.html","Process Name":"novi","Link":"https:\/\/linux.die.net\/man\/1\/novi"}},{"Process":{"Description":"Sample scenarios for using novi","Process Name":"novi_examples","Link":"https:\/\/linux.die.net\/man\/1\/novi_examples"}},{"Process":{"Description":"","Process Name":"novnc_server","Link":"https:\/\/linux.die.net\/man\/1\/novnc_server"}},{"Process":{"Description":"Nping is an open-source tool for network packet generation, response analysis and response time measurement. Nping allows users to generate network packets of a wide range of protocols, letting them tune virtually any field of the protocol headers. While Nping can be used as a simple ping utility to detect active hosts, it can also be used as a raw packet generator for network stack stress tests, ARP poisoning, Denial of Service attacks, route tracing, and other purposes. Additionally, Nping offers a special mode of operation called the \"Echo Mode\", that lets users see how the generated probes change in transit, revealing the differences between the transmitted packets and the packets received at the other end. See section \"Echo Mode\" for details. The output from Nping is a list of the packets that are being sent and received. The level of detail depends on the options used. A typical Nping execution is shown in Example 1. The only Nping arguments used in this example are -c, to specify the number of times to target each host, --tcp to specify TCP Probe Mode, -p 80,433 to specify the target ports; and then the two target hostnames. Example 1. A representative Nping execution # nping -c 1 --tcp -p 80,433 scanme.nmap.org google.com\n\nStarting Nping ( http:\/\/nmap.org\/nping )\nSENT (0.0120s) TCP 96.16.226.135:50091 > 64.13.134.52:80 S ttl=64 id=52072 iplen=40  seq=1077657388 win=1480\nRCVD (0.1810s) TCP 64.13.134.52:80 > 96.16.226.135:50091 SA ttl=53 id=0 iplen=44  seq=4158134847 win=5840 <mss 1460>\nSENT (1.0140s) TCP 96.16.226.135:50091 > 74.125.45.100:80 S ttl=64 id=13932 iplen=40  seq=1077657388 win=1480\nRCVD (1.1370s) TCP 74.125.45.100:80 > 96.16.226.135:50091 SA ttl=52 id=52913 iplen=44  seq=2650443864 win=5720 <mss 1430>\nSENT (2.0140s) TCP 96.16.226.135:50091 > 64.13.134.52:433 S ttl=64 id=8373 iplen=40  seq=1077657388 win=1480\nSENT (3.0140s) TCP 96.16.226.135:50091 > 74.125.45.100:433 S ttl=64 id=23624 iplen=40  seq=1077657388 win=1480\n\nStatistics for host scanme.nmap.org (64.13.134.52):\n |  Probes Sent: 2 | Rcvd: 1 | Lost: 1  (50.00%)\n |_ Max rtt: 169.720ms | Min rtt: 169.720ms | Avg rtt: 169.720ms\nStatistics for host google.com (74.125.45.100):\n |  Probes Sent: 2 | Rcvd: 1 | Lost: 1  (50.00%)\n |_ Max rtt: 122.686ms | Min rtt: 122.686ms | Avg rtt: 122.686ms\nRaw packets sent: 4 (160B) | Rcvd: 2 (92B) | Lost: 2 (50.00%)\nTx time: 3.00296s | Tx bytes\/s: 53.28 | Tx pkts\/s: 1.33\nRx time: 3.00296s | Rx bytes\/s: 30.64 | Rx pkts\/s: 0.67\nNping done: 2 IP addresses pinged in 4.01 seconds","Process Name":"nping","Link":"https:\/\/linux.die.net\/man\/1\/nping"}},{"Process":{"Description":"Print the number of processing units available to the current process, which may be less than the number of online processors --all print the number of installed processors --ignore= N if possible, exclude N processing units --help display this help and exit --version output version information and exit","Process Name":"nproc","Link":"https:\/\/linux.die.net\/man\/1\/nproc"}},{"Process":{"Description":null,"Process Name":"nqc","Link":"https:\/\/linux.die.net\/man\/1\/nqc"}},{"Process":{"Description":"This utility converts a existing NQS job script to work with PBS and NQS. The existing script is copied and PBS directives, #PBS , are inserted prior to each NQS directive #QSUB or #@$ , in the original script. Certain NQS date specification and options are not supported by PBS. A warning message will be displayed indicating the problem and the line of the script on which it occurred. If any unrecognizable NQS directives are encountered, an error message is displayed. The new PBS script will be deleted if any errors occur.","Process Name":"nqs2pbs","Link":"https:\/\/linux.die.net\/man\/1\/nqs2pbs"}},{"Process":{"Description":"rancid is a perl(1) script which uses the login scripts (see clogin(1)) to login to a device, execute commands to display the configuration, etc, then filters the output for formatting, security, and so on. rancid's product is a file with the name of it's last argument plus the suffix .new. For example, hostname.new. There are complementary scripts for other platforms and\/or manufacturers that are supported by rancid(1). Briefly, these are: agmrancid Cisco Anomaly Guard Module (AGM) arancid Alteon WebOS switches arrancid Arista Networks devices brancid Bay Networks (nortel) cat5rancid Cisco catalyst switches cssrancid Cisco content services switches erancid ADC-kentrox EZ-T3 mux f10rancid Force10 f5rancid F5 BigIPs fnrancid Fortinet Firewalls francid Foundry and HP procurve OEMs of Foundry hrancid HP Procurve Switches htranicd Hitachi Routers jerancid Juniper Networks E-series jrancid Juniper Networks mrancid MRTd mrvrancid MRV optical switches nrancid Netscreen firewalls nsrancid Netscaler nxrancid Cisco Nexus boxes prancid Procket Networks rivrancid Riverstone rrancid Redback srancid SMC switch (some Dell OEMs) trancid Netopia sDSL\/T1 routers tntrancid Lucent TNT xrancid Extreme switches xrrancid Cisco IOS-XR boxes zrancid Zebra routing software The command-line options are as follows: -V Prints package name and version strings. -d Display debugging information. -l Display somewhat less debugging information. -f rancid should interpret the next argument as a filename which contains the output it would normally collect from the device ( hostname) with clogin(1).","Process Name":"nrancid","Link":"https:\/\/linux.die.net\/man\/1\/nrancid"}},{"Process":{"Description":"The nroff script emulates the nroff command using groff. Only ascii, ascii8, latin1, utf8, nippon, and cp1047 are valid arguments for the -T option. If an invalid or no -T option is given, nroff checks the current locale to select a default output device. It first tries the locale program, then the environment variables LC_ALL, LC_CTYPE, and LANG, and finally the LESSCHARSET environment variable. The -h and -c options are equivalent to grotty's options -h (using tabs in the output) and -c (using the old output scheme instead of SGR escape sequences). The -C, -i, -n, -m, -o, and -r options have the effect described in troff(1). In addition, nroff silently ignores the options -e, -q, and -s (which are not implemented in troff). Options -p (pic), -t (tbl), -S (safer), and -U (unsafe) are passed to groff. -v shows the version number.","Process Name":"nroff","Link":"https:\/\/linux.die.net\/man\/1\/nroff"}},{"Process":{"Description":"The XML Bookmark Exchange Language, or XBEL, is an Internet \"bookmarks\" interchange format. ns_parse parses Netscape bookmark files.","Process Name":"ns_parse","Link":"https:\/\/linux.die.net\/man\/1\/ns_parse"}},{"Process":{"Description":null,"Process Name":"nsc","Link":"https:\/\/linux.die.net\/man\/1\/nsc"}},{"Process":{"Description":"The shared library nsdejavu.so uses the Netscape browser plugin API to display DjVu images in in a number of popular web browsers. Different web browsers provide various level of support for Netscape plugins. Please check section \"Browser Compatibility\" for instructions on how to enable the DjVu browser plugin. The DjVuLibre browser plugin works by invoking a standalone viewer with the special command line option -netscape. The plugin first searches a program named djview. If this program cannot be found, it searches for djview4 and finally djview3. It is always possible to override this search strategy by setting the environment variable NPX_DJVIEW to the full path of the desired executable.","Process Name":"nsdejavu","Link":"https:\/\/linux.die.net\/man\/1\/nsdejavu"}},{"Process":{"Description":"The nseq command takes a file containing a Netscape certificate sequence and prints out the certificates contained in it or takes a file of certificates and converts it into a Netscape certificate sequence.","Process Name":"nseq","Link":"https:\/\/linux.die.net\/man\/1\/nseq"}},{"Process":{"Description":"onsgmls parses and validates the SGML document whose document entity is specified by the system identifiers and prints on the standard output a simple text representation of its Element Structure Information Set. (This is the information set which a structure-controlled conforming SGML application should act upon.) If more than one system identifier is specified, then the corresponding entities will be concatenated to form the document entity. Thus the document entity may be spread among several files; for example, the SGML declaration, prolog and document instance set could each be in a separate file. If no system identifiers are specified, then onsgmls will read the document entity from the standard input. A command line system identifier of - can be used to refer to the standard input. (Normally in a system identifier, <OSFD>0 is used to refer to standard input.) Part of an SGML System Conforming to International Standard ISO 8879 -- Standard Generalized Markup Language. An SGML Extended Facilities system conforming to Annex A of Internal Standard ISO\/IEC 10744 -- Hypermedia\/Time-based Structuring Language The following options are available: -alinktype, --activate=linktype Make link type linktype active. Not all ESIS information is output in this case: the active LPDs are not explicitly reported, although each link attribute is qualified with its link type name; there is no information about result elements; when there are multiple link rules applicable to the current element, onsgmls always chooses the first. -A architecture, --architecture= architecture Parse with respect to architecture architecture. -b bctf, --bctf= bctf, -b encoding, --encoding= encoding This determines the encoding used for output. If in fixed character set mode it specifies the name of an encoding; if not, it specifies the name of a BCTF. -B, --batch_mode Batch mode. Parse each specified on the command line separately, rather than concatenating them. This is useful mainly with -s. If -tfilename is also specified, then the specified filename will be prefixed to the sysid to make the filename for the RAST result for each sysid. -c sysid, --catalog= sysid Map public identifiers and entity names to system identifiers using the catalog entry file whose system identifier is sysid. Multiple -c options are allowed. If there is a catalog entry file called catalog in the same place as the document entity, it will be searched for immediately after those specified by -c. -C, --catalogs The arguments specify catalog files rather than the document entity. The document entity is specified by the first DOCUMENT entry in the catalog files. -D directory, --directory= directory Search directory for files specified in system identifiers. Multiple -D options are allowed. See the description of the osfile storage manager for more information about file searching. -e, --open-entities Describe open entities in error messages. Error messages always include the position of the most recently opened external entity. -E max_errors, --max-errors= max_errors onsgmls will exit after max_errors errors. If max_errors is 0, there is no limit on the number of errors. The default is 200. -f file, --error-file= file Redirect errors to file. This is useful mainly with shells that do not support redirection of stderr. -g, --open-elements Show the generic identifiers of open elements in error messages. -h, --help Show a help message and exit. -i name, --include= name Pretend that <!ENTITY % name \"INCLUDE\"> occurs at the start of the document type declaration subset in the SGML document entity. Since repeated definitions of an entity are ignored, this definition will take precedence over any other definitions of this entity in the document type declaration. Multiple -i options are allowed. If the SGML declaration replaces the reserved name INCLUDE then the new reserved name will be the replacement text of the entity. Typically the document type declaration will contain <!ENTITY % name \"IGNORE\"> and will use %name; in the status keyword specification of a marked section declaration. In this case the effect of the option will be to cause the marked section not to be ignored. -n, --error-numbers Show message numbers in error messages. -o output_option, --option= output_option Output additional information according to output_option: entity Output definitions of all general entities not just for data or subdoc entities that are referenced or named in an ENTITY or ENTITIES attribute. id Distinguish attributes whose declared value is ID. line Output L commands giving the current line number and filename. included Output an i command for included sub-elements. empty Output an e command for elements which are not allowed to have an end-tag, that is those with a declared content of empty or with a content reference attribute. notation-sysid Output an f command before an N command, if a system identifier could be generated for that notation. nonsgml In fixed character set mode, output \\% escape sequences for non-SGML data characters. Non-SGML data characters can result from numeric character references. data-attribute Output the notation name and attributes for DATA attributes. Otherwise, DATA attributes are treated like CDATA attributes. For more details see clause 4.4.3 of Annex K of ISO 8879. comment Output an _ command with the contents of a comment. Multiple comments in a single comment declaration will result in multiple distinct _ commands, just as if the comments were each in a separate comment declaration. omitted Output an o command before a command which was implied by the input document, but omitted from the actual markup. This currently affects (,), and A commands. tagomit As omitted, but only for ( and ) commands. attromit As omitted, but only for A commands. Multiple -o options are allowed. -p, --only-prolog Parse only the prolog. onsgmls will exit after parsing the document type declaration. Implies -s. -R, --restricted Restrict file reading. This option is intended for use with onsgmls-based Web tools (e.g. CGI scripts) to prevent reading of arbitrary files on the Web server. With this option enabled, onsgmls will not read any local files unless they are located in a directory (or subdirectory) specified by the -D option or included in the SGML_SEARCH_PATH environment variable. As a further security precaution, this option limits filesnames to the characters A-Z, a-z, 0-9, '?', '.', '_', '-' and does not allow filenames containing \"..\". On systems with MS-DOS file names ':' and '\\' are also allowed. -s, --no-output Suppress output. Error messages will still be printed. -t file, --rast-file= file Output to file the RAST result as defined by ISO\/IEC 13673:1995 (actually this isn't quite an IS yet; this implements the Intermediate Editor's Draft of 1994\/08\/29, with changes to implement ISO\/IEC JTC1\/SC18\/WG8 N1777). The normal output is not produced. -v, --version Print the version number. -w type, --warning= type Control warnings and errors. Multiple -w options are allowed. The following values of type enable warnings: xml Warn about constructs that are not allowed by XML. mixed Warn about mixed content models that do not allow #PCDATA anywhere. sgmldecl Warn about various dubious constructions in the SGML declaration. should Warn about various recommendations made in ISO 8879 that the document does not comply with. (Recommendations are expressed with \"should\", as distinct from requirements which are usually expressed with \"shall\".) default Warn about defaulted references. duplicate Warn about duplicate entity declarations. undefined Warn about undefined elements: elements used in the DTD but not defined. unclosed Warn about unclosed start and end-tags. empty Warn about empty start and end-tags. net Warn about net-enabling start-tags and null end-tags. min-tag Warn about minimized start and end-tags. Equivalent to combination of unclosed, empty and net warnings. unused-map Warn about unused short reference maps: maps that are declared with a short reference mapping declaration but never used in a short reference use declaration in the DTD. unused-param Warn about parameter entities that are defined but not used in a DTD. Unused internal parameter entities whose text is INCLUDE or IGNORE won't get the warning. notation-sysid Warn about notations for which no system identifier could be generated. all Warn about conditions that should usually be avoided (in the opinion of the author). Equivalent to: mixed, should, default, undefined, sgmldecl, unused-map, unused-param, empty and unclosed. immediate-recursion Warn about immediately recursive elements. For more detais see clause 2.2.5 of Annex K of ISO 8879. fully-declared Warn if the document instance fails to be fully declared. This has the effect of changing the SGML declaration to specify IMPLYDEF ATTLIST NO ELEMENT NO ENTITY NO NOTATION NO. For more details see clause 2.2.1 of Annex K of ISO 8879. fully-tagged Warn if the document instance fails to be fully-tagged. This has the effect of changing the SGML declaration to specify DATATAG NO, RANK NO, OMITTAG NO, SHORTTAG STARTTAG EMPTY NO and SHORTTAG ATTRIB OMITNAME NO. For more details see clause 2.2.2 of Annex K of ISO 8879. amply-tagged, amply-tagged-recursive Warn if the doucment instance fails to be amply-tagged. Implicitly defined elements may be immediately recurisve if amply-tagged-recursive is specified. This has the effect of changing the SGML declaration to specify DATATAG NO, RANK NO, OMITTAG NO, SHORTTAG ATTRIB OMITNAME NO and either IMPLYDEF ELEMENT ANYOTHER or IMPLYDEF ELEMENT YES. For more details see clause 2.2.4 of Annex K of ISO 8879. type-valid Warn if the document instance fails to be type-valid. This has the effect of changing the SGML declaration to specify VALIDITY YES. For more details see clause 2.2.3 of Annex K of ISO 8879. entity-ref Warn about references to non-predefined entities. This has the effect of changing the SGML declaration to specify ENTITIES REF NONE. For more details see clause 2.3.2 of Annex K of ISO 8879. external-entity-ref Warn about references to external entities. This includes references to an external DTD subset. This has the effect of changing the SGML declaration to specify ENTITIES REF INTERNAL. For more details see clause 2.3.3 of Annex K of ISO 8879. integral Warn if the document instance is not integrally stored. This has the effect of changing the SGML declaration to specify ENTITIES INTEGRAL YES. For more details see clause 2.3.1 of Annex K of ISO 8879. A warning can be disabled by using its name prefixed with no-. Thus -wall -wno-duplicate will enable all warnings except those about duplicate entity declarations. The following values for warning_type disable errors: no-idref Do not give an error for an ID reference value which no element has as its ID. The effect will be as if each attribute declared as an ID reference value had been declared as a name. no-significant Do not give an error when a character that is not a significant character in the reference concrete syntax occurs in a literal in the SGML declaration. This may be useful in conjunction with certain buggy test suites. no-valid Do not require the document to be type-valid. This has the effect of changing the SGML declaration to specify VALIDITY NOASSERT and IMPLYDEF ATTLIST YES ELEMENT YES. An option of -wvalid has the effect of changing the SGML declaration to specify VALIDITY TYPE and IMPLYDEF ATTLIST NO ELEMENT NO. If neither -wvalid nor -wno-valid are specified, then the VALIDITY and IMPLYDEF specified in the SGML declaration will be used. no-afdr Do not give errors when AFDR meta-DTD notation features are used in the DTD. These errors are normally produced when parsing the DTD, but suppressed when parsing meta-DTDs. -x, --references Show information about relevant clauses (from ISO 8879:1986) in error messages. The following options are also supported for backward compatibility with sgmls: -d Same as -wduplicate. -l Same as -oline. -m sysid Same as -c. -r Same as -wdefault. -u Same as -wundef.","Process Name":"nsgmls","Link":"https:\/\/linux.die.net\/man\/1\/nsgmls"}},{"Process":{"Description":"clogin is an expect(1) script to automate the process of logging into a Cisco router, catalyst switch, Extreme switch, Juniper ERX\/E-series, Procket Networks, or Redback router. There are complementary scripts for Alteon, Avocent (Cyclades), Bay Networks (nortel), ADC-kentrox EZ-T3 mux, Foundry, HP Procurve Switches and Cisco AGMs, Hitachi Routers, Juniper Networks, MRV optical switch, Netscreen firewalls, Netscaler, Riverstone, Netopia, and Lucent TNT, named alogin, avologin, blogin, elogin, flogin, fnlogin, hlogin, htlogin, jlogin, mrvlogin, nlogin, nslogin, rivlogin, tlogin, and tntlogin, respectively. clogin reads the .cloginrc file for its configuration, then connects and logs into each of the routers specified on the command line in the order listed. Command-line options exist to override some of the directives found in the .cloginrc configuration file. The command-line options are as follows: -S Save the configuration on exit, if the device prompts at logout time. This only has affect when used with -s. -V Prints package name and version strings. -c Command to be run on each router list on the command-line. Multiple commands maybe listed by separating them with semi-colons (;). The argument should be quoted to avoid shell expansion. -d Enable expect debugging. -E Specifies a variable to pass through to scripts (-s). For example, the command-line option -Efoo=bar will produce a global variable by the name Efoo with the initial value \"bar\". -e Specify a password to be supplied when gaining enable privileges on the router(s). Also see the password directive of the .cloginrc file. -f Specifies an alternate configuration file. The default is $HOME\/.cloginrc. -p Specifies a password associated with the user specified by the -u option, user directive of the .cloginrc file, or the Unix username of the user. -s The filename of an expect(1) script which will be sourced after the login is successful and is expected to return control to clogin, with the connection to the router intact, when it is done. Note that clogin disables log_user of expect(1)when -s is used. Example script(s) can be found in share\/rancid\/*.exp. -t Alters the timeout interval; the period that clogin waits for an individual command to return a prompt or the login process to produce a prompt or failure. The argument is in seconds. -u Specifies the username used when prompted. The command-line option overrides any user directive found in .cloginrc. The default is the current Unix username. -v Specifies a vty password, that which is prompted for upon connection to the router. This overrides the vty password of the .cloginrc file's password directive. -w Specifies the username used if prompted when gaining enable privileges. The command-line option overrides any user or enauser directives found in .cloginrc. The default is the current Unix username. -x Similar to the -c option; -x specifies a file with commands to run on each of the routers. The commands must not expect additional input, such as 'copy rcp startup-config' does. For example: show version\nshow logging -y Specifies the encryption algorithm for use with the ssh(1) -c option. The default encryption type is often not supported. See the ssh(1) man page for details. The default is 3des.","Process Name":"nslogin","Link":"https:\/\/linux.die.net\/man\/1\/nslogin"}},{"Process":{"Description":"Nslookup is a program to query Internet domain name servers. Nslookup has two modes: interactive and non-interactive. Interactive mode allows the user to query name servers for information about various hosts and domains or to print a list of hosts in a domain. Non-interactive mode is used to print just the name and requested information for a host or domain.","Process Name":"nslookup","Link":"https:\/\/linux.die.net\/man\/1\/nslookup"}},{"Process":{"Description":"rancid is a perl(1) script which uses the login scripts (see clogin(1)) to login to a device, execute commands to display the configuration, etc, then filters the output for formatting, security, and so on. rancid's product is a file with the name of it's last argument plus the suffix .new. For example, hostname.new. There are complementary scripts for other platforms and\/or manufacturers that are supported by rancid(1). Briefly, these are: agmrancid Cisco Anomaly Guard Module (AGM) arancid Alteon WebOS switches arrancid Arista Networks devices brancid Bay Networks (nortel) cat5rancid Cisco catalyst switches cssrancid Cisco content services switches erancid ADC-kentrox EZ-T3 mux f10rancid Force10 f5rancid F5 BigIPs fnrancid Fortinet Firewalls francid Foundry and HP procurve OEMs of Foundry hrancid HP Procurve Switches htranicd Hitachi Routers jerancid Juniper Networks E-series jrancid Juniper Networks mrancid MRTd mrvrancid MRV optical switches nrancid Netscreen firewalls nsrancid Netscaler nxrancid Cisco Nexus boxes prancid Procket Networks rivrancid Riverstone rrancid Redback srancid SMC switch (some Dell OEMs) trancid Netopia sDSL\/T1 routers tntrancid Lucent TNT xrancid Extreme switches xrrancid Cisco IOS-XR boxes zrancid Zebra routing software The command-line options are as follows: -V Prints package name and version strings. -d Display debugging information. -l Display somewhat less debugging information. -f rancid should interpret the next argument as a filename which contains the output it would normally collect from the device ( hostname) with clogin(1).","Process Name":"nsrancid","Link":"https:\/\/linux.die.net\/man\/1\/nsrancid"}},{"Process":{"Description":"NSS-GUI(1) is a graphical user interface to manage data and configuration of NSS (Network Security Services). Features includes managing the contents of a certificate database, CRLs and PKCS#11 security devices. More precisely, NSS-GUI is a simple frontend to run the PKI management features provided by the Mozilla XULRunner runtime environment software. NSS-GUI(1) uses NSS' shared database access mechanism.","Process Name":"nss-gui","Link":"https:\/\/linux.die.net\/man\/1\/nss-gui"}},{"Process":{"Description":"nsscache synchronises a local NSS cache against a remote data source. This approach allows the administrator to separate the network from the NSS lookup codepath, improving speed and reliability of name services.","Process Name":"nsscache","Link":"https:\/\/linux.die.net\/man\/1\/nsscache"}},{"Process":{"Description":"nsupdate is used to submit Dynamic DNS Update requests as defined in RFC 2136 to a name server. This allows resource records to be added or removed from a zone without manually editing the zone file. A single update request can contain requests to add or remove more than one resource record. Zones that are under dynamic control via nsupdate or a DHCP server should not be edited by hand. Manual edits could conflict with dynamic updates and cause data to be lost. The resource records that are dynamically added or removed with nsupdate have to be in the same zone. Requests are sent to the zone's master server. This is identified by the MNAME field of the zone's SOA record. The -d option makes nsupdate operate in debug mode. This provides tracing information about the update requests that are made and the replies received from the name server. The -D option makes nsupdate report additional debugging information to -d. The -L option with an integer argument of zero or higher sets the logging debug level. If zero, logging is disabled. Transaction signatures can be used to authenticate the Dynamic DNS updates. These use the TSIG resource record type described in RFC 2845 or the SIG(0) record described in RFC 2535 and RFC 2931 or GSS-TSIG as described in RFC 3645. TSIG relies on a shared secret that should only be known to nsupdate and the name server. Ensure that you select the appropriate algorithms for the applications as well as the key when authenticating each other. For instance, suitable key and server statements would be added to \/etc\/named.conf so that the name server can associate the appropriate secret key and algorithm with the IP address of the client application that will be using TSIG authentication. SIG(0) uses public key cryptography. To use a SIG(0) key, the public key must be stored in a KEY record in a zone served by the name server. nsupdate does not read \/etc\/named.conf. GSS-TSIG uses Kerberos credentials. Standard GSS-TSIG mode is switched on with the -g flag. A non-standards-compliant variant of GSS-TSIG used by Windows 2000 can be switched on with the -o flag. nsupdate uses the -y or -k option to provide the shared secret needed to generate a TSIG record for authenticating Dynamic DNS update requests, default type HMAC-MD5. These options are mutually exclusive. When the -y option is used, a signature is generated from [hmac:]keyname:secret. keyname is the name of the key, and secret is the base64 encoded shared secret. Use of the -y option is discouraged because the shared secret is supplied as a command line argument in clear text. This may be visible in the output from ps(1) or in a history file maintained by the user's shell. With the -k option, nsupdate reads the shared secret from the file keyfile. Keyfiles may be in two formats: a single file containing a named.conf-format key statement, which may be generated automatically by ddns-confgen, or a pair of files whose names are of the format K{name}.+157.+{random}.key and K{name}.+157.+{random}.private, which can be generated by dnssec-keygen. The -k may also be used to specify a SIG(0) key used to authenticate Dynamic DNS update requests. In this case, the key specified is not an HMAC-MD5 key. nsupdate can be run in a local-host only mode using the -l flag. This sets the server address to localhost (disabling the server so that the server address cannot be overridden). Connections to the local server will use a TSIG key found in \/var\/run\/named\/session.key, which is automatically generated by named if any local master zone has set update-policy to local. The location of this key file can be overridden with the -k option. By default, nsupdate uses UDP to send update requests to the name server unless they are too large to fit in a UDP request in which case TCP will be used. The -v option makes nsupdate use a TCP connection. This may be preferable when a batch of update requests is made. The -p sets the default port number to use for connections to a name server. The default is 53. The -t option sets the maximum time an update request can take before it is aborted. The default is 300 seconds. Zero can be used to disable the timeout. The -u option sets the UDP retry interval. The default is 3 seconds. If zero, the interval will be computed from the timeout interval and number of UDP retries. The -r option sets the number of UDP retries. The default is 3. If zero, only one update request will be made. The -R randomdev option specifies a source of randomness. If the operating system does not provide a \/dev\/random or equivalent device, the default source of randomness is keyboard input. randomdev specifies the name of a character device or file containing random data to be used instead of the default. The special value keyboard indicates that keyboard input should be used. This option may be specified multiple times.","Process Name":"nsupdate","Link":"https:\/\/linux.die.net\/man\/1\/nsupdate"}},{"Process":{"Description":"This tool is part of the samba(7) suite. ntlm_auth is a helper utility that authenticates users using NT\/LM authentication. It returns 0 if the users is authenticated successfully and 1 if access was denied. ntlm_auth uses winbind to access the user and authentication data for a domain. This utility is only intended to be used by other programs (currently Squid and mod_ntlm_winbind)","Process Name":"ntlm_auth","Link":"https:\/\/linux.die.net\/man\/1\/ntlm_auth"}},{"Process":{"Description":"ntpctl is a full-screen console (ncurses) variant of the tpctl program. Please see the tpctl(1) man page for more information about what can be configured using these utilities.","Process Name":"ntpctl","Link":"https:\/\/linux.die.net\/man\/1\/ntpctl"}},{"Process":{"Description":"ntsc-cc reads vbi data from \/dev\/vbi0 and decodes the enclosed cc data. Start it with '-h' to get a list of cmd line options.","Process Name":"ntsc-cc","Link":"https:\/\/linux.die.net\/man\/1\/ntsc-cc"}},{"Process":{"Description":"The nttcp program measures the transferrate (and other numbers) on a TCP, UDP or UDP multicast connection. To use nttcp you have to provide the executable on the local machine and on a partner machine. On the partner machine simply start nttcp with the option -i. Started this way, nttcp is waiting for connections from other nttcps. On the local host simply call nttcp with the name of the partner host. It will contact the nttcp started on the partner machine and initiate the transfer. On default the program transfers 2048 buffers of 4KByte length (a total of 8 MByte) to the partner host. On both sides the performance will be measured and the findings (both, remote and local) are reported on the local side. You may change nearly every parameter of the transmission via commandline options, even what and how results are printed.","Process Name":"nttcp","Link":"https:\/\/linux.die.net\/man\/1\/nttcp"}},{"Process":{"Description":"Nttlscan is a quick network topology scanner and functions as a highly parallel traceroute(8). It randomly picks destination IP addresses and send TCP or UDP probes. Returing ICMP messages are interpreted to reconstruct the route that packets take to their respective destination. Nttlscan can be used to construct virtual routing topologies for Honeyd(8). The options are as follows:       -u'                       Uses UDP probes instead of TCP probes. -h' Outputs usage information. -m total-probes' Specifies the total number of addresses to probe. The addresses are taken randomly from the specified destination address range. -M max-active-probes The number of probes that can be active at any given time. Although, nttlscan does not require much state if it is used behind a NAT device, the state tables of the NAT can quickly run out of space. This flag can be used to slow down the scanning speed. -i device' Specifies the network device that should be used to listen for return packets. -d dst-address-range Specifies a range of destination addresses that should be probed. The address is specified in CIDR notation. The output from nttlscan contains the destination IP addresses followed by a list of router IP addresses or stars if no response was received for a certain TTL.","Process Name":"nttlscan","Link":"https:\/\/linux.die.net\/man\/1\/nttlscan"}},{"Process":{"Description":null,"Process Name":"numconv","Link":"https:\/\/linux.die.net\/man\/1\/numconv"}},{"Process":{"Description":"This program generates a Python C\/API file (<modulename>module.c) that contains wrappers for given Fortran or C functions so that they can be called from Python. With the -c option the corresponding extension modules are built.","Process Name":"numpy","Link":"https:\/\/linux.die.net\/man\/1\/numpy"}},{"Process":{"Description":"nuxwdog is a watchdog daemon that builds on the uxwdog service that is part of the Netscape Enterprise Server (NES). nuxwdog can start, stop, monitor, and reconfigure server programs, depending on the parameters passed to it in its configuration file. nuxwdog opens a Unix domain socket to accept requests from any server process it is managing. Optionally, nuxwdog can be configured to communicate only with clients that are descendants of the nuxwdog process, limiting an avenue of potential access to any servers managed by the watchdog. Some servers require a high-level of security to protect their data or operations, which means (for example) that they cannot store plaintext passwords in a password file to allow the server to be started automatically. nuxwdog can be configured to prompt for server passwords when a server first starts and then caches those passwords so that nuxwdog can restart the server without intervention if the server crashes. To make it easy for clients to communicate with nuxwdog, a C\/C++ shared library is provided with the nuxwdog source code (libnuxwdog.so). Additionally, nuxwdog provides JNI interfaces and Perl bindings to the libnuxwdog.so library, so that calls can be made from Java and Perl programs. For more information on this library and the client interfaces, see https:\/\/fedorahosted.org\/nuxwdog\/wiki\/HOWTO. nuxwdog is used by Dogtag PKI to monitor and manage the subsystem server processes for Java, Tomcat, and Apache servers.","Process Name":"nuxwdog","Link":"https:\/\/linux.die.net\/man\/1\/nuxwdog"}},{"Process":{"Description":null,"Process Name":"nvclock","Link":"https:\/\/linux.die.net\/man\/1\/nvclock"}},{"Process":{"Description":"Vi is a screen oriented text editor. Ex is a line-oriented text editor. Ex and vi are different interfaces to the same program, and it is possible to switch back and forth during an edit session. View is the equivalent of using the -R (read-only) option of vi. This manual page is the one provided with the nex\/nvi versions of the ex\/vi text editors. Nex\/nvi are intended as bug-for-bug compatible replacements for the original Fourth Berkeley Software Distribution (4BSD) ex and vi programs. For the rest of this manual page, nex\/nvi is used only when it's necessary to distinguish it from the historic implementations of ex\/vi. This manual page is intended for users already familiar with ex\/vi. Anyone else should almost certainly read a good tutorial on the editor before this manual page. If you're in an unfamiliar environment, and you absolutely have to get work done immediately, read the section after the options description, entitled \"Fast Startup\". It's probably enough to get you going. The following options are available: -c Execute cmd immediately after starting the edit session. Particularly useful for initial positioning in the file, however cmd is not limited to positioning commands. This is the POSIX 1003.2 interface for the historic \"+cmd\" syntax. Nex\/nvi supports both the old and new syntax. -e Start editing in ex mode, as if the command name were ex. -l Start editing with the lisp and showmatch options set. -R Start editing in read-only mode, as if the command name was view, or the readonly option was set. -r Recover the specified files, or, if no files are specified, list the files that could be recovered. If no recoverable files by the specified name exist, the file is edited as if the -r option had not been specified. -S Run with the secure edit option set, disallowing all access to external programs. -s Enter batch mode; applicable only to ex edit sessions. Batch mode is useful when running ex scripts. Prompts, informative messages and other user oriented message are turned off, and no startup files or environmental variables are read. This is the POSIX 1003.2 interface for the historic \"-\" argument. Nex\/nvi supports both the old and new syntax. -t Start editing at the specified tag. (See ctags(1)). -w Set the initial window size to the specified number of lines. -v Start editing in vi mode, as if the command name was vi or view. Note that the -F option (which prevented ex\/vi from making a full backup of the target file) has been removed and is no longer available. Command input for ex\/vi is read from the standard input. In the vi interface, it is an error if standard input is not a terminal. In the ex interface, if standard input is not a terminal, ex will read commands from it regardless, however, the session will be a batch mode session, exactly as if the -s option had been specified. Ex\/vi exits 0 on success, and greater than 0 if an error occurs.","Process Name":"nvi","Link":"https:\/\/linux.die.net\/man\/1\/nvi"}},{"Process":{"Description":"Vi is a screen oriented text editor. Ex is a line-oriented text editor. Ex and vi are different interfaces to the same program, and it is possible to switch back and forth during an edit session. View is the equivalent of using the -R (read-only) option of vi. This manual page is the one provided with the nex\/nvi versions of the ex\/vi text editors. Nex\/nvi are intended as bug-for-bug compatible replacements for the original Fourth Berkeley Software Distribution (4BSD) ex and vi programs. For the rest of this manual page, nex\/nvi is used only when it's necessary to distinguish it from the historic implementations of ex\/vi. This manual page is intended for users already familiar with ex\/vi. Anyone else should almost certainly read a good tutorial on the editor before this manual page. If you're in an unfamiliar environment, and you absolutely have to get work done immediately, read the section after the options description, entitled \"Fast Startup\". It's probably enough to get you going. The following options are available: -c Execute cmd immediately after starting the edit session. Particularly useful for initial positioning in the file, however cmd is not limited to positioning commands. This is the POSIX 1003.2 interface for the historic \"+cmd\" syntax. Nex\/nvi supports both the old and new syntax. -e Start editing in ex mode, as if the command name were ex. -l Start editing with the lisp and showmatch options set. -R Start editing in read-only mode, as if the command name was view, or the readonly option was set. -r Recover the specified files, or, if no files are specified, list the files that could be recovered. If no recoverable files by the specified name exist, the file is edited as if the -r option had not been specified. -S Run with the secure edit option set, disallowing all access to external programs. -s Enter batch mode; applicable only to ex edit sessions. Batch mode is useful when running ex scripts. Prompts, informative messages and other user oriented message are turned off, and no startup files or environmental variables are read. This is the POSIX 1003.2 interface for the historic \"-\" argument. Nex\/nvi supports both the old and new syntax. -t Start editing at the specified tag. (See ctags(1)). -w Set the initial window size to the specified number of lines. -v Start editing in vi mode, as if the command name was vi or view. Note that the -F option (which prevented ex\/vi from making a full backup of the target file) has been removed and is no longer available. Command input for ex\/vi is read from the standard input. In the vi interface, it is an error if standard input is not a terminal. In the ex interface, if standard input is not a terminal, ex will read commands from it regardless, however, the session will be a batch mode session, exactly as if the -s option had been specified. Ex\/vi exits 0 on success, and greater than 0 if an error occurs.","Process Name":"nview","Link":"https:\/\/linux.die.net\/man\/1\/nview"}},{"Process":{"Description":"nwipe is a command that will securely erase disks using a variety of recognised methods. It is a fork of the dwipe command used by Darik's Boot and Nuke (dban). nwipe is included with partedmagic if want a quick and easy bootable CD version. nwipe was created out of a need to run the DBAN dwipe command outside of DBAN, in order to allow its use with any host distribution, thus giving better hardware support. It is essentially the same as dwipe, with a few changes: - pthreads is used instead of fork - The parted library is used to detect drives - The code is designed to be compiled with gcc","Process Name":"nwipe","Link":"https:\/\/linux.die.net\/man\/1\/nwipe"}},{"Process":{"Description":"rancid is a perl(1) script which uses the login scripts (see clogin(1)) to login to a device, execute commands to display the configuration, etc, then filters the output for formatting, security, and so on. rancid's product is a file with the name of it's last argument plus the suffix .new. For example, hostname.new. There are complementary scripts for other platforms and\/or manufacturers that are supported by rancid(1). Briefly, these are: agmrancid Cisco Anomaly Guard Module (AGM) arancid Alteon WebOS switches arrancid Arista Networks devices brancid Bay Networks (nortel) cat5rancid Cisco catalyst switches cssrancid Cisco content services switches erancid ADC-kentrox EZ-T3 mux f10rancid Force10 f5rancid F5 BigIPs fnrancid Fortinet Firewalls francid Foundry and HP procurve OEMs of Foundry hrancid HP Procurve Switches htranicd Hitachi Routers jerancid Juniper Networks E-series jrancid Juniper Networks mrancid MRTd mrvrancid MRV optical switches nrancid Netscreen firewalls nsrancid Netscaler nxrancid Cisco Nexus boxes prancid Procket Networks rivrancid Riverstone rrancid Redback srancid SMC switch (some Dell OEMs) trancid Netopia sDSL\/T1 routers tntrancid Lucent TNT xrancid Extreme switches xrrancid Cisco IOS-XR boxes zrancid Zebra routing software The command-line options are as follows: -V Prints package name and version strings. -d Display debugging information. -l Display somewhat less debugging information. -f rancid should interpret the next argument as a filename which contains the output it would normally collect from the device ( hostname) with clogin(1).","Process Name":"nxrancid","Link":"https:\/\/linux.die.net\/man\/1\/nxrancid"}},{"Process":{"Description":"nxtvepg is an X11 and Win32 application to receive, analyze and browse TV programme schedules transmitted on top of Teletext as defined by the European Telecommunications Standards Institute ( ETSI ) in ETS 300 707: \"Protocol for a TV Guide using electronic data transmission\". nxtvepgd is a stripped-down version of nxtvepg which only performs data acquisition as a background daemon process. The Nextview EPG standard was developed for use in TV sets, but the data can be received and used in a PC , too - provided you have a Teletext capable TV tuner card and are lucky enough to have a content provider in your country. nxtvepg enables you to obtain free TV programme listings for all of the major networks in Germany, Austria, France, Belgium and Switzerland. Currently Nextview EPG is transmitted by the following TV networks (note that each of these EPGs cover not only the provider's programme but also that of many other networks): \u2022 In Germany and Austria: Kabel1 (coverage: apx. 32 networks) \u2022 In Switzerland: SF1 , TSR1 , TSI1 , TV5 (coverage: apx. 37 networks) \u2022 In France: Canal+, M6, TV5 (coverage: 8 networks) \u2022 In Belgium: M6, TV5 (coverage: 32 networks) \u2022 In Turkey: TRT family (coverage: apx. 17 networks) For up-to-date information check the nxtvepg homepage in the Internet (see the About popup in the Help menu). If you don't receive any of the channels listed above, you can only use the demo mode as described with the -demo command line option. Since version 2.8.0 nxtvepg also allows to extract EPG data from teletext or import from external XMLTV sources. Note when importing data you need to take care to respect copyright, same as when exporting data. In particular, the German law does not permit \"Web scraping\", i.e. extraction of programme information from Internet sources without prior permission of the content provider.","Process Name":"nxtvepg","Link":"https:\/\/linux.die.net\/man\/1\/nxtvepg"}},{"Process":{"Description":"nycheck is a tool in the Nypatchy suite of programs for working with Patchy Master Files (PAM files); see nypatchy(1). Specifically, it is a syntax checker for these files which is more strict than nypatchy itself.","Process Name":"nycheck","Link":"https:\/\/linux.die.net\/man\/1\/nycheck"}},{"Process":{"Description":"nydiff is a tool in the Nypatchy suite of programs for working with Patchy Master Files (PAM files); see nypatchy(1). Specifically, it compares two different versions of the same PAM file and generates a \"correction patch\" that can be used by nypatchy to update the older version to the newer version.","Process Name":"nydiff","Link":"https:\/\/linux.die.net\/man\/1\/nydiff"}},{"Process":{"Description":"nyindex is a tool in the Nypatchy suite of programs for working with Patchy Master Files (PAM files); see nypatchy(1). Specifically, it can output a table of contents and\/or index for these files.","Process Name":"nyindex","Link":"https:\/\/linux.die.net\/man\/1\/nyindex"}},{"Process":{"Description":"nylist is a tool in the Nypatchy suite of programs for working with Patchy Master Files (PAM files); see nypatchy(1). Specifically, it can print a listing (including line numbers) of the contents of these files.","Process Name":"nylist","Link":"https:\/\/linux.die.net\/man\/1\/nylist"}},{"Process":{"Description":"nymerge is a tool in the Nypatchy suite of programs for working with Patchy Master Files (PAM files); see nypatchy(1). Specifically, it can update a PAM file old with a new version number and date\/time stamp, optionally also merging in updated source code from a separate PAM file merge, and saving the result to file new. The default file extension of these three files is presumed to be \".car\".","Process Name":"nymerge","Link":"https:\/\/linux.die.net\/man\/1\/nymerge"}},{"Process":{"Description":"nypatchy is a tool for working with Patchy Master Files (PAM files). A PAM file is an ordinary text file (generally with a three-letter extension of \".car\") that holds source code interleaved with special pre-processing instructions for nypatchy. The source code may be in C, FORTRAN, assembly language, or a combination of these. The pre-processing instructions allow one to maintain separate optional patches independently, for instance in the case of architecture-specific code. Details of the pre-processing commands used by nypatchy are beyond the scope of this man page; the reader should refer to the full manual available from CERN. Telling nypatchy which set of patches to use may be done on standard input or via a so-called cradle file. Typically the cradle file will contain one or more +USE statements as well as +EXE and +QUIT, for instance in the case of the isajet Monte Carlo generator: +USE,*ISAJET +EXE +PAM +QUIT","Process Name":"nypatchy","Link":"https:\/\/linux.die.net\/man\/1\/nypatchy"}},{"Process":{"Description":"nyshell is a tool in the Nypatchy suite of programs for working with Patchy Master Files (PAM files); see nypatchy(1). Specifically, given the log file of a nypatchy run, it can create a shell script to compile all the source code files output by nypatchy. This program is similar to fcasplit except that it takes the log file as input instead of a source file, and it remembers which source code files have already been compiled in previous runs.","Process Name":"nyshell","Link":"https:\/\/linux.die.net\/man\/1\/nyshell"}},{"Process":{"Description":"nysynopt is a tool in the Nypatchy suite of programs for working with Patchy Master Files (PAM files); see nypatchy(1). Like nylist, it can print a listing (including line numbers) of the contents of these files. However, it permits fine-tuning of the output through the use of a cradle file whose syntax is a subset of the nypatchy instruction set. It also expands sequences inline.","Process Name":"nysynopt","Link":"https:\/\/linux.die.net\/man\/1\/nysynopt"}},{"Process":{"Description":"nytidy is a tool in the Nypatchy suite of programs for working with Patchy Master Files (PAM files); see nypatchy(1). Specifically, it will make a cleaned-up copy of a PAM file. Changes include removal of trailing whitespace on each line, removal of trailing and leading comment lines (only in FORTRAN decks), and update of some built-in sequences.","Process Name":"nytidy","Link":"https:\/\/linux.die.net\/man\/1\/nytidy"}},{"Process":{"Description":null,"Process Name":"nytprofcg","Link":"https:\/\/linux.die.net\/man\/1\/nytprofcg"}},{"Process":{"Description":"\"nytprofcsv\" is a script that implements Devel::NYTProf::Reader to create comma-seperated value formatted reports from Devel::NYTProf databases. See the Devel::NYTProf Perl code profiler for more information.","Process Name":"nytprofcsv","Link":"https:\/\/linux.die.net\/man\/1\/nytprofcsv"}},{"Process":{"Description":null,"Process Name":"nytprofhtml","Link":"https:\/\/linux.die.net\/man\/1\/nytprofhtml"}}]